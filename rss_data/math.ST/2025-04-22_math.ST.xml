<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.ST updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.ST</link>
    <description>math.ST updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.ST" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 23 Apr 2025 01:47:48 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Testing Random Effects for Binomial Data</title>
      <link>https://arxiv.org/abs/2504.13977</link>
      <description>arXiv:2504.13977v1 Announce Type: new 
Abstract: In modern scientific research, small-scale studies with limited participants are increasingly common. However, interpreting individual outcomes can be challenging, making it standard practice to combine data across studies using random effects to draw broader scientific conclusions. In this work, we introduce an optimal methodology for assessing the goodness of fit between a given reference distribution and the distribution of random effects arising from binomial counts.
  Using the minimax framework, we characterize the smallest separation between the null and alternative hypotheses, called the critical separation, under the 1-Wasserstein distance that ensures the existence of a valid and powerful test. The optimal test combines a plug-in estimator of the Wasserstein distance with a debiased version of Pearson's chi-squared test.
  We focus on meta-analyses, where a key question is whether multiple studies agree on a treatment's effectiveness before pooling data. That is, researchers must determine whether treatment effects are homogeneous across studies. We begin by analyzing scenarios with a specified reference effect, such as testing whether all studies show the treatment is effective 80% of the time, and describe how the critical separation depends on the reference effect. We then extend the analysis to homogeneity testing without a reference effect and construct an optimal test by debiasing Cochran's chi-squared test.
  Finally, we illustrate how our proposed methodologies improve the construction of p-values and confidence intervals, with applications to assessing drug safety in the context of rare adverse outcomes and modeling political outcomes at the county level.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.13977v1</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lucas Kania, Larry Wasserman, Sivaraman Balakrishnan</dc:creator>
    </item>
    <item>
      <title>Asymptotic well-calibration of the posterior predictive $p$-value under the modified Kolmogorov-Smirnov test</title>
      <link>https://arxiv.org/abs/2504.14077</link>
      <description>arXiv:2504.14077v1 Announce Type: new 
Abstract: The posterior predictive $p$-value is a widely used tool for Bayesian model checking. However, under most test statistics, its asymptotic null distribution is more concentrated around 1/2 than uniform. Consequently, its finite-sample behavior is difficult to interpret and tends to lack power, which is a well-known issue among practitioners. A common choice of test statistic is the Kolmogorov-Smirnov test with plug-in estimators. It provides a global measure of model-data discrepancy for real-valued observations and is sensitive to model misspecification. In this work, we establish that under this test statistic, the posterior predictive $p$-value converges in distribution to uniform under the null. We further use numerical experiments to demonstrate that this $p$-value is well-behaved in finite samples and can effectively detect a wide range of alternative models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14077v1</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yueming Shen</dc:creator>
    </item>
    <item>
      <title>Robust Estimation in metric spaces: Achieving Exponential Concentration with a Fr\'echet Median</title>
      <link>https://arxiv.org/abs/2504.14161</link>
      <description>arXiv:2504.14161v1 Announce Type: new 
Abstract: There is growing interest in developing statistical estimators that achieve exponential concentration around a population target even when the data distribution has heavier than exponential tails. More recent activity has focused on extending such ideas beyond Euclidean spaces to Hilbert spaces and Riemannian manifolds. In this work, we show that such exponential concentration in presence of heavy tails can be achieved over a broader class of parameter spaces called CAT($\kappa$) spaces, a very general metric space equipped with the minimal essential geometric structure for our purpose, while being sufficiently broad to encompass most typical examples encountered in statistics and machine learning. The key technique is to develop and exploit a general concentration bound for the Fr\'echet median in CAT($\kappa$) spaces. We illustrate our theory through a number of examples, and provide empirical support through simulation studies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14161v1</guid>
      <category>math.ST</category>
      <category>math.MG</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Proceedings of the 28th International Conference on Artificial Intelligence and Statistics (AISTATS) 2025, PMLR 258</arxiv:journal_reference>
      <dc:creator>Jakwang Kim, Jiyoung Park, Anirban Bhattacharya</dc:creator>
    </item>
    <item>
      <title>Nonparametric Estimation in Uniform Deconvolution and Interval Censoring</title>
      <link>https://arxiv.org/abs/2504.14555</link>
      <description>arXiv:2504.14555v1 Announce Type: new 
Abstract: In the uniform deconvolution problem one is interested in estimating the distribution function $F_0$ of a nonnegative random variable, based on a sample with additive uniform noise. A peculiar and not well understood phenomenon of the nonparametric maximum likelihood estimator in this setting is the dichotomy between the situations where $F_0(1)=1$ and $F_0(1)&lt;1$. If $F_0(1)=1$, the MLE can be computed in a straightforward way and its asymptotic pointwise behavior can be derived using the connection to the so-called current status problem. However, if $F_0(1)&lt;1$, one needs an iterative procedure to compute it and the asymptotic pointwise behavior of the nonparametric maximum likelihood estimator is not known. In this paper we describe the problem, connect it to interval censoring problems and a more general model studied in Groeneboom (2024) to state two competing naturally occurring conjectures for the case $F_0(1)&lt;1$. Asymptotic arguments related to smooth functional theory and extensive simulations lead us to to bet on one of these two conjectures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14555v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Piet Groeneboom, Geurt Jongbloed</dc:creator>
    </item>
    <item>
      <title>Sum of Independent XGamma Distributions</title>
      <link>https://arxiv.org/abs/2504.15186</link>
      <description>arXiv:2504.15186v1 Announce Type: new 
Abstract: The XGamma distribution is a generated distribution from a mixture of Exponential and Gamma distributions. It is found that in many cases the XGamma has more flexibility than the Exponential distribution. In this paper we consider the sum of independent XGamma distributions with different parameters. We showed that the probability density function of this distribution is a sum of the probability density function of the Erlang distributions. As a consequence, we find exact closed expressions of the other related statistical functions. Next, we examine the estimation of the parameters by maximum likelihood estimators. We observe in an applications a real data set which shows that this model provides better fit to the data as compared to the sum of the Exponential distributions, the Hypoexponential models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.15186v1</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Therrar Kadri, Rahil Omairi, Khaled Smaili, Seifedine Kadry</dc:creator>
    </item>
    <item>
      <title>Markovian Continuity of the MMSE</title>
      <link>https://arxiv.org/abs/2504.14659</link>
      <description>arXiv:2504.14659v1 Announce Type: cross 
Abstract: Minimum mean square error (MMSE) estimation is widely used in signal processing and related fields. While it is known to be non-continuous with respect to all standard notions of stochastic convergence, it remains robust in practical applications. In this work, we review the known counterexamples to the continuity of the MMSE. We observe that, in these counterexamples, the discontinuity arises from an element in the converging measurement sequence providing more information about the estimand than the limit of the measurement sequence. We argue that this behavior is uncharacteristic of real-world applications and introduce a new stochastic convergence notion, termed Markovian convergence, to address this issue. We prove that the MMSE is, in fact, continuous under this new notion. We supplement this result with semi-continuity and continuity guarantees of the MMSE in other settings and prove the continuity of the MMSE under linear estimation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14659v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Elad Domanovitz, Anatoly Khina</dc:creator>
    </item>
    <item>
      <title>Prevalence estimation in infectious diseases with imperfect tests: A comparison of Frequentist and Bayesian Logistic Regression methods with misclassification correction</title>
      <link>https://arxiv.org/abs/2504.15150</link>
      <description>arXiv:2504.15150v1 Announce Type: cross 
Abstract: Accurate estimation of disease prevalence is essential for guiding public health strategies. Imperfect diagnostic tests can cause misclassification errors-false positives (FP) and false negatives (FN)-that may skew estimates if unaddressed. This study compared four statistical methods for estimating the prevalence of sexually transmitted infections (STIs) and associated factors, while correcting for misclassification. The methods were: (1) Standard Logistic Regression with external correction using known sensitivity and specificity; (2) the Liu et al. model, which jointly estimates FP and FN rates; (3) Bayesian Logistic Regression with external correction; and (4) a Bayesian model with internal correction using informative priors on diagnostic accuracy. Data came from 11,452 participants in a voluntary screening campaign for HIV, syphilis, and hepatitis B (2020-2024). Prevalence estimates and regression coefficients were compared across models using relative changes from crude estimates, confidence interval (CI) width, and coefficient variability. The Liu model produced higher prevalence estimates but had wider CIs and convergence issues in low-prevalence settings. The Bayesian model with internal correction gave intermediate estimates with the narrowest CIs and more stable intercepts, suggesting improved baseline prevalence estimation. Informative or weakly informative priors helped regularize estimates, especially in small-sample or rare-event contexts. Accounting for misclassification influenced both prevalence and covariate associations. While the Liu model offers theoretical strengths, its practical limitations in sparse data settings reduce its utility. Bayesian models with misclassification correction emerge as robust and flexible tools, particularly valuable in low-prevalence contexts where diagnostic uncertainty is high.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.15150v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jorge Mario Estrada Alvarez, Henan F. Garcia, Miguel \'Angel Montero-Alonso, Juan de Dios Luna del Castillo</dc:creator>
    </item>
    <item>
      <title>On Learning Parallel Pancakes with Mostly Uniform Weights</title>
      <link>https://arxiv.org/abs/2504.15251</link>
      <description>arXiv:2504.15251v1 Announce Type: cross 
Abstract: We study the complexity of learning $k$-mixtures of Gaussians ($k$-GMMs) on $\mathbb{R}^d$. This task is known to have complexity $d^{\Omega(k)}$ in full generality. To circumvent this exponential lower bound on the number of components, research has focused on learning families of GMMs satisfying additional structural properties. A natural assumption posits that the component weights are not exponentially small and that the components have the same unknown covariance. Recent work gave a $d^{O(\log(1/w_{\min}))}$-time algorithm for this class of GMMs, where $w_{\min}$ is the minimum weight. Our first main result is a Statistical Query (SQ) lower bound showing that this quasi-polynomial upper bound is essentially best possible, even for the special case of uniform weights. Specifically, we show that it is SQ-hard to distinguish between such a mixture and the standard Gaussian. We further explore how the distribution of weights affects the complexity of this task. Our second main result is a quasi-polynomial upper bound for the aforementioned testing task when most of the weights are uniform while a small fraction of the weights are potentially arbitrary.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.15251v1</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ilias Diakonikolas, Daniel M. Kane, Sushrut Karmalkar, Jasper C. H. Lee, Thanasis Pittas</dc:creator>
    </item>
    <item>
      <title>Tail Bounds for Canonical $U$-Statistics and $U$-Processes with Unbounded Kernels</title>
      <link>https://arxiv.org/abs/2504.01318</link>
      <description>arXiv:2504.01318v2 Announce Type: replace 
Abstract: In this paper, we prove exponential tail bounds for canonical (or degenerate) $U$-statistics and $U$-processes under exponential-type tail assumptions on the kernels. Most of the existing results in the relevant literature often assume bounded kernels or obtain sub-optimal tail behavior under unbounded kernels. We obtain sharp rates and optimal tail behavior under sub-Weibull kernel functions. Some examples from nonparametric and semiparametric statistics literature are considered.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.01318v2</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Abhishek Chakrabortty, Arun K. Kuchibhotla</dc:creator>
    </item>
    <item>
      <title>Power properties of the two-sample test based on the nearest neighbors graph</title>
      <link>https://arxiv.org/abs/2504.10719</link>
      <description>arXiv:2504.10719v2 Announce Type: replace 
Abstract: In this paper, we study the problem of testing the equality of two multivariate distributions. One class of tests used for this purpose utilizes geometric graphs constructed using inter-point distances. So far, the asymptotic theory of these tests applies only to graphs which fall under the stabilizing graphs framework of \citet{penroseyukich2003weaklaws}. We study the case of the $K$-nearest neighbors graph where $K=k_N$ increases with the sample size, which does not fall under the stabilizing graphs framework. Our main result gives detection thresholds for this test in parametrized families when $k_N = o(N^{1/4})$, thus extending the family of graphs where the theoretical behavior is known. We propose a 2-sided version of the test which removes an exponent gap that plagues the 1-sided test. Our result also shows that increasing the number of nearest neighbors boosts the power of the test. This provides theoretical justification for using denser graphs in testing equality of two distributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.10719v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rahul Raphael Kanekar</dc:creator>
    </item>
    <item>
      <title>Estimation and inference in error-in-operator model</title>
      <link>https://arxiv.org/abs/2504.11834</link>
      <description>arXiv:2504.11834v2 Announce Type: replace 
Abstract: Many statistical problems can be reduced to a linear inverse problem in which only a noisy version of the operator is available. Particular examples include random design regression, deconvolution problem, instrumental variable regression, functional data analysis, error-in-variable regression, drift estimation in stochastic diffusion, and many others. The pragmatic plug-in approach can be well justified in the classical asymptotic setup with a growing sample size. However, recent developments in high dimensional inference reveal some new features of this problem. In high dimensional linear regression with a random design, the plug-in approach is questionable but the use of a simple ridge penalization yields a benign overfitting phenomenon; see \cite{baLoLu2020}, \cite{ChMo2022}, \cite{NoPuSp2024}. This paper revisits the general Error-in-Operator problem for finite samples and high dimension of the source and image spaces. A particular focus is on the choice of a proper regularization. We show that a simple ridge penalty (Tikhonov regularization) works properly in the case when the operator is more regular than the signal. In the opposite case, some model reduction technique like spectral truncation should be applied.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.11834v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vladimir Spokoiny</dc:creator>
    </item>
    <item>
      <title>Universal time-series forecasting with mixture predictors</title>
      <link>https://arxiv.org/abs/2010.00297</link>
      <description>arXiv:2010.00297v2 Announce Type: replace-cross 
Abstract: This book is devoted to the problem of sequential probability forecasting, that is, predicting the probabilities of the next outcome of a growing sequence of observations given the past. This problem is considered in a very general setting that unifies commonly used probabilistic and non-probabilistic settings, trying to make as few as possible assumptions on the mechanism generating the observations. A common form that arises in various formulations of this problem is that of mixture predictors, which are formed as a combination of a finite or infinite set of other predictors attempting to combine their predictive powers. The main subject of this book are such mixture predictors, and the main results demonstrate the universality of this method in a very general probabilistic setting, but also show some of its limitations. While the problems considered are motivated by practical applications, involving, for example, financial, biological or behavioural data, this motivation is left implicit and all the results exposed are theoretical.
  The book targets graduate students and researchers interested in the problem of sequential prediction, and, more generally, in theoretical analysis of problems in machine learning and non-parametric statistics, as well as mathematical and philosophical foundations of these fields.
  The material in this volume is presented in a way that presumes familiarity with basic concepts of probability and statistics, up to and including probability distributions over spaces of infinite sequences. Familiarity with the literature on learning or stochastic processes is not required.</description>
      <guid isPermaLink="false">oai:arXiv.org:2010.00297v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/978-3-030-54304-4</arxiv:DOI>
      <dc:creator>Daniil Ryabko</dc:creator>
    </item>
    <item>
      <title>Online Statistical Inference in Decision-Making with Matrix Context</title>
      <link>https://arxiv.org/abs/2212.11385</link>
      <description>arXiv:2212.11385v2 Announce Type: replace-cross 
Abstract: The study of online decision-making problems that leverage contextual information has drawn notable attention due to their significant applications in fields ranging from healthcare to autonomous systems. In modern applications, contextual information can be rich and is often represented as a matrix. Moreover, while existing online decision algorithms mainly focus on reward maximization, less attention has been devoted to statistical inference. To address these gaps, in this work, we consider an online decision-making problem with a matrix context where the true model parameters have a low-rank structure. We propose a fully online procedure to conduct statistical inference with adaptively collected data. The low-rank structure of the model parameter and the adaptive nature of the data collection process make this difficult: standard low-rank estimators are biased and cannot be obtained in a sequential manner while existing inference approaches in sequential decision-making algorithms fail to account for the low-rankness and are also biased. To overcome these challenges, we introduce a new online debiasing procedure to simultaneously handle both sources of bias. Our inference framework encompasses both parameter inference and optimal policy value inference. In theory, we establish the asymptotic normality of the proposed online debiased estimators and prove the validity of the constructed confidence intervals for both inference tasks. Our inference results are built upon a newly developed low-rank stochastic gradient descent estimator and its convergence result, which are also of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.11385v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qiyu Han, Will Wei Sun, Yichen Zhang</dc:creator>
    </item>
    <item>
      <title>The Decaying Missing-at-Random Framework: Model Doubly Robust Causal Inference with Partially Labeled Data</title>
      <link>https://arxiv.org/abs/2305.12789</link>
      <description>arXiv:2305.12789v3 Announce Type: replace-cross 
Abstract: In modern large-scale observational studies, data collection constraints often result in partially labeled datasets, posing challenges for reliable causal inference, especially due to potential labeling bias and relatively small size of the labeled data. This paper introduces a decaying missing-at-random (decaying MAR) framework and associated approaches for doubly robust causal inference on treatment effects in such semi-supervised (SS) settings. This simultaneously addresses selection bias in the labeling mechanism and the extreme imbalance between labeled and unlabeled groups, bridging the gap between the standard SS and missing data literatures, while throughout allowing for confounded treatment assignment and high-dimensional confounders under appropriate sparsity conditions. To ensure robust causal conclusions, we propose a bias-reduced SS (BRSS) estimator for the average treatment effect, a type of 'model doubly robust' estimator appropriate for such settings, establishing asymptotic normality at the appropriate rate under decaying labeling propensity scores, provided that at least one nuisance model is correctly specified. Our approach also relaxes sparsity conditions beyond those required in existing methods, including standard supervised approaches. Recognizing the asymmetry between labeling and treatment mechanisms, we further introduce a de-coupled BRSS (DC-BRSS) estimator, which integrates inverse probability weighting (IPW) with bias-reducing techniques in nuisance estimation. This refinement further weakens model specification and sparsity requirements. Numerical experiments confirm the effectiveness and adaptability of our estimators in addressing labeling bias and model misspecification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.12789v3</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuqian Zhang, Abhishek Chakrabortty, Jelena Bradic</dc:creator>
    </item>
    <item>
      <title>Aggregating Dependent Signals with Heavy-Tailed Combination Tests</title>
      <link>https://arxiv.org/abs/2310.20460</link>
      <description>arXiv:2310.20460v3 Announce Type: replace-cross 
Abstract: Combining dependent p-values poses a long-standing challenge in statistical inference, particularly when aggregating findings from multiple methods to enhance signal detection. Recently, p-value combination tests based on regularly varying-tailed distributions, such as the Cauchy combination test and harmonic mean p-value, have attracted attention for their robustness to unknown dependence. This paper provides a theoretical and empirical evaluation of these methods under an asymptotic regime where the number of p-values is fixed and the global test significance level approaches zero. We examine two types of dependence among the p-values. First, when p-values are pairwise asymptotically independent, such as with bivariate normal test statistics with no perfect correlation, we prove that these combination tests are asymptotically valid. However, they become equivalent to the Bonferroni test as the significance level tends to zero for both one-sided and two-sided p-values. Empirical investigations suggest that this equivalence can emerge at moderately small significance levels. Second, under pairwise quasi-asymptotic dependence, such as with bivariate t-distributed test statistics, our simulations suggest that these combination tests can remain valid and exhibit notable power gains over Bonferroni, even as the significance level diminishes. These findings highlight the potential advantages of these combination tests in scenarios where p-values exhibit substantial dependence. Our simulations also examine how test performance depends on the support and tail heaviness of the underlying distributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.20460v3</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.TH</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lin Gui, Yuchao Jiang, Jingshu Wang</dc:creator>
    </item>
    <item>
      <title>Inference for Synthetic Controls via Refined Placebo Tests</title>
      <link>https://arxiv.org/abs/2401.07152</link>
      <description>arXiv:2401.07152v3 Announce Type: replace-cross 
Abstract: The synthetic control method is often applied to problems with one treated unit and a small number of control units. A common inferential task in this setting is to test null hypotheses regarding the average treatment effect on the treated. Inference procedures that are justified asymptotically are often unsatisfactory due to (1) small sample sizes that render large-sample approximation fragile and (2) simplification of the estimation procedure that is implemented in practice. An alternative is permutation inference, which is related to a common diagnostic called the placebo test. It has provable Type-I error guarantees in finite samples without simplification of the method, when the treatment is uniformly assigned. Despite this robustness, the placebo test suffers from low resolution since the null distribution is constructed from only $N$ reference estimates, where $N$ is the sample size. This creates a barrier for statistical inference at a common level like $\alpha = 0.05$, especially when $N$ is small. We propose a novel leave-two-out procedure that bypasses this issue, while still maintaining the same finite-sample Type-I error guarantee under uniform assignment for a wide range of $N$. Unlike the placebo test whose Type-I error always equals the theoretical upper bound, our procedure often achieves a lower unconditional Type-I error than theory suggests; this enables useful inference in the challenging regime when $\alpha &lt; 1/N$. Empirically, our procedure achieves a higher power when the effect size is reasonably large and a comparable power otherwise. We generalize our procedure to non-uniform assignments and show how to conduct sensitivity analysis. From a methodological perspective, our procedure can be viewed as a new type of randomization inference different from permutation or rank-based inference, which is particularly effective in small samples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.07152v3</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lihua Lei, Timothy Sudijono</dc:creator>
    </item>
    <item>
      <title>Early Detection of Treatments Side Effect: A Sequential Approach</title>
      <link>https://arxiv.org/abs/2401.13760</link>
      <description>arXiv:2401.13760v2 Announce Type: replace-cross 
Abstract: With the emergence and spread of infectious diseases with pandemic potential, such as COVID- 19, the urgency for vaccine development have led to unprecedented compressed and accelerated schedules that shortened the standard development timeline. In a relatively short time, the leading pharmaceutical companies1, received an Emergency Use Authorization (EUA) for vaccine\prime s en-mass deployment To monitor the potential side effect(s) of the vaccine during the (initial) vaccination campaign, we developed an optimal sequential test that allows for the early detection of potential side effect(s). This test employs a rule to stop the vaccination process once the observed number of side effect incidents exceeds a certain (pre-determined) threshold. The optimality of the proposed sequential test is justified when compared with the ({\alpha}, {\beta}) optimality of the non-randomized fixed-sample Uniformly Most Powerful (UMP) test. In the case of a single side effect, we study the properties of the sequential test and derive the exact expressions of the Average Sample Number (ASN) curve of the stopping time (and its variance) via the regularized incomplete beta function. Additionally, we derive the asymptotic distribution of the relative savings in ASN as compared to maximal sample size. Moreover, we construct the post-test parameter estimate and studied its sampling properties, including its asymptotic behavior under local-type alternatives. These limiting behavior results are the consistency and asymptotic normality of the post-test parameter estimator. We conclude the paper with a small simulation study illustrating the asymptotic performance of the point and interval estimation and provide a detailed example, based on COVID-19 side effect data (see Beatty et al. (2021)) of our suggested testing procedure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.13760v2</guid>
      <category>stat.AP</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiayue Wang, Ben Boukai</dc:creator>
    </item>
    <item>
      <title>Federated Transfer Learning with Differential Privacy</title>
      <link>https://arxiv.org/abs/2403.11343</link>
      <description>arXiv:2403.11343v3 Announce Type: replace-cross 
Abstract: Federated learning has emerged as a powerful framework for analysing distributed data, yet two challenges remain pivotal: heterogeneity across sites and privacy of local data. In this paper, we address both challenges within a federated transfer learning framework, aiming to enhance learning on a target data set by leveraging information from multiple heterogeneous source data sets while adhering to privacy constraints. We rigorously formulate the notion of federated differential privacy, which offers privacy guarantees for each data set without assuming a trusted central server. Under this privacy model, we study three classical statistical problems: univariate mean estimation, low-dimensional linear regression, and high-dimensional linear regression. By investigating the minimax rates and quantifying the cost of privacy in each problem, we show that federated differential privacy is an intermediate privacy model between the well-established local and central models of differential privacy. Our analyses account for data heterogeneity and privacy, highlighting the fundamental costs associated with each factor and the benefits of knowledge transfer in federated learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11343v3</guid>
      <category>cs.LG</category>
      <category>cs.CR</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mengchu Li, Ye Tian, Yang Feng, Yi Yu</dc:creator>
    </item>
    <item>
      <title>4+3 Phases of Compute-Optimal Neural Scaling Laws</title>
      <link>https://arxiv.org/abs/2405.15074</link>
      <description>arXiv:2405.15074v3 Announce Type: replace-cross 
Abstract: We consider the solvable neural scaling model with three parameters: data complexity, target complexity, and model-parameter-count. We use this neural scaling model to derive new predictions about the compute-limited, infinite-data scaling law regime. To train the neural scaling model, we run one-pass stochastic gradient descent on a mean-squared loss. We derive a representation of the loss curves which holds over all iteration counts and improves in accuracy as the model parameter count grows. We then analyze the compute-optimal model-parameter-count, and identify 4 phases (+3 subphases) in the data-complexity/target-complexity phase-plane. The phase boundaries are determined by the relative importance of model capacity, optimizer noise, and embedding of the features. We furthermore derive, with mathematical proof and extensive numerical evidence, the scaling-law exponents in all of these phases, in particular computing the optimal model-parameter-count as a function of floating point operation budget.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15074v3</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Elliot Paquette, Courtney Paquette, Lechao Xiao, Jeffrey Pennington</dc:creator>
    </item>
    <item>
      <title>Efficient estimation and data fusion under general semiparametric restrictions on outcome mean functions</title>
      <link>https://arxiv.org/abs/2406.06941</link>
      <description>arXiv:2406.06941v3 Announce Type: replace-cross 
Abstract: We provide a novel characterization of semiparametric efficiency in a generic supervised learning setting where the outcome mean function -- defined as the conditional expectation of the outcome of interest given the other observed variables -- is restricted to lie in some known semiparametric function class. The primary motivation is causal inference where a researcher running a randomized controlled trial often has access to an auxiliary observational dataset that is confounded or otherwise biased for estimating causal effects. Prior work has imposed various bespoke assumptions on this bias in an attempt to improve precision via data fusion. We show how many of these assumptions can be formulated as restrictions on the outcome mean function in the concatenation of the experimental and observational datasets. Then our theory provides a unified framework to maximally leverage such restrictions for precision gain by constructing efficient estimators in all of these settings as well as in a wide range of others that future investigators might be interested in. For example, when the observational dataset is subject to outcome-mediated selection bias, we show our novel efficient estimator dominates an existing control variate approach both asymptotically and in numerical studies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06941v3</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Harrison H. Li</dc:creator>
    </item>
    <item>
      <title>Higher-criticism for sparse multi-stream change-point detection</title>
      <link>https://arxiv.org/abs/2409.15597</link>
      <description>arXiv:2409.15597v2 Announce Type: replace-cross 
Abstract: We study a statistical procedure based on higher criticism (HC) to address the sparse multi-stream quickest change-point detection problem. Namely, we aim to detect a potential change in the distribution of multiple data streams at some unknown time. If a change occurs, only a few streams are affected, whereas the identity of the affected streams is unknown. The HC-based procedure involves testing for a change point in individual streams and combining multiple tests using higher criticism. Relying on HC thresholding, the procedure also indicates a set of streams suspected to be affected by the change. We provide a theoretical analysis under a sparse heteroscedastic normal change-point model. We establish an information-theoretic detection delay lower bound when individual tests are based on the likelihood ratio or the generalized likelihood ratio statistics and show that the delay of the HC-based method converges in distribution to this bound. In the special case of constant variance, our bound coincides with known results in (Chan, 2017). We demonstrate the effectiveness of the HC-based method compared to other methods in detecting sparse changes through extensive numerical evaluations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.15597v2</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tingnan Gong, Alon Kipnis, Yao Xie</dc:creator>
    </item>
    <item>
      <title>Algorithmic contiguity from low-degree conjecture and applications in correlated random graphs</title>
      <link>https://arxiv.org/abs/2502.09832</link>
      <description>arXiv:2502.09832v2 Announce Type: replace-cross 
Abstract: In this paper, assuming a natural strengthening of the low-degree conjecture, we provide evidence of computational hardness for two problems: (1) the (partial) matching recovery problem in the sparse correlated Erd\H{o}s-R\'enyi graphs $\mathcal G(n,q;\rho)$ when the edge-density $q=n^{-1+o(1)}$ and the correlation $\rho&lt;\sqrt{\alpha}$ lies below the Otter's threshold, solving a remaining problem in \cite{DDL23+}; (2) the detection problem between the correlated sparse stochastic block model $\mathcal S(n,\tfrac{\lambda}{n};k,\epsilon;s)$ and a pair of independent stochastic block models $\mathcal S(n,\tfrac{\lambda s}{n};k,\epsilon)$ when $\epsilon^2 \lambda s&lt;1$ lies below the Kesten-Stigum (KS) threshold and $s&lt;\sqrt{\alpha}$ lies below the Otter's threshold, solving a remaining problem in \cite{CDGL24+}.
  One of the main ingredient in our proof is to derive certain forms of \emph{algorithmic contiguity} between two probability measures based on bounds on their low-degree advantage. To be more precise, consider the high-dimensional hypothesis testing problem between two probability measures $\mathbb{P}$ and $\mathbb{Q}$ based on the sample $\mathsf Y$. We show that if the low-degree advantage $\mathsf{Adv}_{\leq D} \big( \frac{\mathrm{d}\mathbb{P}}{\mathrm{d}\mathbb{Q}} \big)=O(1)$, then (assuming the low-degree conjecture) there is no efficient algorithm $\mathcal A$ such that $\mathbb{Q}(\mathcal A(\mathsf Y)=0)=1-o(1)$ and $\mathbb{P}(\mathcal A(\mathsf Y)=1)=\Omega(1)$. This framework provides a useful tool for performing reductions between different inference tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.09832v2</guid>
      <category>stat.ML</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhangsong Li</dc:creator>
    </item>
    <item>
      <title>Testing Conditional Stochastic Dominance at Target Points</title>
      <link>https://arxiv.org/abs/2503.14747</link>
      <description>arXiv:2503.14747v2 Announce Type: replace-cross 
Abstract: This paper introduces a novel test for conditional stochastic dominance (CSD) at specific values of the conditioning covariates, referred to as target points. The test is relevant for analyzing income inequality, evaluating treatment effects, and studying discrimination. We propose a Kolmogorov--Smirnov-type test statistic that utilizes induced order statistics from independent samples. Notably, the test features a data-independent critical value, eliminating the need for resampling techniques such as the bootstrap. Our approach avoids kernel smoothing and parametric assumptions, instead relying on a tuning parameter to select relevant observations. We establish the asymptotic properties of our test, showing that the induced order statistics converge to independent draws from the true conditional distributions and that the test is asymptotically of level $\alpha$ under weak regularity conditions. While our results apply to both continuous and discrete data, in the discrete case, the critical value only provides a valid upper bound. To address this, we propose a refined critical value that significantly enhances power, requiring only knowledge of the support size of the distributions. Additionally, we analyze the test's behavior in the limit experiment, demonstrating that it reduces to a problem analogous to testing unconditional stochastic dominance in finite samples. This framework allows us to prove the validity of permutation-based tests for stochastic dominance when the random variables are continuous. Monte Carlo simulations confirm the strong finite-sample performance of our method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.14747v2</guid>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Federico A. Bugni, Ivan A. Canay, Deborah Kim</dc:creator>
    </item>
    <item>
      <title>A Computational Theory for Efficient Model Evaluation with Causal Guarantees</title>
      <link>https://arxiv.org/abs/2503.21138</link>
      <description>arXiv:2503.21138v3 Announce Type: replace-cross 
Abstract: In order to reduce the cost of experimental evaluation for models, we introduce a computational theory of evaluation for prediction and decision models: build evaluation model to accelerate the evaluation procedures. We prove upper bounds of generalized error and generalized causal effect error of given evaluation models. We also prove efficiency, and consistency to estimated causal effect from deployed subject to evaluation metric by prediction. To learn evaluation models, we propose a meta-learner to handle heterogeneous evaluation subjects space problem. Comparing with existed evaluation approaches, our (conditional) evaluation model reduced 24.1\%-99.0\% evaluation errors across 12 scenes, including individual medicine, scientific simulation, social experiment, business activity, and quantum trade. The evaluation time is reduced 3-7 order of magnitude comparing with experiments or simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.21138v3</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hedong Yan</dc:creator>
    </item>
    <item>
      <title>An Improved Satterthwaite Effective Degrees of Freedom Correction for Weighted Syntheses of Variance</title>
      <link>https://arxiv.org/abs/2503.22080</link>
      <description>arXiv:2503.22080v2 Announce Type: replace-cross 
Abstract: This article presents an improved approximation for the effective degrees of freedom in the Satterthwaite (1941, 1946) method which estimates the distribution of a weighted combination of variance components The standard Satterthwaite approximation assumes a scaled chisquare distribution for the composite variance estimator but is known to be biased downward when component degrees of freedom are small. Building on recent work by von Davier (2025), we propose an adjusted estimator that corrects this bias by modifying both the numerator and denominator of the traditional formula. The new approximation incorporates a weighted average of component degrees of freedom and a scaling factor that ensures consistency as the number of components or their degrees of freedom increases. We demonstrate the utility of this adjustment in practical settings, including Rubin's (1987) total variance estimation in multiple imputations, where weighted variance combinations are common. The proposed estimator generalizes and further improves von Davier's (2025) unweighted case and more accurately approximates synthetic variance estimators with arbitrary weights.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.22080v2</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Matthias von Davier</dc:creator>
    </item>
  </channel>
</rss>
