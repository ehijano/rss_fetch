<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NE</link>
    <description>cs.NE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 18 Apr 2025 01:42:37 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Adaptively Pruned Spiking Neural Networks for Energy-Efficient Intracortical Neural Decoding</title>
      <link>https://arxiv.org/abs/2504.11568</link>
      <description>arXiv:2504.11568v1 Announce Type: new 
Abstract: Intracortical brain-machine interfaces demand low-latency, energy-efficient solutions for neural decoding. Spiking Neural Networks (SNNs) deployed on neuromorphic hardware have demonstrated remarkable efficiency in neural decoding by leveraging sparse binary activations and efficient spatiotemporal processing. However, reducing the computational cost of SNNs remains a critical challenge for developing ultra-efficient intracortical neural implants. In this work, we introduce a novel adaptive pruning algorithm specifically designed for SNNs with high activation sparsity, targeting intracortical neural decoding. Our method dynamically adjusts pruning decisions and employs a rollback mechanism to selectively eliminate redundant synaptic connections without compromising decoding accuracy. Experimental evaluation on the NeuroBench Non-Human Primate (NHP) Motor Prediction benchmark shows that our pruned network achieves performance comparable to dense networks, with a maximum tenfold improvement in efficiency. Moreover, hardware simulation on the neuromorphic processor reveals that the pruned network operates at sub-$\mu$W power levels, underscoring its potential for energy-constrained neural implants. These results underscore the promise of our approach for advancing energy-efficient intracortical brain-machine interfaces with low-overhead on-device intelligence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.11568v1</guid>
      <category>cs.NE</category>
      <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Francesca Rivelli, Martin Popov, Charalampos S. Kouzinopoulos, Guangzhi Tang</dc:creator>
    </item>
    <item>
      <title>Graph-Theoretic Measures for Interpretable Multicriteria Decision Making in Emergency Department Layout Optimization</title>
      <link>https://arxiv.org/abs/2504.11620</link>
      <description>arXiv:2504.11620v1 Announce Type: new 
Abstract: Overcrowding in emergency departments (ED) is a persistent problem exacerbated by population growth, emergence of pandemics, and increased morbidity and mortality rates. Thus, automated approaches for ED layout design have recently emerged as promising tools for boosting healthcare service quality. Still, ED design typically involves multiple conflicting objectives, where the interpretability of the associated solutions depends on the availability of intuitive metrics that can capture ED layout complexity. In this paper, we propose graph-theoretic measures to evaluate and rank ED layouts produced by a multi-objective metaheuristic optimization framework with the non-dominated sorting genetic algorithm (NSGA-II) and generalized differential evolution (GDE3). Indeed, Pareto-optimal ED layouts were sought to minimize patient flow cost while maximizing closeness between ED service areas. Then, the layouts were evaluated based on local graph measures (degree centrality, betweenness, clustering coefficient, closeness centrality, nodal strength, and eccentricity) as well as global ones (global efficiency, network characteristic path length and transitivity). Then, a multi-criteria decision-making technique was employed to rank the layouts based on either the objective functions, the graph measures, or combinations of both. The ranking results on a real-world scenario show that the top-ranking layouts are the ones with the best graph-theoretic values. This shows that the graph-theoretic measures can enhance solution interpretability and hence help medical planners in selecting the best layouts. In comparison with the input layout, optimal NSGA-II and GDE3 solutions reduce the patient flow cost by 18.32% and 11.42%, respectively. Also, the two solutions improve the closeness by 14.5% and 18.02%, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.11620v1</guid>
      <category>cs.NE</category>
      <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ola Sarhan, Manal Abdel Wahed, Muhammad Ali Rushdi</dc:creator>
    </item>
    <item>
      <title>Polarisation-Inclusive Spiking Neural Networks for Real-Time RFI Detection in Modern Radio Telescopes</title>
      <link>https://arxiv.org/abs/2504.11720</link>
      <description>arXiv:2504.11720v1 Announce Type: new 
Abstract: Radio Frequency Interference (RFI) is a known growing challenge for radio astronomy, intensified by increasing observatory sensitivity and prevalence of orbital RFI sources. Spiking Neural Networks (SNNs) offer a promising solution for real-time RFI detection by exploiting the time-varying nature of radio observation and neuron dynamics together. This work explores the inclusion of polarisation information in SNN-based RFI detection, using simulated data from the Hydrogen Epoch of Reionisation Array (HERA) instrument and provides power usage estimates for deploying SNN-based RFI detection on existing neuromorphic hardware. Preliminary results demonstrate state-of-the-art detection accuracy and highlight possible extensive energy-efficiency gains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.11720v1</guid>
      <category>cs.NE</category>
      <category>astro-ph.IM</category>
      <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicholas J. Pritchard, Andreas Wicenec, Richard Dodson, Mohammed Bennamoun</dc:creator>
    </item>
    <item>
      <title>Learning Strategies in Particle Swarm Optimizer: A Critical Review and Performance Analysis</title>
      <link>https://arxiv.org/abs/2504.11812</link>
      <description>arXiv:2504.11812v1 Announce Type: new 
Abstract: Nature has long inspired the development of swarm intelligence (SI), a key branch of artificial intelligence that models collective behaviors observed in biological systems for solving complex optimization problems. Particle swarm optimization (PSO) is widely adopted among SI algorithms due to its simplicity and efficiency. Despite numerous learning strategies proposed to enhance PSO's performance in terms of convergence speed, robustness, and adaptability, no comprehensive and systematic analysis of these strategies exists. We review and classify various learning strategies to address this gap, assessing their impact on optimization performance. Additionally, a comparative experimental evaluation is conducted to examine how these strategies influence PSO's search dynamics. Finally, we discuss open challenges and future directions, emphasizing the need for self-adaptive, intelligent PSO variants capable of addressing increasingly complex real-world problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.11812v1</guid>
      <category>cs.NE</category>
      <category>cs.AI</category>
      <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Dikshit Chauhan,  Shivani, P. N. Suganthan</dc:creator>
    </item>
    <item>
      <title>GT-SVQ: A Linear-Time Graph Transformer for Node Classification Using Spiking Vector Quantization</title>
      <link>https://arxiv.org/abs/2504.11840</link>
      <description>arXiv:2504.11840v1 Announce Type: new 
Abstract: Graph Transformers (GTs), which simultaneously integrate message-passing and self-attention mechanisms, have achieved promising empirical results in some graph prediction tasks. Although these approaches show the potential of Transformers in capturing long-range graph topology information, issues concerning the quadratic complexity and high computing energy consumption severely limit the scalability of GTs on large-scale graphs. Recently, as brain-inspired neural networks, Spiking Neural Networks (SNNs), facilitate the development of graph representation learning methods with lower computational and storage overhead through the unique event-driven spiking neurons. Inspired by these characteristics, we propose a linear-time Graph Transformer using Spiking Vector Quantization (GT-SVQ) for node classification. GT-SVQ reconstructs codebooks based on rate coding outputs from spiking neurons, and injects the codebooks into self-attention blocks to aggregate global information in linear complexity. Besides, spiking vector quantization effectively alleviates codebook collapse and the reliance on complex machinery (distance measure, auxiliary loss, etc.) present in previous vector quantization-based graph learning methods. In experiments, we compare GT-SVQ with other state-of-the-art baselines on node classification datasets ranging from small to large. Experimental results show that GT-SVQ has achieved competitive performances on most datasets while maintaining up to 130x faster inference speed compared to other GTs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.11840v1</guid>
      <category>cs.NE</category>
      <category>cs.LG</category>
      <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Huizhe Zhang, Jintang Li, Yuchang Zhu, Liang Chen, Zibin Zheng</dc:creator>
    </item>
    <item>
      <title>EngramNCA: a Neural Cellular Automaton Model of Memory Transfer</title>
      <link>https://arxiv.org/abs/2504.11855</link>
      <description>arXiv:2504.11855v1 Announce Type: new 
Abstract: This study introduces EngramNCA, a neural cellular automaton (NCA) that integrates both publicly visible states and private, cell-internal memory channels, drawing inspiration from emerging biological evidence suggesting that memory storage extends beyond synaptic modifications to include intracellular mechanisms. The proposed model comprises two components: GeneCA, an NCA trained to develop distinct morphologies from seed cells containing immutable "gene" encodings, and GenePropCA, an auxiliary NCA that modulates the private "genetic" memory of cells without altering their visible states. This architecture enables the encoding and propagation of complex morphologies through the interaction of visible and private channels, facilitating the growth of diverse structures from a shared "genetic" substrate. EngramNCA supports the emergence of hierarchical and coexisting morphologies, offering insights into decentralized memory storage and transfer in artificial systems. These findings have potential implications for the development of adaptive, self-organizing systems and may contribute to the broader understanding of memory mechanisms in both biological and synthetic contexts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.11855v1</guid>
      <category>cs.NE</category>
      <category>cs.AI</category>
      <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Etienne Guichard, Felix Reimers, Mia Kvalsund, Mikkel Lepper{\o}d, Stefano Nichele</dc:creator>
    </item>
    <item>
      <title>Evolutionary Reinforcement Learning for Interpretable Decision-Making in Supply Chain Management</title>
      <link>https://arxiv.org/abs/2504.12023</link>
      <description>arXiv:2504.12023v1 Announce Type: new 
Abstract: In the context of Industry 4.0, Supply Chain Management (SCM) faces challenges in adopting advanced optimization techniques due to the "black-box" nature of most AI-based solutions, which causes reluctance among company stakeholders. To overcome this issue, in this work, we employ an Interpretable Artificial Intelligence (IAI) approach that combines evolutionary computation with Reinforcement Learning (RL) to generate interpretable decision-making policies in the form of decision trees. This IAI solution is embedded within a simulation-based optimization framework specifically designed to handle the inherent uncertainties and stochastic behaviors of modern supply chains. To our knowledge, this marks the first attempt to combine IAI with simulation-based optimization for decision-making in SCM. The methodology is tested on two supply chain optimization problems, one fictional and one from the real world, and its performance is compared against widely used optimization and RL algorithms. The results reveal that the interpretable approach delivers competitive, and sometimes better, performance, challenging the prevailing notion that there must be a trade-off between interpretability and optimization efficiency. Additionally, the developed framework demonstrates strong potential for industrial applications, offering seamless integration with various Python-based algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.12023v1</guid>
      <category>cs.NE</category>
      <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Stefano Genetti, Alberto Longobardi, Giovanni Iacca</dc:creator>
    </item>
    <item>
      <title>Dynamics and Computational Principles of Echo State Networks: A Mathematical Perspective</title>
      <link>https://arxiv.org/abs/2504.11757</link>
      <description>arXiv:2504.11757v1 Announce Type: cross 
Abstract: Reservoir computing (RC) represents a class of state-space models (SSMs) characterized by a fixed state transition mechanism (the reservoir) and a flexible readout layer that maps from the state space. It is a paradigm of computational dynamical systems that harnesses the transient dynamics of high-dimensional state spaces for efficient processing of temporal data. Rooted in concepts from recurrent neural networks, RC achieves exceptional computational power by decoupling the training of the dynamic reservoir from the linear readout layer, thereby circumventing the complexities of gradient-based optimization. This work presents a systematic exploration of RC, addressing its foundational properties such as the echo state property, fading memory, and reservoir capacity through the lens of dynamical systems theory. We formalize the interplay between input signals and reservoir states, demonstrating the conditions under which reservoirs exhibit stability and expressive power. Further, we delve into the computational trade-offs and robustness characteristics of RC architectures, extending the discussion to their applications in signal processing, time-series prediction, and control systems. The analysis is complemented by theoretical insights into optimization, training methodologies, and scalability, highlighting open challenges and potential directions for advancing the theoretical underpinnings of RC.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.11757v1</guid>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pradeep Singh, Ashutosh Kumar, Sutirtha Ghosh, Hrishit B P, Balasubramanian Raman</dc:creator>
    </item>
    <item>
      <title>DelGrad: Exact event-based gradients for training delays and weights on spiking neuromorphic hardware</title>
      <link>https://arxiv.org/abs/2404.19165</link>
      <description>arXiv:2404.19165v3 Announce Type: replace 
Abstract: Spiking neural networks (SNNs) inherently rely on the timing of signals for representing and processing information. Incorporating trainable transmission delays, alongside synaptic weights, is crucial for shaping these temporal dynamics. While recent methods have shown the benefits of training delays and weights in terms of accuracy and memory efficiency, they rely on discrete time, approximate gradients, and full access to internal variables like membrane potentials. This limits their precision, efficiency, and suitability for neuromorphic hardware due to increased memory requirements and I/O bandwidth demands. To address these challenges, we propose DelGrad, an analytical, event-based method to compute exact loss gradients for both synaptic weights and delays. The inclusion of delays in the training process emerges naturally within our proposed formalism, enriching the model's search space with a temporal dimension. Moreover, DelGrad, grounded purely in spike timing, eliminates the need to track additional variables such as membrane potentials. To showcase this key advantage, we demonstrate the functionality and benefits of DelGrad on the BrainScaleS-2 neuromorphic platform, by training SNNs in a chip-in-the-loop fashion. For the first time, we experimentally demonstrate the memory efficiency and accuracy benefits of adding delays to SNNs on noisy mixed-signal hardware. Additionally, these experiments also reveal the potential of delays for stabilizing networks against noise. DelGrad opens a new way for training SNNs with delays on neuromorphic hardware, which results in fewer required parameters, higher accuracy and ease of hardware training.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.19165v3</guid>
      <category>cs.NE</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Julian G\"oltz, Jimmy Weber, Laura Kriener, Sebastian Billaudelle, Peter Lake, Johannes Schemmel, Melika Payvand, Mihai A. Petrovici</dc:creator>
    </item>
    <item>
      <title>GAAPO: Genetic Algorithmic Applied to Prompt Optimization</title>
      <link>https://arxiv.org/abs/2504.07157</link>
      <description>arXiv:2504.07157v3 Announce Type: replace 
Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across various tasks, with their performance heavily dependent on the quality of input prompts. While prompt engineering has proven effective, it typically relies on manual adjustments, making it time-consuming and potentially suboptimal. This paper introduces GAAPO (Genetic Algorithm Applied to Prompt Optimization), a novel hybrid optimization framework that leverages genetic algorithm principles to evolve prompts through successive generations. Unlike traditional genetic approaches that rely solely on mutation and crossover operations, GAAPO integrates multiple specialized prompt generation strategies within its evolutionary framework. Through extensive experimentation on diverse datasets including ETHOS, MMLU-Pro, and GPQA, our analysis reveals several important point for the future development of automatic prompt optimization methods: importance of the tradeoff between the population size and the number of generations, effect of selection methods on stability results, capacity of different LLMs and especially reasoning models to be able to automatically generate prompts from similar queries... Furthermore, we provide insights into the relative effectiveness of different prompt generation strategies and their evolution across optimization phases. These findings contribute to both the theoretical understanding of prompt optimization and practical applications in improving LLM performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.07157v3</guid>
      <category>cs.NE</category>
      <category>cs.LG</category>
      <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xavier S\'echeresse, Jacques-Yves Guilbert--Ly, Antoine Villedieu de Torcy</dc:creator>
    </item>
    <item>
      <title>CatCMA with Margin: Stochastic Optimization for Continuous, Integer, and Categorical Variables</title>
      <link>https://arxiv.org/abs/2504.07884</link>
      <description>arXiv:2504.07884v3 Announce Type: replace 
Abstract: This study focuses on mixed-variable black-box optimization (MV-BBO), addressing continuous, integer, and categorical variables. Many real-world MV-BBO problems involve dependencies among these different types of variables, requiring efficient methods to optimize them simultaneously. Recently, stochastic optimization methods leveraging the mechanism of the covariance matrix adaptation evolution strategy have shown promising results in mixed-integer or mixed-category optimization. However, such methods cannot handle the three types of variables simultaneously. In this study, we propose CatCMA with Margin (CatCMAwM), a stochastic optimization method for MV-BBO that jointly optimizes continuous, integer, and categorical variables. CatCMAwM is developed by incorporating a novel integer handling into CatCMA, a mixed-category black-box optimization method employing a joint distribution of multivariate Gaussian and categorical distributions. The proposed integer handling is carefully designed by reviewing existing integer handlings and following the design principles of CatCMA. Even when applied to mixed-integer problems, it stabilizes the marginal probability and improves the convergence performance of continuous variables. Numerical experiments show that CatCMAwM effectively handles the three types of variables, outperforming state-of-the-art Bayesian optimization methods and baselines that simply incorporate existing integer handlings into CatCMA.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.07884v3</guid>
      <category>cs.NE</category>
      <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3712256.3726471</arxiv:DOI>
      <dc:creator>Ryoki Hamano, Masahiro Nomura, Shota Saito, Kento Uchida, Shinichi Shirakawa</dc:creator>
    </item>
    <item>
      <title>Spatio-Temporal Fuzzy-oriented Multi-Modal Meta-Learning for Fine-grained Emotion Recognition</title>
      <link>https://arxiv.org/abs/2412.13541</link>
      <description>arXiv:2412.13541v3 Announce Type: replace-cross 
Abstract: Fine-grained emotion recognition (FER) plays a vital role in various fields, such as disease diagnosis, personalized recommendations, and multimedia mining. However, existing FER methods face three key challenges in real-world applications: (i) they rely on large amounts of continuously annotated data to ensure accuracy since emotions are complex and ambiguous in reality, which is costly and time-consuming; (ii) they cannot capture the temporal heterogeneity caused by changing emotion patterns, because they usually assume that the temporal correlation within sampling periods is the same; (iii) they do not consider the spatial heterogeneity of different FER scenarios, that is, the distribution of emotion information in different data may have bias or interference. To address these challenges, we propose a Spatio-Temporal Fuzzy-oriented Multi-modal Meta-learning framework (ST-F2M). Specifically, ST-F2M first divides the multi-modal videos into multiple views, and each view corresponds to one modality of one emotion. Multiple randomly selected views for the same emotion form a meta-training task. Next, ST-F2M uses an integrated module with spatial and temporal convolutions to encode the data of each task, reflecting the spatial and temporal heterogeneity. Then it adds fuzzy semantic information to each task based on generalized fuzzy rules, which helps handle the complexity and ambiguity of emotions. Finally, ST-F2M learns emotion-related general meta-knowledge through meta-recurrent neural networks to achieve fast and robust fine-grained emotion recognition. Extensive experiments show that ST-F2M outperforms various state-of-the-art methods in terms of accuracy and model efficiency. In addition, we construct ablation studies and further analysis to explore why ST-F2M performs well.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13541v3</guid>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jingyao Wang, Wenwen Qiang, Changwen Zheng, Fuchun Sun</dc:creator>
    </item>
    <item>
      <title>Emergence of the Primacy Effect in Structured State-Space Models</title>
      <link>https://arxiv.org/abs/2502.13729</link>
      <description>arXiv:2502.13729v4 Announce Type: replace-cross 
Abstract: Human and animal memory for sequentially presented items is well-documented to be more accurate for those at the beginning and end of the sequence, phenomena known as the primacy and recency effects, respectively. By contrast, artificial neural network (ANN) models are typically designed with a memory that decays monotonically over time. Accordingly, ANNs are expected to show the recency effect but not the primacy effect. Contrary to this theoretical expectation, however, the present study reveals a counterintuitive finding: a recently developed ANN architecture, called structured state-space models, exhibits the primacy effect when trained and evaluated on a synthetic task that mirrors psychological memory experiments. Given that this model was originally designed for recovering neuronal activity patterns observed in biological brains, this result provides a novel perspective on the psychological primacy effect while also posing a non-trivial puzzle for the current theories in machine learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13729v4</guid>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <category>q-bio.NC</category>
      <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Takashi Morita</dc:creator>
    </item>
  </channel>
</rss>
