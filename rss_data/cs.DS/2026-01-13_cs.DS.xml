<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 13 Jan 2026 05:00:16 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Lower Bounds for the Algorithmic Complexity of Learned Indexes</title>
      <link>https://arxiv.org/abs/2601.06629</link>
      <description>arXiv:2601.06629v1 Announce Type: new 
Abstract: Learned index structures aim to accelerate queries by training machine learning models to approximate the rank function associated with a database attribute. While effective in practice, their theoretical limitations are not fully understood. We present a general framework for proving lower bounds on query time for learned indexes, expressed in terms of their space overhead and parameterized by the model class used for approximation. Our formulation captures a broad family of learned indexes, including most existing designs, as piecewise model-based predictors.
  We solve the problem of lower bounding query time in two steps: first, we use probabilistic tools to control the effect of sampling when the database attribute is drawn from a probability distribution. Then, we analyze the approximation-theoretic problem of how to optimally represent a cumulative distribution function with approximators from a given model class. Within this framework, we derive lower bounds under a range of modeling and distributional assumptions, paying particular attention to the case of piecewise linear and piecewise constant model classes, which are common in practical implementations.
  Our analysis shows how tools from approximation theory, such as quantization and Kolmogorov widths, can be leveraged to formalize the space-time tradeoffs inherent to learned index structures. The resulting bounds illuminate core limitations of these methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06629v1</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luis Alberto Croquevielle, Roman Sokolovskii, Thomas Heinis</dc:creator>
    </item>
    <item>
      <title>Approximating Matroid Basis Testing for Partition Matroids using Budget-In-Expectation</title>
      <link>https://arxiv.org/abs/2601.06723</link>
      <description>arXiv:2601.06723v1 Announce Type: new 
Abstract: We consider the following Stochastic Boolean Function Evaluation problem, which is closely related to several problems from the literature. A matroid $\mathcal{M}$ (in compact representation) on ground set $E$ is given, and each element $i\in E$ is active independently with known probability $p_i\in(0,1)$. The elements can be queried, upon which it is revealed whether the respective element is active or not. The goal is to find an adaptive querying strategy for determining whether there is a basis of $\mathcal{M}$ in which all elements are active, with the objective of minimizing the expected number of queries.
  When $\mathcal{M}$ is a uniform matroid, this is the problem of evaluating a $k$-of-$n$ function, first studied in the 1970s. This problem is well-understood, and has an optimal adaptive strategy that can be computed in polynomial time.
  Taking $\mathcal{M}$ to instead be a partition matroid, we show that previous approaches fail to give a constant-factor approximation. Our main result is a polynomial-time constant-factor approximation algorithm producing a randomized strategy for this partition matroid problem. We obtain this result by combining a new technique with several well-established techniques. Our algorithm adaptively interleaves solutions to several instances of a novel type of stochastic querying problem, with a constraint on the $\textit{expected}$ cost. We believe that this type of problem is of independent interest, will spark follow-up work, and has the potential for additional applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06723v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lisa Hellerstein, Benedikt M. Plank, Kevin Schewior</dc:creator>
    </item>
    <item>
      <title>Algorithmic Reductions: Network Flow and NP-Completeness in Real-World Scheduling Problems</title>
      <link>https://arxiv.org/abs/2601.06737</link>
      <description>arXiv:2601.06737v1 Announce Type: new 
Abstract: This paper presents two real-world scheduling problems and their algorithmic solutions through polynomial-time reductions. First, we address the Hospital Patient-to-Bed Assignment problem, demonstrating its reduction to Maximum Bipartite Matching and solution via Network Flow algorithms. Second, we tackle the University Course Scheduling problem, proving its NP-Completeness through reduction from Graph Coloring and providing greedy approximation algorithms. Both problems are implemented in Python, with experimental results validating theoretical complexity analyses. Our Network Flow solution achieves O(n2.51) empirical complexity, while the greedy coloring algorithms demonstrate O(n2) behavior with approximation ratios consistently below the theoretical delta + 1 bound.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06737v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anay Sinhal, Arpana Sinhal, Amit Sinhal, Amit Hirawat</dc:creator>
    </item>
    <item>
      <title>Spectral Shadows: When Communication Complexity Meets Linear Invariance Testing</title>
      <link>https://arxiv.org/abs/2601.06828</link>
      <description>arXiv:2601.06828v1 Announce Type: new 
Abstract: In this short note, we initiate the study of the Linear Isomorphism Testing Problem in the setting of communication complexity, a natural linear algebraic generalization of the classical Equality problem. Given Boolean functions $f, g : \mathbb{F}_2^n \to \{-1, +1\}$, Alice and Bob are tasked with determining whether $f$ and $g$ are equivalent up to a nonsingular linear transformation of the input variables, or far from being so. This problem has been extensively investigated in several models of computation, including standard algorithmic and property testing frameworks, owing to its fundamental connections with combinatorial circuit design, complexity theory, and cryptography. However, despite its broad relevance, it has remained unexplored in the context of communication complexity, a gap we address in this work.
  Our main results demonstrate that the approximate spectral norm of the input functions plays a central role in governing the communication complexity of this problem. We design a simple deterministic protocol whose communication cost is polynomial in the approximate spectral norm, and complement it with nearly matching lower bounds (up to a quadratic gap). In the randomised setting with private coins, we present an even more efficient protocol, though equally simple, that achieves a quadratically improved dependence on the approximate spectral norm compared to the deterministic case, and we prove that such a dependence is essentially unavoidable.
  These results identify the approximate spectral norm as a key complexity measure for testing linear invariance in the communication complexity framework. As a core technical ingredient, we establish new junta theorems for Boolean functions with small approximate spectral norm, which may be of independent interest in Fourier analysis and learning theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06828v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Swarnalipa Datta, Arijit Ghosh, Chandrima Kayal, Manaswi Paraashar, Manmatha Roy</dc:creator>
    </item>
    <item>
      <title>Optimal Extended Formulations from Optimal Dynamic Programming Algorithms</title>
      <link>https://arxiv.org/abs/2601.06947</link>
      <description>arXiv:2601.06947v1 Announce Type: new 
Abstract: Vertex Subset Problems (VSPs) are a class of combinatorial optimization problems on graphs where the goal is to find a subset of vertices satisfying a predefined condition. Two prominent approaches for solving VSPs are dynamic programming over tree-like structures, such as tree decompositions or clique decompositions, and linear programming. In this work, we establish a sharp connection between both approaches by showing that if a vertex-subset problem $\Pi$ admits a solution-preserving dynamic programming algorithm that produces tables of size at most $\alpha(k,n)$ when processing a tree decomposition of width at most $k$ of an $n$-vertex graph $G$, then the polytope $P_{\Pi}(G)$ defined as the convex-hull of solutions of $\Pi$ in $G$ has extension complexity at most $O(\alpha(k,n)\cdot n)$. Additionally, this upper bound is optimal under the exponential time hypothesis (ETH).
  On the one hand, our results imply that ETH-optimal solution-preserving dynamic programming algorithms for combinatorial problems yield optimal-size parameterized extended formulations for the solution polytopes associated with instances of these problems. On the other hand, unconditional lower bounds obtained in the realm of the theory of extended formulations yield unconditional lower bounds on the table complexity of solution-preserving dynamic programming algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06947v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Mateus de Oliveira Oliveira, Wim Van den Broeck</dc:creator>
    </item>
    <item>
      <title>The Secretary Problem with Predictions and a Chosen Order</title>
      <link>https://arxiv.org/abs/2601.07482</link>
      <description>arXiv:2601.07482v1 Announce Type: new 
Abstract: We study a learning-augmented variant of the secretary problem, recently introduced by Fujii and Yoshida (2023), in which the decision-maker has access to machine-learned predictions of candidate values. The central challenge is to balance consistency and robustness: when predictions are accurate, the algorithm should select a near-optimal secretary, while under inaccurate predictions it should still guarantee a bounded competitive ratio.
  We consider both the classical Random Order Secretary Problem (ROSP), where candidates arrive in a uniformly random order, and a more natural learning-augmented model in which the decision-maker may choose the arrival order based on predicted values. We call this model the Chosen Order Secretary Problem (COSP), capturing scenarios such as interview schedules set in advance.
  We propose a new randomized algorithm applicable to both ROSP and COSP. Our method switches from fully trusting predictions to a threshold-based rule once a large prediction deviation is detected. Let $\epsilon \in [0,1]$ denote the maximum multiplicative prediction error. For ROSP, our algorithm achieves a competitive ratio of $\max\{0.221, (1-\epsilon)/(1+\epsilon)\}$, improving upon the prior bound of $\max\{0.215, (1-\epsilon)/(1+\epsilon)\}$. For COSP, we achieve $\max\{0.262, (1-\epsilon)/(1+\epsilon)\}$, surpassing the $0.25$ worst-case bound for prior approaches and moving closer to the classical secretary benchmark of $1/e \approx 0.368$. These results highlight the benefit of combining predictions with arrival-order control in online decision-making.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07482v1</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Helia Karisani, Mohammadreza Daneshvaramoli, Hedyeh Beyhaghi, Mohammad Hajiesmaili, Cameron Musco</dc:creator>
    </item>
    <item>
      <title>Dynamic $(\Delta + 1)$ Vertex Coloring</title>
      <link>https://arxiv.org/abs/2601.07566</link>
      <description>arXiv:2601.07566v1 Announce Type: new 
Abstract: Several recent results from dynamic and sublinear graph coloring are surveyed. This problem is widely studied and has motivating applications like network topology control, constraint satisfaction, and real-time resource scheduling. Graph coloring algorithms are called colorers. In \S 1 are defined graph coloring, the dynamic model, and the notion of performance of graph algorithms in the dynamic model. In particular $(\Delta + 1)$-coloring, sublinear performance, and oblivious and adaptive adversaries are noted and motivated. In \S 2 the pair of approximately optimal dynamic vertex colorers given in arXiv:1708.09080 are summarized as a warmup for the $(\Delta + 1)$-colorers. In \S 3 the state of the art in dynamic $(\Delta + 1)$-coloring is presented. This section comprises a pair of papers (arXiv:1711.04355 and arXiv:1910.02063) that improve dynamic $(\Delta + 1)$-coloring from the naive algorithm with $O(\Delta)$ expected amortized update time to $O(\log \Delta)$, then to $O(1)$ with high probability. In \S 4 the results in arXiv:2411.04418, which gives a sublinear algorithm for $(\Delta + 1)$-coloring that generalizes oblivious adversaries to adaptive adversaries, are presented.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07566v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Noam Benson-Tilsen</dc:creator>
    </item>
    <item>
      <title>Analyzing the effect of prediction accuracy on the distributionally-robust competitive ratio</title>
      <link>https://arxiv.org/abs/2601.06813</link>
      <description>arXiv:2601.06813v1 Announce Type: cross 
Abstract: The field of algorithms with predictions aims to improve algorithm performance by integrating machine learning predictions into algorithm design. A central question in this area is how predictions can improve performance, and a key aspect of this analysis is the role of prediction accuracy. In this context, prediction accuracy is defined as a guaranteed probability that an instance drawn from the distribution belongs to the predicted set. As a performance measure that incorporates prediction accuracy, we focus on the distributionally-robust competitive ratio (DRCR), introduced by Sun et al.~(ICML 2024). The DRCR is defined as the expected ratio between the algorithm's cost and the optimal cost, where the expectation is taken over the worst-case instance distribution that satisfies the given prediction and accuracy requirement. A known structural property is that, for any fixed algorithm, the DRCR decreases linearly as prediction accuracy increases. Building on this result, we establish that the optimal DRCR value (i.e., the infimum over all algorithms) is a monotone and concave function of prediction accuracy. We further generalize the DRCR framework to a multiple-prediction setting and show that monotonicity and concavity are preserved in this setting. Finally, we apply our results to the ski rental problem, a benchmark problem in online optimization, to identify the conditions on prediction accuracies required for the optimal DRCR to attain a target value. Moreover, we provide a method for computing the critical accuracy, defined as the minimum accuracy required for the optimal DRCR to strictly improve upon the performance attainable without any accuracy guarantee.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06813v1</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Toru Yoshinaga, Yasushi Kawase</dc:creator>
    </item>
    <item>
      <title>Faster Exponential-Time Approximation Algorithms Using Approximate Monotone Local Search</title>
      <link>https://arxiv.org/abs/2206.13481</link>
      <description>arXiv:2206.13481v2 Announce Type: replace 
Abstract: We generalize the monotone local search approach of Fomin, Gaspers, Lokshtanov and Saurabh [J. ACM 2019], by establishing a connection between parameterized approximation and exponential-time approximation algorithms for monotone subset minimization problems. In a monotone subset minimization problem the input implicitly describes a non-empty set family over a universe of size $n$ which is closed under taking supersets. The task is to find a minimum cardinality set in this family. Broadly speaking, we use approximate monotone local search to show that a parameterized $\alpha$-approximation algorithm that runs in $c^k \cdot n^{O(1)}$ time, where $k$ is the solution size, can be used to derive an $\alpha$-approximation randomized algorithm that runs in $d^n \cdot n^{O(1)}$ time, where $d$ is the unique value in $d \in (1,1+\frac{c-1}{\alpha})$ such that $\mathcal{D}(\frac{1}{\alpha}\|\frac{d-1}{c-1})=\frac{\ln c}{\alpha}$ and $\mathcal{D}(a \|b)$ is the Kullback-Leibler divergence. This running time matches that of Fomin et al. for $\alpha=1$, and is strictly better when $\alpha &gt;1$, for any $c &gt; 1$. Furthermore, we also show that this result can be derandomized at the expense of a sub-exponential multiplicative factor in the running time.
  We demonstrate the potential of approximate monotone local search by deriving new and faster exponential approximation algorithms for Vertex Cover, $3$-Hitting Set, Directed Feedback Vertex Set, Directed Subset Feedback Vertex Set, Directed Odd Cycle Transversal and Undirected Multicut. For instance, we get a $1.1$-approximation algorithm for Vertex Cover with running time $1.114^n \cdot n^{O(1)}$, improving upon the previously best known $1.1$-approximation running in time $1.127^n \cdot n^{O(1)}$ by Bourgeois et al. [DAM 2011].</description>
      <guid isPermaLink="false">oai:arXiv.org:2206.13481v2</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bar{\i}\c{s} Can Esmer, Ariel Kulik, D\'aniel Marx, Daniel Neuen, Roohani Sharma</dc:creator>
    </item>
    <item>
      <title>When is local search both effective and efficient?</title>
      <link>https://arxiv.org/abs/2410.02634</link>
      <description>arXiv:2410.02634v3 Announce Type: replace 
Abstract: Combinatorial optimization problems implicitly define fitness landscapes that combine the numeric structure of the 'fitness' function to be maximized with the combinatorial structure of which assignments are 'adjacent'. Local search starts at an assignment in this landscape and successively moves assignments until no further improvement is possible among the adjacent assignments. Classic analyses of local search algorithms have focused more on the question of effectiveness ("did we find a good solution?") and often implicitly assumed that there are no doubts about their efficiency ("did we find it quickly?"). But there are many reasons to doubt the efficiency of local search. Even if we focus on fitness landscapes on the hypercube that are single peaked on every subcube (i.e., semismooth fitness landscapes) where effectiveness is obvious, many local search algorithms are known to be inefficient. Since fitness landscapes are unwieldy exponentially large objects, we focus on their polynomial-sized representations by instances of valued constraint satisfaction problems (VCSP). We define a "direction" for valued constraints such that directed VCSPs generate semismooth fitness landscapes. We call VCSPs oriented if they do not have any pair of variables with arcs in both directions. Since recognizing if a VCSP-instance is directed or oriented is coNP-complete, we generalized oriented VCSPs as conditionally-smooth fitness landscapes that are recognizable in polynomial time for a VCSP-instance. We prove that many popular local search algorithms like random ascent, simulated annealing, history-based rules, jumping rules, and the Kernighan-Lin heuristic are very efficient on conditionally-smooth landscapes. But conditionally-smooth landscapes are still expressive enough so that algorithms like steepest ascent and random facet require a super-polynomial number of steps to find the fitness peak.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02634v3</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <category>q-bio.PE</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Artem Kaznatcheev, Sofia Vazquez Alferez</dc:creator>
    </item>
    <item>
      <title>Potential-Based Greedy Matching for Dynamic Delivery Pooling</title>
      <link>https://arxiv.org/abs/2502.16862</link>
      <description>arXiv:2502.16862v3 Announce Type: replace 
Abstract: We study the dynamic pooling of multiple orders into a single trip, a strategy widely adopted by online delivery platforms. When an order has to be dispatched, the platform must determine which (if any) of the available orders to pool it with, weighing the immediate efficiency gains against the uncertain, differential benefits of holding each order for future pooling opportunities. In this paper, we demonstrate the effectiveness of using the delivery distance as a proxy for opportunity cost via a potential-based greedy algorithm (PB). The algorithm is simple, pooling each departing job with the available job that maximizes the immediate savings in travel distance minus "half its delivery distance", which we call the potential of the available job. Theoretically, we show that PB achieves vanishing worst-case regret per job as market density increases, whereas a naive greedy policy suffers constant regret. We further show that the potential approximates the true opportunity cost of dispatching a job, in a stochastic setting with sufficient density. Finally, we conduct extensive numerical experiments on both synthetic data and real-world data from the Meituan platform. Despite being forecast-agnostic, PB consistently outperforms greedy heuristics that rely on historical data. Moreover, PB achieves performance comparable to computationally-intensive batching heuristics, which themselves also benefit from incorporating the potential to further improve their performance or drastically reduce computational costs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16862v3</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hongyao Ma, Will Ma, Matias Romero</dc:creator>
    </item>
    <item>
      <title>Efficient Online Random Sampling via Randomness Recycling</title>
      <link>https://arxiv.org/abs/2505.18879</link>
      <description>arXiv:2505.18879v3 Announce Type: replace 
Abstract: This article studies the fundamental problem of using i.i.d. coin tosses from an entropy source to efficiently generate random variables $X_i \sim P_i$ $(i \ge 1)$, where $(P_1, P_2, \dots)$ is a random sequence of rational discrete probability distributions subject to an \textit{arbitrary} stochastic process. Our method achieves an amortized expected entropy cost within $\varepsilon &gt; 0$ bits of the information-theoretically optimal Shannon lower bound using $O(\log(1/\varepsilon))$ space. This result holds both pointwise in terms of the Shannon information content conditioned on $X_i$ and $P_i$, and in expectation to obtain a rate of $\mathbb{E}[H(P_1) + \dots + H(P_n)]/n + \varepsilon$ bits per sample as $n \to \infty$ (where $H$ is the Shannon entropy). The combination of space, time, and entropy properties of our method improves upon the Knuth and Yao (1976) entropy-optimal algorithm and Han and Hoshi (1997) interval algorithm for online sampling, which require unbounded space. It also uses exponentially less space than the more specialized methods of Kozen and Soloviev (2022) and Shao and Wang (2025) that generate i.i.d. samples from a fixed distribution. Our online sampling algorithm rests on a powerful algorithmic technique called \textit{randomness recycling}, which reuses a fraction of the random information consumed by a probabilistic algorithm to reduce its amortized entropy cost.
  On the practical side, we develop randomness recycling techniques to accelerate a variety of prominent sampling algorithms. We show that randomness recycling enables state-of-the-art runtime performance on the Fisher-Yates shuffle when using a cryptographically secure pseudorandom number generator, and that it reduces the entropy cost of discrete Gaussian sampling. Accompanying the manuscript is a performant software library in the C programming language.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18879v3</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.PR</category>
      <category>stat.CO</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1137/1.9781611978971.89</arxiv:DOI>
      <arxiv:journal_reference>Proceedings of the 2026 Annual ACM-SIAM Symposium on Discrete Algorithms (SODA), pp. 2473-2511. Society for Industrial and Applied Mathematics, 2026</arxiv:journal_reference>
      <dc:creator>Thomas L. Draper, Feras A. Saad</dc:creator>
    </item>
    <item>
      <title>Approximate Graph Propagation Revisited: Dynamic Parameterized Queries, Tighter Bounds and Dynamic Updates</title>
      <link>https://arxiv.org/abs/2509.10036</link>
      <description>arXiv:2509.10036v2 Announce Type: replace 
Abstract: We revisit Approximate Graph Propagation (AGP), a unified framework which captures various graph propagation tasks, such as PageRank, feature propagation in Graph Neural Networks (GNNs), and graph-based Retrieval-Augmented Generation (RAG). Our work focuses on the settings of dynamic graphs and dynamic parameterized queries, where the underlying graphs evolve over time (updated by edge insertions or deletions) and the input query parameters are specified on the fly to fit application needs. Our first contribution is an interesting observation that the SOTA solution, AGP-Static, can be adapted to support dynamic parameterized queries; however several challenges remain unresolved. Firstly, the query time complexity of AGP-Static is based on an assumption of using an optimal algorithm for subset sampling in its query algorithm. Unfortunately, back to that time, such an algorithm did not exist; without such an optimal algorithm, an extra $O(\log^2 n)$ factor is required in the query complexity, where $n$ is the number of vertices in the graphs. Secondly, AGP-Static performs poorly on dynamic graphs, taking $O(n\log n)$ time to process each update. To address these challenges, we propose a new algorithm, AGP-Static++, which is simpler yet reduces roughly a factor of $O(\log^2 n)$ in the query complexity while preserving the approximation guarantees of AGP-Static. However, AGP-Static++ still requires $O(n)$ time to process each update. To better support dynamic graphs, we further propose AGP-Dynamic, which achieves $O(1)$ amortized time per update, significantly improving the aforementioned $O(n)$ per-update bound, while still preserving the query complexity and approximation guarantees. Last, our comprehensive experiments validate the theoretical improvements: compared to the baselines, our algorithm achieves speedups of up to $177\times$ on update time and $10\times$ on query efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10036v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhuowei Zhao, Zhuo Zhang, Hanzhi Wang, Junhao Gan, Zhifeng Bao, Jianzhong Qi</dc:creator>
    </item>
    <item>
      <title>Balanced Spanning Tree Distributions Have Separation Fairness</title>
      <link>https://arxiv.org/abs/2509.15137</link>
      <description>arXiv:2509.15137v2 Announce Type: replace 
Abstract: Sampling-based methods such as ReCom are widely used to audit redistricting plans for fairness, with the balanced spanning tree distribution playing a central role since it favors compact, contiguous, and population-balanced districts. However, whether such samples are truly representative or exhibit hidden biases remains an open question. In this work, we introduce the notion of separation fairness, which asks whether adjacent geographic units are separated with at most a constant probability (bounded away from one) in sampled redistricting plans. Focusing on grid graphs and two-district partitions, we prove that a smooth variant of the balanced spanning tree distribution satisfies separation fairness. Our results also provide theoretical support for popular MCMC methods like ReCom, suggesting that they maintain fairness at a granular level in the sampling process. Along the way, we develop tools for analyzing loop-erased random walks and partitions that may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.15137v2</guid>
      <category>cs.DS</category>
      <category>cs.CY</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Harry Chen, Kamesh Munagala, Govind S. Sankar</dc:creator>
    </item>
    <item>
      <title>Tree Embedding in High Dimensions: Dynamic and Massively Parallel</title>
      <link>https://arxiv.org/abs/2510.22490</link>
      <description>arXiv:2510.22490v2 Announce Type: replace 
Abstract: Tree embedding has been a fundamental method in algorithm design with wide applications. We focus on the efficiency of building tree embedding in various computational settings under high-dimensional Euclidean $\mathbb{R}^d$. We devise a new tree embedding construction framework that operates on an arbitrary metric decomposition with bounded diameter, offering a tradeoff between distortion and the locality of its algorithmic steps. This framework works for general metric spaces and may be of independent interest beyond the Euclidean setting. Using this framework, we obtain a dynamic algorithm that maintains an $O_\epsilon(\log n)$-distortion tree embedding with update time $\tilde O(n^\epsilon + d)$ subject to point insertions/deletions, and a massively parallel algorithm that achieves $O_\epsilon(\log n)$-distortion in $O(1)$ rounds and total space $\tilde O(n^{1 + \epsilon})$ (for constant $\epsilon \in (0, 1)$). These new tree embedding results allow for a wide range of applications. Notably, under a similar performance guarantee as in our tree embedding algorithms, i.e., $\tilde O(n^\epsilon + d)$ update time and $O(1)$ rounds, we obtain $O_\epsilon(\log n)$-approximate dynamic and MPC algorithms for $k$-median and earth-mover distance in $\mathbb{R}^d$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22490v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gramoz Goranci, Shaofeng H. -C. Jiang, Peter Kiss, Qihao Kong, Yi Qian, Eva Szilagyi</dc:creator>
    </item>
    <item>
      <title>Merging RLBWTs adaptively</title>
      <link>https://arxiv.org/abs/2511.16953</link>
      <description>arXiv:2511.16953v4 Announce Type: replace 
Abstract: We show how to merge two run-length compressed Burrows-Wheeler Transforms (RLBWTs) into a run-length compressed extended Burrows-Wheeler Transform (eBWT) in $O (r)$ space and $O ((r + L) \log (m + n))$ time, where $m$ and $n$ are the lengths of the uncompressed strings, $r$ is the number of runs in the final eBWT and $L$ is the sum of its irreducible LCP values.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.16953v4</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Travis Gagie</dc:creator>
    </item>
    <item>
      <title>Bounds on Longest Simple Cycles in Weighted Directed Graphs via Optimum Cycle Means</title>
      <link>https://arxiv.org/abs/2601.00094</link>
      <description>arXiv:2601.00094v2 Announce Type: replace 
Abstract: The problem of finding the longest simple cycle in a directed graph is NP-hard, with critical applications in computational biology, scheduling, and network analysis. Existing approaches include exact algorithms with exponential runtimes, approximation algorithms limited to specific graph classes, and heuristics with no formal guarantees. In this paper, we exploit optimum cycle means (minimum and maximum cycle means), computable in strongly polynomial time, to derive both strict bounds and heuristic estimates for the weight and length of the longest simple cycle in general graphs. The strict bounds can prune search spaces in exact algorithms while the heuristic estimates (the arithmetic mean and geometric mean of the optimum cycle means) guarantee bounded approximation error. Crucially, a single computation of optimum cycle means yields both the bounds and the heuristic estimates. Experimental evaluation on ISCAS benchmark circuits demonstrates that, compared to true values, the strict algebraic lower bounds are loose (median 80--99% below) while the heuristic estimates are much tighter: the arithmetic mean and the geometric mean have median errors of 6--13% vs. 11--21% for symmetric (uniform) weights and 41--92% vs. 25--35% for skewed (log-normal) weights, favoring the arithmetic mean for symmetric distributions and the geometric mean for skewed distributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00094v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ali Dasdan</dc:creator>
    </item>
    <item>
      <title>Certificates in P and Subquadratic-Time Computation of Radius, Diameter, and all Eccentricities in Graphs</title>
      <link>https://arxiv.org/abs/1803.04660</link>
      <description>arXiv:1803.04660v5 Announce Type: replace-cross 
Abstract: In the context of fine-grained complexity, we investigate the notion of certificate enabling faster polynomial-time algorithms. We specifically target radius (minimum eccentricity), diameter (maximum eccentricity), and all-eccentricity computations for which quadratic-time lower bounds are known under plausible conjectures. In each case, we introduce a notion of certificate as a specific set of nodes from which appropriate bounds on all eccentricities can be derived in subquadratic time when this set has sublinear size. The existence of small certificates is a barrier against SETH-based lower bounds for these problems. We indeed prove that for graph classes with small certificates, there exist randomized subquadratic-time algorithms for computing the radius, the diameter, and all eccentricities respectively. Moreover, these notions of certificates are tightly related to algorithms probing the graph through one-to-all distance queries and allow to explain the efficiency of practical radius and diameter algorithms from the literature. Our formalization enables a novel primal-dual analysis of a classical approach for diameter computation that leads to algorithms for radius, diameter and all eccentricities with theoretical guarantees with respect to certain graph parameters. This is complemented by experimental results on various types of real-world graphs showing that these parameters appear to be low in practice. Finally, we obtain refined results for several graph classes.</description>
      <guid isPermaLink="false">oai:arXiv.org:1803.04660v5</guid>
      <category>cs.DM</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>cs.NI</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>Proceedings of the 2025 Annual ACM-SIAM Symposium on Discrete Algorithms (SODA), Jan 2025, New Orleans (LA), United States. pp.2157--2193</arxiv:journal_reference>
      <dc:creator>Feodor F. Dragan (UniBuc, ICI), Guillaume Ducoffe (UniBuc, ICI), Michel Habib (IRIF), Laurent Viennot (DI-ENS, ARGO)</dc:creator>
    </item>
    <item>
      <title>Deterministic approximate counting of colorings with fewer than $2\Delta$ colors via absence of zeros</title>
      <link>https://arxiv.org/abs/2408.04727</link>
      <description>arXiv:2408.04727v3 Announce Type: replace-cross 
Abstract: Let $\Delta,q\geq 3$ be integers. We prove that there exists $\eta\geq 0.002$ such that if $q\geq (2-\eta)\Delta$, then there exists an open set $\mathcal{U}\subset \mathbb{C}$ that contains the interval $[0,1]$ such that for each $w\in \mathcal{U}$ and any graph $G=(V,E)$ of maximum degree at most $\Delta$, the partition function of the anti-ferromagnetic $q$-state Potts model evaluated at $w$ does not vanish. This provides a (modest) improvement on a result of Liu, Sinclair, and Srivastava, and breaks the $q=2\Delta$-barrier for this problem.
  As a direct consequence we obtain via Barvinok's interpolation method a deterministic polynomial time algorithm to approximate the number of proper $q$-colorings of graphs of maximum degree at most $\Delta$, provided $q\geq (2-\eta)\Delta$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04727v3</guid>
      <category>math.CO</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.46298/theoretics.26.1</arxiv:DOI>
      <arxiv:journal_reference>TheoretiCS, Volume 5 (2026), Article 1, 1-41</arxiv:journal_reference>
      <dc:creator>Ferenc Bencs, Khallil Berrekkal, Guus Regts</dc:creator>
    </item>
    <item>
      <title>The Power of Iterative Filtering for Supervised Learning with (Heavy) Contamination</title>
      <link>https://arxiv.org/abs/2505.20177</link>
      <description>arXiv:2505.20177v2 Announce Type: replace-cross 
Abstract: Inspired by recent work on learning with distribution shift, we give a general outlier removal algorithm called iterative polynomial filtering and show a number of striking applications for supervised learning with contamination: (1) We show that any function class that can be approximated by low-degree polynomials with respect to a hypercontractive distribution can be efficiently learned under bounded contamination (also known as nasty noise). This is a surprising resolution to a longstanding gap between the complexity of agnostic learning and learning with contamination, as it was widely believed that low-degree approximators only implied tolerance to label noise. In particular, it implies the first efficient algorithm for learning halfspaces with $\eta$-bounded contamination up to error $2\eta+\epsilon$ with respect to the Gaussian distribution. (2) For any function class that admits the (stronger) notion of sandwiching approximators, we obtain near-optimal learning guarantees even with respect to heavy additive contamination, where far more than $1/2$ of the training set may be added adversarially. Prior related work held only for regression and in a list-decodable setting. (3) We obtain the first efficient algorithms for tolerant testable learning of functions of halfspaces with respect to any fixed log-concave distribution. Even the non-tolerant case for a single halfspace in this setting had remained open. These results significantly advance our understanding of efficient supervised learning under contamination, a setting that has been much less studied than its unsupervised counterpart.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20177v2</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>stat.ML</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Adam R. Klivans, Konstantinos Stavropoulos, Kevin Tian, Arsen Vasilyan</dc:creator>
    </item>
    <item>
      <title>ALNS for Tugboat Scheduling in Inland Waterway</title>
      <link>https://arxiv.org/abs/2509.19718</link>
      <description>arXiv:2509.19718v2 Announce Type: replace-cross 
Abstract: This paper focuses on the barges shipping problem, also known as the tugboats scheduling problem, within the context of a scenario where a single tugboat has the capacity to tow multiple barges and conduct multiple trips in a drop-and-pull mode during a daily work shift. The problem is mathematically formalized as mixed-integer programming models. To tackle real-world-sized problem instances, an adaptive large neighborhood search (ALNS) algorithm integrated with a decoding mathematical model is proposed. When applied to large-scale instances, the ALNS algorithm showcases performance superiority over the strengthened mathematical model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.19718v2</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zihang Ma</dc:creator>
    </item>
    <item>
      <title>Simple Quantum Algorithm for Approximate $k$-Mismatch Problem</title>
      <link>https://arxiv.org/abs/2510.02399</link>
      <description>arXiv:2510.02399v2 Announce Type: replace-cross 
Abstract: In the $k$-mismatch problem, given a pattern and a text of length $n$ and $m$ respectively, we have to find if the text has a sub-string with a Hamming distance of at most $k$ from the pattern. This has been studied in the classical setting since 1982 and recently in the quantum computational setting by Jin and Nogler and Kociumaka, Nogler, and Wellnitz. We provide a simple quantum algorithm that solves the problem in an approximate manner, given a parameter $\epsilon \in (0, 1]$. It returns an occurrence as a match only if it is a $\left(1+\epsilon\right)k$-mismatch. If it does not return any occurrence, then there is no $k$-mismatch. This algorithm has a time (size) complexity of $\tilde{O}\left( \epsilon^{-1} \sqrt{\frac{mn}{k}} \right)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.02399v2</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ruhan Habib, Shadman Shahriar</dc:creator>
    </item>
    <item>
      <title>Most Juntas Saturate the Hardcore Lemma</title>
      <link>https://arxiv.org/abs/2510.25165</link>
      <description>arXiv:2510.25165v2 Announce Type: replace-cross 
Abstract: Consider a function that is mildly hard for size-$s$ circuits. For sufficiently large $s$, Impagliazzo's hardcore lemma guarantees a constant-density subset of inputs on which the same function is extremely hard for circuits of size $s'&lt;\!\!&lt;s$. Blanc, Hayderi, Koch, and Tan [FOCS 2024] recently showed that the degradation from $s$ to $s'$ in this lemma is quantitatively tight in certain parameter regimes. We give a simpler and more general proof of this result in almost all parameter regimes of interest by showing that a random junta witnesses the tightness of the hardcore lemma with high probability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25165v2</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1137/1.9781611978964.11</arxiv:DOI>
      <dc:creator>Vinayak M. Kumar</dc:creator>
    </item>
  </channel>
</rss>
