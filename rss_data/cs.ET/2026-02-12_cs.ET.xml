<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.ET updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.ET</link>
    <description>cs.ET updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.ET" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 12 Feb 2026 05:00:24 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Fungal systems for security and resilience</title>
      <link>https://arxiv.org/abs/2602.10543</link>
      <description>arXiv:2602.10543v1 Announce Type: new 
Abstract: Modern security, infrastructure, and safety-critical systems increasingly operate in environments characterised by disruption, uncertainty, physical damage, and degraded communications. Conventional digital technologies -- centralised sensors, software-defined control, and energy-intensive monitoring -- often struggle under such conditions. We propose fungi, and in particular living mycelial networks, as a novel class of biohybride systems for security, resilience, and protection in extreme environments. We discuss how fungi can function as distributed sensing substrates, self-healing materials, and low-observability anomaly-detection layers. We map fungal properties -- such as decentralised control, embodied memory, and autonomous repair -- to applications in infrastructure protection, environmental monitoring, tamper evidence, and long-duration resilience.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10543v1</guid>
      <category>cs.ET</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrew Adamatzky</dc:creator>
    </item>
    <item>
      <title>Function Approximation Using Analog Building Blocks in Flexible Electronics</title>
      <link>https://arxiv.org/abs/2502.01489</link>
      <description>arXiv:2502.01489v1 Announce Type: cross 
Abstract: Function approximation is crucial in Flexible Electronics (FE), where applications demand efficient computational techniques within strict constraints on size, power, and performance. Devices like wearables and compact sensors are constrained by their limited physical dimensions and energy capacity, making traditional digital function approximation challenging and hardware-demanding. This paper addresses function approximation in FE by proposing a systematic and generic approach using a combination of Analog Building Blocks (ABBs) that perform basic mathematical operations such as addition, multiplication, and squaring. These ABBs serve as the foundation for constructing splines, which are then employed in the creation of Kolmogorov-Arnold Networks (KANs), improving the approximation. The analog realization of KAN offers a promising alternative to digital solutions, providing significant hardware benefits, particularly in terms of area and power consumption. Our design achieves a 125x reduction in area and a 10.59% power saving compared to a digital spline with 8-bit precision. Results also show that the analog design introduces an approximation error of up to 7.58% due to both the design and parasitic elements. Nevertheless, KANs are shown to be a viable candidate for function approximation in FE, with potential for further optimization to address the challenges of error reduction and hardware cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01489v1</guid>
      <category>cs.AR</category>
      <category>cs.ET</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Paula Carolina Lozano Duarte, Aradhana Dube, Georgios Zervakis, Mehdi Tahoori, Sani Nassif</dc:creator>
    </item>
    <item>
      <title>Fault Tolerant Design of IGZO-based Binary Search ADCs</title>
      <link>https://arxiv.org/abs/2602.10790</link>
      <description>arXiv:2602.10790v1 Announce Type: cross 
Abstract: Thin-film technologies such as Indium Gallium Zinc Oxide (IGZO) enable Flexible Electronics (FE) for emerging applications in wearable sensing, personal health monitoring, and large-area systems. Analog-to-digital converters (ADCs) serve as critical sensor interfaces in these systems. Yet, their vulnerability to manufacturing defects remains poorly understood despite unipolar technologies' inherently high defect densities and process variations compared to mature CMOS technologies. We present a hierarchical fault injection framework to characterize defect sensitivity in Binary Search ADCs implemented in n-type only technologies. Our methodology combines transistor-level defect characterization with system-level fault propagation analysis, enabling efficient exploration of both single and multiple fault scenarios across the conversion hierarchy. The framework identifies critical fault-sensitive circuit components and enables selective redundancy strategies targeting only the most sensitive components. The resulting defect-tolerant designs improve fault coverage from 60% to 92% under single-fault injections and from 34% to 77.6% under multi-fault injection, while incurring only 4.2% area overhead and 6% power increase. While validated on IGZO-TFTs, the methodology applies to all emerging unipolar technologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10790v1</guid>
      <category>cs.AR</category>
      <category>cs.ET</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Paula Carolina Lozano Duarte, Sule Ozev, Mehdi Tahoori</dc:creator>
    </item>
    <item>
      <title>Evaluating Kubernetes Performance for GenAI Inference: From Automatic Speech Recognition to LLM Summarization</title>
      <link>https://arxiv.org/abs/2602.04900</link>
      <description>arXiv:2602.04900v3 Announce Type: replace 
Abstract: As Generative AI (GenAI), particularly inference, rapidly emerges as a dominant workload category, the Kubernetes ecosystem is proactively evolving to natively support its unique demands. This industry paper demonstrates how emerging Kubernetes-native projects can be combined to deliver the benefits of container orchestration, such as scalability and resource efficiency, to complex AI workflows. We implement and evaluate an illustrative, multi-stage use case consisting of automatic speech recognition and summarization. First, we address batch inference by using Kueue to manage jobs that transcribe audio files with Whisper models and Dynamic Accelerator Slicer (DAS) to increase parallel job execution. Second, we address a discrete online inference scenario by feeding the transcripts to a Large Language Model for summarization hosted using llm-d, a novel solution utilizing the recent developments around the Kubernetes Gateway API Inference Extension (GAIE) for optimized routing of inference requests. Our findings illustrate that these complementary components (Kueue, DAS, and GAIE) form a cohesive, high-performance platform, proving Kubernetes' capability to serve as a unified foundation for demanding GenAI workloads: Kueue reduced total makespan by up to 15%; DAS shortened mean job completion time by 36\%; and GAIE working in conjunction with llm-d improved tail Time to First Token latency by up to 90% even under high loads.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.04900v3</guid>
      <category>cs.ET</category>
      <category>cs.AI</category>
      <category>cs.DC</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sai Sindhur Malleni, Ra\'ul Sevilla, Aleksei Vasilevskii, Jos\'e Castillo Lema, Andr\'e Bauer</dc:creator>
    </item>
    <item>
      <title>OrbitChain: Orchestrating In-orbit Real-time Analytics of Earth Observation Data</title>
      <link>https://arxiv.org/abs/2508.13374</link>
      <description>arXiv:2508.13374v3 Announce Type: replace-cross 
Abstract: Earth observation analytics have the potential to transform many sectors. However, due to limited ground connections, it currently takes hours to days to download and analyze Earth observation data, diminishing the value of data for time-sensitive applications like disaster monitoring or search-and-rescue. To enable real-time analytics, we propose OrbitChain, an in-orbit multi-satellite Earth analytics framework. OrbitChain uses a pipelined design to decompose workflows into analytics functions, and orchestrates constellation-wide resources to finish real-time analytics tasks. It provides timely insights to Earth sensing applications and enables advanced workflows like in-orbit tip-and-cue. Hardware-in-the-loop experiments show that OrbitChain can deliver analytics results in minutes, supports up to 60% more analytics workload than existing frameworks, and reduces inter-satellite communication overhead by up to 45%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.13374v3</guid>
      <category>cs.DC</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhouyu Li, Zhijin Yang, Huayue Gu, Xiaojian Wang, Yuchen Liu, Ruozhou Yu</dc:creator>
    </item>
    <item>
      <title>HuMam: Humanoid Motion Control via End-to-End Deep Reinforcement Learning with Mamba</title>
      <link>https://arxiv.org/abs/2509.18046</link>
      <description>arXiv:2509.18046v2 Announce Type: replace-cross 
Abstract: End-to-end reinforcement learning (RL) for humanoid locomotion is appealing for its compact perception-action mapping, yet practical policies often suffer from training instability, inefficient feature fusion, and high actuation cost. We present HuMam, a state-centric end-to-end RL framework that employs a single-layer Mamba encoder to fuse robot-centric states with oriented footstep targets and a continuous phase clock. The policy outputs joint position targets tracked by a low-level PD loop and is optimized with PPO. A concise six-term reward balances contact quality, swing smoothness, foot placement, posture, and body stability while implicitly promoting energy saving. On the JVRC-1 humanoid in mc-mujoco, HuMam consistently improves learning efficiency, training stability, and overall task performance over a strong feedforward baseline, while reducing power consumption and torque peaks. To our knowledge, this is the first end-to-end humanoid RL controller that adopts Mamba as the fusion backbone, demonstrating tangible gains in efficiency, stability, and control economy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.18046v2</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>eess.SY</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Yinuo Wang, Yuanyang Qi, Jinzhao Zhou, Pengxiang Meng, Xiaowen Tao</dc:creator>
    </item>
    <item>
      <title>From Fragmentation to Integration: Exploring the Design Space of AI Agents for Human-as-the-Unit Privacy Management</title>
      <link>https://arxiv.org/abs/2602.05016</link>
      <description>arXiv:2602.05016v2 Announce Type: replace-cross 
Abstract: Managing one's digital footprint is overwhelming, as it spans multiple platforms and involves countless context-dependent decisions. Recent advances in agentic AI offer ways forward by enabling holistic, contextual privacy-enhancing solutions. Building on this potential, we adopted a ''human-as-the-unit'' perspective and investigated users' cross-context privacy challenges through 12 semi-structured interviews. Results reveal that people rely on ad hoc manual strategies while lacking comprehensive privacy controls, highlighting nine privacy-management challenges across applications, temporal contexts, and relationships. To explore solutions, we generated nine AI agent concepts and evaluated them via a speed-dating survey with 116 US participants. The three highest-ranked concepts were all post-sharing management tools with half or full agent autonomy, with users expressing greater trust in AI accuracy than in their own efforts. Our findings highlight a promising design space where users see AI agents bridging the fragments in privacy management, particularly through automated, comprehensive post-sharing remediation of users' digital footprints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.05016v2</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.ET</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3772318.3790671</arxiv:DOI>
      <arxiv:journal_reference>CHI 2026</arxiv:journal_reference>
      <dc:creator>Eryue Xu, Tianshi Li</dc:creator>
    </item>
  </channel>
</rss>
