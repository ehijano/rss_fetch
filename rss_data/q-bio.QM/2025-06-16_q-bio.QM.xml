<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.QM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.QM</link>
    <description>q-bio.QM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.QM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 16 Jun 2025 04:00:22 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Optimal experiment design for practical parameter identifiability and model discrimination</title>
      <link>https://arxiv.org/abs/2506.11311</link>
      <description>arXiv:2506.11311v1 Announce Type: new 
Abstract: Mechanistic mathematical models of biological systems usually contain a number of unknown parameters whose values need to be estimated from available experimental data in order for the models to be validated and used to make quantitative predictions. This requires that the models are practically identifiable, that is, the values of the parameters can be confidently determined, given available data. A well-designed experiment can produce data that are much more informative for the purpose of inferring parameter values than a poorly designed experiment. It is, therefore, of great interest to optimally design experiments such that the resulting data maximise the practical identifiability of a chosen model. Experimental design is also useful for model discrimination, where we seek to distinguish between multiple distinct, competing models of the same biological system in order to determine which model better reveals insight into the underlying biological mechanisms. In many cases, an external stimulus can be used as a control input to probe the behaviour of the system. In this paper, we will explore techniques for optimally designing such a control for a given experiment, in order to maximise parameter identifiability and model discrimination, and demonstrate these techniques in the context of commonly applied ordinary differential equation models. We use a profile likelihood-based approach to assess parameter identifiability. We then show how the problem of optimal experimental design for model discrimination can be formulated as an optimal control problem, which can be solved efficiently by applying Pontryagin's Maximum Principle.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11311v1</guid>
      <category>q-bio.QM</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yue Liu (University of Oxford, Purdue University), Philip K. Maini (University of Oxford), Ruth E. Baker (University of Oxford)</dc:creator>
    </item>
    <item>
      <title>Scalable Non-Equivariant 3D Molecule Generation via Rotational Alignment</title>
      <link>https://arxiv.org/abs/2506.10186</link>
      <description>arXiv:2506.10186v1 Announce Type: cross 
Abstract: Equivariant diffusion models have achieved impressive performance in 3D molecule generation. These models incorporate Euclidean symmetries of 3D molecules by utilizing an SE(3)-equivariant denoising network. However, specialized equivariant architectures limit the scalability and efficiency of diffusion models. In this paper, we propose an approach that relaxes such equivariance constraints. Specifically, our approach learns a sample-dependent SO(3) transformation for each molecule to construct an aligned latent space. A non-equivariant diffusion model is then trained over the aligned representations. Experimental results demonstrate that our approach performs significantly better than previously reported non-equivariant models. It yields sample quality comparable to state-of-the-art equivariant diffusion models and offers improved training and sampling efficiency. Our code is available at https://github.com/skeletondyh/RADM</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10186v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>q-bio.QM</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuhui Ding, Thomas Hofmann</dc:creator>
    </item>
    <item>
      <title>Longitudinal Omics Data Analysis: A Review on Models, Algorithms, and Tools</title>
      <link>https://arxiv.org/abs/2506.11161</link>
      <description>arXiv:2506.11161v1 Announce Type: cross 
Abstract: Longitudinal omics data (LOD) analysis is essential for understanding the dynamics of biological processes and disease progression over time. This review explores various statistical and computational approaches for analyzing such data, emphasizing their applications and limitations. The main characteristics of longitudinal data, such as imbalancedness, high-dimensionality, and non-Gaussianity are discussed for modeling and hypothesis testing. We discuss the properties of linear mixed models (LMM) and generalized linear mixed models (GLMM) as foundation stones in LOD analyses and highlight their extensions to handle the obstacles in the frequentist and Bayesian frameworks. We differentiate in dynamic data analysis between time-course and longitudinal analyses, covering functional data analysis (FDA) and replication constraints. We explore classification techniques, single-cell as exemplary omics longitudinal studies, survival modeling, and multivariate methods for clinical/biomarker-based applications. Emerging topics, including data integration, clustering, and network-based modeling, are also discussed. We categorized the state-of-the-art approaches applicable to omics data, highlighting how they address the data features. This review serves as a guideline for researchers seeking robust strategies to analyze longitudinal omics data effectively, which is usually complex.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11161v1</guid>
      <category>stat.ME</category>
      <category>q-bio.QM</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ali R. Taheriyoun, Allen Ross, Abolfazl Safikhani, Damoon Soudbakhsh, Ali Rahnavard</dc:creator>
    </item>
    <item>
      <title>Entropy-Constrained Noise Yields Superdiffusive Dynamics in Axonal Growth</title>
      <link>https://arxiv.org/abs/2506.11272</link>
      <description>arXiv:2506.11272v1 Announce Type: cross 
Abstract: We present a coarse-grained stochastic model for axonal extension on periodic arrays of parallel micropatterns that integrates three key biophysical mechanisms: (i) the molecular clutch that couples actin retrograde flow to substrate adhesions, (ii) an active biopolymer-based mechanism generating traction-force fluctuations, and (iii) the mechanical interaction of the growth cone with the micropatterned substrate. Using the Shannon-Jaynes maximum entropy principle with constraints derived from experimental observations, we derive a unique probability distribution for the colored acceleration noise that enters the Langevin equation. The resulting stationary process exhibits power-law temporal correlations with negative exponent, which accounts for the observed superdiffusive dynamics of axons. For biologically relevant parameters the model predicts this exponent to be -1/2, in close quantitative agreement with measurements of cortical neurons cultured on patterned substrates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11272v1</guid>
      <category>physics.bio-ph</category>
      <category>cond-mat.soft</category>
      <category>nlin.AO</category>
      <category>q-bio.CB</category>
      <category>q-bio.QM</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Julian Sutaria, Cristian Staii</dc:creator>
    </item>
    <item>
      <title>On the performance of multi-fidelity and reduced-dimensional neural emulators for inference of physiologic boundary conditions</title>
      <link>https://arxiv.org/abs/2506.11683</link>
      <description>arXiv:2506.11683v1 Announce Type: cross 
Abstract: Solving inverse problems in cardiovascular modeling is particularly challenging due to the high computational cost of running high-fidelity simulations. In this work, we focus on Bayesian parameter estimation and explore different methods to reduce the computational cost of sampling from the posterior distribution by leveraging low-fidelity approximations. A common approach is to construct a surrogate model for the high-fidelity simulation itself. Another is to build a surrogate for the discrepancy between high- and low-fidelity models. This discrepancy, which is often easier to approximate, is modeled with either a fully connected neural network or a nonlinear dimensionality reduction technique that enables surrogate construction in a lower-dimensional space. A third possible approach is to treat the discrepancy between the high-fidelity and surrogate models as random noise and estimate its distribution using normalizing flows. This allows us to incorporate the approximation error into the Bayesian inverse problem by modifying the likelihood function. We validate five different methods which are variations of the above on analytical test cases by comparing them to posterior distributions derived solely from high-fidelity models, assessing both accuracy and computational cost. Finally, we demonstrate our approaches on two cardiovascular examples of increasing complexity: a lumped-parameter Windkessel model and a patient-specific three-dimensional anatomy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11683v1</guid>
      <category>stat.ML</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>q-bio.QM</category>
      <category>stat.TH</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chloe H. Choi, Andrea Zanoni, Daniele E. Schiavazzi, Alison L. Marsden</dc:creator>
    </item>
    <item>
      <title>Viral Dark Matter: Illuminating Protein Function, Ecology, and Biotechnological Promises</title>
      <link>https://arxiv.org/abs/2506.11942</link>
      <description>arXiv:2506.11942v1 Announce Type: cross 
Abstract: Viruses are the most abundant biological entities on Earth and play central roles in shaping microbiomes and influencing ecosystem functions. Yet, most viral genes remain uncharacterized, comprising what is commonly referred to as "viral dark matter." Metagenomic studies across diverse environments consistently show that 40-90% of viral genes lack known homologs or annotated functions. This persistent knowledge gap limits our ability to interpret viral sequence data, understand virus-host interactions, and assess the ecological or applied significance of viral genes. Among the most intriguing components of viral dark matter are auxiliary viral genes (AVGs), including auxiliary metabolic genes (AMGs), regulatory genes (AReGs), and host physiology-modifying genes (APGs), which may alter host function during infection and contribute to microbial metabolism, stress tolerance, or resistance. In this review, we explore recent advances in the discovery and functional characterization of viral dark matter. We highlight representative examples of novel viral proteins across diverse ecosystems including human microbiomes, soil, oceans, and extreme environments, and discuss what is known, and still unknown, about their roles. We then examine the bioinformatic and experimental challenges that hinder functional characterization, and present emerging strategies to overcome these barriers. Finally, we highlight both the fundamental and applied benefits that multidisciplinary efforts to characterize viral proteins can bring. By integrating computational predictions with experimental validation, and fostering collaboration across disciplines, we emphasize that illuminating viral dark matter is both feasible and essential for advancing microbial ecology and unlocking new tools for biotechnology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11942v1</guid>
      <category>q-bio.GN</category>
      <category>q-bio.QM</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>James C. Kosmopoulos, Karthik Anantharaman</dc:creator>
    </item>
    <item>
      <title>DeepGDel: Deep Learning-based Gene Deletion Prediction Framework for Growth-Coupled Production in Genome-Scale Metabolic Models</title>
      <link>https://arxiv.org/abs/2504.06316</link>
      <description>arXiv:2504.06316v3 Announce Type: replace 
Abstract: In genome-scale constraint-based metabolic models, gene deletion strategies are crucial for achieving growth-coupled production, where cell growth and target metabolite production are simultaneously achieved. While computational methods for calculating gene deletions have been widely explored and contribute to developing gene deletion strategy databases, current approaches are limited in leveraging new data-driven paradigms, such as machine learning, for more efficient strain design. Therefore, it is necessary to propose a fundamental framework for this objective. In this study, we first formulate the problem of gene deletion strategy prediction and then propose a framework for predicting gene deletion strategies for growth-coupled production in genome-scale metabolic models. The proposed framework leverages deep learning algorithms to learn and integrate sequential gene and metabolite data representation, enabling the automatic gene deletion strategy prediction. Computational experiment results demonstrate the feasibility of the proposed framework, showing substantial improvements over baseline methods. Specifically, the proposed framework achieves a 14.69%, 22.52%, and 13.03% increase in overall accuracy across three metabolic models of different scales under study, while maintaining balanced precision and recall in predicting gene deletion statuses. The source code and examples for the framework are publicly available at https://github.com/MetNetComp/DeepGDel.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.06316v3</guid>
      <category>q-bio.QM</category>
      <category>cs.LG</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ziwei Yang, Takeyuki Tamura</dc:creator>
    </item>
    <item>
      <title>Parameter estimation in ODEs: assessing the potential of local and global solvers</title>
      <link>https://arxiv.org/abs/2405.01989</link>
      <description>arXiv:2405.01989v2 Announce Type: replace-cross 
Abstract: We consider the problem of parameter estimation in dynamic systems described by ordinary differential equations. A review of the existing literature emphasizes the need for deterministic global optimization methods due to the nonconvex nature of these problems. Recent works have focused on expanding the capabilities of specialized deterministic global optimization algorithms to handle more complex problems. Despite advancements, current deterministic methods are limited to problems with a maximum of around five state and five decision variables, prompting ongoing efforts to enhance their applicability to practical problems. Our study seeks to assess the effectiveness of state-of-the-art general-purpose global and local solvers in handling realistic-sized problems efficiently, and evaluating their capabilities to cope with the nonconvex nature of the underlying estimation problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.01989v2</guid>
      <category>math.OC</category>
      <category>q-bio.QM</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s11081-025-09978-9</arxiv:DOI>
      <arxiv:journal_reference>Optimization and Engineering (2025)</arxiv:journal_reference>
      <dc:creator>M. Fern\'andez de Dios, \'Angel M. Gonz\'alez-Rueda, Julio R. Banga, Julio Gonz\'alez-D\'iaz, David R. Penas</dc:creator>
    </item>
  </channel>
</rss>
