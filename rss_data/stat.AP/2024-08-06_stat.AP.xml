<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.AP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.AP</link>
    <description>stat.AP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.AP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 06 Aug 2024 04:01:38 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 06 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Reconstructing and Forecasting Marine Dynamic Variable Fields across Space and Time Globally and Gaplessly</title>
      <link>https://arxiv.org/abs/2408.01509</link>
      <description>arXiv:2408.01509v1 Announce Type: new 
Abstract: Spatiotemporal projections in marine science are essential for understanding ocean systems and their impact on Earth's climate. However, existing AI-based and statistics-based inversion methods face challenges in leveraging ocean data, generating continuous outputs, and incorporating physical constraints. We propose the Marine Dynamic Reconstruction and Forecast Neural Networks (MDRF-Net), which integrates marine physical mechanisms and observed data to reconstruct and forecast continuous ocean temperature-salinity and dynamic fields. MDRF-Net leverages statistical theories and techniques, incorporating parallel neural network sharing initial layer, two-step training strategy, and ensemble methodology, facilitating in exploring challenging marine areas like the Arctic zone. We have theoretically justified the efficacy of our ensemble method and the rationality of it by providing an upper bound on its generalization error.The effectiveness of MDRF-Net's is validated through a comprehensive simulation study, which highlights its capability to reliably estimate unknown parameters. Comparison with other inversion methods and reanalysis data are also conducted, and the global test error is 0.455{\deg}C for temperature and 0.0714psu for salinity. Overall, MDRF-Net effectively learns the ocean dynamics system using physical mechanisms and statistical insights, contributing to a deeper understanding of marine systems and their impact on the environment and human use of the ocean.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01509v1</guid>
      <category>stat.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Zhixi Xiong, Yukang Jiang, Wenfang Lu, Xueqin Wang, Ting Tian</dc:creator>
    </item>
    <item>
      <title>Journey-Based Transit Equity Analysis: A Case Study in the Greater Boston Area</title>
      <link>https://arxiv.org/abs/2408.01888</link>
      <description>arXiv:2408.01888v1 Announce Type: new 
Abstract: In this paper, a new methodology, journey-based equity analysis, is presented for measuring the equity of transit convenience between income groups. Two data sources are combined in the proposed transit equity analysis: on-board ridership surveys and passenger origin-destination data. The spatial unit of our proposed transit equity analysis is census blocks, which are relatively stable over time and allows an exploration of the data that is granular enough to make conclusions about the service convenience various communities are facing. A case study in the Greater Boston area using real data from the Massachusetts Bay Transportation Authority (MBTA) bus network demonstrates a significant difference in transit service convenience, measured by number of transfers per unit distance, transfer wait time and travel time per unit distance, between low-income riders and high income riders. Implications of analysis results to transit agencies are also discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01888v1</guid>
      <category>stat.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniela Shuman, Xiaotong Guo, Nicholas S. Caros</dc:creator>
    </item>
    <item>
      <title>A statistical procedure to assist dysgraphia detection through dynamic modelling of handwriting</title>
      <link>https://arxiv.org/abs/2408.02099</link>
      <description>arXiv:2408.02099v1 Announce Type: new 
Abstract: Dysgraphia is a neurodevelopmental condition in which children encounter difficulties in handwriting. Dysgraphia is not a disorder per se, but is secondary to neurodevelopmental disorders, mainly dyslexia, Developmental Coordination Disorder (DCD, also known as dyspraxia) or Attention Deficit Hyperactivity Disorder (ADHD). Since the mastering of handwriting is central for the further acquisition of other skills such as orthograph or syntax, an early diagnosis and handling of dysgraphia is thus essential for the academic success of children. In this paper, we investigated a large handwriting database composed of 36 individual symbols (26 isolated letters of the Latin alphabet written in cursive and the 10 digits) written by 545 children from 6,5 to 16 years old, among which 66 displayed dysgraphia (around 12\%). To better understand the dynamics of handwriting, mathematical models of nonpathological handwriting have been proposed, assuming oscillatory and fluid generation of strokes (Parsimonious Oscillatory Model of Handwriting [Andr\'e, 2014]). The purpose of this work is to study how such models behave when applied to children dysgraphic handwriting, and whether a lack of fit may help in the diagnosis, using a two-layer classification procedure with different compositions of classification algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02099v1</guid>
      <category>stat.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yunjiao Lu, Jean-Charles Quinton, Caroline Jolly, Vincent Brault</dc:creator>
    </item>
    <item>
      <title>A Functional Data Approach for Structural Health Monitoring</title>
      <link>https://arxiv.org/abs/2408.02106</link>
      <description>arXiv:2408.02106v1 Announce Type: new 
Abstract: Structural Health Monitoring (SHM) is increasingly applied in civil engineering. One of its primary purposes is detecting and assessing changes in structure conditions to increase safety and reduce potential maintenance downtime. Recent advancements, especially in sensor technology, facilitate data measurements, collection, and process automation, leading to large data streams. We propose a function-on-function regression framework for (nonlinear) modeling the sensor data and adjusting for covariate-induced variation. Our approach is particularly suited for long-term monitoring when several months or years of training data are available. It combines highly flexible yet interpretable semi-parametric modeling with functional principal component analysis and uses the corresponding out-of-sample phase-II scores for monitoring. The method proposed can also be described as a combination of an ``input-output'' and an ``output-only'' method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02106v1</guid>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Philipp Wittenberg, Lizzie Neumann, Alexander Mendler, Jan Gertheiss</dc:creator>
    </item>
    <item>
      <title>SPINEX-Optimization: Similarity-based Predictions with Explainable Neighbors Exploration for Single, Multiple, and Many Objectives Optimization</title>
      <link>https://arxiv.org/abs/2408.02155</link>
      <description>arXiv:2408.02155v1 Announce Type: new 
Abstract: This article introduces an expansion within SPINEX (Similarity-based Predictions with Explainable Neighbors Exploration) suite, now extended to single, multiple, and many objective optimization problems. The newly developed SPINEX-Optimization algorithm incorporates a nuanced approach to optimization in low and high dimensions by accounting for similarity across various solutions. We conducted extensive benchmarking tests comparing SPINEX-Optimization against ten single and eight multi/many optimization algorithms over 55 mathematical benchmarking functions and realistic scenarios. Then, we evaluated the performance of the proposed algorithm in terms of scalability and computational efficiency across low and high dimensions, number of objectives, and population sizes. The results indicate that SPINEX-Optimization consistently outperforms most algorithms and excels in managing complex scenarios, especially in high dimensions. The algorithm's capabilities in explainability, Pareto efficiency, and moderate complexity are highlighted through in-depth experiments and visualization methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02155v1</guid>
      <category>stat.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>MZ Naser, Ahmed Z Naser</dc:creator>
    </item>
    <item>
      <title>Peer-induced Fairness: A Causal Approach to Reveal Algorithmic Unfairness in Credit Approval</title>
      <link>https://arxiv.org/abs/2408.02558</link>
      <description>arXiv:2408.02558v1 Announce Type: new 
Abstract: This paper introduces a novel framework, "peer-induced fairness", to scientifically audit algorithmic fairness. It addresses a critical but often overlooked issue: distinguishing between adverse outcomes due to algorithmic discrimination and those resulting from individuals' insufficient capabilities. By utilizing counterfactual fairness and advanced causal inference techniques, such as the Single World Intervention Graph, this model-agnostic approach evaluates fairness at the individual level through peer comparisons and hypothesis testing. It also tackles challenges like data scarcity and imbalance, offering a flexible, plug-and-play self-audit tool for stakeholders and an external audit tool for regulators, while providing explainable feedback for those affected by unfavorable decisions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02558v1</guid>
      <category>stat.AP</category>
      <category>cs.CY</category>
      <category>q-fin.CP</category>
      <category>q-fin.ST</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shiqi Fang, Zexun Chen, Jake Ansell</dc:creator>
    </item>
    <item>
      <title>Log-Gaussian Cox Processes for Spatiotemporal Traffic Fatality Estimation in Addis Ababa</title>
      <link>https://arxiv.org/abs/2408.02612</link>
      <description>arXiv:2408.02612v1 Announce Type: new 
Abstract: We investigate the spatiotemporal dynamics of traffic accidents in Addis Ababa, Ethiopia, using 2016--2019 data. We formulate the traffic accident intensity as a log-Gaussian Cox Process and model it as a spatiotemporal point process with and without fixed and random effect components that incorporate possible covariates and spatial correlation information. The covariate includes population density and distance of accident locations from schools, from markets, from bus stops and from worship places. We estimate the posterior of the state variables using integrated nested Laplace approximations with stochastic partial differential equations approach by considering Mat\`ern prior. Deviance and Watanabe - Akaike information criteria are used to check the performance of the models. We implement the methodology to map traffic accident intensity over Addis Ababa entirely and on its road networks and visualize the potential traffic accident hotspot areas. The comparison of the observation with the model output reveals that the covariates considered has significant effect for the accident intensity. Moreover, the information criteria results reveal the model with covariate performs well compared with the model without covariates. We obtained temporal correlation of the log-intensity as 0.78 indicating the existence of similar traffic fatality trend in space during the study period.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02612v1</guid>
      <category>stat.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yassin Tesfaw Abebe, Abdu Mohammed Seid, Lassi Roininen</dc:creator>
    </item>
    <item>
      <title>Momentum Capture and Prediction System Based on Wimbledon Open2023 Tournament Data</title>
      <link>https://arxiv.org/abs/2408.01544</link>
      <description>arXiv:2408.01544v1 Announce Type: cross 
Abstract: There is a hidden energy in tennis, which cannot be seen or touched. It is the force that controls the flow of the game and is present in all types of matches. This mysterious force is Momentum. This study introduces an evaluation model that synergizes the Entropy Weight Method (EWM) and Gray Relation Analysis (GRA) to quantify momentum's impact on match outcomes. Empirical validation was conducted through Mann-Whitney U and Kolmogorov-Smirnov tests, which yielded p values of 0.0043 and 0.00128,respectively. These results underscore the non-random association between momentum shifts and match outcomes, highlighting the critical role of momentum in tennis. Otherwise, our investigation foucus is the creation of a predictive model that combines the advanced machine learning algorithm XGBoost with the SHAP framework. This model enables precise predictions of match swings with exceptional accuracy (0.999013 for multiple matches and 0.992738 for finals). The model's ability to identify the influence of specific factors on match dynamics,such as bilateral distance run during points, demonstrates its prowess.The model's generalizability was thoroughly evaluated using datasets from the four Grand Slam tournaments. The results demonstrate its remarkable adaptability to different match scenarios,despite minor variations in predictive accuracy. It offers strategic insights that can help players effectively respond to opponents' shifts in momentum,enhancing their competitive edge.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01544v1</guid>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chang Liu, Tongyuan Yang, Yan Zhao</dc:creator>
    </item>
    <item>
      <title>Weighted Brier Score -- an Overall Summary Measure for Risk Prediction Models with Clinical Utility Consideration</title>
      <link>https://arxiv.org/abs/2408.01626</link>
      <description>arXiv:2408.01626v1 Announce Type: cross 
Abstract: As advancements in novel biomarker-based algorithms and models accelerate disease risk prediction and stratification in medicine, it is crucial to evaluate these models within the context of their intended clinical application. Prediction models output the absolute risk of disease; subsequently, patient counseling and shared decision-making are based on the estimated individual risk and cost-benefit assessment. The overall impact of the application is often referred to as clinical utility, which received significant attention in terms of model assessment lately. The classic Brier score is a popular measure of prediction accuracy; however, it is insufficient for effectively assessing clinical utility. To address this limitation, we propose a class of weighted Brier scores that aligns with the decision-theoretic framework of clinical utility. Additionally, we decompose the weighted Brier score into discrimination and calibration components, examining how weighting influences the overall score and its individual components. Through this decomposition, we link the weighted Brier score to the $H$ measure, which has been proposed as a coherent alternative to the area under the receiver operating characteristic curve. This theoretical link to the $H$ measure further supports our weighting method and underscores the essential elements of discrimination and calibration in risk prediction evaluation. The practical use of the weighted Brier score as an overall summary is demonstrated using data from the Prostate Cancer Active Surveillance Study (PASS).</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01626v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kehao Zhu, Yingye Zheng, Kwun Chuen Gary Chan</dc:creator>
    </item>
    <item>
      <title>A Novel Metric for Measuring the Robustness of Large Language Models in Non-adversarial Scenarios</title>
      <link>https://arxiv.org/abs/2408.01963</link>
      <description>arXiv:2408.01963v1 Announce Type: cross 
Abstract: We evaluate the robustness of several large language models on multiple datasets. Robustness here refers to the relative insensitivity of the model's answers to meaning-preserving variants of their input. Benchmark datasets are constructed by introducing naturally-occurring, non-malicious perturbations, or by generating semantically equivalent paraphrases of input questions or statements. We further propose a novel metric for assessing a model robustness, and demonstrate its benefits in the non-adversarial scenario by empirical evaluation of several models on the created datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01963v1</guid>
      <category>cs.CL</category>
      <category>stat.AP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Samuel Ackerman, Ella Rabinovich, Eitan Farchi, Ateret Anaby-Tavor</dc:creator>
    </item>
    <item>
      <title>Graph-Enabled Fast MCMC Sampling with an Unknown High-Dimensional Prior Distribution</title>
      <link>https://arxiv.org/abs/2408.02122</link>
      <description>arXiv:2408.02122v1 Announce Type: cross 
Abstract: Posterior sampling is a task of central importance in Bayesian inference. For many applications in Bayesian meta-analysis and Bayesian transfer learning, the prior distribution is unknown and needs to be estimated from samples. In practice, the prior distribution can be high-dimensional, adding to the difficulty of efficient posterior inference. In this paper, we propose a novel Markov chain Monte Carlo algorithm, which we term graph-enabled MCMC, for posterior sampling with unknown and potentially high-dimensional prior distributions. The algorithm is based on constructing a geometric graph from prior samples and subsequently uses the graph structure to guide the transition of the Markov chain. Through extensive theoretical and numerical studies, we demonstrate that our graph-enabled MCMC algorithm provides reliable approximation to the posterior distribution and is highly computationally efficient.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02122v1</guid>
      <category>stat.CO</category>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chenyang Zhong, Shouxuan Ji, Tian Zheng</dc:creator>
    </item>
    <item>
      <title>Machine Learning-based Relative Valuation of Municipal Bonds</title>
      <link>https://arxiv.org/abs/2408.02273</link>
      <description>arXiv:2408.02273v1 Announce Type: cross 
Abstract: The trading ecosystem of the Municipal (muni) bond is complex and unique. With nearly 2\% of securities from over a million securities outstanding trading daily, determining the value or relative value of a bond among its peers is challenging. Traditionally, relative value calculation has been done using rule-based or heuristics-driven approaches, which may introduce human biases and often fail to account for complex relationships between the bond characteristics. We propose a data-driven model to develop a supervised similarity framework for the muni bond market based on CatBoost algorithm. This algorithm learns from a large-scale dataset to identify bonds that are similar to each other based on their risk profiles. This allows us to evaluate the price of a muni bond relative to a cohort of bonds with a similar risk profile. We propose and deploy a back-testing methodology to compare various benchmarks and the proposed methods and show that the similarity-based method outperforms both rule-based and heuristic-based methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02273v1</guid>
      <category>q-fin.ST</category>
      <category>q-fin.TR</category>
      <category>stat.AP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Preetha Saha, Jingrao Lyu, Dhruv Desai, Rishab Chauhan, Jerinsh Jeyapaulraj, Philip Sommer, Dhagash Mehta</dc:creator>
    </item>
    <item>
      <title>Comparison of Probabilistic Structural Reliability Methods for Ultimate Limit State Assessment of Wind Turbines</title>
      <link>https://arxiv.org/abs/2312.04972</link>
      <description>arXiv:2312.04972v2 Announce Type: replace 
Abstract: The probabilistic design of offshore wind turbines aims to ensure structural safety in a cost-effective way. This involves conducting structural reliability assessments for different design options and considering different structural responses. There are several structural reliability methods, and this paper will apply and compare different approaches in some simplified case studies. In particular, the well known environmental contour method will be compared to a more novel approach based on sequential sampling and Gaussian processes regression for an ultimate limit state case study. For one of the case studies, results will also be compared to results from a brute force simulation approach. Interestingly, the comparison is very different from the two case studies. In one of the cases the environmental contours method agrees well with the sequential sampling method but in the other, results vary considerably. Probably, this can be explained by the violation of some of the assumptions associated with the environmental contour approach, i.e. that the short-term variability of the response is large compared to the long-term variability of the environmental conditions. Results from this simple comparison study suggests that the sequential sampling method can be a robust and computationally effective approach for structural reliability assessment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.04972v2</guid>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.strusafe.2024.102502</arxiv:DOI>
      <dc:creator>Hong Wang, Odin Gramstad, Styfen Sch\"ar, Stefano Marelli, Erik Vanem</dc:creator>
    </item>
    <item>
      <title>Stress Resultant-Based Approach to Mass Assumption-Free Bayesian Model Updating of Frame Structures</title>
      <link>https://arxiv.org/abs/2401.17932</link>
      <description>arXiv:2401.17932v2 Announce Type: replace 
Abstract: Bayesian model updating facilitates the calibration of analytical models based on observations and the quantification of uncertainties in model parameters such as stiffness and mass. This process significantly enhances damage assessment and response predictions in existing civil structures. Predominantly, current methods employ modal properties identified from acceleration measurements to evaluate the likelihood of the model parameters. This modal analysis-based likelihood generally involves a prior assumption regarding the mass parameters. In civil structures, accurate determination of mass parameters proves challenging owing to the significant uncertainty and time-varying nature of imposed loads. The resulting inaccuracy potentially introduces biases while estimating the stiffness parameters, which affects the assessment of structural response and associated damage. Addressing this issue, the present study introduces a stress-resultant-based approach for Bayesian model updating independent of mass assumptions. This approach utilizes system identification on strain and acceleration measurements to establish the relationship between nodal displacements and elemental stress resultants. Employing static analysis to depict this relationship aids in assessing the likelihood of stiffness parameters. Integrating this static-analysis-based likelihood with a modal-analysis-based likelihood facilitates the simultaneous estimation of mass and stiffness parameters. The proposed approach was validated using numerical examples on a planar frame and experimental studies on a full-scale moment-resisting steel frame structure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.17932v2</guid>
      <category>stat.AP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1061/AJRUA6.RUENG-1314</arxiv:DOI>
      <arxiv:journal_reference>ASCE-ASME Journal of Risk and Uncertainty in Engineering Systems, Part A: Civil Engineering, 10 (2024), 04024055</arxiv:journal_reference>
      <dc:creator>Taro Yaoyama, Tatsuya Itoi, Jun Iyama</dc:creator>
    </item>
    <item>
      <title>Design-Based Inference for Spatial Experiments under Unknown Interference</title>
      <link>https://arxiv.org/abs/2010.13599</link>
      <description>arXiv:2010.13599v5 Announce Type: replace-cross 
Abstract: We consider design-based causal inference for spatial experiments in which treatments may have effects that bleed out and feed back in complex ways. Such spatial spillover effects violate the standard ``no interference'' assumption for standard causal inference methods. The complexity of spatial spillover effects also raises the risk of misspecification and bias in model-based analyses. We offer an approach for robust inference in such settings without having to specify a parametric outcome model. We define a spatial ``average marginalized effect'' (AME) that characterizes how, in expectation, units of observation that are a specified distance from an intervention location are affected by treatment at that location, averaging over effects emanating from other intervention nodes. We show that randomization is sufficient for non-parametric identification of the AME even if the nature of interference is unknown. Under mild restrictions on the extent of interference, we establish asymptotic distributions of estimators and provide methods for both sample-theoretic and randomization-based inference. We show conditions under which the AME recovers a structural effect. We illustrate our approach with a simulation study. Then we re-analyze a randomized field experiment and a quasi-experiment on forest conservation, showing how our approach offers robust inference on policy-relevant spillover effects.</description>
      <guid isPermaLink="false">oai:arXiv.org:2010.13599v5</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ye Wang, Cyrus Samii, Haoge Chang, P. M. Aronow</dc:creator>
    </item>
    <item>
      <title>Priming bias versus post-treatment bias in experimental designs</title>
      <link>https://arxiv.org/abs/2306.01211</link>
      <description>arXiv:2306.01211v5 Announce Type: replace-cross 
Abstract: Conditioning on variables affected by treatment can induce post-treatment bias when estimating causal effects. Although this suggests that researchers should measure potential moderators before administering the treatment in an experiment, doing so may also bias causal effect estimation if the covariate measurement primes respondents to react differently to the treatment. This paper formally analyzes this trade-off between post-treatment and priming biases in three experimental designs that vary when moderators are measured: pre-treatment, post-treatment, or a randomized choice between the two. We derive nonparametric bounds for interactions between the treatment and the moderator under each design and show how to use substantive assumptions to narrow these bounds. These bounds allow researchers to assess the sensitivity of their empirical findings to priming and post-treatment bias. We then apply the proposed methodology to a survey experiment on electoral messaging.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.01211v5</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matthew Blackwell, Jacob R. Brown, Sophie Hill, Kosuke Imai, Teppei Yamamoto</dc:creator>
    </item>
    <item>
      <title>Robust Survival Analysis with Adversarial Regularization</title>
      <link>https://arxiv.org/abs/2312.16019</link>
      <description>arXiv:2312.16019v3 Announce Type: replace-cross 
Abstract: Survival Analysis (SA) models the time until an event occurs, with applications in fields like medicine, defense, finance, and aerospace. Recent work shows that Neural Networks (NNs) can capture complex relationships in SA. However, dataset uncertainties (e.g., noisy measurements, human error) can degrade model performance. To address this, we leverage NN verification advances to create algorithms for robust, fully-parametric survival models. We introduce a robust loss function and use CROWN-IBP regularization to handle computational challenges in the Min-Max problem. Evaluating our approach on SurvSet datasets, we find that our Survival Analysis with Adversarial Regularization (SAWAR) method consistently outperforms baselines under various perturbations with respect to Negative Log Likelihood (NegLL), Integrated Brier Score (IBS), and Concordance Index (CI). This demonstrates that adversarial regularization enhances SA performance and calibration, mitigating data uncertainty and improving generalization across diverse datasets up to 150% across all perturbation magnitudes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.16019v3</guid>
      <category>stat.ML</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael Potter, Stefano Maxenti, Michael Everett</dc:creator>
    </item>
    <item>
      <title>The Multi-Range Theory of Translation Quality Measurement: MQM scoring models and Statistical Quality Control</title>
      <link>https://arxiv.org/abs/2405.16969</link>
      <description>arXiv:2405.16969v5 Announce Type: replace-cross 
Abstract: The year 2024 marks the 10th anniversary of the Multidimensional Quality Metrics (MQM) framework for analytic translation quality evaluation. The MQM error typology has been widely used by practitioners in the translation and localization industry and has served as the basis for many derivative projects. The annual Conference on Machine Translation (WMT) shared tasks on both human and automatic translation quality evaluations used the MQM error typology.
  The metric stands on two pillars: error typology and the scoring model. The scoring model calculates the quality score from annotation data, detailing how to convert error type and severity counts into numeric scores to determine if the content meets specifications. Previously, only the raw scoring model had been published. This April, the MQM Council published the Linear Calibrated Scoring Model, officially presented herein, along with the Non-Linear Scoring Model, which had not been published before.
  This paper details the latest MQM developments and presents a universal approach to translation quality measurement across three sample size ranges. It also explains why Statistical Quality Control should be used for very small sample sizes, starting from a single sentence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16969v5</guid>
      <category>cs.CL</category>
      <category>stat.AP</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Arle Lommel, Serge Gladkoff, Alan Melby, Sue Ellen Wright, Ingemar Strandvik, Katerina Gasova, Angelika Vaasa, Andy Benzo, Romina Marazzato Sparano, Monica Foresi, Johani Innis, Lifeng Han, Goran Nenadic</dc:creator>
    </item>
    <item>
      <title>Causal Inference with Outcomes Truncated by Death and Missing Not at Random</title>
      <link>https://arxiv.org/abs/2406.10554</link>
      <description>arXiv:2406.10554v2 Announce Type: replace-cross 
Abstract: In clinical trials, principal stratification analysis is commonly employed to address the issue of truncation by death, where a subject dies before the outcome can be measured. However, in practice, many survivor outcomes may remain uncollected or be missing not at random, posing a challenge to standard principal stratification analyses. In this paper, we explore the identification, estimation, and bounds of the average treatment effect within a subpopulation of individuals who would potentially survive under both treatment and control conditions. We show that the causal parameter of interest can be identified by introducing a proxy variable that affects the outcome only through the principal strata, while requiring that the treatment variable does not directly affect the missingness mechanism. Subsequently, we propose an approach for estimating causal parameters and derive nonparametric bounds in cases where identification assumptions are violated. We illustrate the performance of the proposed method through simulation studies and a real dataset obtained from a Human Immunodeficiency Virus (HIV) study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.10554v2</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wei Li, Yuan Liu, Shanshan Luo, Zhi Geng</dc:creator>
    </item>
    <item>
      <title>The inverse Kalman filter</title>
      <link>https://arxiv.org/abs/2407.10089</link>
      <description>arXiv:2407.10089v2 Announce Type: replace-cross 
Abstract: In this study, we introduce a new approach, the inverse Kalman filter (IKF), which enables accurate matrix-vector multiplication between a covariance matrix from a dynamic linear model and any real-valued vector with linear computational cost. We incorporate the IKF with the conjugate gradient algorithm, which substantially accelerates the computation of matrix inversion for a general form of covariance matrices, whereas other approximation approaches may not be directly applicable. We demonstrate the scalability and efficiency of the IKF approach through distinct applications, including nonparametric estimation of particle interaction functions and predicting incomplete lattices of correlated data, using both simulation and real-world observations, including cell trajectory and satellite radar interferogram.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10089v2</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xinyi Fang, Mengyang Gu</dc:creator>
    </item>
    <item>
      <title>FAVis: Visual Analytics of Factor Analysis for Psychological Research</title>
      <link>https://arxiv.org/abs/2407.14072</link>
      <description>arXiv:2407.14072v2 Announce Type: replace-cross 
Abstract: Psychological research often involves understanding psychological constructs through conducting factor analysis on data collected by a questionnaire, which can comprise hundreds of questions. Without interactive systems for interpreting factor models, researchers are frequently exposed to subjectivity, potentially leading to misinterpretations or overlooked crucial information. This paper introduces FAVis, a novel interactive visualization tool designed to aid researchers in interpreting and evaluating factor analysis results. FAVis enhances the understanding of relationships between variables and factors by supporting multiple views for visualizing factor loadings and correlations, allowing users to analyze information from various perspectives. The primary feature of FAVis is to enable users to set optimal thresholds for factor loadings to balance clarity and information retention. FAVis also allows users to assign tags to variables, enhancing the understanding of factors by linking them to their associated psychological constructs. Our user study demonstrates the utility of FAVis in various tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.14072v2</guid>
      <category>cs.HC</category>
      <category>stat.AP</category>
      <category>stat.OT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yikai Lu, Chaoli Wang</dc:creator>
    </item>
    <item>
      <title>AI-Powered Energy Algorithmic Trading: Integrating Hidden Markov Models with Neural Networks</title>
      <link>https://arxiv.org/abs/2407.19858</link>
      <description>arXiv:2407.19858v2 Announce Type: replace-cross 
Abstract: In quantitative finance, machine learning methods are essential for alpha generation. This study introduces a new approach that combines Hidden Markov Models (HMM) and neural networks, integrated with Black-Litterman portfolio optimization. During the COVID period (2019-2022), this dual-model approach achieved a 97% return with a Sharpe ratio of 0.992. It incorporates two risk models to enhance risk management, showing efficiency during volatile periods. The methodology was implemented on the QuantConnect platform, which was chosen for its robust framework and experimental reproducibility. The system, which predicts future price movements, includes a three-year warm-up to ensure proper algorithm function. It targets highly liquid, large-cap energy stocks to ensure stable and predictable performance while also considering broker payments. The dual-model alpha system utilizes log returns to select the optimal state based on the historical performance. It combines state predictions with neural network outputs, which are based on historical data, to generate trading signals. This study examined the architecture of the trading system, data pre-processing, training, and performance. The full code and backtesting data are available under the MIT license.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.19858v2</guid>
      <category>q-fin.PM</category>
      <category>cs.LG</category>
      <category>q-fin.GN</category>
      <category>stat.AP</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tiago Monteiro</dc:creator>
    </item>
  </channel>
</rss>
