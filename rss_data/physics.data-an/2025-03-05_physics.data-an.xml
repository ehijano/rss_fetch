<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.data-an updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.data-an</link>
    <description>physics.data-an updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.data-an" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 06 Mar 2025 02:50:11 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Inferring Galactic Parameters from Chemical Abundances with Simulation-Based Inference</title>
      <link>https://arxiv.org/abs/2503.02456</link>
      <description>arXiv:2503.02456v1 Announce Type: cross 
Abstract: Galactic chemical abundances provide crucial insights into fundamental galactic parameters, such as the high-mass slope of the initial mass function (IMF) and the normalization of Type Ia supernova (SN Ia) rates. Constraining these parameters is essential for advancing our understanding of stellar feedback, metal enrichment, and galaxy formation processes. However, traditional Bayesian inference techniques, such as Hamiltonian Monte Carlo (HMC), are computationally prohibitive when applied to large datasets of modern stellar surveys. We leverage simulation-based-inference (SBI) as a scalable, robust, and efficient method for constraining galactic parameters from stellar chemical abundances and demonstrate its the advantages over HMC in terms of speed, scalability, and robustness against model misspecifications. We combine a Galactic Chemical Evolution (GCE) model, CHEMPY, with a neural network emulator and a Neural Posterior Estimator (NPE) to train our SBI pipeline. Mock datasets are generated using CHEMPY, including scenarios with mismatched nucleosynthetic yields, with additional tests conducted on data from a simulated Milky Way-like galaxy. SBI results are benchmarked against HMC-based inference, focusing on computational performance, accuracy, and resilience to systematic discrepancies. SBI achieves a $\sim75,600\times$ speed-up compared to HMC, reducing inference runtime from $\gtrsim42$ hours to mere seconds for thousands of stars. Inference on $1,000$ stars yields precise estimates for the IMF slope ($\alpha_{\rm IMF} = -2.298 \pm 0.002$) and SN Ia normalization ($\log_{10}(N_{\rm Ia}) = -2.885 \pm 0.003$), deviating less than 0.05% from the ground truth. SBI also demonstrates similar robustness to model misspecification than HMC, recovering accurate parameters even with alternate yield tables or data from a cosmological simulation. (shortened...)</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.02456v1</guid>
      <category>astro-ph.GA</category>
      <category>astro-ph.IM</category>
      <category>physics.comp-ph</category>
      <category>physics.data-an</category>
      <category>physics.space-ph</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tobias Buck, Berkay G\"unes, Giuseppe Viterbo, William H. Oliver, Sven Buder</dc:creator>
    </item>
    <item>
      <title>Quantum measurement fitting</title>
      <link>https://arxiv.org/abs/2503.02460</link>
      <description>arXiv:2503.02460v1 Announce Type: cross 
Abstract: Quantum measurements are not deterministic. For this reason quantum measurements are repeated for a number of shots on identically prepared systems. The uncertainty in each measurement depends on the number of shots and the expected outcome of the measurement. This information can be used to improve the fitting of models to quantum measurements.
  In this paper we analyse ordinary-least squares, weighted least squares and maximum-likelihood estimation. We show that using the information on the quantum measurement uncertainty can lead to improved estimation of system parameters. We also introduce the concept of model violation and demonstrate it can be a valuable tool to analyze model assumptions and performance of quantum systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.02460v1</guid>
      <category>quant-ph</category>
      <category>physics.data-an</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pieter Thijs Eendebak</dc:creator>
    </item>
    <item>
      <title>Fast multilabel classification of HEP constraints with deep learning</title>
      <link>https://arxiv.org/abs/2409.05453</link>
      <description>arXiv:2409.05453v2 Announce Type: replace-cross 
Abstract: The shortcomings of the Standard Model (SM) motivate its extension to accommodate new expected phenomena, such as dark matter and neutrino masses. However, such extensions are generally more complex due to the presence of a large number of free parameters and additional phenomenology. Understanding how theoretical and experimental limits affect the parameter spaces of new models, individually and collectively, is of utmost importance for conducting model status analysis, motivating precise computations, or model-building aimed at solving certain issues. However, checking the constraints usually require a large amount of time using a chain of physics tools. We demonstrate, for the first time, the application of deep learning (DL) for the multilabel classification (MLC) of a group of theoretical and experimental constraints in the dark doublet phase of the next-to-two-Higgs-doublet model (DDP-N2HDM), as a representative 9-dimensional parameter space. We analyze the issue of class imbalance and the ability of the classifier to learn joint class distributions. We demonstrate the time advantage compared to physics tools, with the classifier achieving orders of magnitude faster checks on groups of constraints and strong performance. The classifier performed strongly in terms of identifying regions where all constraints are valid or invalid, as well as regions where one or more of the constraints are valid or invalid simultaneously. This approach can be applied to any extension beyond the SM with the potential to aid HEP tools or act as a surrogate for fast model status checks. To that end, we provide a python tool \texttt{HEPMLC} for generating and investigating multilabel classifiers for SM extensions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.05453v2</guid>
      <category>hep-ph</category>
      <category>hep-ex</category>
      <category>hep-th</category>
      <category>physics.comp-ph</category>
      <category>physics.data-an</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maien Binjonaid</dc:creator>
    </item>
    <item>
      <title>Doppler correlation-driven vetoes for the Frequency Hough analysis in continuous gravitational-wave searches</title>
      <link>https://arxiv.org/abs/2410.19420</link>
      <description>arXiv:2410.19420v5 Announce Type: replace-cross 
Abstract: We present an improved method for vetoing candidates of continuous gravitational-wave sources during all-sky searches utilizing the Frequency Hough pipeline. This approach leverages linear correlations between source parameters induced by the Earth Doppler effect, which can be effectively identified through the Hough Transform. Candidates that do not align with these patterns are considered spurious and can thus be vetoed, enhancing the depth and statistical significance of follow-up analyses. Additionally, we provide a comprehensive explanation of the method calibration, which intrinsically linked to the total duration of the observing run. On average, the procedure successfully vetoes $56\%$ of candidates. To assess the method performance, we conducted a Monte-Carlo simulation injecting fake continuous-wave signals into data from the third observing run of the LIGO detectors. This analysis allowed us to infer strain amplitude upper limits at a $90\%$ confidence level. We found that the optimal sensitivity is $h_0^{90\%} = 3.62^{+0.23}_{-0.22}\times 10^{-26}$ in the [128, 200] Hz band, which is within the most sensible frequency band of the LIGO detectors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.19420v5</guid>
      <category>gr-qc</category>
      <category>astro-ph.IM</category>
      <category>physics.data-an</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1103/PhysRevD.111.062001</arxiv:DOI>
      <arxiv:journal_reference>Phys. Rev. D 111, 062001 (2025)</arxiv:journal_reference>
      <dc:creator>Matteo Di Giovanni, Paola Leaci, Pia Astone, Stefano Dal Pra, Sabrina D'Antonio, Luca D'Onofrio, Sergio Frasca, Federico Muciaccia, Cristiano Palomba, Lorenzo Pierini, Francesco Safai Tehrani</dc:creator>
    </item>
    <item>
      <title>Physical meaning of principal component analysis for classical lattice systems with translational invariance</title>
      <link>https://arxiv.org/abs/2410.22682</link>
      <description>arXiv:2410.22682v3 Announce Type: replace-cross 
Abstract: We explore the physical implications of applying principal component analysis (PCA) to translationally invariant classical systems defined on a $d$-dimensional hypercubic lattice. Using Rayleigh-Schr\"odinger perturbation theory, we demonstrate that the principal components are related to the reciprocal lattice vectors of the hypercubic lattice, and the corresponding eigenvalues are connected to the discrete Fourier transform of the sampled configurations. From a different perspective, we show that the PCA in question can be viewed as a numerical method for computing the ensemble average of the squared moduli of the Fourier transform of physical quantities. Our results also provide a way to determine approximately the principal components of a classical system with translational invariance without the need for matrix diagonalization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.22682v3</guid>
      <category>cond-mat.stat-mech</category>
      <category>physics.data-an</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Su-Chan Park</dc:creator>
    </item>
    <item>
      <title>Designing a Dataset for Convolutional Neural Networks to Predict Space Groups Consistent with Extinction Laws</title>
      <link>https://arxiv.org/abs/2411.00803</link>
      <description>arXiv:2411.00803v3 Announce Type: replace-cross 
Abstract: In this paper, a dataset of one-dimensional powder diffraction patterns was designed with new strategy to train Convolutional Neural Networks for predicting space groups. The diffraction pattern was calculated based on lattice parameters and Extinction Laws, instead of the traditional approach of generating it from a crystallographic database. This paper demonstrates that the new strategy is more effective than the conventional method. As a result, the model trained on the cubic and tetragonal training set from the newly designed dataset achieves prediction accuracy that matches the theoretical maximums calculated based on Extinction Laws. These results demonstrate that machine learning-based prediction can be both physically reasonable and reliable. Additionally, the model trained on our newly designed dataset shows excellent generalization capability, much better than the one trained on a traditionally designed dataset.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00803v3</guid>
      <category>cs.NE</category>
      <category>physics.data-an</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hao Wang, Jiajun Zhong, Yikun Li, Junrong Zhang, Rong Du</dc:creator>
    </item>
  </channel>
</rss>
