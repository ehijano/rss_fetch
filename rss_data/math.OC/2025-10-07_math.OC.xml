<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 08 Oct 2025 01:42:13 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Machine Learning and Control: Foundations, Advances, and Perspectives</title>
      <link>https://arxiv.org/abs/2510.03303</link>
      <description>arXiv:2510.03303v1 Announce Type: new 
Abstract: Control theory of dynamical systems offers a powerful framework for tackling challenges in deep neural networks and other machine learning architectures. We show that concepts such as simultaneous and ensemble controllability offer new insights into the classification and representation properties of deep neural networks while the control and optimization of static systems can be employed to better understand the performance of shallow networks. Inspired by the classical concept of turnpike, we also explore the relationship between dynamic and static neural networks, where depth is traded for width, and the role of transformers as mechanisms for accelerating classical neural network tasks. We also exploit the expressive power of neural networks (exemplified, for instance, by the Universal Approximation Theorem) to develop a novel hybrid modeling methodology, the Hybrid-Cooperative Learning (HYCO), combining mechanics and data-driven methods in a game-theoretic setting. Finally, we describe how classical properties of diffusion processes, long established in the context of partial differential equations, contribute to explaining the success of modern generative artificial intelligence (AI). We present an overview of our recent results in these areas, illustrating how control, machine learning, numerical analysis, and partial differential equations come together to motivate a fertile ground for future research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.03303v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Enrique Zuazua</dc:creator>
    </item>
    <item>
      <title>Efficient Input-Constrained Impulsive Optimal Control of Linear Systems with Application to Spacecraft Relative Motion</title>
      <link>https://arxiv.org/abs/2510.03423</link>
      <description>arXiv:2510.03423v1 Announce Type: new 
Abstract: This work presents a novel algorithm for impulsive optimal control of linear time-varying systems with the inclusion of input magnitude constraints. Impulsive optimal control problems, where the optimal input solution is a sum of delta functions, are typically formulated as an optimization over a normed function space subject to integral equality constraints and can be efficiently solved for linear time-varying systems in their dual formulation. In this dual setting, the problem takes the form of a semi-infinite program which is readily solvable in online scenarios for constructing maneuver plans. This work augments the approach with the inclusion of magnitude constraints on the input over time windows of interest, which is shown to preserve the impulsive nature of the optimal solution and enable efficient solution procedures via semi-infinite programming. The resulting algorithm is demonstrated on the highly relevant problem of relative motion control of spacecraft in Low Earth Orbit (LEO) and compared to several other proposed solutions from the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.03423v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ethan Foss, Simone D'Amico</dc:creator>
    </item>
    <item>
      <title>Cooling Under Convexity: An Inventory Control Perspective on Industrial Refrigeration</title>
      <link>https://arxiv.org/abs/2510.03448</link>
      <description>arXiv:2510.03448v1 Announce Type: new 
Abstract: Industrial refrigeration systems have substantial energy needs, but optimizing their operation remains challenging due to the tension between minimizing energy costs and meeting strict cooling requirements. Load shifting--strategic overcooling in anticipation of future demands--offers substantial efficiency gains. This work seeks to rigorously quantify these potential savings through the derivation of optimal load shifting policies. Our first contribution establishes a novel connection between industrial refrigeration and inventory control problems with convex ordering costs, where the convexity arises from the relationship between energy consumption and cooling capacity. Leveraging this formulation, we derive three main theoretical results: (1) an optimal algorithm for deterministic demand scenarios, along with proof that optimal trajectories are non-increasing (a valuable structural insight for practical control); (2) performance bounds that quantify the value of load shifting as a function of cost convexity, demand variability, and temporal patterns; (3) a computationally tractable load shifting heuristic with provable near-optimal performance under uncertainty. Numerical simulations validate our theoretical findings, and a case study using real industrial refrigeration data demonstrates an opportunity for improved load shifting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.03448v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vade Shah, Yohan John, Ethan Freifeld, Lily Y. Chen, Jason R. Marden</dc:creator>
    </item>
    <item>
      <title>Optimal Regularization Under Uncertainty: Distributional Robustness and Convexity Constraints</title>
      <link>https://arxiv.org/abs/2510.03464</link>
      <description>arXiv:2510.03464v1 Announce Type: new 
Abstract: Regularization is a central tool for addressing ill-posedness in inverse problems and statistical estimation, with the choice of a suitable penalty often determining the reliability and interpretability of downstream solutions. While recent work has characterized optimal regularizers for well-specified data distributions, practical deployments are often complicated by distributional uncertainty and the need to enforce structural constraints such as convexity. In this paper, we introduce a framework for distributionally robust optimal regularization, which identifies regularizers that remain effective under perturbations of the data distribution. Our approach leverages convex duality to reformulate the underlying distributionally robust optimization problem, eliminating the inner maximization and yielding formulations that are amenable to numerical computation. We show how the resulting robust regularizers interpolate between memorization of the training distribution and uniform priors, providing insights into their behavior as robustness parameters vary. For example, we show how certain ambiguity sets, such as those based on the Wasserstein-1 distance, naturally induce regularity in the optimal regularizer by promoting regularizers with smaller Lipschitz constants. We further investigate the setting where regularizers are required to be convex, formulating a convex program for their computation and illustrating their stability with respect to distributional shifts. Taken together, our results provide both theoretical and computational foundations for designing regularizers that are reliable under model uncertainty and structurally constrained for robust deployment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.03464v1</guid>
      <category>math.OC</category>
      <category>math.MG</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Oscar Leong, Eliza O'Reilly, Yong Sheng Soh</dc:creator>
    </item>
    <item>
      <title>A Sequential Quadratic Programming Perspective on Optimal Control</title>
      <link>https://arxiv.org/abs/2510.03475</link>
      <description>arXiv:2510.03475v1 Announce Type: new 
Abstract: This paper offers a unified perspective on different approaches to the solution of optimal control problems through the lens of constrained sequential quadratic programming. In particular, it allows us to find the relationships between Newton's method, the iterative LQR (iLQR), and Differential Dynamic Programming (DDP) approaches to solve the problem. It is shown that the iLQR is a principled SQP approach, rather than simply an approximation of DDP by neglecting the Hessian terms, to solve optimal control problems that can be guaranteed to always produce a cost-descent direction and converge to an optimum; while Newton's approach or DDP do not have similar guarantees, especially far from an optimum. Our empirical evaluations on the pendulum and cart-pole swing-up tasks serve to corroborate the SQP-based analysis proposed in this paper.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.03475v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator> Abhijeet, Suman Chakravorty</dc:creator>
    </item>
    <item>
      <title>CANOPI: Contingency-Aware Nodal Optimal Power Investments with High Temporal Resolution</title>
      <link>https://arxiv.org/abs/2510.03484</link>
      <description>arXiv:2510.03484v1 Announce Type: new 
Abstract: We present CANOPI, a novel algorithmic framework, for solving the Contingency-Aware Nodal Power Investments problem, a large-scale nonlinear optimization problem that jointly optimizes generation, storage, and transmission expansion. The underlying problem is nonlinear due to the impact of transmission upgrades on impedances, and the problem's large scale arises from the confluence of spatial and temporal resolutions. We propose algorithmic approaches to address these computational challenges. We pose a linear approximation of the overall nonlinear model, and develop a fixed-point algorithm to adjust for the nonlinear impedance feedback effect. We solve the large-scale linear expansion model with a specialized level-bundle method leveraging a novel interleaved approach to contingency constraint generation. We introduce a minimal cycle basis algorithm that improves the numerical sparsity of cycle-based DC power flow formulations, accelerating solve times for the operational subproblems. CANOPI is demonstrated on a 1493-bus Western Interconnection test system built from realistic-geography network data, with hourly operations spanning 52 week-long scenarios and a total possible set of 20 billion individual transmission contingency constraints. Numerical results quantify the reliability and economic benefits of fully incorporating transmission contingencies in integrated planning models and highlight the computational advantages of the proposed methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.03484v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas Lee, Andy Sun</dc:creator>
    </item>
    <item>
      <title>Composite Optimization with Error Feedback: the Dual Averaging Approach</title>
      <link>https://arxiv.org/abs/2510.03507</link>
      <description>arXiv:2510.03507v1 Announce Type: new 
Abstract: Communication efficiency is a central challenge in distributed machine learning training, and message compression is a widely used solution. However, standard Error Feedback (EF) methods (Seide et al., 2014), though effective for smooth unconstrained optimization with compression (Karimireddy et al., 2019), fail in the broader and practically important setting of composite optimization, which captures, e.g., objectives consisting of a smooth loss combined with a non-smooth regularizer or constraints. The theoretical foundation and behavior of EF in the context of the general composite setting remain largely unexplored. In this work, we consider composite optimization with EF. We point out that the basic EF mechanism and its analysis no longer stand when a composite part is involved. We argue that this is because of a fundamental limitation in the method and its analysis technique. We propose a novel method that combines Dual Averaging with EControl (Gao et al., 2024), a state-of-the-art variant of the EF mechanism, and achieves for the first time a strong convergence analysis for composite optimization with error feedback. Along with our new algorithm, we also provide a new and novel analysis template for inexact dual averaging method, which might be of independent interest. We also provide experimental results to complement our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.03507v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuan Gao, Anton Rodomanov, Jeremy Rack, Sebastian Stich</dc:creator>
    </item>
    <item>
      <title>Agile Tradespace Exploration for Space Rendezvous Mission Design via Transformers</title>
      <link>https://arxiv.org/abs/2510.03544</link>
      <description>arXiv:2510.03544v1 Announce Type: new 
Abstract: Spacecraft rendezvous enables on-orbit servicing, debris removal, and crewed docking, forming the foundation for a scalable space economy. Designing such missions requires rapid exploration of the tradespace between control cost and flight time across multiple candidate targets. However, multi-objective optimization in this setting is challenging, as the underlying constraints are often highly nonconvex, and mission designers must balance accuracy (e.g., solving the full problem) with efficiency (e.g., convex relaxations), slowing iteration and limiting design agility. To address these challenges, this paper proposes an AI-powered framework that enables agile mission design for a wide range of Earth orbit rendezvous scenarios. Given the orbital information of the target spacecraft, boundary conditions, and a range of flight times, this work proposes a Transformer-based architecture that generates, in a single parallelized inference step, a set of near-Pareto optimal trajectories across varying flight times, thereby enabling rapid mission trade studies. The model is further extended to accommodate variable flight times and perturbed orbital dynamics, supporting realistic multi-objective trade-offs. Validation on chance-constrained rendezvous problems with passive safety constraints demonstrates that the model generalizes across both flight times and dynamics, consistently providing high-quality initial guesses that converge to superior solutions in fewer iterations. Moreover, the framework efficiently approximates the Pareto front, achieving runtimes comparable to convex relaxation by exploiting parallelized inference. Together, these results position the proposed framework as a practical surrogate for nonconvex trajectory generation and mark an important step toward AI-driven trajectory design for accelerating preliminary mission planning in real-world rendezvous applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.03544v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.RO</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuji Takubo, Daniele Gammelli, Marco Pavone, Simone D'Amico</dc:creator>
    </item>
    <item>
      <title>On damping neutral-type control system on a temporal star graph with global time-proportional delay</title>
      <link>https://arxiv.org/abs/2510.03579</link>
      <description>arXiv:2510.03579v1 Announce Type: new 
Abstract: We consider, on a temporal star graph, the problem of optimal damping a control system is considered for a generalized pantograph equation, which is a neutral-type equation with a time-proportional delay. The delay in the system propagates through the internal vertex of the graph. We study the variational problem of minimizing the energy functional, taking into account the probabilities the of scenarios corresponding to different edges. It is established that the optimal trajectory satisfies Kirchhoff-type conditions at the internal vertex. The equivalence of the variational problem to a certain boundary value problem for second-order functional-differential equations on the graph is proved, and the unique solvability of both problems is established.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.03579v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexsandr Lednov</dc:creator>
    </item>
    <item>
      <title>Optimal Zeroth-Order Bilevel Optimization</title>
      <link>https://arxiv.org/abs/2510.03646</link>
      <description>arXiv:2510.03646v1 Announce Type: new 
Abstract: In this paper, we develop zeroth-order algorithms with provably (nearly) optimal sample complexity for stochastic bilevel optimization, where only noisy function evaluations are available. We propose two distinct algorithms: the first is inspired by Jacobian/Hessian-based approaches, and the second builds on using a penalty function reformulation. The Jacobian/Hessian-based method achieves a sample complexity of $\mathcal{O}(d^3/\epsilon^2)$, which is optimal in terms of accuracy $\epsilon$, albeit with polynomial dependence on the problem dimension $d$. In contrast, the penalty-based method sharpens this guarantee to $\mathcal{O}(d/\epsilon^2)$, optimally reducing the dimension dependence to linear while preserving optimal accuracy scaling. Our analysis is built upon Gaussian smoothing techniques, and we rigorously establish their validity under the stochastic bilevel settings considered in the existing literature. To the best of our knowledge, this is the first work to provide provably optimal sample complexity guarantees for a zeroth-order stochastic approximation method in bilevel optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.03646v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alireza Aghasi, Jeongyeol Kwon, Saeed Ghadimi</dc:creator>
    </item>
    <item>
      <title>Achieving Universal Approximation and Universal Interpolation via Nonlinearity of Control Families</title>
      <link>https://arxiv.org/abs/2510.03676</link>
      <description>arXiv:2510.03676v1 Announce Type: new 
Abstract: A significant connection exists between the controllability of dynamical systems and the approximation capabilities of neural networks, where residual networks and vanilla feedforward neural networks can both be regarded as numerical discretizations of the flow maps of dynamical systems. Leveraging the expressive power of neural networks, prior works have explored various control families $\mathcal{F}$ that enable the flow maps of dynamical systems to achieve either the universal approximation property (UAP) or the universal interpolation property (UIP). For example, the control family $\mathcal{F}_\text{ass}({\mathrm{ReLU}})$, consisting of affine maps together with a specific nonlinear function ReLU, achieves UAP; while the affine-invariant nonlinear control family $\mathcal{F}_{\mathrm{aff}}(f)$ containing a nonlinear function $f$ achieves UIP. However, UAP and UIP are generally not equivalent, and thus typically need to be studied separately with different techniques. In this paper, we investigate more general control families, including $\mathcal{F}_\text{ass}(f)$ with nonlinear functions $f$ beyond ReLU, the diagonal affine-invariant family $\mathcal{F}_{\mathrm{diag}}(f)$, and UAP for orientation-preserving diffeomorphisms under the uniform norm. We show that in certain special cases, UAP and UIP are indeed equivalent, whereas in the general case, we introduce the notion of local UIP (a substantially weaker version of UIP) and prove that the combination of UAP and local UIP implies UIP. In particular, the control family $\mathcal{F}_\text{ass}({\mathrm{ReLU}})$ achieves the UIP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.03676v1</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yongqiang Cai, Yifei Duan</dc:creator>
    </item>
    <item>
      <title>Learning Polynomial Activation Functions for Deep Neural Networks</title>
      <link>https://arxiv.org/abs/2510.03682</link>
      <description>arXiv:2510.03682v1 Announce Type: new 
Abstract: Activation functions are crucial for deep neural networks. This novel work frames the problem of training neural network with learnable polynomial activation functions as a polynomial optimization problem, which is solvable by the Moment-SOS hierarchy. This work represents a fundamental departure from the conventional paradigm of training deep neural networks, which relies on local optimization methods like backpropagation and gradient descent. Numerical experiments are presented to demonstrate the accuracy and robustness of optimum parameter recovery in presence of noises.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.03682v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Linghao Zhang, Jiawang Nie, Tingting Tang</dc:creator>
    </item>
    <item>
      <title>Well-Posedness and Efficient Algorithms for Inverse Optimal Transport with Bregman Regularization</title>
      <link>https://arxiv.org/abs/2510.03803</link>
      <description>arXiv:2510.03803v1 Announce Type: new 
Abstract: This work analyzes the inverse optimal transport (IOT) problem under Bregman regularization. We establish well-posedness results, including existence, uniqueness (up to equivalence classes of solutions), and stability, under several structural assumptions on the cost matrix. On the computational side, we investigate the existence of solutions to the optimization problem with general constraints on the cost matrix and provide a sufficient condition guaranteeing existence. In addition, we propose an inexact block coordinate descent (BCD) method for the problem with a strongly convex penalty term. In particular, when the penalty is quadratic, the subproblems admit a diagonal Hessian structure, which enables highly efficient element-wise Newton updates. We establish a linear convergence rate for the algorithm and demonstrate its practical performance through numerical experiments, including the validation of stability bounds, the investigation of regularization effects, and the application to a marriage matching dataset.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.03803v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chenglong Bao, Zanyu Li, Yunan Yang</dc:creator>
    </item>
    <item>
      <title>A Frank-Wolfe Algorithm for Strongly Monotone Variational Inequalities</title>
      <link>https://arxiv.org/abs/2510.03842</link>
      <description>arXiv:2510.03842v1 Announce Type: new 
Abstract: We propose an accelerated algorithm with a Frank-Wolfe method as an oracle for solving strongly monotone variational inequality problems. While standard solution approaches, such as projected gradient descent (aka value iteration), involve projecting onto the desired set at each iteration, a distinctive feature of our proposed method is the use of a linear minimization oracle in each iteration. This difference potentially reduces the projection cost, a factor that can become significant for certain sets or in high-dimensional problems. We validate the performance of the proposed algorithm on the traffic assignment problem, motivated by the fact that the projection complexity per iteration increases exponentially with respect to the number of links.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.03842v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Reza Rahimi Baghbadorani, Peyman Mohajerin Esfahani, Sergio Grammatico</dc:creator>
    </item>
    <item>
      <title>Optimization Outperforms Unscented Techniques for Nonlinear Smoothing</title>
      <link>https://arxiv.org/abs/2510.03846</link>
      <description>arXiv:2510.03846v1 Announce Type: new 
Abstract: We review optimization-based approaches to smoothing nonlinear dynamical systems. These approaches leverage the fact that the Extended Kalman Filter and corresponding smoother can be framed as the Gauss-Newton method for a nonlinear least squares maximum a posteriori loss, and stabilized with standard globalization techniques. We compare the performance of the Optimized Kalman Smoother (OKS) to Unscented Kalman smoothing techniques, and show that they achieve significant improvement for highly nonlinear systems, particularly in noisy settings. The comparison is performed across standard parameter choices (such as the trade-off between process and measurement terms). To our knowledge, this is the first comparison of these methods in the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.03846v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Payton Howell, Aleksandr Aravkin</dc:creator>
    </item>
    <item>
      <title>Calm local optimality for couple-constrained minimax problems</title>
      <link>https://arxiv.org/abs/2510.03861</link>
      <description>arXiv:2510.03861v1 Announce Type: new 
Abstract: Recently, a new local optimality concept for minimax problems, termed calm local minimax points, has been introduced. In this paper, we extend this concept to a general class of nonsmooth, nonconvex nonconcave minimax problems with coupled constraints, where the inner feasible set depends on the outer variable. We derive comprehensive first-order and second-order necessary and sufficient optimality conditions for calm local minimax points in the setting of nonsmooth, nonconvex nonconcave minimax problems with coupled constraints. Furthermore, we show how these conditions apply to problems with set constraints, as well as those involving systems of inequalities and equalities. By unifying existing formulations that often rely on stronger assumptions within the framework of calm local minimax points, we show that our results hold under weaker assumptions than those previously required.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.03861v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaoxiao Ma, Jane Ye</dc:creator>
    </item>
    <item>
      <title>Convex Pollution Control of Wastewater Treatment Systems</title>
      <link>https://arxiv.org/abs/2510.03918</link>
      <description>arXiv:2510.03918v1 Announce Type: new 
Abstract: We design a model-predictive controller for managing the actuators in sewer networks. It minimizes flooding and combined-sewer overflow during rain and pollution at other times. To make the problem tractable, we use a convex relaxation of the microbial growth kinetics and a physically motivated linearization of the mass flow bilinearities. With these approximations, the trajectory optimization in each control period is a second-order cone program. In simulation, the controller releases roughly 15% less pollutant mass than a conventional controller while treating nearly the same volume of flow. It does so by better balancing the flow over the treatment plants and over time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.03918v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joshua Taylor</dc:creator>
    </item>
    <item>
      <title>Modeling and Optimization of Control Problems on GPUs</title>
      <link>https://arxiv.org/abs/2510.03932</link>
      <description>arXiv:2510.03932v2 Announce Type: new 
Abstract: We present a fully Julia-based, GPU-accelerated workflow for solving large-scale sparse nonlinear optimal control problems. Continuous-time dynamics are modeled and then discretized via direct transcription with \texttt{OptimalControl.jl} into structured sparse nonlinear programs. These programs are compiled into GPU kernels using \texttt{ExaModels.jl}, leveraging SIMD parallelism for fast evaluation of objectives, constraints, gradients, Jacobians and Hessians. The resulting sparse problems are solved entirely on GPU using the interior-point solver \texttt{MadNLP.jl} and the GPU sparse linear solver cuDSS, yielding significant speed-ups over CPU-based approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.03932v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexis Montoison, Jean-Baptiste Caillau</dc:creator>
    </item>
    <item>
      <title>On vehicle routing problems with stochastic demands -- Part I: Generic integer L-shaped formulations</title>
      <link>https://arxiv.org/abs/2510.04043</link>
      <description>arXiv:2510.04043v1 Announce Type: new 
Abstract: We study a broad class of vehicle routing problems in which the cost of a route is allowed to be any nonnegative rational value computable in polynomial time in the input size. To address this class, we introduce a unifying framework that generalizes existing integer L-shaped (ILS) formulations developed for vehicle routing problems with stochastic demands (VRPSDs). This framework and subsequent analysis allow us to generalize previous ILS cuts and pinpoint which assumptions are needed to apply those generalizations to other problems. Using these tools, we develop the first algorithm for the VRPSD in the case where the demands are given by an empirical probability distribution of scenarios - a data-driven variant that tackles a significant challenge identified in the literature: dealing with correlations. Indeed, all previous ILS-based exact algorithms for the VRPSD assume either independence of customer demands or correlations through a single external factor. This shows the potential of this generic unifying framework to be applied to a multitude of different variants of the problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.04043v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matheus J. Ota, Ricardo Fukasawa</dc:creator>
    </item>
    <item>
      <title>Inverse Continuous-Time Linear Quadratic Regulator: From Control Cost Matrix to Entire Cost Reconstruction</title>
      <link>https://arxiv.org/abs/2510.04083</link>
      <description>arXiv:2510.04083v1 Announce Type: new 
Abstract: This paper studies the inverse optimal control problem for continuous-time linear quadratic regulators over finite-time horizon, aiming to reconstruct the control, state, and terminal cost matrices in the objective function from observed optimal inputs. Previous studies have mainly explored the recovery of state cost matrices under the assumptions that the system is controllable and the control cost matrix is given. Motivated by various applications in which the control cost matrix is unknown and needs to be identified, we present two reconstruction methods. The first exploits the full trajectory of the feedback matrix and establishes the necessary and sufficient condition for unique recovery. To further reduce the computational complexity, the second method utilizes the feedback matrix at some time points, where sufficient conditions for uniqueness are provided. Moreover, we study the recovery of the state and terminal cost matrices in a more general manner. Unlike prior works that assume controllability, we analyse its impact on well-posedness, and derive analytical expressions for unknown matrices for both controllable and uncontrollable cases. Finally, we characterize the structural relation between the inverse problems with the control cost matrix either to be reconstructed or given as a prior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.04083v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuexin Cao, Yibei Li, Zhuo Zou, Xiaoming Hu</dc:creator>
    </item>
    <item>
      <title>DADS Under Unknown Input Coefficients</title>
      <link>https://arxiv.org/abs/2510.04117</link>
      <description>arXiv:2510.04117v1 Announce Type: new 
Abstract: This short note shows that the Deadzone-Adapted Disturbance Suppression (DADS) adaptive control scheme is applicable to systems with unknown input coefficients. We study time-invariant, control-affine systems that satisfy the matching condition for which no bounds for the disturbance and the unknown parameters are known. The input coefficients can be time-varying as well as the unknown parameters. The only thing assumed for the input coefficients is their sign. The adaptive control design is Lyapunov-based and can be accomplished for every system for which a smooth globally stabilizing feedback exists when the disturbances are absent and all unknown parameters are known. The design is given by simple, explicit formulas. The proposed controllers guarantee an attenuation of the plant state to an assignable small level, despite unknown bounds on the parameters and disturbance, without a drift of the gain, state, and input.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.04117v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Iasson Karafyllis, Miroslav Krstic</dc:creator>
    </item>
    <item>
      <title>Convex Formulation of the Zero Emission Vessel Route Planning Problem</title>
      <link>https://arxiv.org/abs/2510.04313</link>
      <description>arXiv:2510.04313v1 Announce Type: new 
Abstract: This paper focuses on the zero emission vessel route planning problem, which deals with cost-effective planning of battery-electric vessel services for predetermined routes. Vessel characteristics (including battery capacity), fleet size, cyclic schedule frequencies, sailing leg speeds, and shore charging infrastructure are jointly optimized. The problem is nonlinear and nonconvex in its original form, which makes it intractable for most real-world instances. The conventional approach in the literature is to solve a linear approximation by restricting vessel designs and sailing leg speeds to a small finite set. Contrary to the conventional linearization approach, this paper deals with the nonlinearities directly. We show that the problem exhibits a hidden convex structure uncovered by nonlinear changes of variables. By exploiting the favorable convex form of the transformed problem, we solve it in a few seconds using a free off-the-shelf solver that requires no initial guesses, variable bounds, or parameter tuning. We then easily recover the exact solution to the original nonconvex problem by reversing the variable changes. We provide an open-source implementation of our method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.04313v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Antti Ritari, Jani Romanoff, Kari Tammi</dc:creator>
    </item>
    <item>
      <title>Quantizer Design for Finite Model Approximations, Model Learning, and Quantized Q-Learning for MDPs with Unbounded Spaces</title>
      <link>https://arxiv.org/abs/2510.04355</link>
      <description>arXiv:2510.04355v1 Announce Type: new 
Abstract: In this paper, for Markov decision processes (MDPs) with unbounded state spaces we present refined upper bounds presented in [Kara et. al. JMLR'23] on finite model approximation errors via optimizing the quantizers used for finite model approximations. We also consider implications on quantizer design for quantized Q-learning and empirical model learning, and the performance of policies obtained via Q-learning where the quantized state is treated as the state itself. We highlight the distinctions between planning, where approximating MDPs can be independently designed, and learning (either via Q-learning or empirical model learning), where approximating MDPs are restricted to be defined by invariant measures of Markov chains under exploration policies, leading to significant subtleties on quantizer design performance, even though asymptotic near optimality can be established under both setups. In particular, under Lyapunov growth conditions, we obtain explicit upper bounds which decay to zero as the number of bins approaches infinity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.04355v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Osman Bicer, Ali D. Kara, Serdar Yuksel</dc:creator>
    </item>
    <item>
      <title>Geometry of Distance Protection</title>
      <link>https://arxiv.org/abs/2510.04379</link>
      <description>arXiv:2510.04379v1 Announce Type: new 
Abstract: Distance relays detect faults on transmission lines. They face uncertainty from the fault's location and resistance, as well as the current from the line's remote terminal. In this paper, we aggregate this uncertainty with the Minkowski sum. This allows us to explicitly model the power grid surrounding the relay's line, and in turn accommodate any mix of synchronous machines and inverter-based resources. To make the relay's task easier, inverters can inject perturbations, or auxiliary signals, such as negative-sequence current. We use Farkas' lemma to construct an optimization for designing inverter auxiliary signals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.04379v1</guid>
      <category>math.OC</category>
      <category>cs.IT</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.IT</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Josh A. Taylor, Alejandro D. Dom\'inguez-Garc\'ia</dc:creator>
    </item>
    <item>
      <title>Zeroth-Order Methods for Stochastic Nonconvex Nonsmooth Composite Optimization</title>
      <link>https://arxiv.org/abs/2510.04446</link>
      <description>arXiv:2510.04446v1 Announce Type: new 
Abstract: This work aims to solve a stochastic nonconvex nonsmooth composite optimization problem. Previous works on composite optimization problem requires the major part to satisfy Lipschitz smoothness or some relaxed smoothness conditions, which excludes some machine learning examples such as regularized ReLU network and sparse support matrix machine. In this work, we focus on stochastic nonconvex composite optimization problem without any smoothness assumptions. In particular, we propose two new notions of approximate stationary points for such optimization problem and obtain finite-time convergence results of two zeroth-order algorithms to these two approximate stationary points respectively. Finally, we demonstrate that these algorithms are effective using numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.04446v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ziyi Chen, Peiran Yu, Heng Huang</dc:creator>
    </item>
    <item>
      <title>Inverse Mixed-Integer Programming: Learning Constraints then Objective Functions</title>
      <link>https://arxiv.org/abs/2510.04455</link>
      <description>arXiv:2510.04455v1 Announce Type: new 
Abstract: In mixed-integer linear programming, data-driven inverse optimization that learns the objective function and the constraints from observed data plays an important role in constructing appropriate mathematical models for various fields, including power systems and scheduling. However, to the best of our knowledge, there is no known method for learning both the objective functions and the constraints. In this paper, we propose a two-stage method for a class of problems where the objective function is expressed as a linear combination of functions and the constraints are represented by functions and thresholds. Specifically, our method first learns the constraints and then learns the objective function. On the theoretical side, we show the proposed method can solve inverse optimization problems in finite dataset, develop statistical learning theory in pseudometric spaces and sub-Gaussian distributions, and construct a statistical learning for inverse optimization. On the experimental side, we demonstrate that our method is practically applicable for scheduling problems formulated as integer linear programmings with up to 100 decision variables, which are typical in real-world settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.04455v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Akira Kitaoka</dc:creator>
    </item>
    <item>
      <title>A Time-certified Predictor-corrector IPM Algorithm for Box-QP</title>
      <link>https://arxiv.org/abs/2510.04467</link>
      <description>arXiv:2510.04467v1 Announce Type: new 
Abstract: Minimizing both the worst-case and average execution times of optimization algorithms is equally critical in real-time optimization-based control applications such as model predictive control (MPC). Most MPC solvers have to trade off between certified worst-case and practical average execution times. For example, our previous work [1] proposed a full-Newton path-following interior-point method (IPM) with data-independent, simple-calculated, and exact $O(\sqrt{n})$ iteration complexity, but not as efficient as the heuristic Mehrotra predictor-corrector IPM algorithm (which sacrifices global convergence). This letter proposes a new predictor-corrector IPM algorithm that preserves the same certified $O(\sqrt{n})$ iteration complexity while achieving a $5\times$ speedup over [1]. Numerical experiments and codes that validate these results are provided.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.04467v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liang Wu, Yunhong Che, Richard D. Braatz, Jan Drgona</dc:creator>
    </item>
    <item>
      <title>Introduction to Interpolation-Based Optimization</title>
      <link>https://arxiv.org/abs/2510.04473</link>
      <description>arXiv:2510.04473v1 Announce Type: new 
Abstract: The field of derivative-free optimization (DFO) studies algorithms for nonlinear optimization that do not rely on the availability of gradient or Hessian information. It is primarily designed for settings when functions are black-box, expensive to evaluate and/or noisy. A widely used and studied class of DFO methods for local optimization is interpolation-based optimization (IBO), also called model-based DFO, where the general principles from derivative-based nonlinear optimization algorithms are followed, but local Taylor-type approximations are replaced with alternative local models constructed by interpolation. This document provides an overview of the basic algorithms and analysis for IBO, covering worst-case complexity, approximation theory for polynomial interpolation models, and extensions to constrained and noisy problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.04473v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Lindon Roberts</dc:creator>
    </item>
    <item>
      <title>Overlapping Schwarz Scheme for Linear-Quadratic Programs in Continuous Time</title>
      <link>https://arxiv.org/abs/2510.04478</link>
      <description>arXiv:2510.04478v1 Announce Type: new 
Abstract: We present an optimize-then-discretize framework for solving linear-quadratic optimal control problems (OCP) governed by time-inhomogeneous ordinary differential equations (ODEs). Our method employs a modified overlapping Schwarz decomposition based on the Pontryagin Minimum Principle, partitioning the temporal domain into overlapping intervals and independently solving Hamiltonian systems in continuous time. We demonstrate that the convergence is ensured by appropriately updating the boundary conditions of the individual Hamiltonian dynamics. The cornerstone of our analysis is to prove that the exponential decay of sensitivity (EDS) exhibited in discrete-time OCPs carries over to the continuous-time setting. Unlike the discretize-then-optimize approach, our method can flexibly incorporate different numerical integration methods for solving the resulting Hamiltonian two-point boundary-value subproblems, including adaptive-time integrators. A numerical experiment on a linear-quadratic OCP illustrates the practicality of our approach in broad scientific applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.04478v1</guid>
      <category>math.OC</category>
      <category>cs.CE</category>
      <category>cs.DC</category>
      <category>cs.NA</category>
      <category>math.DS</category>
      <category>math.NA</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hongli Zhao, Mihai Anitescu, Sen Na</dc:creator>
    </item>
    <item>
      <title>Range of optimal values in absolute value linear programming with interval data</title>
      <link>https://arxiv.org/abs/2510.04604</link>
      <description>arXiv:2510.04604v1 Announce Type: new 
Abstract: Absolute value linear programming problems is quite a new area of optimization problems, involving linear functions and absolute values in the description of the model. In this paper, we consider interval uncertainty of the input coefficients. Our goal is to determine the best and the worst case optimal values. For the former, we derive an explicit formula, reducing the problem to a certain optimization problem. However, the latter is more complicated, and we propose a lower and upper bound approaches to estimate the value. We also investigate the basis stability, in which situation the best case optimal value is efficiently computable. The worst case optimal value then also admits a simple characterization; however, the computational complexity remains open.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.04604v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Milan Hlad\'ik</dc:creator>
    </item>
    <item>
      <title>On decomposability and subdifferential of the tensor nuclear norm</title>
      <link>https://arxiv.org/abs/2510.04647</link>
      <description>arXiv:2510.04647v1 Announce Type: new 
Abstract: We study the decomposability and the subdifferential of the tensor nuclear norm. Both concepts are well understood and widely applied in matrices but remain unclear for higher-order tensors. We show that the tensor nuclear norm admits a full decomposability over specific subspaces and determine the largest possible subspaces that allow the full decomposability. We derive novel inclusions of the subdifferential of the tensor nuclear norm and study its subgradients in a variety of subspaces of interest. All the results hold for tensors of an arbitrary order. As an immediate application, we establish the statistical performance of the tensor robust principal component analysis, the first such result for tensors of an arbitrary order.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.04647v1</guid>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiewen Guan, Bo Jiang, Zhening Li</dc:creator>
    </item>
    <item>
      <title>Rapid stabilization for a wave equation with boundary disturbance</title>
      <link>https://arxiv.org/abs/2510.04893</link>
      <description>arXiv:2510.04893v1 Announce Type: new 
Abstract: In this paper, we study the rapid stabilization of an unstable wave equation, in which an unknown disturbance is located at the boundary condition. We address two different boundary conditions: Dirichlet- Dirichlet and Dirichlet-Neumann. In both cases, we design a feedback law, located at the same place as the unknown disturbance, that forces the exponential decay of the energy for any desired decay rate while suppressing the effects of the unknown disturbance. For the feedback design, we employ the backstepping method, Lyapunov techniques and the sign multivalued operator. The well-posedness of the closed-loop system, which is a differential inclusion, is shown with the maximal monotone operator theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.04893v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.AP</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Patricio Guzm\'an, Agust\'in Huerta, Hugo Parada</dc:creator>
    </item>
    <item>
      <title>A Backstepping-KKL observer for a cascade of a nonlinear ODE with a heat equation</title>
      <link>https://arxiv.org/abs/2510.04941</link>
      <description>arXiv:2510.04941v1 Announce Type: new 
Abstract: We propose an observer design for a cascaded system composed of an arbitrary nonlinear ordinary differential equation (ODE) with a 1D heat equation. The nonlinear output of the ODE imposes a boundary condition on one side of the heat equation, while the measured output is on the other side. The observer design combines an infinitedimensional Kazantzis-Kravaris/Luenberger (KKL) observer for the ODE with a backstepping observer for the heat equation. This construction is the first extension of the KKL methodology to infinite-dimensional systems. We establish the convergence of the observer under a differential observability condition on the ODE. The effectiveness of the proposed approach is illustrated in numerical simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.04941v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Adam Braun (L2S), Lucas Brivadis (L2S), Jean Auriol (L2S)</dc:creator>
    </item>
    <item>
      <title>Optimal participation of energy communities in electricity markets under uncertainty. A multi-stage stochastic programming approach</title>
      <link>https://arxiv.org/abs/2510.04965</link>
      <description>arXiv:2510.04965v1 Announce Type: new 
Abstract: We propose a multi-stage stochastic programming model for the optimal participation of energy communities in electricity markets. The multi-stage aspect captures the different times at which variable renewable generation and electricity prices are observed. This results in large-scale optimization problem instances containing large scenario trees with 34 stages, to which scenario reduction techniques are applied. Case studies with real data are discussed to analyse proposed regulatory frameworks in Europe. The added value of considering stochasticity is also analysed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.04965v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Albert Sol\`a Vilalta, Ignasi Ma\~n\'e, F. - Javier Heredia</dc:creator>
    </item>
    <item>
      <title>A Unified Optimization Framework for Multiclass Classification with Structured Hyperplane Arrangements</title>
      <link>https://arxiv.org/abs/2510.05047</link>
      <description>arXiv:2510.05047v1 Announce Type: new 
Abstract: In this paper, we propose a new mathematical optimization model for multiclass classification based on arrangements of hyperplanes. Our approach preserves the core support vector machine (SVM) paradigm of maximizing class separation while minimizing misclassification errors, and it is computationally more efficient than a previous formulation. We present a kernel-based extension that allows it to construct nonlinear decision boundaries. Furthermore, we show how the framework can naturally incorporate alternative geometric structures, including classification trees, $\ell_p$-SVMs, and models with discrete feature selection. To address large-scale instances, we develop a dynamic clustering matheuristic that leverages the proposed MIP formulation. Extensive computational experiments demonstrate the efficiency of the proposed model and dynamic clustering heuristic, and we report competitive classification performance on both synthetic datasets and real-world benchmarks from the UCI Machine Learning Repository, comparing our method with state-of-the-art implementations available in scikit-learn.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05047v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>V\'ictor Blanco, Harshit Kothari, James Luedtke</dc:creator>
    </item>
    <item>
      <title>On Improvement of Control Chart using Repetitive Sampling for Monitoring Process Mean</title>
      <link>https://arxiv.org/abs/2510.05086</link>
      <description>arXiv:2510.05086v1 Announce Type: new 
Abstract: In the practical industry, the most commonly used application of statistical analysis for monitoring the process mean is the control chart. Control charts are generated based on the presumption that we have a sample from a stable process. The control chart then provides a graphical display to test this presumption. In the existing estimator \textcolor{red}{$Mr$}, researchers use a technique involving repetitive sampling along with an auxiliary variable for detecting and monitoring the statistical process mean. The existing control chart, namely \textcolor{red}{$Mr$}, is based on the regression estimator of the mean using a single auxiliary variable $X$. We propose the \textcolor{red}{$Mrep$} chart using a ratio-product exponential type estimator, and the \textcolor{red}{$Mrwp$} chart with a more efficient difference-cum-exponential type estimator used in quality control for improving the process mean in terms of $ARL$. Then we compare the proposed charts \textcolor{red}{$Mrep$} and \textcolor{red}{$Mrwp$} with the existing \textcolor{red}{$Mr$} chart in terms of $ARL$. Using $ARL$ as a performance measure, better results of the proposed charts are observed for detecting shifts in the mean level of the characteristic of interest. Moreover, Monte Carlo simulation in terms of repetitive sampling is used for quality control charting and statistical process control for the betterment of the process mean.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05086v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fahad Rafique, Saadia Masood, Shabbir Ahmad, Sadaf Amin</dc:creator>
    </item>
    <item>
      <title>The Optimal Strategy for Playing Lucky 13</title>
      <link>https://arxiv.org/abs/2510.03234</link>
      <description>arXiv:2510.03234v1 Announce Type: cross 
Abstract: The game show Lucky 13 differs from other television game shows in that contestants are required to place a bet on their own knowledge of trivia by selecting a range that contains the number of questions that they answered correctly. We present a model for this game show using binomial random variables and generate tables outlining the optimal range the player should select based on maximization of two different utility functions. After analyzing the decisions made by some actual contestants on this show, we present a numerical simulation for how many questions an average player is expected to answer correctly based on question categories observed for two sample contestants.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.03234v1</guid>
      <category>math.HO</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Steven Berger, Daniel Conus</dc:creator>
    </item>
    <item>
      <title>Non-conservative optimal transport</title>
      <link>https://arxiv.org/abs/2510.03332</link>
      <description>arXiv:2510.03332v1 Announce Type: cross 
Abstract: Motivated by optimal re-balancing of a portfolio, we formalize an optimal transport problem in which the transported mass is scaled by a mass-change factor depending on the source and destination. This allows direct modeling of the creation or destruction of mass. We discuss applications and position the framework alongside unbalanced, entropic, and unnormalized optimal transport. The existence of optimal transport plans and strong duality are established. The existence of optimal maps are deduced in two central regimes, i.e., perturbative mass-change and quadratic mass-loss. For $\ell_p$ costs we derive the analogue of the Benamou-Brenier dynamic formulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.03332v1</guid>
      <category>q-fin.PM</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gabriela Kov\'a\v{c}ov\'a, Georg Menz, Niket Patel</dc:creator>
    </item>
    <item>
      <title>Physics-informed Neural-operator Predictive Control for Drag Reduction in Turbulent Flows</title>
      <link>https://arxiv.org/abs/2510.03360</link>
      <description>arXiv:2510.03360v1 Announce Type: cross 
Abstract: Assessing turbulence control effects for wall friction numerically is a significant challenge since it requires expensive simulations of turbulent fluid dynamics. We instead propose an efficient deep reinforcement learning (RL) framework for modeling and control of turbulent flows. It is model-based RL for predictive control (PC), where both the policy and the observer models for turbulence control are learned jointly using Physics Informed Neural Operators (PINO), which are discretization invariant and can capture fine scales in turbulent flows accurately. Our PINO-PC outperforms prior model-free reinforcement learning methods in various challenging scenarios where the flows are of high Reynolds numbers and unseen, i.e., not provided during model training. We find that PINO-PC achieves a drag reduction of 39.0\% under a bulk-velocity Reynolds number of 15,000, outperforming previous fluid control methods by more than 32\%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.03360v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>physics.flu-dyn</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zelin Zhao, Zongyi Li, Kimia Hassibi, Kamyar Azizzadenesheli, Junchi Yan, H. Jane Bae, Di Zhou, Anima Anandkumar</dc:creator>
    </item>
    <item>
      <title>Mechanisms for Quantum Advantage in Global Optimization of Nonconvex Functions</title>
      <link>https://arxiv.org/abs/2510.03385</link>
      <description>arXiv:2510.03385v1 Announce Type: cross 
Abstract: We present new theoretical mechanisms for quantum speedup in the global optimization of nonconvex functions, expanding the scope of quantum advantage beyond traditional tunneling-based explanations. As our main building-block, we demonstrate a rigorous correspondence between the spectral properties of Schr\"{o}dinger operators and the mixing times of classical Langevin diffusion. This correspondence motivates a mechanism for separation on functions with unique global minimum: while quantum algorithms operate on the original potential, classical diffusions correspond to a Schr\"{o}dinger operators with a WKB potential having nearly degenerate global minima. We formalize these ideas by proving that a real-space adiabatic quantum algorithm (RsAA) achieves provably polynomial-time optimization for broad families of nonconvex functions. First, for block-separable functions, we show that RsAA maintains polynomial runtime while known off-the-shelf algorithms require exponential time and structure-aware algorithms exhibit arbitrarily large polynomial runtimes. These results leverage novel non-asymptotic results in semiclassical analysis. Second, we use recent advances in the theory of intrinsic hypercontractivity to demonstrate polynomial runtimes for RsAA on appropriately perturbed strongly convex functions that lack global structure, while off-the-shelf algorithms remain exponentially bottlenecked. In contrast to prior works based on quantum tunneling, these separations do not depend on the geometry of barriers between local minima. Our theoretical claims about classical algorithm runtimes are supported by rigorous analysis and comprehensive numerical benchmarking. These findings establish a rigorous theoretical foundation for quantum advantage in continuous optimization and open new research directions connecting quantum algorithms, stochastic processes, and semiclassical analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.03385v1</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.OC</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dylan Herman, Guneykan Ozgul, Anuj Apte, Junhyung Lyle Kim, Anupam Prakash, Jiayu Shen, Shouvanik Chakrabarti</dc:creator>
    </item>
    <item>
      <title>Error estimates for deterministic empirical approximations of probability measures</title>
      <link>https://arxiv.org/abs/2510.03451</link>
      <description>arXiv:2510.03451v1 Announce Type: cross 
Abstract: The question of approximating an arbitrary probability measure in the Wasserstein distance by a discrete one with uniform weights is considered. Estimates are obtained for the rate of convergence as the number of points tends to infinity, depending on the moment parameter, the parameter in the Wasserstein distance, and the dimension. In certain low-dimensional regimes and for measures with unbounded support, the rates are improvements over those obtained through other methods, including through random sampling. Except for some critical cases, the rates are shown to be optimal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.03451v1</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Benjamin Seeger</dc:creator>
    </item>
    <item>
      <title>How to Set $\beta_1, \beta_2$ in Adam: An Online Learning Perspective</title>
      <link>https://arxiv.org/abs/2510.03478</link>
      <description>arXiv:2510.03478v1 Announce Type: cross 
Abstract: While Adam is one of the most effective optimizer for training large-scale machine learning models, a theoretical understanding of how to optimally set its momentum factors, $\beta_1$ and $\beta_2$, remains largely incomplete.
  Prior works have shown that Adam can be seen as an instance of Follow-the-Regularized-Leader (FTRL), one of the most important class of algorithms in online learning.
  The prior analyses in these works required setting $\beta_1 = \sqrt{\beta_2}$, which does not cover the more practical cases with $\beta_1 \neq \sqrt{\beta_2}$.
  We derive novel, more general analyses that hold for both $\beta_1 \geq \sqrt{\beta_2}$ and $\beta_1 \leq \sqrt{\beta_2}$.
  In both cases, our results strictly generalize the existing bounds.
  Furthermore, we show that our bounds are tight in the worst case.
  We also prove that setting $\beta_1 = \sqrt{\beta_2}$ is optimal for an oblivious adversary, but sub-optimal for an non-oblivious adversary.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.03478v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Quan Nguyen</dc:creator>
    </item>
    <item>
      <title>Machine Unlearning Meets Adversarial Robustness via Constrained Interventions on LLMs</title>
      <link>https://arxiv.org/abs/2510.03567</link>
      <description>arXiv:2510.03567v1 Announce Type: cross 
Abstract: With the increasing adoption of Large Language Models (LLMs), more customization is needed to ensure privacy-preserving and safe generation. We address this objective from two critical aspects: unlearning of sensitive information and robustness to jail-breaking attacks. We investigate various constrained optimization formulations that address both aspects in a \emph{unified manner}, by finding the smallest possible interventions on LLM weights that either make a given vocabulary set unreachable or embed the LLM with robustness to tailored attacks by shifting part of the weights to a \emph{safer} region. Beyond unifying two key properties, this approach contrasts with previous work in that it doesn't require an oracle classifier that is typically not available or represents a computational overhead. Surprisingly, we find that the simplest point-wise constraint-based intervention we propose leads to better performance than max-min interventions, while having a lower computational cost. Comparison against state-of-the-art defense methods demonstrates superior performance of the proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.03567v1</guid>
      <category>cs.LG</category>
      <category>cs.CL</category>
      <category>cs.CR</category>
      <category>cs.CY</category>
      <category>math.OC</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fatmazohra Rezkellah, Ramzi Dakhmouche</dc:creator>
    </item>
    <item>
      <title>Infinite-time Mean Field FBSDEs and Viscosity Solutions to Elliptic Master Equations</title>
      <link>https://arxiv.org/abs/2510.03707</link>
      <description>arXiv:2510.03707v1 Announce Type: cross 
Abstract: This paper presents a further investigation of the properties of infinite-time mean field FBSDEs and elliptic master equations, which were introduced in \cite{yang2025discounted} as mathematical tools for solving discounted infinite-time mean field games. By establishing the continuous dependence of the FBSDE solutions on their initial values, we prove the flow property of the mean field FBSDEs. Furthermore, we prove that, at the Nash equilibrium, the value function of the representative player constitutes a viscosity solution to the corresponding elliptic master equation. Our work extends the classical theory of finite-time mean field games and parabolic master equations to the infinite-time setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.03707v1</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zeyu Yang, Yongsheng Song</dc:creator>
    </item>
    <item>
      <title>Rapid boundary stabilization of 1D nonlinear parabolic equations</title>
      <link>https://arxiv.org/abs/2510.03740</link>
      <description>arXiv:2510.03740v1 Announce Type: cross 
Abstract: In this paper, we focus on the rapid boundary stabilization of 1D nonlinear parabolic equations via the modal decomposition method. The nonlinear term is assumed to satisfy certain local Lipschitz continuity and global growth conditions. Through the modal decomposition, we construct a feedback control that modifies only the unstable eigenvalues to achieve spectral reduction. Under this control, we establish locally rapid stabilization by estimating the nonlinearity in Lyapunov stability analysis. Furthermore, utilizing the dissipative property, we derive a globally rapid stabilization result for dissipative systems such as the Burgers equation and the Allen-Cahn equation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.03740v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yu Xiao, Can Zhang</dc:creator>
    </item>
    <item>
      <title>BONSAI: Structure-exploiting robust Bayesian optimization for networked black-box systems under uncertainty</title>
      <link>https://arxiv.org/abs/2510.03893</link>
      <description>arXiv:2510.03893v1 Announce Type: cross 
Abstract: Optimal design under uncertainty remains a fundamental challenge in advancing reliable, next-generation process systems. Robust optimization (RO) offers a principled approach by safeguarding against worst-case scenarios across a range of uncertain parameters. However, traditional RO methods typically require known problem structure, which limits their applicability to high-fidelity simulation environments. To overcome these limitations, recent work has explored robust Bayesian optimization (RBO) as a flexible alternative that can accommodate expensive, black-box objectives. Existing RBO methods, however, generally ignore available structural information and struggle to scale to high-dimensional settings. In this work, we introduce BONSAI (Bayesian Optimization of Network Systems under uncertAInty), a new RBO framework that leverages partial structural knowledge commonly available in simulation-based models. Instead of treating the objective as a monolithic black box, BONSAI represents it as a directed graph of interconnected white- and black-box components, allowing the algorithm to utilize intermediate information within the optimization process. We further propose a scalable Thompson sampling-based acquisition function tailored to the structured RO setting, which can be efficiently optimized using gradient-based methods. We evaluate BONSAI across a diverse set of synthetic and real-world case studies, including applications in process systems engineering. Compared to existing simulation-based RO algorithms, BONSAI consistently delivers more sample-efficient and higher-quality robust solutions, highlighting its practical advantages for uncertainty-aware design in complex engineering systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.03893v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.compchemeng.2025.109393</arxiv:DOI>
      <dc:creator>Akshay Kudva, Joel A. Paulson</dc:creator>
    </item>
    <item>
      <title>PolyKAN: A Polyhedral Analysis Framework for Provable and Minimal KAN Compression</title>
      <link>https://arxiv.org/abs/2510.04205</link>
      <description>arXiv:2510.04205v1 Announce Type: cross 
Abstract: Kolmogorov-Arnold Networks (KANs) have emerged as a promising alternative to traditional Multi-Layer Perceptrons (MLPs), offering enhanced interpretability and a strong mathematical foundation. However, their parameter efficiency remains a significant challenge for practical deployment. This paper introduces PolyKAN, a novel theoretical framework for KAN compression that provides formal guarantees on both model size reduction and approximation error. By leveraging the inherent piecewise polynomial structure of KANs, we formulate the compression problem as one of optimal polyhedral region merging. We establish a rigorous polyhedral characterization of KANs, develop a complete theory of $\epsilon$-equivalent compression, and design an optimal dynamic programming algorithm that guarantees minimal compression under specified error bounds. Our theoretical analysis demonstrates that PolyKAN achieves provably minimal compression while maintaining strict error control, with polynomial-time complexity in all network parameters. The framework provides the first formal foundation for KAN compression with mathematical guarantees, opening new directions for efficient deployment of interpretable neural architectures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.04205v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Di Zhang</dc:creator>
    </item>
    <item>
      <title>Closing the Loop: Coordinating Inventory and Recommendation via Deep Reinforcement Learning on Multiple Timescales</title>
      <link>https://arxiv.org/abs/2510.04272</link>
      <description>arXiv:2510.04272v1 Announce Type: cross 
Abstract: Effective cross-functional coordination is essential for enhancing firm-wide profitability, particularly in the face of growing organizational complexity and scale. Recent advances in artificial intelligence, especially in reinforcement learning (RL), offer promising avenues to address this fundamental challenge. This paper proposes a unified multi-agent RL framework tailored for joint optimization across distinct functional modules, exemplified via coordinating inventory replenishment and personalized product recommendation. We first develop an integrated theoretical model to capture the intricate interplay between these functions and derive analytical benchmarks that characterize optimal coordination. The analysis reveals synchronized adjustment patterns across products and over time, highlighting the importance of coordinated decision-making. Leveraging these insights, we design a novel multi-timescale multi-agent RL architecture that decomposes policy components according to departmental functions and assigns distinct learning speeds based on task complexity and responsiveness. Our model-free multi-agent design improves scalability and deployment flexibility, while multi-timescale updates enhance convergence stability and adaptability across heterogeneous decisions. We further establish the asymptotic convergence of the proposed algorithm. Extensive simulation experiments demonstrate that the proposed approach significantly improves profitability relative to siloed decision-making frameworks, while the behaviors of the trained RL agents align closely with the managerial insights from our theoretical model. Taken together, this work provides a scalable, interpretable RL-based solution to enable effective cross-functional coordination in complex business settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.04272v1</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jinyang Jiang, Jinhui Han, Yijie Peng, Ying Zhang</dc:creator>
    </item>
    <item>
      <title>Robust Optimality of Bundling Goods Beyond Finite Variance</title>
      <link>https://arxiv.org/abs/2510.04343</link>
      <description>arXiv:2510.04343v1 Announce Type: cross 
Abstract: When selling many goods with independent valuations, we develop a distributionally robust framework, consisting of a two-player game between seller and nature. The seller has only limited knowledge about the value distribution. The seller selects a revenue-maximizing mechanism, after which nature chooses a revenue-minimizing distribution from all distributions that comply with the limited knowledge. When the seller knows the mean and variance of valuations, bundling is known to be an asymptotically optimal deterministic mechanism, achieving a normalized revenue close to the mean. Moving beyond this variance assumption, we assume knowledge of the mean absolute deviation (MAD), accommodating more dispersion and heavy-tailed valuations with infinite variance. We show for a large range of MAD values that bundling remains optimal, but the seller can only guarantee a revenue strictly smaller than the mean. Another noteworthy finding is indifference to the order of play, as both the max-min and min-max versions of the problem yield identical values. This contrasts with deterministic mechanisms and the separate sale of goods, where the order of play significantly impacts outcomes. We further underscore the universality of the optimal bundling price by demonstrating its efficacy in optimizing not only absolute revenue but also the absolute regret and ratio objective among all bundling prices</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.04343v1</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tim S. G. van Eck, Pieter Kleer, Johan S. H. van Leeuwaarden</dc:creator>
    </item>
    <item>
      <title>Achieve Performatively Optimal Policy for Performative Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2510.04430</link>
      <description>arXiv:2510.04430v1 Announce Type: cross 
Abstract: Performative reinforcement learning is an emerging dynamical decision making framework, which extends reinforcement learning to the common applications where the agent's policy can change the environmental dynamics. Existing works on performative reinforcement learning only aim at a performatively stable (PS) policy that maximizes an approximate value function. However, there is a provably positive constant gap between the PS policy and the desired performatively optimal (PO) policy that maximizes the original value function. In contrast, this work proposes a zeroth-order Frank-Wolfe algorithm (0-FW) algorithm with a zeroth-order approximation of the performative policy gradient in the Frank-Wolfe framework, and obtains \textbf{the first polynomial-time convergence to the desired PO} policy under the standard regularizer dominance condition. For the convergence analysis, we prove two important properties of the nonconvex value function. First, when the policy regularizer dominates the environmental shift, the value function satisfies a certain gradient dominance property, so that any stationary point (not PS) of the value function is a desired PO. Second, though the value function has unbounded gradient, we prove that all the sufficiently stationary points lie in a convex and compact policy subspace $\Pi_{\Delta}$, where the policy value has a constant lower bound $\Delta&gt;0$ and thus the gradient becomes bounded and Lipschitz continuous. Experimental results also demonstrate that our 0-FW algorithm is more effective than the existing algorithms in finding the desired PO policy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.04430v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ziyi Chen, Heng Huang</dc:creator>
    </item>
    <item>
      <title>Trade-off in Estimating the Number of Byzantine Clients in Federated Learning</title>
      <link>https://arxiv.org/abs/2510.04432</link>
      <description>arXiv:2510.04432v1 Announce Type: cross 
Abstract: Federated learning has attracted increasing attention at recent large-scale optimization and machine learning research and applications, but is also vulnerable to Byzantine clients that can send any erroneous signals. Robust aggregators are commonly used to resist Byzantine clients. This usually requires to estimate the unknown number $f$ of Byzantine clients, and thus accordingly select the aggregators with proper degree of robustness (i.e., the maximum number $\hat{f}$ of Byzantine clients allowed by the aggregator). Such an estimation should have important effect on the performance, which has not been systematically studied to our knowledge. This work will fill in the gap by theoretically analyzing the worst-case error of aggregators as well as its induced federated learning algorithm for any cases of $\hat{f}$ and $f$. Specifically, we will show that underestimation ($\hat{f}&lt;f$) can lead to arbitrarily poor performance for both aggregators and federated learning. For non-underestimation ($\hat{f}\ge f$), we have proved optimal lower and upper bounds of the same order on the errors of both aggregators and federated learning. All these optimal bounds are proportional to $\hat{f}/(n-f-\hat{f})$ with $n$ clients, which monotonically increases with larger $\hat{f}$. This indicates a fundamental trade-off: while an aggregator with a larger robustness degree $\hat{f}$ can solve federated learning problems of wider range $f\in [0,\hat{f}]$, the performance can deteriorate when there are actually fewer or even no Byzantine clients (i.e., $f\in [0,\hat{f})$).</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.04432v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ziyi Chen, Su Zhang, Heng Huang</dc:creator>
    </item>
    <item>
      <title>Stochastic Approximation Methods for Distortion Risk Measure Optimization</title>
      <link>https://arxiv.org/abs/2510.04563</link>
      <description>arXiv:2510.04563v1 Announce Type: cross 
Abstract: Distortion Risk Measures (DRMs) capture risk preferences in decision-making and serve as general criteria for managing uncertainty. This paper proposes gradient descent algorithms for DRM optimization based on two dual representations: the Distortion-Measure (DM) form and Quantile-Function (QF) form. The DM-form employs a three-timescale algorithm to track quantiles, compute their gradients, and update decision variables, utilizing the Generalized Likelihood Ratio and kernel-based density estimation. The QF-form provides a simpler two-timescale approach that avoids the need for complex quantile gradient estimation. A hybrid form integrates both approaches, applying the DM-form for robust performance around distortion function jumps and the QF-form for efficiency in smooth regions. Proofs of strong convergence and convergence rates for the proposed algorithms are provided. In particular, the DM-form achieves an optimal rate of $O(k^{-4/7})$, while the QF-form attains a faster rate of $O(k^{-2/3})$. Numerical experiments confirm their effectiveness and demonstrate substantial improvements over baselines in robust portfolio selection tasks. The method's scalability is further illustrated through integration into deep reinforcement learning. Specifically, a DRM-based Proximal Policy Optimization algorithm is developed and applied to multi-echelon dynamic inventory management, showcasing its practical applicability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.04563v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jinyang Jiang, Bernd Heidergott, Jiaqiao Hu, Yijie Peng</dc:creator>
    </item>
    <item>
      <title>Constrained Dikin-Langevin diffusion for polyhedra</title>
      <link>https://arxiv.org/abs/2510.04582</link>
      <description>arXiv:2510.04582v2 Announce Type: cross 
Abstract: Interior-point geometry offers a straightforward approach to constrained sampling and optimization on polyhedra, eliminating reflections and ad hoc projections. We exploit the Dikin log-barrier to define a Dikin--Langevin diffusion whose drift and noise are modulated by the inverse barrier Hessian. In continuous time, we establish a boundary no-flux property; trajectories started in the interior remain in $U$ almost surely, so feasibility is maintained by construction. For computation, we adopt a discretize-then-correct design: an Euler--Maruyama proposal with state-dependent covariance, followed by a Metropolis--Hastings correction that targets the exact constrained law and reduces to a Dikin random walk when $f$ is constant.
  Numerically, the unadjusted diffusion exhibits the expected first-order step size bias, while the MH-adjusted variant delivers strong convergence diagnostics on anisotropic, box-constrained Gaussians (rank-normalized split-$\hat{R}$ concentrated near $1$) and higher inter-well transition counts on a bimodal target, indicating superior cross-well mobility. Taken together, these results demonstrate that coupling calibrated stochasticity with interior-point preconditioning provides a practical, reflection-free approach to sampling and optimization over polyhedral domains, offering clear advantages near faces, corners, and in nonconvex landscapes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.04582v2</guid>
      <category>stat.CO</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>James Chok, Domenic Petzinna</dc:creator>
    </item>
    <item>
      <title>Parameter-free Algorithms for the Stochastically Extended Adversarial Model</title>
      <link>https://arxiv.org/abs/2510.04685</link>
      <description>arXiv:2510.04685v1 Announce Type: cross 
Abstract: We develop the first parameter-free algorithms for the Stochastically Extended Adversarial (SEA) model, a framework that bridges adversarial and stochastic online convex optimization. Existing approaches for the SEA model require prior knowledge of problem-specific parameters, such as the diameter of the domain $D$ and the Lipschitz constant of the loss functions $G$, which limits their practical applicability. Addressing this, we develop parameter-free methods by leveraging the Optimistic Online Newton Step (OONS) algorithm to eliminate the need for these parameters. We first establish a comparator-adaptive algorithm for the scenario with unknown domain diameter but known Lipschitz constant, achieving an expected regret bound of $\tilde{O}\big(\|u\|_2^2 + \|u\|_2(\sqrt{\sigma^2_{1:T}} + \sqrt{\Sigma^2_{1:T}})\big)$, where $u$ is the comparator vector and $\sigma^2_{1:T}$ and $\Sigma^2_{1:T}$ represent the cumulative stochastic variance and cumulative adversarial variation, respectively. We then extend this to the more general setting where both $D$ and $G$ are unknown, attaining the comparator- and Lipschitz-adaptive algorithm. Notably, the regret bound exhibits the same dependence on $\sigma^2_{1:T}$ and $\Sigma^2_{1:T}$, demonstrating the efficacy of our proposed methods even when both parameters are unknown in the SEA model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.04685v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shuche Wang, Adarsh Barik, Peng Zhao, Vincent Y. F. Tan</dc:creator>
    </item>
    <item>
      <title>A Lie Theoretic Framework for Controlling Open Quantum Systems</title>
      <link>https://arxiv.org/abs/2510.04719</link>
      <description>arXiv:2510.04719v1 Announce Type: cross 
Abstract: This thesis focuses on the Lie-theoretic foundations of controlled open quantum systems. We describe Markovian open quantum system evolutions by Lie semigroups, whose corresponding infinitesimal generators lie in a special type of convex cone - a Lie wedge. The Lie wedge associated to a given control system therefore consists of all generators of the quantum dynamical semigroup that are physically realisable as a result of the interplay between the coherent and incoherent processes the quantum system is subject to. For $n$-qubit open quantum systems, we provide a parametrisation of the largest physically relevant Lie algebra (the system algebra), in which these Lie wedges are contained: the Lindblad-Kossakowski Lie algebra. This parametrisation provides several useful benefits. First, it allows us to construct explicit forms of these system Lie wedges and their respective system Lie algebras. Second, we analyse which control scenarios yield Lie wedges that are closed under Baker-Campbell-Hausdorff (BCH) multiplication and therefore generate Markovian semigroups of time-independent quantum channels. Lie wedges of this form are called Lie semialgebras, and we completely solve this open problem by proving that Lie wedges specialise to this form only when the coherent controls have no effect on both the inherent drift Hamiltonian and the incoherent part of the dynamics. Finally, this parametrisation of the Lindblad-Kossakowski Lie algebra points to an intuitive separation between unital and non-unital dissipative dynamics, where the non-unital component of the dynamics is described by affine translation operations. These translation operators are then exploited to construct purely dissipative fixed-point engineering schemes to obtain either pure or mixed states as a system's unique fixed point.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.04719v1</guid>
      <category>quant-ph</category>
      <category>math.OC</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Corey O'Meara</dc:creator>
    </item>
    <item>
      <title>Online Multiple Resource Allocation Problems with Departures via the Primal-Dual Approach</title>
      <link>https://arxiv.org/abs/2510.04737</link>
      <description>arXiv:2510.04737v1 Announce Type: cross 
Abstract: In this paper we propose primal-dual algorithms for different variants of the online resource allocation problem with departures. In the basic variant, requests (items) arrive over time to a set of resources (knapsacks) and upon arrival, the duration of time a request may occupy a resource, the demand and reward if the request can be granted, become known. %We assume that the duration of stay of a request may depend on the resource. %and that resources may have different capacity sizes. The goal of the algorithm is to decide whether to accept/reject a request upon arrival and to which resource to allocate it such that the reward obtained over time is maximized. Under some mild assumptions, we show that the proposed primal-dual algorithm achieves a competitive ratio of $O\big(\log(\bar\theta^{\max}\cdot\bar d^{\max})\big)$, where $\bar \theta^{\max}$ is the maximum value density fluctuation ratio and $\bar d^{\max}$ is the maximum duration fluctuation ratio. We prove similar results for two other variants, namely, one with an additional load balancing constraint, and the multi-dimensional variant where an admitted request consumes capacity on multiple resources. Our results show that the primal-dual approach offers a simple, unified framework for obtaining competitive ratios comparable to those previously obtained via threshold policies known for these problems. Additionally, we show that this framework allows us to incorporate additional constraints, such as load-balancing constraints, without sacrificing the competitive ratio.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.04737v1</guid>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yusuf Amidu, Khaled Elbassioni, Adriana F. Gabor</dc:creator>
    </item>
    <item>
      <title>Finite elements and moving asymptotes accelerate quantum optimal control - FEMMA</title>
      <link>https://arxiv.org/abs/2510.04798</link>
      <description>arXiv:2510.04798v1 Announce Type: cross 
Abstract: Quantum optimal control is central to designing spin manipulation pulses. While GRAPE efficiently computes gradients, realistic ensemble models make optimization time-consuming. In this work, we accelerated single-spin optimal control by combining the finite element method with the method of moving asymptotes. By treating discretized time as spatial coordinates, the Liouville-von Neumann equation was reformulated as a linear system, yielding gradients solving over an order of magnitude faster than GRAPE with less than one percent relative-accuracy loss. The moving asymptotes further improves convergence, outperforming L-BFGS and approaching Newton-level efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.04798v1</guid>
      <category>physics.chem-ph</category>
      <category>math.OC</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mengjia He, Yongbo Deng, Burkhard Luy, Jan G. Korvink</dc:creator>
    </item>
    <item>
      <title>On the Feinberg-Piunovskiy Theorem and its extension to chattering policies</title>
      <link>https://arxiv.org/abs/2510.04808</link>
      <description>arXiv:2510.04808v1 Announce Type: cross 
Abstract: The Feinberg-Piunovskiy Theorem established in [14, Theorem 3.8] asserts that for a discrete-time uniformly absorbing and atomless Markov Decision Process (MDP) with Borel state space and multiple criteria, the family of deterministic stationary policies is a sufficient class of policies. In this paper, we study some related problems and some extensions. In particular dropping the atomless hypothesis, we establish that the set of chattering stationary policies is a sufficient class of policies for uniformly absorbing MDPs with measurable state space and multiple criteria. We also prove the Feinberg-Piunovskiy Theorem in the context of a measurable state space in two different ways that differ from \cite{piunovskiy19}. In particular, we show that the sufficiency of chattering stationary policies directly yields the sufficiency of deterministics stationary policies for atomless models. Our approach is partially based on the analysis of extreme points of certain convex sets of occupation measures satisfying integral type constraints. We show that for a uniformly absorbing model an extreme point of such sets is necessarily given by occupation measures induced by chattering stationary policies of order $d+1$ where $d$ is the dimension of the vector of constraints. When in addition the model $\mathsf{M}$ is atomless, then the extreme points of this constrained set of occupation measures are precisely the occupation measures generated by deterministic stationary policies satisfying these constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.04808v1</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Francois Dufour, Tomas Prieto-Rumeau</dc:creator>
    </item>
    <item>
      <title>A Fixed Point Framework for the Existence of EFX Allocations</title>
      <link>https://arxiv.org/abs/2510.04915</link>
      <description>arXiv:2510.04915v1 Announce Type: cross 
Abstract: We consider the problem of the existence of an envy-free allocation up to any good (EFX) for linear valuations and establish new results by connecting this problem to a fixed point framework. Specifically, we first use randomized rounding to extend the discrete EFX constraints into a continuous space and show that an EFX allocation exists if and only if the optimal value of the continuously extended objective function is nonpositive. In particular, we demonstrate that this optimization problem can be formulated as an unconstrained difference of convex (DC) program, which can be further simplified to the minimization of a piecewise linear concave function over a polytope. Leveraging this connection, we show that the proposed DC program has a nonpositive optimal objective value if and only if a well-defined continuous vector map admits a fixed point. Crucially, we prove that the reformulated fixed point problem satisfies all the conditions of Brouwer's fixed point theorem, except that self-containedness is violated by an arbitrarily small positive constant. To address this, we propose a slightly perturbed continuous map that always admits a fixed point. This fixed point serves as a proxy for the fixed point (if it exists) of the original map, and hence for an EFX allocation through an appropriate transformation. Our results offer a new approach to establishing the existence of EFX allocations through fixed point theorems. Moreover, the equivalence with DC programming enables a more efficient and systematic method for computing such allocations (if one exists) using tools from nonlinear optimization. Our findings bridge the discrete problem of finding an EFX allocation with two continuous frameworks: solving an unconstrained DC program and identifying a fixed point of a continuous vector map.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.04915v1</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>S. Rasoul Etesami</dc:creator>
    </item>
    <item>
      <title>Robust Cislunar Navigation via LFT-Based $\mathcal{H}_\infty$ Filtering with Bearing-Only Measurements</title>
      <link>https://arxiv.org/abs/2510.04942</link>
      <description>arXiv:2510.04942v1 Announce Type: cross 
Abstract: This paper develops a robust estimation framework for cislunar navigation that embeds the Circular Restricted Three-Body Problem (CR3BP) dynamics and bearing-only optical measurements within a Linear Fractional Transformation (LFT) representation. A full-order $\mathcal{H}_\infty$ observer is synthesized with explicit $\mathcal{L}_2$ performance bounds. The formulation yields a nonlinear estimator that operates directly on the governing equations and avoids reliance on local linearizations. Dominant nonlinearities are expressed as structured real uncertainties, while measurement fidelity is represented through range-dependent weighting with Earth-Moon distances reconstructed from line-of-sight geometry. The sensing architecture assumes passive star-tracker-class optical instruments, eliminating the need for time-of-flight ranging or precision clocks. Simulations demonstrate bounded estimation errors and smooth position tracking over multiple orbital periods, with the largest deviations observed in the out-of-plane states, consistent with the stiffness of the vertical dynamics and the limitations of angle-only observability. Application to a Near Rectilinear Halo Orbit (NRHO) illustrates that the framework can achieve robust onboard navigation with bounded estimation errors with flight-representative sensors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.04942v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Raktim Bhattacharya</dc:creator>
    </item>
    <item>
      <title>On convergence of infinite matrix products with alternating factors from two sets of matrices</title>
      <link>https://arxiv.org/abs/1712.06356</link>
      <description>arXiv:1712.06356v4 Announce Type: replace 
Abstract: We consider the problem of convergence to zero of matrix products $A_{n}B_{n}\cdots A_{1}B_{1}$ with factors from two sets of matrices, $A_{i}\in\mathscr{A}$ and $B_{i}\in\mathscr{B}$, due to a suitable choice of matrices $\{B_{i}\}$. It is assumed that for any sequence of matrices $\{A_{i}\}$ there is a sequence of matrices $\{B_{i}\}$ such that the corresponding matrix product $A_{n}B_{n}\cdots A_{1}B_{1}$ converges to zero. We show that in this case the convergence of the matrix products under consideration is uniformly exponential, that is, $\|A_{n}B_{n}\cdots A_{1}B_{1}\|\le C\lambda^{n}$, where the constants $C&gt;0$ and $\lambda\in(0,1)$ do not depend on the sequence $\{A_{i}\}$ and the corresponding sequence $\{B_{i}\}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:1712.06356v4</guid>
      <category>math.OC</category>
      <category>math.RA</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1155/2018/9216760</arxiv:DOI>
      <arxiv:journal_reference>Discrete Dynamics in Nature and Society, Volume 2018 (2018), Article ID 9216760, 5 pages</arxiv:journal_reference>
      <dc:creator>Victor Kozyakin</dc:creator>
    </item>
    <item>
      <title>Sliding Window Codes: Near-Optimality and Q-Learning for Zero-Delay Coding</title>
      <link>https://arxiv.org/abs/2310.06742</link>
      <description>arXiv:2310.06742v4 Announce Type: replace 
Abstract: We study the problem of zero-delay coding for the transmission of a Markov source over a noisy channel with feedback and present a reinforcement learning solution which is guaranteed to achieve near-optimality. To this end, we formulate the problem as a Markov decision process (MDP) where the state is a probability-measure valued predictor/belief and the actions are quantizer maps. This MDP formulation has been used to show the optimality of certain classes of encoder policies in prior work, but their computation is prohibitively complex due to the uncountable nature of the constructed state space and the lack of minorization or strong ergodicity results. These challenges invite rigorous reinforcement learning methods, which entail several open questions: can we approximate this MDP with a finite-state one with some performance guarantee? Can we ensure convergence of a reinforcement learning algorithm for this approximate MDP? What regularity assumptions are required for the above to hold? We address these questions as follows: we present an approximation of the belief MDP using a sliding finite window of channel outputs and quantizers. Under an appropriate notion of predictor stability, we show that policies based on this finite window are near-optimal, in the sense that the lowest distortion achievable by such a policy approaches the true lowest distortion as the window length increases. We give sufficient conditions for predictor stability to hold. Finally, we propose a Q-learning algorithm which provably converges to a near-optimal policy and provide a detailed comparison of~the sliding finite window scheme with another approximation scheme which quantizes the belief MDP in a nearest neighbor fashion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.06742v4</guid>
      <category>math.OC</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Liam Cregg, Fady Alajaji, Serdar Yuksel</dc:creator>
    </item>
    <item>
      <title>Duality Theory on Vector Spaces</title>
      <link>https://arxiv.org/abs/2311.13241</link>
      <description>arXiv:2311.13241v5 Announce Type: replace 
Abstract: In this paper, we study the Fenchel-Rockafellar duality and the Lagrange duality in the general frame work of vector spaces without topological structures. We utilize the geometric approach, inspired from its successful application by B. S. Mordukhovich and his coauthors in variational and convex analysis. After revisiting coderivative calculus rules and providing the subdifferential maximum rule in vector spaces, we establish conjugate calculus rules under qualifying conditions through the algebraic interior of the function's domains. Then we develop sufficient conditions which guarantee the Fenchel-Rockafellar strong duality. Finally, after deriving some necessary and sufficient conditions for optimal solutions to convex minimization problems, under a Slater condition via the algebraic interior, we then obtain a sufficient condition for the Lagrange strong duality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.13241v5</guid>
      <category>math.OC</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dang Van Cuong, Tuyen Tran</dc:creator>
    </item>
    <item>
      <title>New global Carleman estimates and null controllability for forward/backward semi-linear parabolic SPDEs</title>
      <link>https://arxiv.org/abs/2401.13455</link>
      <description>arXiv:2401.13455v4 Announce Type: replace 
Abstract: In this paper, we study the null controllability for parabolic SPDEs involving both the state and the gradient of the state. To start with, an improved global Carleman estimate for linear forward (resp. backward) parabolic SPDEs with general random coefficients and square-integrable source terms is derived. Based on this, we further develop a new global Carleman estimate for linear forward (resp. backward) parabolic SPDEs with source terms in the Sobolev space of negative order, which enables us to deal with the global null controllability for linear backward (resp. forward) parabolic SPDEs with gradient terms. As a byproduct, a special weighted energy-type estimate for the controlled system that explicitly depends on the parameters $\lambda,\mu$ and the weighted function $\theta$ is obtained, which makes it possible to extend the previous linear null controllability to semi-linear backward (resp. forward) parabolic SPDEs by applying the fixed-point argument in an appropriate Banach space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.13455v4</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lei Zhang, Fan Xu, Bin Liu</dc:creator>
    </item>
    <item>
      <title>Distributionally Robust Optimization with Decision-Dependent Information Discovery</title>
      <link>https://arxiv.org/abs/2404.05900</link>
      <description>arXiv:2404.05900v2 Announce Type: replace 
Abstract: We study two-stage distributionally robust optimization (DRO) problems with decision-dependent information discovery (DDID) wherein (a portion of) the uncertain parameters are revealed only if an (often costly) investment is made in the first stage. This class of problems finds many important applications in selection problems (e.g., in hiring, project portfolio optimization, or optimal sensor location). Despite the wide applicability of the problem, it has not been previously studied. We propose a framework for modeling and approximately solving DRO problems with DDID. We formulate the problem as a min-max-min-max problem and adopt the popular K-adaptability approximation scheme, which chooses K candidate recourse actions here-and-now and implements the best of those actions after the uncertain parameters that were chosen to be observed are revealed. We then present a decomposition algorithm that solves the K-adaptable formulation exactly. In particular, we devise a cutting plane algorithm that iteratively solves a relaxed version of the problem, evaluates the true objective value of the corresponding solution, generates valid cuts, and imposes them in the relaxed problem. For the evaluation problem, we develop a branch-and-cut algorithm that provably converges to an optimal solution. We showcase the effectiveness of our framework on the R&amp;D project portfolio optimization problem and the best box problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.05900v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qing Jin, Angelos Georghiou, Phebe Vayanos, Grani A. Hanasusanto</dc:creator>
    </item>
    <item>
      <title>Data-Driven Performance Guarantees for Classical and Learned Optimizers</title>
      <link>https://arxiv.org/abs/2404.13831</link>
      <description>arXiv:2404.13831v3 Announce Type: replace 
Abstract: We introduce a data-driven approach to analyze the performance of continuous optimization algorithms using generalization guarantees from statistical learning theory. We study classical and learned optimizers to solve families of parametric optimization problems. We build generalization guarantees for classical optimizers, using a sample convergence bound, and for learned optimizers, using the Probably Approximately Correct (PAC)-Bayes framework. To train learned optimizers, we use a gradient-based algorithm to directly minimize the PAC-Bayes upper bound. Numerical experiments in signal processing, control, and meta-learning showcase the ability of our framework to provide strong generalization guarantees for both classical and learned optimizers given a fixed budget of iterations. For classical optimizers, our bounds are much tighter than those that worst-case guarantees provide. For learned optimizers, our bounds outperform the empirical outcomes observed in their non-learned counterparts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13831v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Rajiv Sambharya, Bartolomeo Stellato</dc:creator>
    </item>
    <item>
      <title>Concrete convergence rates for common fixed point problems under Karamata regularity</title>
      <link>https://arxiv.org/abs/2407.13234</link>
      <description>arXiv:2407.13234v2 Announce Type: replace 
Abstract: We introduce the notion of Karamata regular operators, which is a notion of regularity that is suitable for obtaining concrete convergence rates for common fixed point problems. This provides a broad framework that includes, but goes beyond, H\"olderian error bounds and H\"older regular operators. By concrete, we mean that the rates we obtain are explicitly expressed in terms of a function of the iteration number $k$ instead, of say, a function of the iterate $x^k$. While it is well-known that under H\"olderian-like assumptions many algorithms converge linearly/sublinearly (depending on the exponent), little it is known when the underlying problem data does not satisfy H\"olderian assumptions, which may happen if a problem involves exponentials and logarithms. Our main innovation is the usage of the theory of regularly varying functions which we showcase by obtaining concrete convergence rates for quasi-cylic algorithms in non-H\"olderian settings. This includes certain rates that are neither sublinear nor linear but sit somewhere in-between, including a case where the rate is expressed via the Lambert W function. Finally, we connect our discussion to o-minimal geometry and show that, under mild assumptions, definable operators in any o-minimal structure are always Karamata regular.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13234v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.FA</category>
      <category>math.MG</category>
      <category>math.NA</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tianxiang Liu, Bruno F. Louren\c{c}o</dc:creator>
    </item>
    <item>
      <title>Faces of homogeneous cones and applications to homogeneous chordality</title>
      <link>https://arxiv.org/abs/2501.09581</link>
      <description>arXiv:2501.09581v3 Announce Type: replace 
Abstract: A convex cone $\mathcal{K}$ is said to be homogeneous if its group of automorphisms acts transitively on its relative interior. Important examples of homogeneous cones include symmetric cones and cones of positive semidefinite (PSD) matrices that follow a sparsity pattern given by a homogeneous chordal graph. Our goal in this paper is to elucidate the facial structure of homogeneous cones and make it as transparent as the faces of the PSD matrices. We prove that each face of a homogeneous cone $\mathcal{K}$ is mapped by an automorphism of $\mathcal{K}$ to one of its finitely many so-called principal faces. Furthermore, constructing such an automorphism can be done algorithmically by making use of a generalized Cholesky decomposition. Among other consequences, we give a proof that homogeneous cones are projectionally exposed, which strengthens the previous best result that they are amenable. Using our results, we will carefully analyze the facial structure of cones of PSD matrices satisfying homogeneous chordality and discuss consequences for the corresponding family of PSD completion problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.09581v3</guid>
      <category>math.OC</category>
      <category>math.CO</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jo\~ao Gouveia, Masaru Ito, Bruno F. Louren\c{c}o</dc:creator>
    </item>
    <item>
      <title>Controllability scores of linear time-varying network systems</title>
      <link>https://arxiv.org/abs/2501.13345</link>
      <description>arXiv:2501.13345v3 Announce Type: replace 
Abstract: For large-scale network systems, network centrality based on control theory plays a crucial role in understanding their properties and controlling them efficiently. The controllability score is such a centrality index and can give a physically meaningful measure. It is originally proposed for linear time-invariant (LTI) systems, and we extend it to linear time-varying (LTV) systems in this paper. Since the controllability score is defined as an optimal solution to some optimization problem, it is not necessarily uniquely determined. Its uniqueness must be guaranteed for reproducibility and interpretability. In this paper, we show its uniqueness in almost all cases, which guarantees its use as a network centrality measure. We also prove its continuity with respect to the time parameters. In addition, we propose a data-driven method to compute it. Finally, we verify the effectiveness of the extension and examine the performance of the data-driven method through numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13345v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kota Umezu, Kazuhiro Sato</dc:creator>
    </item>
    <item>
      <title>Rough Stochastic Pontryagin Maximum Principle and an Indirect Shooting Method</title>
      <link>https://arxiv.org/abs/2502.06726</link>
      <description>arXiv:2502.06726v3 Announce Type: replace 
Abstract: We derive first-order Pontryagin optimality conditions for stochastic optimal control with deterministic controls for systems modeled by rough differential equations (RDE) driven by Gaussian rough paths. This Pontryagin Maximum Principle (PMP) applies to systems following stochastic differential equations (SDE) driven by Brownian motion, yet it does not rely on forward-backward SDEs and involves the same Hamiltonian as the deterministic PMP. The proof consists of first deriving various integrable error bounds for solutions to nonlinear and linear RDEs by leveraging recent results on Gaussian rough paths. The PMP then follows using standard techniques based on needle-like variations. As an application, we propose the first indirect shooting method for nonlinear stochastic optimal control and show that it converges 10x faster than a direct method on a stabilization task.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06726v3</guid>
      <category>math.OC</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.PR</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Thomas Lew</dc:creator>
    </item>
    <item>
      <title>Sample Complexity of Linear Quadratic Regulator Without Initial Stability</title>
      <link>https://arxiv.org/abs/2502.14210</link>
      <description>arXiv:2502.14210v3 Announce Type: replace 
Abstract: Inspired by REINFORCE, we introduce a novel receding-horizon algorithm for the Linear Quadratic Regulator (LQR) problem with unknown dynamics. Unlike prior methods, our algorithm avoids reliance on two-point gradient estimates while maintaining the same order of sample complexity. Furthermore, it eliminates the restrictive requirement of starting with a stable initial policy, broadening its applicability. Beyond these improvements, we introduce a refined analysis of error propagation through the contraction of the Riccati operator under the Riemannian distance. This refinement leads to a better sample complexity and ensures improved convergence guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.14210v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Amirreza Neshaei Moghaddam, Alex Olshevsky, Bahman Gharesifard</dc:creator>
    </item>
    <item>
      <title>Optimization under uncertainty: understanding orders and testing programs with specifications</title>
      <link>https://arxiv.org/abs/2503.18561</link>
      <description>arXiv:2503.18561v2 Announce Type: replace 
Abstract: One of the most ubiquitous problems in optimization is that of finding all the elements of a finite set at which a function $f$ attains its minimum (or maximum). When the codomain of $f$ is equipped with a total order, it is easy to specify, implement, and verify generic solutions to this problem. But what if $f$ is affected by uncertainties? What if one seeks values that minimize more than one objective, or if $f$ does not return a single result but a set of possible results, or even a probability distribution? Such situations are common in climate science, economics, and engineering. Developing trustworthy solution methods for optimization under uncertainty requires formulating and answering these questions rigorously, including deciding which order relations to apply in different cases. We show how functional programming can support this task, and apply it to specify and test solution methods for cases where optimization is affected by two conceptually different kinds of uncertainty: value and functorial uncertainty.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.18561v2</guid>
      <category>math.OC</category>
      <category>cs.SE</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicola Botta, Patrik Jansson, Tim Richter</dc:creator>
    </item>
    <item>
      <title>Reducing Contextual Stochastic Bilevel Optimization via Structured Function Approximation</title>
      <link>https://arxiv.org/abs/2503.19991</link>
      <description>arXiv:2503.19991v3 Announce Type: replace 
Abstract: Contextual Stochastic Bilevel Optimization (CSBO) extends standard stochastic bilevel optimization (SBO) by incorporating context-dependent lower-level problems. CSBO problems are generally intractable since existing methods require solving a distinct lower-level problem for each sampled context, resulting in prohibitive sample and computational complexity, in addition to relying on impractical conditional sampling oracles. We propose a reduction framework that approximates the lower-level solutions using expressive basis functions, thereby decoupling the lower-level dependence on context and transforming CSBO into a standard SBO problem solvable using only joint samples from the context and noise distribution. First, we show that this reduction preserves hypergradient accuracy and yields an $\epsilon$-stationary solution to CSBO. Then, we relate the sample complexity of the reduced problem to simple metrics of the basis. This establishes sufficient criteria for a basis to yield $\epsilon$-stationary solutions with a near-optimal complexity of $\widetilde{O}(\epsilon^{-3})$, matching the best-known rate for standard SBO up to logarithmic factors. Moreover, we show that Chebyshev polynomials provide a concrete and efficient choice of basis that satisfies these criteria for a broad class of problems. Empirical results on inverse and hyperparameter optimization demonstrate that our approach outperforms CSBO baselines in convergence, sample efficiency, and memory usage.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.19991v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Maxime Bouscary, Jiawei Zhang, Saurabh Amin</dc:creator>
    </item>
    <item>
      <title>Symplectic Geometry in Hybrid and Impulsive Optimal Control</title>
      <link>https://arxiv.org/abs/2504.15117</link>
      <description>arXiv:2504.15117v2 Announce Type: replace 
Abstract: Hybrid dynamical systems are systems which undergo both continuous and discrete transitions. The Bolza problem from optimal control theory was applied to these systems and a hybrid version of Pontryagin's maximum principle was presented. This hybrid maximum principle was presented to emphasize its geometric nature which made its study amenable to the tools of geometric mechanics and symplectic geometry. One explicit benefit of this geometric approach was that the symplectic structure (and hence the induced volume) was preserved. This allowed for a hybrid analog of caustics and conjugate points. Additionally, an introductory analysis of singular solutions (beating and Zeno) was discussed geometrically. This work concluded on a biological example where beating can occur.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.15117v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>William Clark, Maria Oprea</dc:creator>
    </item>
    <item>
      <title>Revisiting the convergence rate of the Lasserre hierarchy for polynomial optimization over the hypercube</title>
      <link>https://arxiv.org/abs/2505.00544</link>
      <description>arXiv:2505.00544v2 Announce Type: replace 
Abstract: We revisit the problem of minimizing a given polynomial $f$ on the hypercube $[-1,1]^n$. Lasserre's hierarchy (also known as the moment- or sum-of-squares hierarchy) provides a sequence of lower bounds $\{f_{(r)}\}_{r \in \mathbb N}$ on the minimum value $f^*$, where $r$ refers to the allowed degrees in the sum-of-squares hierarchy. A natural question is how fast the hierarchy converges as a function of the parameter $r$. The current state-of-the-art is due to Baldi and Slot [SIAM J. on Applied Algebraic Geometry, 2024] and roughly shows a convergence rate of order $1/r$. Here we obtain closely related results via a different approach: the polynomial kernel method. We also discuss limitations of the polynomial kernel method, suggesting a lower bound of order $1/r^2$ for our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00544v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sander Gribling, Etienne de Klerk, Juan Vera</dc:creator>
    </item>
    <item>
      <title>On the Convergence Rates of Iterative Regularization Algorithms for Composite Bi-Level Optimization</title>
      <link>https://arxiv.org/abs/2506.16382</link>
      <description>arXiv:2506.16382v2 Announce Type: replace 
Abstract: This paper investigates iterative methods for solving bi-level optimization problems where both inner and outer functions have a composite structure. We establish novel theoretical results, including the first analysis that provides simultaneous convergence rates for the Iteratively REgularized Proximal Gradient (IRE-PG) method, a variant of Solodov's algorithm. These rates for the inner and outer functions highlight the inherent trade-offs between their respective convergence behaviors. We further extend this analysis to an accelerated version of IRE-PG, proving faster convergence rates under specific settings. Additionally, we propose a new scheme for handling cases where these methods cannot be directly applied to the bi-level problem due to the difficulty of computing the associated proximal operator. This scheme offers surrogate functions to approximate the original problem and a framework to translate convergence rates between the surrogate and original functions. Our results show that the accelerated method's advantage diminishes under this translation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.16382v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shimrit Shtern, Adeolu Taiwo</dc:creator>
    </item>
    <item>
      <title>Causal Hamilton-Jacobi-Bellman Equations for Anticipative Stochastic Optimal Control</title>
      <link>https://arxiv.org/abs/2507.08657</link>
      <description>arXiv:2507.08657v2 Announce Type: replace 
Abstract: We consider a stochastic optimal control problem where the controller can anticipate the evolution of the driving noise over some dynamically changing time window. The controlled state dynamics are understood as a rough differential equation. We combine the martingale optimality principle with a functional form of It\^o's formula to derive a Hamilton-Jacobi-Bellman (HJB) equation for this problem. This HJB equation is formulated in terms of Dupire's functional derivatives and involves a transport equation arising from the anticipativity of the problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.08657v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Peter Bank, Franziska Bielert</dc:creator>
    </item>
    <item>
      <title>Learning Acceleration Algorithms for Fast Parametric Convex Optimization with Certified Robustness</title>
      <link>https://arxiv.org/abs/2507.16264</link>
      <description>arXiv:2507.16264v2 Announce Type: replace 
Abstract: We develop a machine-learning framework to learn hyperparameter sequences for accelerated first-order methods (e.g., the step size and momentum sequences in accelerated gradient descent) to quickly solve parametric convex optimization problems with certified robustness. We obtain a strong form of robustness guarantee -- certification of worst-case performance over all parameters within a set after a given number of iterations -- through regularization-based training. The regularization term is derived from the performance estimation problem (PEP) framework based on semidefinite programming, in which the hyperparameters appear as problem data. We show how to use gradient-based training to learn the hyperparameters for several first-order methods: accelerated versions of gradient descent, proximal gradient descent, and alternating direction method of multipliers. Through various numerical examples from signal processing, control, and statistics, we demonstrate that the quality of the solution can be dramatically improved within a budget of iterations, while also maintaining strong robustness guarantees. Notably, our approach is highly data-efficient in that we only use ten training instances in all of the numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.16264v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Rajiv Sambharya, Jinho Bok, Nikolai Matni, George Pappas</dc:creator>
    </item>
    <item>
      <title>Riemannian Optimization on Tree Tensor Networks with Application in Machine Learning</title>
      <link>https://arxiv.org/abs/2507.21726</link>
      <description>arXiv:2507.21726v2 Announce Type: replace 
Abstract: Tree tensor networks (TTNs) are widely used in low-rank approximation and quantum many-body simulation. In this work, we present a formal analysis of the differential geometry underlying TTNs. Building on this foundation, we develop efficient first- and second-order optimization algorithms that exploit the intrinsic quotient structure of TTNs. Additionally, we devise a backpropagation algorithm for training TTNs in a kernel learning setting. We validate our methods through numerical experiments on a representative machine learning task.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.21726v2</guid>
      <category>math.OC</category>
      <category>cond-mat.other</category>
      <category>cs.LG</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Marius Willner, Marco Trenti, Dirk Lebiedz</dc:creator>
    </item>
    <item>
      <title>A distributed augmented Lagrangian decomposition algorithm for constrained optimization</title>
      <link>https://arxiv.org/abs/2508.04960</link>
      <description>arXiv:2508.04960v3 Announce Type: replace 
Abstract: Within the framework of the augmented Lagrangian (AL), we propose a novel distributed optimization method, termed Distributed Augmented Lagrangian Decomposition (DALD), and provide a rigorous convergence proof for its standard version. To address the high iteration costs in early stages, we propose several accelerated variants of DALD that enhances efficiency without compromising theoretical guarantees, supported by a comprehensive convergence analysis. To facilitate the description of the distributed optimization process, the concept of hierarchical coordination networks is introduced, integrating hierarchical matrix concepts to aid in this explanation. We further explore and expand the applicability of the DALD method and demonstrate how it unifies existing distributed optimization theories within the AL framework. The effectiveness and applicability of the proposed distributed optimization method and its variants are further validated through numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.04960v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenyou Guo, Ting Qu, Hainan Huang, Yafeng Wei</dc:creator>
    </item>
    <item>
      <title>Lyapunov stability of the Euler method</title>
      <link>https://arxiv.org/abs/2509.11415</link>
      <description>arXiv:2509.11415v2 Announce Type: replace 
Abstract: We extend the Lyapunov stability criterion to Euler discretizations of set-valued dynamical systems. It relies on a pair of Lyapunov functions, one in continuous time and one in discrete time. In the context of optimization, this yields sufficient conditions for normalized gradient descent to converge to a region containing the flat minima.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11415v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>C\'edric Josz</dc:creator>
    </item>
    <item>
      <title>Distributionally robust LMI synthesis for LTI systems</title>
      <link>https://arxiv.org/abs/2509.23493</link>
      <description>arXiv:2509.23493v2 Announce Type: replace 
Abstract: This article shows that distributionally robust controller synthesis as investigated in \cite{taskesen2024distributionally} can be formulated as a convex linear matrix inequality (LMI) synthesis problem. To this end, we rely on well-established convexification techniques from robust control. The LMI synthesis problem we propose has the advantage that it can be solved efficiently using off-the-shelf semi-definite programming (SDP) solvers. In addition, our formulation exposes the studied distributionally robust controller synthesis problem as an instance of robust $H_2$ synthesis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.23493v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dennis Gramlich, Shuhao Yan, Carsten W. Scherer, Christian Ebenbauer%</dc:creator>
    </item>
    <item>
      <title>A first-order method for constrained nonconvex--nonconcave minimax problems under a local Kurdyka-{\L}ojasiewicz condition</title>
      <link>https://arxiv.org/abs/2510.01168</link>
      <description>arXiv:2510.01168v2 Announce Type: replace 
Abstract: We study a class of constrained nonconvex--nonconcave minimax problems in which the inner maximization involves potentially complex constraints. Under the assumption that the inner problem of a novel lifted minimax problem satisfies a local Kurdyka-{\L}ojasiewicz (KL) condition, we show that the maximal function of the original problem enjoys a local H\"older smoothness property. We also propose a sequential convex programming (SCP) method for solving constrained optimization problems and establish its convergence rate under a local KL condition. Leveraging these results, we develop an inexact proximal gradient method for the original minimax problem, where the inexact gradient of the maximal function is computed via the SCP method applied to a locally KL-structured subproblem. Finally, we establish complexity guarantees for the proposed method in computing an approximate stationary point of the original minimax problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01168v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.ML</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhaosong Lu, Xiangyuan Wang</dc:creator>
    </item>
    <item>
      <title>Robust MPC for Large-scale Linear Systems</title>
      <link>https://arxiv.org/abs/2510.01794</link>
      <description>arXiv:2510.01794v2 Announce Type: replace 
Abstract: State-of-the-art approaches of Robust Model Predictive Control (MPC) are restricted to linear systems of relatively small scale, i.e., with no more than about 5 states. The main reason is the computational burden of determining a robust positively invariant (RPI) set, whose complexity suffers from the curse of dimensionality. The recently proposed approach of Deadbeat Robust Model Predictive Control (DRMPC) is the first that does not rely on an RPI set. Yet it comes with the full set of essential system theoretic guarantees. DRMPC is hence a viable option, in particular, for large-scale systems. This paper introduces a detailed design procedure for DRMPC. It is shown that the optimal control problem generated for DRMPC has exactly the same computational complexity as Nominal MPC. A numerical study validates its applicability to randomly generated large-scale linear systems of various dimensions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01794v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Georg Schildbach</dc:creator>
    </item>
    <item>
      <title>Improving Online-to-Nonconvex Conversion for Smooth Optimization via Double Optimism</title>
      <link>https://arxiv.org/abs/2510.03167</link>
      <description>arXiv:2510.03167v2 Announce Type: replace 
Abstract: A recent breakthrough in nonconvex optimization is the online-to-nonconvex conversion framework of [Cutkosky et al., 2023], which reformulates the task of finding an $\varepsilon$-first-order stationary point as an online learning problem. When both the gradient and the Hessian are Lipschitz continuous, instantiating this framework with two different online learners achieves a complexity of $O(\varepsilon^{-1.75}\log(1/\varepsilon))$ in the deterministic case and a complexity of $O(\varepsilon^{-3.5})$ in the stochastic case. However, this approach suffers from several limitations: (i) the deterministic method relies on a complex double-loop scheme that solves a fixed-point equation to construct hint vectors for an optimistic online learner, introducing an extra logarithmic factor; (ii) the stochastic method assumes a bounded second-order moment of the stochastic gradient, which is stronger than standard variance bounds; and (iii) different online learning algorithms are used in the two settings. In this paper, we address these issues by introducing an online optimistic gradient method based on a novel doubly optimistic hint function. Specifically, we use the gradient at an extrapolated point as the hint, motivated by two optimistic assumptions: that the difference between the hint and the target gradient remains near constant, and that consecutive update directions change slowly due to smoothness. Our method eliminates the need for a double loop and removes the logarithmic factor. Furthermore, by simply replacing full gradients with stochastic gradients and under the standard assumption that their variance is bounded by $\sigma^2$, we obtain a unified algorithm with complexity $O(\varepsilon^{-1.75} + \sigma^2 \varepsilon^{-3.5})$, smoothly interpolating between the best-known deterministic rate and the optimal stochastic rate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.03167v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Francisco Patitucci, Ruichen Jiang, Aryan Mokhtari</dc:creator>
    </item>
    <item>
      <title>Tutorial on amortized optimization</title>
      <link>https://arxiv.org/abs/2202.00665</link>
      <description>arXiv:2202.00665v5 Announce Type: replace-cross 
Abstract: Optimization is a ubiquitous modeling tool and is often deployed in settings which repeatedly solve similar instances of the same problem. Amortized optimization methods use learning to predict the solutions to problems in these settings, exploiting the shared structure between similar problem instances. These methods have been crucial in variational inference and reinforcement learning and are capable of solving optimization problems many orders of magnitudes faster than traditional optimization methods that do not use amortization. This tutorial presents an introduction to the amortized optimization foundations behind these advancements and overviews their applications in variational inference, sparse coding, gradient-based meta-learning, control, reinforcement learning, convex optimization, optimal transport, and deep equilibrium networks. The source code for this tutorial is available at https://github.com/facebookresearch/amortized-optimization-tutorial.</description>
      <guid isPermaLink="false">oai:arXiv.org:2202.00665v5</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Brandon Amos</dc:creator>
    </item>
    <item>
      <title>Adaptive Disturbance Observer-based Full-Order Integral-Terminal Sliding Mode Control with Unknown A Priori Bound on Uncertainty</title>
      <link>https://arxiv.org/abs/2304.02433</link>
      <description>arXiv:2304.02433v4 Announce Type: replace-cross 
Abstract: This study presents a novel, continuous finite-time control strategy for a class of nonlinear systems subject to matched uncertainties with unknown bounds. We propose an Adaptive Disturbance Observer-based Full-order Integral-Terminal Sliding Mode Control (ADO-FOITSMC) to stabilize a chain of integrators in presence of exogenous disturbances whose time derivative is bounded by a constant that is not known a priori. Key features of this approach include a significant reduction in control input chattering and a non-monotonic adaptive law for the observer gains, which prevents overestimation while ensuring the global boundedness of system states. The effectiveness and practical viability of the proposed algorithm are demonstrated through its application to the attitude stabilization of a rigid spacecraft.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.02433v4</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Jit Koley, Binoy Krishna Roy</dc:creator>
    </item>
    <item>
      <title>Code Generation and Conic Constraints for Model-Predictive Control on Microcontrollers with Conic-TinyMPC</title>
      <link>https://arxiv.org/abs/2403.18149</link>
      <description>arXiv:2403.18149v2 Announce Type: replace-cross 
Abstract: Model-predictive control (MPC) is a powerful framework for controlling dynamic systems under constraints, but it remains challenging to deploy on resource-constrained platforms, especially for problems involving conic constraints. To address this, we extend recent work developing fast, structure-exploiting, cached ADMM solvers for embedded applications, to provide support for second-order cones, as well as C++ code generation from Python, MATLAB, and Julia for easy deployment. Microcontroller benchmarks show that our solver provides up to a two-order-of-magnitude speedup, ranging from 10.6x to 142.7x, over state-of-the-art embedded solvers on QP and SOCP problems, and enables us to fit order-of-magnitude larger problems in memory. We validate our solver's deployed performance through simulation and hardware experiments, including conically-constrained trajectory tracking on a 27g Crazyflie quadrotor. To get started with Conic-TinyMPC, visit our documentation, examples, and the open-source codebase at https://tinympc.org.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.18149v2</guid>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ishaan Mahajan, Khai Nguyen, Sam Schoedel, Elakhya Nedumaran, Moises Mata, Brian Plancher, Zachary Manchester</dc:creator>
    </item>
    <item>
      <title>Robust dividend policy: Equivalence of Epstein-Zin and Maenhout preferences</title>
      <link>https://arxiv.org/abs/2406.12305</link>
      <description>arXiv:2406.12305v4 Announce Type: replace-cross 
Abstract: In a continuous-time economy, this paper formulates the Epstein-Zin preference for discounted dividends received by an investor as an Epstein-Zin singular control utility. We introduce a backward stochastic differential equation with an aggregator integrated with respect to a singular control, prove its well-posedness, and show that it coincides with the Epstein-Zin singular control utility. We then establish that this formulation is equivalent to a robust dividend policy chosen by the firm's executive under the Maenhout's ambiguity-averse preference. In particular, the robust dividend policy takes the form of a threshold strategy on the firm's surplus process, where the threshold level is characterized as the free boundary of a Hamilton-Jacobi-Bellman variational inequality. Therefore, dividend-caring investors can choose firms that match their preferences by examining stock's dividend policies and financial statements, whereas executives can make use of dividend to signal their confidence, in the form of ambiguity aversion, on realizing the earnings implied by their financial statements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12305v4</guid>
      <category>q-fin.MF</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>q-fin.GN</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kexin Chen, Kyunghyun Park, Hoi Ying Wong</dc:creator>
    </item>
    <item>
      <title>Exploring Applications of State Space Models and Advanced Training Techniques in Sequential Recommendations: A Comparative Study on Efficiency and Performance</title>
      <link>https://arxiv.org/abs/2408.05606</link>
      <description>arXiv:2408.05606v2 Announce Type: replace-cross 
Abstract: Recommender systems aim to estimate the dynamically changing user preferences and sequential dependencies between historical user behaviour and metadata. Although transformer-based models have proven to be effective in sequential recommendations, their state growth is proportional to the length of the sequence that is being processed, which makes them expensive in terms of memory and inference costs. Our research focused on three promising directions in sequential recommendations: enhancing speed through the use of State Space Models (SSM), as they can achieve SOTA results in the sequential recommendations domain with lower latency, memory, and inference costs, as proposed by arXiv:2403.03900 improving the quality of recommendations with Large Language Models (LLMs) via Monolithic Preference Optimization without Reference Model (ORPO); and implementing adaptive batch- and step-size algorithms to reduce costs and accelerate training processes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05606v2</guid>
      <category>cs.IR</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mark Obozov, Makar Baderko, Stepan Kulibaba, Nikolay Kutuzov, Alexander Gasnikov</dc:creator>
    </item>
    <item>
      <title>Machine Learning for Inverse Problems and Data Assimilation</title>
      <link>https://arxiv.org/abs/2410.10523</link>
      <description>arXiv:2410.10523v2 Announce Type: replace-cross 
Abstract: The aim of these notes is to demonstrate the potential for ideas in machine learning to impact on the fields of inverse problems and data assimilation. The perspective is one that is primarily aimed at researchers from inverse problems and/or data assimilation who wish to see a mathematical presentation of machine learning as it pertains to their fields. As a by-product, we include a succinct mathematical treatment of various fundamental underpinning topics in machine learning, and adjacent areas of (computational) mathematics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10523v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eviatar Bach, Ricardo Baptista, Daniel Sanz-Alonso, Andrew Stuart</dc:creator>
    </item>
    <item>
      <title>Generalized Separation of Collections of Sets</title>
      <link>https://arxiv.org/abs/2412.05336</link>
      <description>arXiv:2412.05336v2 Announce Type: replace-cross 
Abstract: We show that the existing generalized separation statements including the conventional extremal principle and its extensions differ {in the ways norms on product spaces are defined}. We prove a general separation statement with arbitrary product norms covering the existing results of this kind. The proof is divided into a series of claims and exposes the key steps and arguments used when proving generalized separation statements. As an application, we prove dual necessary (sufficient) conditions for an abstract product norm extension of the approximate stationarity (transversality) property.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05336v2</guid>
      <category>math.FA</category>
      <category>math.OC</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1080/02331934.2025.2562434</arxiv:DOI>
      <dc:creator>Nguyen Duy Cuong, Alexander Y. Kruger</dc:creator>
    </item>
    <item>
      <title>MAGPIE: Multilevel-Adaptive-Guided Solver for Ptychographic Phase Retrieval</title>
      <link>https://arxiv.org/abs/2504.10118</link>
      <description>arXiv:2504.10118v5 Announce Type: replace-cross 
Abstract: We introduce MAGPIE (Multilevel-Adaptive-Guided Ptychographic Iterative Engine), a stochastic multigrid solver for the ptychographic phase-retrieval problem. The ptychographic phase-retrieval problem is inherently nonconvex and ill-posed. To address these challenges, we reformulate the original nonlinear and nonconvex inverse problem as the iterative minimization of a quadratic surrogate model that majorizes the original objective. This surrogate not only ensures favorable convergence properties but also generalizes the Ptychographic Iterative Engine (PIE) family of algorithms. By solving the surrogate model using a multigrid method, MAGPIE achieves substantial gains in convergence speed and reconstruction quality over traditional approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.10118v5</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Borong Zhang, Qin Li, Zichao Wendy Di</dc:creator>
    </item>
    <item>
      <title>Quadrature rules with few nodes supported on algebraic curves</title>
      <link>https://arxiv.org/abs/2509.06643</link>
      <description>arXiv:2509.06643v2 Announce Type: replace-cross 
Abstract: We investigate quadrature rules for measures supported on real algebraic and rational curves, focusing on the {odd-degree} case \(2s-1\). Adopting an optimization viewpoint, we minimize suitable penalty functions over the space of quadrature rules of strength \(2s-1\), so that optimal solutions yield rules with the minimal number of nodes. For plane algebraic curves of degree \(d\), we derive explicit node bounds depending on \(d\) and the number of places at infinity, improving results of Riener--Schweighofer, and Zalar. For rational curves in arbitrary dimension of degree \(d\), we further refine these bounds using the geometry of the parametrization and recover the classical Gaussian quadrature bound when \(d=1\). Our results reveal a direct link between the algebraic complexity of the supporting curve and the minimal size of quadrature formulas, providing a unified framework that connects real algebraic geometry, polynomial optimization, and moment theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.06643v2</guid>
      <category>math.AG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cordian Riener, Ettore Teixeira Turatti</dc:creator>
    </item>
    <item>
      <title>Smooth hyperbolicity cones are second-order cone representable</title>
      <link>https://arxiv.org/abs/2509.17121</link>
      <description>arXiv:2509.17121v2 Announce Type: replace-cross 
Abstract: Netzer and Sanyal proved that every smooth hyperbolicity cone is a spectrahedral shadow. We generalize and sharpen this result at the same time, by showing that every Nash-smooth hyperbolicity cone is even second-order cone representable (socr). The result is proved as a consequence of our second theorem, according to which every compact convex semialgebraic set with Nash-smooth boundary of strict positive curvature is socr. The proof uses the technique of tensor evaluation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.17121v2</guid>
      <category>math.AG</category>
      <category>math.OC</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Claus Scheiderer</dc:creator>
    </item>
    <item>
      <title>Muon Outperforms Adam in Tail-End Associative Memory Learning</title>
      <link>https://arxiv.org/abs/2509.26030</link>
      <description>arXiv:2509.26030v2 Announce Type: replace-cross 
Abstract: The Muon optimizer is consistently faster than Adam in training Large Language Models (LLMs), yet the mechanism underlying its success remains unclear. This paper demystifies this mechanism through the lens of associative memory. By ablating the transformer components optimized by Muon, we reveal that the associative memory parameters of LLMs, namely the Value and Output (VO) attention weights and Feed-Forward Networks (FFNs), are the primary contributors to Muon's superiority. Motivated by this associative memory view, we then explain Muon's superiority on real-world corpora, which are intrinsically heavy-tailed: a few classes (tail classes) appear far less frequently than others. The superiority is explained through two key properties: (i) its update rule consistently yields a more isotropic singular spectrum than Adam; and as a result, (ii) on heavy-tailed data, it optimizes tail classes more effectively than Adam. Beyond empirical evidence, we theoretically confirm these findings by analyzing a one-layer associative memory model under class-imbalanced data. We prove that Muon consistently achieves balanced learning across classes regardless of feature embeddings, whereas Adam can induce large disparities in learning errors depending on embedding properties. In summary, our empirical observations and theoretical analyses reveal Muon's core advantage: its update rule aligns with the outer-product structure of linear associative memories, enabling more balanced and effective learning of tail classes in heavy-tailed distributions than Adam.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.26030v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shuche Wang, Fengzhuo Zhang, Jiaxiang Li, Cunxiao Du, Chao Du, Tianyu Pang, Zhuoran Yang, Mingyi Hong, Vincent Y. F. Tan</dc:creator>
    </item>
  </channel>
</rss>
