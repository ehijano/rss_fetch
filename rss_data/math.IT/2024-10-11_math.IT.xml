<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.IT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.IT</link>
    <description>math.IT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.IT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 11 Oct 2024 04:00:19 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>An Analysis of Minimum Error Entropy Loss Functions in Wireless Communications</title>
      <link>https://arxiv.org/abs/2410.07208</link>
      <description>arXiv:2410.07208v1 Announce Type: new 
Abstract: This paper introduces the minimum error entropy (MEE) criterion as an advanced information-theoretic loss function tailored for deep learning applications in wireless communications. The MEE criterion leverages higher-order statistical properties, offering robustness in noisy scenarios like Rayleigh fading and impulsive interference. In addition, we propose a less computationally complex version of the MEE function to enhance practical usability in wireless communications. The method is evaluated through simulations on two critical applications: over-the-air regression and indoor localization. Results indicate that the MEE criterion outperforms conventional loss functions, such as mean squared error (MSE) and mean absolute error (MAE), achieving significant performance improvements in terms of accuracy, over $20 \%$ gain over traditional methods, and convergence speed across various channel conditions. This work establishes MEE as a promising alternative for wireless communication tasks in deep learning models, enabling better resilience and adaptability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07208v1</guid>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rumeshika Pallewela, Eslam Eldeeb, Hirley Alves</dc:creator>
    </item>
    <item>
      <title>Hull's Parameters of Projective Reed-Muller Code</title>
      <link>https://arxiv.org/abs/2410.07217</link>
      <description>arXiv:2410.07217v1 Announce Type: new 
Abstract: Projective Reed-Muller codes(PRM codes) are constructed from the family of projective hypersurfaces of a fixed degree over a finite field $\F_q$. In this paper, we completely determine the minimal distance of the hull of any Projective Reed-Muller codes. Motivated by Nathan Kaplan and Jon-Lark Kim \cite{kaplankim},we extend their results and calculate the hulls' dimension of Projective Reed-Muller Codes in a larger range. We also analyse two special classes of PRM codes apart from self-dual,self-orthgonal and LCD cases, which Kaplan and Kim \cite[section 3]{kaplankim} didn't consider.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07217v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yufeng Song, Jinquan Luo</dc:creator>
    </item>
    <item>
      <title>CKMImageNet: A Comprehensive Dataset to Enable Channel Knowledge Map Construction via Computer Vision</title>
      <link>https://arxiv.org/abs/2410.07219</link>
      <description>arXiv:2410.07219v1 Announce Type: new 
Abstract: Environment-aware communication and sensing is one of the promising paradigm shifts towards 6G, which fully leverages prior information of the local wireless environment to optimize network performance. One of the key enablers for environment-aware communication and sensing is channel knowledge map (CKM), which provides location-specific channel knowledge that is crucial for channel state information (CSI) acquisition. To support the efficient construction of CKM, large-scale location-specific channel data is essential. However, most existing channel datasets do not have the location information nor visual representations of channel data, making them inadequate for exploring the intrinsic relationship between the channel knowledge and the local environment, nor for applying advanced artificial intelligence (AI) algorithms such as computer vision (CV) for CKM construction. To address such issues, in this paper, a large-scale dataset named CKMImageNet is established, which can provide both location-tagged numerical channel data and visual images, providing a holistic view of the channel and environment. Built using commercial ray tracing software, CKMImageNet captures electromagnetic wave propagation in different scenarios, revealing the relationships between location, environment and channel knowledge. By integrating detailed channel data and the corresponding image, CKMImageNet not only supports the verification of various communication and sensing algorithms, but also enables CKM construction with CV algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07219v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Di Wu, Zijian Wu, Yuelong Qiu, Shen Fu, Yong Zeng</dc:creator>
    </item>
    <item>
      <title>MIMO MAC Empowered by Reconfigurable Intelligent Surfaces: Capacity Region and Large System Analysis</title>
      <link>https://arxiv.org/abs/2410.07389</link>
      <description>arXiv:2410.07389v1 Announce Type: new 
Abstract: Smart wireless environments enabled by multiple distributed Reconfigurable Intelligent Surfaces (RISs) have recently attracted significant research interest as a wireless connectivity paradigm for sixth Generation (6G) networks. In this paper, using random matrix theory methods, we calculate the mean of the sum Mutual Information (MI) for the correlated Multiple-Input Multiple-Output (MIMO) Multiple Access Channel (MAC) in the presence of multiple RISs, in the large-antenna number limit. We thus obtain the capacity region boundaries, after optimizing over the tunable RISs' phase configurations. Furthermore, we obtain a closed-form expression for the variance of the sum-MI metric, which together with the mean provides a tight Gaussian approximation for the outage probability. The derived results become relevant in the presence of fast-fading, when channel estimation is extremely challenging. Our numerical investigations showcased that, when the angle-spread in the neighborhood of each RIS is small, which is expected for higher carrier frequencies, the communication link strongly improves from optimizing the ergodic MI of the multiple RISs.We also found that, increasing the number of transmitting users in such MIMO-MAC-RIS systems results to rapidly diminishing sum-MI gains, hence, providing limits on the number of users that can be efficiently served by a given RIS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07389v1</guid>
      <category>cs.IT</category>
      <category>cs.ET</category>
      <category>math.IT</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Aris L. Moustakas, George C. Alexandropoulos</dc:creator>
    </item>
    <item>
      <title>Improving Numerical Stability of Normalized Mutual Information Estimator on High Dimensions</title>
      <link>https://arxiv.org/abs/2410.07642</link>
      <description>arXiv:2410.07642v1 Announce Type: new 
Abstract: Mutual information provides a powerful, general-purpose metric for quantifying the amount of shared information between variables. Estimating normalized mutual information using a k-Nearest Neighbor (k-NN) based approach involves the calculation of the scaling-invariant k-NN radius. Calculation of the radius suffers from numerical overflow when the joint dimensionality of the data becomes high, typically in the range of several hundred dimensions. To address this issue, we propose a logarithmic transformation technique that improves the numerical stability of the radius calculation in high-dimensional spaces. By applying the proposed transformation during the calculation of the radius, numerical overflow is avoided, and precision is maintained. Proposed transformation is validated through both theoretical analysis and empirical evaluation, demonstrating its ability to stabilize the calculation without compromizing the precision of the results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07642v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marko Tuononen, Ville Hautam\"aki</dc:creator>
    </item>
    <item>
      <title>Collision Diversity SCRAM: Beyond the Sphere-Packing Bound</title>
      <link>https://arxiv.org/abs/2410.07887</link>
      <description>arXiv:2410.07887v1 Announce Type: new 
Abstract: This paper presents a novel scheme dubbed Collision Diversity (CoD) SCRAM, which is provisioned to meet the challenging requirements of the future 6G, portrayed in massive connectivity, reliability, and ultra-low latency. The conventional SCRAM mechanism, which stands for Slotted Coded Random Access Multiplexing, is a hybrid decoding scheme, that jointly resolves collisions and decodes the Low Density Parity Check (LDPC) codewords, in a similar analogy to Belief Propagation (BP) decoding on a joint three-layer Tanner graph. The CoD SCRAM proposed herein tends to enhance the performance of SCRAM by adopting an information-theoretic approach that tends to maximize the attainable Spectral Efficiency. Besides, due to the analogy between the two-layer Tanner graph of classical LDPC codes, and the three-layer Tanner graph of SCRAM, the CoD SCRAM adopts the well-developed tools utilized to design powerful LDPC codes. Finally, the proposed CoD scheme tends to leverage the collisions among the users in order to induce diversity. Results show that the proposed CoD SCRAM scheme surpasses the conventional SCRAM scheme, which is superior to the state-of-the-art Non-Orthogonal Multiple Access (NOMA) schemes. Additionally, by leveraging the collisions, the CoD SCRAM tends to surpass the Sphere-Packing Bound (SPB) at the respective information block length of the underlying LDPC codes of the accommodated users.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07887v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sally Nafie, Joerg Robert, Albert Heuberger</dc:creator>
    </item>
    <item>
      <title>Minimal Trellises for non-Degenerate and Degenerate Decoding of Quantum Stabilizer Codes</title>
      <link>https://arxiv.org/abs/2410.07897</link>
      <description>arXiv:2410.07897v1 Announce Type: new 
Abstract: This paper presents a comprehensive guide to designing minimal trellises for both non-degenerate and degenerate decoding of quantum stabilizer codes. For non-degenerate decoding, various strategies are explored, leveraging insights from classical rectangular codes to minimize the complexity associated with the non-degenerate maximum likelihood error estimation using the Viterbi algorithm. Additionally, novel techniques for constructing minimal multi-goal trellises for degenerate decoding are introduced, including a merging algorithm, a Shannon-product approach, and the BCJR-Wolf method. The study establishes essential properties of multi-goal trellises and provides bounds on the decoding complexity using the sum-product Viterbi decoding algorithm. These advancements decrease the decoding complexity by a factor $\mathcal{O}(n)$, where $n$ is the code length. Finally, the paper applies these results to CSS codes and demonstrates a reduction in complexity by independently applying degenerate decoding to $X$ and $Z$ errors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07897v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Evagoras Stylianou, Vladimir Sidorenko, Christian Deppe, Holger Boche</dc:creator>
    </item>
    <item>
      <title>Distributed Source Coding, Multiple Description Coding, and Source Coding with Side Information at Decoders Using Constrained-Random Number Generators</title>
      <link>https://arxiv.org/abs/2410.07939</link>
      <description>arXiv:2410.07939v1 Announce Type: new 
Abstract: This paper investigates a unification of distributed source coding, multiple description coding, and source coding with side information at decoders. The equivalence between the multiple-decoder extension of distributed source coding with decoder side information and the multiple-source extension of multiple description coding with decoder side information is clarified. Their multi-letter rate-distortion region for arbitrary general correlated sources is characterized in terms of entropy functions. We construct a code based on constrained-random number generators and show its achievability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07939v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jun Muramatsu</dc:creator>
    </item>
    <item>
      <title>Large Deviation Analysis for the Reverse Shannon Theorem</title>
      <link>https://arxiv.org/abs/2410.07984</link>
      <description>arXiv:2410.07984v1 Announce Type: new 
Abstract: Channel simulation is to simulate a noisy channel using noiseless channels with unlimited shared randomness. This can be interpreted as the reverse problem to Shannon's noisy coding theorem. In contrast to previous works, our approach employs R\'enyi divergence (with the parameter $\alpha\in(0,\infty)$) to measure the level of approximation. Specifically, we obtain the reverse Shannon theorem under the R\'enyi divergence, which characterizes the R\'enyi simulation rate, the minimum communication cost rate required for the R\'enyi divergence vanishing asymptotically. We also investigate the behaviors of the R\'enyi divergence when the communication cost rate is above or below the R\'enyi simulation rate. When the communication cost rate is above the R\'enyi simulation rate, we provide a complete characterization of the convergence exponent, called the reliability function. When the communication cost rate is below the R\'enyi simulation rate, we determine the linear increasing rate for the R\'enyi divergence with parameter $\alpha\in(0,\infty]$, which implies the strong converse exponent for the $\alpha$-order fidelity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07984v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shi-Bing Li, Ke Li, Lei Yu</dc:creator>
    </item>
    <item>
      <title>A Graphical Correlation-Based Method for Counting the Number of Global 8-Cycles on the SCRAM Three-Layer Tanner Graph</title>
      <link>https://arxiv.org/abs/2410.07998</link>
      <description>arXiv:2410.07998v1 Announce Type: new 
Abstract: This paper presents a novel graphical approach that counts the number of global 8-cycles on the SCRAM three-layer Tanner graph. SCRAM, which stands for Slotted Coded Random Access Multiplexing, is a joint decoder that is meets challenging requirements of 6G. At the transmitter side, the data of the accommodated users is encoded by Low Density Parity Check (LDPC) codes, and the codewords are transmitted over the shared channel by means of Slotted ALOHA. Unlike the state-of-the-art sequential decoders, the SCRAM decoder jointly resolves collisions and decodes the LDPC codewords, in a similar analogy to Belief Propagation on a three-layer Tanner graph. By leveraging the analogy between the two-layer Tanner graph of conventional LDPC codes and the three-layer Tanner graph of SCRAM, the well-developed analysis tools of classical LDPC codes could be utilized to enhance the performance of SCRAM. In essence, the contribution of this paper is three-fold; First it proposes the methodology to utilize these tools to assess the performance of SCRAM. Second, it derives a lower bound on the shortest cycle length of an arbitrary SCRAM Tanner graph. Finally, the paper presents a novel graphical method that counts the number of cycles of length that corresponds to the girth.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07998v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sally Nafie, Joerg Robert, Albert Heuberger</dc:creator>
    </item>
    <item>
      <title>Timely NextG Communications with Decoy Assistance against Deep Learning-based Jamming</title>
      <link>https://arxiv.org/abs/2410.08045</link>
      <description>arXiv:2410.08045v1 Announce Type: new 
Abstract: We consider the transfer of time-sensitive information in next-generation (NextG) communication systems in the presence of a deep learning based eavesdropper capable of jamming detected transmissions, subject to an average power budget. A decoy-based anti-jamming strategy is presented to confuse a jammer, causing it to waste power when disrupting decoy messages instead of real messages. We investigate the effectiveness of the anti-jamming strategy to guarantee timeliness of NextG communications in addition to reliability objectives, analyzing the Age of Information subject to jamming and channel effects. We assess the effect of power control, which determines the success of a transmission but also affects the accuracy of the adversary's detection, making it more likely for the jammer to successfully identify and jam the communication. The results demonstrate the feasibility of mitigating eavesdropping and jamming attacks in NextG communications with information freshness objectives using a decoy to guarantee timely information transfer.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08045v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/ICCWorkshops59551.2024.10615460</arxiv:DOI>
      <arxiv:journal_reference>Proc. 2024 IEEE International Conference on Communications Workshops, pp.554-559. %\thanks{Peer-reviewed version in Proc. 2024 IEEE International Conference on Communications Workshops (ICC Workshops), Denver, CO, USA, 2024, pp. 554-559</arxiv:journal_reference>
      <dc:creator>Maice Costa, Yalin E. Sagduyu</dc:creator>
    </item>
    <item>
      <title>On the Second-Order Achievabilities of Indirect Quadratic Lossy Source Coding</title>
      <link>https://arxiv.org/abs/2410.08110</link>
      <description>arXiv:2410.08110v1 Announce Type: new 
Abstract: This paper studies the second-order achievabilities of indirect quadratic lossy source coding for a specific class of source models, where the term "quadratic" denotes that the reconstruction fidelity of the hidden source is quantified by a squared error distortion measure. Specifically, it is assumed that the hidden source $S$ can be expressed as $S = \varphi(X) + W$, where $X$ is the observable source with alphabet $\mathcal{X}$, $\varphi(\cdot)$ is a deterministic function, and $W$ is a random variable independent of $X$, satisfying $\mathbb{E}[W] = 0$, $\mathbb{E}[W^2] &gt; 0$, $\mathbb{E}[W^3] = 0$, and $\mathbb{E}[W^6] &lt; \infty$. Additionally, both the set $\{\varphi(x):\ x \in \mathcal{X} \}$ and the reconstruction alphabet for $S$ are assumed to be bounded. Under the above settings, a second-order achievability bound is established using techniques based on distortion-tilted information. This result is then generalized to the case of indirect quadratic lossy source coding with observed source reconstruction, where reconstruction is required for both the hidden source $S$ and the observable source $X$, and the distortion measure for $X$ is not necessarily quadratic. These obtained bounds are consistent in form with their finite-alphabet counterparts, which have been proven to be second-order tight.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08110v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Huiyuan Yang, Xiaojun Yuan</dc:creator>
    </item>
    <item>
      <title>How Much Power Must We Extract From a Receiver Antenna to Effect Communications?</title>
      <link>https://arxiv.org/abs/2410.07393</link>
      <description>arXiv:2410.07393v1 Announce Type: cross 
Abstract: Subject to the laws of classical physics - the science that governs the design of today's wireless communication systems - there is no need to extract power from a receiver antenna in order to effect communications. If we dispense with a transmission line and, instead, make the front-end electronics colocated with the antenna, then a high input-impedance preamplifier can measure the open-circuit voltage directly on the antenna port without drawing either current or power. Neither Friis' concept of noise figure, nor Shannon information theory, nor electronics technology dictates that we must extract power from an antenna.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07393v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas L. Marzetta, Brian McMinn, Amritpal Singh, Thorkild B. Hansen</dc:creator>
    </item>
    <item>
      <title>Hybrid Summary Statistics</title>
      <link>https://arxiv.org/abs/2410.07548</link>
      <description>arXiv:2410.07548v1 Announce Type: cross 
Abstract: We present a way to capture high-information posteriors from training sets that are sparsely sampled over the parameter space for robust simulation-based inference. In physical inference problems, we can often apply domain knowledge to define traditional summary statistics to capture some of the information in a dataset. We show that augmenting these statistics with neural network outputs to maximise the mutual information improves information extraction compared to neural summaries alone or their concatenation to existing summaries and makes inference robust in settings with low training data. We introduce 1) two loss formalisms to achieve this and 2) apply the technique to two different cosmological datasets to extract non-Gaussian parameter information.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07548v1</guid>
      <category>stat.ML</category>
      <category>astro-ph.CO</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>physics.data-an</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>T. Lucas Makinen, Ce Sui, Benjamin D. Wandelt, Natalia Porqueres, Alan Heavens</dc:creator>
    </item>
    <item>
      <title>Geometric structure and transversal logic of quantum Reed-Muller codes</title>
      <link>https://arxiv.org/abs/2410.07595</link>
      <description>arXiv:2410.07595v1 Announce Type: cross 
Abstract: Designing efficient and noise-tolerant quantum computation protocols generally begins with an understanding of quantum error-correcting codes and their native logical operations. The simplest class of native operations are transversal gates, which are naturally fault-tolerant. In this paper, we aim to characterize the transversal gates of quantum Reed-Muller (RM) codes by exploiting the well-studied properties of their classical counterparts. We start our work by establishing a new geometric characterization of quantum RM codes via the Boolean hypercube and its associated subcube complex. More specifically, a set of stabilizer generators for a quantum RM code can be described via transversal $X$ and $Z$ operators acting on subcubes of particular dimensions. This characterization leads us to define subcube operators composed of single-qubit $\pi/2^k$ $Z$-rotations that act on subcubes of given dimensions. We first characterize the action of subcube operators on the code space: depending on the dimension of the subcube, these operators either (1) act as a logical identity on the code space, (2) implement non-trivial logic, or (3) rotate a state away from the code space. Second, and more remarkably, we uncover that the logic implemented by these operators corresponds to circuits of multi-controlled-$Z$ gates that have an explicit and simple combinatorial description. Overall, this suite of results yields a comprehensive understanding of a class of natural transversal operators for quantum RM codes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07595v1</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.CO</category>
      <category>math.IT</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Barg, Nolan J. Coble, Dominik Hangleiter, Christopher Kang</dc:creator>
    </item>
    <item>
      <title>An Analysis of XML Compression Efficiency</title>
      <link>https://arxiv.org/abs/2410.07603</link>
      <description>arXiv:2410.07603v1 Announce Type: cross 
Abstract: XML simplifies data exchange among heterogeneous computers, but it is notoriously verbose and has spawned the development of many XML-specific compressors and binary formats. We present an XML test corpus and a combined efficiency metric integrating compression ratio and execution speed. We use this corpus and linear regression to assess 14 general-purpose and XML-specific compressors relative to the proposed metric. We also identify key factors when selecting a compressor. Our results show XMill or WBXML may be useful in some instances, but a general-purpose compressor is often the best choice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07603v1</guid>
      <category>cs.DB</category>
      <category>cs.IT</category>
      <category>cs.PF</category>
      <category>math.IT</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <arxiv:DOI>10.1145/1281700.1281707</arxiv:DOI>
      <arxiv:journal_reference>Proceedings of the 2007 workshop on Experimental Computer Science (ExpCS) at ACM FCRC 2007</arxiv:journal_reference>
      <dc:creator>Christopher James Augeri, Barry E. Mullins, Leemon C. Baird III, Dursun A. Bulutoglu, Rusty O. Baldwin</dc:creator>
    </item>
    <item>
      <title>The Plug-in Approach for Average-Reward and Discounted MDPs: Optimal Sample Complexity Analysis</title>
      <link>https://arxiv.org/abs/2410.07616</link>
      <description>arXiv:2410.07616v1 Announce Type: cross 
Abstract: We study the sample complexity of the plug-in approach for learning $\varepsilon$-optimal policies in average-reward Markov decision processes (MDPs) with a generative model. The plug-in approach constructs a model estimate then computes an average-reward optimal policy in the estimated model. Despite representing arguably the simplest algorithm for this problem, the plug-in approach has never been theoretically analyzed. Unlike the more well-studied discounted MDP reduction method, the plug-in approach requires no prior problem information or parameter tuning. Our results fill this gap and address the limitations of prior approaches, as we show that the plug-in approach is optimal in several well-studied settings without using prior knowledge. Specifically it achieves the optimal diameter- and mixing-based sample complexities of $\widetilde{O}\left(SA \frac{D}{\varepsilon^2}\right)$ and $\widetilde{O}\left(SA \frac{\tau_{\mathrm{unif}}}{\varepsilon^2}\right)$, respectively, without knowledge of the diameter $D$ or uniform mixing time $\tau_{\mathrm{unif}}$. We also obtain span-based bounds for the plug-in approach, and complement them with algorithm-specific lower bounds suggesting that they are unimprovable. Our results require novel techniques for analyzing long-horizon problems which may be broadly useful and which also improve results for the discounted plug-in approach, removing effective-horizon-related sample size restrictions and obtaining the first optimal complexity bounds for the full range of sample sizes without reward perturbation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07616v1</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matthew Zurek, Yudong Chen</dc:creator>
    </item>
    <item>
      <title>Almost Minimax Optimal Best Arm Identification in Piecewise Stationary Linear Bandits</title>
      <link>https://arxiv.org/abs/2410.07638</link>
      <description>arXiv:2410.07638v1 Announce Type: cross 
Abstract: We propose a {\em novel} piecewise stationary linear bandit (PSLB) model, where the environment randomly samples a context from an unknown probability distribution at each changepoint, and the quality of an arm is measured by its return averaged over all contexts. The contexts and their distribution, as well as the changepoints are unknown to the agent. We design {\em Piecewise-Stationary $\varepsilon$-Best Arm Identification$^+$} (PS$\varepsilon$BAI$^+$), an algorithm that is guaranteed to identify an $\varepsilon$-optimal arm with probability $\ge 1-\delta$ and with a minimal number of samples. PS$\varepsilon$BAI$^+$ consists of two subroutines, PS$\varepsilon$BAI and {\sc Na\"ive $\varepsilon$-BAI} (N$\varepsilon$BAI), which are executed in parallel. PS$\varepsilon$BAI actively detects changepoints and aligns contexts to facilitate the arm identification process. When PS$\varepsilon$BAI and N$\varepsilon$BAI are utilized judiciously in parallel, PS$\varepsilon$BAI$^+$ is shown to have a finite expected sample complexity. By proving a lower bound, we show the expected sample complexity of PS$\varepsilon$BAI$^+$ is optimal up to a logarithmic factor. We compare PS$\varepsilon$BAI$^+$ to baseline algorithms using numerical experiments which demonstrate its efficiency. Both our analytical and numerical results corroborate that the efficacy of PS$\varepsilon$BAI$^+$ is due to the delicate change detection and context alignment procedures embedded in PS$\varepsilon$BAI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07638v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>stat.ML</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yunlong Hou, Vincent Y. F. Tan, Zixin Zhong</dc:creator>
    </item>
    <item>
      <title>Optimal additive quaternary codes of dimension $3.5$</title>
      <link>https://arxiv.org/abs/2410.07650</link>
      <description>arXiv:2410.07650v1 Announce Type: cross 
Abstract: After the optimal parameters of additive quaternary codes of dimension $k\le 3$ have been determined there is some recent activity to settle the next case of dimension $k=3.5$. Here we complete dimension $k=3.5$ and give partial results for dimension $k=4$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07650v1</guid>
      <category>math.CO</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sascha Kurz</dc:creator>
    </item>
    <item>
      <title>Theoretical limits of descending $\ell_0$ sparse-regression ML algorithms</title>
      <link>https://arxiv.org/abs/2410.07651</link>
      <description>arXiv:2410.07651v1 Announce Type: cross 
Abstract: We study the theoretical limits of the $\ell_0$ (quasi) norm based optimization algorithms when employed for solving classical compressed sensing or sparse regression problems. Considering standard contexts with deterministic signals and statistical systems, we utilize \emph{Fully lifted random duality theory} (Fl RDT) and develop a generic analytical program for studying performance of the \emph{maximum-likelihood} (ML) decoding. The key ML performance parameter, the residual \emph{root mean square error} ($\textbf{RMSE}$), is uncovered to exhibit the so-called \emph{phase-transition} (PT) phenomenon. The associated aPT curve, which separates the regions of systems dimensions where \emph{an} $\ell_0$ based algorithm succeeds or fails in achieving small (comparable to the noise) ML optimal $\textbf{RMSE}$ is precisely determined as well. In parallel, we uncover the existence of another dPT curve which does the same separation but for practically feasible \emph{descending} $\ell_0$ ($d\ell_0$) algorithms. Concrete implementation and practical relevance of the Fl RDT typically rely on the ability to conduct a sizeable set of the underlying numerical evaluations which reveal that for the ML decoding the Fl RDT converges astonishingly fast with corrections in the estimated quantities not exceeding $\sim 0.1\%$ already on the third level of lifting. Analytical results are supplemented by a sizeable set of numerical experiments where we implement a simple variant of $d\ell_0$ and demonstrate that its practical performance very accurately matches the theoretical predictions. Completely surprisingly, a remarkably precise agreement between the simulations and the theory is observed for fairly small dimensions of the order of 100.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07651v1</guid>
      <category>stat.ML</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mihailo Stojnic</dc:creator>
    </item>
    <item>
      <title>Learning to Compress: Local Rank and Information Compression in Deep Neural Networks</title>
      <link>https://arxiv.org/abs/2410.07687</link>
      <description>arXiv:2410.07687v1 Announce Type: cross 
Abstract: Deep neural networks tend to exhibit a bias toward low-rank solutions during training, implicitly learning low-dimensional feature representations. This paper investigates how deep multilayer perceptrons (MLPs) encode these feature manifolds and connects this behavior to the Information Bottleneck (IB) theory. We introduce the concept of local rank as a measure of feature manifold dimensionality and demonstrate, both theoretically and empirically, that this rank decreases during the final phase of training. We argue that networks that reduce the rank of their learned representations also compress mutual information between inputs and intermediate layers. This work bridges the gap between feature manifold rank and information compression, offering new insights into the interplay between information bottlenecks and representation learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07687v1</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Niket Patel, Ravid Shwartz-Ziv</dc:creator>
    </item>
    <item>
      <title>Optimality of meta-converse for channel simulation</title>
      <link>https://arxiv.org/abs/2410.08140</link>
      <description>arXiv:2410.08140v1 Announce Type: cross 
Abstract: We study the effect of shared non-signaling correlations for the problem of simulating a channel using noiseless communication in the one-shot setting. For classical channels, we show how to round any non-signaling-assisted simulation strategy--which corresponds to the natural linear programming meta-converse for channel simulation--to a strategy that only uses shared randomness. For quantum channels, we round any non-signaling-assisted simulation strategy to a strategy that only uses shared entanglement. Our main result is for classical and classical-quantum channels, for which we employ ideas from approximation algorithms to give a guarantee on the ratio of success probabilities of at least $(1-\mathrm{e}^{-1})$. We further show this ratio to be optimal for the purely classical case. It can be improved to $(1-t^{-1})$ using $O(\ln \ln(t))$ additional bits of communication.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08140v1</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aadil Oufkir, Omar Fawzi, Mario Berta</dc:creator>
    </item>
    <item>
      <title>Optimal Strategies for Winning Certain Coset-Guessing Quantum Games</title>
      <link>https://arxiv.org/abs/2410.08160</link>
      <description>arXiv:2410.08160v1 Announce Type: cross 
Abstract: In a recently introduced coset guessing game, Alice plays against Bob and Charlie, aiming to meet a joint winning condition. Bob and Charlie can only communicate before the game starts to devise a joint strategy. The game we consider begins with Alice preparing a 2m-qubit quantum state based on a random selection of three parameters. She sends the first m qubits to Bob and the rest to Charlie and then reveals to them her choice for one of the parameters. Bob is supposed to guess one of the hidden parameters, Charlie the other, and they win if both guesses are correct. From previous work, we know that the probability of Bob's and Charlie's guesses being simultaneously correct goes to zero exponentially as m increases. We derive a tight upper bound on this probability and show how Bob and Charlie can achieve it. While developing the optimal strategy, we devised an encoding circuit using only CNOT and Hadamard gates, which could be relevant for building efficient CSS-coded systems. We found that the role of quantum information that Alice communicates to Bob and Charlie is to make their responses correlated rather than improve their individual (marginal) correct guessing rates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08160v1</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Schleppy, Emina Soljanin, Nicolas Swanson</dc:creator>
    </item>
    <item>
      <title>On the Fundamental Tradeoff of Joint Communication and Quickest Change Detection with State-Independent Data Channels</title>
      <link>https://arxiv.org/abs/2401.12499</link>
      <description>arXiv:2401.12499v2 Announce Type: replace 
Abstract: In this work, we take the initiative in studying the information-theoretic tradeoff between communication and quickest change detection (QCD) under an integrated sensing and communication setting. We formally establish a joint communication and sensing problem for the quickest change detection. We assume a broadcast channel with a transmitter, a communication receiver, and a QCD detector in which only the detection channel is state dependent. For the problem setting, by utilizing constant subblock-composition codes and a modified CuSum detection rule, which we call subblock CuSum (SCS), we provide an inner bound on the information-theoretic tradeoff between communication rate and change point detection delay in the asymptotic regime of vanishing false alarm rate. We further provide a partial converse that matches our inner bound for a certain class of codes. This implies that the SCS detection strategy is asymptotically optimal for our codes as the false alarm rate constraint vanishes. We also present some canonical examples of the tradeoff region for a binary channel, a scalar Gaussian channel, and a MIMO Gaussian channel.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.12499v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daewon Seo, Sung Hoon Lim</dc:creator>
    </item>
    <item>
      <title>Analytical Characterization of the Operational Diversity Order in Fading Channels</title>
      <link>https://arxiv.org/abs/2405.09336</link>
      <description>arXiv:2405.09336v2 Announce Type: replace 
Abstract: We introduce and characterize the operational diversity order (ODO) in fading channels, as a proxy to the classical notion of diversity order at any arbitrary operational signal-to-noise ratio (SNR). Thanks to this definition, relevant insights are brought up in a number of cases: (i) We quantify that in dominant line-of-sight scenarios an increased diversity order is attainable compared to that achieved asymptotically, even in the single-antenna case; (ii) this effect is attenuated, but still visible, in the presence of an additional dominant specular component; (iii) the decay slope in Rayleigh product channels increases very slowly, never fully achieving unitary slope for a finite SNR.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.09336v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Santiago Fern\'andez, J. Alfonso Bail\'on-Mart\'inez, Juan E. Galeote-Cazorla, F. Javier L\'opez-Mart\'inez</dc:creator>
    </item>
    <item>
      <title>Asynchronous MIMO-OFDM Massive Unsourced Random Access with Codeword Collisions</title>
      <link>https://arxiv.org/abs/2405.11883</link>
      <description>arXiv:2405.11883v2 Announce Type: replace 
Abstract: This paper investigates asynchronous multiple-input multiple-output (MIMO) massive unsourced random access (URA) in an orthogonal frequency division multiplexing (OFDM) system over frequency-selective fading channels, with the presence of both timing and carrier frequency offsets (TO and CFO) and non-negligible codeword collisions. The proposed coding framework segregates the data into two components, namely, preamble and coding parts, with the former being tree-coded and the latter LDPC-coded. By leveraging the dual sparsity of the equivalent channel across both codeword and delay domains (CD and DD), we develop a message-passing-based sparse Bayesian learning algorithm, combined with belief propagation and mean field, to iteratively estimate DD channel responses, TO, and delay profiles. Furthermore, by jointly leveraging the observations among multiple slots, we establish a novel graph-based algorithm to iteratively separate the superimposed channels and compensate for the phase rotations. Additionally, the proposed algorithm is applied to the flat fading scenario to estimate both TO and CFO, where the channel and offset estimation is enhanced by leveraging the geometric characteristics of the signal constellation. Extensive simulations reveal that the proposed algorithm achieves superior performance and substantial complexity reduction in both channel and offset estimation compared to the codebook enlarging-based counterparts, and enhanced data recovery performances compared to state-of-the-art URA schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.11883v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tianya Li, Yongpeng Wu, Junyuan Gao, Wenjun Zhang, Xiang-Gen Xia, Derrick Wing Kwan Ng, Chengshan Xiao</dc:creator>
    </item>
    <item>
      <title>Optimal Sensing Policy With Interference-Model Uncertainty</title>
      <link>https://arxiv.org/abs/2406.06280</link>
      <description>arXiv:2406.06280v5 Announce Type: replace 
Abstract: This paper considers a half-duplex scenario where an interferer behaves according to a parametric model but the values of the model parameters are unknown. We explore the necessary number of sensing steps to gather sufficient knowledge about the interferer's behavior. With more sensing steps, the reliability of the model-parameter estimates is improved, thereby enabling more effective link adaptation. However, in each time slot, the communication system experiencing interference must choose between sensing and communication. Thus, we propose to investigate the optimal policy for maximizing the expected sum communication data rate over a finite-time communication. This approach contrasts with most studies on interference management in the literature, which assume that the parameters of the interference model are perfectly known. We begin by showing that the problem under consideration can be modeled within the framework of a Markov decision process (MDP). Following this, we demonstrate that both the optimal open-loop and optimal closed-loop policies can be determined with reduced computational complexity compared to the standard backward-induction algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06280v5</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vincent Corlay, Jean-Christophe Sibel, Nicolas Gresset</dc:creator>
    </item>
    <item>
      <title>Factor Graph Optimization of Error-Correcting Codes for Belief Propagation Decoding</title>
      <link>https://arxiv.org/abs/2406.12900</link>
      <description>arXiv:2406.12900v2 Announce Type: replace 
Abstract: The design of optimal linear block codes capable of being efficiently decoded is of major concern, especially for short block lengths. As near capacity-approaching codes, Low-Density Parity-Check (LDPC) codes possess several advantages over other families of codes, the most notable being its efficient decoding via Belief Propagation. While many LDPC code design methods exist, the development of efficient sparse codes that meet the constraints of modern short code lengths and accommodate new channel models remains a challenge. In this work, we propose for the first time a gradient-based data-driven approach for the design of sparse codes. We develop locally optimal codes with respect to Belief Propagation decoding via the learning of the Factor graph under channel noise simulations. This is performed via a novel complete graph tensor representation of the Belief Propagation algorithm, optimized over finite fields via backpropagation and coupled with an efficient line-search method. The proposed approach is shown to outperform the decoding performance of existing popular codes by orders of magnitude and demonstrates the power of data-driven approaches for code design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12900v2</guid>
      <category>cs.IT</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yoni Choukroun, Lior Wolf</dc:creator>
    </item>
    <item>
      <title>Group Movable Antenna With Flexible Sparsity: Joint Array Position and Sparsity Optimization</title>
      <link>https://arxiv.org/abs/2407.13306</link>
      <description>arXiv:2407.13306v2 Announce Type: replace 
Abstract: Movable antenna (MA) is a promising technology to exploit the spatial variation of wireless channel for performance enhancement, by dynamically varying the antenna position within a certain region. However, for multi-antenna communication systems, moving each antenna independently not only requires prohibitive complexity to find the optimal antenna positions, but also incurs sophisticated movement control in practice. To address this issue, this letter proposes a new MA architecture termed group MA (GMA), enabling the group movement of all elements collectively in a continuous manner, and simultaneously achieving flexible array architecture by antenna selection (AS). In this letter, we focus on the uniform sparse array based GMA, where equally spaced antenna elements are selected to achieve desired array sparsity. The array position and sparsity level are jointly optimized to maximize the sum rate of the multi-user communication system. Numerical results verify the necessity to optimize the position and sparsity of GMA, and considerable performance gain is achieved as compared to the conventional fixed-position antenna (FPA).</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13306v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haiquan Lu, Yong Zeng, Shi Jin, Rui Zhang</dc:creator>
    </item>
    <item>
      <title>Optical ISAC: Fundamental Performance Limits and Transceiver Design</title>
      <link>https://arxiv.org/abs/2408.11792</link>
      <description>arXiv:2408.11792v5 Announce Type: replace 
Abstract: This paper characterizes the optimal capacity-distortion (C-D) tradeoff in an optical point-to-point system with single-input single-output (SISO) for communication and single-input multiple-output (SIMO) for sensing within an integrated sensing and communication (ISAC) framework. We consider the optimal rate-distortion (R-D) region and explore several inner (IB) and outer bounds (OB). We introduce practical, asymptotically optimal maximum a posteriori (MAP) and maximum likelihood estimators (MLE) for target distance, addressing nonlinear measurement-to-state relationships and non-conjugate priors. As the number of sensing antennas increases, these estimators converge to the Bayesian Cram\'er-Rao bound (BCRB). We also establish that the achievable rate-Cram\'er-Rao bound (R-CRB) serves as an OB for the optimal C-D region, valid for both unbiased estimators and asymptotically large numbers of receive antennas. To clarify that the input distribution determines the tradeoff across the Pareto boundary of the C-D region, we propose two algorithms: i) an iterative Blahut-Arimoto algorithm (BAA)-type method, and ii) a memory-efficient closed-form (CF) approach. The CF approach includes a CF optimal distribution for high optical signal-to-noise ratio (O-SNR) conditions. Additionally, we adapt and refine the deterministic-random tradeoff (DRT) to this optical ISAC context.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.11792v5</guid>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alireza Ghazavi Khorasgani (5/6GIC, Institute for Communication Systems), Mahtab Mirmohseni (5/6GIC, Institute for Communication Systems), Ahmed Elzanaty (5/6GIC, Institute for Communication Systems)</dc:creator>
    </item>
    <item>
      <title>Statistically Valid Information Bottleneck via Multiple Hypothesis Testing</title>
      <link>https://arxiv.org/abs/2409.07325</link>
      <description>arXiv:2409.07325v2 Announce Type: replace 
Abstract: The information bottleneck (IB) problem is a widely studied framework in machine learning for extracting compressed features that are informative for downstream tasks. However, current approaches to solving the IB problem rely on a heuristic tuning of hyperparameters, offering no guarantees that the learned features satisfy information-theoretic constraints. In this work, we introduce a statistically valid solution to this problem, referred to as IB via multiple hypothesis testing (IB-MHT), which ensures that the learned features meet the IB constraints with high probability, regardless of the size of the available dataset. The proposed methodology builds on Pareto testing and learn-then-test (LTT), and it wraps around existing IB solvers to provide statistical guarantees on the IB constraints. We demonstrate the performance of IB-MHT on classical and deterministic IB formulations, including experiments on distillation of language models. The results validate the effectiveness of IB-MHT in outperforming conventional methods in terms of statistical robustness and reliability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.07325v2</guid>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Amirmohammad Farzaneh, Osvaldo Simeone</dc:creator>
    </item>
    <item>
      <title>Generalizing Deep Learning-Based CSI Feedback in Massive MIMO via ID-Photo-Inspired Preprocessing</title>
      <link>https://arxiv.org/abs/2409.13494</link>
      <description>arXiv:2409.13494v2 Announce Type: replace 
Abstract: Deep learning (DL)-based channel state information (CSI) feedback has shown great potential in improving spectrum efficiency in massive MIMO systems. However, DL models optimized for specific environments often experience performance degradation in others due to model mismatch. To overcome this barrier in the practical deployment, we propose UniversalNet, an ID-photo-inspired universal CSI feedback framework that enhances model generalizability by standardizing the input format across diverse data distributions. Specifically, UniversalNet employs a standardized input format to mitigate the influence of environmental variability, coupled with a lightweight sparsity-aligning operation in the transformed sparse domain and marginal control bits for original format recovery. This enables seamless integration with existing CSI feedback models, requiring minimal modifications in preprocessing and postprocessing without updating neural network weights. Furthermore, we propose an efficient eigenvector joint optimization method to enhance the sparsity of the precoding matrix by projecting the channel correlation into the eigenspace, thus improving the implicit CSI compression efficiency. Test results demonstrate that UniversalNet effectively improves generalization performance and ensures precise CSI feedback, even in scenarios with limited training diversity and previously unseen CSI environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.13494v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhenyu Liu, Yi Ma, Rahim Tafazolli</dc:creator>
    </item>
    <item>
      <title>Localized Adaptive Risk Control</title>
      <link>https://arxiv.org/abs/2405.07976</link>
      <description>arXiv:2405.07976v3 Announce Type: replace-cross 
Abstract: Adaptive Risk Control (ARC) is an online calibration strategy based on set prediction that offers worst-case deterministic long-term risk control, as well as statistical marginal coverage guarantees. ARC adjusts the size of the prediction set by varying a single scalar threshold based on feedback from past decisions. In this work, we introduce Localized Adaptive Risk Control (L-ARC), an online calibration scheme that targets statistical localized risk guarantees ranging from conditional risk to marginal risk, while preserving the worst-case performance of ARC. L-ARC updates a threshold function within a reproducing kernel Hilbert space (RKHS), with the kernel determining the level of localization of the statistical risk guarantee. The theoretical results highlight a trade-off between localization of the statistical risk and convergence speed to the long-term risk target. Thanks to localization, L-ARC is demonstrated via experiments to produce prediction sets with risk guarantees across different data subpopulations, significantly improving the fairness of the calibrated model for tasks such as image segmentation and beam selection in wireless networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07976v3</guid>
      <category>stat.ML</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Matteo Zecchin, Osvaldo Simeone</dc:creator>
    </item>
    <item>
      <title>Universally Optimal Watermarking Schemes for LLMs: from Theory to Practice</title>
      <link>https://arxiv.org/abs/2410.02890</link>
      <description>arXiv:2410.02890v2 Announce Type: replace-cross 
Abstract: Large Language Models (LLMs) boosts human efficiency but also poses misuse risks, with watermarking serving as a reliable method to differentiate AI-generated content from human-created text. In this work, we propose a novel theoretical framework for watermarking LLMs. Particularly, we jointly optimize both the watermarking scheme and detector to maximize detection performance, while controlling the worst-case Type-I error and distortion in the watermarked text. Within our framework, we characterize the universally minimum Type-II error, showing a fundamental trade-off between detection performance and distortion. More importantly, we identify the optimal type of detectors and watermarking schemes. Building upon our theoretical analysis, we introduce a practical, model-agnostic and computationally efficient token-level watermarking algorithm that invokes a surrogate model and the Gumbel-max trick. Empirical results on Llama-13B and Mistral-8$\times$7B demonstrate the effectiveness of our method. Furthermore, we also explore how robustness can be integrated into our theoretical framework, which provides a foundation for designing future watermarking systems with improved resilience to adversarial attacks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02890v2</guid>
      <category>cs.CR</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haiyun He, Yepeng Liu, Ziqiao Wang, Yongyi Mao, Yuheng Bu</dc:creator>
    </item>
  </channel>
</rss>
