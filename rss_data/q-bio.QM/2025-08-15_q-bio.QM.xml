<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.QM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.QM</link>
    <description>q-bio.QM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.QM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 15 Aug 2025 04:01:26 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>A Structural Analysis of Population Graphs</title>
      <link>https://arxiv.org/abs/2508.10058</link>
      <description>arXiv:2508.10058v1 Announce Type: new 
Abstract: The format of graphing algorithms for genomic data has been a debate in recent biotechnology. In this paper, we discuss the construction of population graphs using said genomic data. We first examine the GENPOFAD distance measurement, developed by Joly et. al., and prove that this constitutes a metric function. We develop an algorithm to construct graphs to visualize the relationships between individuals in a population. We then provide a statistical analysis of these simulated population graphs, and show that they are distinct from randomly generated graphs, and also show differences from small-world graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10058v1</guid>
      <category>q-bio.QM</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kimberly Ayers, Maxwell Kooiker</dc:creator>
    </item>
    <item>
      <title>Developing an Inhaled NEU1 Inhibitor for Cystic Fibrosis via Pharmacokinetic and Biophysical Modeling</title>
      <link>https://arxiv.org/abs/2508.10082</link>
      <description>arXiv:2508.10082v1 Announce Type: new 
Abstract: Background: Cystic fibrosis (CF) airway mucus exhibits reduced mucin sialylation, increasing viscosity and impairing mucociliary clearance (MCC). NEU1 inhibition has been proposed to restore MCC, but its quantitative pharmacokinetic and rheological effects, particularly with inhaled delivery, remain uncharacterized.
  Objective: To develop an integrated pharmacokinetic/pharmacodynamic (PK/PD) and biophysical model to assess the efficacy of an inhaled NEU1 inhibitor.
  Methods: Empirical and preclinical NEU1 inhibition data were combined with inhalation PK/PD modeling and a biophysical viscosity framework linking mucin sialylation and extracellular DNA. Synthetic cohort simulations (N = 200) were reconciled with empirical PK benchmarks using Latin hypercube parameter sampling. Cross-validation, hold-out testing, and causal inference methods (inverse probability of treatment weighting and targeted maximum likelihood estimation) quantified predicted effects on lung function (delta FEV1).
  Results: With reconciled parameters (F_dep = 0.12; k_abs = 0.21 per hour; k_muc = 0.24 per hour), epithelial lining fluid drug levels reached a peak concentration of 7.5 micromolar (95 percent CI: 6 to 10 micromolar), achieving IC50 coverage for approximately 10 hours per day and greater than 80 percent modeled NEU1 inhibition. Predicted mucus viscosity reduction averaged 25 to 28 percent. Causal inference estimated delta FEV1 improvement of +0.13 liters (95 percent CI: 0.10 to 0.15 liters), with about 70 percent mediated via MCC.
  Conclusions: Empirically anchored PK/PD and biophysical modeling support the feasibility of inhaled NEU1 inhibition as a rheology-targeting strategy in CF, projecting clinically realistic efficacy while maintaining pharmacological viability. This calibrated proof of concept warrants in vivo validation in CF models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10082v1</guid>
      <category>q-bio.QM</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yousra Hassan Alsaad Almeshale, Abdulelah Hassan Almeshali, Omar Alsaddique, Noura Jandali, Nadeen Garaween, Bin Hu</dc:creator>
    </item>
    <item>
      <title>Estimating carbon pools in the shelf sea environment: reanalysis or model-informed machine learning?</title>
      <link>https://arxiv.org/abs/2508.10178</link>
      <description>arXiv:2508.10178v1 Announce Type: new 
Abstract: Shelf seas are important for carbon sequestration and carbon cycle, but available in situ, or satellite data for carbon pools in the shelf sea environment are often sparse, or highly uncertain. Alternative can be provided by reanalyses, but these are often expensive to run. We propose to use an ensemble of neural networks (NN) to learn from a coupled physics-biogeochemistry model the relationship between the directly observable variables and carbon pools. We demonstrate for North-West European Shelf (NWES) sea environment, that when the NN trained on a model free run simulation is applied to the NWES reanalysis, it is capable to reproduce the reanalysis outputs for carbon pools. Moreover, unlike the existing NWES reanalysis, the NN ensemble is also capable to provide uncertainty information for the pools. We focus on explainability of the results and demonstrate potential use of the NNs for future climate what-if scenarios. We suggest that model-informed machine learning presents a viable alternative to expensive reanalyses and could complement observational data, wherever they are missing and/or highly uncertain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10178v1</guid>
      <category>q-bio.QM</category>
      <category>cs.LG</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jozef Skakala</dc:creator>
    </item>
    <item>
      <title>Scalable Modeling of Nonlinear Network Dynamics in Neurodegenerative Disease</title>
      <link>https://arxiv.org/abs/2508.10343</link>
      <description>arXiv:2508.10343v1 Announce Type: new 
Abstract: Mechanistic models of progressive neurodegeneration offer great potential utility for clinical use and novel treatment development. Toward this end, several connectome-informed models of neuroimaging biomarkers have been proposed. However, these models typically do not scale well beyond a small number of biomarkers due to heterogeneity in individual disease trajectories and a large number of parameters. To address this, we introduce the Connectome-based Monotonic Inference of Neurodegenerative Dynamics (COMIND). The model combines concepts from diffusion and logistic models with structural brain connectivity. This guarantees monotonic disease trajectories while maintaining a limited number of parameters to improve scalability. We evaluate our model on simulated data as well as on the Parkinson's Progressive Markers Initiative (PPMI) data. Our model generalizes to anatomical imaging representations from a standard brain atlas without the need to reduce biomarker number.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10343v1</guid>
      <category>q-bio.QM</category>
      <category>q-bio.NC</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniel Semchin, Emile d'Angremont, Marco Lorenzi, Boris Gutman</dc:creator>
    </item>
    <item>
      <title>SimAQ: Mitigating Experimental Artifacts in Soft X-Ray Tomography using Simulated Acquisitions</title>
      <link>https://arxiv.org/abs/2508.10821</link>
      <description>arXiv:2508.10821v1 Announce Type: new 
Abstract: Soft X-ray tomography (SXT) provides detailed structural insight into whole cells but is hindered by experimental artifacts such as the missing wedge and by limited availability of annotated datasets. We present \method, a simulation pipeline that generates realistic cellular phantoms and applies synthetic artifacts to produce paired noisy volumes, sinograms, and reconstructions. We validate our approach by training a neural network primarily on synthetic data and demonstrate effective few-shot and zero-shot transfer learning on real SXT tomograms. Our model delivers accurate segmentations, enabling quantitative analysis of noisy tomograms without relying on large labeled datasets or complex reconstruction methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10821v1</guid>
      <category>q-bio.QM</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jacob Egebjerg, Daniel W\"ustner</dc:creator>
    </item>
    <item>
      <title>HelixVS: Deep Learning Enhanced Structure-based Virtual Screening Platform for Hit Discovery</title>
      <link>https://arxiv.org/abs/2508.10262</link>
      <description>arXiv:2508.10262v1 Announce Type: cross 
Abstract: Drug discovery through virtual screening (VS) has become a popular strategy for identifying hits against protein targets. VS has the potential to reduce the cost and time needed for manual selection and wet-laboratory experiments. Improving the cost-effectiveness of virtual screening is a significant challenge, aiming to explore larger compound libraries while maintaining lower screening costs. Here, we present HelixVS, a structure-based VS platform enhanced by deep learning models. HelixVS integrates a precise deep learning-based pose-scoring model and a pose-screening module into a multi-stage VS process, enabling more effective screening of active compounds. Compared to classic molecular docking tools like Vina, HelixVS demonstrated significantly improved screening performance across nearly a hundred targets, achieving an average 2.6-fold higher enrichment factor (EF) and more than 10 times faster screening speed. We applied HelixVS in four drug development pipelines, targeting both traditional competitive drug-binding pockets and novel protein-protein interaction interfaces. Wet-lab validations across these pipelines consistently identified active compounds, with over 10% of the molecules tested in wet labs demonstrating activity at uM or even nM levels. This demonstrates the ability of HelixVS to identify high-affinity ligands for various targets and pockets. Furthermore, we provide a publicly available and free version of HelixVS with limited computing power to assist drug development scientists in accelerating their drug discovery processes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10262v1</guid>
      <category>q-bio.BM</category>
      <category>q-bio.QM</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Shanzhuo Zhang, Xianbin Ye, Donglong He, Yueyang Huang, Xiaonan Zhang, Xiaomin Fang</dc:creator>
    </item>
    <item>
      <title>Using machine learning to inform harvest control rule design in complex fishery settings</title>
      <link>https://arxiv.org/abs/2412.12400</link>
      <description>arXiv:2412.12400v2 Announce Type: replace-cross 
Abstract: In fishery science, harvest management of size-structured stochastic populations is a long-standing and difficult problem. Rectilinear precautionary policies based on biomass and harvesting reference points have now become a standard approach to this problem. While these standard feedback policies are adapted from analytical or dynamic programming solutions assuming relatively simple ecological dynamics, they are often applied to more complicated ecological settings in the real world. In this paper we explore the problem of designing harvest control rules for partially observed, age-structured, spasmodic fish populations using tools from reinforcement learning (RL) and Bayesian optimization. Our focus is on the case of Walleye fisheries in Alberta, Canada, whose highly variable recruitment dynamics have perplexed managers and ecologists. We optimized and evaluated policies using several complementary performance metrics. The main questions we addressed were: 1. How do standard policies based on reference points perform relative to numerically optimized policies? 2. Can an observation of mean fish weight, in addition to stock biomass, aid policy decisions?</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.12400v2</guid>
      <category>q-bio.PE</category>
      <category>cs.LG</category>
      <category>q-bio.QM</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1111/faf.70013</arxiv:DOI>
      <dc:creator>Felipe Montealegre-Mora, Carl Boettiger, Carl J. Walters, Christopher L. Cahill</dc:creator>
    </item>
    <item>
      <title>Multimorbidity as a multistage disease process</title>
      <link>https://arxiv.org/abs/2501.18742</link>
      <description>arXiv:2501.18742v2 Announce Type: replace-cross 
Abstract: There is a growing proportion of people with several disease conditions ("multimorbidity"), placing increasing demands on healthcare systems. One hypothesis is that clusters of diseases may arise from shared underlying disease processes (shared "pathogenesis"), whereby the presence of one disease indicates the state of disease progression to several related disease types. This article explains how this hypothesis can be tested using observational data for disease incidence. Specifically, a multistage model is used to test whether two diseases can have a "shared stage" or "step", before either disease can occur, and how the unobserved rate of this step can be determined. The approach offers a simple method for studying multiple diseases and identifying shared underlying causes of multiple conditions, and is illustrated with published data and numerical examples. The fundamental mathematical model is analysed to compare key statistical properties such as the expectation and variance with those of independent diseases. The main results do not need an understanding of the underlying mathematics and can be appreciated by a non-expert.
  Significance: It is widely believed that there are shared underlying pathways that can lead to several disease types (shared "pathogenesis"), and this may explain observed clusters of disease types. This article shows how this hypothesis can be tested for a pair or cluster of diseases, using observational data of disease incidence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18742v2</guid>
      <category>stat.ME</category>
      <category>q-bio.QM</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anthony J. Webster</dc:creator>
    </item>
    <item>
      <title>Adaptive k-space Radial Sampling for Cardiac MRI with Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2508.04727</link>
      <description>arXiv:2508.04727v2 Announce Type: replace-cross 
Abstract: Accelerated Magnetic Resonance Imaging (MRI) requires careful optimization of k-space sampling patterns to balance acquisition speed and image quality. While recent advances in deep learning have shown promise in optimizing Cartesian sampling, the potential of reinforcement learning (RL) for non-Cartesian trajectory optimization remains largely unexplored. In this work, we present a novel RL framework for optimizing radial sampling trajectories in cardiac MRI. Our approach features a dual-branch architecture that jointly processes k-space and image-domain information, incorporating a cross-attention fusion mechanism to facilitate effective information exchange between domains. The framework employs an anatomically-aware reward design and a golden-ratio sampling strategy to ensure uniform k-space coverage while preserving cardiac structural details. Experimental results demonstrate that our method effectively learns optimal radial sampling strategies across multiple acceleration factors, achieving improved reconstruction quality compared to conventional approaches. Code available: https://github.com/Ruru-Xu/RL-kspace-Radial-Sampling</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.04727v2</guid>
      <category>q-bio.TO</category>
      <category>eess.IV</category>
      <category>q-bio.QM</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ruru Xu, Ilkay Oksuz</dc:creator>
    </item>
  </channel>
</rss>
