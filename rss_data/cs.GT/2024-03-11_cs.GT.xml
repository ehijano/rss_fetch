<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 12 Mar 2024 04:00:07 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 12 Mar 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>The Flow Game: Leximin and Leximax Core Imputations</title>
      <link>https://arxiv.org/abs/2403.06037</link>
      <description>arXiv:2403.06037v1 Announce Type: new 
Abstract: Recently [Vaz24] gave mechanisms for finding leximin and leximax core imputations for the assignment game and remarked, "Within the area of algorithm design, the "right" technique for solving several types of algorithmic questions was first discovered in the context of matching and later these insights were applied to other problems. We expect a similar phenomenon here." One of the games explicitly mentioned in this context was the flow game of Kalai and Zemel [KZ82]. In this paper, we give strongly polynomial time mechanisms for computing the leximin and leximax core imputations for the flow game, among the set of core imputations that are captured as optimal solutions to the dual LP. We address two versions: 1. The imputations are leximin and leximax with respect to the distance labels of edges. 2. The imputations are leximin and leximax with respect to the product of capacities of edges and their distance labels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06037v1</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rohith R. Gangam, Naveen Garg, Parnian Shahkar, Vijay V. Vazirani</dc:creator>
    </item>
    <item>
      <title>Pre- and Post-Auction Discounts in First-Price Auctions</title>
      <link>https://arxiv.org/abs/2403.06278</link>
      <description>arXiv:2403.06278v1 Announce Type: new 
Abstract: One method to offer some bidders a discount in a first-price auction is to augment their bids when selecting a winner but only charge them their original bids should they win. Another method is to use their original bids to select a winner, then charge them a discounted price that is lower than their bid should they win. We show that the two methods have equivalent auction outcomes, for equal additive discounts and for multiplicative ones with appropriate adjustments to discount amounts. As a result, they have corresponding equilibria when equilibria exist. We also show that with the same level of multiplicative adjustments, bidders with discounts should prefer an augmented bid to a discounted price. Then we estimate optimal bid functions for valuation distributions based on data from online advertising auctions, and show how different discount levels affect auction outcomes for those bid functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06278v1</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Miguel Alcobendas, Eric Bax</dc:creator>
    </item>
    <item>
      <title>Defaults: a double-edged sword in governing common resources</title>
      <link>https://arxiv.org/abs/2403.06796</link>
      <description>arXiv:2403.06796v1 Announce Type: new 
Abstract: Extracting from shared resources requires making choices to balance personal profit and sustainability. We present the results of a behavioural experiment wherein we manipulate the default extraction from a finite resource. Participants were exposed to two treatments -- pro-social or self-serving extraction defaults -- and a control without defaults. We examined the persistence of these nudges by removing the default after five rounds. Results reveal that a self-serving default increased the average extraction while present, whereas a pro-social default only decreased extraction for the first two rounds. Notably, the influence of defaults depended on individual inclinations, with cooperative individuals extracting more under a self-serving default, and selfish individuals less under a pro-social default. After the removal of the default, we observed no significant differences with the control treatment. Our research highlights the potential of defaults as cost-effective tools for promoting sustainability, while also advocating for a careful use to avoid adverse effects.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06796v1</guid>
      <category>cs.GT</category>
      <category>cs.CY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eladio Montero-Porras, R\'emi Suchon, Tom Lenaerts, Elias Fern\'andez Domingos</dc:creator>
    </item>
    <item>
      <title>Synthesis of Robust Optimal Strategies in Weighted Timed Games</title>
      <link>https://arxiv.org/abs/2403.06921</link>
      <description>arXiv:2403.06921v1 Announce Type: new 
Abstract: Weighted Timed Games (WTG for short) are the most widely used model to describe controller synthesis problems involving real-time issues. The synthesized strategies rely on a perfect measure of time elapse, which is not realistic in practice. In order to produce strategies tolerant to timing imprecisions, we rely on a notion of robustness first introduced for timed automata. More precisely, WTGs are two-player zero-sum games played in a timed automaton equipped with integer weights in which one of the players, that we call Min, wants to reach a target location while minimising the cumulated weight. In this work, we equip the underlying timed automaton with a semantics depending on some parameter (representing the maximal possible perturbation) in which the opponent of Min can in addition perturb delays chosen by Min.
  The robust value problem can then be stated as follows: given some threshold, determine whether there exists a positive perturbation and a strategy for Min ensuring to reach the target, with an accumulated weight below the threshold, whatever the opponent does.
  We provide the first decidability result for this robust value problem by computing the robust value function, in a parametric way, for the class of divergent WTGs (introduced to obtain decidability of the (classical) value problem in WTGs without bounding the number of clocks). To this end, we show that the robust value is the fixpoint of some operators, as is classically done for value iteration algorithms. We then combine in a very careful way two representations: piecewise affine functions introduced in [1] to analyse WTGs, and shrunk Difference Bound Matrices considered in [29] to analyse robustness in timed automata. Last, we also study qualitative decision problems and close an open problem on robust reachability, showing it is EXPTIME-complete for general WTGs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06921v1</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Benjamin Monmege, Julie Parreaux, Pierre-Alain Reynier</dc:creator>
    </item>
    <item>
      <title>Elections in the Post-Quantum Era: Is the Complexity Shield Strong Enough?</title>
      <link>https://arxiv.org/abs/2403.05273</link>
      <description>arXiv:2403.05273v1 Announce Type: cross 
Abstract: The election, a cornerstone of democracy, is one of the best-recognizable symbols of democratic governance. Voters' confidence in elections is essential, and these days, we can watch practically in live broadcast what consequences distrust in the fairness of elections may have. From the times of the celebrated Gibbard-Satterthwaite theorem, it is well-known in the social-choice community that most voting systems are vulnerable to the efforts of various players to influence elections. Luckily for us, computing such influence to affect election outcomes is a hard problem from the computational complexity perspective. This intractability is regarded as a ``complexity shield'' that secures voting rules against this malicious behavior.
  In this work, we consider quantum computers to be a new threat to the complexity shield described above, as they break out of standard computing paradigms and unlock additional computational resources. To this end, we provide an overview of possible attacks on election, discuss the abilities of quantum computing, and chart possible directions for future research in this area.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05273v1</guid>
      <category>cs.CR</category>
      <category>cs.CY</category>
      <category>cs.GT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>\v{S}imon Schierreich</dc:creator>
    </item>
    <item>
      <title>Provable Policy Gradient Methods for Average-Reward Markov Potential Games</title>
      <link>https://arxiv.org/abs/2403.05738</link>
      <description>arXiv:2403.05738v1 Announce Type: cross 
Abstract: We study Markov potential games under the infinite horizon average reward criterion. Most previous studies have been for discounted rewards. We prove that both algorithms based on independent policy gradient and independent natural policy gradient converge globally to a Nash equilibrium for the average reward criterion. To set the stage for gradient-based methods, we first establish that the average reward is a smooth function of policies and provide sensitivity bounds for the differential value functions, under certain conditions on ergodicity and the second largest eigenvalue of the underlying Markov decision process (MDP). We prove that three algorithms, policy gradient, proximal-Q, and natural policy gradient (NPG), converge to an $\epsilon$-Nash equilibrium with time complexity $O(\frac{1}{\epsilon^2})$, given a gradient/differential Q function oracle. When policy gradients have to be estimated, we propose an algorithm with $\tilde{O}(\frac{1}{\min_{s,a}\pi(a|s)\delta})$ sample complexity to achieve $\delta$ approximation error w.r.t~the $\ell_2$ norm. Equipped with the estimator, we derive the first sample complexity analysis for a policy gradient ascent algorithm, featuring a sample complexity of $\tilde{O}(1/\epsilon^5)$. Simulation studies are presented.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05738v1</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Min Cheng, Ruida Zhou, P. R. Kumar, Chao Tian</dc:creator>
    </item>
    <item>
      <title>Pursuit Winning Strategies for Reach-Avoid Games with Polygonal Obstacles</title>
      <link>https://arxiv.org/abs/2403.06202</link>
      <description>arXiv:2403.06202v1 Announce Type: cross 
Abstract: This paper studies a multiplayer reach-avoid differential game in the presence of general polygonal obstacles that block the players' motions. The pursuers cooperate to protect a convex region from the evaders who try to reach the region. We propose a multiplayer onsite and close-to-goal (MOCG) pursuit strategy that can tell and achieve an increasing lower bound on the number of guaranteed defeated evaders. This pursuit strategy fuses the subgame outcomes for multiple pursuers against one evader with hierarchical optimal task allocation in the receding-horizon manner. To determine the qualitative subgame outcomes that who is the game winner, we construct three pursuit winning regions and strategies under which the pursuers guarantee to win against the evader, regardless of the unknown evader strategy. First, we utilize the expanded Apollonius circles and propose the onsite pursuit winning that achieves the capture in finite time. Second, we introduce convex goal-covering polygons (GCPs) and propose the close-to-goal pursuit winning for the pursuers whose visibility region contains the whole protected region, and the goal-visible property will be preserved afterwards. Third, we employ Euclidean shortest paths (ESPs) and construct a pursuit winning region and strategy for the non-goal-visible pursuers, where the pursuers are firstly steered to positions with goal visibility along ESPs. In each horizon, the hierarchical optimal task allocation maximizes the number of defeated evaders and consists of four sequential matchings: capture, enhanced, non-dominated and closest matchings. Numerical examples are presented to illustrate the results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06202v1</guid>
      <category>eess.SY</category>
      <category>cs.GT</category>
      <category>cs.SY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rui Yan, Shuai Mi, Xiaoming Duan, Jintao Chen, Xiangyang Ji</dc:creator>
    </item>
    <item>
      <title>Disentangling Resilience from Robustness: Contextual Dualism, Interactionism, and Game-Theoretic Paradigms</title>
      <link>https://arxiv.org/abs/2403.06299</link>
      <description>arXiv:2403.06299v1 Announce Type: cross 
Abstract: This article explains the distinctions between robustness and resilience in control systems. Resilience confronts a distinct set of challenges, posing new ones for designing controllers for feedback systems, networks, and machines that prioritize resilience over robustness. The concept of resilience is explored through a three-stage model, emphasizing the need for a proactive preparation and automated response to elastic events. A toy model is first used to illustrate the tradeoffs between resilience and robustness. Then, it delves into contextual dualism and interactionism, and introduces game-theoretic paradigms as a unifying framework to consolidate resilience and robustness. The article concludes by discussing the interplay between robustness and resilience, suggesting that a comprehensive theory of resilience and quantification metrics, and formalization through game-theoretic frameworks are necessary. The exploration extends to system-of-systems resilience and various mechanisms, including the integration of AI techniques and non-technical solutions, like cyber insurance, to achieve comprehensive resilience in control systems. As we approach 2030, the systems and control community is at the opportune moment to lay scientific foundations of resilience by bridging feedback control theory, game theory, and learning theory. Resilient control systems will enhance overall quality of life, enable the development of a resilient society, and create a societal-scale impact amid global challenges such as climate change, conflicts, and cyber insecurity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06299v1</guid>
      <category>eess.SY</category>
      <category>cs.GT</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Quanyan Zhu, Tamer Basar</dc:creator>
    </item>
    <item>
      <title>Provable Mutual Benefits from Federated Learning in Privacy-Sensitive Domains</title>
      <link>https://arxiv.org/abs/2403.06672</link>
      <description>arXiv:2403.06672v1 Announce Type: cross 
Abstract: Cross-silo federated learning (FL) allows data owners to train accurate machine learning models by benefiting from each others private datasets. Unfortunately, the model accuracy benefits of collaboration are often undermined by privacy defenses. Therefore, to incentivize client participation in privacy-sensitive domains, a FL protocol should strike a delicate balance between privacy guarantees and end-model accuracy. In this paper, we study the question of when and how a server could design a FL protocol provably beneficial for all participants. First, we provide necessary and sufficient conditions for the existence of mutually beneficial protocols in the context of mean estimation and convex stochastic optimization. We also derive protocols that maximize the total clients' utility, given symmetric privacy preferences. Finally, we design protocols maximizing end-model accuracy and demonstrate their benefits in synthetic experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06672v1</guid>
      <category>stat.ML</category>
      <category>cs.CR</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nikita Tsoy, Anna Mihalkova, Teodora Todorova, Nikola Konstantinov</dc:creator>
    </item>
    <item>
      <title>Machine Learning-Powered Course Allocation</title>
      <link>https://arxiv.org/abs/2210.00954</link>
      <description>arXiv:2210.00954v3 Announce Type: replace 
Abstract: We study the course allocation problem, where universities assign course schedules to students. The current state-of-the-art mechanism, Course Match, has one major shortcoming: students make significant mistakes when reporting their preferences, which negatively affects welfare and fairness. To address this issue, we introduce a new mechanism, Machine Learning-powered Course Match (MLCM). At the core of MLCM is a machine learning-powered preference elicitation module that iteratively asks personalized pairwise comparison queries to alleviate students' reporting mistakes. Extensive computational experiments, grounded in real-world data, demonstrate that MLCM, with only ten comparison queries, significantly increases both average and minimum student utility by 7%-11% and 17%-29%, respectively. Finally, we highlight MLCM's robustness to changes in the environment and show how our design minimizes the risk of upgrading to MLCM while making the upgrade process simple for universities and seamless for their students.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.00954v3</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ermis Soumalias, Behnoosh Zamanlooy, Jakob Weissteiner, Sven Seuken</dc:creator>
    </item>
    <item>
      <title>Markov $\alpha$-Potential Games</title>
      <link>https://arxiv.org/abs/2305.12553</link>
      <description>arXiv:2305.12553v5 Announce Type: replace 
Abstract: This paper proposes a new framework of Markov $\alpha$-potential games to study Markov games. In this new framework, Markov games are shown to be Markov $\alpha$-potential games, and the existence of an associated $\alpha$-potential function is established. Any optimizer of an $\alpha$-potential function is shown to be an $\alpha$-stationary NE. Two important classes of practically significant Markov games, Markov congestion games and the perturbed Markov team games, are studied via this framework of Markov $\alpha$-potential games, with explicit characterization of an upper bound for $\alpha$ and its relation to game parameters. Additionally, a semi-infinite linear programming based formulation is presented to obtain an upper bound for $\alpha$ for any Markov game. Furthermore, two equilibrium approximation algorithms, namely the projected gradient-ascent algorithm and the sequential maximum improvement algorithm, are presented along with their Nash regret analysis, and corroborated by numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.12553v5</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xin Guo, Xinyu Li, Chinmay Maheshwari, Shankar Sastry, Manxi Wu</dc:creator>
    </item>
    <item>
      <title>Computing Optimal Commitments to Strategies and Outcome-Conditional Utility Transfers</title>
      <link>https://arxiv.org/abs/2402.06626</link>
      <description>arXiv:2402.06626v2 Announce Type: replace 
Abstract: Prior work has studied the computational complexity of computing optimal strategies to commit to in Stackelberg or leadership games, where a leader commits to a strategy which is observed by one or more followers. We extend this setting to one where the leader can additionally commit to outcome-conditional utility transfers. We characterize the computational complexity of finding optimal strategies in normal-form and Bayesian games, giving a mix of efficient algorithms and NP-hardness results. Finally, we allow the leader to also commit to a signaling scheme which induces a correlated equilibrium. In this setting, optimal commitments can be found in polynomial time for arbitrarily many players.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.06626v2</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nathaniel Sauerberg, Caspar Oesterheld</dc:creator>
    </item>
    <item>
      <title>Conjectural Online Learning with First-order Beliefs in Asymmetric Information Stochastic Games</title>
      <link>https://arxiv.org/abs/2402.18781</link>
      <description>arXiv:2402.18781v3 Announce Type: replace 
Abstract: Asymmetric information stochastic games (\textsc{aisg}s) arise in many complex socio-technical systems, such as cyber-physical systems and IT infrastructures. Existing computational methods for \textsc{aisg}s are primarily offline and can not adapt to equilibrium deviations. Further, current methods are limited to special classes of \textsc{aisg}s to avoid belief hierarchies. To address these limitations, we propose conjectural online learning (\textsc{col}), an online method for generic \textsc{aisg}s. \textsc{col} uses a forecaster-actor-critic (\textsc{fac}) architecture where subjective forecasts are used to conjecture the opponents' strategies within a lookahead horizon, and Bayesian learning is used to calibrate the conjectures. To adapt strategies to nonstationary environments, \textsc{col} uses online rollout with cost function approximation (actor-critic). We prove that the conjectures produced by \textsc{col} are asymptotically consistent with the information feedback in the sense of a relaxed Bayesian consistency. We also prove that the empirical strategy profile induced by \textsc{col} converges to the Berk-Nash equilibrium, a solution concept characterizing rationality under subjectivity. Experimental results from an intrusion response use case demonstrate \textsc{col}'s superiority over state-of-the-art reinforcement learning methods against nonstationary attacks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.18781v3</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tao Li, Kim Hammar, Rolf Stadler, Quanyan Zhu</dc:creator>
    </item>
    <item>
      <title>A Bayesian Learning Algorithm for Unknown Zero-sum Stochastic Games with an Arbitrary Opponent</title>
      <link>https://arxiv.org/abs/2109.03396</link>
      <description>arXiv:2109.03396v3 Announce Type: replace-cross 
Abstract: In this paper, we propose Posterior Sampling Reinforcement Learning for Zero-sum Stochastic Games (PSRL-ZSG), the first online learning algorithm that achieves Bayesian regret bound of $O(HS\sqrt{AT})$ in the infinite-horizon zero-sum stochastic games with average-reward criterion. Here $H$ is an upper bound on the span of the bias function, $S$ is the number of states, $A$ is the number of joint actions and $T$ is the horizon. We consider the online setting where the opponent can not be controlled and can take any arbitrary time-adaptive history-dependent strategy. Our regret bound improves on the best existing regret bound of $O(\sqrt[3]{DS^2AT^2})$ by Wei et al. (2017) under the same assumption and matches the theoretical lower bound in $T$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2109.03396v3</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mehdi Jafarnia-Jahromi, Rahul Jain, Ashutosh Nayyar</dc:creator>
    </item>
    <item>
      <title>Designing Equilibria in Concurrent Games with Social Welfare and Temporal Logic Constraints</title>
      <link>https://arxiv.org/abs/2306.03045</link>
      <description>arXiv:2306.03045v2 Announce Type: replace-cross 
Abstract: In game theory, mechanism design is concerned with the design of incentives so that a desired outcome of the game can be achieved. In this paper, we explore the concept of equilibrium design, where incentives are designed to obtain a desirable equilibrium that satisfies a specific temporal logic property. Our study is based on a framework where system specifications are represented as temporal logic formulae, games as quantitative concurrent game structures, and players' goals as mean-payoff objectives. We consider system specifications given by LTL and GR(1) formulae, and show that designing incentives to ensure that a given temporal logic property is satisfied on some/every Nash equilibrium of the game can be achieved in PSPACE for LTL properties and in NP/{\Sigma}P 2 for GR(1) specifications. We also examine the complexity of related decision and optimisation problems, such as optimality and uniqueness of solutions, as well as considering social welfare, and show that the complexities of these problems lie within the polynomial hierarchy. Equilibrium design can be used as an alternative solution to rational synthesis and verification problems for concurrent games with mean-payoff objectives when no solution exists or as a technique to repair concurrent games with undesirable Nash equilibria in an optimal way.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.03045v2</guid>
      <category>cs.LO</category>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Julian Gutierrez, Muhammad Najib, Giuseppe Perelli, Michael Wooldridge</dc:creator>
    </item>
    <item>
      <title>Defending Against Malicious Behaviors in Federated Learning with Blockchain</title>
      <link>https://arxiv.org/abs/2307.00543</link>
      <description>arXiv:2307.00543v2 Announce Type: replace-cross 
Abstract: In the era of deep learning, federated learning (FL) presents a promising approach that allows multi-institutional data owners, or clients, to collaboratively train machine learning models without compromising data privacy. However, most existing FL approaches rely on a centralized server for global model aggregation, leading to a single point of failure. This makes the system vulnerable to malicious attacks when dealing with dishonest clients. In this work, we address this problem by proposing a secure and reliable FL system based on blockchain and distributed ledger technology. Our system incorporates a peer-to-peer voting mechanism and a reward-and-slash mechanism, which are powered by on-chain smart contracts, to detect and deter malicious behaviors. Both theoretical and empirical analyses are presented to demonstrate the effectiveness of the proposed approach, showing that our framework is robust against malicious client-side behaviors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.00543v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CR</category>
      <category>cs.GT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nanqing Dong, Zhipeng Wang, Jiahao Sun, Michael Kampffmeyer, William Knottenbelt, Eric Xing</dc:creator>
    </item>
    <item>
      <title>On the tractability of Nash equilibrium</title>
      <link>https://arxiv.org/abs/2311.05644</link>
      <description>arXiv:2311.05644v3 Announce Type: replace-cross 
Abstract: In this paper, we propose a method for solving a PPAD-complete problem [Papadimitriou, 1994]. Given is the payoff matrix $C$ of a symmetric bimatrix game $(C, C^T)$ and our goal is to compute a Nash equilibrium of $(C, C^T)$. In this paper, we devise a nonlinear replicator dynamic (whose right-hand-side can be obtained by solving a pair of convex optimization problems) with the following property: Under any invertible $0 &lt; C \leq 1$, every orbit of our dynamic starting at an interior strategy of the standard simplex approaches a set of strategies of $(C, C^T)$ such that, for each strategy in this set, a symmetric Nash equilibrium strategy can be computed by solving the aforementioned convex mathematical programs. We prove convergence using results in analysis (the analytic implicit function theorem), nonlinear optimization theory (duality theory, Berge's maximum principle, and a theorem of Robinson [1980] on the Lipschitz continuity of parametric nonlinear programs), and dynamical systems theory (such as the LaSalle invariance principle).</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.05644v3</guid>
      <category>math.OC</category>
      <category>cs.GT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ioannis Avramopoulos</dc:creator>
    </item>
    <item>
      <title>Strategic Usage in a Multi-Learner Setting</title>
      <link>https://arxiv.org/abs/2401.16422</link>
      <description>arXiv:2401.16422v2 Announce Type: replace-cross 
Abstract: Real-world systems often involve some pool of users choosing between a set of services. With the increase in popularity of online learning algorithms, these services can now self-optimize, leveraging data collected on users to maximize some reward such as service quality. On the flipside, users may strategically choose which services to use in order to pursue their own reward functions, in the process wielding power over which services can see and use their data. Extensive prior research has been conducted on the effects of strategic users in single-service settings, with strategic behavior manifesting in the manipulation of observable features to achieve a desired classification; however, this can often be costly or unattainable for users and fails to capture the full behavior of multi-service dynamic systems. As such, we analyze a setting in which strategic users choose among several available services in order to pursue positive classifications, while services seek to minimize loss functions on their observations. We focus our analysis on realizable settings, and show that naive retraining can still lead to oscillation even if all users are observed at different times; however, if this retraining uses memory of past observations, convergent behavior can be guaranteed for certain loss function classes. We provide results obtained from synthetic and real-world data to empirically validate our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.16422v2</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eliot Shekhtman, Sarah Dean</dc:creator>
    </item>
    <item>
      <title>On the Detection of Reviewer-Author Collusion Rings From Paper Bidding</title>
      <link>https://arxiv.org/abs/2402.07860</link>
      <description>arXiv:2402.07860v2 Announce Type: replace-cross 
Abstract: A major threat to the peer-review systems of computer science conferences is the existence of "collusion rings" between reviewers. In such collusion rings, reviewers who have also submitted their own papers to the conference work together to manipulate the conference's paper assignment, with the aim of being assigned to review each other's papers. The most straightforward way that colluding reviewers can manipulate the paper assignment is by indicating their interest in each other's papers through strategic paper bidding. One potential approach to solve this important problem would be to detect the colluding reviewers from their manipulated bids, after which the conference can take appropriate action. While prior work has developed effective techniques to detect other kinds of fraud, no research has yet established that detecting collusion rings is even possible. In this work, we tackle the question of whether it is feasible to detect collusion rings from the paper bidding. To answer this question, we conduct empirical analysis of two realistic conference bidding datasets, including evaluations of existing algorithms for fraud detection in other applications. We find that collusion rings can achieve considerable success at manipulating the paper assignment while remaining hidden from detection: for example, in one dataset, undetected colluders are able to achieve assignment to up to 30% of the papers authored by other colluders. In addition, when 10 colluders bid on all of each other's papers, no detection algorithm outputs a group of reviewers with more than 31% overlap with the true colluders. These results suggest that collusion cannot be effectively detected from the bidding using popular existing tools, demonstrating the need to develop more complex detection algorithms as well as those that leverage additional metadata (e.g., reviewer-paper text-similarity scores).</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.07860v2</guid>
      <category>cs.SI</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Steven Jecmen, Nihar B. Shah, Fei Fang, Leman Akoglu</dc:creator>
    </item>
  </channel>
</rss>
