<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.CO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.CO</link>
    <description>stat.CO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.CO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 18 Jul 2024 01:45:08 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 17 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Scaling Hawkes processes to one million COVID-19 cases</title>
      <link>https://arxiv.org/abs/2407.11349</link>
      <description>arXiv:2407.11349v1 Announce Type: new 
Abstract: Hawkes stochastic point process models have emerged as valuable statistical tools for analyzing viral contagion. The spatiotemporal Hawkes process characterizes the speeds at which viruses spread within human populations. Unfortunately, likelihood-based inference using these models requires $O(N^2)$ floating-point operations, for $N$ the number of observed cases. Recent work responds to the Hawkes likelihood's computational burden by developing efficient graphics processing unit (GPU)-based routines that enable Bayesian analysis of tens-of-thousands of observations. We build on this work and develop a high-performance computing (HPC) strategy that divides 30 Markov chains between 4 GPU nodes, each of which uses multiple GPUs to accelerate its chain's likelihood computations. We use this framework to apply two spatiotemporal Hawkes models to the analysis of one million COVID-19 cases in the United States between March 2020 and June 2023. In addition to brute-force HPC, we advocate for two simple strategies as scalable alternatives to successful approaches proposed for small data settings. First, we use known county-specific population densities to build a spatially varying triggering kernel in a manner that avoids computationally costly nearest neighbors search. Second, we use a cut-posterior inference routine that accounts for infections' spatial location uncertainty by iteratively sampling latent locations uniformly within their respective counties of occurrence, thereby avoiding full-blown latent variable inference for 1,000,000 infection locations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.11349v1</guid>
      <category>stat.CO</category>
      <category>stat.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Seyoon Ko, Marc A. Suchard, Andrew J. Holbrook</dc:creator>
    </item>
    <item>
      <title>Optimal estimators of cross-partial derivatives and surrogates of functions</title>
      <link>https://arxiv.org/abs/2407.11035</link>
      <description>arXiv:2407.11035v1 Announce Type: cross 
Abstract: Computing cross-partial derivatives using fewer model runs is relevant in modeling, such as stochastic approximation, derivative-based ANOVA, exploring complex models, and active subspaces. This paper introduces surrogates of all the cross-partial derivatives of functions by evaluating such functions at $N$ randomized points and using a set of $L$ constraints. Randomized points rely on independent, central, and symmetric variables. The associated estimators, based on $NL$ model runs, reach the optimal rates of convergence (i.e., $\mathcal{O}(N^{-1})$), and the biases of our approximations do not suffer from the curse of dimensionality for a wide class of functions. Such results are used for i) computing the main and upper-bounds of sensitivity indices, and ii) deriving emulators of simulators or surrogates of functions thanks to the derivative-based ANOVA. Simulations are presented to show the accuracy of our emulators and estimators of sensitivity indices. The plug-in estimates of indices using the U-statistics of one sample are numerically much stable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.11035v1</guid>
      <category>stat.ME</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Matieyendou Lamboni</dc:creator>
    </item>
    <item>
      <title>The 2023/24 VIEWS Prediction Challenge: Predicting the Number of Fatalities in Armed Conflict, with Uncertainty</title>
      <link>https://arxiv.org/abs/2407.11045</link>
      <description>arXiv:2407.11045v1 Announce Type: cross 
Abstract: This draft article outlines a prediction challenge where the target is to forecast the number of fatalities in armed conflicts, in the form of the UCDP `best' estimates, aggregated to the VIEWS units of analysis. It presents the format of the contributions, the evaluation metric, and the procedures, and a brief summary of the contributions. The article serves a function analogous to a pre-analysis plan: a statement of the forecasting models made publicly available before the true future prediction window commences. More information on the challenge, and all data referred to in this document, can be found at https://viewsforecasting.org/research/prediction-challenge-2023.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.11045v1</guid>
      <category>stat.AP</category>
      <category>cs.LG</category>
      <category>stat.CO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>H{\aa}vard Hegre (Peace Research Institute Oslo), Paola Vesco (Peace Research Institute Oslo), Michael Colaresi (Department of Peace and Conflict Research, Uppsala University), Jonas Vestby (Peace Research Institute Oslo), Alexa Timlick (Peace Research Institute Oslo), Noorain Syed Kazmi (Peace Research Institute Oslo), Friederike Becker (Institute of Statistics), Marco Binetti (Center for Crisis Early Warning, University of the Bundeswehr Munich), Tobias Bodentien (Institute of Statistics), Tobias Bohne (Center for Crisis Early Warning, University of the Bundeswehr Munich), Patrick T. Brandt (School of Economic, Political, and Policy Sciences, University of Texas, Dallas), Thomas Chadefaux (Trinity College Dublin), Simon Drauz (Institute of Statistics), Christoph Dworschak (University of York), Vito D'Orazio (West Virginia University), Cornelius Fritz (Pennsylvania State University), Hannah Frank (Trinity College Dublin), Kristian Skrede Gleditsch (University of Essex), Sonja H\"affner (Center for Crisis Early Warning, University of the Bundeswehr Munich), Martin Hofer (University College London), Finn L. Klebe (University College London), Luca Macis (Department of Economics and Statistics Cognetti de Martiis, University of Turin), Alexandra Malaga (Institute for Economic Analysis, Barcelona), Marius Mehrl (University of Leeds), Nils W. Metternich (University College London), Daniel Mittermaier (Center for Crisis Early Warning, University of the Bundeswehr Munich), David Muchlinski (Georgia Tech), Hannes Mueller (Institute for Economic Analysis, Barcelona), Christian Oswald (Center for Crisis Early Warning, University of the Bundeswehr Munich), Paola Pisano (Department of Economics and Statistics Cognetti de Martiis, University of Turin), David Randahl (Department of Peace and Conflict Research, Uppsala University), Christopher Rauh (University of Cambridge), Lotta R\"uter (Institute of Statistics), Thomas Schincariol (Trinity College Dublin), Benjamin Seimon (Fundaci\'o Economia Analitica), Elena Siletti (Department of Economics and Statistics Cognetti de Martiis, University of Turin), Marco Tagliapietra (Department of Economics and Statistics Cognetti de Martiis, University of Turin), Chandler Thornhill (Georgia Tech), Johan Vegelius (Department of Medical Sciences, Uppsala University), Julian Walterskirchen (Center for Crisis Early Warning, University of the Bundeswehr Munich)</dc:creator>
    </item>
    <item>
      <title>Combining Wasserstein-1 and Wasserstein-2 proximals: robust manifold learning via well-posed generative flows</title>
      <link>https://arxiv.org/abs/2407.11901</link>
      <description>arXiv:2407.11901v1 Announce Type: cross 
Abstract: We formulate well-posed continuous-time generative flows for learning distributions that are supported on low-dimensional manifolds through Wasserstein proximal regularizations of $f$-divergences. Wasserstein-1 proximal operators regularize $f$-divergences so that singular distributions can be compared. Meanwhile, Wasserstein-2 proximal operators regularize the paths of the generative flows by adding an optimal transport cost, i.e., a kinetic energy penalization. Via mean-field game theory, we show that the combination of the two proximals is critical for formulating well-posed generative flows. Generative flows can be analyzed through optimality conditions of a mean-field game (MFG), a system of a backward Hamilton-Jacobi (HJ) and a forward continuity partial differential equations (PDEs) whose solution characterizes the optimal generative flow. For learning distributions that are supported on low-dimensional manifolds, the MFG theory shows that the Wasserstein-1 proximal, which addresses the HJ terminal condition, and the Wasserstein-2 proximal, which addresses the HJ dynamics, are both necessary for the corresponding backward-forward PDE system to be well-defined and have a unique solution with provably linear flow trajectories. This implies that the corresponding generative flow is also unique and can therefore be learned in a robust manner even for learning high-dimensional distributions supported on low-dimensional manifolds. The generative flows are learned through adversarial training of continuous-time flows, which bypasses the need for reverse simulation. We demonstrate the efficacy of our approach for generating high-dimensional images without the need to resort to autoencoders or specialized architectures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.11901v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hyemin Gu, Markos A. Katsoulakis, Luc Rey-Bellet, Benjamin J. Zhang</dc:creator>
    </item>
    <item>
      <title>Beyond time-homogeneity for continuous-time multistate Markov models</title>
      <link>https://arxiv.org/abs/2211.03214</link>
      <description>arXiv:2211.03214v3 Announce Type: replace 
Abstract: Multistate Markov models are a canonical parametric approach for data modeling of observed or latent stochastic processes supported on a finite state space. Continuous-time Markov processes describe data that are observed irregularly over time, as is often the case in longitudinal medical data, for example. Assuming that a continuous-time Markov process is time-homogeneous, a closed-form likelihood function can be derived from the Kolmogorov forward equations -- a system of differential equations with a well-known matrix-exponential solution. Unfortunately, however, the forward equations do not admit an analytical solution for continuous-time, time-inhomogeneous Markov processes, and so researchers and practitioners often make the simplifying assumption that the process is piecewise time-homogeneous. In this paper, we provide intuitions and illustrations of the potential biases for parameter estimation that may ensue in the more realistic scenario that the piecewise-homogeneous assumption is violated, and we advocate for a solution for likelihood computation in a truly time-inhomogeneous fashion. Particular focus is afforded to the context of multistate Markov models that allow for state label misclassifications, which applies more broadly to hidden Markov models (HMMs), and Bayesian computations bypass the necessity for computationally demanding numerical gradient approximations for obtaining maximum likelihood estimates (MLEs). Supplemental materials are available online.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.03214v3</guid>
      <category>stat.CO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Emmett B. Kendall, Jonathan P. Williams, Gudmund H. Hermansen, Frederic Bois, Vo Hong Thanh</dc:creator>
    </item>
    <item>
      <title>Combinatorial Potential of Random Equations with Mixture Models: Modeling and Simulation</title>
      <link>https://arxiv.org/abs/2403.20152</link>
      <description>arXiv:2403.20152v3 Announce Type: replace 
Abstract: The goal of this paper is to demonstrate the general modeling and practical simulation of random equations with mixture model parameter random variables. Random equations, understood as stationary (non-dynamical) equations with parameters as random variables, have a long history and a broad range of applications. The specific novelty of this explorative study lies on the demonstration of the combinatorial complexity of these equations with mixture model parameters. In a Bayesian argumentation framework we derive a general likelihood function and posterior density of approximate best fit solutions while avoiding significant restrictions about the type of nonlinearity of the equation or mixture models, and demonstrate their numerically efficient implementation for the applied researcher. In the results section, we are specifically focusing on expressive example simulations of approximate likelihood/posterior solutions for random linear equation systems, nonlinear systems of random conic section equations, as well as applications to portfolio optimization, stochastic control and random matrix theory in order to show the wide applicability of the presented methodology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.20152v3</guid>
      <category>stat.CO</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wolfgang Hoegele</dc:creator>
    </item>
    <item>
      <title>Simulation Model Calibration with Dynamic Stratification and Adaptive Sampling</title>
      <link>https://arxiv.org/abs/2401.14558</link>
      <description>arXiv:2401.14558v2 Announce Type: replace-cross 
Abstract: Calibrating simulation models that take large quantities of multi-dimensional data as input is a hard simulation optimization problem. Existing adaptive sampling strategies offer a methodological solution. However, they may not sufficiently reduce the computational cost for estimation and solution algorithm's progress within a limited budget due to extreme noise levels and heteroskedasticity of system responses. We propose integrating stratification with adaptive sampling for the purpose of efficiency in optimization. Stratification can exploit local dependence in the simulation inputs and outputs. Yet, the state-of-the-art does not provide a full capability to adaptively stratify the data as different solution alternatives are evaluated. We devise two procedures for data-driven calibration problems that involve a large dataset with multiple covariates to calibrate models within a fixed overall simulation budget. The first approach dynamically stratifies the input data using binary trees, while the second approach uses closed-form solutions based on linearity assumptions between the objective function and concomitant variables. We find that dynamical adjustment of stratification structure accelerates optimization and reduces run-to-run variability in generated solutions. Our case study for calibrating a wind power simulation model, widely used in the wind industry, using the proposed stratified adaptive sampling, shows better-calibrated parameters under a limited budget.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.14558v2</guid>
      <category>stat.ME</category>
      <category>math.PR</category>
      <category>stat.CO</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pranav Jain, Sara Shashaani, Eunshin Byon</dc:creator>
    </item>
  </channel>
</rss>
