<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 04 Oct 2024 04:00:44 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 04 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Separating minimal from radical embodied cognitive neuroscience</title>
      <link>https://arxiv.org/abs/2410.01830</link>
      <description>arXiv:2410.01830v1 Announce Type: new 
Abstract: Mougenot and Matheson (2024) make a compelling case for the development of a mechanistic cognitive neuroscience that is embodied. However, their analysis of extant work under this header plays down important distinctions between "minimal" and "radical" embodiment. The former remains firmly neurocentric and therefore has limited potential to move the needle in understanding the functional contributions of neural dynamics to cognition in the context of wider organism-environment dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.01830v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Fri, 04 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matthieu M. de Wit</dc:creator>
    </item>
    <item>
      <title>HyperBrain: Anomaly Detection for Temporal Hypergraph Brain Networks</title>
      <link>https://arxiv.org/abs/2410.02087</link>
      <description>arXiv:2410.02087v1 Announce Type: cross 
Abstract: Identifying unusual brain activity is a crucial task in neuroscience research, as it aids in the early detection of brain disorders. It is common to represent brain networks as graphs, and researchers have developed various graph-based machine learning methods for analyzing them. However, the majority of existing graph learning tools for the brain face a combination of the following three key limitations. First, they focus only on pairwise correlations between regions of the brain, limiting their ability to capture synchronized activity among larger groups of regions. Second, they model the brain network as a static network, overlooking the temporal changes in the brain. Third, most are designed only for classifying brain networks as healthy or disordered, lacking the ability to identify abnormal brain activity patterns linked to biomarkers associated with disorders. To address these issues, we present HyperBrain, an unsupervised anomaly detection framework for temporal hypergraph brain networks. HyperBrain models fMRI time series data as temporal hypergraphs capturing dynamic higher-order interactions. It then uses a novel customized temporal walk (BrainWalk) and neural encodings to detect abnormal co-activations among brain regions. We evaluate the performance of HyperBrain in both synthetic and real-world settings for Autism Spectrum Disorder and Attention Deficit Hyperactivity Disorder(ADHD). HyperBrain outperforms all other baselines on detecting abnormal co-activations in brain networks. Furthermore, results obtained from HyperBrain are consistent with clinical research on these brain disorders. Our findings suggest that learning temporal and higher-order connections in the brain provides a promising approach to uncover intricate connectivity patterns in brain networks, offering improved diagnosis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02087v1</guid>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <pubDate>Fri, 04 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sadaf Sadeghian, Xiaoxiao Li, Margo Seltzer</dc:creator>
    </item>
    <item>
      <title>Tracking objects that change in appearance with phase synchrony</title>
      <link>https://arxiv.org/abs/2410.02094</link>
      <description>arXiv:2410.02094v1 Announce Type: cross 
Abstract: Objects we encounter often change appearance as we interact with them. Changes in illumination (shadows), object pose, or movement of nonrigid objects can drastically alter available image features. How do biological visual systems track objects as they change? It may involve specific attentional mechanisms for reasoning about the locations of objects independently of their appearances -- a capability that prominent neuroscientific theories have associated with computing through neural synchrony. We computationally test the hypothesis that the implementation of visual attention through neural synchrony underlies the ability of biological visual systems to track objects that change in appearance over time. We first introduce a novel deep learning circuit that can learn to precisely control attention to features separately from their location in the world through neural synchrony: the complex-valued recurrent neural network (CV-RNN). Next, we compare object tracking in humans, the CV-RNN, and other deep neural networks (DNNs), using FeatureTracker: a large-scale challenge that asks observers to track objects as their locations and appearances change in precisely controlled ways. While humans effortlessly solved FeatureTracker, state-of-the-art DNNs did not. In contrast, our CV-RNN behaved similarly to humans on the challenge, providing a computational proof-of-concept for the role of phase synchronization as a neural substrate for tracking appearance-morphing objects as they move about.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02094v1</guid>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>q-bio.NC</category>
      <pubDate>Fri, 04 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sabine Muzellec, Drew Linsley, Alekh K. Ashok, Ennio Mingolla, Girik Malik, Rufin VanRullen, Thomas Serre</dc:creator>
    </item>
    <item>
      <title>Predictive Attractor Models</title>
      <link>https://arxiv.org/abs/2410.02430</link>
      <description>arXiv:2410.02430v1 Announce Type: cross 
Abstract: Sequential memory, the ability to form and accurately recall a sequence of events or stimuli in the correct order, is a fundamental prerequisite for biological and artificial intelligence as it underpins numerous cognitive functions (e.g., language comprehension, planning, episodic memory formation, etc.) However, existing methods of sequential memory suffer from catastrophic forgetting, limited capacity, slow iterative learning procedures, low-order Markov memory, and, most importantly, the inability to represent and generate multiple valid future possibilities stemming from the same context. Inspired by biologically plausible neuroscience theories of cognition, we propose \textit{Predictive Attractor Models (PAM)}, a novel sequence memory architecture with desirable generative properties. PAM is a streaming model that learns a sequence in an online, continuous manner by observing each input \textit{only once}. Additionally, we find that PAM avoids catastrophic forgetting by uniquely representing past context through lateral inhibition in cortical minicolumns, which prevents new memories from overwriting previously learned knowledge. PAM generates future predictions by sampling from a union set of predicted possibilities; this generative ability is realized through an attractor model trained alongside the predictor. We show that PAM is trained with local computations through Hebbian plasticity rules in a biologically plausible framework. Other desirable traits (e.g., noise tolerance, CPU-based learning, capacity scaling) are discussed throughout the paper. Our findings suggest that PAM represents a significant step forward in the pursuit of biologically plausible and computationally efficient sequential memory models, with broad implications for cognitive science and artificial intelligence research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02430v1</guid>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <pubDate>Fri, 04 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ramy Mounir, Sudeep Sarkar</dc:creator>
    </item>
    <item>
      <title>Toward Neuronal Implementations of Delayed Optimal Control</title>
      <link>https://arxiv.org/abs/2410.02555</link>
      <description>arXiv:2410.02555v1 Announce Type: cross 
Abstract: Animal sensorimotor behavior is frequently modeled using optimal controllers. However, it is unclear how the neuronal circuits within the animal's nervous system implement optimal controller-like behavior. In this work, we study the question of implementing a delayed linear quadratic regulator with linear dynamical "neurons" on a muscle model. We show that for any second-order controller, there are three minimal neural circuit configurations that implement the same controller. Furthermore, the firing rate characteristics of each circuit can vary drastically, even as the overall controller behavior is preserved. Along the way, we introduce concepts that bridge controller realizations to neural implementations that are compatible with known neuronal delay structures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02555v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>q-bio.NC</category>
      <pubDate>Fri, 04 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jing Shuang Li</dc:creator>
    </item>
    <item>
      <title>NECOMIMI: Neural-Cognitive Multimodal EEG-informed Image Generation with Diffusion Models</title>
      <link>https://arxiv.org/abs/2410.00712</link>
      <description>arXiv:2410.00712v2 Announce Type: replace 
Abstract: NECOMIMI (NEural-COgnitive MultImodal EEG-Informed Image Generation with Diffusion Models) introduces a novel framework for generating images directly from EEG signals using advanced diffusion models. Unlike previous works that focused solely on EEG-image classification through contrastive learning, NECOMIMI extends this task to image generation. The proposed NERV EEG encoder demonstrates state-of-the-art (SoTA) performance across multiple zero-shot classification tasks, including 2-way, 4-way, and 200-way, and achieves top results in our newly proposed Category-based Assessment Table (CAT) Score, which evaluates the quality of EEG-generated images based on semantic concepts. A key discovery of this work is that the model tends to generate abstract or generalized images, such as landscapes, rather than specific objects, highlighting the inherent challenges of translating noisy and low-resolution EEG data into detailed visual outputs. Additionally, we introduce the CAT Score as a new metric tailored for EEG-to-image evaluation and establish a benchmark on the ThingsEEG dataset. This study underscores the potential of EEG-to-image generation while revealing the complexities and challenges that remain in bridging neural activity with visual representation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00712v2</guid>
      <category>q-bio.NC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 04 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chi-Sheng Chen</dc:creator>
    </item>
    <item>
      <title>Language models and brains align due to more than next-word prediction and word-level information</title>
      <link>https://arxiv.org/abs/2212.00596</link>
      <description>arXiv:2212.00596v2 Announce Type: replace-cross 
Abstract: Pretrained language models have been shown to significantly predict brain recordings of people comprehending language. Recent work suggests that the prediction of the next word is a key mechanism that contributes to this alignment. What is not yet understood is whether prediction of the next word is necessary for this observed alignment or simply sufficient, and whether there are other shared mechanisms or information that are similarly important. In this work, we take a step towards understanding the reasons for brain alignment via two simple perturbations in popular pretrained language models. These perturbations help us design contrasts that can control for different types of information. By contrasting the brain alignment of these differently perturbed models, we show that improvements in alignment with brain recordings are due to more than improvements in next-word prediction and word-level information.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.00596v2</guid>
      <category>cs.CL</category>
      <category>q-bio.NC</category>
      <pubDate>Fri, 04 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gabriele Merlin, Mariya Toneva</dc:creator>
    </item>
    <item>
      <title>Saddle avoidance of noise-induced transitions in multiscale systems</title>
      <link>https://arxiv.org/abs/2311.10231</link>
      <description>arXiv:2311.10231v4 Announce Type: replace-cross 
Abstract: In multistable dynamical systems driven by weak Gaussian noise, transitions between competing states are often assumed to pass via a saddle on the separating basin boundary. By contrast, we show that timescale separation can cause saddle avoidance in non-gradient systems. Using toy models from neuroscience and ecology, we study cases where sample transitions deviate strongly from the instanton predicted by Freidlin-Wentzell theory, even for weak finite noise. We attribute this to a flat quasipotential and present an approach based on the Onsager-Machlup action to aptly predict transition paths.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.10231v4</guid>
      <category>math.DS</category>
      <category>cond-mat.stat-mech</category>
      <category>q-bio.NC</category>
      <category>q-bio.PE</category>
      <pubDate>Fri, 04 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Reyk B\"orner, Ryan Deeley, Raphael R\"omer, Tobias Grafke, Valerio Lucarini, Ulrike Feudel</dc:creator>
    </item>
  </channel>
</rss>
