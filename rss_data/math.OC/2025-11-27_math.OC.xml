<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 27 Nov 2025 05:00:05 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 27 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A derivative-free trust-region approach for Low Order-Value Optimization problems</title>
      <link>https://arxiv.org/abs/2511.20783</link>
      <description>arXiv:2511.20783v1 Announce Type: new 
Abstract: The Low Order-Value Optimization (LOVO) problem involves minimizing the minimum among a finite number of function values within a feasible set. LOVO has several practical applications such as robust parameter estimation, protein alignment, portfolio optimization, among others. In this work, we are interested in the constrained nonlinear optimization LOVO problem of minimizing the minimum between a finite number of function values subject to a nonempty closed convex set where each function is a black-box and continuously differentiable, but the derivatives are not available. We develop the first derivative-free trust-region algorithm for constrained LOVO problems with convergence to weakly critical points. Under suitable conditions, we establish the global convergence of the algorithm and also its worst-case iteration complexity analysis. An initial open-source implementation using only linear interpolation models is developed. Extensive numerical experiments and comparison with existing alternatives show the properties and the efficiency of the proposed approach when solving LOVO problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.20783v1</guid>
      <category>math.OC</category>
      <category>cs.MS</category>
      <pubDate>Thu, 27 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anderson E. Schwertner, Francisco N. C. Sobral</dc:creator>
    </item>
    <item>
      <title>A Review of Pseudospectral Optimal Control: From Theory to Flight</title>
      <link>https://arxiv.org/abs/2511.20843</link>
      <description>arXiv:2511.20843v1 Announce Type: new 
Abstract: The home space for optimal control is a Sobolev space. The home space for pseudospectral theory is also a Sobolev space. It thus seems natural to combine pseudospectral theory with optimal control theory and construct ``pseudospectral optimal control theory,'' a term coined by Ross. In this paper, we review key theoretical results in pseudospectral optimal control that have proven to be critical for a successful flight. Implementation details of flight demonstrations onboard NASA spacecraft are discussed along with emerging trends and techniques in both theory and practice. The 2011 launch of pseudospectral optimal control in embedded platforms is changing the way in which we see solutions to challenging control problems in aerospace and autonomous systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.20843v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.NA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.FA</category>
      <category>math.NA</category>
      <pubDate>Thu, 27 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.arcontrol.2012.09.002</arxiv:DOI>
      <arxiv:journal_reference>Annual Reviews in Control, 36/2, 2012, 182--197</arxiv:journal_reference>
      <dc:creator>I. M. Ross, M. Karpenko</dc:creator>
    </item>
    <item>
      <title>Maximization of Supercapacitor Storage via Topology Optimization of Electrode Structures</title>
      <link>https://arxiv.org/abs/2511.20969</link>
      <description>arXiv:2511.20969v1 Announce Type: new 
Abstract: As widely used electrochemical storage devices, supercapacitors deliver higher power density than batteries, but suffer from significantly lower energy density. In this work, we propose a topology optimization model for electrode structure to maximize energy storage in supercapacitors. The existence of minimizers to the resulting optimal control problem, which is constrained by a modified steady-state Poisson--Nernst--Planck system describing ionic electrodiffusion, has been theoretically established by using the direct method in the calculus of variation. Sensitivity analysis of the topology optimization model is performed to derive variational derivatives and corresponding adjoint equations. A gradient flow formulation discretized by a stabilized semi-implicit scheme is developed to solve the resulting topology optimization problem. Extensive numerical experiments present various porous electrode structures that own large area of electrode-electrolyte interface, demonstrating the effectiveness and robustness of the proposed topology optimization model and corresponding algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.20969v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 27 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Jiajie Li, Xiang Ji, Shenggao Zhou, Shengfeng Zhu</dc:creator>
    </item>
    <item>
      <title>Data-driven control of continuous-time systems: A synthesis-operator approach</title>
      <link>https://arxiv.org/abs/2511.21041</link>
      <description>arXiv:2511.21041v1 Announce Type: new 
Abstract: This paper addresses data-driven control of continuous-time systems. We develop a framework based on synthesis operators associated with input and state trajectories. A key advantage of the proposed method is that it does not require the state derivative and uses continuous-time data directly without sampling or filtering. First, systems compatible with given data are described by the synthesis operators into which data trajectories are embedded. Next, we characterize data informativity properties for system identification and for stabilization. Finally, we establish a necessary and sufficient condition for informativity for quadratic stabilization in the presence of process noise. This condition is formulated as linear matrix inequalities by exploiting the finite-rank structure of the synthesis operators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.21041v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 27 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Masashi Wakaiki</dc:creator>
    </item>
    <item>
      <title>Accelerated ADMM: Automated Parameter Tuning and Improved Linear Convergence</title>
      <link>https://arxiv.org/abs/2511.21210</link>
      <description>arXiv:2511.21210v1 Announce Type: new 
Abstract: This work studies the linear convergence of an accelerated scheme of the Alternating Direction Method of Multipliers (ADMM) for strongly convex and Lipschitz-smooth problems. We use the methodology of expressing the accelerated ADMM as a Lur'e system, i.e., an interconnection of a linear dynamical system in feedback with a slope-restricted operator, and we use Integral Quadratic Constraints to establish linear convergence. In addition, we propose several parameter tuning heuristics and their impact on the convergence rate through numerical analyses. Our new bounds show significantly improved linear convergence rates compared to the vanilla algorithm and previous proposed accelerated variants, which is also empirically validated on a LASSO regression benchmark.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.21210v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 27 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Meisam Tavakoli, Fabian Jakob, Guido Carnevale, Giuseppe Notarstefano, Andrea Iannelli</dc:creator>
    </item>
    <item>
      <title>Conditional Generative Modeling of Stochastic LTI Systems: A Behavioral Approach</title>
      <link>https://arxiv.org/abs/2511.21219</link>
      <description>arXiv:2511.21219v1 Announce Type: new 
Abstract: This paper presents a data-driven model for Linear Time-Invariant (LTI) stochastic systems by sampling from the conditional probability distribution of future outputs given past input-outputs and future inputs. It operates in a fully behavioral manner, relying solely on the current trajectory and pre-collected input-output data, without requiring explicit identification of system parameters. We refer to this model as a behavioral Conditional Generative Model (CGM). We prove the convergence of the distribution of samples generated by the CGM as the size of the trajectory library increases, with an explicit characterization of the convergence rate. Furthermore, we demonstrate that the gap between the asymptotic distribution of the proposed CGM and the true posterior distribution obtained by Kalman filter, which leverages the knowledge of all system parameters and all historical data, decreases exponentially with respect to the length of past samples. Finally, we integrate this generative model into predictive controllers for stochastic LTI systems. Numerical results verify the derived bounds and demonstrate the effectiveness of the controller equipped with the proposed behavioral CGM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.21219v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 27 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiayun Li, Yilin Mo</dc:creator>
    </item>
    <item>
      <title>An exact method for a problem of time slot pricing</title>
      <link>https://arxiv.org/abs/2511.21518</link>
      <description>arXiv:2511.21518v1 Announce Type: new 
Abstract: A company provides a service at different time slots, each slot being endowed with a capacity. A non-atomic population of users is willing to purchase this service. The population is modeled as a continuous measure over the preferred times. Every user looks at the time slot that minimizes the sum of the price assigned by the company to this time slot and the distance to their preferred time. If this sum is non-negative, then the user chooses this time slot for getting the service. If this sum is positive, then the user rejects the service.
  We address the problem of finding prices that ensure that the volume of users choosing each time slot is below capacity, while maximizing the revenue of the company. For the case where the distance function is convex, we propose an exact algorithm for solving this problem in time $O(n^3|P|^3)$, where $P$ is the set of possible prices and $n$ is the number of time slots. For the case where the prices can be any real numbers, this algorithm can also be used to find asymptotically optimal solutions in polynomial time under mild extra assumptions on the distance function and the measure modeling the population.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.21518v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 27 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Olivier Bilenne, Fr\'ed\'eric Meunier</dc:creator>
    </item>
    <item>
      <title>Singular extremals of optimal control problems with $L^1$ cost</title>
      <link>https://arxiv.org/abs/2511.21527</link>
      <description>arXiv:2511.21527v1 Announce Type: new 
Abstract: We study the optimal control problem for a control-affine system, where we want to minimize the $L^1$ norm of the control. First, we show how Pontryagin Maximum Principle (PMP) applies to this problem and we divide the extremal trajectories into two categories: regular and singular extremals. Then, we obtain a strong generalized Legendre-Clebsch condition for singular extremals and we show that this condition together with the absence of conjugate points is sufficient to ensure local strong optimality. We provide also some geometric examples where we apply our results. Finally, we prove that generalized Legendre-Clebsch condition is necessary for optimality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.21527v1</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <pubDate>Thu, 27 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrei Agrachev, Ivan Beschastnyi, Michele Motta</dc:creator>
    </item>
    <item>
      <title>Closed Form HJB Solution for Continuous-Time Optimal Control of a Non-Linear Input-Affine System</title>
      <link>https://arxiv.org/abs/2511.21593</link>
      <description>arXiv:2511.21593v1 Announce Type: new 
Abstract: Designing optimal controllers for nonlinear dynamical systems often relies on reinforcement learning and adaptive dynamic programming (ADP) to approximate solutions of the Hamilton Jacobi Bellman (HJB) equation. However, these methods require iterative training and depend on an initially admissible policy. This work introduces a new analytical framework that yields closed-form solutions to the HJB equation for a class of continuous-time nonlinear input-affine systems with known dynamics. Unlike ADP-based approaches, it avoids iterative learning and numerical approximation. Lyapunov theory is used to prove the asymptotic stability of the resulting closed-loop system, and theoretical guarantees are provided. The method offers a closed-form control policy derived from the HJB framework, demonstrating improved computational efficiency and optimal performance on state-of-the-art optimal control problems in the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.21593v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 27 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Akash Vyas, Shreyas Kumar, Jayant Kumar Mohanta, Ravi Prakash</dc:creator>
    </item>
    <item>
      <title>Beyond Expectation: Concentration Inequalities for Randomized Iterative Methods</title>
      <link>https://arxiv.org/abs/2511.20877</link>
      <description>arXiv:2511.20877v1 Announce Type: cross 
Abstract: Stochastic iterative methods are useful in a variety of large-scale numerical linear algebraic, machine learning, and statistical problems, in part due to their low-memory footprint. They are frequently used in a variety of applications, and thus it is imperative to have a thorough theoretical understanding of their behavior. Most theoretical convergence results for stochastic iterative methods provide bounds on the expected error of the iterates, and yield a type of average case analysis. However, understanding the behavior of these methods in the near-worst-case is desirable. For stochastic methods, this motivates providing bounds on the variance and concentration of their error, which can be used to generate confidence intervals around the bounds on their expected error.
  Here, we provide upper bounds for the concentration and variance of the error of a general class of linear stochastic iterative methods, including the randomized Kaczmarz method and the randomized Gauss--Seidel method, and a more general class of nonlinear stochastic iterative methods, including the randomized Kaczmarz method for systems of linear inequalities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.20877v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Thu, 27 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Toby Anderson, Max Collins, Jamie Haddock, Jackie Lok, Elizaveta Rebrova</dc:creator>
    </item>
    <item>
      <title>Independent policy gradient-based reinforcement learning for economic and reliable energy management of multi-microgrid systems</title>
      <link>https://arxiv.org/abs/2511.20977</link>
      <description>arXiv:2511.20977v1 Announce Type: cross 
Abstract: Efficiency and reliability are both crucial for energy management, especially in multi-microgrid systems (MMSs) integrating intermittent and distributed renewable energy sources. This study investigates an economic and reliable energy management problem in MMSs under a distributed scheme, where each microgrid independently updates its energy management policy in a decentralized manner to optimize the long-term system performance collaboratively. We introduce the mean and variance of the exchange power between the MMS and the main grid as indicators for the economic performance and reliability of the system. Accordingly, we formulate the energy management problem as a mean-variance team stochastic game (MV-TSG), where conventional methods based on the maximization of expected cumulative rewards are unsuitable for variance metrics. To solve MV-TSGs, we propose a fully distributed independent policy gradient algorithm, with rigorous convergence analysis, for scenarios with known model parameters. For large-scale scenarios with unknown model parameters, we further develop a deep reinforcement learning algorithm based on independent policy gradients, enabling data-driven policy optimization. Numerical experiments in two scenarios validate the effectiveness of the proposed methods. Our approaches fully leverage the distributed computational capabilities of MMSs and achieve a well-balanced trade-off between economic performance and operational reliability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.20977v1</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 27 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Junkai Hu, Li Xia</dc:creator>
    </item>
    <item>
      <title>A Unified Understanding of Offline Data Selection and Online Self-refining Generation for Post-training LLMs</title>
      <link>https://arxiv.org/abs/2511.21056</link>
      <description>arXiv:2511.21056v1 Announce Type: cross 
Abstract: Offline data selection and online self-refining generation, which enhance the data quality, are crucial steps in adapting large language models (LLMs) to specific downstream tasks. We tackle offline data selection and online self-refining generations through an optimization perspective. Specifically, bilevel data selection is used for offline data selection with respect to the validation dataset, and we treat online self-refining generation as a model adaptation step of selecting the model trained on current responses that best fits the validation data. Our framework offers a unified understanding of offline data selection and self-refining generation by assigning a learned data weight to each question and response, either explicitly or implicitly. For the first time, we theoretically demonstrate the effectiveness of the bilevel data selection framework and demonstrate its performance gains over unfiltered direct mixing baselines. By combining offline data with validation-weighted online generations, our method enhances fine-tuning performance. Experiments on quality enhancement and safety-aware LLM fine-tuning validate its effectiveness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.21056v1</guid>
      <category>cs.LG</category>
      <category>cs.CL</category>
      <category>math.OC</category>
      <pubDate>Thu, 27 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Quan Xiao, Tianyi Chen</dc:creator>
    </item>
    <item>
      <title>Stability of data-driven Koopman MPC with terminal conditions</title>
      <link>https://arxiv.org/abs/2511.21248</link>
      <description>arXiv:2511.21248v1 Announce Type: cross 
Abstract: This paper derives conditions under which Model Predictive Control (MPC) with terminal conditions, using a data-driven surrogate model as a prediction model, asymptotically stabilizes the plant despite approximation errors. In particular, we prove recursive feasibility and asymptotic stability if a proportional error bound holds, where proportional means that the bound is linear in the norm of the state and the input. For a broad class of nonlinear systems, this condition can be satisfied using data-driven surrogate models generated by kernel Extended Dynamic Mode Decomposition (kEDMD) using the Koopman operator. Last, the applicability of the proposed framework is demonstrated in a numerical case study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.21248v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 27 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Irene Schimperna, Lea Bold, Johannes K\"ohler, Karl Worthmann, Lalo Magni</dc:creator>
    </item>
    <item>
      <title>Dynamic characterization of barycentric optimal transport problems and their martingale relaxation</title>
      <link>https://arxiv.org/abs/2511.21287</link>
      <description>arXiv:2511.21287v1 Announce Type: cross 
Abstract: We extend the Benamou-Brenier formula from classical optimal transport to weak optimal transport and show that the barycentric optimal transport problem studied by Gozlan and Juillet has a dynamic analogue. We also investigate a martingale relaxation of this problem, and relate it to the martingale Benamou-Brenier formula of Backhoff-Veraguas, Beiglb\"ock, Huesmann and K\"allblad.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.21287v1</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <category>q-fin.MF</category>
      <pubDate>Thu, 27 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ivan Guo, Severin Nilsson, Johannes Wiesel</dc:creator>
    </item>
    <item>
      <title>New Hybrid Heuristics for Pseudo-Boolean Propagation</title>
      <link>https://arxiv.org/abs/2511.21417</link>
      <description>arXiv:2511.21417v1 Announce Type: cross 
Abstract: In pseudo-boolean solving the currently most successful unit propagation strategy is a hybrid mode combining the watched literal scheme with the counting method. This short paper introduces new heuristics for this hybrid decision, which are able to drastically outperform the current method in the RoundingSAT solver.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.21417v1</guid>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Thu, 27 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mia M\"u{\ss}ig, Jan Johannsen</dc:creator>
    </item>
    <item>
      <title>Mean-Field Limits for Two-Layer Neural Networks Trained with Consensus-Based Optimization</title>
      <link>https://arxiv.org/abs/2511.21466</link>
      <description>arXiv:2511.21466v1 Announce Type: cross 
Abstract: We study two-layer neural networks and train these with a particle-based method called consensus-based optimization (CBO). We compare the performance of CBO against Adam on two test cases and demonstrate how a hybrid approach, combining CBO with Adam, provides faster convergence than CBO. In the context of multi-task learning, we recast CBO into a formulation that offers less memory overhead. The CBO method allows for a mean-field limit formulation, which we couple with the mean-field limit of the neural network. To this end, we first reformulate CBO within the optimal transport framework. Finally, in the limit of infinitely many particles, we define the corresponding dynamics on the Wasserstein-over-Wasserstein space and show that the variance decreases monotonically.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.21466v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 27 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>William De Deyn, Michael Herty, Giovanni Samaey</dc:creator>
    </item>
    <item>
      <title>Bang-Bang Evasion: Its Stochastic Optimality and a Terminal-Set-Based Implementation</title>
      <link>https://arxiv.org/abs/2511.21633</link>
      <description>arXiv:2511.21633v1 Announce Type: cross 
Abstract: We address the problem of optimal evasion in a planar endgame engagement, where a target with bounded lateral acceleration seeks to avoid interception by a missile guided by a linear feedback law. Contrary to existing approaches, that assume perfect information or use heuristic maneuver models in stochastic settings, we formulate the problem in an inherently stochastic framework involving imperfect information and bounded controls. Complying with the generalized separation theorem, the control law factors in the posterior distribution of the state. Extending the well-known optimality of bang-bang evasion maneuvers in deterministic settings to the realm of realistic, stochastic evasion scenarios, we firstly prove that an optimal evasion strategy always exists, and that the set of optimal solutions includes at least one bang-bang policy, rendering the resulting optimal control problem finite-dimensional. Leveraging this structure, we secondly propose the closed-loop terminal-set-based evasion (TSE) strategy, and demonstrate its effectiveness in simulation against a proportional navigation pursuer. Monte Carlo simulations show that the TSE strategy outperforms traditional stochastic evasion strategies based on random telegraph, Singer, and weaving models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.21633v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 27 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liraz Mudrik, Yaakov Oshman</dc:creator>
    </item>
    <item>
      <title>Stochastic Optimal Control of Interacting Particle Systems in Hilbert Spaces and Applications</title>
      <link>https://arxiv.org/abs/2511.21646</link>
      <description>arXiv:2511.21646v1 Announce Type: cross 
Abstract: Optimal control of interacting particles governed by stochastic evolution equations in Hilbert spaces is an open area of research. Such systems naturally arise in formulations where each particle is modeled by stochastic partial differential equations, path-dependent stochastic differential equations (such as stochastic delay differential equations or stochastic Volterra integral equations), or partially observed stochastic systems. The purpose of this manuscript is to build the foundations for a limiting theory as the number of particles tends to infinity. We prove the convergence of the value functions $u_n$ of finite particle systems to a function $\mathcal{V}$, {which} is the unique {$L$}-viscosity solution of the corresponding mean-field Hamilton-Jacobi-Bellman equation {in the space of probability measures}, and we identify its lift with the value function $U$ of the so-called ``lifted'' limit optimal control problem. Under suitable additional assumptions, we show $C^{1,1}$-regularity of $U$, we prove that $\mathcal{V}$ projects precisely onto the value functions $u_n$, and that optimal (resp. optimal feedback) controls of the particle system correspond to optimal (resp. optimal feedback) controls of the lifted control problem started at the corresponding initial condition. To the best of our knowledge, these are the first results of this kind for stochastic optimal control problems for interacting particle systems of stochastic evolution equations in Hilbert spaces. We apply the developed theory to problems arising in economics where the particles are modeled by stochastic delay differential equations and stochastic partial differential equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.21646v1</guid>
      <category>math.PR</category>
      <category>econ.GN</category>
      <category>math.AP</category>
      <category>math.OC</category>
      <category>q-fin.EC</category>
      <pubDate>Thu, 27 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Filippo de Feo, Fausto Gozzi, Andrzej \'Swi\k{e}ch, Lukas Wessels</dc:creator>
    </item>
    <item>
      <title>Decentralized Bilevel Optimization: A Perspective from Transient Iteration Complexity</title>
      <link>https://arxiv.org/abs/2402.03167</link>
      <description>arXiv:2402.03167v5 Announce Type: replace 
Abstract: Stochastic bilevel optimization (SBO) is becoming increasingly essential in machine learning due to its versatility in handling nested structures. To address large-scale SBO, decentralized approaches have emerged as effective paradigms in which nodes communicate with immediate neighbors without a central server, thereby improving communication efficiency and enhancing algorithmic robustness. However, most decentralized SBO algorithms focus solely on asymptotic convergence rates, overlooking transient iteration complexity-the number of iterations required before asymptotic rates dominate, which results in limited understanding of the influence of network topology, data heterogeneity, and the nested bilevel algorithmic structures. To address this issue, this paper introduces D-SOBA, a Decentralized Stochastic One-loop Bilevel Algorithm framework. D-SOBA comprises two variants: D-SOBA-SO, which incorporates second-order Hessian and Jacobian matrices, and D-SOBA-FO, which relies entirely on first-order gradients. We provide a comprehensive non-asymptotic convergence analysis and establish the transient iteration complexity of D-SOBA. This provides the first theoretical understanding of how network topology, data heterogeneity, and nested bilevel structures influence decentralized SBO. Extensive experimental results demonstrate the efficiency and theoretical advantages of D-SOBA.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.03167v5</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Thu, 27 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Boao Kong, Shuchen Zhu, Songtao Lu, Xinmeng Huang, Kun Yuan</dc:creator>
    </item>
    <item>
      <title>On second order conditions for singular optimal control of port-Hamiltonian systems</title>
      <link>https://arxiv.org/abs/2407.03213</link>
      <description>arXiv:2407.03213v3 Announce Type: replace 
Abstract: We study nonlinear singular optimal control problems of port-Hamil-tonian (descriptor) systems. We employ general control-affine cost functionals that include as a special case the energy supplied to the system. We first derive optimality conditions for the case of ordinary differential equations with and without control bounds by applying the general theory to the specially structured port-Hamiltonian case, and show that this leads to elegant optimality conditions, in particular in the linear case. We then extend these results to classes of nonlinear port-Hamiltonian descriptor systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03213v3</guid>
      <category>math.OC</category>
      <pubDate>Thu, 27 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>M. Soledad Aronna, Volker Mehrmann</dc:creator>
    </item>
    <item>
      <title>A multilevel stochastic regularized first-order method with application to finite sum minimization</title>
      <link>https://arxiv.org/abs/2412.11630</link>
      <description>arXiv:2412.11630v2 Announce Type: replace 
Abstract: In this paper, we propose a multilevel stochastic framework for the solution of nonconvex unconstrained optimization problems. The proposed approach uses random regularized first-order models that exploit an available hierarchical description of the problem, being either in the classical variable space or in the function space, meaning that different levels of accuracy for the objective function are available. We propose a convergence analysis showing an almost sure global convergence of the method to a first order stationary point. The numerical behavior is tested on the solution of finite sum minimization problems. Differently from classical deterministic multilevel schemes, our stochastic method does not require the finest approximation to coincide with the original objective function along all the optimization process. This allows for significantly decreasing their cost, for instance in data-fitting problems, where considering all the data at each iteration can be avoided.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.11630v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 27 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Filippo Marini, Margherita Porcelli, Elisa Riccietti</dc:creator>
    </item>
    <item>
      <title>Discontinuous integro-differential equations and sliding mode control</title>
      <link>https://arxiv.org/abs/2505.10116</link>
      <description>arXiv:2505.10116v2 Announce Type: replace 
Abstract: The paper deals with analysis and design sliding mode control systems modeled by integro-differential equations. Filippov method and equivalent control approach are extended to a class of nonlinear discontinuous integro-differential equations. Sliding mode control algorithm is designed for a control system with distributed input delay. The obtained results are illustrated by numerical example.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.10116v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 27 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrey Polyakov</dc:creator>
    </item>
    <item>
      <title>On Discounted Infinite-Time Mean Field Games</title>
      <link>https://arxiv.org/abs/2505.15131</link>
      <description>arXiv:2505.15131v4 Announce Type: replace 
Abstract: In this paper, we study the infinite-time mean field games with discounting, establishing an equilibrium where individual optimal strategies collectively regenerate the mean-field distribution. To solve this problem, we partition all agents into a representative player and the social equilibrium. When the optimal strategy of the representative player shares the same feedback form with the strategy of the social equilibrium, we say the system achieves a Nash equilibrium.
  We construct a Nash equilibrium using the stochastic maximum principle and infinite-time forward-backward stochastic differential equations(FBSDEs). By employing the elliptic master equations, a class of distribution-dependent elliptic PDEs , we provide a representation for the Nash equilibrium. We prove the Yamada-Watanabe theorem and show the weak uniqueness for infinite-time FBSDEs. And we prove that the solutions to a system of infinite-time FBSDEs can be employed to construct viscosity solutions for a class of distribution-dependent elliptic PDEs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.15131v4</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Thu, 27 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yongsheng Song, Zeyu Yang</dc:creator>
    </item>
    <item>
      <title>Finite-Time Minimax Bounds and an Optimal Lyapunov Policy in Queueing Control</title>
      <link>https://arxiv.org/abs/2506.18278</link>
      <description>arXiv:2506.18278v2 Announce Type: replace 
Abstract: We introduce an original minimax framework for finite-time performance analysis in queueing control and propose a surprisingly simple Lyapunov-based scheduling policy with superior finite-time performance. The framework quantitatively characterizes how the expected total queue length scales with key system parameters, including the capacity of the scheduling set and the variability of arrivals and departures across queues. To our knowledge, this provides the first firm foundation for evaluating and comparing scheduling policies in the finite-time regime, including nonstationary settings, and shows that the proposed policy can provably and empirically outperform classical MaxWeight in finite time. Within this framework, we establish three main sets of results. First, we derive minimax lower bounds on the expected total queue length for parallel-queue scheduling via a novel Brownian coupling argument. Second, we propose a new policy, LyapOpt, which minimizes the full quadratic Lyapunov drift-capturing both first- and second-order terms-and achieves optimal finite-time performance in heavy traffic while retaining classical stability guarantees. Third, we identify a key limitation of the classical MaxWeight policy, which optimizes only the first-order drift: its finite-time performance depends suboptimally on system parameters, leading to substantially larger backlogs in explicitly characterized settings. Together, these results delineate the scope and limitations of classical drift-based scheduling and motivate new queueing-control methods with rigorous finite-time guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.18278v2</guid>
      <category>math.OC</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Thu, 27 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yujie Liu, Vincent Y. F. Tan, Yunbei Xu</dc:creator>
    </item>
    <item>
      <title>Approximating the order 2 quantum Wasserstein distance using the moment-SOS hierarchy</title>
      <link>https://arxiv.org/abs/2506.20006</link>
      <description>arXiv:2506.20006v2 Announce Type: replace 
Abstract: Optimal transport theory has recently been extended to quantum settings, where the density matrices generalize the probability measures. In this paper, we study the computational aspects of the order 2 quantum Wasserstein distance, formulating it as an infinite dimensional linear program in the space of positive Borel measures supported on products of two unit spheres. This formulation is recognized as an instance of the Generalized Moment Problem, which enables us to use the moment-sums of squares hierarchy to provide a sequence of lower bounds converging to the distance. We illustrate our approach with numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.20006v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 27 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Saroj Prasad Chhatoi, Victor Magron</dc:creator>
    </item>
    <item>
      <title>Stiefel optimization is NP-hard</title>
      <link>https://arxiv.org/abs/2507.02839</link>
      <description>arXiv:2507.02839v2 Announce Type: replace 
Abstract: We show that linearly constrained linear optimization over a Stiefel or Grassmann manifold is NP-hard in general. We show that the same is true for unconstrained quadratic optimization over a Stiefel manifold. We will show that unless $\mathrm{P}=\mathrm{NP}$, these optimization problems over a Stiefel manifold do not have $\mathrm{FPTAS}$. As an aside we extend our results to flag manifolds. Combined with earlier findings, this shows that manifold optimization is a difficult endeavor -- even the simplest problems like LP and unconstrained QP are already NP-hard on the most common manifolds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.02839v2</guid>
      <category>math.OC</category>
      <category>cs.CC</category>
      <pubDate>Thu, 27 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zehua Lai, Lek-Heng Lim, Tianyun Tang</dc:creator>
    </item>
    <item>
      <title>Clarke Differentials and the Envelope Theorem in Dynamic Programming</title>
      <link>https://arxiv.org/abs/2509.17103</link>
      <description>arXiv:2509.17103v2 Announce Type: replace 
Abstract: In this paper, we consider a deterministic dynamic programming model, and derive the envelope theorem using the Clarke differential. Compared with previous research, we do not require differentiability, convexity, or boundedness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.17103v2</guid>
      <category>math.OC</category>
      <category>econ.TH</category>
      <pubDate>Thu, 27 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuhki Hosoya</dc:creator>
    </item>
    <item>
      <title>On Characterizations of $\sigma$-Quasiconvexity</title>
      <link>https://arxiv.org/abs/2511.11384</link>
      <description>arXiv:2511.11384v2 Announce Type: replace 
Abstract: We revisit classical gradient characterizations of quasiconvexity and provide corrected proofs that close gaps in earlier arguments. For the differentiable case of $\sigma$-quasiconvexity, we establish the full equivalence between several first-order conditions, resolving a remaining implication left open in the recent literature. Our approach yields a concise, self-contained proof of a classical characterization originally stated in the 1970s and sharpens the first-order theory for strong quasiconvexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.11384v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 27 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nguyen Xuan Duy Bao, Nguyen Mau Nam</dc:creator>
    </item>
    <item>
      <title>The iterates of FISTA convergence even under inexact computations and stochastic gradients</title>
      <link>https://arxiv.org/abs/2511.12665</link>
      <description>arXiv:2511.12665v2 Announce Type: replace 
Abstract: Very recently, the papers "Point Convergence of Nesterov's Accelerated Gradient Method: An AI-Assisted Proof" by Jang and Ryu, and "The Iterates of Nesterov's Accelerated Algorithm Converge in the Critical Regimes" by Bot, Fadili, and Nguyen simultaneously have resolved a long-standing open problem concerning Nesterov's accelerated gradient method. These works show that the iterates of the algorithm (known in its composite form as FISTA) indeed converge to an optimal solution. In this work, we extend these results and prove that, in infinite dimensional Hilbert spaces, the iterates of such an algorithm still converge (in the weak sense) even when the proximity operator and the gradient are computed inexactly, with the latter possibly stochastic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.12665v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 27 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Saverio Salzo</dc:creator>
    </item>
    <item>
      <title>An Axiomatic Analysis of Distributionally Robust Optimization with $q$-Norm Ambiguity Sets for Probability Smoothing</title>
      <link>https://arxiv.org/abs/2511.18815</link>
      <description>arXiv:2511.18815v2 Announce Type: replace 
Abstract: We analyze the axiomatic properties of a class of probability estimators derived from Distributionally Robust Optimization (DRO) with $q$-norm ambiguity sets ($q$-DRO), a principled approach to the zero-frequency problem. While classical estimators such as Laplace smoothing are characterized by strong linearity axioms like Ratio Preservation, we show that $q$-DRO provides a flexible alternative that satisfies other desirable properties. We first prove that for any $q \in [1, \infty]$, the $q$-DRO estimator satisfies the fundamental axioms of Positivity and Symmetry. For the case of $q \in (1, \infty)$, we then prove that it also satisfies Order Preservation. Our analysis of the optimality conditions also reveals that the $q$-DRO formulation is equivalent to the regularized empirical loss minimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.18815v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 27 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yoichi Izunaga, Kota Kurihara, Hokuto Nagano, Daiki Uchida</dc:creator>
    </item>
    <item>
      <title>Adaptive SGD with Line-Search and Polyak Stepsizes: Nonconvex Convergence and Accelerated Rates</title>
      <link>https://arxiv.org/abs/2511.20207</link>
      <description>arXiv:2511.20207v2 Announce Type: replace 
Abstract: We extend the convergence analysis of AdaSLS and AdaSPS in [Jiang and Stich, 2024] to the nonconvex setting, presenting a unified convergence analysis of stochastic gradient descent with adaptive Armijo line-search (AdaSLS) and Polyak stepsize (AdaSPS) for nonconvex optimization. Our contributions include: (1) an $\mathcal{O}(1/\sqrt{T})$ convergence rate for general nonconvex smooth functions, (2) an $\mathcal{O}(1/T)$ rate under quasar-convexity and interpolation, and (3) an $\mathcal{O}(1/T)$ rate under the strong growth condition for general nonconvex functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.20207v2</guid>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 27 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haotian Wu</dc:creator>
    </item>
    <item>
      <title>Single- vs. Dual-Policy Reinforcement Learning for Dynamic Bike Rebalancing</title>
      <link>https://arxiv.org/abs/2402.03589</link>
      <description>arXiv:2402.03589v2 Announce Type: replace-cross 
Abstract: Bike-sharing systems (BSS) provide a sustainable urban mobility solution, but ensuring their reliability requires effective rebalancing strategies to address stochastic demand and prevent station imbalances. This paper proposes reinforcement learning (RL) algorithms for dynamic rebalancing problem with multiple vehicles, introducing and comparing two RL approaches: Single-policy RL and Dual-policy RL. We formulate this network optimization problem as a Markov Decision Process within a continuous-time framework, allowing vehicles to make independent and cooperative rebalancing decisions without synchronization constraints. In the first approach, a single deep Q-network (DQN) is trained to jointly learn inventory and routing decisions. The second approach decouples node-level inventory decisions from arc-level vehicle routing, enhancing learning efficiency and adaptability. A high-fidelity simulator under the first-arrive-first-serve rule is developed to estimate rewards across diverse demand scenarios influenced by temporal and weather variations. Extensive experiments demonstrate that while the single-policy model is competitive against several benchmarks, the dual-policy model significantly reduces lost demand. These findings provide valuable insights for bike-sharing operators, reinforcing the potential of RL for real-time rebalancing and paving the way for more adaptive and intelligent urban mobility solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.03589v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 27 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiaqi Liang, Defeng Liu, Sanjay Dominik Jena, Andrea Lodi, Thibaut Vidal</dc:creator>
    </item>
    <item>
      <title>A Partially Defined Game with Costs</title>
      <link>https://arxiv.org/abs/2405.07591</link>
      <description>arXiv:2405.07591v3 Announce Type: replace-cross 
Abstract: The present study explores a problem that can be resolved by employing the notion of a partially defined cooperative game, yet cannot by using a restricted game. The following situation is considered: First, it is assumed that the worth of the grand and singleton coalitions are known. It takes some amount of costs to obtain worth of unknown coalitions. If it is performed, then the worth of the grand coalition is decreased by the value of a cost function. With the view point of fairness of a payoff allocation, we should examine coalitional worth as much as possible. However, we should stop examining coalitional worth at some point since total payoff is reduced by continuing the examinations. We name the new decision making problem a partially defined cooperative game with costs. The problem of a partially defined cooperative game with costs is finding the solution of partially defined cooperative games at each point and the best exiting rule of examinations of coalitional worth.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07591v3</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Thu, 27 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Satoshi Masuya</dc:creator>
    </item>
    <item>
      <title>A Catalyst Framework for the Quantum Linear System Problem via the Proximal Point Algorithm</title>
      <link>https://arxiv.org/abs/2406.13879</link>
      <description>arXiv:2406.13879v2 Announce Type: replace-cross 
Abstract: Solving systems of linear equations is a fundamental problem, but it can be computationally intensive for classical algorithms in high dimensions. Existing quantum algorithms can achieve exponential speedups for the quantum linear system problem (QLSP) in terms of the problem dimension, but the advantage is bottlenecked by condition number of the coefficient matrix. In this work, we propose a new quantum algorithm for QLSP inspired by the classical proximal point algorithm (PPA). Our proposed method can be viewed as a meta-algorithm that allows inverting a modified matrix via an existing \texttt{QLSP\_solver}, thereby directly approximating the solution vector instead of approximating the inverse of the coefficient matrix. By carefully choosing the step size $\eta$, the proposed algorithm can effectively precondition the linear system to mitigate the dependence on condition numbers that hindered the applicability of previous approaches. Importantly, this is the first iterative framework for QLSP where a tunable parameter $\eta$ and initialization $x_0$ allows controlling the trade-off between the runtime and approximation error.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.13879v2</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 27 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Junhyung Lyle Kim, Nai-Hui Chia, Anastasios Kyrillidis</dc:creator>
    </item>
    <item>
      <title>L4acados: Learning-based models for acados, applied to Gaussian process-based predictive control</title>
      <link>https://arxiv.org/abs/2411.19258</link>
      <description>arXiv:2411.19258v3 Announce Type: replace-cross 
Abstract: Incorporating learning-based models, such as artificial neural networks or Gaussian processes, into model predictive control (MPC) strategies can significantly improve control performance and online adaptation capabilities for real-world applications. Still, enabling state-of-the-art implementations of learning-based models for MPC is complicated by the challenge of interfacing machine learning frameworks with real-time optimal control software. This work aims at filling this gap by incorporating external sensitivities in sequential quadratic programming solvers for nonlinear optimal control. To this end, we provide L4acados, a general framework for incorporating Python-based dynamics models in the real-time optimal control software acados. By computing external sensitivities via a user-defined Python module, L4acados enables the implementation of MPC controllers with learning-based residual models in acados, while supporting parallelization of sensitivity computations when preparing the quadratic subproblems. We demonstrate significant speed-ups and superior scaling properties of L4acados compared to available software using a neural-network-based control example. Last, we provide an efficient and modular real-time implementation of Gaussian process-based MPC using L4acados, which is applied to two hardware examples: autonomous miniature racing, as well as motion control of a full-scale autonomous vehicle for an ISO lane change maneuver.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19258v3</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 27 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amon Lahr, Joshua N\"af, Kim P. Wabersich, Jonathan Frey, Pascal Siehl, Andrea Carron, Moritz Diehl, Melanie N. Zeilinger</dc:creator>
    </item>
    <item>
      <title>MeshCone: Second-Order Cone Programming for Geometrically-Constrained Mesh Enhancement</title>
      <link>https://arxiv.org/abs/2412.08484</link>
      <description>arXiv:2412.08484v4 Announce Type: replace-cross 
Abstract: Modern mesh generation pipelines whether learning-based or classical often produce outputs requiring post-processing to achieve production-quality geometry. This work introduces MeshCone, a convex optimization framework for guided mesh refinement that leverages reference geometry to correct deformed or degraded meshes. We formulate the problem as a second-order cone program where vertex positions are optimized to align with target geometry while enforcing smoothness through convex edge-length regularization. MeshCone performs geometry-aware optimization that preserves fine details while correcting structural defects. We demonstrate robust performance across 56 diverse object categories from ShapeNet and ThreeDScans, achieving superior refinement quality compared to Laplacian smoothing and unoptimized baselines while maintaining sub-second inference times. MeshCone is particularly suited for applications where reference geometry is available, such as mesh-from-template workflows, scan-to-CAD alignment, and quality assurance in asset production pipelines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.08484v4</guid>
      <category>cs.GR</category>
      <category>cs.CV</category>
      <category>math.OC</category>
      <pubDate>Thu, 27 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexander Valverde</dc:creator>
    </item>
    <item>
      <title>Policy Optimization and Multi-agent Reinforcement Learning for Mean-variance Team Stochastic Games</title>
      <link>https://arxiv.org/abs/2503.22779</link>
      <description>arXiv:2503.22779v3 Announce Type: replace-cross 
Abstract: We study a long-run mean-variance team stochastic game (MV-TSG), where each agent shares a common mean-variance objective for the system and takes actions independently to maximize it. MV-TSG has two main challenges. First, the variance metric is neither additive nor Markovian in a dynamic setting. Second, simultaneous policy updates of all agents lead to a non-stationary environment for each individual agent. Both challenges make dynamic programming inapplicable. In this paper, we study MV-TSGs from the perspective of sensitivity-based optimization. The performance difference and performance derivative formulas for joint policies are derived, which provide optimization information for MV-TSGs. We prove the existence of a deterministic Nash policy for this problem. Subsequently, we propose a Mean-Variance Multi-Agent Policy Iteration (MV-MAPI) algorithm with a sequential update scheme, where individual agent policies are updated one by one in a given order. We prove that the MV-MAPI algorithm converges to a first-order stationary point of the objective function. By analyzing the local geometry of stationary points, we derive specific conditions for stationary points to be (local) Nash equilibria, and further, strict local optima. To solve large-scale MV-TSGs in scenarios with unknown environmental parameters, we extend the idea of trust region methods to MV-MAPI and develop a multi-agent reinforcement learning algorithm named Mean-Variance Multi-Agent Trust Region Policy Optimization (MV-MATRPO). We derive a performance lower bound for each update of joint policies. Finally, numerical experiments on energy management in multiple microgrid systems are conducted.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.22779v3</guid>
      <category>cs.MA</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 27 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Junkai Hu, Li Xia</dc:creator>
    </item>
    <item>
      <title>Alignment of large language models with constrained learning</title>
      <link>https://arxiv.org/abs/2505.19387</link>
      <description>arXiv:2505.19387v2 Announce Type: replace-cross 
Abstract: We study the problem of computing an optimal large language model (LLM) policy for the constrained alignment problem, where the goal is to maximize a primary reward objective while satisfying constraints on secondary utilities. Despite the popularity of Lagrangian-based LLM policy search in constrained alignment, iterative primal-dual methods often fail to converge, and non-iterative dual-based methods do not achieve optimality in the LLM parameter space. To address these challenges, we employ Lagrangian duality to develop an iterative dual-based alignment method that alternates between updating the LLM policy via Lagrangian maximization and updating the dual variable via dual descent. In theory, we characterize the primal-dual gap between the primal value in the distribution space and the dual value in the LLM parameter space. We further quantify the optimality gap of the learned LLM policies at near-optimal dual variables with respect to both the objective and the constraint functions. These results prove that dual-based alignment methods can find an optimal constrained LLM policy, up to an LLM parametrization gap. We demonstrate the effectiveness and merits of our approach through extensive experiments conducted on the PKU-SafeRLHF and Anthropic HH-RLHF datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19387v2</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 27 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Botong Zhang, Shuo Li, Ignacio Hounie, Osbert Bastani, Dongsheng Ding, Alejandro Ribeiro</dc:creator>
    </item>
    <item>
      <title>Infinite-time Mean Field FBSDEs and Viscosity Solutions to Elliptic Master Equations</title>
      <link>https://arxiv.org/abs/2510.03707</link>
      <description>arXiv:2510.03707v2 Announce Type: replace-cross 
Abstract: This paper presents a further investigation of the properties of infinite-time mean field FBSDEs and elliptic master equations, which were introduced in \cite{yang2025discounted} as mathematical tools for solving discounted infinite-time mean field games. By establishing the continuous dependence of the FBSDE solutions on their initial values, we prove the flow property of the mean field FBSDEs. Furthermore, we prove that, at the Nash equilibrium, the value function of the representative player constitutes a viscosity solution to the corresponding elliptic master equation. Our work extends the classical theory of finite-time mean field games and parabolic master equations to the infinite-time setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.03707v2</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <pubDate>Thu, 27 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yongsheng Song, Zeyu Yang</dc:creator>
    </item>
    <item>
      <title>Simultaneous Calibration of Noise Covariance and Kinematics for State Estimation of Legged Robots via Bi-level Optimization</title>
      <link>https://arxiv.org/abs/2510.11539</link>
      <description>arXiv:2510.11539v2 Announce Type: replace-cross 
Abstract: Accurate state estimation is critical for legged and aerial robots operating in dynamic, uncertain environments. A key challenge lies in specifying process and measurement noise covariances, which are typically unknown or manually tuned. In this work, we introduce a bi-level optimization framework that jointly calibrates covariance matrices and kinematic parameters in an estimator-in-the-loop manner. The upper level treats noise covariances and model parameters as optimization variables, while the lower level executes a full-information estimator. Differentiating through the estimator allows direct optimization of trajectory-level objectives, resulting in accurate and consistent state estimates. We validate our approach on quadrupedal and humanoid robots, demonstrating significantly improved estimation accuracy and uncertainty calibration compared to hand-tuned baselines. Our method unifies state estimation, sensor, and kinematics calibration into a principled, data-driven framework applicable across diverse robotic platforms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.11539v2</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <pubDate>Thu, 27 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Denglin Cheng, Jiarong Kang, Xiaobin Xiong</dc:creator>
    </item>
    <item>
      <title>Duality Perspective on Nonlinear Eigenproblems</title>
      <link>https://arxiv.org/abs/2511.19188</link>
      <description>arXiv:2511.19188v2 Announce Type: replace-cross 
Abstract: We investigate nonlinear eigenproblems for a broad class of proper, closed, convex functionals in reflexive Banach spaces. We develop a dual formulation of the nonlinear eigenproblem using the Fenchel conjugate and establish an equivalence to the primal problem. Further, we introduce a duality gap and a geometric characterization of eigenvectors that apply in general Banach spaces. We interpret the dual problem as the eigenproblem for the inverse operator of the primal problem. Concerning numerical methods for solving nonlinear eigenproblems, we analyze the inverse power method, framed as a dual power method, showing strong convergence in the case of absolutely p-homogeneous functionals. Our theoretical results are validated by extensive numerical experiments for the p-Laplacian. We further connect the flow-based proximal power method from the literature to the inverse power method and discuss two numerical approaches to approximate higher-order nonlinear eigenfunctions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.19188v2</guid>
      <category>math.SP</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Thu, 27 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jonathan Laubmann, Manuel Friedrich, Daniel Tenbrinck</dc:creator>
    </item>
    <item>
      <title>Lower Complexity Bounds for Nonconvex-Strongly-Convex Bilevel Optimization with First-Order Oracles</title>
      <link>https://arxiv.org/abs/2511.19656</link>
      <description>arXiv:2511.19656v2 Announce Type: replace-cross 
Abstract: Although upper bound guarantees for bilevel optimization have been widely studied, progress on lower bounds has been limited due to the complexity of the bilevel structure. In this work, we focus on the smooth nonconvex-strongly-convex setting and develop new hard instances that yield nontrivial lower bounds under deterministic and stochastic first-order oracle models. In the deterministic case, we prove that any first-order zero-respecting algorithm requires at least $\Omega(\kappa^{3/2}\epsilon^{-2})$ oracle calls to find an $\epsilon$-accurate stationary point, improving the optimal lower bounds known for single-level nonconvex optimization and for nonconvex-strongly-convex min-max problems. In the stochastic case, we show that at least $\Omega(\kappa^{5/2}\epsilon^{-4})$ stochastic oracle calls are necessary, again strengthening the best known bounds in related settings. Our results expose substantial gaps between current upper and lower bounds for bilevel optimization and suggest that even simplified regimes, such as those with quadratic lower-level objectives, warrant further investigation toward understanding the optimal complexity of bilevel optimization under standard first-order oracles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.19656v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 27 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kaiyi Ji</dc:creator>
    </item>
  </channel>
</rss>
