<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CY updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CY</link>
    <description>cs.CY updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CY" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 18 Feb 2026 05:59:03 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Knowing Isn't Understanding: Re-grounding Generative Proactivity with Epistemic and Behavioral Insight</title>
      <link>https://arxiv.org/abs/2602.15259</link>
      <description>arXiv:2602.15259v1 Announce Type: new 
Abstract: Generative AI agents equate understanding with resolving explicit queries, an assumption that confines interaction to what users can articulate. This assumption breaks down when users themselves lack awareness of what is missing, risky, or worth considering. In such conditions, proactivity is not merely an efficiency enhancement, but an epistemic necessity. We refer to this condition as epistemic incompleteness: where progress depends on engaging with unknown unknowns for effective partnership. Existing approaches to proactivity remain narrowly anticipatory, extrapolating from past behavior and presuming that goals are already well defined, thereby failing to support users meaningfully. However, surfacing possibilities beyond a user's current awareness is not inherently beneficial. Unconstrained proactive interventions can misdirect attention, overwhelm users, or introduce harm. Proactive agents, therefore, require behavioral grounding: principled constraints on when, how, and to what extent an agent should intervene. We advance the position that generative proactivity must be grounded both epistemically and behaviorally. Drawing on the philosophy of ignorance and research on proactive behavior, we argue that these theories offer critical guidance for designing agents that can engage responsibly and foster meaningful partnerships.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15259v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kirandeep Kaur, Xingda Lyu, Chirag Shah</dc:creator>
    </item>
    <item>
      <title>FrameRef: A Framing Dataset and Simulation Testbed for Modeling Bounded Rational Information Health</title>
      <link>https://arxiv.org/abs/2602.15273</link>
      <description>arXiv:2602.15273v1 Announce Type: new 
Abstract: Information ecosystems increasingly shape how people internalize exposure to adverse digital experiences, raising concerns about the long-term consequences for information health. In modern search and recommendation systems, ranking and personalization policies play a central role in shaping such exposure and its long-term effects on users. To study these effects in a controlled setting, we present FrameRef, a large-scale dataset of 1,073,740 systematically reframed claims across five framing dimensions: authoritative, consensus, emotional, prestige, and sensationalist, and propose a simulation-based framework for modeling sequential information exposure and reinforcement dynamics characteristic of ranking and recommendation systems. Within this framework, we construct framing-sensitive agent personas by fine-tuning language models with framing-conditioned loss attenuation, inducing targeted biases while preserving overall task competence. Using Monte Carlo trajectory sampling, we show that small, systematic shifts in acceptance and confidence can compound over time, producing substantial divergence in cumulative information health trajectories. Human evaluation further confirms that FrameRef's generated framings measurably affect human judgment. Together, our dataset and framework provide a foundation for systematic information health research through simulation, complementing and informing responsible human-centered research. We release FrameRef, code, documentation, human evaluation data, and persona adapter models at https://github.com/infosenselab/frameref.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15273v1</guid>
      <category>cs.CY</category>
      <category>cs.CL</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Victor De Lima, Jiqun Liu, Grace Hui Yang</dc:creator>
    </item>
    <item>
      <title>From PhysioNet to Foundation Models -- A history and potential futures</title>
      <link>https://arxiv.org/abs/2602.15371</link>
      <description>arXiv:2602.15371v1 Announce Type: new 
Abstract: Over the last 35 years, the sharing of medical data and models for research has evolved from sneakernet to the internet - from mailing magnetic tapes and compact discs of a handful of well-curated recordings, to the high-speed download of relatively comprehensive hospital databases. More recently, the fervor around the potential for modern machine learning and 'AI' to catapult us into the next industrial revolution has led to a seemingly insatiable desire to pump almost any source of data into large models. Although this has great potential, it also presents a whole set of new challenges. In this article I examine these trends over the last 30 years, drawing on examples from cardiology, one of the oldest data-intensive fields that is undergoing a renaissance via machine learning. From the early days of computerized cardiology, the Research Resource for Complex Physiologic Signals (PhysioNet) has been at the cutting edge of this field. This article, therefore, includes much of the Resource's history and the contributions drawn from 25 years of firsthand experience of co-developing elements of the Resource with its founders. I identify the most promising future directions for the PhysioNet Resource, and more generally, the growing issues and opportunities around dissemination and use of massive physiological databases, associated open access code, and public competitions, along with potential solutions to the key issues facing our field. Topics range from how we should approach foundation models in the context of the rapidly growing AI carbon footprint, to the potential of Tiny-ML and edge computing. I also cover issues around prizes and incentives, funding models, and scientific repeatability, as well as how we might address these issues by leveraging the PhysioNet Challenges, consistent with the philosophy of open-access from the early days of the PhysioNet Resource.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15371v1</guid>
      <category>cs.CY</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Gari D. Clifford</dc:creator>
    </item>
    <item>
      <title>What makes an Expert? Comparing Problem-solving Practices in Data Science Notebooks</title>
      <link>https://arxiv.org/abs/2602.15428</link>
      <description>arXiv:2602.15428v1 Announce Type: new 
Abstract: The development of data science expertise requires tacit, process-oriented skills that are difficult to teach directly. This study addresses the resulting challenge of empirically understanding how the problem-solving processes of experts and novices differ. We apply a multi-level sequence analysis to 440 Jupyter notebooks from a public dataset, mapping low-level coding actions to higher-level problem-solving practices. Our findings reveal that experts do not follow fundamentally different transitions between data science phases than novices (e.g., Data Import, EDA, Model Training, Visualization). Instead, expertise is distinguished by the overall workflow structure from a problem-solving perspective and cell-level, fine-grained action patterns. Novices tend to follow long, linear processes, whereas experts employ shorter, more iterative strategies enacted through efficient, context-specific action sequences. These results provide data science educators with empirical insights for curriculum design and assessment, shifting the focus from final products toward the development of the flexible, iterative thinking that defines expertise-a priority in a field increasingly shaped by AI tools.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15428v1</guid>
      <category>cs.CY</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Manuel Valle Torre, Marcus Specht, Catharine Oertel</dc:creator>
    </item>
    <item>
      <title>From Earthquake Solidarity to Educational Equity: Conceptualizing a Sustainable, Volunteer-Driven P2P Learning Ecosystem at Scale</title>
      <link>https://arxiv.org/abs/2602.15432</link>
      <description>arXiv:2602.15432v1 Announce Type: new 
Abstract: This study examines the evolution of a grassroots, volunteer-driven peer-to-peer (P2P) educational initiative from an emergency response to the 2023 T\"urkiye earthquake into a sustainable ecosystem that operated for over two years and supported 300+ middle-school learners with 40+ volunteer tutors. Employing an interpretive case study approach, we triangulated data from participant observation, focus groups, questionnaires, and collaborative visioning workshops to investigate the socio-technical dynamics enabling long-term resilience in a fully online, nonreciprocal far-peer tutoring setting. Our findings reveal that while age proximity fosters trust and open communication, it also poses challenges for tutors who must balance peer rapport with instructional authority. Volunteer engagement is driven primarily by intrinsic motives - educational impact and community belonging - while optional micro-earning is envisioned as a practical enabler for long-term sustainability. Tutees report significant gains in confidence, self-expression, and accelerated comprehension, attributing these outcomes to personalized, interactive sessions within a "family-like" safe space that combines academic instruction with socio-emotional support. Notably, tutees view tutors as aspirational role models and express strong intentions to return as tutors themselves, envisioning a self-regenerating cycle of intergenerational reciprocity that carries knowledge and solidarity from generation to generation. Both cohorts call for a dedicated platform featuring integrated scheduling, personalization, feedback, and quality assurance mechanisms. We synthesize these insights into theory-informed implications and five design principles for sustainable P2P learning ecosystems at scale.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15432v1</guid>
      <category>cs.CY</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>\"Oyk\"u Kaplan, Adam Przyby{\l}ek, Michael Neumann, Netta Iivari</dc:creator>
    </item>
    <item>
      <title>Algorithmic Approaches to Opinion Selection for Online Deliberation: A Comparative Study</title>
      <link>https://arxiv.org/abs/2602.15439</link>
      <description>arXiv:2602.15439v1 Announce Type: new 
Abstract: During deliberation processes, mediators and facilitators typically need to select a small and representative set of opinions later used to produce digestible reports for stakeholders. In online deliberation platforms, algorithmic selection is increasingly used to automate this process. However, such automation is not without consequences. For instance, enforcing consensus-seeking algorithmic strategies can imply ignoring or flattening conflicting preferences, which may lead to erasing minority voices and reducing content diversity. More generally, across the variety of existing selection strategies (e.g., consensus, diversity), it remains unclear how each approach influences desired democratic criteria such as proportional representation. To address this gap, we benchmark several algorithmic approaches in this context. We also build on social choice theory to propose a novel algorithm that incorporates both diversity and a balanced notion of representation in the selection strategy. We find empirically that while no single strategy dominates across all democratic desiderata, our social-choice-inspired selection rule achieves the strongest trade-off between proportional representation and diversity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15439v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.SI</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Salim Hafid, Manon Berriche, Jean-Philippe Cointet</dc:creator>
    </item>
    <item>
      <title>How to Detect Information Voids Using Longitudinal Data from Social Media and Web Searches</title>
      <link>https://arxiv.org/abs/2602.15476</link>
      <description>arXiv:2602.15476v1 Announce Type: new 
Abstract: The model of the attention economy, where content producers compete for the attention of users, relies on two key forces: information supply and demand. This study leverages the feedback loop between these forces to develop a method for detecting and quantifying information voids, i.e., periods in which little or no reliable information is available on a given topic. Using a case study on COVID-19 vaccines rollout in six European countries, and drawing on data from multiple platforms including Facebook, Google, Twitter, Wikipedia, and online news outlets, we examine how information voids emerge, persist and correlate with a decline in the proportion of high-quality information circulating online. By conceptualising information voids as a specific regime of information spreading, we also quantify their counterpart, information overabundance, which constitute a central component of the current definition of infodemic. We show that information voids are associated with a higher prevalence of misinformation, thus representing problematic hotspots in which individuals are more likely to be misled by low-quality online content. Overall, our findings provide empirical support for the inclusion of information voids in mechanistic explanations of misinformation emergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15476v1</guid>
      <category>cs.CY</category>
      <category>physics.soc-ph</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Irene Scalco, Francesco Gesualdo, Roy Cerqueti, Matteo Cinelli</dc:creator>
    </item>
    <item>
      <title>Who Is Doing the Thinking? AI as a Dynamic Cognitive Partner: A Learner-Informed Framework</title>
      <link>https://arxiv.org/abs/2602.15638</link>
      <description>arXiv:2602.15638v1 Announce Type: new 
Abstract: Artificial intelligence is increasingly embedded in education, yet there remains a need to explain how students conceptualize AI's role in their thinking and learning. This study proposes a framework positioning AI as a dynamic cognitive partner whose function shifts across learning situations. Using qualitative analysis of written responses from 133 secondary students in Hong Kong following completion of an AI literacy course, we identified nine interrelated dimensions through which learners described AI as partnering with their cognition: conceptual scaffolding for difficult ideas; feedback and error detection; idea stimulation; cognitive organization; adaptive tutoring support; metacognitive monitoring support; task and cognitive load regulation; learning continuity beyond classroom boundaries; and explanation reframing through representational flexibility during moments of being stuck or overwhelmed. Across these dimensions, students distinguished between productive support that extends understanding and unproductive reliance that replaces cognitive effort, indicating situational awareness of when AI should and should not be used. Grounded in sociocultural theory, distributed cognition, self-regulated learning, and cognitive load perspectives, the framework clarifies how AI becomes integrated into learners' cognitive activity while illuminating the boundary between cognitive extension and substitution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15638v1</guid>
      <category>cs.CY</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>C. K. Y Chan</dc:creator>
    </item>
    <item>
      <title>One Rule to Bring Them All: Investigating Transport Connectivity in Public Transport Route Generation for Equitable Access</title>
      <link>https://arxiv.org/abs/2602.15053</link>
      <description>arXiv:2602.15053v1 Announce Type: cross 
Abstract: Designing a city-wide public transport network poses a dual challenge: achieving computational efficiency while ensuring spatial equity for different population groups. We investigate whether AI-based optimization hybrid neuroevolutionary methods combining graph neural networks with evolutionary algorithms - can scale Transit Network Design Problem (TNDP) solutions from synthetic tests to real urban networks while preserving social fairness. Our contribution is to introduce a transport connectivity-aware accessibility metric that bases optimization on principles of equitable accessibility rather than traditional trade-offs between passenger and operator costs. The results show a noticeable improvement in network resilience by improving algebraic connectivity on synthetic datasets, and highlight the ambiguity of applying network generation to real data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15053v1</guid>
      <category>physics.soc-ph</category>
      <category>cs.CY</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aleksandr Morozov, Ruslan Kozliak, Georgii Kontsevik, Sergey Mityagin</dc:creator>
    </item>
    <item>
      <title>Travel Time Prediction from Sparse Open Data</title>
      <link>https://arxiv.org/abs/2602.15069</link>
      <description>arXiv:2602.15069v1 Announce Type: cross 
Abstract: Travel time prediction is central to transport geography and planning's accessibility analyses, sustainable transportation infrastructure provision, and active transportation interventions. However, calculating accurate travel times, especially for driving, requires either extensive technical capacity and bespoke data, or resources like the Google Maps API that quickly become prohibitively expensive to analyze thousands or millions of trips necessary for metropolitan-scale analyses. Such obstacles particularly challenge less-resourced researchers, practitioners, and community advocates. This article argues that a middle-ground is needed to provide reasonably accurate travel time predictions without extensive data or computing requirements. It introduces a free, open-source minimally-congested driving time prediction model with minimal cost, data, and computational requirements. It trains and tests this model using the Los Angeles, California urban area as a case study by calculating naive travel times from open data then developing a random forest model to predict travel times as a function of those naive times plus open data on turns and traffic controls. Validation shows that this interpretable machine learning method offers a superior middle-ground technique that balances reasonable accuracy with minimal resource requirements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15069v1</guid>
      <category>physics.soc-ph</category>
      <category>cs.CY</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1080/13658816.2026.2628193</arxiv:DOI>
      <arxiv:journal_reference>International Journal of Geographical Information Science, 2026</arxiv:journal_reference>
      <dc:creator>Geoff Boeing, Yuquan Zhou</dc:creator>
    </item>
    <item>
      <title>"The Intangible Victory", Interactive Audiovisual Installation</title>
      <link>https://arxiv.org/abs/2602.15071</link>
      <description>arXiv:2602.15071v1 Announce Type: cross 
Abstract: "Intangible Victory" is an audiovisual installation in the form of the intangible being of the Victory of Samothrace that uses interactive digital media. Specifically, through this installation, we redefine the visual symbolism of the ancient sculpture, paying attention to time as a wear factor (entropy) and the special importance of the void as an absence of the sculptural form. Emptiness completes the intangible essence of the sculpture in the field of symbolism as well as in that of artistic significance for the interpretation of the work today. The function of the void and the interaction of the viewer with the work, causes the emergence of a new experience-dialogue between space and time. The use of digital media and technology reveals the absence of the sculptural form as it is visualized in the Victory of Samothrace. The sculptural form is reconstructed from fibers in space in a cylindrical arrangement. The form is rendered with colored strings - conductive sensors, that allow the visitor to interact with the work, creating a sound environment through movement. The sound completely replaces the volume, as the void of the sculptural form together with the viewer in unison present an audiovisual symbolism of the Victory of Samothrace.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15071v1</guid>
      <category>cs.MM</category>
      <category>cs.CY</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Konstantinos Tsioutas, Panagiotis Pangalos, Konstantinos Tiligadis, Andreas Sitorengo</dc:creator>
    </item>
    <item>
      <title>From Diagnosis to Inoculation: Building Cognitive Resistance to AI Disempowerment</title>
      <link>https://arxiv.org/abs/2602.15265</link>
      <description>arXiv:2602.15265v1 Announce Type: cross 
Abstract: Recent empirical research by Sharma et al. (2026) demonstrated that AI assistant interactions carry meaningful potential for situational human disempowerment, including reality distortion, value judgment distortion, and action distortion. While this work provides a critical diagnosis of the problem, concrete pedagogical interventions remain underexplored. I present an AI literacy framework built around eight cross-cutting Learning Outcomes (LOs), developed independently through teaching practice and subsequently found to align with Sharma et al.'s disempowerment taxonomy. I report a case study from a publicly available online course, where a co-teaching methodology--with AI serving as an active voice co-instructor--was used to deliver this framework. Drawing on inoculation theory (McGuire, 1961)--a well-established persuasion research framework recently applied to misinformation prebunking by the Cambridge school (van der Linden, 2022; Roozenbeek &amp; van der Linden, 2019)--I argue that AI literacy cannot be acquired through declarative knowledge alone, but requires guided exposure to AI failure modes, including the sycophantic validation and authority projection patterns identified by Sharma et al. This application of inoculation theory to AI-specific distortion is, to my knowledge, novel. I discuss the convergence between the pedagogically-derived framework and Sharma et al.'s empirically-derived taxonomy, and argue that this convergence--two independent approaches arriving at similar problem descriptions--strengthens the case for both the diagnosis and the proposed educational response.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15265v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aleksey Komissarov</dc:creator>
    </item>
    <item>
      <title>Energy Concerns with HPC Systems and Applications</title>
      <link>https://arxiv.org/abs/2309.08615</link>
      <description>arXiv:2309.08615v2 Announce Type: replace 
Abstract: For various reasons including those related to climate changes, {\em energy} has become a critical concern in all relevant activities and technical designs. For the specific case of computer activities, the problem is exacerbated with the emergence and pervasiveness of the so called {\em intelligent devices}. From the application side, we point out the special topic of {\em Artificial Intelligence}, who clearly needs an efficient computing support in order to succeed in its purpose of being a {\em ubiquitous assistant}. There are mainly two contexts where {\em energy} is one of the top priority concerns: {\em embedded computing} and {\em supercomputing}. For the former, power consumption is critical because the amount of energy that is available for the devices is limited. For the latter, the heat dissipated is a serious source of failure and the financial cost related to energy is likely to be a significant part of the maintenance budget. On a single computer, the problem is commonly considered through the electrical power consumption. This paper, written in the form of a survey, we depict the landscape of energy concerns in computer activities, both from the hardware and the software standpoints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.08615v2</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.PF</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Roblex Nana, Claude Tadonki, Petr Dokladal, Youssef Mesri</dc:creator>
    </item>
    <item>
      <title>The Generative Reasonable Person</title>
      <link>https://arxiv.org/abs/2508.02766</link>
      <description>arXiv:2508.02766v2 Announce Type: replace 
Abstract: This Article introduces the generative reasonable person, a new tool for estimating how ordinary people judge reasonableness. As claims about AI capabilities often outpace evidence, the Article proceeds empirically: adapting randomized controlled trials to large language models, it replicates three published studies of lay judgment across negligence, consent, and contract interpretation, drawing on nearly 10,000 simulated decisions. The findings reveal that models can replicate subtle patterns that run counter to textbook treatment. Like human subjects, models prioritize social conformity over cost-benefit analysis when assessing negligence, inverting the hierarchy that textbooks teach. They reproduce the paradox that material lies erode consent less than lies about a transaction's essence. And they track lay contract formalism, judging hidden fees more enforceable than fair. For two centuries, scholars have debated whether the reasonable person is empirical or normative, majoritarian or aspirational. But much of this debate assumed a constraint that no longer holds: that lay judgments are expensive to surface, slow to collect, and unavailable at scale. Generative reasonable people loosen that constraint. They offer judges empirical checks on elite intuition, give resource-constrained litigants access to simulated jury feedback, and let regulators pilot-test public comprehension, all at a fraction of survey costs. The reasonable person standard has long functioned as a vessel for judicial intuition precisely because the empirical baseline was missing. With that baseline now available, departures from lay understanding become transparent rather than hidden, a choice to be justified, not a fact to be assumed. Properly cabined, the generative reasonable person may become a dictionary for reasonableness judgments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.02766v2</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yonathan A. Arbel</dc:creator>
    </item>
    <item>
      <title>Navigating the Ethical and Societal Impacts of Generative AI in Higher Computing Education</title>
      <link>https://arxiv.org/abs/2511.15768</link>
      <description>arXiv:2511.15768v2 Announce Type: replace 
Abstract: Generative AI (GenAI) presents societal and ethical challenges related to equity, academic integrity, bias, and data provenance. In this paper, we outline the goals, methodology and deliverables of their collaborative research, considering the ethical and societal impacts of GenAI in higher computing education. A systematic literature review that addresses a wide set of issues and topics covering the rapidly emerging technology of GenAI from the perspective of its ethical and societal impacts is presented. This paper then presents an evaluation of a broad international review of a set of university adoption, guidelines, and policies related to the use of GenAI and the implications for computing education. The Ethical and Societal Impacts-Framework (ESI-Framework), derived from the literature and policy review and evaluation, outlines the ethical and societal impacts of GenAI in computing education. This work synthesizes existing research and considers the implications for computing higher education. Educators, computing professionals and policy makers facing dilemmas related to the integration of GenAI in their respective contexts may use this framework to guide decision-making in the age of GenAI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15768v2</guid>
      <category>cs.CY</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Janice Mak, Joyce Nakatumba-Nabende, Tony Clear, Alison Clear, Ibrahim Albluwi, Oana Andrei, Lorenzo Angeli, Stephen MacNeil, Solomon Sunday Oyelere, Matthew Hale Rattigan, Judy Sheard, Tingting Zhu</dc:creator>
    </item>
    <item>
      <title>The Manifold of the Absolute: Religious Perennialism as Generative Inference</title>
      <link>https://arxiv.org/abs/2602.11368</link>
      <description>arXiv:2602.11368v3 Announce Type: replace 
Abstract: This paper formalizes religious epistemology through the mathematics of Variational Autoencoders. We model religious traditions as distinct generative mappings from a shared, low-dimensional latent space to the high-dimensional space of observable cultural forms, and define three competing generative configurations corresponding to exclusivism, universalism, and perennialism, alongside syncretism as direct mixing in observable space. Through abductive comparison, we argue that exclusivism cannot parsimoniously account for cross-traditional contemplative convergence, that syncretism fails because combining the outputs of distinct generative processes produces incoherent artifacts, and that universalism suffers from posterior collapse: stripping traditions to a common core discards the structural information necessary for inference. The perennialist configuration provides the best explanatory fit. Within this framework, strict orthodoxy emerges not as a cultural constraint but as a structural necessity: the contemplative practices that recover the latent source must be matched to the specific tradition whose forms they take as input. The unity of religions, if it exists, is real but inaccessible by shortcut: one must go deep rather than wide.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11368v3</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arthur Juliani</dc:creator>
    </item>
    <item>
      <title>Peaceful Anarcho-Accelerationism: Decentralized Full Automation for a Society of Universal Care</title>
      <link>https://arxiv.org/abs/2602.13154</link>
      <description>arXiv:2602.13154v3 Announce Type: replace 
Abstract: Foundational results in machine learning -- the universal approximation theorem and deep reinforcement learning convergence -- imply that the vast majority of instrumental labor can be progressively automated. As this process accelerates, the critical question becomes one of governance: who controls the machines, and toward what ends? This paper introduces anarcho-accelerationism, a sociotechnical framework in which full automation is decentralized, commons-governed, and oriented toward universal care. We propose the Liberation Stack, a layered architecture of energy, manufacturing, food, communication, knowledge, and governance commons, powered by frontier clean energy technologies within an accelerationist ecologism that achieves sustainability through abundance rather than degrowth. We introduce Universal Desired Resources (UDR) as a post-monetary design principle and show that UDR constitutes the most comprehensive intersectional intervention yet proposed: by eliminating the material basis of oppression, it dissolves all axes of structural inequality simultaneously. Drawing on Maslow's hierarchy, we show that the Liberation Stack satisfies basic needs universally, enabling what we term synthetic liberty -- the positive freedom that emerges when commons infrastructure provides the material conditions for genuine autonomy. We establish that the framework respects freedom of faith on principled ontological grounds. We propose a progressive transition from Universal Basic Income to UDR and present empirical evidence from Linux, Wikipedia, Mondragon, and Rojava confirming that commons-based systems operate at scale. A phased roadmap with explicit assumptions and limitations is provided.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.13154v3</guid>
      <category>cs.CY</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eduardo C. Garrido-Merch\'an</dc:creator>
    </item>
    <item>
      <title>Reranking Social Media Feeds: A Practical Guide for Field Experiments</title>
      <link>https://arxiv.org/abs/2406.19571</link>
      <description>arXiv:2406.19571v2 Announce Type: replace-cross 
Abstract: Social media plays a central role in shaping public opinion and behavior, yet performing experiments on these platforms and, in particular, on feed algorithms is becoming increasingly challenging. This guide offers practical recommendations for researchers developing and deploying field experiments focused on real-time reranking of social media feeds. The article is organized around two contributions. First, we provide an overview of an experimental method using web browser extensions that intercepts and reranks content in real time, enabling naturalistic reranking field experiments. We then describe feed interventions and measurements that this paradigm enables on participants' actual feeds, without requiring the involvement of social media platforms. Second, we offer concrete technical recommendations for intercepting and reranking social media feeds with minimal user-facing delay, and provide an open-source implementation. This document aims to summarize lessons learned in running field experiments on social media, provide concrete implementation details, and foster the ecosystem of independent social media research. Finally, we release the source code that serves as a blueprint for implementing future feed-ranking experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19571v2</guid>
      <category>cs.SI</category>
      <category>cs.CY</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tiziano Piccardi, Martin Saveski, Chenyan Jia, Jeffrey Hancock, Jeanne L. Tsai, Michael S. Bernstein</dc:creator>
    </item>
    <item>
      <title>SIGMUS: Semantic Integration for Knowledge Graphs in Multimodal Urban Spaces</title>
      <link>https://arxiv.org/abs/2509.00287</link>
      <description>arXiv:2509.00287v2 Announce Type: replace-cross 
Abstract: Modern urban spaces are equipped with an increasingly diverse set of sensors, all producing an abundance of multimodal data. Such multimodal data can be used to identify and reason about important incidents occurring in urban landscapes, such as major emergencies, cultural and social events, as well as natural disasters. However, such data may be fragmented over several sources and difficult to integrate due to the reliance on human-driven reasoning for identifying relationships between the multimodal data corresponding to an incident, as well as understanding the different components which define an incident. Such relationships and components are critical to identifying the causes of such incidents, as well as producing forecasting the scale and intensity of future incidents as they begin to develop. In this work, we create SIGMUS, a system for Semantic Integration for Knowledge Graphs in Multimodal Urban Spaces. SIGMUS uses Large Language Models (LLMs) to produce the necessary world knowledge for identifying relationships between incidents occurring in urban spaces and data from different modalities, allowing us to organize evidence and observations relevant to an incident without relying and human-encoded rules for relating multimodal sensory data with incidents. This organized knowledge is represented as a knowledge graph, organizing incidents, observations, and much more. We find that our system is able to produce reasonable connections between 5 different data sources (new article text, CCTV images, air quality, weather, and traffic measurements) and relevant incidents occurring at the same time and location.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.00287v2</guid>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Brian Wang, Mani Srivastava</dc:creator>
    </item>
    <item>
      <title>Bowling with ChatGPT: On the Evolving User Interactions with Conversational AI Systems</title>
      <link>https://arxiv.org/abs/2602.01114</link>
      <description>arXiv:2602.01114v3 Announce Type: replace-cross 
Abstract: Recent studies have discussed how users are increasingly using conversational AI systems, powered by LLMs, for information seeking, decision support, and even emotional support. However, these macro-level observations offer limited insight into how the purpose of these interactions shifts over time, how users frame their interactions with the system, and how steering dynamics unfold in these human-AI interactions. To examine these evolving dynamics, we gathered and analyzed a unique dataset InVivoGPT: consisting of 825K ChatGPT interactions, donated by 300 users through their GDPR data rights. Our analyses reveal three key findings. First, participants increasingly turn to ChatGPT for a broader range of purposes, including substantial growth in sensitive domains such as health and mental health. Second, interactions become more socially framed: the system anthropomorphizes itself at rising rates, participants more frequently treat it as a companion, and personal data disclosure becomes both more common and more diverse. Third, conversational steering becomes more prominent, especially after the release of GPT-4o, with conversations where the participants followed a model-initiated suggestion quadrupling over the period of our dataset. Overall, our results show that conversational AI systems are shifting from functional tools to social partners, raising important questions about their design and governance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01114v3</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sai Keerthana Karnam, Abhisek Dash, Krishna P. Gummadi, Animesh Mukherjee, Ingmar Weber, Savvas Zannettou</dc:creator>
    </item>
    <item>
      <title>Towards Human-AI Accessibility Mapping in India: VLM-Guided Annotations and POI-Centric Analysis in Chandigarh</title>
      <link>https://arxiv.org/abs/2602.09216</link>
      <description>arXiv:2602.09216v2 Announce Type: replace-cross 
Abstract: Project Sidewalk is a web-based platform that enables crowdsourcing accessibility of sidewalks at city-scale by virtually walking through city streets using Google Street View. The tool has been used in 40 cities across the world, including the US, Mexico, Chile, and Europe. In this paper, we describe adaptation efforts to enable deployment in Chandigarh, India, including modifying annotation types, provided examples, and integrating VLM-based mission guidance, which adapts instructions based on a street scene and metadata analysis. Our evaluation with 3 annotators indicates the utility of AI-mission guidance with an average score of 4.66. Using this adapted Project Sidewalk tool, we conduct a Points of Interest (POI)-centric accessibility analysis for three sectors in Chandigarh with very different land uses, residential, commercial and institutional covering about 40 km of sidewalks. Across 40 km of roads audited in three sectors and around 230 POIs, we identified 1,644 of 2,913 locations where infrastructure improvements could enhance accessibility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.09216v2</guid>
      <category>cs.HC</category>
      <category>cs.CV</category>
      <category>cs.CY</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Varchita Lalwani, Utkarsh Agarwal, Michael Saugstad, Manish Kumar, Jon E. Froehlich, Anupam Sobti</dc:creator>
    </item>
    <item>
      <title>"Sorry, I Didn't Catch That": How Speech Models Miss What Matters Most</title>
      <link>https://arxiv.org/abs/2602.12249</link>
      <description>arXiv:2602.12249v2 Announce Type: replace-cross 
Abstract: Despite speech recognition systems achieving low word error rates on standard benchmarks, they often fail on short, high-stakes utterances in real-world deployments. Here, we study this failure mode in a high-stakes task: the transcription of U.S. street names as spoken by U.S. participants. We evaluate 15 models from OpenAI, Deepgram, Google, and Microsoft on recordings from linguistically diverse U.S. speakers and find an average transcription error rate of 44%. We quantify the downstream impact of failed transcriptions by geographic locations and show that mis-transcriptions systematically cause errors for all speakers, but that routing distance errors are twice as large for non-English primary speakers compared to English primary speakers. To mitigate this harm, we introduce a synthetic data generation approach that produces diverse pronunciations of named entities using open-source text-to-speech models. Fine-tuning with less than 1,000 synthetic samples improves street name transcription accuracy by nearly 60% (relative to base models) for non-English primary speakers. Our results highlight a critical gap between benchmark performance and real-world reliability in speech systems and demonstrate a simple, scalable path to reducing high-stakes transcription errors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.12249v2</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Kaitlyn Zhou, Martijn Bartelds, Federico Bianchi, James Zou</dc:creator>
    </item>
    <item>
      <title>Multi-Agent Comedy Club: Investigating Community Discussion Effects on LLM Humor Generation</title>
      <link>https://arxiv.org/abs/2602.14770</link>
      <description>arXiv:2602.14770v2 Announce Type: replace-cross 
Abstract: Prior work has explored multi-turn interaction and feedback for LLM writing, but evaluations still largely center on prompts and localized feedback, leaving persistent public reception in online communities underexamined. We test whether broadcast community discussion improves stand-up comedy writing in a controlled multi-agent sandbox: in the discussion condition, critic and audience threads are recorded, filtered, stored as social memory, and later retrieved to condition subsequent generations, whereas the baseline omits discussion. Across 50 rounds (250 paired monologues) judged by five expert annotators using A/B preference and a 15-item rubric, discussion wins 75.6% of instances and improves Craft/Clarity ({\Delta} = 0.440) and Social Response ({\Delta} = 0.422), with occasional increases in aggressive humor.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14770v2</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Shiwei Hong, Lingyao Li, Ethan Z. Rong, Chenxinran Shen, Zhicong Lu</dc:creator>
    </item>
  </channel>
</rss>
