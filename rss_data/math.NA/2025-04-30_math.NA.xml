<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.NA</link>
    <description>math.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 01 May 2025 01:48:02 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 30 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Fast LDL factorization for dense and sparse symmetric matrices over an arbitrary field</title>
      <link>https://arxiv.org/abs/2504.20305</link>
      <description>arXiv:2504.20305v2 Announce Type: new 
Abstract: While existing algorithms may be used to solve a linear system over a general field in matrix-multiplication time, the complexity of constructing a symmetric triangular factorization (LDL) has received relatively little formal study. The LDL factorization is a common tool for factorization of symmetric matrices, and, unlike orthogonal counterparts, generalizes to an arbitrary field. We provide algorithms for dense and sparse LDL factorization and for dense LU factorization that aim to minimize complexity for factorization over a general field. For LU of an $m\times n$ rank $R$ matrix, we obtain an algorithm with complexity $O(mnR^{\omega-2})$, where $\omega$ is the matrix multiplication complexity exponent. For LDL of an $n\times n$ matrix, we give an algorithm with complexity $O(n^\omega)$ and for a sparse matrix corresponding to a graph with treewidth $\tau$, we obtain $O(n\tau^{\omega-1})$. Our sparse LDL algorithm is based on an adaptation of the null-space method for solving saddle point systems of equations, which may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.20305v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 30 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Edgar Solomonik</dc:creator>
    </item>
    <item>
      <title>An energy-stable minimal deformation rate scheme for mean curvature flow and surface diffusion</title>
      <link>https://arxiv.org/abs/2504.20494</link>
      <description>arXiv:2504.20494v1 Announce Type: new 
Abstract: We propose a new parametric finite element method, referred to as the BGN-MDR method, for simulating both mean curvature flow and surface diffusion for closed hypersurfaces, as well as open hypersurfaces with moving contact lines in three dimensions. The method is also applicable to closed and open curves with moving contact points in two dimensions. The proposed scheme inherits the energy stability from the BGN scheme proposed by Barrett, Garcke, and N\"urnberg in 2008, and offers improved mesh quality similar to the minimal deformation rate (MDR) method proposed by Hu and Li in 2022, especially for small time step sizes where the BGN scheme may become unstable and result in deteriorated meshes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.20494v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 30 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guangwei Gao, Harald Garcke, Buyang Li, Rong Tang</dc:creator>
    </item>
    <item>
      <title>Finite element method with Gr\"unwald-Letnikov type approximation in time for a constant time delay subdiffusion equation</title>
      <link>https://arxiv.org/abs/2504.20524</link>
      <description>arXiv:2504.20524v1 Announce Type: new 
Abstract: In this work, a subdiffusion equation with constant time delay $\tau$ is considered. First, the regularity of the solution to the considered problem is investigated, finding that its first-order time derivative exhibits singularity at $t=0^+$ and its second-order time derivative shows singularity at both $t=0^+$ and $\tau^+$, while the solution can be decomposed into its singular and regular components. Then, we derive a fully discrete finite element scheme to solve the considered problem based on the standard Galerkin finite element method in space and the Gr\"unwald-Letnikov type approximation in time. The analysis shows that the developed numerical scheme is stable. In order to discuss the error estimate, a new discrete Gronwall inequality is established. Under the above decomposition of the solution, we obtain a local error estimate in time for the developed numerical scheme. Finally, some numerical tests are provided to support our theoretical analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.20524v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 30 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weiping Bu, Xueqin Zhang, Weizhi Liao, Yue Zhao</dc:creator>
    </item>
    <item>
      <title>On Stochastic Rounding with Few Random Bits</title>
      <link>https://arxiv.org/abs/2504.20634</link>
      <description>arXiv:2504.20634v1 Announce Type: new 
Abstract: Large-scale numerical computations make increasing use of low-precision (LP) floating point formats and mixed precision arithmetic, which can be enhanced by the technique of stochastic rounding (SR), that is, rounding an intermediate high-precision value up or down randomly as a function of the value's distance to the two rounding candidates. Stochastic rounding requires, in addition to the high-precision input value, a source of random bits. As the provision of high-quality random bits is an additional computational cost, it is of interest to require as few bits as possible while maintaining the desirable properties of SR in a given computation, or computational domain. This paper examines a number of possible implementations of few-bit stochastic rounding (FBSR), and shows how several natural implementations can introduce sometimes significant bias into the rounding process, which are not present in the case of infinite-bit, infinite-precision examinations of these implementations. The paper explores the impact of these biases in machine learning examples, and hence opens another class of configuration parameters of which practitioners should be aware when developing or adopting low-precision floating point. Code is available at http://github.com/graphcore-research/arith25-stochastic-rounding.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.20634v1</guid>
      <category>math.NA</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.MS</category>
      <category>cs.NA</category>
      <pubDate>Wed, 30 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrew Fitzgibbon, Stephen Felix</dc:creator>
    </item>
    <item>
      <title>Neural semi-Lagrangian method for high-dimensional advection-diffusion problems</title>
      <link>https://arxiv.org/abs/2504.20715</link>
      <description>arXiv:2504.20715v1 Announce Type: new 
Abstract: This work is devoted to the numerical approximation of high-dimensional advection-diffusion equations. It is well-known that classical methods, such as the finite volume method, suffer from the curse of dimensionality, and that their time step is constrained by a stability condition. The semi-Lagrangian method is known to overcome the stability issue, while recent time-discrete neural network-based approaches overcome the curse of dimensionality. In this work, we propose a novel neural semi-Lagrangian method that combines these last two approaches. It relies on projecting the initial condition onto a finite-dimensional neural space, and then solving an optimization problem, involving the backwards characteristic equation, at each time step. It is particularly well-suited for implementation on GPUs, as it is fully parallelizable and does not require a mesh. We provide rough error estimates, and present several high-dimensional numerical experiments to assess the performance of our approach, and compare it to other neural methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.20715v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 30 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Emmanuel Franck, Victor Michel-Dansac, Laurent Navoret</dc:creator>
    </item>
    <item>
      <title>A high-order energy-conserving semi-Lagrangian discontinuous Galerkin method for the Vlasov-Ampere system</title>
      <link>https://arxiv.org/abs/2504.20813</link>
      <description>arXiv:2504.20813v1 Announce Type: new 
Abstract: In this paper, we propose a high-order energy-conserving semi-Lagrangian discontinuous Galerkin(ECSLDG) method for the Vlasov-Ampere system. The method employs a semi-Lagrangian discontinuous Galerkin scheme for spatial discretization of the Vlasov equation, achieving high-order accuracy while removing the Courant-Friedrichs-Lewy (CFL) constraint. To ensure energy conservation and eliminate the need to resolve the plasma period, we adopt an energy-conserving time discretization introduced by Liu et al. [J. Comput. Phys., 492 (2023), 112412]. Temporal accuracy is further enhanced through a high-order operator splitting strategy, yielding a method that is high-order accurate in both space and time. The resulting ECSLDG scheme is unconditionally stable and conserves both mass and energy at the fully discrete level, regardless of spatial or temporal resolution. Numerical experiments demonstrate the accuracy, stability, and conservation properties of the proposed method. In particular, the method achieves more accurate enforcement of Gauss's law and improved numerical fidelity over low-order schemes, especially when using a large CFL number.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.20813v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 30 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaofeng Cai, Qingtao Li, Hongtao Liu, Haibiao Zheng</dc:creator>
    </item>
    <item>
      <title>Optimizing Hard Thresholding for Sparse Model Discovery</title>
      <link>https://arxiv.org/abs/2504.20256</link>
      <description>arXiv:2504.20256v1 Announce Type: cross 
Abstract: Many model selection algorithms rely on sparse dictionary learning to provide interpretable and physics-based governing equations. The optimization algorithms typically use a hard thresholding process to enforce sparse activations in the model coefficients by removing library elements from consideration. By introducing an annealing scheme that reactivates a fraction of the removed terms with a cooling schedule, we are able to improve the performance of these sparse learning algorithms. We concentrate on two approaches to the optimization, SINDy, and an alternative using hard thresholding pursuit. We see in both cases that annealing can improve model accuracy. The effectiveness of annealing is demonstrated through comparisons on several nonlinear systems pulled from convective flows, excitable systems, and population dynamics. Finally we apply these algorithms to experimental data for projectile motion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.20256v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.DS</category>
      <category>math.NA</category>
      <pubDate>Wed, 30 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Derek W. Jollie, Scott G. McCalla</dc:creator>
    </item>
    <item>
      <title>Global Optimality Characterizations and Algorithms for Minimizing Quartically-Regularized Third-Order Taylor Polynomials</title>
      <link>https://arxiv.org/abs/2504.20259</link>
      <description>arXiv:2504.20259v1 Announce Type: cross 
Abstract: High-order methods for convex and nonconvex optimization, particularly $p$th-order Adaptive Regularization Methods (AR$p$), have attracted significant research interest by naturally incorporating high-order Taylor models into adaptive regularization frameworks, resulting in algorithms with faster global and local convergence rates than first- and second-order methods. This paper establishes global optimality conditions for general, nonconvex cubic polynomials with quartic regularization. These criteria generalise existing results, recovering the optimality results for regularized quadratic polynomials, and can be further simplified in the low-rank and diagonal tensor cases. Under suitable assumptions on the Taylor polynomial, we derive a lower bound for the regularization parameter such that the necessary and sufficient criteria coincide, establishing a connection between this bound and the subproblem's convexification and sum-of-squares (SoS) convexification techniques. Leveraging the optimality characterization, we develop a Diagonal Tensor Method (DTM) for minimizing quartically-regularized cubic Taylor polynomials by iteratively minimizing a sequence of local models that incorporate both diagonal cubic terms and quartic regularization (DTM model). We show that the DTM algorithm is provably convergent, with a global evaluation complexity of $\mathcal{O}(\epsilon^{-3/2})$. Furthermore, when special structure is present (such as low rank or diagonal), DTM can exactly solve the given problem (in one iteration). In our numerical experiments, we propose practical DTM variants that exploit local problem information for model construction, which we then show to be competitive with cubic regularization and other subproblem solvers, with superior performance on problems with special structure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.20259v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 30 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Wenqi Zhu, Coralia Cartis</dc:creator>
    </item>
    <item>
      <title>Entropy based lower dimension bounds for finite-time prediction of Dynamic Mode Decomposition algorithms</title>
      <link>https://arxiv.org/abs/2504.20269</link>
      <description>arXiv:2504.20269v1 Announce Type: cross 
Abstract: Motivated by Dynamic Mode Decomposition algorithms, we provide lower bounds on the dimension of a finite-dimensional subspace $F \subseteq \mathrm{L}^2(\mathrm{X})$ required for predicting the behavior of dynamical systems over long time horizons. We distinguish between two cases: (i) If $F$ is determined by a finite partition of $X$ we derive a lower bound that depends on the dynamical measure-theoretic entropy of the partition. (ii) We consider general finite-dimensional subspaces $F$ and establish a lower bound for the dimension of $F$ that is contingent on the spectral structure of the Koopman operator of the system, via the approximation entropy of $F$ as studied by Voiculescu. Furthermore, we motivate the use of delay observables to improve the predictive qualities of Dynamic Mode Decomposition algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.20269v1</guid>
      <category>math.DS</category>
      <category>cs.NA</category>
      <category>math.FA</category>
      <category>math.NA</category>
      <pubDate>Wed, 30 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Till Hauser, Julian H\"olz</dc:creator>
    </item>
    <item>
      <title>FourierSpecNet: Neural Collision Operator Approximation Inspired by the Fourier Spectral Method for Solving the Boltzmann Equation</title>
      <link>https://arxiv.org/abs/2504.20408</link>
      <description>arXiv:2504.20408v1 Announce Type: cross 
Abstract: The Boltzmann equation, a fundamental model in kinetic theory, describes the evolution of particle distribution functions through a nonlinear, high-dimensional collision operator. However, its numerical solution remains computationally demanding, particularly for inelastic collisions and high-dimensional velocity domains. In this work, we propose the Fourier Neural Spectral Network (FourierSpecNet), a hybrid framework that integrates the Fourier spectral method with deep learning to approximate the collision operator in Fourier space efficiently. FourierSpecNet achieves resolution-invariant learning and supports zero-shot super-resolution, enabling accurate predictions at unseen resolutions without retraining. Beyond empirical validation, we establish a consistency result showing that the trained operator converges to the spectral solution as the discretization is refined. We evaluate our method on several benchmark cases, including Maxwellian and hard-sphere molecular models, as well as inelastic collision scenarios. The results demonstrate that FourierSpecNet offers competitive accuracy while significantly reducing computational cost compared to traditional spectral solvers. Our approach provides a robust and scalable alternative for solving the Boltzmann equation across both elastic and inelastic regimes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.20408v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Wed, 30 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jae Yong Lee, Gwang Jae Jung, Byung Chan Lim, Hyung Ju Hwang</dc:creator>
    </item>
    <item>
      <title>On optimal error rates for strong approximation of SDEs with a H\"older continuous drift coefficient</title>
      <link>https://arxiv.org/abs/2504.20728</link>
      <description>arXiv:2504.20728v1 Announce Type: cross 
Abstract: In the present article we study strong approximation of solutions of scalar stochastic differential equations (SDEs) with bounded and $\alpha$-H\"older continuous drift coefficient and constant diffusion coefficient at time point $1$. Recently, it was shown in [arXiv:1909.07961v4 (2021)] that for such SDEs the equidistant Euler scheme achieves an $L^p$-error rate of at least $(1+\alpha)/2$, up to an arbitrary small $\varepsilon$, for all $p\geq 1$ and all $\alpha\in(0, 1]$ in terms of the number of evaluations of the driving Brownian motion $W$. In this article we prove a matching lower error bound for $\alpha\in(0, 1)$. More precisely, we show that for every $\alpha\in(0, 1)$, the $L^p$-error rate $(1+\alpha)/2$ of the Euler scheme in [arXiv:1909.07961v4 (2021)] can not be improved in general by no numerical method based on finitely many evaluations of $W$ at fixed time points. Up to now, this result was known in the literature only for $\alpha=1$.
  Additionally, we extend a result from [arXiv:2402.13732v2 (2024)] on sharp lower errror bounds for strong approximation of SDEs with a bounded drift coefficient of fractional Sobolev regularity $\alpha\in (0,1)$ and constant diffusion coefficient at time point $1$. We prove that for every $\alpha\in (0,1)$, the $L^p$-error rate $ (1 + \alpha)/2$ that was shown in [arXiv:2101.12185v2 (2022)] for the equidistant Euler scheme can, up to a logarithmic term, not be improved in general by no numerical method based on finitely many evaluations of W at fixed time points. This result was known from [arXiv:2402.13732v2 (2024)] only for $\alpha\in (1/2,1)$ and $p=2$.
  For the proof of these lower bounds we use variants of the Weierstrass function as a drift coefficient and we employ the coupling of noise technique recently introduced in [arXiv:2010.00915v1 (2020)].</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.20728v1</guid>
      <category>math.PR</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 30 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Simon Ellinger, Thomas M\"uller-Gronbach, Larisa Yaroslavtseva</dc:creator>
    </item>
    <item>
      <title>Avoided-crossings, degeneracies and Berry phases in the spectrum of quantum noise through analytic Bloch-Messiah decomposition</title>
      <link>https://arxiv.org/abs/2504.20730</link>
      <description>arXiv:2504.20730v2 Announce Type: cross 
Abstract: The Bloch-Messiah decomposition (BMD) is a fundamental tool in quantum optics, enabling the analysis and tailoring of multimode Gaussian states by decomposing linear optical transformations into passive interferometers and single-mode squeezers. Its extension to frequency-dependent matrix-valued functions, recently introduced as the "analytic Bloch-Messiah decomposition" (ABMD), provides the most general approach for characterizing the driven-dissipative dynamics of quantum optical systems governed by quadratic Hamiltonians. In this work, we present a detailed study of the ABMD, focusing on the typical behavior of parameter-dependent singular values and of their corresponding singular vectors. In particular, we analyze the hitherto unexplored occurrence of avoided and genuine crossings in the spectrum of quantum noise, the latter being manifested by nontrivial topological Berry phases of the singular vectors. We demonstrate that avoided crossings arise naturally when a single parameter is varied, leading to hypersensitivity of the singular vectors and suggesting the presence of genuine crossings in nearby systems. We highlight the possibility of programming the spectral response of photonic systems through the deliberate design of avoided crossings. As a notable example, we show that such control can be exploited to generate broad, flat-band squeezing spectra -- a desirable feature for enhancing degaussification protocols. This study provides new insights into the structure of multimode quantum correlations and offers a theoretical framework for experimental exploitation of complex quantum optical systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.20730v2</guid>
      <category>quant-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 30 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Giuseppe Patera, Alessandro Pugliese</dc:creator>
    </item>
    <item>
      <title>A Nystr\"{o}m Method for Scattering by a Two-layered Medium with a Rough Boundary</title>
      <link>https://arxiv.org/abs/2303.02339</link>
      <description>arXiv:2303.02339v4 Announce Type: replace 
Abstract: This paper is concerned with problems of scattering of time-harmonic acoustic waves by a two-layered medium with a non-locally perturbed boundary (called a rough boundary in this paper) in two dimensions, where a Dirichlet or impedance boundary condition is imposed on the boundary. The two-layered medium is composed of two unbounded media with different physical properties and the interface between the two media is considered to be a planar surface. We formulate the scattering problems considered as boundary value problems and prove the result of the well-posedness of each boundary value problem by utilizing the integral equation method associated with the two-layered Green function. Moreover, we develop a Nystr\"{o}m method for numerically solving the boundary value problems considered, based on the proposed integral equation formulations. We establish the convergence results of the Nystr\"{o}m method with the convergence rates depending on the smoothness of the rough boundary. It is worth noting that in establishing the well-posedness of the boundary value problems as well as the convergence results of the Nystr\"{o}m method, an essential role is played by the investigation of the asymptotic properties of the two-layered Green function for small and large arguments. Finally, numerical experiments are carried out to show the effectiveness of the Nystr\"{o}m method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.02339v4</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <pubDate>Wed, 30 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haiyang Liu, Long Li, Jiansheng Yang, Bo Zhang, Haiwen Zhang</dc:creator>
    </item>
    <item>
      <title>An Adaptive Algorithm Based on Stochastic Discontinuous Galerkin for Convection Dominated Equations with Random Data</title>
      <link>https://arxiv.org/abs/2308.05500</link>
      <description>arXiv:2308.05500v3 Announce Type: replace 
Abstract: In this paper, we propose an adaptive approach, based on mesh refinement or parametric enrichment with polynomial degree adaption, for numerical solution of convection dominated equations with random input data. A parametric system emerged from an application of stochastic Galerkin approach is discretized by using symmetric interior penalty Galerkin (SIPG) method with upwinding for the convection term in the spatial domain. We derive a residual-based error estimator contributed by the error due to the SIPG discretization, the (generalized) polynomial chaos discretization in the stochastic space, and data oscillations. Then, the reliability of the proposed error estimator, an upper bound for the energy error up to a multiplicative constant, is shown. Moreover, to balance the errors stemmed from spatial and stochastic spaces, the truncation error emerged from Karhunen--Lo\`{e}ve expansion are considered in the numerical simulations. Last, several benchmark examples including a random diffusivity parameter, a random convectivity parameter, random diffusivity/convectivity parameters, and a random (jump) discontinuous diffusivity parameter, are tested to illustrate the performance of the proposed estimator.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.05500v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 30 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pelin \c{C}ilo\u{g}lu, Hamdullah Y\"ucel</dc:creator>
    </item>
    <item>
      <title>A randomized algorithm for simultaneously diagonalizing symmetric matrices by congruence</title>
      <link>https://arxiv.org/abs/2402.16557</link>
      <description>arXiv:2402.16557v3 Announce Type: replace 
Abstract: A family of symmetric matrices $A_1,\ldots, A_d$ is SDC (simultaneous diagonalization by congruence, also called non-orthogonal joint diagonalization) if there is an invertible matrix $X$ such that every $X^T A_k X$ is diagonal. In this work, a novel randomized SDC (RSDC) algorithm is proposed that reduces SDC to a generalized eigenvalue problem by considering two (random) linear combinations of the family. We establish exact recovery: RSDC achieves diagonalization with probability $1$ if the family is exactly SDC. Under a mild regularity assumption, robust recovery is also established: Given a family that is $\epsilon$-close to SDC then RSDC diagonalizes, with high probability, the family up to an error of norm $\mathcal{O}(\epsilon)$. Under a positive definiteness assumption, which often holds in applications, stronger results are established, including a bound on the condition number of the transformation matrix. For practical use, we suggest to combine RSDC with an optimization algorithm. The performance of the resulting method is verified for synthetic data, image separation and EEG analysis tasks. It turns out that our newly developed method outperforms existing optimization-based methods in terms of efficiency while achieving a comparable level of accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.16557v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 30 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haoze He, Daniel Kressner</dc:creator>
    </item>
    <item>
      <title>Enforcing conservation laws and dissipation inequalities numerically via auxiliary variables</title>
      <link>https://arxiv.org/abs/2407.11904</link>
      <description>arXiv:2407.11904v3 Announce Type: replace 
Abstract: We propose a general strategy for enforcing multiple conservation laws and dissipation inequalities in the numerical solution of initial value problems. The key idea is to represent each conservation law or dissipation inequality by means of an associated test function; we introduce auxiliary variables representing the projection of these test functions onto a discrete test set, and modify the equation to use these new variables. We demonstrate these ideas by their application to the Navier-Stokes equations. We generalize to arbitrary order the energy-dissipating and helicity-tracking scheme of Rebholz for the incompressible Navier-Stokes equations, and devise the first time discretization of the compressible equations that conserves mass, momentum, and energy, and provably dissipates entropy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.11904v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 30 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Boris D. Andrews, Patrick E. Farrell</dc:creator>
    </item>
    <item>
      <title>A quantitative comparison of high-order asymptotic-preserving and asymptotically-accurate IMEX methods for the Euler equations with non-ideal gases</title>
      <link>https://arxiv.org/abs/2501.12733</link>
      <description>arXiv:2501.12733v3 Announce Type: replace 
Abstract: We present a quantitative comparison between two different Implicit-Explicit Runge-Kutta (IMEX-RK) approaches for the Euler equations of gas dynamics, specifically tailored for the low Mach limit. In this regime, a classical IMEX-RK approach involves an implicit coupling between the momentum and energy balance so as to avoid the acoustic CFL restriction, while the density can be treated in a fully explicit fashion. This approach leads to a mildly nonlinear equation for the pressure, which can be solved according to a fixed point procedure. An alternative strategy consists of employing a semi-implicit temporal integrator based on IMEX-RK methods (SI-IMEX-RK). The stiff dependence is carefully analyzed, so as to avoid the solution of a nonlinear equation for the pressure also for equations of state (EOS) of non-ideal gases. The spatial discretization is based on a Discontinuous Galerkin (DG) method, which naturally allows high-order accuracy. The asymptotic-preserving (AP) and the asymptotically-accurate (AA) properties of the two approaches are assessed on a number of classical benchmarks for ideal gases and on their extension to non-ideal gases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12733v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 30 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Giuseppe Orlando, Sebastiano Boscarino, Giovanni Russo</dc:creator>
    </item>
    <item>
      <title>Optimal Oblivious Subspace Embeddings with Near-optimal Sparsity</title>
      <link>https://arxiv.org/abs/2411.08773</link>
      <description>arXiv:2411.08773v2 Announce Type: replace-cross 
Abstract: An oblivious subspace embedding is a random $m\times n$ matrix $\Pi$ such that, for any $d$-dimensional subspace, with high probability $\Pi$ preserves the norms of all vectors in that subspace within a $1\pm\epsilon$ factor. In this work, we give an oblivious subspace embedding with the optimal dimension $m=\Theta(d/\epsilon^2)$ that has a near-optimal sparsity of $\tilde O(1/\epsilon)$ non-zero entries per column of $\Pi$. This is the first result to nearly match the conjecture of Nelson and Nguyen [FOCS 2013] in terms of the best sparsity attainable by an optimal oblivious subspace embedding, improving on a prior bound of $\tilde O(1/\epsilon^6)$ non-zeros per column [Chenakkod et al., STOC 2024]. We further extend our approach to the non-oblivious setting, proposing a new family of Leverage Score Sparsified embeddings with Independent Columns, which yield faster runtimes for matrix approximation and regression tasks.
  In our analysis, we develop a new method which uses a decoupling argument together with the cumulant method for bounding the edge universality error of isotropic random matrices. To achieve near-optimal sparsity, we combine this general-purpose approach with new traces inequalities that leverage the specific structure of our subspace embedding construction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08773v2</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <pubDate>Wed, 30 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shabarish Chenakkod, Micha{\l} Derezi\'nski, Xiaoyu Dong</dc:creator>
    </item>
    <item>
      <title>Unravelling mean-field Lindblad equation</title>
      <link>https://arxiv.org/abs/2504.19928</link>
      <description>arXiv:2504.19928v2 Announce Type: replace-cross 
Abstract: We propose a mean-field particle Monte Carlo method for simulating the N-body Lindblad equation. We provide a convergence result showing that a system of interacting particles converges to the corresponding nonlinear Lindblad equation in the large N limit.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19928v2</guid>
      <category>quant-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <pubDate>Wed, 30 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sofiane Chalal, Nina H. Amini</dc:creator>
    </item>
  </channel>
</rss>
