<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 20 Jan 2025 05:00:03 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 20 Jan 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>An Efficient Algorithm for Permutation Iteration Using a Singly Linked List</title>
      <link>https://arxiv.org/abs/2501.10102</link>
      <description>arXiv:2501.10102v1 Announce Type: new 
Abstract: We present a new algorithm for iterating over all permutations of a sequence. The algorithm leverages elementary operations on recursive lists. Within each recursive call, only two operations are required to generate all permutations (albeit in an unusual order): swapping the first two elements of the list or moving the last element to the front. As a result, no new nodes are allocated during the computation. Instead, all elements are rearranged within the original nodes of the singly linked list throughout the process. A proof of concept written in the Lisp programming language is proposed and discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10102v1</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <category>math.CO</category>
      <pubDate>Mon, 20 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Thomas Baruchel</dc:creator>
    </item>
    <item>
      <title>Cutwidth and Crossings</title>
      <link>https://arxiv.org/abs/2501.10183</link>
      <description>arXiv:2501.10183v1 Announce Type: new 
Abstract: We provide theoretical insights around the cutwidth of a graph and the One-Sided Crossing Minimization (OSCM) problem. OSCM was posed in the Parameterized Algorithms and Computational Experiments Challenge 2024, where the cutwidth of the input graph was the parameter in the parameterized track. We prove an asymptotically sharp upper bound on the size of a graph in terms of its order and cutwidth. As the number of so-called unsuited pairs is one of the factors that determine the difficulty of an OSCM instance, we provide a sharp upper bound on them in terms of the order $n$ and the cutwidth of the input graph. If the cutwidth is bounded by a constant, this implies an $\mathcal{O}(2^n)$-time algorithm, while the trivial algorithm has a running time of $\mathcal{O}(2^{n^2})$. At last, we prove structural properties of the so-called crossing numbers in an OSCM instance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10183v1</guid>
      <category>cs.DS</category>
      <category>math.CO</category>
      <pubDate>Mon, 20 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Johannes Rauch, Dieter Rautenbach</dc:creator>
    </item>
    <item>
      <title>Streaming Graph Algorithms in the Massively Parallel Computation Model</title>
      <link>https://arxiv.org/abs/2501.10230</link>
      <description>arXiv:2501.10230v1 Announce Type: new 
Abstract: We initiate the study of graph algorithms in the streaming setting on massive distributed and parallel systems inspired by practical data processing systems. The objective is to design algorithms that can efficiently process evolving graphs via large batches of edge insertions and deletions using as little memory as possible.
  We focus on the nowadays canonical model for the study of theoretical algorithms for massive networks, the Massively Parallel Computation (MPC) model. We design MPC algorithms that efficiently process evolving graphs: in a constant number of rounds they can handle large batches of edge updates for problems such as connectivity, minimum spanning forest, and approximate matching while adhering to the most restrictive memory regime, in which the local memory per machine is strongly sublinear in the number of vertices and the total memory is sublinear in the graph size. These results improve upon earlier works in this area which rely on using larger total space, proportional to the size of the processed graph. Our work demonstrates that parallel algorithms can process dynamically changing graphs with asymptotically optimal utilization of MPC resources: parallel time, local memory, and total memory, while processing large batches of edge updates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10230v1</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 20 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Artur Czumaj, Gopinath Mishra, Anish Mukherjee</dc:creator>
    </item>
    <item>
      <title>Learning Noisy Halfspaces with a Margin: Massart is No Harder than Random</title>
      <link>https://arxiv.org/abs/2501.09851</link>
      <description>arXiv:2501.09851v1 Announce Type: cross 
Abstract: We study the problem of PAC learning $\gamma$-margin halfspaces with Massart noise. We propose a simple proper learning algorithm, the Perspectron, that has sample complexity $\widetilde{O}((\epsilon\gamma)^{-2})$ and achieves classification error at most $\eta+\epsilon$ where $\eta$ is the Massart noise rate. Prior works [DGT19,CKMY20] came with worse sample complexity guarantees (in both $\epsilon$ and $\gamma$) or could only handle random classification noise [DDK+23,KIT+23] -- a much milder noise assumption. We also show that our results extend to the more challenging setting of learning generalized linear models with a known link function under Massart noise, achieving a similar sample complexity to the halfspace case. This significantly improves upon the prior state-of-the-art in this setting due to [CKMY20], who introduced this model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.09851v1</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <pubDate>Mon, 20 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gautam Chandrasekaran, Vasilis Kontonis, Konstantinos Stavropoulos, Kevin Tian</dc:creator>
    </item>
    <item>
      <title>Efficient Sampling of Temporal Networks with Preserved Causality Structure</title>
      <link>https://arxiv.org/abs/2501.09856</link>
      <description>arXiv:2501.09856v1 Announce Type: cross 
Abstract: In this paper, we extend the classical Color Refinement algorithm for static networks to temporal (undirected and directed) networks. This enables us to design an algorithm to sample synthetic networks that preserves the $d$-hop neighborhood structure of a given temporal network. The higher $d$ is chosen, the better the temporal neighborhood structure of the original network is preserved. Specifically, we provide efficient algorithms that preserve time-respecting ("causal") paths in the networks up to length $d$, and scale to real-world network sizes. We validate our approach theoretically (for Degree and Katz centrality) and experimentally (for edge persistence, causal triangles, and burstiness). An experimental comparison shows that our method retains these key temporal characteristics more effectively than existing randomization methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.09856v1</guid>
      <category>cs.SI</category>
      <category>cs.DS</category>
      <pubDate>Mon, 20 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Felix I. Stamm, Mehdi Naima, Michael T. Schaub</dc:creator>
    </item>
    <item>
      <title>FLASH-TB: Integrating Arc-Flags and Trip-Based Public Transit Routing</title>
      <link>https://arxiv.org/abs/2312.13146</link>
      <description>arXiv:2312.13146v2 Announce Type: replace 
Abstract: We present FLASH-TB, a journey planning algorithm for public transit networks that combines Trip-Based Public Transit Routing (TB) with the Arc-Flags speedup technique. The basic idea is simple: The network is partitioned into a configurable number of cells. For each cell and each possible transfer between two vehicles, the algorithm precomputes a flag that indicates whether the transfer is required to reach the cell. During a query, only flagged transfers are explored. Our algorithm improves upon previous attempts to apply Arc-Flags to public transit networks, which saw limited success due to conflicting rules for pruning the search space. We show that these rules can be reconciled while still producing correct results. Because the number of cells is configurable, FLASH-TB offers a tradeoff between query time and memory consumption. It is significantly more space-efficient than existing techniques with a comparable preprocessing time, which store generalized shortest-path trees: to match their query performance, it requires up to two orders of magnitude less memory. The fastest configuration of FLASH-TB achieves a speedup of more than two orders of magnitude over TB, offering sub-millisecond query times even on large countrywide networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.13146v2</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 20 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ernestine Gro{\ss}mann, Jonas Sauer, Christian Schulz, Patrick Steil, Sascha Witt</dc:creator>
    </item>
    <item>
      <title>On Approximability of Steiner Tree in $\ell_p$-metrics</title>
      <link>https://arxiv.org/abs/2306.02189</link>
      <description>arXiv:2306.02189v3 Announce Type: replace-cross 
Abstract: In the Continuous Steiner Tree problem (CST), we are given as input a set of points (called terminals) in a metric space and ask for the minimum-cost tree connecting them. Additional points (called Steiner points) from the metric space can be introduced as nodes in the solution. In the Discrete Steiner Tree problem (DST), we are given in addition to the terminals, a set of facilities, and any solution tree connecting the terminals can only contain the Steiner points from this set of facilities.
  Trevisan [SICOMP'00] showed that CST and DST are APX-hard when the input lies in the $\ell_1$-metric (and Hamming metric). Chleb\'ik and Chleb\'ikov\'a [TCS'08] showed that DST is NP-hard to approximate to factor of $96/95\approx 1.01$ in the graph metric (and consequently $\ell_\infty$-metric). Prior to this work, it was unclear if CST and DST are APX-hard in essentially every other popular metric.
  In this work, we prove that DST is APX-hard in every $\ell_p$-metric. We also prove that CST is APX-hard in the $\ell_{\infty}$-metric. Finally, we relate CST and DST, showing a general reduction from CST to DST in $\ell_p$-metrics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.02189v3</guid>
      <category>cs.CC</category>
      <category>cs.CG</category>
      <category>cs.DS</category>
      <pubDate>Mon, 20 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.46298/theoretics.25.4</arxiv:DOI>
      <arxiv:journal_reference>TheoretiCS, Volume 4 (2025), Article 4, 1-53</arxiv:journal_reference>
      <dc:creator>Henry Fleischmann, Surya Teja Gavva, Karthik C. S</dc:creator>
    </item>
  </channel>
</rss>
