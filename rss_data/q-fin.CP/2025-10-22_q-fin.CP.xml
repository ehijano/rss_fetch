<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-fin.CP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-fin.CP</link>
    <description>q-fin.CP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-fin.CP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 23 Oct 2025 04:01:02 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Optimized Multi-Level Monte Carlo Parametrization and Antithetic Sampling for Nested Simulations</title>
      <link>https://arxiv.org/abs/2510.18995</link>
      <description>arXiv:2510.18995v1 Announce Type: new 
Abstract: Estimating risk measures such as large loss probabilities and Value-at-Risk is fundamental in financial risk management and often relies on computationally intensive nested Monte Carlo methods. While Multi-Level Monte Carlo (MLMC) techniques and their weighted variants are typically more efficient, their effectiveness tends to deteriorate when dealing with irregular functions, notably indicator functions, which are intrinsic to these risk measures. We address this issue by introducing a novel MLMC parametrization that significantly improves performance in practical, non-asymptotic settings while maintaining theoretical asymptotic guarantees. We also prove that antithetic sampling of MLMC levels enhances efficiency regardless of the regularity of the underlying function. Numerical experiments motivated by the calculation of economic capital in a life insurance context confirm the practical value of our approach for estimating loss probabilities and quantiles, bridging theoretical advances and practical requirements in financial risk estimation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18995v1</guid>
      <category>q-fin.CP</category>
      <category>q-fin.RM</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexandre Boumezoued, Adel Cherchali, Vincent Lemaire, Gilles Pag\`es, Mathieu Truc</dc:creator>
    </item>
    <item>
      <title>An Efficient Calibration Framework for Volatility Derivatives under Rough Volatility with Jumps</title>
      <link>https://arxiv.org/abs/2510.19126</link>
      <description>arXiv:2510.19126v1 Announce Type: new 
Abstract: We present a fast and robust calibration method for stochastic volatility models that admit Fourier-analytic transform-based pricing via characteristic functions. The design is structure-preserving: we keep the original pricing transform and (i) split the pricing formula into data-independent inte- grals and a market-dependent remainder; (ii) precompute those data-independent integrals with GPU acceleration; and (iii) approximate only the remaining, market-dependent pricing map with a small neural network. We instantiate the workflow on a rough volatility model with tempered-stable jumps tailored to power-type volatility derivatives and calibrate it to VIX options with a global-to-local search. We verify that a pure-jump rough volatility model adequately captures the VIX dynamics, consistent with prior empirical findings, and demonstrate that our calibration method achieves high accuracy and speed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.19126v1</guid>
      <category>q-fin.CP</category>
      <category>q-fin.PR</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Keyuan Wu, Tenghan Zhong, Yuxuan Ouyang</dc:creator>
    </item>
    <item>
      <title>Denoising Complex Covariance Matrices with Hybrid ResNet and Random Matrix Theory: Cryptocurrency Portfolio Applications</title>
      <link>https://arxiv.org/abs/2510.19130</link>
      <description>arXiv:2510.19130v1 Announce Type: new 
Abstract: Covariance matrices estimated from short, noisy, and non-Gaussian financial time series-particularly cryptocurrencies-are notoriously unstable. Empirical evidence indicates that these covariance structures often exhibit power-law scaling, reflecting complex and hierarchical interactions among assets. Building on this insight, we propose a power-law covariance model to characterize the collective dynamics of cryptocurrencies and develop a hybrid estimator that integrates Random Matrix Theory (RMT) with Residual Neural Networks (ResNets). The RMT component regularizes the eigenvalue spectrum under high-dimensional noise, while the ResNet learns data-driven corrections to recover latent structural dependencies. Monte Carlo simulations show that ResNet-based estimators consistently minimize both Frobenius and minimum-variance (MV) losses across diverse covariance models. Empirical experiments on 89 cryptocurrencies (2020-2025), using a training period ending at the local BTC maximum in November 2021 and testing through the subsequent bear market, demonstrate that a two-step estimator combining hierarchical filtering with ResNet corrections yields the most profitable and balanced portfolios, remaining robust under market regime shifts. These findings highlight the potential of combining RMT, deep learning, and power-law modeling to capture the intrinsic complexity of financial systems and enhance portfolio optimization under realistic conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.19130v1</guid>
      <category>q-fin.CP</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andres Garcia-Medina</dc:creator>
    </item>
    <item>
      <title>News-Aware Direct Reinforcement Trading for Financial Markets</title>
      <link>https://arxiv.org/abs/2510.19173</link>
      <description>arXiv:2510.19173v1 Announce Type: new 
Abstract: The financial market is known to be highly sensitive to news. Therefore, effectively incorporating news data into quantitative trading remains an important challenge. Existing approaches typically rely on manually designed rules and/or handcrafted features. In this work, we directly use the news sentiment scores derived from large language models, together with raw price and volume data, as observable inputs for reinforcement learning. These inputs are processed by sequence models such as recurrent neural networks or Transformers to make end-to-end trading decisions. We conduct experiments using the cryptocurrency market as an example and evaluate two representative reinforcement learning algorithms, namely Double Deep Q-Network (DDQN) and Group Relative Policy Optimization (GRPO). The results demonstrate that our news-aware approach, which does not depend on handcrafted features or manually designed rules, can achieve performance superior to market benchmarks. We further highlight the critical role of time-series information in this process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.19173v1</guid>
      <category>q-fin.CP</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qing-Yu Lan, Zhan-He Wang, Jun-Qian Jiang, Yu-Tong Wang, Yun-Song Piao</dc:creator>
    </item>
    <item>
      <title>Aligning Multilingual News for Stock Return Prediction</title>
      <link>https://arxiv.org/abs/2510.19203</link>
      <description>arXiv:2510.19203v1 Announce Type: new 
Abstract: News spreads rapidly across languages and regions, but translations may lose subtle nuances. We propose a method to align sentences in multilingual news articles using optimal transport, identifying semantically similar content across languages. We apply this method to align more than 140,000 pairs of Bloomberg English and Japanese news articles covering around 3500 stocks in Tokyo exchange over 2012-2024. Aligned sentences are sparser, more interpretable, and exhibit higher semantic similarity. Return scores constructed from aligned sentences show stronger correlations with realized stock returns, and long-short trading strategies based on these alignments achieve 10\% higher Sharpe ratios than analyzing the full text sample.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.19203v1</guid>
      <category>q-fin.CP</category>
      <category>cs.CL</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuntao Wu, Lynn Tao, Ing-Haw Cheng, Charles Martineau, Yoshio Nozawa, John Hull, Andreas Veneris</dc:creator>
    </item>
    <item>
      <title>Quantum Machine Learning methods for Fourier-based distribution estimation with application in option pricing</title>
      <link>https://arxiv.org/abs/2510.19494</link>
      <description>arXiv:2510.19494v1 Announce Type: cross 
Abstract: The ongoing progress in quantum technologies has fueled a sustained exploration of their potential applications across various domains. One particularly promising field is quantitative finance, where a central challenge is the pricing of financial derivatives-traditionally addressed through Monte Carlo integration techniques. In this work, we introduce two hybrid classical-quantum methods to address the option pricing problem. These approaches rely on reconstructing Fourier series representations of statistical distributions from the outputs of Quantum Machine Learning (QML) models based on Parametrized Quantum Circuits (PQCs). We analyze the impact of data size and PQC dimensionality on performance. Quantum Accelerated Monte Carlo (QAMC) is employed as a benchmark to quantitatively assess the proposed models in terms of computational cost and accuracy in the extraction of Fourier coefficients. Through the numerical experiments, we show that the proposed methods achieve remarkable accuracy, becoming a competitive quantum alternative for derivatives valuation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.19494v1</guid>
      <category>quant-ph</category>
      <category>math.RT</category>
      <category>q-fin.CP</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fernando Alonso, \'Alvaro Leitao, Carlos V\'azquez</dc:creator>
    </item>
  </channel>
</rss>
