<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.SC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.SC</link>
    <description>cs.SC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.SC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 27 May 2024 04:00:03 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 27 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Submodule approach to creative telescoping</title>
      <link>https://arxiv.org/abs/2401.08455</link>
      <description>arXiv:2401.08455v2 Announce Type: replace 
Abstract: This paper proposes ideas to speed up the process of creative telescoping, particularly when the telescoper is reducible. One can interpret telescoping as computing an annihilator $L \in D$ for an element $m$ in a $D$-module $M$. The main idea is to look for submodules of $M$. If $N$ is a non-trivial submodule of $M$, constructing the minimal operator $R$ of the image of $m$ in $M/N$ gives a right-factor of $L$ in $D$. Then $L = L' R$ where the left-factor $L'$ is the telescoper of $R(m) \in N$. To expedite computing $L'$, compute the action of $D$ on a natural basis of $N$, then obtain $L'$ with a cyclic vector computation.
  The next main idea is that when $N$ has automorphisms, use them to construct submodules. An automorphism with distinct eigenvalues can be used to decompose $N$ as a direct sum $N_1 \oplus \cdots \oplus N_k$. Then $L'$ is the LCLM (Least Common Left Multiple) of $L_1, \ldots, L_k$ where $L_i$ is the telescoper of the projection of $R(m)$ on $N_i$. An LCLM can greatly increase the degrees of coefficients, so $L'$ and $L$ can be much larger expressions than the factors $L_1,\ldots,L_k$ and $R$. Examples show that computing each factor $L_i$ and $R$ seperately can save a lot of CPU time compared to computing $L$ in expanded form with standard creative telescoping.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.08455v2</guid>
      <category>cs.SC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mark van Hoeij</dc:creator>
    </item>
    <item>
      <title>Hierarchical NeuroSymbolic Approach for Comprehensive and Explainable Action Quality Assessment</title>
      <link>https://arxiv.org/abs/2403.13798</link>
      <description>arXiv:2403.13798v2 Announce Type: replace-cross 
Abstract: Action quality assessment (AQA) applies computer vision to quantitatively assess the performance or execution of a human action. Current AQA approaches are end-to-end neural models, which lack transparency and tend to be biased because they are trained on subjective human judgements as ground-truth. To address these issues, we introduce a neuro-symbolic paradigm for AQA, which uses neural networks to abstract interpretable symbols from video data and makes quality assessments by applying rules to those symbols. We take diving as the case study. We found that domain experts prefer our system and find it more informative than purely neural approaches to AQA in diving. Our system also achieves state-of-the-art action recognition and temporal segmentation, and automatically generates a detailed report that breaks the dive down into its elements and provides objective scoring with visual evidence. As verified by a group of domain experts, this report may be used to assist judges in scoring, help train judges, and provide feedback to divers. Annotated training data and code: https://github.com/laurenok24/NSAQA.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.13798v2</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.SC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Lauren Okamoto, Paritosh Parmar</dc:creator>
    </item>
  </channel>
</rss>
