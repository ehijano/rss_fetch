<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.FL updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.FL</link>
    <description>cs.FL updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.FL" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 11 Jun 2024 04:01:36 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 11 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Attributed Tree Transducers for Partial Functions</title>
      <link>https://arxiv.org/abs/2406.06141</link>
      <description>arXiv:2406.06141v1 Announce Type: new 
Abstract: Attributed tree transducers (atts) have been equipped with regular look-around (i.e., a preprocessing via an attributed relabeling) in order to obtain a more robust class of translations. Here we give further evidence of this robustness: we show that if the class of translations realized by nondeterministic atts with regular look-around is restricted to partial functions, then we obtain exactly the class of translations realized by deterministic atts with regular look-around.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06141v1</guid>
      <category>cs.FL</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sebastian Maneth, Martin Vu</dc:creator>
    </item>
    <item>
      <title>Automata Extraction from Transformers</title>
      <link>https://arxiv.org/abs/2406.05564</link>
      <description>arXiv:2406.05564v1 Announce Type: cross 
Abstract: In modern machine (ML) learning systems, Transformer-based architectures have achieved milestone success across a broad spectrum of tasks, yet understanding their operational mechanisms remains an open problem. To improve the transparency of ML systems, automata extraction methods, which interpret stateful ML models as automata typically through formal languages, have proven effective for explaining the mechanism of recurrent neural networks (RNNs). However, few works have been applied to this paradigm to Transformer models. In particular, understanding their processing of formal languages and identifying their limitations in this area remains unexplored. In this paper, we propose an automata extraction algorithm specifically designed for Transformer models. Treating the Transformer model as a black-box system, we track the model through the transformation process of their internal latent representations during their operations, and then use classical pedagogical approaches like L* algorithm to interpret them as deterministic finite-state automata (DFA). Overall, our study reveals how the Transformer model comprehends the structure of formal languages, which not only enhances the interpretability of the Transformer-based ML systems but also marks a crucial step toward a deeper understanding of how ML systems process formal languages. Code and data are available at https://github.com/Zhang-Yihao/Transfomer2DFA.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05564v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.FL</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yihao Zhang, Zeming Wei, Meng Sun</dc:creator>
    </item>
    <item>
      <title>TR2MTL: LLM based framework for Metric Temporal Logic Formalization of Traffic Rules</title>
      <link>https://arxiv.org/abs/2406.05709</link>
      <description>arXiv:2406.05709v1 Announce Type: cross 
Abstract: Traffic rules formalization is crucial for verifying the compliance and safety of autonomous vehicles (AVs). However, manual translation of natural language traffic rules as formal specification requires domain knowledge and logic expertise, which limits its adaptation. This paper introduces TR2MTL, a framework that employs large language models (LLMs) to automatically translate traffic rules (TR) into metric temporal logic (MTL). It is envisioned as a human-in-loop system for AV rule formalization. It utilizes a chain-of-thought in-context learning approach to guide the LLM in step-by-step translation and generating valid and grammatically correct MTL formulas. It can be extended to various forms of temporal logic and rules. We evaluated the framework on a challenging dataset of traffic rules we created from various sources and compared it against LLMs using different in-context learning methods. Results show that TR2MTL is domain-agnostic, achieving high accuracy and generalization capability even with a small dataset. Moreover, the method effectively predicts formulas with varying degrees of logical and semantic structure in unstructured traffic rules.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05709v1</guid>
      <category>cs.RO</category>
      <category>cs.FL</category>
      <category>cs.LG</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kumar Manas, Stefan Zwicklbauer, Adrian Paschke</dc:creator>
    </item>
    <item>
      <title>Repetition Threshold for Binary Automatic Sequences</title>
      <link>https://arxiv.org/abs/2406.06513</link>
      <description>arXiv:2406.06513v1 Announce Type: cross 
Abstract: The critical exponent of an infinite word $\bf x$ is the supremum, over all finite nonempty factors $f$, of the exponent of $f$. In this note we show that for all integers $k\geq 2,$ there is a binary infinite $k$-automatic sequence with critical exponent $\leq 7/3$. The same conclusion holds for Fibonacci-automatic and Tribonacci-automatic sequences.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06513v1</guid>
      <category>math.CO</category>
      <category>cs.DM</category>
      <category>cs.FL</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>J. -P. Allouche, N. Rampersad, J. Shallit</dc:creator>
    </item>
    <item>
      <title>Weighted Tree Automata -- May it be a little more?</title>
      <link>https://arxiv.org/abs/2212.05529</link>
      <description>arXiv:2212.05529v2 Announce Type: replace 
Abstract: This is a book on weighted tree automata. We present the basic definitions and some of the important results in a coherent form with full proofs. The concept of weighted tree automata is part of Automata Theory and it touches the area of Universal Algebra. It originated from two sources: weighted string automata and finite-state tree automata.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.05529v2</guid>
      <category>cs.FL</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zolt\'an F\"ul\"op, Heiko Vogler</dc:creator>
    </item>
    <item>
      <title>The Expansion Problem for Infinite Trees</title>
      <link>https://arxiv.org/abs/2308.01174</link>
      <description>arXiv:2308.01174v3 Announce Type: replace 
Abstract: We study Ramsey like theorems for infinite trees and similar combinatorial tools. As an application we consider the expansion problem for tree algebras.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.01174v3</guid>
      <category>cs.FL</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Achim Blumensath</dc:creator>
    </item>
    <item>
      <title>Probabilistic Regular Tree Priors for Scientific Symbolic Reasoning</title>
      <link>https://arxiv.org/abs/2306.08506</link>
      <description>arXiv:2306.08506v2 Announce Type: replace-cross 
Abstract: Symbolic Regression (SR) allows for the discovery of scientific equations from data. To limit the large search space of possible equations, prior knowledge has been expressed in terms of formal grammars that characterize subsets of arbitrary strings. However, there is a mismatch between context-free grammars required to express the set of syntactically correct equations, missing closure properties of the former, and a tree structure of the latter. Our contributions are to (i) compactly express experts' prior beliefs about which equations are more likely to be expected by probabilistic Regular Tree Expressions (pRTE), and (ii) adapt Bayesian inference to make such priors efficiently available for symbolic regression encoded as finite state machines. Our scientific case studies show its effectiveness in soil science to find sorption isotherms and for modeling hyper-elastic materials.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.08506v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.FL</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tim Schneider, Amin Totounferoush, Wolfgang Nowak, Steffen Staab</dc:creator>
    </item>
  </channel>
</rss>
