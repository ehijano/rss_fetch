<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CR updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CR</link>
    <description>cs.CR updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CR" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 29 May 2025 01:54:35 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>EarthOL: A Proof-of-Human-Contribution Consensus Protocol -- Addressing Fundamental Challenges in Decentralized Value Assessment with Enhanced Verification and Security Mechanisms</title>
      <link>https://arxiv.org/abs/2505.20614</link>
      <description>arXiv:2505.20614v1 Announce Type: new 
Abstract: This paper introduces EarthOL, a novel consensus protocol that attempts to replace computational waste in blockchain systems with verifiable human contributions within bounded domains. While recognizing the fundamental impossibility of universal value assessment, we propose a domain-restricted approach that acknowledges cultural diversity and subjective preferences while maintaining cryptographic security. Our enhanced Proof-of-Human-Contribution (PoHC) protocol uses a multi-layered verification system with domain-specific evaluation criteria, time-dependent validation mechanisms, and comprehensive security frameworks. We present theoretical analysis demonstrating meaningful progress toward incentive-compatible human contribution verification in high-consensus domains, achieving Byzantine fault tolerance in controlled scenarios while addressing significant scalability and cultural bias challenges. Through game-theoretic analysis, probabilistic modeling, and enhanced security protocols, we identify specific conditions under which the protocol remains stable and examine failure modes with comprehensive mitigation strategies. This work contributes to understanding the boundaries of decentralized value assessment and provides a framework for future research in human-centered consensus mechanisms for specific application domains, with particular emphasis on validator and security specialist incentive systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20614v1</guid>
      <category>cs.CR</category>
      <category>cs.CY</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiaxiong He</dc:creator>
    </item>
    <item>
      <title>Respond to Change with Constancy: Instruction-tuning with LLM for Non-I.I.D. Network Traffic Classification</title>
      <link>https://arxiv.org/abs/2505.20866</link>
      <description>arXiv:2505.20866v1 Announce Type: new 
Abstract: Encrypted traffic classification is highly challenging in network security due to the need for extracting robust features from content-agnostic traffic data. Existing approaches face critical issues: (i) Distribution drift, caused by reliance on the closedworld assumption, limits adaptability to realworld, shifting patterns; (ii) Dependence on labeled data restricts applicability where such data is scarce or unavailable. Large language models (LLMs) have demonstrated remarkable potential in offering generalizable solutions across a wide range of tasks, achieving notable success in various specialized fields. However, their effectiveness in traffic analysis remains constrained by challenges in adapting to the unique requirements of the traffic domain. In this paper, we introduce a novel traffic representation model named Encrypted Traffic Out-of-Distribution Instruction Tuning with LLM (ETooL), which integrates LLMs with knowledge of traffic structures through a self-supervised instruction tuning paradigm. This framework establishes connections between textual information and traffic interactions. ETooL demonstrates more robust classification performance and superior generalization in both supervised and zero-shot traffic classification tasks. Notably, it achieves significant improvements in F1 scores: APP53 (I.I.D.) to 93.19%(6.62%) and 92.11%(4.19%), APP53 (O.O.D.) to 74.88%(18.17%) and 72.13%(15.15%), and ISCX-Botnet (O.O.D.) to 95.03%(9.16%) and 81.95%(12.08%). Additionally, we construct NETD, a traffic dataset designed to support dynamic distributional shifts, and use it to validate ETooL's effectiveness under varying distributional conditions. Furthermore, we evaluate the efficiency gains achieved through ETooL's instruction tuning approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20866v1</guid>
      <category>cs.CR</category>
      <category>cs.AI</category>
      <category>cs.NI</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TIFS.2025.3574971</arxiv:DOI>
      <dc:creator>Xinjie Lin, Gang Xiong, Gaopeng Gou, Wenqi Dong, Jing Yu, Zhen Li, Wei Xia</dc:creator>
    </item>
    <item>
      <title>Towards a DSL for hybrid secure computation</title>
      <link>https://arxiv.org/abs/2505.20912</link>
      <description>arXiv:2505.20912v1 Announce Type: new 
Abstract: Fully homomorphic encryption (FHE) and trusted execution environments (TEE) are two approaches to provide confidentiality during data processing. Each approach has its own strengths and weaknesses. In certain scenarios, computations can be carried out in a hybrid environment, using both FHE and TEE. However, processing data in such hybrid settings presents challenges, as it requires to adapt and rewrite the algorithms for the chosen technique. We propose a domain-specific language (DSL) for secure computation that allows to express the computations to perform and execute them using a backend that leverages either FHE or TEE, depending on what is available.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20912v1</guid>
      <category>cs.CR</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3701717.3733225</arxiv:DOI>
      <dc:creator>Romain de Laage</dc:creator>
    </item>
    <item>
      <title>IRCopilot: Automated Incident Response with Large Language Models</title>
      <link>https://arxiv.org/abs/2505.20945</link>
      <description>arXiv:2505.20945v1 Announce Type: new 
Abstract: Incident response plays a pivotal role in mitigating the impact of cyber attacks. In recent years, the intensity and complexity of global cyber threats have grown significantly, making it increasingly challenging for traditional threat detection and incident response methods to operate effectively in complex network environments. While Large Language Models (LLMs) have shown great potential in early threat detection, their capabilities remain limited when it comes to automated incident response after an intrusion. To address this gap, we construct an incremental benchmark based on real-world incident response tasks to thoroughly evaluate the performance of LLMs in this domain. Our analysis reveals several key challenges that hinder the practical application of contemporary LLMs, including context loss, hallucinations, privacy protection concerns, and their limited ability to provide accurate, context-specific recommendations. In response to these challenges, we propose IRCopilot, a novel framework for automated incident response powered by LLMs. IRCopilot mimics the three dynamic phases of a real-world incident response team using four collaborative LLM-based session components. These components are designed with clear divisions of responsibility, reducing issues such as hallucinations and context loss. Our method leverages diverse prompt designs and strategic responsibility segmentation, significantly improving the system's practicality and efficiency. Experimental results demonstrate that IRCopilot outperforms baseline LLMs across key benchmarks, achieving sub-task completion rates of 150%, 138%, 136%, 119%, and 114% for various response tasks. Moreover, IRCopilot exhibits robust performance on public incident response platforms and in real-world attack scenarios, showcasing its strong applicability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20945v1</guid>
      <category>cs.CR</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xihuan Lin, Jie Zhang, Gelei Deng, Tianzhe Liu, Xiaolong Liu, Changcai Yang, Tianwei Zhang, Qing Guo, Riqing Chen</dc:creator>
    </item>
    <item>
      <title>Unveiling Impact of Frequency Components on Membership Inference Attacks for Diffusion Models</title>
      <link>https://arxiv.org/abs/2505.20955</link>
      <description>arXiv:2505.20955v1 Announce Type: new 
Abstract: Diffusion models have achieved tremendous success in image generation, but they also raise significant concerns regarding privacy and copyright issues. Membership Inference Attacks (MIAs) are designed to ascertain whether specific data were utilized during a model's training phase. As current MIAs for diffusion models typically exploit the model's image prediction ability, we formalize them into a unified general paradigm which computes the membership score for membership identification. Under this paradigm, we empirically find that existing attacks overlook the inherent deficiency in how diffusion models process high-frequency information. Consequently, this deficiency leads to member data with more high-frequency content being misclassified as hold-out data, and hold-out data with less high-frequency content tend to be misclassified as member data. Moreover, we theoretically demonstrate that this deficiency reduces the membership advantage of attacks, thereby interfering with the effective discrimination of member data and hold-out data. Based on this insight, we propose a plug-and-play high-frequency filter module to mitigate the adverse effects of the deficiency, which can be seamlessly integrated into any attacks within this general paradigm without additional time costs. Extensive experiments corroborate that this module significantly improves the performance of baseline attacks across different datasets and models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20955v1</guid>
      <category>cs.CR</category>
      <category>cs.LG</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Puwei Lian, Yujun Cai, Songze Li</dc:creator>
    </item>
    <item>
      <title>A Hitchhiker's Guide to Privacy-Preserving Cryptocurrencies: A Survey on Anonymity, Confidentiality, and Auditability</title>
      <link>https://arxiv.org/abs/2505.21008</link>
      <description>arXiv:2505.21008v1 Announce Type: new 
Abstract: Cryptocurrencies and central bank digital currencies (CBDCs) are reshaping the monetary landscape, offering transparency and efficiency while raising critical concerns about user privacy and regulatory compliance. This survey provides a comprehensive and technically grounded overview of privacy-preserving digital currencies, covering both cryptocurrencies and CBDCs. We propose a taxonomy of privacy goals -- including anonymity, confidentiality, unlinkability, and auditability -- and map them to underlying cryptographic primitives, protocol mechanisms, and system architectures. Unlike previous surveys, our work adopts a design-oriented perspective, linking high-level privacy objectives to concrete implementations. We also trace the evolution of privacy-preserving currencies through three generations, highlighting shifts from basic anonymity guarantees toward more nuanced privacy-accountability trade-offs. Finally, we identify open challenges at the intersection of cryptography, distributed systems, and policy definition, which motivate further investigation into the primitives and design of digital currencies that balance real-world privacy and auditability needs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21008v1</guid>
      <category>cs.CR</category>
      <category>cs.DC</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matteo Nardelli, Francesco De Sclavis, Michela Iezzi</dc:creator>
    </item>
    <item>
      <title>Uncovering Black-hat SEO based fake E-commerce scam groups from their redirectors and websites</title>
      <link>https://arxiv.org/abs/2505.21021</link>
      <description>arXiv:2505.21021v1 Announce Type: new 
Abstract: While law enforcements agencies and cybercrime researchers are working hard, fake E-commerce scam is still a big threat to Internet users. One of the major techniques to victimize users is luring them by black-hat search-engine-optimization (SEO); making search engines display their lure pages as if these were placed on compromised websites and then redirecting visitors to malicious sites. In this study, we focus on the threat actors conduct fake E-commerce scam with this strategy. Our previous study looked at the connection between some malware families used for black-hat SEO to enlighten threat actors and their infrastructures, however it shows only a limited part of the whole picture because we could not find all SEO malware samples from limited sources. In this paper, we aim to identify and analyze threat actor groups using a large dataset of fake E-commerce sites collected by Japan Cybercrime Control Center, which we believe is of higher quality. It includes 692,865 fake EC sites gathered from redirectors over two and a half years, from May 20, 2022 to Dec. 31, 2024. We analyzed the links between these sites using Maltego, a well-known link analysis tool, and tailored programs. We also conducted time series analysis to track group changes in the groups. According to the analysis, we estimate that 17 relatively large groups were active during the dataset period and some of them were active throughout the period.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21021v1</guid>
      <category>cs.CR</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Makoto Shimamura, Shingo Matsugaya, Keisuke Sakai, Kosuke Takeshige, Masaki Hashimoto</dc:creator>
    </item>
    <item>
      <title>SHE-LoRA: Selective Homomorphic Encryption for Federated Tuning with Heterogeneous LoRA</title>
      <link>https://arxiv.org/abs/2505.21051</link>
      <description>arXiv:2505.21051v1 Announce Type: new 
Abstract: Federated fine-tuning of large language models (LLMs) is critical for improving their performance in handling domain-specific tasks. However, prior work has shown that clients' private data can actually be recovered via gradient inversion attacks. Existing privacy preservation techniques against such attacks typically entail performance degradation and high costs, making them ill-suited for clients with heterogeneous data distributions and device capabilities. In this paper, we propose SHE-LoRA, which integrates selective homomorphic encryption (HE) and low-rank adaptation (LoRA) to enable efficient and privacy-preserving federated tuning of LLMs in cross-device environment. Heterogeneous clients adaptively select partial model parameters for homomorphic encryption based on parameter sensitivity assessment, with the encryption subset obtained via negotiation. To ensure accurate model aggregation, we design a column-aware secure aggregation method and customized reparameterization techniques to align the aggregation results with the heterogeneous device capabilities of clients. Extensive experiments demonstrate that SHE-LoRA maintains performance comparable to non-private baselines, achieves strong resistance to the state-of-the-art attacks, and significantly reduces communication overhead by 94.901\% and encryption computation overhead by 99.829\%, compared to baseline. Our code is accessible at https://anonymous.4open.science/r/SHE-LoRA-8D84.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21051v1</guid>
      <category>cs.CR</category>
      <category>cs.DC</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jianmin Liu, Li Yan, Borui Li, Lei Yu, Chao Shen</dc:creator>
    </item>
    <item>
      <title>ColorGo: Directed Concolic Execution</title>
      <link>https://arxiv.org/abs/2505.21130</link>
      <description>arXiv:2505.21130v1 Announce Type: new 
Abstract: Directed fuzzing is a critical technique in cybersecurity, targeting specific sections of a program. This approach is essential in various security-related domains such as crash reproduction, patch testing, and vulnerability detection. Despite its importance, current directed fuzzing methods exhibit a trade-off between efficiency and effectiveness. For instance, directed grey-box fuzzing, while efficient in generating fuzzing inputs, lacks sufficient precision. The low precision causes time wasted on executing code that cannot help reach the target site. Conversely, interpreter- or observer-based directed symbolic execution can produce high-quality inputs while incurring non-negligible runtime overhead. These limitations undermine the feasibility of directed fuzzers in real-world scenarios. To kill the birds of efficiency and effectiveness with one stone, in this paper, we involve compilation-based concolic execution into directed fuzzing and present ColorGo, achieving high scalability while preserving the high precision from symbolic execution. ColorGo is a new directed whitebox fuzzer that concretely executes the instrumented program with constraint-solving capability on generated input. It guides the exploration by \textit{incremental coloration}, including static reachability analysis and dynamic feasibility analysis. We evaluated ColorGo on diverse real-world programs and demonstrated that ColorGo outperforms AFLGo by up to \textbf{100x} in reaching target sites and reproducing target crashes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21130v1</guid>
      <category>cs.CR</category>
      <category>cs.SE</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jia Li, Jiacheng Shen, Yuxin Su, Michael R. Lyu</dc:creator>
    </item>
    <item>
      <title>JavaSith: A Client-Side Framework for Analyzing Potentially Malicious Extensions in Browsers, VS Code, and NPM Packages</title>
      <link>https://arxiv.org/abs/2505.21263</link>
      <description>arXiv:2505.21263v1 Announce Type: new 
Abstract: Modern software supply chains face an increasing threat from malicious code hidden in trusted components such as browser extensions, IDE extensions, and open-source packages. This paper introduces JavaSith, a novel client-side framework for analyzing potentially malicious extensions in web browsers, Visual Studio Code (VSCode), and Node's NPM packages. JavaSith combines a runtime sandbox that emulates browser/Node.js extension APIs (with a ``time machine'' to accelerate time-based triggers) with static analysis and a local large language model (LLM) to assess risk from code and metadata. We present the design and architecture of JavaSith, including techniques for intercepting extension behavior over simulated time and extracting suspicious patterns. Through case studies on real-world attacks (such as a supply-chain compromise of a Chrome extension and malicious VSCode extensions installing cryptominers), we demonstrate how JavaSith can catch stealthy malicious behaviors that evade traditional detection. We evaluate the framework's effectiveness and discuss its limitations and future enhancements. JavaSith's client-side approach empowers end-users/organizations to vet extensions and packages before trustingly integrating them into their environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21263v1</guid>
      <category>cs.CR</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Avihay Cohen</dc:creator>
    </item>
    <item>
      <title>Breaking the Ceiling: Exploring the Potential of Jailbreak Attacks through Expanding Strategy Space</title>
      <link>https://arxiv.org/abs/2505.21277</link>
      <description>arXiv:2505.21277v2 Announce Type: new 
Abstract: Large Language Models (LLMs), despite advanced general capabilities, still suffer from numerous safety risks, especially jailbreak attacks that bypass safety protocols. Understanding these vulnerabilities through black-box jailbreak attacks, which better reflect real-world scenarios, offers critical insights into model robustness. While existing methods have shown improvements through various prompt engineering techniques, their success remains limited against safety-aligned models, overlooking a more fundamental problem: the effectiveness is inherently bounded by the predefined strategy spaces. However, expanding this space presents significant challenges in both systematically capturing essential attack patterns and efficiently navigating the increased complexity. To better explore the potential of expanding the strategy space, we address these challenges through a novel framework that decomposes jailbreak strategies into essential components based on the Elaboration Likelihood Model (ELM) theory and develops genetic-based optimization with intention evaluation mechanisms. To be striking, our experiments reveal unprecedented jailbreak capabilities by expanding the strategy space: we achieve over 90% success rate on Claude-3.5 where prior methods completely fail, while demonstrating strong cross-model transferability and surpassing specialized safeguard models in evaluation accuracy. The code is open-sourced at: https://github.com/Aries-iai/CL-GSO.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21277v2</guid>
      <category>cs.CR</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yao Huang, Yitong Sun, Shouwei Ruan, Yichi Zhang, Yinpeng Dong, Xingxing Wei</dc:creator>
    </item>
    <item>
      <title>Enhancing JavaScript Malware Detection through Weighted Behavioral DFAs</title>
      <link>https://arxiv.org/abs/2505.21406</link>
      <description>arXiv:2505.21406v1 Announce Type: new 
Abstract: This work addresses JavaScript malware detection to enhance client-side web application security with a behavior-based system. The ability to detect malicious JavaScript execution sequences is a critical problem in modern web security as attack techniques become more sophisticated. This study introduces a new system for detecting JavaScript malware using a Deterministic Finite Automaton (DFA) along with a weighted-behavior system, which we call behavior DFA. This system captures malicious patterns and provides a dynamic mechanism to classify new sequences that exhibit partial similarity to known attacks, differentiating them between benign, partially malicious, and fully malicious behaviors. Experimental evaluation on a dataset of 1,058 sequences captured in a real-world environment demonstrates the capability of the system to detect and classify threats effectively, with the behavior DFA successfully identifying exact matches and partial similarities to known malicious behaviors. The results highlight the adaptability of the system in detecting emerging threats while maintaining transparency in decision making.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21406v1</guid>
      <category>cs.CR</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pedro Pereira, Jos\'e Gon\c{c}alves, Jo\~ao Vitorino, Eva Maia, Isabel Pra\c{c}a</dc:creator>
    </item>
    <item>
      <title>Cryptography from Lossy Reductions: Towards OWFs from ETH, and Beyond</title>
      <link>https://arxiv.org/abs/2505.21442</link>
      <description>arXiv:2505.21442v1 Announce Type: new 
Abstract: One-way functions (OWFs) form the foundation of modern cryptography, yet their unconditional existence remains a major open question. In this work, we study this question by exploring its relation to lossy reductions, i.e., reductions~$R$ for which it holds that $I(X;R(X)) \ll n$ for all distributions~$X$ over inputs of size $n$. Our main result is that either OWFs exist or any lossy reduction for any promise problem~$\Pi$ runs in time~$2^{\Omega(\log\tau_\Pi / \log\log n)}$, where $\tau_\Pi(n)$ is the infimum of the runtime of all (worst-case) solvers of~$\Pi$ on instances of size~$n$. In fact, our result requires a milder condition, that $R$ is lossy for sparse uniform distributions (which we call mild-lossiness). It also extends to $f$-reductions as long as $f$ is a non-constant permutation-invariant Boolean function, which includes And-, Or-, Maj-, Parity-, Modulo $k$, and Threshold $k$-reductions.
  Additionally, we show that worst-case to average-case Karp reductions and randomized encodings are special cases of mildly-lossy reductions and improve the runtime above as $2^{\Omega(\log \tau_\Pi)}$ when these mappings are considered. Restricting to weak fine-grained OWFs, this runtime can be further improved as~$\Omega(\tau_\Pi)$. Taking~$\Pi$ as~$kSAT$, our results provide sufficient conditions under which (fine-grained) OWFs exist assuming the Exponential Time Hypothesis (ETH). Conversely, if (fine-grained) OWFs do not exist, we obtain impossibilities on instance compressions (Harnik and Naor, FOCS 2006) and instance randomizations of~$kSAT$ under the ETH.
  Finally, we partially extend these findings to the quantum setting; the existence of a pure quantum mildly-lossy reduction for $\Pi$ within the runtime~$2^{o(\log\tau_\Pi / \log\log n)}$ implies the existence of one-way state generators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21442v1</guid>
      <category>cs.CR</category>
      <category>quant-ph</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pouria Fallahpour, Alex B. Grilo, Garazi Muguruza, Mahshid Riahinia</dc:creator>
    </item>
    <item>
      <title>M3S-UPD: Efficient Multi-Stage Self-Supervised Learning for Fine-Grained Encrypted Traffic Classification with Unknown Pattern Discovery</title>
      <link>https://arxiv.org/abs/2505.21462</link>
      <description>arXiv:2505.21462v1 Announce Type: new 
Abstract: The growing complexity of encrypted network traffic presents dual challenges for modern network management: accurate multiclass classification of known applications and reliable detection of unknown traffic patterns. Although deep learning models show promise in controlled environments, their real-world deployment is hindered by data scarcity, concept drift, and operational constraints. This paper proposes M3S-UPD, a novel Multi-Stage Self-Supervised Unknown-aware Packet Detection framework that synergistically integrates semi-supervised learning with representation analysis. Our approach eliminates artificial segregation between classification and detection tasks through a four-phase iterative process: 1) probabilistic embedding generation, 2) clustering-based structure discovery, 3) distribution-aligned outlier identification, and 4) confidence-aware model updating. Key innovations include a self-supervised unknown detection mechanism that requires neither synthetic samples nor prior knowledge, and a continuous learning architecture that is resistant to performance degradation. Experimental results show that M3S-UPD not only outperforms existing methods on the few-shot encrypted traffic classification task, but also simultaneously achieves competitive performance on the zero-shot unknown traffic discovery task.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21462v1</guid>
      <category>cs.CR</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yali Yuan, Yu Huang, Xingjian Zeng, Hantao Mei, Guang Cheng</dc:creator>
    </item>
    <item>
      <title>AdInject: Real-World Black-Box Attacks on Web Agents via Advertising Delivery</title>
      <link>https://arxiv.org/abs/2505.21499</link>
      <description>arXiv:2505.21499v1 Announce Type: new 
Abstract: Vision-Language Model (VLM) based Web Agents represent a significant step towards automating complex tasks by simulating human-like interaction with websites. However, their deployment in uncontrolled web environments introduces significant security vulnerabilities. Existing research on adversarial environmental injection attacks often relies on unrealistic assumptions, such as direct HTML manipulation, knowledge of user intent, or access to agent model parameters, limiting their practical applicability. In this paper, we propose AdInject, a novel and real-world black-box attack method that leverages the internet advertising delivery to inject malicious content into the Web Agent's environment. AdInject operates under a significantly more realistic threat model than prior work, assuming a black-box agent, static malicious content constraints, and no specific knowledge of user intent. AdInject includes strategies for designing malicious ad content aimed at misleading agents into clicking, and a VLM-based ad content optimization technique that infers potential user intents from the target website's context and integrates these intents into the ad content to make it appear more relevant or critical to the agent's task, thus enhancing attack effectiveness. Experimental evaluations demonstrate the effectiveness of AdInject, attack success rates exceeding 60% in most scenarios and approaching 100% in certain cases. This strongly demonstrates that prevalent advertising delivery constitutes a potent and real-world vector for environment injection attacks against Web Agents. This work highlights a critical vulnerability in Web Agent security arising from real-world environment manipulation channels, underscoring the urgent need for developing robust defense mechanisms against such threats. Our code is available at https://github.com/NicerWang/AdInject.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21499v1</guid>
      <category>cs.CR</category>
      <category>cs.AI</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haowei Wang, Junjie Wang, Xiaojun Jia, Rupeng Zhang, Mingyang Li, Zhe Liu, Yang Liu, Qing Wang</dc:creator>
    </item>
    <item>
      <title>Red-Teaming Text-to-Image Systems by Rule-based Preference Modeling</title>
      <link>https://arxiv.org/abs/2505.21074</link>
      <description>arXiv:2505.21074v1 Announce Type: cross 
Abstract: Text-to-image (T2I) models raise ethical and safety concerns due to their potential to generate inappropriate or harmful images. Evaluating these models' security through red-teaming is vital, yet white-box approaches are limited by their need for internal access, complicating their use with closed-source models. Moreover, existing black-box methods often assume knowledge about the model's specific defense mechanisms, limiting their utility in real-world commercial API scenarios. A significant challenge is how to evade unknown and diverse defense mechanisms. To overcome this difficulty, we propose a novel Rule-based Preference modeling Guided Red-Teaming (RPG-RT), which iteratively employs LLM to modify prompts to query and leverages feedback from T2I systems for fine-tuning the LLM. RPG-RT treats the feedback from each iteration as a prior, enabling the LLM to dynamically adapt to unknown defense mechanisms. Given that the feedback is often labeled and coarse-grained, making it difficult to utilize directly, we further propose rule-based preference modeling, which employs a set of rules to evaluate desired or undesired feedback, facilitating finer-grained control over the LLM's dynamic adaptation process. Extensive experiments on nineteen T2I systems with varied safety mechanisms, three online commercial API services, and T2V models verify the superiority and practicality of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21074v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CR</category>
      <category>cs.CV</category>
      <category>stat.ML</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yichuan Cao, Yibo Miao, Xiao-Shan Gao, Yinpeng Dong</dc:creator>
    </item>
    <item>
      <title>An average case efficient algorithm for solving two-variable linear Diophantine equations</title>
      <link>https://arxiv.org/abs/2409.14052</link>
      <description>arXiv:2409.14052v4 Announce Type: replace 
Abstract: We revisit two algorithms to solve two-variable linear Diophantine equations. We write the iterative version of one of them. For another, we analyze the number of recursive calls. We find that the number of recursive calls is a periodic function. We derive the period of this function and various upper bounds on this function. We find that for a fixed value of $a$, $b$ and $a$ varying $c$, such that equation $ax+by = c$ (where $a &gt; b$) is solvable, we can find the solution in $O\left(\frac{\log b}{gcd(a,b)}\right)$ average number of recursions. We computationally evaluate and verify this bound. We compare this bound and another bound with the average number of recursive calls in Extended Euclid's algorithm on random $512$-bit inputs. We propose an iterative version of the algorithm. Our algorithm performs better in terms of the average number of iterations against the two existing algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.14052v4</guid>
      <category>cs.CR</category>
      <category>cs.DS</category>
      <category>math.NT</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mayank Deora, Pinakpani Pal</dc:creator>
    </item>
    <item>
      <title>CRSet: Private Non-Interactive Verifiable Credential Revocation</title>
      <link>https://arxiv.org/abs/2501.17089</link>
      <description>arXiv:2501.17089v2 Announce Type: replace 
Abstract: Like any digital certificate, Verifiable Credentials (VCs) require a way to revoke them in case of an error or key compromise. Existing solutions for VC revocation, most prominently Bitstring Status List, are not viable for many use cases because they may leak the issuer's activity, which in turn leaks internal business metrics. For instance, staff fluctuation through the revocation of employee IDs. We identify the protection of issuer activity as a key gap and propose formal definitions for corresponding characteristics of a revocation mechanism. Then, we introduce CRSet, a non-interactive mechanism that trades some space efficiency to reach these privacy characteristics. For that, we provide a proof sketch. Issuers periodically encode revocation data and publish it via Ethereum blob-carrying transactions, ensuring secure and private availability. Relying Parties (RPs) can download it to perform revocation checks locally. Sticking to a non-interactive design also makes adoption easier because it requires no changes to wallet agents and exchange protocols. We also implement and empirically evaluate CRSet, finding its real-world behavior to match expectations. One Ethereum blob fits revocation data for about 170k VCs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.17089v2</guid>
      <category>cs.CR</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Felix Hoops, Jonas Gebele, Florian Matthes</dc:creator>
    </item>
    <item>
      <title>ALLMod: Exploring $\underline{\mathbf{A}}$rea-Efficiency of $\underline{\mathbf{L}}$UT-based $\underline{\mathbf{L}}$arge Number $\underline{\mathbf{Mod}}$ular Reduction via Hybrid Workloads</title>
      <link>https://arxiv.org/abs/2503.15916</link>
      <description>arXiv:2503.15916v2 Announce Type: replace 
Abstract: Modular arithmetic, particularly modular reduction, is widely used in cryptographic applications such as homomorphic encryption (HE) and zero-knowledge proofs (ZKP). High-bit-width operations are crucial for enhancing security; however, they are computationally intensive due to the large number of modular operations required. The lookup-table-based (LUT-based) approach, a ``space-for-time'' technique, reduces computational load by segmenting the input number into smaller bit groups, pre-computing modular reduction results for each segment, and storing these results in LUTs. While effective, this method incurs significant hardware overhead due to extensive LUT usage. In this paper, we introduce ALLMod, a novel approach that improves the area efficiency of LUT-based large-number modular reduction by employing hybrid workloads. Inspired by the iterative method, ALLMod splits the bit groups into two distinct workloads, achieving lower area costs without compromising throughput. We first develop a template to facilitate workload splitting and ensure balanced distribution. Then, we conduct design space exploration to evaluate the optimal timing for fusing workload results, enabling us to identify the most efficient design under specific constraints. Extensive evaluations show that ALLMod achieves up to $1.65\times$ and $3\times$ improvements in area efficiency over conventional LUT-based methods for bit-widths of $128$ and $8,192$, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.15916v2</guid>
      <category>cs.CR</category>
      <category>cs.AR</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fangxin Liu, Haomin Li, Zongwu Wang, Bo Zhang, Mingzhe Zhang, Shoumeng Yan, Li Jiang, Haibing Guan</dc:creator>
    </item>
    <item>
      <title>Eccfrog512ck2: An Enhanced 512-bit Weierstrass Elliptic Curve</title>
      <link>https://arxiv.org/abs/2504.09584</link>
      <description>arXiv:2504.09584v2 Announce Type: replace 
Abstract: Whilst many key exchange and digital signature methods use the NIST P256 (secp256r1) and secp256k1 curves, there is often a demand for increased security. With these curves, we have a 128-bit security. These security levels can be increased to 256-bit security with NIST P-521 Curve 448 and Brainpool-P512. This paper outlines a new curve - Eccfrog512ck2 - and which provides 256-bit security and enhanced performance over NIST P-521. Along with this, it has side-channel resistance and is designed to avoid weaknesses such as related to the MOV attack. It shows that Eccfrog512ck2 can have a 61.5% speed-up on scalar multiplication and a 33.3% speed-up on point generation over the NIST P-521 curve.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.09584v2</guid>
      <category>cs.CR</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>V\'ictor Duarte Melo, William J. Buchanan</dc:creator>
    </item>
    <item>
      <title>BLACKOUT: Data-Oblivious Computation with Blinded Capabilities</title>
      <link>https://arxiv.org/abs/2504.14654</link>
      <description>arXiv:2504.14654v2 Announce Type: replace 
Abstract: Lack of memory-safety and exposure to side channels are two prominent, persistent challenges for the secure implementation of software. Memory-safe programming languages promise to significantly reduce the prevalence of memory-safety bugs, but make it more difficult to implement side-channel-resistant code. We aim to address both memory-safety and side-channel resistance by augmenting memory-safe hardware with the ability for data-oblivious programming. We describe an extension to the CHERI capability architecture to provide blinded capabilities that allow data-oblivious computation to be carried out by userspace tasks. We also present BLACKOUT, our realization of blinded capabilities on a FPGA softcore based on the speculative out-of-order CHERI-Toooba processor and extend the CHERI-enabled Clang/LLVM compiler and the CheriBSD operating system with support for blinded capabilities. BLACKOUT makes writing side-channel-resistant code easier by making non-data-oblivious operations via blinded capabilities explicitly fault. Through rigorous evaluation we show that BLACKOUT ensures memory operated on through blinded capabilities is securely allocated, used, and reclaimed and demonstrate that, in benchmarks comparable to those used by previous work, BLACKOUT imposes only a small performance degradation (1.5% geometric mean) compared to the baseline CHERI-Toooba processor.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14654v2</guid>
      <category>cs.CR</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hossam ElAtali, Merve G\"ulmez, Thomas Nyman, N. Asokan</dc:creator>
    </item>
    <item>
      <title>BitHydra: Towards Bit-flip Inference Cost Attack against Large Language Models</title>
      <link>https://arxiv.org/abs/2505.16670</link>
      <description>arXiv:2505.16670v2 Announce Type: replace 
Abstract: Large language models (LLMs) have shown impressive capabilities across a wide range of applications, but their ever-increasing size and resource demands make them vulnerable to inference cost attacks, where attackers induce victim LLMs to generate the longest possible output content. In this paper, we revisit existing inference cost attacks and reveal that these methods can hardly produce large-scale malicious effects since they are self-targeting, where attackers are also the users and therefore have to execute attacks solely through the inputs, whose generated content will be charged by LLMs and can only directly influence themselves. Motivated by these findings, this paper introduces a new type of inference cost attacks (dubbed 'bit-flip inference cost attack') that target the victim model itself rather than its inputs. Specifically, we design a simple yet effective method (dubbed 'BitHydra') to effectively flip critical bits of model parameters. This process is guided by a loss function designed to suppress &lt;EOS&gt; token's probability with an efficient critical bit search algorithm, thus explicitly defining the attack objective and enabling effective optimization. We evaluate our method on 11 LLMs ranging from 1.5B to 14B parameters under both int8 and float16 settings. Experimental results demonstrate that with just 4 search samples and as few as 3 bit flips, BitHydra can force 100% of test prompts to reach the maximum generation length (e.g., 2048 tokens) on representative LLMs such as LLaMA3, highlighting its efficiency, scalability, and strong transferability across unseen inputs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.16670v2</guid>
      <category>cs.CR</category>
      <category>cs.AI</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaobei Yan, Yiming Li, Zhaoxin Fan, Han Qiu, Tianwei Zhang</dc:creator>
    </item>
    <item>
      <title>Evaluating AI cyber capabilities with crowdsourced elicitation</title>
      <link>https://arxiv.org/abs/2505.19915</link>
      <description>arXiv:2505.19915v2 Announce Type: replace 
Abstract: As AI systems become increasingly capable, understanding their offensive cyber potential is critical for informed governance and responsible deployment. However, it's hard to accurately bound their capabilities, and some prior evaluations dramatically underestimated them. The art of extracting maximum task-specific performance from AIs is called "AI elicitation", and today's safety organizations typically conduct it in-house. In this paper, we explore crowdsourcing elicitation efforts as an alternative to in-house elicitation work.
  We host open-access AI tracks at two Capture The Flag (CTF) competitions: AI vs. Humans (400 teams) and Cyber Apocalypse (8000 teams). The AI teams achieve outstanding performance at both events, ranking top-5% and top-10% respectively for a total of \$7500 in bounties. This impressive performance suggests that open-market elicitation may offer an effective complement to in-house elicitation. We propose elicitation bounties as a practical mechanism for maintaining timely, cost-effective situational awareness of emerging AI capabilities.
  Another advantage of open elicitations is the option to collect human performance data at scale. Applying METR's methodology, we found that AI agents can reliably solve cyber challenges requiring one hour or less of effort from a median human CTF participant.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19915v2</guid>
      <category>cs.CR</category>
      <category>cs.AI</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Artem Petrov, Dmitrii Volkov</dc:creator>
    </item>
    <item>
      <title>ZeroPur: Succinct Training-Free Adversarial Purification</title>
      <link>https://arxiv.org/abs/2406.03143</link>
      <description>arXiv:2406.03143v3 Announce Type: replace-cross 
Abstract: Adversarial purification is a kind of defense technique that can defend against various unseen adversarial attacks without modifying the victim classifier. Existing methods often depend on external generative models or cooperation between auxiliary functions and victim classifiers. However, retraining generative models, auxiliary functions, or victim classifiers relies on the domain of the fine-tuned dataset and is computation-consuming. In this work, we suppose that adversarial images are outliers of the natural image manifold, and the purification process can be considered as returning them to this manifold. Following this assumption, we present a simple adversarial purification method without further training to purify adversarial images, called ZeroPur. ZeroPur contains two steps: given an adversarial example, Guided Shift obtains the shifted embedding of the adversarial example by the guidance of its blurred counterparts; after that, Adaptive Projection constructs a directional vector by this shifted embedding to provide momentum, projecting adversarial images onto the manifold adaptively. ZeroPur is independent of external models and requires no retraining of victim classifiers or auxiliary functions, relying solely on victim classifiers themselves to achieve purification. Extensive experiments on three datasets (CIFAR-10, CIFAR-100, and ImageNet-1K) using various classifier architectures (ResNet, WideResNet) demonstrate that our method achieves state-of-the-art robust performance. The code will be publicly available.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.03143v3</guid>
      <category>cs.CV</category>
      <category>cs.CR</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Erhu Liu, Zonglin Yang, Bo Liu, Bin Xiao, Xiuli Bi</dc:creator>
    </item>
    <item>
      <title>Securing Federated Learning against Backdoor Threats with Foundation Model Integration</title>
      <link>https://arxiv.org/abs/2410.17573</link>
      <description>arXiv:2410.17573v3 Announce Type: replace-cross 
Abstract: Federated Learning (FL) enables decentralized model training while preserving privacy. Recently, the integration of Foundation Models (FMs) into FL has enhanced performance but introduced a novel backdoor attack mechanism. Attackers can exploit FM vulnerabilities to embed backdoors into synthetic data generated by FMs. During global model fusion, these backdoors are transferred to the global model through compromised synthetic data, subsequently infecting all client models. Existing FL backdoor defenses are ineffective against this novel attack due to its fundamentally different mechanism compared to classic ones. In this work, we propose a novel data-free defense strategy that addresses both classic and novel backdoor attacks in FL. The shared attack pattern lies in the abnormal activations within the hidden feature space during model aggregation. Hence, we propose to constrain internal activations to remain within reasonable ranges, effectively mitigating attacks while preserving model functionality. The activation constraints are optimized using synthetic data alongside FL training. Extensive experiments demonstrate its effectiveness against both novel and classic backdoor attacks, outperforming existing defenses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.17573v3</guid>
      <category>cs.LG</category>
      <category>cs.CR</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaohuan Bi, Xi Li</dc:creator>
    </item>
    <item>
      <title>Fast, Secure, Adaptable: LionsOS Design, Implementation and Performance</title>
      <link>https://arxiv.org/abs/2501.06234</link>
      <description>arXiv:2501.06234v2 Announce Type: replace-cross 
Abstract: We present LionsOS, an operating system for security- and safety-critical embedded systems. LionsOS is based on the formally verified seL4 microkernel and designed with verification in mind. It uses a static architecture and features a highly modular design driven by strict separa- tion of concerns and a focus on simplicity. We demonstrate that LionsOS achieves excellent performance on system-call intensive workloads.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.06234v2</guid>
      <category>cs.OS</category>
      <category>cs.CR</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Gernot Heiser, Ivan Velickovic, Peter Chubb, Alwin Joshy, Anuraag Ganesh, Bill Nguyen, Cheng Li, Courtney Darville, Guangtao Zhu, James Archer, Jingyao Zhou, Krishnan Winter, Lucy Parker, Szymon Duchniewicz, Tianyi Bai</dc:creator>
    </item>
    <item>
      <title>ExpProof : Operationalizing Explanations for Confidential Models with ZKPs</title>
      <link>https://arxiv.org/abs/2502.03773</link>
      <description>arXiv:2502.03773v3 Announce Type: replace-cross 
Abstract: In principle, explanations are intended as a way to increase trust in machine learning models and are often obligated by regulations. However, many circumstances where these are demanded are adversarial in nature, meaning the involved parties have misaligned interests and are incentivized to manipulate explanations for their purpose. As a result, explainability methods fail to be operational in such settings despite the demand \cite{bordt2022post}. In this paper, we take a step towards operationalizing explanations in adversarial scenarios with Zero-Knowledge Proofs (ZKPs), a cryptographic primitive. Specifically we explore ZKP-amenable versions of the popular explainability algorithm LIME and evaluate their performance on Neural Networks and Random Forests. Our code is publicly available at https://github.com/emlaufer/ExpProof.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03773v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CR</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chhavi Yadav, Evan Monroe Laufer, Dan Boneh, Kamalika Chaudhuri</dc:creator>
    </item>
    <item>
      <title>Grassroots Consensus</title>
      <link>https://arxiv.org/abs/2505.19216</link>
      <description>arXiv:2505.19216v2 Announce Type: replace-cross 
Abstract: Grassroots platforms aim to offer an egalitarian alternative to global platforms -- centralized/autocratic and decentralized/plutocratic alike. Within the grassroots architecture, consensus is needed to realize platforms that employ digital social contracts, which are like smart contracts except that they are among people not accounts and are executed by these people's smartphones not by high-performance servers controlled by parties outside to the contract. Key envisioned grassroots platforms include sovereign democratic digital communities and federations, community banks and their grassroots cryptocurrencies, and digital cooperatives.
  The grassroots architecture can benefit from a consensus protocol that is (i) quiescent, (ii) efficient during low- and high-throughput, (iii) responsive, (iv) blocklace-based, (v) UDP-ready, and (vi) grassroots. The Grassroots Consensus protocol addresses all these requirements while having competitive performance in both low- and high-throughput scenarios and being one of the most concise and elegant consensus protocols for partial synchrony. It achieves that by building on two cutting-edge consensus protocols -- the quiescent high-performance Morpheus and the blocklace-based Cordial Miners, improving the latter's dissemination protocol and making it UDP-ready, and extending the protocol with a constitution and a constitutional amendment component, making it grassroots.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19216v2</guid>
      <category>cs.DC</category>
      <category>cs.CR</category>
      <category>cs.DS</category>
      <category>cs.NI</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Idit Keidar, Andrew Lewis-Pye, Ehud Shapiro</dc:creator>
    </item>
    <item>
      <title>Transformers in Protein: A Survey</title>
      <link>https://arxiv.org/abs/2505.20098</link>
      <description>arXiv:2505.20098v2 Announce Type: replace-cross 
Abstract: As protein informatics advances rapidly, the demand for enhanced predictive accuracy, structural analysis, and functional understanding has intensified. Transformer models, as powerful deep learning architectures, have demonstrated unprecedented potential in addressing diverse challenges across protein research. However, a comprehensive review of Transformer applications in this field remains lacking. This paper bridges this gap by surveying over 100 studies, offering an in-depth analysis of practical implementations and research progress of Transformers in protein-related tasks. Our review systematically covers critical domains, including protein structure prediction, function prediction, protein-protein interaction analysis, functional annotation, and drug discovery/target identification. To contextualize these advancements across various protein domains, we adopt a domain-oriented classification system. We first introduce foundational concepts: the Transformer architecture and attention mechanisms, categorize Transformer variants tailored for protein science, and summarize essential protein knowledge. For each research domain, we outline its objectives and background, critically evaluate prior methods and their limitations, and highlight transformative contributions enabled by Transformer models. We also curate and summarize pivotal datasets and open-source code resources to facilitate reproducibility and benchmarking. Finally, we discuss persistent challenges in applying Transformers to protein informatics and propose future research directions. This review aims to provide a consolidated foundation for the synergistic integration of Transformer and protein informatics, fostering further innovation and expanded applications in the field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20098v2</guid>
      <category>cs.LG</category>
      <category>cs.CR</category>
      <category>q-bio.QM</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaowen Ling, Zhiqiang Li, Yanbin Wang, Zhuhong You</dc:creator>
    </item>
    <item>
      <title>TrojanStego: Your Language Model Can Secretly Be A Steganographic Privacy Leaking Agent</title>
      <link>https://arxiv.org/abs/2505.20118</link>
      <description>arXiv:2505.20118v2 Announce Type: replace-cross 
Abstract: As large language models (LLMs) become integrated into sensitive workflows, concerns grow over their potential to leak confidential information. We propose TrojanStego, a novel threat model in which an adversary fine-tunes an LLM to embed sensitive context information into natural-looking outputs via linguistic steganography, without requiring explicit control over inference inputs. We introduce a taxonomy outlining risk factors for compromised LLMs, and use it to evaluate the risk profile of the threat. To implement TrojanStego, we propose a practical encoding scheme based on vocabulary partitioning learnable by LLMs via fine-tuning. Experimental results show that compromised models reliably transmit 32-bit secrets with 87% accuracy on held-out prompts, reaching over 97% accuracy using majority voting across three generations. Further, they maintain high utility, can evade human detection, and preserve coherence. These results highlight a new class of LLM data exfiltration attacks that are passive, covert, practical, and dangerous.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20118v2</guid>
      <category>cs.CL</category>
      <category>cs.CR</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Dominik Meier, Jan Philip Wahle, Paul R\"ottger, Terry Ruas, Bela Gipp</dc:creator>
    </item>
  </channel>
</rss>
