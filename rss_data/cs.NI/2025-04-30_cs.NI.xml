<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 30 Apr 2025 04:00:12 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 30 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Tree embedding based mapping system for low-latency mobile applications in multi-access networks</title>
      <link>https://arxiv.org/abs/2504.20246</link>
      <description>arXiv:2504.20246v1 Announce Type: new 
Abstract: Low-latency applications like AR/VR and online gaming need fast, stable connections. New technologies such as V2X, LEO satellites, and 6G bring unique challenges in mobility management. Traditional solutions based on centralized or distributed anchors often fall short in supporting rapid mobility due to inefficient routing, low versatility, and insufficient multi-access support. In this paper, we design a new end-to-end system for tracking multi-connected mobile devices at scale and optimizing performance for latency-sensitive, highly dynamic applications. Our system, based on the locator/ID separation principle, extends to multi-access networks without requiring specialized routers or caching. Using a novel tree embedding-based overlay, we enable fast session setup while allowing endpoints to directly handle mobility between them. Evaluation with real network data shows our solution cuts connection latency to 7.42% inflation over the shortest path, compared to LISP's 359\% due to cache misses. It also significantly reduces location update overhead and disruption time during mobility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.20246v1</guid>
      <category>cs.NI</category>
      <pubDate>Wed, 30 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yu Mi, Randeep Bhatia, Fang Hao, An Wang, Steve Benno, Tv Lakshman</dc:creator>
    </item>
    <item>
      <title>VA-CDH: A Variance-Aware Method to Optimize Latency for Caching with Delayed Hits</title>
      <link>https://arxiv.org/abs/2504.20335</link>
      <description>arXiv:2504.20335v1 Announce Type: new 
Abstract: Caches are fundamental to latency-sensitive systems like Content Delivery Networks (CDNs) and Mobile Edge Computing (MEC). However, the delayed hit phenomenon where multiple requests for an object occur during its fetch from the remote server after a miss significantly inflates user-perceived latency. While recent algorithms acknowledge delayed hits by estimating the resulting aggregate delay, they predominantly focus on its mean value. We identify and demonstrate that such approaches are insufficient, as the real aggregate delay frequently exhibits substantial variance in the true production system, leading to suboptimal latency performance when ignored. Thus, we propose VA-CDH, a variance-aware method to optimize latency for caching with delayed hits. It employs a novel ranking function that explicitly incorporates both the empirically estimated mean and standard deviation of aggregate delay, allowing caching decisions to account for its variation. We derive the analytical distribution of aggregate delay under Poisson arrivals as a theoretical contribution, offering more statistical insight beyond the mean value. Through the simulations conducted on synthetic and real-world datasets, we show that VA-CDH reduces the total latency by 1%-6% approximately compared to state-of-the-art algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.20335v1</guid>
      <category>cs.NI</category>
      <pubDate>Wed, 30 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bowen Jiang, Chaofan Ma, Duo Wang</dc:creator>
    </item>
    <item>
      <title>Fiber to the Room: Key Technologies, Challenges, and Prospects</title>
      <link>https://arxiv.org/abs/2504.20433</link>
      <description>arXiv:2504.20433v1 Announce Type: new 
Abstract: Fiber to the Room (FTTR) is a next-generation access network designed to deliver high bandwidth, low latency, and room-level optical coverage. This paper presents a comprehensive analysis of the FTTR system architecture and protocol stack, focusing on three key technical aspects: centralized scheduling and control, integrated management and maintenance, and green energy-saving mechanisms. A simplified FTTR architecture based on the convergence of the medium access control (MAC) and physical (PHY) layers is introduced to enhance coordination and scheduling efficiency. An extended remote management scheme, based on the optical network unit management and control interface (OMCI), is described to enable unified control across main fiber units (MFUs) and sub-fiber units (SFUs). Furthermore, a service-aware energy-saving framework is discussed for dynamic power optimization. The paper also explores the integration of artificial intelligence (AI) and passive sensing into FTTR systems to support intelligent scheduling, energy management, and environment-aware optimization. These insights provide technical guidance for the scalable deployment and future evolution of FTTR networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.20433v1</guid>
      <category>cs.NI</category>
      <pubDate>Wed, 30 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jinhan Cai, Xiaolong Zhang, Xiang Wang, Tianhai Chang, Gangxiang Shen</dc:creator>
    </item>
    <item>
      <title>WakeLoc: An Ultra-Low Power, Accurate and Scalable On-Demand RTLS using Wake-Up Radios</title>
      <link>https://arxiv.org/abs/2504.20545</link>
      <description>arXiv:2504.20545v1 Announce Type: new 
Abstract: For future large scale robotic moon missions, the availability of infrastructure-less, cheap and low power real-time locating systems (RTLSs) is critical. Traditional RTLS face significant trade-offs between power consumption and localization latency, often requiring anchors to be connected to the power grid or sacrificing speed for energy efficiency. This paper proposes WakeLoc, an on-demand RTLS based on ultra-wideband (UWB), enabling both low-latency and ultra-low power consumption by leveraging UWB wake-up radios (WuRs). In WakeLoc, tags independently start a localization procedure by sending a wake-up call (WuC) to anchors, before performing the actual localization. Distributed tags equipped with WuRs listen to the WuC and use passive listening of the UWB messages to determine their own position. Experimental measurements demonstrate that the localization accuracy in a 2D setup achieves less than 12.9cm error, both for the active and the passive tag. Additional power simulations based on real-world measurements were performed in a realistic environment, showing that anchors can achieve a power consumption as low as 15.53{\mu}W while the RTLS performs one on-demand localization per minute for 5 tags, thus operate up to 5.01 years on a single coin cell battery (690mWh).</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.20545v1</guid>
      <category>cs.NI</category>
      <pubDate>Wed, 30 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Silvano Cortesi, Christian Vogt, Michele Magno</dc:creator>
    </item>
    <item>
      <title>Handling Large-Scale Network Flow Records: A Comparative Study on Lossy Compression</title>
      <link>https://arxiv.org/abs/2504.20729</link>
      <description>arXiv:2504.20729v1 Announce Type: new 
Abstract: Flow records, that summarize the characteristics of traffic flows, represent a practical and powerful way to monitor a network. While they already offer significant compression compared to full packet captures, their sheer volume remains daunting, especially for large Internet Service Providers (ISPs). In this paper, we investigate several lossy compression techniques to further reduce storage requirements while preserving the utility of flow records for key tasks, such as predicting the domain name of contacted servers. Our study evaluates scalar quantization, Principal Component Analysis (PCA), and vector quantization, applied to a real-world dataset from an operational campus network. Results reveal that scalar quantization provides the best tradeoff between compression and accuracy. PCA can preserve predictive accuracy but hampers subsequent entropic compression, and while vector quantization shows promise, it struggles with scalability due to the high-dimensional nature of the data. These findings result in practical strategies for optimizing flow record storage in large-scale monitoring scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.20729v1</guid>
      <category>cs.NI</category>
      <pubDate>Wed, 30 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gabriele Merlach, Damiano Ravalico, Martino Trevisan, Fabio Palmese, Giovanni Baccichet, Alessandro E. C. Redondi</dc:creator>
    </item>
    <item>
      <title>Towards Easy and Realistic Network Infrastructure Testing for Large-scale Machine Learning</title>
      <link>https://arxiv.org/abs/2504.20854</link>
      <description>arXiv:2504.20854v1 Announce Type: new 
Abstract: This paper lays the foundation for Genie, a testing framework that captures the impact of real hardware network behavior on ML workload performance, without requiring expensive GPUs. Genie uses CPU-initiated traffic over a hardware testbed to emulate GPU to GPU communication, and adapts the ASTRA-sim simulator to model interaction between the network and the ML workload.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.20854v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.DC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 30 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jinsun Yoo, ChonLam Lao, Lianjie Cao, Bob Lantz, Minlan Yu, Tushar Krishna, Puneet Sharma</dc:creator>
    </item>
    <item>
      <title>Flexible Semantic-Aware Resource Allocation: Serving More Users Through Similarity Range Constraints</title>
      <link>https://arxiv.org/abs/2504.20939</link>
      <description>arXiv:2504.20939v1 Announce Type: new 
Abstract: Semantic communication (SemCom) aims to enhance the resource efficiency of next-generation networks by transmitting the underlying meaning of messages, focusing on information relevant to the end user. Existing literature on SemCom primarily emphasizes learning the encoder and decoder through end-to-end deep learning frameworks, with the objective of minimizing a task-specific semantic loss function. Beyond its influence on the physical and application layer design, semantic variability across users in multi-user systems enables the design of resource allocation schemes that incorporate user-specific semantic requirements. To this end, \emph{a semantic-aware resource allocation} scheme is proposed with the objective of maximizing transmission and semantic reliability, ultimately increasing the number of users whose semantic requirements are met. The resulting resource allocation problem is a non-convex mixed-integer nonlinear program (MINLP), which is known to be NP-hard. To make the problem tractable, it is decomposed into a set of sub-problems, each of which is efficiently solved via geometric programming techniques. Finally, simulations demonstrate that the proposed method improves user satisfaction by up to $17.1\%$ compared to state of the art methods based on quality of experience-aware SemCom methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.20939v1</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Wed, 30 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nasrin Gholami, Neda Moghim, Behrouz Shahgholi Ghahfarokhi, Pouyan Salavati, Christo Kurisummoottil Thomas, Sachin Shetty, Tahereh Rahmati</dc:creator>
    </item>
    <item>
      <title>Network-Aware Scheduling for Remote Gate Execution in Quantum Data Centers</title>
      <link>https://arxiv.org/abs/2504.20176</link>
      <description>arXiv:2504.20176v1 Announce Type: cross 
Abstract: Modular quantum computing provides a scalable approach to overcome the limitations of monolithic quantum architectures by interconnecting multiple Quantum Processing Units (QPUs) through a quantum network. In this work, we explore and evaluate two entanglement scheduling strategies-static and dynamic-and analyze their performance in terms of circuit execution delay and network resource utilization under realistic assumptions and practical limitations such as probabilistic entanglement generation, limited communication qubits, photonic switch reconfiguration delays, and topology-induced contention. We show that dynamic scheduling consistently outperforms static scheduling in scenarios with high entanglement parallelism, especially when network resources are scarce. Furthermore, we investigate the impact of communication qubit coherence time, modeled as a cutoff for holding EPR pairs, and demonstrate that aggressive lookahead strategies can degrade performance when coherence times are short, due to premature entanglement discarding and wasted resources. We also identify congestion-free BSM provisioning by profiling peak BSM usage per switch. Our results provide actionable insights for scheduler design and resource provisioning in realistic quantum data centers, bringing system-level considerations closer to practical quantum computing deployment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.20176v1</guid>
      <category>quant-ph</category>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <category>cs.PF</category>
      <pubDate>Wed, 30 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shahrooz Pouryousef, Reza Nejabati, Don Towsley, Ramana Kompella, Eneet Kaur</dc:creator>
    </item>
    <item>
      <title>A Virtual Cybersecurity Department for Securing Digital Twins in Water Distribution Systems</title>
      <link>https://arxiv.org/abs/2504.20266</link>
      <description>arXiv:2504.20266v1 Announce Type: cross 
Abstract: Digital twins (DTs) help improve real-time monitoring and decision-making in water distribution systems. However, their connectivity makes them easy targets for cyberattacks such as scanning, denial-of-service (DoS), and unauthorized access. Small and medium-sized enterprises (SMEs) that manage these systems often do not have enough budget or staff to build strong cybersecurity teams. To solve this problem, we present a Virtual Cybersecurity Department (VCD), an affordable and automated framework designed for SMEs. The VCD uses open-source tools like Zabbix for real-time monitoring, Suricata for network intrusion detection, Fail2Ban to block repeated login attempts, and simple firewall settings. To improve threat detection, we also add a machine-learning-based IDS trained on the OD-IDS2022 dataset using an improved ensemble model. This model detects cyber threats such as brute-force attacks, remote code execution (RCE), and network flooding, with 92\% accuracy and fewer false alarms. Our solution gives SMEs a practical and efficient way to secure water systems using low-cost and easy-to-manage tools.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.20266v1</guid>
      <category>cs.CR</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <pubDate>Wed, 30 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Mohammadhossein Homaei, Agustin Di Bartolo, Oscar Mogollon-Gutierrez, Fernando Broncano Morgado, Pablo Garcia Rodriguez</dc:creator>
    </item>
    <item>
      <title>did:self A registry-less DID method</title>
      <link>https://arxiv.org/abs/2504.20767</link>
      <description>arXiv:2504.20767v1 Announce Type: cross 
Abstract: We introduce did:self, a Decentralized Identifier (DID) method that does not depend on any trusted registry for storing the corresponding DID documents. Information for authenticating a did:self subject can be disseminated using any means and without making any security assumption about the delivery method. did:self is lightweight, it allows controlled delegation, it offers increased security and privacy, and it can be used for identifying people, content, as well as IoT devices. Furthermore, DID documents in did:self can be implicit, allowing re-construction of DID documents based on other authentication material, such as JSON Web Tokens and X.509 certificates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.20767v1</guid>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <pubDate>Wed, 30 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nikos Fotiou, George C. Polyzos, Vasilios A. Siris</dc:creator>
    </item>
    <item>
      <title>Optimal In-Network Distribution of Learning Functions for a Secure-by-Design Programmable Data Plane of Next-Generation Networks</title>
      <link>https://arxiv.org/abs/2411.18384</link>
      <description>arXiv:2411.18384v2 Announce Type: replace 
Abstract: The rise of programmable data plane (PDP) and in-network computing (INC) paradigms paves the way for the development of network devices (switches, network interface cards, etc.) capable of performing advanced processing tasks. This allows running various types of algorithms, including machine learning, within the network itself to support user and network services. In particular, this paper delves into the deployment of in-network learning models with the aim of implementing fully distributed intrusion detection systems (IDS) or intrusion prevention systems (IPS). Specifically, a model is proposed for the optimal distribution of the IDS/IPS workload among data plane devices with the aim of ensuring complete network security without excessively burdening the normal operations of the devices. Furthermore, a meta-heuristic approach is proposed to reduce the long computation time required by the exact solution provided by the mathematical model and its performance is evaluated. The analysis conducted and the results obtained demonstrate the enormous potential of the proposed new approach for the creation of intelligent data planes that act effectively and autonomously as the first line of defense against cyber attacks, with minimal additional workload on the network devices involved.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.18384v2</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Wed, 30 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mattia Giovanni Spina, Edoardo Scalzo, Floriano De Rango, Francesca Guerriero, Antonio Iera</dc:creator>
    </item>
    <item>
      <title>Task-Oriented Communications for Visual Navigation with Edge-Aerial Collaboration in Low Altitude Economy</title>
      <link>https://arxiv.org/abs/2504.18317</link>
      <description>arXiv:2504.18317v2 Announce Type: replace-cross 
Abstract: To support the Low Altitude Economy (LAE), precise unmanned aerial vehicles (UAVs) localization in urban areas where global positioning system (GPS) signals are unavailable. Vision-based methods offer a viable alternative but face severe bandwidth, memory and processing constraints on lightweight UAVs. Inspired by mammalian spatial cognition, we propose a task-oriented communication framework, where UAVs equipped with multi-camera systems extract compact multi-view features and offload localization tasks to edge servers. We introduce the Orthogonally-constrained Variational Information Bottleneck encoder (O-VIB), which incorporates automatic relevance determination (ARD) to prune non-informative features while enforcing orthogonality to minimize redundancy. This enables efficient and accurate localization with minimal transmission cost. Extensive evaluation on a dedicated LAE UAV dataset shows that O-VIB achieves high-precision localization under stringent bandwidth budgets. Code and dataset will be made publicly available: github.com/fangzr/TOC-Edge-Aerial.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.18317v2</guid>
      <category>cs.CV</category>
      <category>cs.NI</category>
      <pubDate>Wed, 30 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhengru Fang, Zhenghao Liu, Jingjing Wang, Senkang Hu, Yu Guo, Yiqin Deng, Yuguang Fang</dc:creator>
    </item>
  </channel>
</rss>
