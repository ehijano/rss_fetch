<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.AP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.AP</link>
    <description>stat.AP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.AP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 27 Jun 2025 04:00:13 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Estimating the Number of Opioid Overdoses in British Columbia Using Relational Evidence with Tree Structure</title>
      <link>https://arxiv.org/abs/2506.21024</link>
      <description>arXiv:2506.21024v1 Announce Type: new 
Abstract: In many fields, populations of interest are hidden from data for a variety of reasons, though their magnitude remains important in determining resource allocation and appropriate policy. In public health and epidemiology, linkages or relationships between sources of data may exist due to intake structure of care providers, referrals, or other related health programming. These relationships often admit a tree structure, with the target population represented by the root, and paths from root-to-leaf representing pathways of care after a health event. In the Canadian province of British Columbia (BC), significant efforts have been made in creating an opioid overdose cohort, a tree-like linked data structure which tracks the movement of individuals along pathways of care after an overdose. In this application, the root node represents the target population, the total number of overdose events occurring in BC during the specified time period. We compare and contrast two methods of estimating the target population size - a weighted multiplier method based on back-calculating estimates from a number of paths and combining these estimates via a variance-minimizing weighted mean, and a fully Bayesian hierarchical model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.21024v1</guid>
      <category>stat.AP</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mallory J Flynn, Paul Gustafson, Michael A. Irvine</dc:creator>
    </item>
    <item>
      <title>Latent-space Field Tension for Astrophysical Component Detection An application to X-ray imaging</title>
      <link>https://arxiv.org/abs/2506.20758</link>
      <description>arXiv:2506.20758v1 Announce Type: cross 
Abstract: Modern observatories are designed to deliver increasingly detailed views of astrophysical signals. To fully realize the potential of these observations, principled data-analysis methods are required to effectively separate and reconstruct the underlying astrophysical components from data corrupted by noise and instrumental effects. In this work, we introduce a novel multi-frequency Bayesian model of the sky emission field that leverages latent-space tension as an indicator of model misspecification, enabling automated separation of diffuse, point-like, and extended astrophysical emission components across wavelength bands. Deviations from latent-space prior expectations are used as diagnostics for model misspecification, thus systematically guiding the introduction of new sky components, such as point-like and extended sources. We demonstrate the effectiveness of this method on synthetic multi-frequency imaging data and apply it to observational X-ray data from the eROSITA Early Data Release (EDR) of the SN1987A region in the Large Magellanic Cloud (LMC). Our results highlight the method's capability to reconstruct astrophysical components with high accuracy, achieving sub-pixel localization of point sources, robust separation of extended emission, and detailed uncertainty quantification. The developed methodology offers a general and well-founded framework applicable to a wide variety of astronomical datasets, and is therefore well suited to support the analysis needs of next-generation multi-wavelength and multi-messenger surveys.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.20758v1</guid>
      <category>astro-ph.IM</category>
      <category>astro-ph.HE</category>
      <category>stat.AP</category>
      <category>stat.ML</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matteo Guardiani, Vincent Eberle, Margret Westerkamp, Julian R\"ustig, Philipp Frank, Torsten En{\ss}lin</dc:creator>
    </item>
    <item>
      <title>Efficacy of Temporal Fusion Transformers for Runoff Simulation</title>
      <link>https://arxiv.org/abs/2506.20831</link>
      <description>arXiv:2506.20831v1 Announce Type: cross 
Abstract: Combining attention with recurrence has shown to be valuable in sequence modeling, including hydrological predictions. Here, we explore the strength of Temporal Fusion Transformers (TFTs) over Long Short-Term Memory (LSTM) networks in rainfall-runoff modeling. We train ten randomly initialized models, TFT and LSTM, for 531 CAMELS catchments in the US. We repeat the experiment with five subsets of the Caravan dataset, each representing catchments in the US, Australia, Brazil, Great Britain, and Chile. Then, the performance of the models, their variability regarding the catchment attributes, and the difference according to the datasets are assessed. Our findings show that TFT slightly outperforms LSTM, especially in simulating the midsection and peak of hydrographs. Furthermore, we show the ability of TFT to handle longer sequences and why it can be a better candidate for higher or larger catchments. Being an explainable AI technique, TFT identifies the key dynamic and static variables, providing valuable scientific insights. However, both TFT and LSTM exhibit a considerable drop in performance with the Caravan dataset, indicating possible data quality issues. Overall, the study highlights the potential of TFT in improving hydrological modeling and understanding.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.20831v1</guid>
      <category>physics.geo-ph</category>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sinan Rasiya Koya, Tirthankar Roy</dc:creator>
    </item>
    <item>
      <title>A Bayesian Nonparametric Approach for Semi-Competing Risks with Application to Cardiovascular Health</title>
      <link>https://arxiv.org/abs/2506.20860</link>
      <description>arXiv:2506.20860v1 Announce Type: cross 
Abstract: We address causal estimation in semi-competing risks settings, where a non-terminal event may be precluded by one or more terminal events. We define a principal-stratification causal estimand for treatment effects on the non-terminal event, conditional on surviving past a specified landmark time. To estimate joint event-time distributions, we employ both vine-copula constructions and Bayesian nonparametric Enriched Dirichlet-process mixtures (EDPM), enabling inference under minimal parametric assumptions. We index our causal assumptions with sensitivity parameters. Posterior summaries via MCMC yield interpretable estimates with credible intervals. We illustrate the proposed method using data from a cardiovascular health study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.20860v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Karina Gelis-Cadena, Michael Daniels, Juned Siddique</dc:creator>
    </item>
    <item>
      <title>Forecasting Geopolitical Events with a Sparse Temporal Fusion Transformer and Gaussian Process Hybrid: A Case Study in Middle Eastern and U.S. Conflict Dynamics</title>
      <link>https://arxiv.org/abs/2506.20935</link>
      <description>arXiv:2506.20935v1 Announce Type: cross 
Abstract: Forecasting geopolitical conflict from data sources like the Global Database of Events, Language, and Tone (GDELT) is a critical challenge for national security. The inherent sparsity, burstiness, and overdispersion of such data cause standard deep learning models, including the Temporal Fusion Transformer (TFT), to produce unreliable long-horizon predictions. We introduce STFT-VNNGP, a hybrid architecture that won the 2023 Algorithms for Threat Detection (ATD) competition by overcoming these limitations. Designed to bridge this gap, our model employs a two-stage process: first, a TFT captures complex temporal dynamics to generate multi-quantile forecasts. These quantiles then serve as informed inputs for a Variational Nearest Neighbor Gaussian Process (VNNGP), which performs principled spatiotemporal smoothing and uncertainty quantification. In a case study forecasting conflict dynamics in the Middle East and the U.S., STFT-VNNGP consistently outperforms a standalone TFT, showing a superior ability to predict the timing and magnitude of bursty event periods, particularly at long-range horizons. This work offers a robust framework for generating more reliable and actionable intelligence from challenging event data, with all code and workflows made publicly available to ensure reproducibility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.20935v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hsin-Hsiung Huang, Hayden Hampton</dc:creator>
    </item>
    <item>
      <title>Simultaneous estimation of the effective reproduction number and the time series of daily infections: Application to Covid-19</title>
      <link>https://arxiv.org/abs/2506.21027</link>
      <description>arXiv:2506.21027v1 Announce Type: cross 
Abstract: The time varying effective reproduction number is an important parameter for communication and policy decisions during an epidemic. It is difficult to estimate because it depends on latent variables such as new infections and other characteristics of an epidemic which have to be inferred from available data. In this paper, we present new statistical methods for a popular model which defines the effective reproduction number based on self-exciting dynamics of new infections. Such a model is conceptually simple and less susceptible to misspecifications than more complicated multi-compartment models. In contrast to the state-of-the-art three-step estimation procedure of \citet{huisman2022estimation}, we present a coherent Bayesian method that approximates the joint posterior of daily new infections and reproduction numbers given the data using a novel Markov chain Monte Carlo (MCMC) algorithm. Comparing our method with that of \citet{huisman2022estimation}, both with daily confirmed cases from Switzerland in the Covid-19 epidemic and with simulated data, we find that our method is more accurate, especially near the beginning and end of the observation period.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.21027v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Hans R. K\"unsch, Fabio Sigrist</dc:creator>
    </item>
    <item>
      <title>Bayesian Modeling for Aggregated Relational Data: A Unified Perspective</title>
      <link>https://arxiv.org/abs/2506.21353</link>
      <description>arXiv:2506.21353v1 Announce Type: cross 
Abstract: Aggregated relational data is widely collected to study social network theory. It has been used to address a variety of key problems in fields such as sociology, public health and economics. ARD models enable researchers to estimate the size of hidden populations, estimate personal network sizes, understand global network structures and fit complex latent variable models to massive network data. Many of the successes of ARD models have been driven by the utilisation of Bayesian modeling, which provides a principled and flexible way to fit and interpret these models for real data. In this work we create a coherent collection of Bayesian implementations of existing models for ARD, within the state of the art Bayesian sampling language, Stan. Our implementations incorporate within-iteration rescaling procedures by default, eliminating the typical post-processing step and improving algorithm run time and convergence diagnostics. Bayesian modelling permits natural tools for model criticism and comparison, which is largely unexplored in the ARD setting. Using synthetic data, we demonstrate how well competing models recover true personal network sizes and subpopulation sizes and how well existing posterior predictive checks compare across a range of Bayesian ARD models. We implement and provide code to leverage Stan's modelling framework for leave-one-out cross-validation, which has not previously been examined for ARD models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.21353v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Owen G. Ward, Anna L. Smith, Tian Zheng</dc:creator>
    </item>
    <item>
      <title>Gender disparities in rehospitalisations after coronary artery bypass grafting: evidence from a sparse functional causal mediation analysis of the MIMIC-IV data</title>
      <link>https://arxiv.org/abs/2410.22502</link>
      <description>arXiv:2410.22502v2 Announce Type: replace 
Abstract: Hospital readmissions following coronary artery bypass grafting (CABG) not only impose a substantial cost burden on healthcare systems but also serve as a potential indicator of the quality of medical care. Previous studies of gender effects on complications after CABG surgery have consistently revealed that women tend to suffer worse outcomes. To better understand the causal pathway from gender to the number of rehospitalisations, we study the postoperative central venous pressure (CVP), recorded over the first 24 hours of patients' intensive care unit (ICU) stay after the CABG surgery, as sparse observations of a functional mediator. Confronted with time-varying CVP measurements and zero-inflated rehospitalisation counts within 60 days following discharge, we propose a parameter-simulating quasi-Bayesian Monte Carlo approximation method that accommodates a sparse functional mediator and a zero-inflated count outcome for causal mediation analysis. We find a causal relationship between the female gender and increased rehospitalisation counts after CABG, and that time-varying central venous pressure mediates this causal effect.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.22502v2</guid>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Henan Xu, Yeying Zhu, Donna L. Coffman</dc:creator>
    </item>
    <item>
      <title>A Scalable Bayesian Spatiotemporal Model for Water Level Predictions using a Nearest Neighbor Gaussian Process Approach</title>
      <link>https://arxiv.org/abs/2412.06934</link>
      <description>arXiv:2412.06934v2 Announce Type: replace 
Abstract: Obtaining accurate water level predictions are essential for water resource management and implementing flood mitigation strategies. Several data-driven models can be found in the literature. However, there has been limited research with regard to addressing the challenges posed by large spatio-temporally referenced hydrological datasets, in particular, the challenges of maintaining predictive performance and uncertainty quantification. Gaussian Processes (GPs) are commonly used to capture complex space-time interactions. However, GPs are computationally expensive and suffer from poor scaling as the number of locations increases due to required covariance matrix inversions. To overcome the computational bottleneck, the Nearest Neighbor Gaussian Process (NNGP) introduces a sparse precision matrix providing scalability without having to make inferential compromises. In this work we introduce an innovative model in the hydrology field, specifically designed to handle large datasets consisting of a large number of spatial points across multiple hydrological basins, with daily observations over an extended period. We investigate the application of a Bayesian spatiotemporal NNGP model to a rich dataset of daily water levels of rivers located in Ireland. The dataset comprises a network of 301 stations situated in various basins across Ireland, measured over a period of 90 days. The proposed approach allows for prediction of water levels at future time points, as well as the prediction of water levels at unobserved locations through spatial interpolation, while maintaining the benefits of the Bayesian approach, such as uncertainty propagation and quantification. Our findings demonstrate that the proposed model outperforms competing approaches in terms of accuracy and precision.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06934v2</guid>
      <category>stat.AP</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Victor Hugo Nagahama, James Sweeney, Niamh Cahill</dc:creator>
    </item>
    <item>
      <title>Club Exco: clustering brain extreme communities from multi-channel EEG data</title>
      <link>https://arxiv.org/abs/2212.04338</link>
      <description>arXiv:2212.04338v2 Announce Type: replace-cross 
Abstract: Current methods for clustering brain networks over time often rely on cross-dependence measures computed from the entire range of EEG signals, which can obscure information specific to extreme neural activity. To overcome this, we introduce Club Exco, a novel clustering method grounded in extreme value theory, designed to detect brain communities with co-occurring high-amplitude EEG events. By focusing on tail behavior, Club Exco isolates extreme-value synchrony across channels, offering new insights into seizure dynamics. We apply Club Exco to neonatal EEG recordings from 30 patients (13 seizure-free and 17 with clinically confirmed seizures). Our method identifies robust ``brain extreme communities'' and constructs Extreme Connectivity Persistence matrices that summarize how often channels exhibit synchronous extremes across time. Seizure patients exhibit more persistent and variable clustering among non-adjacent regions, suggesting seizure propagation, while non-seizure patients show more consistent clustering in anatomically adjacent regions. Compared to coherence-based methods (e.g., Hierarchical Cluster Coherence procedure), Club Exco captures distinct, seizure-associated connectivity patterns, especially in high-amplitude segments. These results highlight Club Exco's potential to characterize extreme neural events and inform clinical understanding of seizure localization and spread.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.04338v2</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matheus B. Guerrero, Paolo V. Redondo, Marco A. Pinto-Orellana, Beth A. Lopour, Hernando Ombao, Rapha\"el Huser</dc:creator>
    </item>
    <item>
      <title>We must re-evaluate assumptions about carbon trading for effective climate change mitigation</title>
      <link>https://arxiv.org/abs/2411.08053</link>
      <description>arXiv:2411.08053v2 Announce Type: replace-cross 
Abstract: Effective climate action depends on dismantling the assumptions and oversimplifications that have become the basis of climate policy. The assumption that greenhouse gases (GHG) are fungible and the use of single-point values in normalizing GHG species to CO2-equivalents can propagate inaccuracies in carbon accounting and have already led to failures of carbon offset systems. Separate emission reduction targets and tracking by GHG species are recommended to achieve long-term climate stabilization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08053v2</guid>
      <category>econ.GN</category>
      <category>physics.ao-ph</category>
      <category>q-fin.EC</category>
      <category>stat.AP</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Alyssa R. Pfadt-Trilling, Marie-Odile P. Fortier</dc:creator>
    </item>
    <item>
      <title>Triadic Novelty: A Typology and Measurement Framework for Recognizing Novel Contributions in Science</title>
      <link>https://arxiv.org/abs/2506.17851</link>
      <description>arXiv:2506.17851v2 Announce Type: replace-cross 
Abstract: Scientific progress depends on novel ideas, but current reward systems often fail to recognize them. Many existing metrics conflate novelty with popularity, privileging ideas that fit existing paradigms over those that challenge them. This study develops a theory-driven framework to better understand how different types of novelty emerge, take hold, and receive recognition. Drawing on network science and theories of discovery, we introduce a triadic typology: Pioneers, who introduce entirely new topics; Mavericks, who recombine distant concepts; and Vanguards, who reinforce weak but promising connections. We apply this typology to a dataset of 41,623 articles in the interdisciplinary field of philanthropy and nonprofit studies, linking novelty types to five-year citation counts using mixed-effects negative binomial regression. Results show that novelty is not uniformly rewarded. Pioneer efforts are foundational but often overlooked. Maverick novelty shows consistent citation benefits, particularly rewarded when it displaces prior focus. Vanguard novelty is more likely to gain recognition when it strengthens weakly connected topics, but its citation advantage diminishes as those reinforced nodes become more central. To enable fair comparison across time and domains, we introduce a simulated baseline model. These findings improve the evaluation of innovations, affecting science policy, funding, and institutional assessment practices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.17851v2</guid>
      <category>physics.soc-ph</category>
      <category>cs.CY</category>
      <category>cs.SI</category>
      <category>stat.AP</category>
      <pubDate>Fri, 27 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jin Ai, Richard S. Steinberg, Chao Guo, Filipi Nascimento Silva</dc:creator>
    </item>
  </channel>
</rss>
