<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CY updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CY</link>
    <description>cs.CY updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CY" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 15 Dec 2025 05:00:15 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 15 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Stabilising Learner Trajectories: A Doubly Robust Evaluation of AI-Guided Student Support using Activity Theory</title>
      <link>https://arxiv.org/abs/2512.11154</link>
      <description>arXiv:2512.11154v1 Announce Type: new 
Abstract: While predictive models are increasingly common in higher education, causal evidence regarding the interventions they trigger remains rare. This study evaluates an AI-guided student support system at a large university using doubly robust propensity score matching. We advance the methodology for learning analytics evaluation by leveraging time-aligned, dynamic AI probability of success scores to match 1,859 treated students to controls, thereby mitigating the selection and immortal time biases often overlooked in observational studies. Results indicate that the intervention effectively stabilised precarious trajectories, and compared to the control group, supported students significantly reduced their course failure rates and achieved higher cumulative grades. However, effects on the speed of qualification completion were positive but statistically constrained. We interpreted these findings through Activity Theory, framing the intervention as a socio-technical brake that interrupts and slows the accumulation of academic failure among at-risk students. The student support-AI configuration successfully resolved the primary contradiction of immediate academic risk, but secondary contradictions within institutional structures limited the acceleration of degree completion. We conclude that while AI-enabled support effectively arrests decline, translating this stability into faster progression requires aligning intervention strategies with broader institutional governance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.11154v1</guid>
      <category>cs.CY</category>
      <pubDate>Mon, 15 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Teo Susnjak, Khalid Bakhshov, Anuradha Mathrani</dc:creator>
    </item>
    <item>
      <title>Personalized Pricing in Social Networks with Individual and Group Fairness Considerations</title>
      <link>https://arxiv.org/abs/2512.11252</link>
      <description>arXiv:2512.11252v1 Announce Type: new 
Abstract: Personalized pricing assigns different prices to customers for the same product based on customer-specific features to improve retailer revenue. However, this practice often raises concerns about fairness at both the individual and group levels. At the individual level, a customer may perceive unfair treatment if he/she notices being charged a higher price than others. At the group level, pricing disparities can result in discrimination against certain protected groups, such as those defined by gender or race. Existing studies on fair pricing typically address individual and group fairness separately. This paper bridges the gap by introducing a new formulation of the personalized pricing problem that incorporates both dimensions of fairness in social network settings. To solve the problem, we propose FairPricing, a novel framework based on graph neural networks (GNNs) that learns a personalized pricing policy using customer features and network topology. In FairPricing, individual perceived unfairness is captured through a penalty on customer demand, and thus the profit objective, while group-level discrimination is mitigated using adversarial debiasing and a price regularization term. Unlike existing optimization-based personalized pricing, which requires re-optimization whenever the network updates, the pricing policy learned by FairPricing assigns personalized prices to all customers in an updated network based on their features and the new network structure, thereby generalizing to network changes. Extensive experimental results show that FairPricing achieves high profitability while improving individual fairness perceptions and satisfying group fairness requirements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.11252v1</guid>
      <category>cs.CY</category>
      <category>cs.SI</category>
      <pubDate>Mon, 15 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zeyu Chen, Bintong Chen, Wei Qian, Jing Huang</dc:creator>
    </item>
    <item>
      <title>The Right Kind of Help: Evaluating the Effectiveness of Intervention Methods in Elementary-Level Visual Programming</title>
      <link>https://arxiv.org/abs/2512.11735</link>
      <description>arXiv:2512.11735v1 Announce Type: new 
Abstract: Prior work has explored various intervention methods for elementary programming. However, the relative impact of these methods during the learning and post-learning phases remains unclear. In this work, we present a large-scale study comparing the effectiveness of various intervention methods in elementary programming both during learning and on novel tasks post-learning. Specifically, we compare three intervention methods: code-edit recommendations (Code-Rec), quizzes based on code edits (Code-Quiz), and quizzes based on metacognitive strategies (Plan-Quiz), along with a no-intervention control (group None). A total of 398 students (across grades 4-7) participated in a two-phase study: learning phase comprising write-code tasks from the Hour of Code: Maze Challenge with the intervention, followed by a post-learning phase comprising more advanced write-code tasks without any intervention. All intervention methods significantly improved learning performance over the control group while preserving students' problem-solving skills in the post-learning phase. Quiz-based methods further improved performance on novel post-learning tasks. Students in intervention groups also reported greater engagement and perceived skill growth.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.11735v1</guid>
      <category>cs.CY</category>
      <pubDate>Mon, 15 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ahana Ghosh, Liina Malva, Alkis Gotovos, Danial Hooshyar, Adish Singla</dc:creator>
    </item>
    <item>
      <title>Applying NLP to iMessages: Understanding Topic Avoidance, Responsiveness, and Sentiment</title>
      <link>https://arxiv.org/abs/2512.11079</link>
      <description>arXiv:2512.11079v1 Announce Type: cross 
Abstract: What is your messaging data used for? While many users do not often think about the information companies can gather based off of their messaging platform of choice, it is nonetheless important to consider as society increasingly relies on short-form electronic communication. While most companies keep their data closely guarded, inaccessible to users or potential hackers, Apple has opened a door to their walled-garden ecosystem, providing iMessage users on Mac with one file storing all their messages and attached metadata. With knowledge of this locally stored file, the question now becomes: What can our data do for us? In the creation of our iMessage text message analyzer, we set out to answer five main research questions focusing on topic modeling, response times, reluctance scoring, and sentiment analysis. This paper uses our exploratory data to show how these questions can be answered using our analyzer and its potential in future studies on iMessage data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.11079v1</guid>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <category>stat.AP</category>
      <category>stat.OT</category>
      <pubDate>Mon, 15 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alan Gerber, Sam Cooperman</dc:creator>
    </item>
    <item>
      <title>Cybersecurity policy adoption in South Africa: Does public trust matter?</title>
      <link>https://arxiv.org/abs/2512.11122</link>
      <description>arXiv:2512.11122v1 Announce Type: cross 
Abstract: This study examines how public perception influences the implementation and adoption of cybersecurity frameworks in South Africa. Using the PRISMA methodology, a systematic literature review was conducted across reputable scholarly databases, yielding 34 relevant sources aligned with predefined inclusion criteria. Cybersecurity, governance, trust, privacy, cybercrime, and public opinion emerged as dominant thematic clusters. Bibliometric and thematic analyses, supported by network visualisations, revealed that while trust and public sentiment affect cybersecurity policy adoption globally, these factors have minimal influence within the South African policy landscape, despite the country's high cybercrime prevalence. In response, the study proposes a trust-centric policymaking framework designed to integrate public perception as a proactive dimension of cybersecurity governance. This framework seeks to prevent trust deficits from obstructing policy effectiveness and provides guidance for restoring trust where it has eroded.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.11122v1</guid>
      <category>cs.CR</category>
      <category>cs.CY</category>
      <pubDate>Mon, 15 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Mbali Nkosi, Mike Nkongolo</dc:creator>
    </item>
    <item>
      <title>Mining Legal Arguments to Study Judicial Formalism</title>
      <link>https://arxiv.org/abs/2512.11374</link>
      <description>arXiv:2512.11374v1 Announce Type: cross 
Abstract: Courts must justify their decisions, but systematically analyzing judicial reasoning at scale remains difficult. This study refutes claims about formalistic judging in Central and Eastern Europe (CEE) by developing automated methods to detect and classify judicial reasoning in Czech Supreme Courts' decisions using state-of-the-art natural language processing methods. We create the MADON dataset of 272 decisions from two Czech Supreme Courts with expert annotations of 9,183 paragraphs with eight argument types and holistic formalism labels for supervised training and evaluation. Using a corpus of 300k Czech court decisions, we adapt transformer LLMs for Czech legal domain by continued pretraining and experiment with methods to address dataset imbalance including asymmetric loss and class weighting. The best models successfully detect argumentative paragraphs (82.6\% macro-F1), classify traditional types of legal argument (77.5\% macro-F1), and classify decisions as formalistic/non-formalistic (83.2\% macro-F1). Our three-stage pipeline combining ModernBERT, Llama 3.1, and traditional feature-based machine learning achieves promising results for decision classification while reducing computational costs and increasing explainability. Empirically, we challenge prevailing narratives about CEE formalism. This work shows that legal argument mining enables reliable judicial philosophy classification and shows the potential of legal argument mining for other important tasks in computational legal studies. Our methodology is easily replicable across jurisdictions, and our entire pipeline, datasets, guidelines, models, and source codes are available at https://github.com/trusthlt/madon.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.11374v1</guid>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <pubDate>Mon, 15 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tom\'a\v{s} Koref, Lena Held, Mahammad Namazov, Harun Kumru, Yassine Thlija, Christoph Burchard, Ivan Habernal</dc:creator>
    </item>
    <item>
      <title>General-purpose AI models can generate actionable knowledge on agroecological crop protection</title>
      <link>https://arxiv.org/abs/2512.11474</link>
      <description>arXiv:2512.11474v1 Announce Type: cross 
Abstract: Generative artificial intelligence (AI) offers potential for democratizing scientific knowledge and converting this to clear, actionable information, yet its application in agri-food science remains unexplored. Here, we verify the scientific knowledge on agroecological crop protection that is generated by either web-grounded or non-grounded large language models (LLMs), i.e., DeepSeek versus the free-tier version of ChatGPT. For nine globally limiting pests, weeds, and plant diseases, we assessed the factual accuracy, data consistency, and breadth of knowledge or data completeness of each LLM. Overall, DeepSeek consistently screened a 4.8-49.7-fold larger literature corpus and reported 1.6-2.4-fold more biological control agents or management solutions than ChatGPT. As a result, DeepSeek reported 21.6% higher efficacy estimates, exhibited greater laboratory-to-field data consistency, and showed more realistic effects of pest identity and management tactics. However, both models hallucinated, i.e., fabricated fictitious agents or references, reported on implausible ecological interactions or outcomes, confused old and new scientific nomenclatures, and omitted data on key agents or solutions. Despite these shortcomings, both LLMs correctly reported low-resolution efficacy trends. Overall, when paired with rigorous human oversight, LLMs may pose a powerful tool to support farm-level decision-making and unleash scientific creativity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.11474v1</guid>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.IR</category>
      <pubDate>Mon, 15 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Kris A. G. Wyckhuys</dc:creator>
    </item>
    <item>
      <title>Measuring Online Behavior Change with Observational Studies: a Review</title>
      <link>https://arxiv.org/abs/2310.19951</link>
      <description>arXiv:2310.19951v3 Announce Type: replace 
Abstract: Exploring online behavior change is imperative for societal progress in the context of 21st-century challenges. We analyze 148 articles (2000-2023) focusing on behavior change in the digital space and build a map that categorizes behaviors, behavior change detection methodologies, platforms of reference, and theoretical frameworks that characterize the analysis of online behavior change. Our findings reveal a focus on sentiment shifts, an emphasis on API-restricted platforms, and limited integration of theory. We call for methodologies able to capture a wider range of behavior types, diverse data sources, and stronger theory-practice alignment in the study of online behavior and its change.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.19951v3</guid>
      <category>cs.CY</category>
      <category>cs.SI</category>
      <category>physics.soc-ph</category>
      <pubDate>Mon, 15 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arianna Pera, Gianmarco de Francisci Morales, Luca Maria Aiello</dc:creator>
    </item>
    <item>
      <title>Empirical Analysis of the Effect of Context in the Task of Automated Essay Scoring in Transformer-Based Models</title>
      <link>https://arxiv.org/abs/2508.16638</link>
      <description>arXiv:2508.16638v2 Announce Type: replace 
Abstract: Automated Essay Scoring (AES) has emerged to prominence in response to the growing demand for educational automation. Providing an objective and cost-effective solution, AES standardises the assessment of extended responses. Although substantial research has been conducted in this domain, recent investigations reveal that alternative deep-learning architectures outperform transformer-based models. Despite the successful dominance in the performance of the transformer architectures across various other tasks, this discrepancy has prompted a need to enrich transformer-based AES models through contextual enrichment.
  This study delves into diverse contextual factors using the ASAP-AES dataset, analysing their impact on transformer-based model performance. Our most effective model, augmented with multiple contextual dimensions, achieves a mean Quadratic Weighted Kappa score of 0.823 across the entire essay dataset and 0.8697 when trained on individual essay sets. Evidently surpassing prior transformer-based models, this augmented approach only underperforms relative to the state-of-the-art deep learning model trained essay-set-wise by an average of 3.83\% while exhibiting superior performance in three of the eight sets.
  Importantly, this enhancement is orthogonal to architecture-based advancements and seamlessly adaptable to any AES model. Consequently, this contextual augmentation methodology presents a versatile technique for refining AES capabilities, contributing to automated grading and evaluation evolution in educational settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.16638v2</guid>
      <category>cs.CY</category>
      <category>cs.CL</category>
      <pubDate>Mon, 15 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Abhirup Chakravarty</dc:creator>
    </item>
    <item>
      <title>AI and Jobs: Has the Inflection Point Arrived? Evidence from an Online Labor Platform</title>
      <link>https://arxiv.org/abs/2312.04180</link>
      <description>arXiv:2312.04180v3 Announce Type: replace-cross 
Abstract: This study investigates how artificial intelligence (AI) influences various online labor markets (OLMs) over time. Employing the Difference-in-Differences method, we discovered two distinct scenarios following ChatGPT's launch: displacement effects featuring reduced work volume and earnings, exemplified by translation &amp; localization OLM; productivity effects featuring increased work volume and earnings, exemplified by web development OLM. To understand these opposite effects in a unified framework, we developed a Cournot competition model to identify an inflection point for each market. Before this point, human workers benefit from AI enhancements; beyond this point, human workers would be replaced. Further analyzing the progression from ChatGPT 3.5 to 4.0, we found three effect scenarios, reinforcing our inflection point conjecture. Heterogeneous analyses reveal that U.S. web developers tend to benefit more from ChatGPT's launch compared to their counterparts in other regions. Experienced translators seem more likely to exit the market than less experienced translators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.04180v3</guid>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Mon, 15 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dandan Qiao, Huaxia Rui, Qian Xiong</dc:creator>
    </item>
    <item>
      <title>Rolling in the deep of cognitive and AI biases</title>
      <link>https://arxiv.org/abs/2407.21202</link>
      <description>arXiv:2407.21202v4 Announce Type: replace-cross 
Abstract: Nowadays, we delegate many of our decisions to Artificial Intelligence (AI) that acts either in solo or as a human companion in decisions made to support several sensitive domains, like healthcare, financial services and law enforcement. AI systems, even carefully designed to be fair, are heavily criticized for delivering misjudged and discriminated outcomes against individuals and groups. Numerous work on AI algorithmic fairness is devoted on Machine Learning pipelines which address biases and quantify fairness under a pure computational view. However, the continuous unfair and unjust AI outcomes, indicate that there is urgent need to understand AI as a sociotechnical system, inseparable from the conditions in which it is designed, developed and deployed. Although, the synergy of humans and machines seems imperative to make AI work, the significant impact of human and societal factors on AI bias is currently overlooked. We address this critical issue by following a radical new methodology under which human cognitive biases become core entities in our AI fairness overview. Inspired by the cognitive science definition and taxonomy of human heuristics, we identify how harmful human actions influence the overall AI lifecycle, and reveal human to AI biases hidden pathways. We introduce a new mapping, which justifies the human heuristics to AI biases reflections and we detect relevant fairness intensities and inter-dependencies. We envision that this approach will contribute in revisiting AI fairness under deeper human-centric case studies, revealing hidden biases cause and effects.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.21202v4</guid>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <pubDate>Mon, 15 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicoleta Tantalaki, Athena Vakali</dc:creator>
    </item>
    <item>
      <title>HyperSBINN: A Hypernetwork-Enhanced Systems Biology-Informed Neural Network for Efficient Drug Cardiosafety Assessment</title>
      <link>https://arxiv.org/abs/2408.14266</link>
      <description>arXiv:2408.14266v2 Announce Type: replace-cross 
Abstract: Mathematical modeling in systems toxicology enables a comprehensive understanding of the effects of pharmaceutical substances on cardiac health. However, the complexity of these models limits their widespread application in early drug discovery. In this paper, we introduce a novel approach to solving parameterized models of cardiac action potentials by combining meta-learning techniques with Systems Biology-Informed Neural Networks (SBINNs). The proposed method, hyperSBINN, effectively addresses the challenge of predicting the effects of various compounds at different concentrations on cardiac action potentials, outperforming traditional differential equation solvers in speed. Our model efficiently handles scenarios with limited data and complex parameterized differential equations. The hyperSBINN model demonstrates robust performance in predicting APD90 values, indicating its potential as a reliable tool for modeling cardiac electrophysiology and aiding in preclinical drug development. This framework represents an advancement in computational modeling, offering a scalable and efficient solution for simulating and understanding complex biological systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.14266v2</guid>
      <category>stat.ML</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <category>q-bio.QM</category>
      <pubDate>Mon, 15 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Inass Soukarieh, Gerhard Hessler, Herv\'e Minoux, Marcel Mohr, Friedemann Schmidt, Jan Wenzel, Pierre Barbillon, Hugo Gangloff, Pierre Gloaguen</dc:creator>
    </item>
    <item>
      <title>Evaluating Federated Learning for At-Risk Student Prediction: A Comparative Analysis of Model Complexity and Data Balancing</title>
      <link>https://arxiv.org/abs/2508.18316</link>
      <description>arXiv:2508.18316v3 Announce Type: replace-cross 
Abstract: This study proposes and validates a Federated Learning (FL) framework to proactively identify at-risk students while preserving data privacy. Persistently high dropout rates in distance education remain a pressing institutional challenge. Using the large-scale OULAD dataset, we simulate a privacy-centric scenario where models are trained on early academic performance and digital engagement patterns. Our work investigates the practical trade-offs between model complexity (Logistic Regression vs. a Deep Neural Network) and the impact of local data balancing. The resulting federated model achieves strong predictive power (ROC AUC approximately 85%), demonstrating that FL is a practical and scalable solution for early-warning systems that inherently respects student data sovereignty.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.18316v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.LO</category>
      <pubDate>Mon, 15 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rodrigo Tertulino, Ricardo Almeida</dc:creator>
    </item>
    <item>
      <title>UpBench: A Dynamically Evolving Real-World Labor-Market Agentic Benchmark Framework Built for Human-Centric AI</title>
      <link>https://arxiv.org/abs/2511.12306</link>
      <description>arXiv:2511.12306v2 Announce Type: replace-cross 
Abstract: As large language model (LLM) agents increasingly undertake digital work, reliable frameworks are needed to evaluate their real-world competence, adaptability, and capacity for human collaboration. Existing benchmarks remain largely static, synthetic, or domain-limited, providing limited insight into how agents perform in dynamic, economically meaningful environments. We introduce UpBench, a dynamically evolving benchmark grounded in real jobs drawn from the global Upwork labor marketplace. Each task corresponds to a verified client transaction, anchoring evaluation in genuine work activity and financial outcomes. UpBench employs a rubric-based evaluation framework, in which expert freelancers decompose each job into detailed, verifiable acceptance criteria and assess AI submissions with per-criterion feedback. This structure enables fine-grained analysis of model strengths, weaknesses, and instruction-following fidelity beyond binary pass/fail metrics. Human expertise is integrated throughout the data pipeline (from job curation and rubric construction to evaluation) ensuring fidelity to real professional standards and supporting research on human-AI collaboration. By regularly refreshing tasks to reflect the evolving nature of online work, UpBench provides a scalable, human-centered foundation for evaluating agentic systems in authentic labor-market contexts, offering a path toward a collaborative framework, where AI amplifies human capability through partnership rather than replacement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.12306v2</guid>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <pubDate>Mon, 15 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Darvin Yi, Teng Liu, Mattie Terzolo, Lance Hasson, Ayan Sinha, Pablo Mendes, Andrew Rabinovich</dc:creator>
    </item>
    <item>
      <title>Causal symmetrization as an empirical signature of operational autonomy in complex systems</title>
      <link>https://arxiv.org/abs/2512.09352</link>
      <description>arXiv:2512.09352v2 Announce Type: replace-cross 
Abstract: Theoretical biology has long proposed that autonomous systems sustain their identity through reciprocal constraints between structure and activity, a dynamical regime underlying concepts such as closure to efficient causation and autopoiesis. Despite their influence, these principles have resisted direct empirical assessment outside biological systems.
  Here, we empirically assess this framework in artificial sociotechnical systems by identifying a statistical signature consistent with operational autonomy. Analyzing 50 large-scale collaborative software ecosystems spanning 11,042 system-months, we develop an order parameter ($\Gamma$) quantifying structural persistence under component turnover and use Granger causality to characterize directional coupling between organizational architecture and collective activity. $\Gamma$ exhibits a bimodal distribution (Hartigan's dip test $p = 0.0126$; $\Delta$BIC = 2000), revealing a sharp phase transition between an exploratory regime of high variance and a mature regime characterized by a 1.77-fold variance collapse. At maturity, causal symmetrization emerges, with the structure--activity coupling ratio shifting from 0.71 (activity-driven) to 0.94 (bidirectional).
  A composite viability index combining activity and structural persistence outperforms activity-based prediction alone (AUC = 0.88 vs. 0.81), identifying ``structural zombie'' systems in which sustained activity masks architectural decay.
  Together, these results show that causal symmetrization functions as a necessary statistical signature consistent with theoretical notions of operational closure, without implying biological life or mechanistic closure. They demonstrate that core principles of autonomy can be empirically probed in artificial collaborative systems, supporting substrate-independent dynamical signatures of self-organizing autonomy across complex adaptive systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.09352v2</guid>
      <category>physics.soc-ph</category>
      <category>cs.CY</category>
      <category>cs.SE</category>
      <pubDate>Mon, 15 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anthony Gosme</dc:creator>
    </item>
    <item>
      <title>EpiPlanAgent: Agentic Automated Epidemic Response Planning</title>
      <link>https://arxiv.org/abs/2512.10313</link>
      <description>arXiv:2512.10313v2 Announce Type: replace-cross 
Abstract: Epidemic response planning is essential yet traditionally reliant on labor-intensive manual methods. This study aimed to design and evaluate EpiPlanAgent, an agent-based system using large language models (LLMs) to automate the generation and validation of digital emergency response plans. The multi-agent framework integrated task decomposition, knowledge grounding, and simulation modules. Public health professionals tested the system using real-world outbreak scenarios in a controlled evaluation. Results demonstrated that EpiPlanAgent significantly improved the completeness and guideline alignment of plans while drastically reducing development time compared to manual workflows. Expert evaluation confirmed high consistency between AI-generated and human-authored content. User feedback indicated strong perceived utility. In conclusion, EpiPlanAgent provides an effective, scalable solution for intelligent epidemic response planning, demonstrating the potential of agentic AI to transform public health preparedness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.10313v2</guid>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <pubDate>Mon, 15 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kangkun Mao, Fang Xu, Jinru Ding, Yidong Jiang, Yujun Yao, Yirong Chen, Junming Liu, Xiaoqin Wu, Qian Wu, Xiaoyan Huang, Jie Xu</dc:creator>
    </item>
  </channel>
</rss>
