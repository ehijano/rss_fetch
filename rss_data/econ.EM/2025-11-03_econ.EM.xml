<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.EM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.EM</link>
    <description>econ.EM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.EM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 03 Nov 2025 05:01:00 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 03 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Emergent Dynamical Spatial Boundaries in Emergency Medical Services: A Navier-Stokes Framework from First Principles</title>
      <link>https://arxiv.org/abs/2510.26810</link>
      <description>arXiv:2510.26810v1 Announce Type: cross 
Abstract: Emergency medical services (EMS) response times are critical determinants of patient survival, yet existing approaches to spatial coverage analysis rely on discrete distance buffers or ad-hoc geographic information system (GIS) isochrones without theoretical foundation. This paper derives continuous spatial boundaries for emergency response from first principles using fluid dynamics (Navier-Stokes equations), demonstrating that response effectiveness decays exponentially with time: $\tau(t) = \tau_0 \exp(-\kappa t)$, where $\tau_0$ is baseline effectiveness and $\kappa$ is the temporal decay rate. Using 10,000 simulated emergency incidents from the National Emergency Medical Services Information System (NEMSIS), I estimate decay parameters and calculate critical boundaries $d^*$ where response effectiveness falls below policy-relevant thresholds. The framework reveals substantial demographic heterogeneity: elderly populations (85+) experience 8.40-minute average response times versus 7.83 minutes for younger adults (18-44), with 33.6\% of poor-access incidents affecting elderly populations despite representing 5.2\% of the sample. Non-parametric kernel regression validation confirms exponential decay is appropriate (mean squared error 8-12 times smaller than parametric), while traditional difference-in-differences analysis validates treatment effect existence (DiD coefficient = -1.35 minutes, $p &lt; 0.001$). The analysis identifies vulnerable populations--elderly, rural, and low-income communities--facing systematically longer response times, informing optimal EMS station placement and resource allocation to reduce health disparities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.26810v1</guid>
      <category>stat.AP</category>
      <category>econ.EM</category>
      <category>stat.ME</category>
      <pubDate>Mon, 03 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tatsuru Kikuchi</dc:creator>
    </item>
    <item>
      <title>Testing for Peer Effects without Specifying the Network Structure</title>
      <link>https://arxiv.org/abs/2306.09806</link>
      <description>arXiv:2306.09806v4 Announce Type: replace 
Abstract: This paper proposes an Anderson-Rubin (AR) test for the presence of peer effects in panel data without the need to specify the network structure. The unrestricted model of our test is a linear panel data model of social interactions with dyad-specific peer effect coefficients for all potential peers. The proposed AR test evaluates if these peer effect coefficients are all zero. As the number of peer effect coefficients increases with the sample size, so does the number of instrumental variables (IVs) employed to test the restrictions under the null, rendering Bekker's many-IV environment. By extending existing many-IV asymptotic results to panel data, we establish the asymptotic validity of the proposed AR test. Our Monte Carlo simulations show the robustness and superior performance of the proposed test compared to some existing tests with misspecified networks. We provide two applications to demonstrate its empirical relevance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.09806v4</guid>
      <category>econ.EM</category>
      <pubDate>Mon, 03 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hyunseok Jung, Xiaodong Liu</dc:creator>
    </item>
    <item>
      <title>A Unified Framework for Identification and Inference of Local Treatment Effects in Sharp Regression Kink Designs</title>
      <link>https://arxiv.org/abs/2506.11663</link>
      <description>arXiv:2506.11663v2 Announce Type: replace 
Abstract: This paper develops a unified framework for the identification, estimation, and uniform inference of local treatment effects (LTEs) in sharp regression kink designs (RKDs). These LTEs quantify the effect of a marginal change in the treatment at the kink point on various features of the outcome distribution. The identification strategy applies to Hadamard-differentiable functionals of the outcome distribution -- including means, quantiles, and inequality measures -- and encompasses several existing RKD estimands as special cases. For estimation, we categorize the corresponding estimands into two general classes and implement their estimation via local polynomial constrained regression. We establish the asymptotic theory for this framework and provide a valid resampling procedure for uniform inference. The method is applied to examine the effect of unemployment insurance on unemployment durations, focusing on the policy's impact on the distribution and inequality of durations, as a complement to existing empirical evidence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11663v2</guid>
      <category>econ.EM</category>
      <pubDate>Mon, 03 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhixin Wang, Zhengyu Zhang</dc:creator>
    </item>
    <item>
      <title>Modeling US Climate Policy Uncertainty: From Causal Identification to Probabilistic Forecasting</title>
      <link>https://arxiv.org/abs/2507.12276</link>
      <description>arXiv:2507.12276v2 Announce Type: replace 
Abstract: Accurately forecasting Climate Policy Uncertainty (CPU) is critical for designing effective climate strategies that balance economic growth with environmental objectives. Elevated CPU levels deter investment in green technologies, delay regulatory implementation, and amplify public resistance to policy reforms, particularly during economic stress. Despite the growing literature highlighting the economic relevance of CPU, the mechanisms through which macroeconomic and financial conditions influence its fluctuations remain insufficiently explored. This study addresses this gap by integrating four complementary causal inference techniques to identify statistically and economically significant determinants of the United States (US) CPU index. Impulse response analysis confirms their dynamic effects on CPU, highlighting the role of housing market activity, credit conditions, and financial market sentiment in shaping CPU fluctuations. The identified predictors, along with sentiment based Google Trends indicators, are incorporated into a Bayesian Structural Time Series (BSTS) framework for probabilistic forecasting. The inclusion of Google Trends data captures behavioral and attention based dynamics, leading to notable improvements in forecast accuracy. Numerical experiments demonstrate the superior performance of BSTS over state of the art classical and modern architectures for medium and long term forecasts, which are most relevant for climate policy implementation. The feature importance plot provides evidence that the spike-and-slab prior mechanism provides interpretable variable selection. The credible intervals quantify forecast uncertainty, thereby enhancing the model's transparency and policy relevance by enabling strategic decision making.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.12276v2</guid>
      <category>econ.EM</category>
      <category>stat.AP</category>
      <pubDate>Mon, 03 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Donia Besher, Anirban Sengupta, Tanujit Chakraborty</dc:creator>
    </item>
    <item>
      <title>SLIM: Stochastic Learning and Inference in Overidentified Models</title>
      <link>https://arxiv.org/abs/2510.20996</link>
      <description>arXiv:2510.20996v2 Announce Type: replace 
Abstract: We propose SLIM (Stochastic Learning and Inference in overidentified Models), a scalable stochastic approximation framework for nonlinear GMM. SLIM forms iterative updates from independent mini-batches of moments and their derivatives, producing unbiased directions that ensure almost-sure convergence. It requires neither a consistent initial estimator nor global convexity and accommodates both fixed-sample and random-sampling asymptotics. We further develop an optional second-order refinement achieving full-sample GMM efficiency and inference procedures based on random scaling and plug-in methods, including plug-in, debiased plug-in, and online versions of the Sargan--Hansen $J$-test tailored to stochastic learning. In Monte Carlo experiments based on a nonlinear demand system with 576 moment conditions, 380 parameters, and $n = 10^5$, SLIM solves the model in under 1.4 hours, whereas full-sample GMM in Stata on a powerful laptop converges only after 18 hours. The debiased plug-in $J$-test delivers satisfactory finite-sample inference, and SLIM scales smoothly to $n = 10^6$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.20996v2</guid>
      <category>econ.EM</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <pubDate>Mon, 03 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Xiaohong Chen, Min Seong Kim, Sokbae Lee, Myung Hwan Seo, Myunghyun Song</dc:creator>
    </item>
  </channel>
</rss>
