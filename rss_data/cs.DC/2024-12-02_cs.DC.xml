<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DC</link>
    <description>cs.DC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 03 Dec 2024 04:25:21 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Unified schemes for directive-based GPU offloading</title>
      <link>https://arxiv.org/abs/2411.18889</link>
      <description>arXiv:2411.18889v1 Announce Type: new 
Abstract: GPU is the dominant accelerator device due to its high performance and energy efficiency. Directive-based GPU offloading using OpenACC or OpenMP target is a convenient way to port existing codes originally developed for multicore CPUs. Although OpenACC and OpenMP target provide similar features, both methods have pros and cons. OpenACC has better functions and an abundance of documents, but it is virtually for NVIDIA GPUs. OpenMP target supports NVIDIA/AMD/Intel GPUs but has fewer functions than OpenACC. Here, we have developed a header-only library, Solomon (Simple Off-LOading Macros Orchestrating multiple Notations), to unify the interface for GPU offloading with the support of both OpenACC and OpenMP target. Solomon provides three types of notations to reduce users' implementation and learning costs: intuitive notation for beginners and OpenACC/OpenMP-like notations for experienced developers. This manuscript denotes Solomon's implementation and usage and demonstrates the GPU-offloading in $N$-body simulation and the three-dimensional diffusion equation. The library and sample codes are provided as open-source software and publicly and freely available at \url{https://github.com/ymiki-repo/solomon}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.18889v1</guid>
      <category>cs.DC</category>
      <category>astro-ph.IM</category>
      <category>cs.PF</category>
      <category>cs.PL</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1109/ACCESS.2024.3509380</arxiv:DOI>
      <dc:creator>Yohei Miki, Toshihiro Hanawa</dc:creator>
    </item>
    <item>
      <title>Quality Time: Carbon-Aware Quality Adaptation for Energy-Intensive Services</title>
      <link>https://arxiv.org/abs/2411.19058</link>
      <description>arXiv:2411.19058v1 Announce Type: new 
Abstract: The energy demand of modern cloud services, particularly those related to generative AI, is increasing at an unprecedented pace. While hyperscalers are collectively failing to meet their self-imposed emission reduction targets, they face increasing pressure from environmental sustainability reporting across many jurisdictions. To date, carbon-aware computing strategies have primarily focused on batch process scheduling or geo-distributed load balancing. However, such approaches are not applicable to services that require constant availability at specific locations, due to latency, privacy, data, or infrastructure constraints.
  In this paper, we explore how the carbon footprint of energy-intensive services can be reduced, by adjusting the fraction of requests served by different service quality tiers. We show, that by adapting the the quality of responses with respect to local carbon intensity, we can achieve additional carbon savings beyond resource and energy efficiency. Building on this, we introduce a multi-horizon optimization, that reaches close-to-optimal carbon savings under realistic conditions, and can dynamically adapt the service quality for best-effort users to stay within an annual carbon budget. Our approach can reduce the emissions of large-scale LLM services, which we estimate at multiple 10,000 tons of CO$_2$ annually, by up to 10%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19058v1</guid>
      <category>cs.DC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Philipp Wiesner, Dennis Grinwald, Philipp Wei{\ss}, Patrick Wilhelm, Ramin Khalili, Odej Kao</dc:creator>
    </item>
    <item>
      <title>PREBA: A Hardware/Software Co-Design for Multi-Instance GPU based AI Inference Servers</title>
      <link>https://arxiv.org/abs/2411.19114</link>
      <description>arXiv:2411.19114v1 Announce Type: new 
Abstract: NVIDIA's Multi-Instance GPU (MIG) is a feature that enables system designers to reconfigure one large GPU into multiple smaller GPU slices. This work characterizes this emerging GPU and evaluates its effectiveness in designing high-performance AI inference servers. Our study reveals that the data preprocessing stage of AI inference causes significant performance bottlenecks to MIG. To this end, we present PREBA, which is a hardware/software co-design targeting MIG inference servers. Our first proposition is an FPGA-based data preprocessing accelerator that unlocks the full potential of MIG with domain-specific acceleration of data preprocessing. The MIG inference server unleashed from preprocessing overheads is then augmented with our dynamic batching system that enables high-performance inference. PREBA is implemented end-to-end in real systems, providing a 3.7x improvement in throughput, 3.4x reduction in tail latency, 3.5x improvement in energy-efficiency, and 3.0x improvement in cost-efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19114v1</guid>
      <category>cs.DC</category>
      <category>cs.AI</category>
      <category>cs.AR</category>
      <category>cs.LG</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Gwangoo Yeo, Jiin Kim, Yujeong Choi, Minsoo Rhu</dc:creator>
    </item>
    <item>
      <title>Strongly-Linearizable Bags</title>
      <link>https://arxiv.org/abs/2411.19365</link>
      <description>arXiv:2411.19365v1 Announce Type: new 
Abstract: Strongly-linearizable objects are valuable building blocks for the design of concurrent data structures. Yet, many objects that have linearizable implementations from some set of objects do not have strongly-linearizable implementations from that set of objects. We focus on one such object with consensus number 2: the bag, a multiset from which processes can take arbitrary elements.
  We present the first lock-free, strongly-linearizable implementation of a bag from interfering objects (specifically, registers, test&amp;set objects, and readable fetch&amp;increment objects). We show that a previously proposed implementation is, in fact, not strongly-linearizable.
  Since a bag can be arbitrarily large, the amount of space that it requires must be unbounded. A more practical object is a $b$-bounded bag, which is a bag whose maximum capacity is $b$ elements. However, a 1-bounded bag has no lock-free, strongly-linearizable implementation from interfering objects. If we restrict the 1-bounded bag so that only one process can insert into it, we are able to obtain a wait-free, linearizable implementation and a lock-free, strongly-linearizable implementation from a bounded number of readable, resettable test&amp;set objects and registers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19365v1</guid>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Faith Ellen, Gal Sela</dc:creator>
    </item>
    <item>
      <title>Marconi: Prefix Caching for the Era of Hybrid LLMs</title>
      <link>https://arxiv.org/abs/2411.19379</link>
      <description>arXiv:2411.19379v1 Announce Type: new 
Abstract: Hybrid models that combine the language modeling capabilities of Attention layers with the efficiency of Recurrent layers (e.g., State Space Models) have gained traction in practically supporting long contexts in Large Language Model serving. Yet, the unique properties of these models complicate the usage of complementary efficiency optimizations such as prefix caching that skip redundant computations across requests. Most notably, their use of in-place state updates for recurrent layers precludes rolling back cache entries for partial sequence overlaps, and instead mandates only exact-match cache hits; the effect is a deluge of (large) cache entries per sequence, most of which yield minimal reuse opportunities. We present Marconi, the first system that supports efficient prefix caching with Hybrid LLMs. Key to Marconi are its novel admission and eviction policies that more judiciously assess potential cache entries based not only on recency, but also on (1) forecasts of their reuse likelihood across a taxonomy of different hit scenarios, and (2) the compute savings that hits deliver relative to memory footprints. Across diverse workloads and Hybrid models, Marconi achieves up to 34.4$\times$ higher token hit rates (71.1% or 617 ms lower TTFT) compared to state-of-the-art prefix caching systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19379v1</guid>
      <category>cs.DC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Rui Pan, Zhuang Wang, Zhen Jia, Can Karakus, Luca Zancato, Tri Dao, Ravi Netravali, Yida Wang</dc:creator>
    </item>
    <item>
      <title>Action Engine: An LLM-based Framework for Automatic FaaS Workflow Generation</title>
      <link>https://arxiv.org/abs/2411.19485</link>
      <description>arXiv:2411.19485v1 Announce Type: new 
Abstract: Function as a Service (FaaS) is poised to become the foundation of the next generation of cloud systems due to its inherent advantages in scalability, cost-efficiency, and ease of use. However, challenges such as the need for specialized knowledge and difficulties in building function workflows persist for cloud-native application developers. To overcome these challenges and mitigate the burden of developing FaaS-based applications, in this paper, we propose a mechanism called Action Engine, that makes use of Tool-Augmented Large Language Models (LLMs) at its kernel to interpret human language queries and automates FaaS workflow generation, thereby, reducing the need for specialized expertise and manual design. Action Engine includes modules to identify relevant functions from the FaaS repository and seamlessly manage the data dependency between them, ensuring that the developer's query is processed and resolved. Beyond that, Action Engine can execute the generated workflow by feeding the user-provided parameters. Our evaluations show that Action Engine can generate workflows with up to 20\% higher correctness without developer involvement. We notice that Action Engine can unlock FaaS workflow generation for non-cloud-savvy developers and expedite the development cycles of cloud-native applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19485v1</guid>
      <category>cs.DC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.SE</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Akiharu Esashi, Pawissanutt Lertpongrujikorn, Mohsen Amini Salehi</dc:creator>
    </item>
    <item>
      <title>HE2C: A Holistic Approach for Allocating Latency-Sensitive AI Tasks across Edge-Cloud</title>
      <link>https://arxiv.org/abs/2411.19487</link>
      <description>arXiv:2411.19487v1 Announce Type: new 
Abstract: The high computational, memory, and energy demands of Deep Learning (DL) applications often exceed the capabilities of battery-powered edge devices, creating difficulties in meeting task deadlines and accuracy requirements. Unlike previous solutions that optimize a single metric (e.g., accuracy or energy efficiency), HE2C framework is designed to holistically address the latency, memory, accuracy, throughput, and energy demands of DL applications across edge-cloud continuum, thereby, delivering a more comprehensive and effective user experience. HE2C comprises three key modules: (a) a "feasibility-check module that evaluates the likelihood of meeting deadlines across both edge and cloud resources; (b) a "resource allocation strategy" that maximizes energy efficiency without sacrificing the inference accuracy; and (c) a "rescue module" that enhances throughput by leveraging approximate computing to trade accuracy for latency when necessary. Our primary objective is to maximize system prolong battery lifespan, throughput, and accuracy while adhering to strict latency constraints. Experimental evaluations in the context of wearable technologies for blind and visually impaired users demonstrate that HE2C significantly improves task throughput via completing a larger number of tasks within their specified deadlines, while preserving edge device battery and maintaining prediction accuracy with minimal latency impact. These results underscore HE2C's potential as a robust solution for resource management in latency-sensitive, energy-constrained edge-to-cloud environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19487v1</guid>
      <category>cs.DC</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Minseo Kim, Wei Shu, Mohsen Amini Salehi</dc:creator>
    </item>
    <item>
      <title>A dynamic parallel method for performance optimization on hybrid CPUs</title>
      <link>https://arxiv.org/abs/2411.19542</link>
      <description>arXiv:2411.19542v1 Announce Type: new 
Abstract: The AIPC concept is gaining popularity, and more and more hybrid CPUs will be running AI models on client devices. However, the current AI inference framework overlooks the imbalanced hardware capability of hybrid CPUs, leading to low inference performance. To address this issue, we have introduced a dynamic parallel method for hybrid CPUs, which significantly increases LLM inference performance by balancing the workload for each core of a hybrid CPU before the parallel work starts. This method has enabled Neural Speed to achieve more than 90% (on average) of memory bandwidth on two hybrid Intel CPUs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19542v1</guid>
      <category>cs.DC</category>
      <category>cs.PF</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luo Yu, Liu Yucheng, Shen Haihao</dc:creator>
    </item>
    <item>
      <title>In-Vehicle Edge System for Real-Time Dashcam Video Analysis</title>
      <link>https://arxiv.org/abs/2411.19558</link>
      <description>arXiv:2411.19558v1 Announce Type: new 
Abstract: Modern vehicles equip dashcams that primarily collect visual evidence for traffic accidents. However, most of the video data collected by dashcams that is not related to traffic accidents is discarded without any use. In this paper, we present a use case for dashcam videos that aims to improve driving safety. By analyzing the real-time videos captured by dashcams, we can detect driving hazards and driver distractedness to alert the driver immediately. To that end, we design and implement a Distributed Edge-based dashcam Video Analytics system (DEVA), that analyzes dashcam videos using personal edge (mobile) devices in a vehicle. DEVA consolidates available in-vehicle edge devices to maintain the resource pool, distributes video frames for analysis to devices considering resource availability in each device, and dynamically adjusts frame rates of dashcams to control the overall workloads. The entire video analytics task is divided into multiple independent phases and executed in a pipelined manner to improve the overall frame processing throughput. We implement DEVA in an Android app and also develop a dashcam emulation app to be used in vehicles that are not equipped with dashcams. Experimental results using the apps and commercial smartphones show that DEVA can process real-time videos from two dashcams with frame rates of around 22~30 FPS per camera within 200 ms of latency, using three high-end devices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19558v1</guid>
      <category>cs.DC</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Seyul Lee, Jayden King, Young Choon Lee, Hyuck Han, Sooyong Kang</dc:creator>
    </item>
    <item>
      <title>Distributed And Parallel Low-Diameter Decompositions for Arbitrary and Restricted Graphs</title>
      <link>https://arxiv.org/abs/2411.19859</link>
      <description>arXiv:2411.19859v1 Announce Type: new 
Abstract: We consider the distributed and parallel construction of low-diameter decompositions with strong diameter for (weighted) graphs and (weighted) graphs that can be separated through $k \in \tilde{O}(1)$ shortest paths. This class of graphs includes planar graphs, graphs of bounded treewidth, and graphs that exclude a fixed minor $K_r$. We present algorithms in the PRAM, CONGEST, and the novel HYBRID communication model that are competitive in all relevant parameters.
  Given $\mathcal{D} &gt; 0$, our low-diameter decomposition algorithm divides the graph into connected clusters of strong diameter $\mathcal{D}$. For a arbitrary graph, an edge $e \in E$ of length $\ell_e$ is cut between two clusters with probability $O(\frac{\ell_e\cdot\log(n)}{\mathcal{D} })$. If the graph can be separated by $k \in \tilde{O}(1)$ paths, the probability improves to $O(\frac{\ell_e\cdot\log \log n}{\mathcal{D} })$. In either case, the decompositions can be computed in $\tilde{O}(1)$ depth and $\tilde{O}(kn)$ work in the PRAM and $\tilde{O}(1)$ time in the HYBRID model. In CONGEST, the runtimes are $\tilde{O}(HD + \sqrt{n})$ and $\tilde{O}(HD)$ respectively. All these results hold w.h.p.
  Broadly speaking, we present distributed and parallel implementations of sequential divide-and-conquer algorithms where we replace exact shortest paths with approximate shortest paths. In contrast to exact paths, these can be efficiently computed in the distributed and parallel setting [STOC '22]. Further, and perhaps more importantly, we show that instead of explicitly computing vertex-separators to enable efficient parallelization of these algorithms, it suffices to sample a few random paths of bounded length and the nodes close to them. Thereby, we do not require complex embeddings whose implementation is unknown in the distributed and parallel setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19859v1</guid>
      <category>cs.DC</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jinfeng Dou, Thorsten G\"otte, Henning Hillebrandt, Christian Scheideler, Julian Werthmann</dc:creator>
    </item>
    <item>
      <title>Memory Efficient GPU-based Label Propagation Algorithm (LPA) for Community Detection on Large Graphs</title>
      <link>https://arxiv.org/abs/2411.19901</link>
      <description>arXiv:2411.19901v1 Announce Type: new 
Abstract: Community detection involves grouping nodes in a graph with dense connections within groups, than between them. We previously proposed efficient multicore (GVE-LPA) and GPU-based ($\nu$-LPA) implementations of Label Propagation Algorithm (LPA) for community detection. However, these methods incur high memory overhead due to their per-thread/per-vertex hashtables. This makes it challenging to process large graphs on shared memory systems. In this report, we introduce memory-efficient GPU-based LPA implementations, using weighted Boyer-Moore (BM) and Misra-Gries (MG) sketches. Our new implementation, $\nu$MG8-LPA, using an 8-slot MG sketch, reduces memory usage by 98x and 44x compared to GVE-LPA and $\nu$-LPA, respectively. It is also 2.4x faster than GVE-LPA and only 1.1x slower than $\nu$-LPA, with minimal quality loss (4.7%/2.9% drop compared to GVE-LPA/$\nu$-LPA).</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19901v1</guid>
      <category>cs.DC</category>
      <category>cs.SI</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Subhajit Sahu</dc:creator>
    </item>
    <item>
      <title>Locally Differentially Private Online Federated Learning With Correlated Noise</title>
      <link>https://arxiv.org/abs/2411.18752</link>
      <description>arXiv:2411.18752v1 Announce Type: cross 
Abstract: We introduce a locally differentially private (LDP) algorithm for online federated learning that employs temporally correlated noise to improve utility while preserving privacy. To address challenges posed by the correlated noise and local updates with streaming non-IID data, we develop a perturbed iterate analysis that controls the impact of the noise on the utility. Moreover, we demonstrate how the drift errors from local updates can be effectively managed for several classes of nonconvex loss functions. Subject to an $(\epsilon,\delta)$-LDP budget, we establish a dynamic regret bound that quantifies the impact of key parameters and the intensity of changes in the dynamic environment on the learning performance. Numerical experiments confirm the efficacy of the proposed algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.18752v1</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>stat.ML</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiaojiao Zhang, Linglingzhi Zhu, Dominik Fay, Mikael Johansson</dc:creator>
    </item>
    <item>
      <title>Formal Verification of Digital Twins with TLA and Information Leakage Control</title>
      <link>https://arxiv.org/abs/2411.18798</link>
      <description>arXiv:2411.18798v1 Announce Type: cross 
Abstract: Verifying the correctness of a digital twin provides a formal guarantee that the digital twin operates as intended. Digital twin verification is challenging due to the presence of uncertainties in the virtual representation, the physical environment, and the bidirectional flow of information between physical and virtual. A further challenge is that a digital twin of a complex system is composed of distributed components. This paper presents a methodology to specify and verify digital twin behavior, translating uncertain processes into a formally verifiable finite state machine. We use the Temporal Logic of Actions (TLA) to create a specification, an implementation abstraction that defines the properties required for correct system behavior. Our approach includes a novel weakening of formal security properties, allowing controlled information leakage while preserving theoretical guarantees. We demonstrate this approach on a digital twin of an unmanned aerial vehicle, verifying synchronization of physical-to-virtual and virtual-to-digital data flows to detect unintended misalignments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.18798v1</guid>
      <category>cs.CR</category>
      <category>cs.DC</category>
      <category>cs.IT</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.IT</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luwen Huang, Lav R. Varshney, Karen E. Willcox</dc:creator>
    </item>
    <item>
      <title>A Lightweight and Scalable Design of Segment Routing in Broadband LEO Constellations Using Landmark-Based Skeleton Graphs</title>
      <link>https://arxiv.org/abs/2411.19679</link>
      <description>arXiv:2411.19679v1 Announce Type: cross 
Abstract: Emerging Low Earth Orbit (LEO) broadband constellations hold significant potential to provide advanced Internet services due to inherent geometric features of the grid topology. However, high dynamics, unstable topology changes, and frequent route updates bring significant challenge to fast and adaptive routing policies. In addition, since computing, bandwidth, and storage resources in each LEO satellite is strictly limited, traffic demands are typically unbalanced, further enlarging the challenge to scalable routing policies with load balancing. Nevertheless, most existing research failed to address the above difficulties. Therefore, this paper proposes a lightweight and scalable protocol of segment routing through landmark-based skeleton graphs. To improve the overall performance, we design an efficient multipath segment routing algorithm. First, the algorithm partitions the network into multiple regions to construct skeleton paths, which can effectively guide packet forwarding and reduce the operating costs. In each region, multipath probabilistic routing is used to achieve uniform traffic distribution, avoiding hotspot congestion. Furthermore, the flexible hierarchical partitioning and localized segmented routing is employed for fine-grained traffic control and QoS guarantee combined with adaptive local single-path routing. Finally, experimental results validate our method's superior performance in terms of response time and network utility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19679v1</guid>
      <category>cs.NI</category>
      <category>cs.DC</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Menglan Hu, Chenxin Wang, Bin Cao, Benkuan Zhou, Yan Dong, Kai Peng</dc:creator>
    </item>
    <item>
      <title>The Streetscape Application Services Stack (SASS): Towards a Distributed Sensing Architecture for Urban Applications</title>
      <link>https://arxiv.org/abs/2411.19714</link>
      <description>arXiv:2411.19714v1 Announce Type: cross 
Abstract: As urban populations grow, cities are becoming more complex, driving the deployment of interconnected sensing systems to realize the vision of smart cities. These systems aim to improve safety, mobility, and quality of life through applications that integrate diverse sensors with real-time decision-making. Streetscape applications-focusing on challenges like pedestrian safety and adaptive traffic management-depend on managing distributed, heterogeneous sensor data, aligning information across time and space, and enabling real-time processing. These tasks are inherently complex and often difficult to scale. The Streetscape Application Services Stack (SASS) addresses these challenges with three core services: multimodal data synchronization, spatiotemporal data fusion, and distributed edge computing. By structuring these capabilities as clear, composable abstractions with clear semantics, SASS allows developers to scale streetscape applications efficiently while minimizing the complexity of multimodal integration.
  We evaluated SASS in two real-world testbed environments: a controlled parking lot and an urban intersection in a major U.S. city. These testbeds allowed us to test SASS under diverse conditions, demonstrating its practical applicability. The Multimodal Data Synchronization service reduced temporal misalignment errors by 88%, achieving synchronization accuracy within 50 milliseconds. Spatiotemporal Data Fusion service improved detection accuracy for pedestrians and vehicles by over 10%, leveraging multicamera integration. The Distributed Edge Computing service increased system throughput by more than an order of magnitude. Together, these results show how SASS provides the abstractions and performance needed to support real-time, scalable urban applications, bridging the gap between sensing infrastructure and actionable streetscape intelligence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19714v1</guid>
      <category>cs.NI</category>
      <category>cs.CV</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Navid Salami Pargoo, Mahshid Ghasemi, Shuren Xia, Mehmet Kerem Turkcan, Taqiya Ehsan, Chengbo Zang, Yuan Sun, Javad Ghaderi, Gil Zussman, Zoran Kostic, Jorge Ortiz</dc:creator>
    </item>
    <item>
      <title>FRESCO: Fast and Reliable Edge Offloading with Reputation-based Hybrid Smart Contracts</title>
      <link>https://arxiv.org/abs/2410.06715</link>
      <description>arXiv:2410.06715v2 Announce Type: replace 
Abstract: Mobile devices offload latency-sensitive application tasks to edge servers to satisfy applications' Quality of Service (QoS) deadlines. Consequently, ensuring reliable offloading without QoS violations is challenging in distributed and unreliable edge environments. However, current edge offloading solutions are either centralized or do not adequately address challenges in distributed environments. We propose FRESCO, a fast and reliable edge offloading framework that utilizes a blockchain-based reputation system, which enhances the reliability of offloading in the distributed edge. The distributed reputation system tracks the historical performance of edge servers, while blockchain through a consensus mechanism ensures that sensitive reputation information is secured against tampering. However, blockchain consensus typically has high latency, and therefore we employ a Hybrid Smart Contract (HSC) that automatically computes and stores reputation securely on-chain (i.e., on the blockchain) while allowing fast offloading decisions off-chain (i.e., outside of blockchain). The offloading decision engine uses a reputation score to derive fast offloading decisions, which are based on Satisfiability Modulo Theory (SMT). The SMT models edge resource constraints, and QoS deadlines, and can formally guarantee a feasible solution that is valuable for latency-sensitive applications that require high reliability. With a combination of on-chain HSC reputation state management and an off-chain SMT decision engine, FRESCO offloads tasks to reliable servers without being hindered by blockchain consensus. We evaluate FRESCO against real availability traces and simulated applications. FRESCO reduces response time by up to 7.86 times and saves energy by up to 5.4% compared to all baselines while minimizing QoS violations to 0.4% and achieving an average decision time of 5.05 milliseconds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06715v2</guid>
      <category>cs.DC</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Josip Zilic, Vincenzo de Maio, Shashikant Ilager, Ivona Brandic</dc:creator>
    </item>
    <item>
      <title>Exact Aggregation for Federated and Efficient Fine-Tuning of Foundation Models</title>
      <link>https://arxiv.org/abs/2410.09432</link>
      <description>arXiv:2410.09432v2 Announce Type: replace 
Abstract: Low-Rank Adaptation (LoRA) is a popular technique for efficient fine-tuning of foundation models. However, applying LoRA in federated learning environments, where data is distributed across multiple clients, presents unique challenges. Existing methods rely on traditional federated averaging of LoRA adapters, resulting in inexact updates. To address this, we propose Federated Exact LoRA, or FedExLoRA, which adds a residual error term to the pretrained frozen weight matrix. Our approach achieves exact updates with minimal computational and communication overhead, preserving LoRA's efficiency. We evaluate the method on various models across arithmetic reasoning, commonsense reasoning, natural language understanding and natural language generation tasks, showing consistent performance gains over state-of-the-art methods across multiple settings. Through extensive analysis, we quantify that the deviations in updates from the ideal solution are significant, highlighting the need for exact aggregation. Our method's simplicity, efficiency, and broad applicability position it as a promising solution for accurate and effective federated fine-tuning of foundation models. Our code is publicly available at https://github.com/RaghavSinghal10/fedex-lora.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09432v2</guid>
      <category>cs.DC</category>
      <category>cs.CL</category>
      <category>cs.CV</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Raghav Singhal, Kaustubh Ponkshe, Praneeth Vepakomma</dc:creator>
    </item>
    <item>
      <title>CkIO: Parallel File Input for Over-Decomposed Task-Based Systems</title>
      <link>https://arxiv.org/abs/2411.18593</link>
      <description>arXiv:2411.18593v2 Announce Type: replace 
Abstract: Parallel input performance issues are often neglected in large scale parallel applications in Computational Science and Engineering. Traditionally, there has been less focus on input performance because either input sizes are small (as in biomolecular simulations) or the time doing input is insignificant compared with the simulation with many timesteps. But newer applications, such as graph algorithms add a premium to file input performance. Additionally, over-decomposed systems, such as Charm++/AMPI, present new challenges in this context in comparison to MPI applications. In the over-decomposition model, naive parallel I/O in which every task makes its own I/O request is impractical. Furthermore, load balancing supported by models such as Charm++/AMPI precludes assumption of data contiguity on individual nodes. We develop a new I/O abstraction to address these issues by separating the decomposition of consumers of input data from that of file-reader tasks that interact with the file system. This enables applications to scale the number of consumers of data without impacting I/O behavior or performance. These ideas are implemented in a new input library, CkIO, that is built on Charm++, which is a well-known task-based and overdecomposed-partitions system. CkIO is configurable via multiple parameters (such as the number of file readers and/or their placement) that can be tuned depending on characteristics of the application, such as file size and number of application objects. Additionally, CkIO input allows for capabilities such as effective overlap of input and application-level computation, as well as load balancing and migration. We describe the relevant challenges in understanding file system behavior and architecture, the design alternatives being explored, and preliminary performance data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.18593v2</guid>
      <category>cs.DC</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mathew Jacob, Maya Taylor, Laxmikant Kale</dc:creator>
    </item>
    <item>
      <title>How to Collaborate: Towards Maximizing the Generalization Performance in Cross-Silo Federated Learning</title>
      <link>https://arxiv.org/abs/2401.13236</link>
      <description>arXiv:2401.13236v2 Announce Type: replace-cross 
Abstract: Federated learning (FL) has attracted vivid attention as a privacy-preserving distributed learning framework. In this work, we focus on cross-silo FL, where clients become the model owners after training and are only concerned about the model's generalization performance on their local data. Due to the data heterogeneity issue, asking all the clients to join a single FL training process may result in model performance degradation. To investigate the effectiveness of collaboration, we first derive a generalization bound for each client when collaborating with others or when training independently. We show that the generalization performance of a client can be improved only by collaborating with other clients that have more training data and similar data distribution. Our analysis allows us to formulate a client utility maximization problem by partitioning clients into multiple collaborating groups. A hierarchical clustering-based collaborative training (HCCT) scheme is then proposed, which does not need to fix in advance the number of groups. We further analyze the convergence of HCCT for general non-convex loss functions which unveils the effect of data similarity among clients. Extensive simulations show that HCCT achieves better generalization performance than baseline schemes, whereas it degenerates to independent training and conventional FL in specific scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.13236v2</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuchang Sun, Marios Kountouris, Jun Zhang</dc:creator>
    </item>
    <item>
      <title>A Cloud-based Real-time Probabilistic Remaining Useful Life (RUL) Estimation using the Sequential Monte Carlo (SMC) Method</title>
      <link>https://arxiv.org/abs/2411.17824</link>
      <description>arXiv:2411.17824v2 Announce Type: replace-cross 
Abstract: The remaining useful life (RUL) estimation is an important metric that helps in condition-based maintenance. Damage data obtained from the diagnostics techniques are often noisy and the RUL estimated from the data is less reliable. Estimating the probabilistic RUL by quantifying the uncertainty in the predictive model parameters using the noisy data increases confidence in the predicted values. Uncertainty quantification methods generate statistical samples for the model parameters, that represent the uncertainty, by evaluating the predictive model several times. The computational time for solving a physics-based predictive model is significant, which makes the statistical techniques to be computationally expensive. It is essential to reduce the computational time to estimate the RUL in a feasible time. In this work, real-time probabilistic RUL estimation is demonstrated in adhesively bonded joints using the Sequential Monte Carlo (SMC) sampling method and cloud-based computations. The SMC sampling method is an alternative to traditional MCMC methods, which enables generating the statistical parameter samples in parallel. The parallel computational capabilities of the SMC methods are exploited by running the SMC simulation on multiple cloud calls. This approach is demonstrated by estimating fatigue RUL in the adhesively bonded joint. The accuracy of probabilistic RUL estimated by SMC is validated by comparing it with RUL estimated by the MCMC and the experimental values. The SMC simulation is run on the cloud and the computational speedup of the SMC is demonstrated.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.17824v2</guid>
      <category>cs.CE</category>
      <category>cs.DC</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Karthik Reddy Lyathakula, Fuh-Gwo Yuan</dc:creator>
    </item>
  </channel>
</rss>
