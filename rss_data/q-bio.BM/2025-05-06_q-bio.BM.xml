<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.BM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.BM</link>
    <description>q-bio.BM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.BM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 06 May 2025 04:00:25 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>From Possibility to Precision in Macromolecular Ensemble Prediction</title>
      <link>https://arxiv.org/abs/2505.01919</link>
      <description>arXiv:2505.01919v1 Announce Type: new 
Abstract: Proteins and other macromolecules do not exist in a single state but as dynamic ensembles of interconverting conformations, which are essential for functions such as catalysis, allosteric regulation, and molecular recognition. While AI-based structure predictors like AlphaFold have revolutionized static structure prediction, they are not yet capable of capturing conformational heterogeneity. Progress towards the next generation of AI models capable of ensemble prediction is currently limited by the lack of accurate, high-resolution ground truth ensembles at the scale required for training and validation. No single experimental technique can fully resolve the atomistic complexity of conformational landscapes, and fundamental challenges remain in defining, representing, comparing, and validating structural ensembles. Here, we outline the infrastructure and methodological advances needed to overcome these barriers. We highlight emerging strategies for integrating heterogeneous experimental data into unified ensemble encoding representations and how to leverage these new methodologies to build benchmarks and establish ensemble-specific validation protocols. Finally, we discuss how ensemble predictions will be an interactive cycle of experimental and computational innovation. Establishing this ecosystem will allow structural biology to move beyond static snapshots toward a dynamic understanding of molecular behavior that captures the full complexity of biological systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01919v1</guid>
      <category>q-bio.BM</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Stephanie A. Wankowicz, Massimiliano Bonomi</dc:creator>
    </item>
    <item>
      <title>NbBench: Benchmarking Language Models for Comprehensive Nanobody Tasks</title>
      <link>https://arxiv.org/abs/2505.02022</link>
      <description>arXiv:2505.02022v1 Announce Type: cross 
Abstract: Nanobodies, single-domain antibody fragments derived from camelid heavy-chain-only antibodies, exhibit unique advantages such as compact size, high stability, and strong binding affinity, making them valuable tools in therapeutics and diagnostics. While recent advances in pretrained protein and antibody language models (PPLMs and PALMs) have greatly enhanced biomolecular understanding, nanobody-specific modeling remains underexplored and lacks a unified benchmark. To address this gap, we introduce NbBench, the first comprehensive benchmark suite for nanobody representation learning. Spanning eight biologically meaningful tasks across nine curated datasets, NbBench encompasses structure annotation, binding prediction, and developability assessment. We systematically evaluate eleven representative models--including general-purpose protein LMs, antibody-specific LMs, and nanobody-specific LMs--in a frozen setting. Our analysis reveals that antibody language models excel in antigen-related tasks, while performance on regression tasks such as thermostability and affinity remains challenging across all models. Notably, no single model consistently outperforms others across all tasks. By standardizing datasets, task definitions, and evaluation protocols, NbBench offers a reproducible foundation for assessing and advancing nanobody modeling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02022v1</guid>
      <category>cs.LG</category>
      <category>q-bio.BM</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yiming Zhang, Koji Tsuda</dc:creator>
    </item>
    <item>
      <title>Liapunov exponent distributions and maps for multiple parameter logistic equation. Application to DNA and RNA sequences</title>
      <link>https://arxiv.org/abs/2505.02276</link>
      <description>arXiv:2505.02276v1 Announce Type: cross 
Abstract: The multiple parameter logistic equation has previously been utilized to determine the global stability of ternary codes, based on the arrangement of different symbols within the code. This approach has been extended to DNA and RNA sequences, proposing a specific application in the context of reading and translation processes involved in DNA replication and RNA-mediated protein codification. To address the complexity of mapping Liapunov exponents in terms of four parameters representing the different nucleotide bases specialized mapping techniques have been developed. These include Liapunov exponent distributions for entire sequences, as well as binary maps that classify nucleotide bases based on their chemical type (purinic or pyrimidinic). Such methodologies provide a framework for examining the structural and functional properties of genetic material. The sequences analyzed encompass a wide range of DNA and RNA types, including those with and without introns, as well as codifying and noncodifying regions. This multifaceted approach offers valuable insights into the dynamic behavior and stability of nucleotide arrangements, contributing to a deeper understanding of the underlying processes that govern genetic replication and protein synthesis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02276v1</guid>
      <category>physics.bio-ph</category>
      <category>physics.comp-ph</category>
      <category>q-bio.BM</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Miguel Martin-Landrove, B. P. Embaid</dc:creator>
    </item>
    <item>
      <title>Fragment-Masked Molecular Optimization</title>
      <link>https://arxiv.org/abs/2408.09106</link>
      <description>arXiv:2408.09106v2 Announce Type: replace 
Abstract: Molecular optimization is a crucial aspect of drug discovery, aimed at refining molecular structures to enhance drug efficacy and minimize side effects, ultimately accelerating the overall drug development process. Many target-based molecular optimization methods have been proposed, significantly advancing drug discovery. These methods primarily on understanding the specific drug target structures or their hypothesized roles in combating diseases. However, challenges such as a limited number of available targets and a difficulty capturing clear structures hinder innovative drug development. In contrast, phenotypic drug discovery (PDD) does not depend on clear target structures and can identify hits with novel and unbiased polypharmacology signatures. As a result, PDD-based molecular optimization can reduce potential safety risks while optimizing phenotypic activity, thereby increasing the likelihood of clinical success. Therefore, we propose a fragment-masked molecular optimization method based on PDD (FMOP). FMOP employs a regression-free diffusion model to conditionally optimize the molecular masked regions without training, effectively generating new molecules with similar scaffolds. On the large-scale drug response dataset GDSCv2, we optimize the potential molecules across all 945 cell lines. The overall experiments demonstrate that the in-silico optimization success rate reaches 94.4%, with an average efficacy increase of 5.3%. Additionally, we conduct extensive ablation and visualization experiments, confirming that FMOP is an effective and robust molecular optimization method. The code is available at:https://anonymous.4open.science/r/FMOP-98C2.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09106v2</guid>
      <category>q-bio.BM</category>
      <category>cs.AI</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Kun Li, Xiantao Cai, Jia Wu, Bo Du, Wenbin Hu</dc:creator>
    </item>
    <item>
      <title>LipidBERT: A Lipid Language Model Pre-trained on METiS de novo Lipid Library</title>
      <link>https://arxiv.org/abs/2408.06150</link>
      <description>arXiv:2408.06150v3 Announce Type: replace-cross 
Abstract: In this study, we generate and maintain a database of 10 million virtual lipids through METiS's in-house de novo lipid generation algorithms and lipid virtual screening techniques. These virtual lipids serve as a corpus for pre-training, lipid representation learning, and downstream task knowledge transfer, culminating in state-of-the-art LNP property prediction performance. We propose LipidBERT, a BERT-like model pre-trained with the Masked Language Model (MLM) and various secondary tasks. Additionally, we compare the performance of embeddings generated by LipidBERT and PhatGPT, our GPT-like lipid generation model, on downstream tasks. The proposed bilingual LipidBERT model operates in two languages: the language of ionizable lipid pre-training, using in-house dry-lab lipid structures, and the language of LNP fine-tuning, utilizing in-house LNP wet-lab data. This dual capability positions LipidBERT as a key AI-based filter for future screening tasks, including new versions of METiS de novo lipid libraries and, more importantly, candidates for in vivo testing for orgran-targeting LNPs. To the best of our knowledge, this is the first successful demonstration of the capability of a pre-trained language model on virtual lipids and its effectiveness in downstream tasks using web-lab data. This work showcases the clever utilization of METiS's in-house de novo lipid library as well as the power of dry-wet lab integration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06150v3</guid>
      <category>cs.CL</category>
      <category>physics.chem-ph</category>
      <category>q-bio.BM</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tianhao Yu, Cai Yao, Zhuorui Sun, Feng Shi, Lin Zhang, Kangjie Lyu, Xuan Bai, Andong Liu, Xicheng Zhang, Jiali Zou, Wenshou Wang, Chris Lai, Kai Wang</dc:creator>
    </item>
  </channel>
</rss>
