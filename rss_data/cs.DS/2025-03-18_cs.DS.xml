<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 18 Mar 2025 04:00:13 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 18 Mar 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Enhanced Approximation Algorithms for the Capacitated Location Routing Problem</title>
      <link>https://arxiv.org/abs/2503.12502</link>
      <description>arXiv:2503.12502v1 Announce Type: new 
Abstract: The Capacitated Location Routing Problem is an important planning and routing problem in logistics, which generalizes the capacitated vehicle routing problem and the uncapacitated facility location problem. In this problem, we are given a set of depots and a set of customers where each depot has an opening cost and each customer has a demand. The goal is to open some depots and route capacitated vehicles from the opened depots to satisfy all customers' demand, while minimizing the total cost. In this paper, we propose a $4.169$-approximation algorithm for this problem, improving the best-known $4.38$-approximation ratio. Moreover, if the demand of each customer is allowed to be delivered by multiple tours, we propose a more refined $4.091$-approximation algorithm. Experimental study on benchmark instances shows that the quality of our computed solutions is better than that of the previous algorithm and is also much closer to optimality than the provable approximation factor.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.12502v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 18 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jingyang Zhao, Mingyu Xiao, Shunwang Wang</dc:creator>
    </item>
    <item>
      <title>Optimal mass estimation in the conditional sampling model</title>
      <link>https://arxiv.org/abs/2503.12518</link>
      <description>arXiv:2503.12518v1 Announce Type: new 
Abstract: The conditional sampling model, introduced by Cannone, Ron and Servedio (SODA 2014, SIAM J.\ Comput.\ 2015) and independently by Chakraborty, Fischer, Goldhirsh and Matsliah (ITCS 2013, SIAM J.\ Comput.\ 2016), is a common framework for a number of studies (and variant models) into strengthened models of distribution testing. A core task in these investigations is that of estimating the mass of individual elements. The above works, as well as the improvement of Kumar, Meel and Pote (AISTATS 2025), have all yielded polylogarithmic algorithms.
  In this work we shatter the polylogarithmic barrier, and provide an estimator for individual elements that uses only $O(\log \log N) + O(\mathrm{poly}(1/\varepsilon))$ conditional samples. This in particular provides an improvement (and in some cases a unifying framework) for a number of related tasks, such as testing by learning of any label-invariant property, and distance estimation between two (unknown) distribution.
  The work of Chakraborty, Chakraborty and Kumar (SODA 2024) contains lower bounds for some of the above tasks. We derive from their work a nearly matching lower bound of $\tilde\Omega(\log\log N)$ for the estimation task. We also show that the full power of the conditional model is indeed required for the double-logarithmic bound. For the testing of label-invariant properties, we exponentially improve the previous lower bound from double-logarithmic to $\Omega(\log N)$ conditional samples, whereas our testing by learning algorithm provides an upper bound of $O(\mathrm{poly}(1/\varepsilon)\cdot\log N \log \log N)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.12518v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 18 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tomer Adar, Eldar Fischer, Amit Levi</dc:creator>
    </item>
    <item>
      <title>Impact of Knowledge on the Cost of Treasure Hunt in Trees</title>
      <link>https://arxiv.org/abs/2503.13100</link>
      <description>arXiv:2503.13100v1 Announce Type: new 
Abstract: A mobile agent has to find an inert target in some environment that can be a graph or a terrain in the plane. This task is known as treasure hunt. We consider deterministic algorithms for treasure hunt in trees. Our goal is to establish the impact of different kinds of initial knowledge given to the agent on the cost of treasure hunt, defined as the total number of edge traversals until the agent reaches the treasure hidden in some node of the tree. The agent can be initially given either a complete map of the tree rooted at its starting node, with all port numbers marked, or a blind map of the tree rooted at its starting node but without port numbers. It may also be given, or not, the distance from the root to the treasure. This yields four different knowledge types that are partially ordered by their precision. (For example knowing the blind map and the distance is less precise than knowing the complete map and the distance). The penalty of a less precise knowledge type ${\cal T}_2$ over a more precise knowledge type ${\cal T}_1$ measures intuitively the worst-case ratio of the cost of an algorithm supplied with knowledge of type ${\cal T}_2$ over the cost of an algorithm supplied with knowledge of type ${\cal T}_1$. Our main results establish penalties for comparable knowledge types in this partial order. For knowledge types with known distance, the penalty for having a blind map over a complete map turns out to be very large. By contrast, for unknown distance, the penalty of having a blind map over having a complete map is small. When a map is provided (either complete or blind), the penalty of not knowing the distance over knowing it is medium.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13100v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 18 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1002/net.22075</arxiv:DOI>
      <arxiv:journal_reference>Networks. 80 (2022), 51-62</arxiv:journal_reference>
      <dc:creator>S\'ebastien Bouchard, Arnaud Labourel, Andrzej Pelc</dc:creator>
    </item>
    <item>
      <title>Parallel Minimum Cost Flow in Near-Linear Work and Square Root Depth for Dense Instances</title>
      <link>https://arxiv.org/abs/2503.13274</link>
      <description>arXiv:2503.13274v1 Announce Type: new 
Abstract: For $n$-vertex $m$-edge graphs with integer polynomially-bounded costs and capacities, we provide a randomized parallel algorithm for the minimum cost flow problem with $\tilde O(m+n^ {1.5})$ work and $\tilde O(\sqrt{n})$ depth. On moderately dense graphs ($m&gt;n^{1.5}$), our algorithm is the first one to achieve both near-linear work and sub-linear depth. Previous algorithms are either achieving almost optimal work but are highly sequential [Chen, Kyng, Liu, Peng, Gutenberg, Sachdev, FOCS'22], or achieving sub-linear depth but use super-linear work, [Lee, Sidford, FOCS'14], [Orlin, Stein, Oper. Res. Lett.'93]. Our result also leads to improvements for the special cases of max flow, bipartite maximum matching, shortest paths, and reachability. Notably, the previous algorithms achieving near-linear work for shortest paths and reachability all have depth $n^{o(1)}\cdot \sqrt{n}$ [Fischer, Haeupler, Latypov, Roeyskoe, Sulser, SOSA'25], [Liu, Jambulapati, Sidford, FOCS'19].
  Our algorithm consists of a parallel implementation of [van den Brand, Lee, Liu, Saranurak, Sidford, Song, Wang, STOC'21]. One important building block is a \emph{dynamic} parallel expander decomposition, which we show how to obtain from the recent parallel expander decomposition of [Chen, Meierhans, Probst Gutenberh, Saranurak, SODA'25].</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13274v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 18 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jan van den Brand, Hossein Gholizadeh, Yonggang Jiang, Tijn de Vos</dc:creator>
    </item>
    <item>
      <title>Hierarchical Multicriteria Shortest Path Search</title>
      <link>https://arxiv.org/abs/2503.13314</link>
      <description>arXiv:2503.13314v1 Announce Type: new 
Abstract: This paper presents a novel multicriteria shortest path search algorithm called Hierarchical MLS. The distinguishing feature of the algorithm is the multilayered structure of compressed k-Path-Cover graphs it operates on. In addition to providing significant improvements in terms of time and memory consumption, the algorithm is notable for several other features. Due to the preprocessing phase requiring only several seconds, the algorithm can be successfully applied to scenarios with dynamic prices. Moreover, the algorithm does not employ bidirectional search, and can thus work on time-dependent metrics. We test the algorithm on multiple graphs and analyze its performance in terms of time and memory efficiency. The results prove Hierarchical MLS to be faster than its direct alternatives by at least 2 times in terms of query runtime and at least 20 times in terms of preprocessing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13314v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 18 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Temirlan Kurbanov, Linxiao Miao, Ji\v{r}\'i Vok\v{r}\'inek</dc:creator>
    </item>
    <item>
      <title>A $(1+\epsilon)$-Approximation for Ultrametric Embedding in Subquadratic Time</title>
      <link>https://arxiv.org/abs/2503.13409</link>
      <description>arXiv:2503.13409v1 Announce Type: new 
Abstract: Efficiently computing accurate representations of high-dimensional data is essential for data analysis and unsupervised learning. Dendrograms, also known as ultrametrics, are widely used representations that preserve hierarchical relationships within the data. However, popular methods for computing them, such as linkage algorithms, suffer from quadratic time and space complexity, making them impractical for large datasets.
  The "best ultrametric embedding" (a.k.a. "best ultrametric fit") problem, which aims to find the ultrametric that best preserves the distances between points in the original data, is known to require at least quadratic time for an exact solution.
  Recent work has focused on improving scalability by approximating optimal solutions in subquadratic time, resulting in a $(\sqrt{2} + \epsilon)$-approximation (Cohen-Addad, de Joannis de Verclos and Lagarde, 2021).
  In this paper, we present the first subquadratic algorithm that achieves arbitrarily precise approximations of the optimal ultrametric embedding. Specifically, we provide an algorithm that, for any $c \geq 1$, outputs a $c$-approximation of the best ultrametric in time $\tilde{O}(n^{1 + 1/c})$. In particular, for any fixed $\epsilon &gt; 0$, the algorithm computes a $(1+\epsilon)$-approximation in time $\tilde{O}(n^{2 - \epsilon + o(\epsilon^2)})$.
  Experimental results show that our algorithm improves upon previous methods in terms of approximation quality while maintaining comparable running times.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13409v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 18 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gabriel Bathie, Guillaume Lagarde</dc:creator>
    </item>
    <item>
      <title>A Quantum Algorithm for the Classification of Patterns of Boolean Functions</title>
      <link>https://arxiv.org/abs/2503.11722</link>
      <description>arXiv:2503.11722v1 Announce Type: cross 
Abstract: This paper introduces a novel quantum algorithm that is able to classify a hierarchy of classes of imbalanced Boolean functions. The fundamental characteristic of imbalanced Boolean functions is that the proportion of elements in their domain that take the value $0$ is not equal to the proportion of elements that take the value $1$. For every positive integer $n$, the hierarchy contains a class of Boolean functions defined based on their behavioral pattern. The common trait of all the functions belonging to the same class is that they possess the same imbalance ratio. Our algorithm achieves classification in a straightforward manner as the final measurement reveals the unknown function with probability $1$. Let us also note that the proposed algorithm is an optimal oracular algorithm because it can classify the aforementioned functions with a single query to the oracle. At the same time we explain in detail the methodology we followed to design this algorithm in the hope that it will prove general and fruitful, given that it can be easily modified and extended to address other classes of imbalanced Boolean functions that exhibit different behavioral patterns.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.11722v1</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <pubDate>Tue, 18 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Theodore Andronikos, Constantinos Bitsakos, Konstantinos Nikas, Georgios I. Goumas, Nectarios Koziris</dc:creator>
    </item>
    <item>
      <title>Local Pan-Privacy for Federated Analytics</title>
      <link>https://arxiv.org/abs/2503.11850</link>
      <description>arXiv:2503.11850v1 Announce Type: cross 
Abstract: Pan-privacy was proposed by Dwork et al. as an approach to designing a private analytics system that retains its privacy properties in the face of intrusions that expose the system's internal state. Motivated by federated telemetry applications, we study local pan-privacy, where privacy should be retained under repeated unannounced intrusions on the local state. We consider the problem of monitoring the count of an event in a federated system, where event occurrences on a local device should be hidden even from an intruder on that device. We show that under reasonable constraints, the goal of providing information-theoretic differential privacy under intrusion is incompatible with collecting telemetry information. We then show that this problem can be solved in a scalable way using standard cryptographic primitives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.11850v1</guid>
      <category>cs.CR</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Tue, 18 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vitaly Feldman, Audra McMillan, Guy N. Rothblum, Kunal Talwar</dc:creator>
    </item>
    <item>
      <title>PREAMBLE: Private and Efficient Aggregation of Block Sparse Vectors and Applications</title>
      <link>https://arxiv.org/abs/2503.11897</link>
      <description>arXiv:2503.11897v1 Announce Type: cross 
Abstract: We revisit the problem of secure aggregation of high-dimensional vectors in a two-server system such as Prio. These systems are typically used to aggregate vectors such as gradients in private federated learning, where the aggregate itself is protected via noise addition to ensure differential privacy. Existing approaches require communication scaling with the dimensionality, and thus limit the dimensionality of vectors one can efficiently process in this setup.
  We propose PREAMBLE: Private Efficient Aggregation Mechanism for BLock-sparse Euclidean Vectors. PREAMBLE is a novel extension of distributed point functions that enables communication- and computation-efficient aggregation of block-sparse vectors, which are sparse vectors where the non-zero entries occur in a small number of clusters of consecutive coordinates. We then show that PREAMBLE can be combined with random sampling and privacy amplification by sampling results, to allow asymptotically optimal privacy-utility trade-offs for vector aggregation, at a fraction of the communication cost. When coupled with recent advances in numerical privacy accounting, our approach incurs a negligible overhead in noise variance, compared to the Gaussian mechanism used with Prio.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.11897v1</guid>
      <category>cs.CR</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Tue, 18 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hilal Asi, Vitaly Feldman, Hannah Keller, Guy N. Rothblum, Kunal Talwar</dc:creator>
    </item>
    <item>
      <title>Changing Base Without Losing Pace: A GPU-Efficient Alternative to MatMul in DNNs</title>
      <link>https://arxiv.org/abs/2503.12211</link>
      <description>arXiv:2503.12211v1 Announce Type: cross 
Abstract: We propose a cheaper alternative bilinear operator to matrix-multiplication in deep neural networks (DNNs). Unlike many stubborn attempts to accelerate MatMuls in DNN inference, this operator is supported by capabilities of existing GPU hardware, most notably NVIDIA TensorCores. To our knowledge, this is the first GPU-native acceleration technique which \emph{does not decrease} (in fact, increases) the number of trainable parameters of the network, mitigating the accuracy-loss of compression-based techniques. Hence, this operator is at the same time more expressive than MatMul, yet requires substantially \emph{fewer} FLOPs to evaluate. We term this new operator \emph{Strassen-Tile} (STL).
  The main idea behind STL$(X,W)$ is a \emph{local} change-of-basis (learnable encoder) on weights and activation \emph{tiles}, after which we perform batched \emph{elementwise} products between tiles, and a final decoding transformation (inspired by algebraic pipelines from fast matrix and polynomial multiplication).
  We compare STL against two benchmarks. The first one is SoTA T2T-ViT on Imagenet-1K. Here we show that replacing \emph{all} linear layers with STL and training from scratch, results in factor x2.7 reduction in FLOPs with a 0.5 \emph{accuracy improvement}. Our second speed-accuracy comparison benchmark for pretrained LLMs is the most practical GPU-acceleration technique, \twofour structured Sparsity. Finetuning TinyLlama \cite{tinyllama24} with STL layers on the Slim Pajama dataset, achieves similar accuracy to 2:4, with x2.2 FLOP speedup compared to x1.7 of the latter.
  Finally, we discuss a group-theoretic approach for discovering \emph{universal} encoders for STL, which could lead to fast \emph{black-box} acceleration via approximate matrix-multiplication (AMM).</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.12211v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.DS</category>
      <pubDate>Tue, 18 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nir Ailon, Akhiad Bercovich, Omri Weinstein</dc:creator>
    </item>
    <item>
      <title>Constant Approximation of Fr\'echet Distance in Strongly Subquadratic Time</title>
      <link>https://arxiv.org/abs/2503.12746</link>
      <description>arXiv:2503.12746v1 Announce Type: cross 
Abstract: Let $\tau$ and $\sigma$ be two polygonal curves in $\mathbb{R}^d$ for any fixed $d$. Suppose that $\tau$ and $\sigma$ have $n$ and $m$ vertices, respectively, and $m\le n$. While conditional lower bounds prevent approximating the Fr\'echet distance between $\tau$ and $\sigma$ within a factor of 3 in strongly subquadratic time, the current best approximation algorithm attains a ratio of $n^c$ in strongly subquadratic time, for some constant $c\in(0,1)$. We present a randomized algorithm with running time $O(nm^{0.99}\log(n/\varepsilon))$ that approximates the Fr\'echet distance within a factor of $7+\varepsilon$, with a success probability at least $1-1/n^6$. We also adapt our techniques to develop a randomized algorithm that approximates the \emph{discrete} Fr\'echet distance within a factor of $7+\varepsilon$ in strongly subquadratic time. They are the first algorithms to approximate the Fr\'echet distance and the discrete Fr\'echet distance within constant factors in strongly subquadratic time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.12746v1</guid>
      <category>cs.CG</category>
      <category>cs.DS</category>
      <pubDate>Tue, 18 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Siu-Wing Cheng, Haoqiang Huang, Shuo Zhang</dc:creator>
    </item>
    <item>
      <title>Semi-Streaming Algorithms for Graph Property Certification</title>
      <link>https://arxiv.org/abs/2503.12996</link>
      <description>arXiv:2503.12996v1 Announce Type: cross 
Abstract: We introduce the {\em certification} of solutions to graph problems when access to the input is restricted. This topic has received a lot of attention in the distributed computing setting, and we introduce it here in the context of \emph{streaming} algorithms, where the input is too large to be stored in memory.
  Given a graph property $\mbox{P}$, a \emph{streaming certification scheme} for $\mbox{P}$ is a \emph{prover-verifier} pair where the prover is a computationally unlimited but non-trustable oracle, and the verifier is a streaming algorithm. For any input graph, the prover provides the verifier with a \emph{certificate}. The verifier then receives the input graph as a stream of edges in an adversarial order, and must check whether the certificate is indeed a \emph{proof} that the input graph satisfies $\mbox{P}$. The main complexity measure for a streaming certification scheme is its \emph{space complexity}, defined as the sum of the size of the certificate provided by the oracle, and of the memory space required by the verifier.
  We give streaming certification schemes for several graph properties, including maximum matching, diameter, degeneracy, and coloring, with space complexity matching the requirement of \emph{semi-streaming}, i.e., with space complexity $O(n\,\mbox{polylog}\, n)$ for $n$-node graphs. All these problems do {\em not} admit semi-streaming algorithms, showing that also in the (semi) streaming setting, certification is sometimes easier than calculation (like $NP$). For each of these properties, we provide upper and lower bounds on the space complexity of the corresponding certification schemes, many being tight up to logarithmic multiplicative factors. We also show that some graph properties are hard for streaming certification, in the sense that they cannot be certified in semi-streaming, as they require $\Omega(n^2)$-bit certificates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.12996v1</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Tue, 18 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Avinandan Das, Pierre Fraigniaud, Ami Paz, Adi Rosen</dc:creator>
    </item>
    <item>
      <title>Connected Partitions via Connected Dominating Sets</title>
      <link>https://arxiv.org/abs/2503.13112</link>
      <description>arXiv:2503.13112v1 Announce Type: cross 
Abstract: The classical theorem due to Gy\H{o}ri and Lov\'{a}sz states that any $k$-connected graph $G$ admits a partition into $k$ connected subgraphs, where each subgraph has a prescribed size and contains a prescribed vertex, as soon as the total size of target subgraphs is equal to the size of $G$. However, this result is notoriously evasive in terms of efficient constructions, and it is still unknown whether such a partition can be computed in polynomial time, even for $k = 5$.
  We make progress towards an efficient constructive version of the Gy\H{o}ri--Lov\'{a}sz theorem by considering a natural weakening of the $k$-connectivity requirement. Specifically, we show that the desired connected partition can be found in polynomial time, if $G$ contains $k$ disjoint connected dominating sets. As a consequence of this result, we give several efficient approximate and exact constructive versions of the original Gy\H{o}ri--Lov\'{a}sz theorem:
  1. On general graphs, a Gy\H{o}ri--Lov\'{a}sz partition with $k$ parts can be computed in polynomial time when the input graph has connectivity $\Omega(k \cdot \log^2 n)$;
  2. On convex bipartite graphs, connectivity of $4k$ is sufficient;
  3. On biconvex graphs and interval graphs, connectivity of $k$ is sufficient, meaning that our algorithm gives a ``true'' constructive version of the theorem on these graph classes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13112v1</guid>
      <category>math.CO</category>
      <category>cs.DS</category>
      <pubDate>Tue, 18 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Aikaterini Niklanovits, Kirill Simonov, Shaily Verma, Ziena Zeif</dc:creator>
    </item>
    <item>
      <title>Follow-the-Regularized-Leader with Adversarial Constraints</title>
      <link>https://arxiv.org/abs/2503.13366</link>
      <description>arXiv:2503.13366v1 Announce Type: cross 
Abstract: Constrained Online Convex Optimization (COCO) can be seen as a generalization of the standard Online Convex Optimization (OCO) framework. At each round, a cost function and constraint function are revealed after a learner chooses an action. The goal is to minimize both the regret and cumulative constraint violation (CCV) against an adaptive adversary. We show for the first time that is possible to obtain the optimal $O(\sqrt{T})$ bound on both regret and CCV, improving the best known bounds of $O \left( \sqrt{T} \right)$ and $\~{O} \left( \sqrt{T} \right)$ for the regret and CCV, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13366v1</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 18 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ricardo N. Ferreira, Cl\'audia Soares</dc:creator>
    </item>
    <item>
      <title>Deciding if a DAG is Interesting is Hard</title>
      <link>https://arxiv.org/abs/2503.13398</link>
      <description>arXiv:2503.13398v1 Announce Type: cross 
Abstract: The \emph{interestingness score} of a directed path $\Pi = e_1, e_2, e_3, \dots, e_\ell$ in an edge-weighted directed graph $G$ is defined as $\texttt{score}(\Pi) := \sum_{i=1}^\ell w(e_i) \cdot \log{(i+1)}$, where $w(e_i)$ is the weight of the edge $e_i$. We consider two optimization problems that arise in the analysis of Mapper graphs, which is a powerful tool in topological data analysis. In the IP problem, the objective is to find a collection $\mathcal{P}$ of edge-disjoint paths in $G$ with the maximum total interestingness score. %; that is, two raised to the power of the sum of the weights of the paths in $\mathcal{P}$. For $k \in \mathbb{N}$, the $k$-IP problem is a variant of the IP problem with the extra constraint that each path in $\mathcal{P}$ must have exactly $k$ edges. Kalyanaraman, Kamruzzaman, and Krishnamoorthy (Journal of Computational Geometry, 2019) claim that both IP and $k$-IP (for $k \geq 3$) are NP-complete. We point out some inaccuracies in their proofs. Furthermore, we show that both problems are NP-hard in directed acyclic graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13398v1</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <pubDate>Tue, 18 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jean-Lou De Carufel, Anil Maheshwari, Saeed Odak, Bodhayan Roy, Michiel Smid, Marc Vicuna</dc:creator>
    </item>
    <item>
      <title>Metric Dimension and Geodetic Set Parameterized by Vertex Cover</title>
      <link>https://arxiv.org/abs/2405.01344</link>
      <description>arXiv:2405.01344v2 Announce Type: replace 
Abstract: For a graph $G$, a subset $S\subseteq V(G)$ is called a resolving set of $G$ if, for any two vertices $u,v\in V(G)$, there exists a vertex $w\in S$ such that $d(w,u)\neq d(w,v)$. The Metric Dimension problem takes as input a graph $G$ on $n$ vertices and a positive integer $k$, and asks whether there exists a resolving set of size at most $k$. In another metric-based graph problem, Geodetic Set, the input is a graph $G$ and an integer $k$, and the objective is to determine whether there exists a subset $S\subseteq V(G)$ of size at most $k$ such that, for any vertex $u \in V(G)$, there are two vertices $s_1, s_2 \in S$ such that $u$ lies on a shortest path from $s_1$ to $s_2$.
  These two classical problems turn out to be intractable with respect to the natural parameter, i.e., the solution size, as well as most structural parameters, including the feedback vertex set number and pathwidth. Some of the very few existing tractable results state that they are both FPT with respect to the vertex cover number $vc$.
  More precisely, we observe that both problems admit an FPT algorithm running in time $2^{\mathcal{O}(vc^2)}\cdot n^{\mathcal{O}(1)}$, and a kernelization algorithm that outputs a kernel with $2^{\mathcal{O}(vc)}$ vertices. We prove that unless the Exponential Time Hypothesis fails, Metric Dimension and Geodetic Set, even on graphs of bounded diameter, neither admit an FPT algorithm running in time $2^{o(vc^2)}\cdot n^{\mathcal(1)}$, nor a kernelization algorithm that reduces the solution size and outputs a kernel with $2^{o(vc)}$ vertices. The versatility of our technique enables us to apply it to both these problems.
  We only know of one other problem in the literature that admits such a tight lower bound. Similarly, the list of known problems with exponential lower bounds on the number of vertices in kernelized instances is very short.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.01344v2</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <pubDate>Tue, 18 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Florent Foucaud, Esther Galby, Liana Khazaliya, Shaohua Li, Fionn Mc Inerney, Roohani Sharma, Prafullkumar Tale</dc:creator>
    </item>
    <item>
      <title>Navigable Graphs for High-Dimensional Nearest Neighbor Search: Constructions and Limits</title>
      <link>https://arxiv.org/abs/2405.18680</link>
      <description>arXiv:2405.18680v4 Announce Type: replace 
Abstract: There has been significant recent interest in graph-based nearest neighbor search methods, many of which are centered on the construction of navigable graphs over high-dimensional point sets. A graph is navigable if we can successfully move from any starting node to any target node using a greedy routing strategy where we always move to the neighbor that is closest to the destination according to a given distance function. The complete graph is navigable for any point set, but the important question for applications is if sparser graphs can be constructed. While this question is fairly well understood in low-dimensions, we establish some of the first upper and lower bounds for high-dimensional point sets. First, we give a simple and efficient way to construct a navigable graph with average degree $O(\sqrt{n \log n })$ for any set of $n$ points, in any dimension, for any distance function. We compliment this result with a nearly matching lower bound: even under the Euclidean metric in $O(\log n)$ dimensions, a random point set has no navigable graph with average degree $O(n^{\alpha})$ for any $\alpha &lt; 1/2$. Our lower bound relies on sharp anti-concentration bounds for binomial random variables, which we use to show that the near-neighborhoods of a set of random points do not overlap significantly, forcing any navigable graph to have many edges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.18680v4</guid>
      <category>cs.DS</category>
      <category>cs.CG</category>
      <category>cs.DB</category>
      <category>cs.LG</category>
      <pubDate>Tue, 18 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haya Diwan, Jinrui Gou, Cameron Musco, Christopher Musco, Torsten Suel</dc:creator>
    </item>
    <item>
      <title>Improving Merge Sort and Quick Sort Performance by Utilizing Alphadev's Sorting Networks as Base Cases</title>
      <link>https://arxiv.org/abs/2503.05934</link>
      <description>arXiv:2503.05934v3 Announce Type: replace 
Abstract: Recent work by Google DeepMind introduced assembly-optimized sorting networks that achieve faster performance for small fixed-size arrays (3-8). In this research, we investigate the integration of these networks as base cases in classical divide-and-conquer sorting algorithms, specifically Merge Sort and Quick Sort, to leverage these efficient sorting networks for small subarrays generated during the recursive process. We conducted benchmarks with 11 different optimization configurations and compared them to classical Merge Sort and Quick Sort. We tested the configurations with random, sorted and nearly sorted arrays.
  Our optimized Merge Sort, using a configuration of three sorting networks (sizes 6, 7, and 8), achieves at least 1.5x speedup for random and nearly sorted arrays, and at least 2x speedup for sorted arrays, in comparison to classical Merge Sort. This optimized Merge Sort surpasses both classical Quick Sort and similarly optimized Quick Sort variants when sorting random arrays of size 10,000 and larger.
  When comparing our optimized Quick Sort to classical Quick Sort, we observe a 1.5x speedup using the 3-to-5 configuration on sorted arrays of size 10,000. The 6-to-8 configuration maintains a consistent 1.5x improvement across sorted arrays from 25,000 to 1 million elements. Our findings demonstrate the potential of integrating AI-optimized sorting networks to enhance the performance of classical sorting algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.05934v3</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Tue, 18 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3696673.3723083</arxiv:DOI>
      <dc:creator>Anas Gamal Aly, Anders E. Jensen, Hala ElAarag</dc:creator>
    </item>
    <item>
      <title>Problems in NP can Admit Double-Exponential Lower Bounds when Parameterized by Treewidth or Vertex Cover</title>
      <link>https://arxiv.org/abs/2307.08149</link>
      <description>arXiv:2307.08149v5 Announce Type: replace-cross 
Abstract: Treewidth (tw) is an important parameter that, when bounded, yields tractability for many problems. For example, graph problems expressible in Monadic Second Order (MSO) logic and QUANTIFIED SAT or, more generally, QUANTIFIED CSP, are FPT parameterized by the tw of the input's (primal) graph plus the length of the MSO-formula [Courcelle, Information &amp; Computation 1990] and the quantifier rank [Chen, ECAI 2004], resp. The algorithms from these (meta-)results have running times whose dependence on tw is a tower of exponents. A conditional lower bound by Fichte et al. [LICS 2020] shows that, for QUANTIFIED SAT, the height of this tower is equal to the number of quantifier alternations. Lower bounds showing that at least double-exponential factors in the running time are necessary are rare: there are very few (for tw and vertex cover vc parameterizations) and they are for problems that are complete for #NP, $\Sigma_2^p$, $\Pi_2^p$, or higher levels of the polynomial hierarchy.
  We show, for the first time, that it is not necessary to go higher up in the polynomial hierarchy to obtain such lower bounds. We design a novel, yet simple versatile technique based on Sperner families to obtain such lower bounds and apply it to 3 problems: METRIC DIMENSION, STRONG METRIC DIMENSION, and GEODETIC SET. We prove that they do not admit $2^{2^{o(tw)}} \cdot n^{O(1)}$-time algorithms, even on bounded diameter graphs, unless the ETH fails. For STRONG METRIC DIMENSION, the lower bound holds even for vc. We complement our lower bounds with matching upper bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.08149v5</guid>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <pubDate>Tue, 18 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Florent Foucaud, Esther Galby, Liana Khazaliya, Shaohua Li, Fionn Mc Inerney, Roohani Sharma, Prafullkumar Tale</dc:creator>
    </item>
    <item>
      <title>Continuous optimization methods for the graph isomorphism problem</title>
      <link>https://arxiv.org/abs/2311.16912</link>
      <description>arXiv:2311.16912v2 Announce Type: replace-cross 
Abstract: The graph isomorphism problem looks deceptively simple, but although polynomial-time algorithms exist for certain types of graphs such as planar graphs and graphs with bounded degree or eigenvalue multiplicity, its complexity class is still unknown. Information about potential isomorphisms between two graphs is contained in the eigenvalues and eigenvectors of their adjacency matrices. However, symmetries of graphs often lead to repeated eigenvalues so that associated eigenvectors are determined only up to basis rotations, which complicates graph isomorphism testing. We consider orthogonal and doubly stochastic relaxations of the graph isomorphism problem, analyze the geometric properties of the resulting solution spaces, and show that their complexity increases significantly if repeated eigenvalues exist. By restricting the search space to suitable subspaces, we derive an efficient Frank-Wolfe based continuous optimization approach for detecting isomorphisms. We illustrate the efficacy of the algorithm with the aid of various highly symmetric graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.16912v2</guid>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <pubDate>Tue, 18 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stefan Klus, Patrick Gel{\ss}</dc:creator>
    </item>
    <item>
      <title>Space Complexity of Euclidean Clustering</title>
      <link>https://arxiv.org/abs/2403.02971</link>
      <description>arXiv:2403.02971v3 Announce Type: replace-cross 
Abstract: The $(k, z)$-Clustering problem in Euclidean space $\mathbb{R}^d$ has been extensively studied. Given the scale of data involved, compression methods for the Euclidean $(k, z)$-Clustering problem, such as data compression and dimension reduction, have received significant attention in the literature. However, the space complexity of the clustering problem, specifically, the number of bits required to compress the cost function within a multiplicative error $\varepsilon$, remains unclear in existing literature. This paper initiates the study of space complexity for Euclidean $(k, z)$-Clustering and offers both upper and lower bounds. Our space bounds are nearly tight when $k$ is constant, indicating that storing a coreset, a well-known data compression approach, serves as the optimal compression scheme. Furthermore, our lower bound result for $(k, z)$-Clustering establishes a tight space bound of $\Theta( n d )$ for terminal embedding, where $n$ represents the dataset size. Our technical approach leverages new geometric insights for principal angles and discrepancy methods, which may hold independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02971v3</guid>
      <category>cs.CG</category>
      <category>cs.DS</category>
      <pubDate>Tue, 18 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TIT.2025.3550192</arxiv:DOI>
      <dc:creator>Xiaoyi Zhu, Yuxiang Tian, Lingxiao Huang, Zengfeng Huang</dc:creator>
    </item>
    <item>
      <title>Accelerating Sparse Tensor Decomposition Using Adaptive Linearized Representation</title>
      <link>https://arxiv.org/abs/2403.06348</link>
      <description>arXiv:2403.06348v2 Announce Type: replace-cross 
Abstract: High-dimensional sparse data emerge in many critical application domains such as healthcare and cybersecurity. To extract meaningful insights from massive volumes of these multi-dimensional data, scientists employ unsupervised analysis tools based on tensor decomposition (TD) methods. However, real-world sparse tensors exhibit highly irregular shapes and data distributions, which pose significant challenges for making efficient use of modern parallel processors. This study breaks the prevailing assumption that compressing sparse tensors into coarse-grained structures or along a particular dimension/mode is more efficient than keeping them in a fine-grained, mode-agnostic form. Our novel sparse tensor representation, Adaptive Linearized Tensor Order (ALTO), encodes tensors in a compact format that can be easily streamed from memory and is amenable to both caching and parallel execution. In contrast to existing compressed tensor formats, ALTO constructs one tensor copy that is agnostic to both the mode orientation and the irregular distribution of nonzero elements. To demonstrate the efficacy of ALTO, we propose a set of parallel TD algorithms that exploit the inherent data reuse of tensor computations to substantially reduce synchronization overhead, decrease memory footprint, and improve parallel performance. Additionally, we characterize the major execution bottlenecks of TD methods on the latest Intel Xeon Scalable processors and introduce dynamic adaptation heuristics to automatically select the best algorithm based on the sparse tensor characteristics. Across a diverse set of real-world data sets, ALTO outperforms the state-of-the-art approaches, achieving more than an order-of-magnitude speedup over the best mode-agnostic formats. Compared to the best mode-specific formats, ALTO achieves 5.1X geometric mean speedup at a fraction (25%) of their storage costs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06348v2</guid>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <category>cs.PF</category>
      <pubDate>Tue, 18 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jan Laukemann, Ahmed E. Helal, S. Isaac Geronimo Anderson, Fabio Checconi, Yongseok Soh, Jesmin Jahan Tithi, Teresa Ranadive, Brian J Gravelle, Fabrizio Petrini, Jee Choi</dc:creator>
    </item>
    <item>
      <title>BinomialHash: A Constant Time, Minimal Memory Consistent Hash Algorithm</title>
      <link>https://arxiv.org/abs/2406.19836</link>
      <description>arXiv:2406.19836v2 Announce Type: replace-cross 
Abstract: Consistent hashing is a technique for distributing data across a network of nodes in a way that minimizes reorganization when nodes join or leave the network. It is extensively applied in modern distributed systems as a fundamental mechanism for routing and data placement. Similarly, distributed storage systems rely on consistent hashing for scalable and fault-tolerant data partitioning. This paper introduces BinomialHash, a consistent hashing algorithm that executes in constant time and requires minimal memory. We provide a detailed explanation of the algorithm, present a pseudo-code implementation, and formally establish its strong theoretical guarantees. Finally, we compare its performance against state-of-the-art constant-time consistent hashing algorithms, demonstrating that our solution is both highly competitive and effective, while also validating the theoretical boundaries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19836v2</guid>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <pubDate>Tue, 18 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Massimo Coluzzi, Amos Brocco, Alessandro Antonucci, Tiziano Leidi</dc:creator>
    </item>
    <item>
      <title>Parameterized Complexity of (d,r)-Domination via Modular Decomposition</title>
      <link>https://arxiv.org/abs/2412.15671</link>
      <description>arXiv:2412.15671v2 Announce Type: replace-cross 
Abstract: With the rise of social media, misinformation has significant negative effects on the decision-making of individuals, organizations and communities within society. Identifying and mitigating the spread of fake information is a challenging issue. We consider a generalization of the Domination problem that can be used to detect a set of individuals who, through an awareness process, can prevent the spreading of fake narratives. The considered problem, named \textsc{$(d,r)$-Domination} generalizes both distance and multiple domination. We study the parameterized complexity of the problem according to standard and structural parameters. We give fixed-parameter algorithms as well as polynomial compressions/kernelizations for some variants of the problem and parameter combinations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.15671v2</guid>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <pubDate>Tue, 18 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gennaro Cordasco, Luisa Gargano, Adele A. Rescigno</dc:creator>
    </item>
  </channel>
</rss>
