<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.ST updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.ST</link>
    <description>math.ST updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.ST" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 06 May 2025 02:29:25 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Robust Generalization of the Active Subspace Method</title>
      <link>https://arxiv.org/abs/2505.00711</link>
      <description>arXiv:2505.00711v1 Announce Type: new 
Abstract: We introduce a new global sensitivity measure called global activity score. The new measure is obtained from the global active subspace method, similar to the way the activity score measure is obtained from the active subspace method. We present theoretical results on the relationship between Sobol' sensitivity indices and global activity scores. We present numerical examples where we compare the results of the global sensitivity analysis of some models using Sobol' sensitivity indices, derivative-based sensitivity measures, activity scores, and global activity scores. The numerical results reveal the scenarios when the global activity score has advantages over derivative-based sensitivity measures and activity scores, and when the three measures give similar results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00711v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruilong Yue, Giray \"Okten</dc:creator>
    </item>
    <item>
      <title>Asymmetric Penalties Underlie Proper Loss Functions in Probabilistic Forecasting</title>
      <link>https://arxiv.org/abs/2505.00937</link>
      <description>arXiv:2505.00937v1 Announce Type: new 
Abstract: Accurately forecasting the probability distribution of phenomena of interest is a classic and ever more widespread goal in statistics and decision theory. In comparison to point forecasts, probabilistic forecasts aim to provide a more complete and informative characterization of the target variable. This endeavor is only fruitful, however, if a forecast is "close" to the distribution it attempts to predict. The role of a loss function -- also known as a scoring rule -- is to make this precise by providing a quantitative measure of proximity between a forecast distribution and target random variable. Numerous loss functions have been proposed in the literature, with a strong focus on proper losses, that is, losses whose expectations are minimized when the forecast distribution is the same as the target. In this paper, we show that a broad class of proper loss functions penalize asymmetrically, in the sense that underestimating a given parameter of the target distribution can incur larger loss than overestimating it, or vice versa. Our theory covers many popular losses, such as the logarithmic, continuous ranked probability, quadratic, and spherical losses, as well as the energy and threshold-weighted generalizations of continuous ranked probability loss. To complement our theory, we present experiments with real epidemiological, meteorological, and retail forecast data sets. Further, as an implication of the loss asymmetries revealed by our work, we show that hedging is possible under a setting of distribution shift.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00937v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Erez Buchweitz, Jo\~ao Vitor Romano, Ryan J. Tibshirani</dc:creator>
    </item>
    <item>
      <title>Rerandomization for covariate balance mitigates p-hacking in regression adjustment</title>
      <link>https://arxiv.org/abs/2505.01137</link>
      <description>arXiv:2505.01137v1 Announce Type: new 
Abstract: Rerandomization enforces covariate balance across treatment groups in the design stage of experiments. Despite its intuitive appeal, its theoretical justification remains unsatisfying because its benefits of improving efficiency for estimating the average treatment effect diminish if we use regression adjustment in the analysis stage. To strengthen the theory of rerandomization, we show that it mitigates false discoveries resulting from $p$-hacking, the practice of strategically selecting covariates to get more significant $p$-values. Moreover, we show that rerandomization with a sufficiently stringent threshold can resolve $p$-hacking. As a byproduct, our theory offers guidance for choosing the threshold in rerandomization in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01137v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xin Lu, Peng Ding</dc:creator>
    </item>
    <item>
      <title>Model-free identification in ill-posed regression</title>
      <link>https://arxiv.org/abs/2505.01297</link>
      <description>arXiv:2505.01297v1 Announce Type: new 
Abstract: The problem of parsimonious parameter identification in possibly high-dimensional linear regression with highly correlated features is addressed. This problem is formalized as the estimation of the best, in a certain sense, linear combinations of the features that are relevant to the response variable. Importantly, the dependence between the features and the response is allowed to be arbitrary. Necessary and sufficient conditions for such parsimonious identification -- referred to as statistical interpretability -- are established for a broad class of linear dimensionality reduction algorithms. Sharp bounds on their estimation errors, with high probability, are derived. To our knowledge, this is the first formal framework that enables the definition and assessment of the interpretability of a broad class of algorithms. The results are specifically applied to methods based on sparse regression, unsupervised projection and sufficient reduction. The implications of employing such methods for prediction problems are discussed in the context of the prolific literature on overparametrized methods in the regime of benign overfitting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01297v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gianluca Finocchio, Tatyana Krivobokova</dc:creator>
    </item>
    <item>
      <title>Multi-Step Consistency Models: Fast Generation with Theoretical Guarantees</title>
      <link>https://arxiv.org/abs/2505.01049</link>
      <description>arXiv:2505.01049v1 Announce Type: cross 
Abstract: Consistency models have recently emerged as a compelling alternative to traditional SDE based diffusion models, offering a significant acceleration in generation by producing high quality samples in very few steps. Despite their empirical success, a proper theoretic justification for their speed up is still lacking. In this work, we provide the analysis which bridges this gap, showing that given a consistency model which can map the input at a given time to arbitrary timestamps along the reverse trajectory, one can achieve KL divergence of order $ O(\varepsilon^2) $ using only $ O\left(\log\left(\frac{d}{\varepsilon}\right)\right) $ iterations with constant step size, where d is the data dimension. Additionally, under minimal assumptions on the data distribution an increasingly common setting in recent diffusion model analyses we show that a similar KL convergence guarantee can be obtained, with the number of steps scaling as $ O\left(d \log\left(\frac{d}{\varepsilon}\right)\right) $. Going further, we also provide a theoretical analysis for estimation of such consistency models, concluding that accurate learning is feasible using small discretization steps, both in smooth and non smooth settings. Notably, our results for the non smooth case yield best in class convergence rates compared to existing SDE or ODE based analyses under minimal assumptions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01049v1</guid>
      <category>cs.LG</category>
      <category>math.AP</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nishant Jain, Xunpeng Huang, Yian Ma, Tong Zhang</dc:creator>
    </item>
    <item>
      <title>Risk Analysis and Design Against Adversarial Actions</title>
      <link>https://arxiv.org/abs/2505.01130</link>
      <description>arXiv:2505.01130v1 Announce Type: cross 
Abstract: Learning models capable of providing reliable predictions in the face of adversarial actions has become a central focus of the machine learning community in recent years. This challenge arises from observing that data encountered at deployment time often deviate from the conditions under which the model was trained. In this paper, we address deployment-time adversarial actions and propose a versatile, well-principled framework to evaluate the model's robustness against attacks of diverse types and intensities. While we initially focus on Support Vector Regression (SVR), the proposed approach extends naturally to the broad domain of learning via relaxed optimization techniques. Our results enable an assessment of the model vulnerability without requiring additional test data and operate in a distribution-free setup. These results not only provide a tool to enhance trust in the model's applicability but also aid in selecting among competing alternatives. Later in the paper, we show that our findings also offer useful insights for establishing new results within the out-of-distribution framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01130v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marco C. Campi, Algo Car\`e, Luis G. Crespo, Simone Garatti, Federico A. Ramponi</dc:creator>
    </item>
    <item>
      <title>Gaussian Differential Private Bootstrap by Subsampling</title>
      <link>https://arxiv.org/abs/2505.01197</link>
      <description>arXiv:2505.01197v1 Announce Type: cross 
Abstract: Bootstrap is a common tool for quantifying uncertainty in data analysis. However, besides additional computational costs in the application of the bootstrap on massive data, a challenging problem in bootstrap based inference under Differential Privacy consists in the fact that it requires repeated access to the data. As a consequence, bootstrap based differentially private inference requires a significant increase of the privacy budget, which on the other hand comes with a substantial loss in statistical accuracy.
  A potential solution to reconcile the conflicting goals of statistical accuracy and privacy is to analyze the data under parametric model assumptions and in the last decade, several parametric bootstrap methods for inference under privacy have been investigated. However, uncertainty quantification by parametric bootstrap is only valid if the the quantities of interest can be identified as the parameters of a statistical model and the imposed model assumptions are (at least approximately) satisfied. An alternative to parametric methods is the empirical bootstrap that is a widely used tool for non-parametric inference and well studied in the non-private regime. However, under privacy, less insight is available. In this paper, we propose a private empirical $m$ out of $n$ bootstrap and validate its consistency and privacy guarantees under Gaussian Differential Privacy. Compared to the the private $n$ out of $n$ bootstrap, our approach has several advantages. First, it comes with less computational costs, in particular for massive data. Second, the proposed procedure needs less additional noise in the bootstrap iterations, which leads to an improved statistical accuracy while asymptotically guaranteeing the same level of privacy. Third, we demonstrate much better finite sample properties compared to the currently available procedures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01197v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.TH</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Holger Dette, Carina Graw</dc:creator>
    </item>
    <item>
      <title>Design-Based Inference under Random Potential Outcomes via Riesz Representation</title>
      <link>https://arxiv.org/abs/2505.01324</link>
      <description>arXiv:2505.01324v2 Announce Type: cross 
Abstract: We introduce a general framework for design-based causal inference that accommodates stochastic potential outcomes, thereby extending the classical Neyman-Rubin setup in which outcomes are treated as fixed. In our formulation, each unit's potential outcome is modelled as a function $\tilde{y}_i(z, \omega)$, where $\omega$ denotes latent randomness external to the treatment assignment. Building on recent work that connects design-based estimation with the Riesz representation theorem, we construct causal estimators by embedding potential outcomes in a Hilbert space and defining treatment effects as linear functionals. This allows us to derive unbiased and consistent estimators, even when potential outcomes exhibit random variation. The framework retains the key advantage of design-based analysis, namely, the use of a known randomisation scheme for identification, while enabling inference in settings with inherent stochasticity. We establish large-sample properties under local dependence, provide a variance estimator compatible with sparse dependency structures, and illustrate the method through a simulation. Our results unify design-based reasoning with random-outcome modelling, broadening the applicability of causal inference in complex experimental environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01324v2</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yukai Yang</dc:creator>
    </item>
    <item>
      <title>Weight-calibrated estimation for factor models of high-dimensional time series</title>
      <link>https://arxiv.org/abs/2505.01357</link>
      <description>arXiv:2505.01357v2 Announce Type: cross 
Abstract: The factor modeling for high-dimensional time series is powerful in discovering latent common components for dimension reduction and information extraction. Most available estimation methods can be divided into two categories: the covariance-based under asymptotically-identifiable assumption and the autocovariance-based with white idiosyncratic noise. This paper follows the autocovariance-based framework and develops a novel weight-calibrated method to improve the estimation performance. It adopts a linear projection to tackle high-dimensionality, and employs a reduced-rank autoregression formulation. The asymptotic theory of the proposed method is established, relaxing the assumption on white noise. Additionally, we make the first attempt in the literature by providing a systematic theoretical comparison among the covariance-based, the standard autocovariance-based, and our proposed weight-calibrated autocovariance-based methods in the presence of factors with different strengths. Extensive simulations are conducted to showcase the superior finite-sample performance of our proposed method, as well as to validate the newly established theory. The superiority of our proposal is further illustrated through the analysis of one financial and one macroeconomic data sets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01357v2</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xinghao Qiao, Zihan Wang, Qiwei Yao, Bo Zhang</dc:creator>
    </item>
    <item>
      <title>Provable Efficiency of Guidance in Diffusion Models for General Data Distribution</title>
      <link>https://arxiv.org/abs/2505.01382</link>
      <description>arXiv:2505.01382v1 Announce Type: cross 
Abstract: Diffusion models have emerged as a powerful framework for generative modeling, with guidance techniques playing a crucial role in enhancing sample quality. Despite their empirical success, a comprehensive theoretical understanding of the guidance effect remains limited. Existing studies only focus on case studies, where the distribution conditioned on each class is either isotropic Gaussian or supported on a one-dimensional interval with some extra conditions. How to analyze the guidance effect beyond these case studies remains an open question. Towards closing this gap, we make an attempt to analyze diffusion guidance under general data distributions. Rather than demonstrating uniform sample quality improvement, which does not hold in some distributions, we prove that guidance can improve the whole sample quality, in the sense that the average reciprocal of the classifier probability decreases with the existence of guidance. This aligns with the motivation of introducing guidance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01382v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gen Li, Yuchen Jiao</dc:creator>
    </item>
    <item>
      <title>Potential Contrast: Properties, Equivalences, and Generalization to Multiple Classes</title>
      <link>https://arxiv.org/abs/2505.01388</link>
      <description>arXiv:2505.01388v1 Announce Type: cross 
Abstract: Potential contrast is typically used as an image quality measure and quantifies the maximal possible contrast between samples from two classes of pixels in an image after an arbitrary grayscale transformation. It has been valuable in cultural heritage applications, identifying and visualizing relevant information in multispectral images while requiring a small number of pixels to be manually sampled. In this work, we introduce a normalized version of potential contrast that removes dependence on image format and also prove equalities that enable generalization to more than two classes and to continuous settings. Finally, we exemplify the utility of multi-class normalized potential contrast through an application to a medieval music manuscript with visible bleedthrough from the back page. We share our implementations, based on both original algorithms and our new equalities, including generalization to multiple classes, at https://github.com/wallacepeaslee/Multiple-Class-Normalized-Potential-Contrast.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01388v1</guid>
      <category>eess.IV</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Wallace Peaslee, Anna Breger, Carola-Bibiane Sch\"onlieb</dc:creator>
    </item>
    <item>
      <title>Reduced-bias estimation of the residual dependence index with unnamed marginals</title>
      <link>https://arxiv.org/abs/2112.02899</link>
      <description>arXiv:2112.02899v4 Announce Type: replace 
Abstract: This paper addresses important weaknesses in current methodology for the estimation of multivariate extreme event distributions. The estimation of the residual dependence index $\eta \in (0,1]$ is notoriously problematic. We introduce a flexible class of reduced-bias estimators for this parameter, designed to ameliorate the usual problems of threshold selection through a unified approach to familiar marginal standardisations. We derive the asymptotic properties of the proposed class of gradient estimators for $\eta$. Their efficiency stems from a hitherto neglected exponentially decaying term in the characterisation of the asymptotic independence based on the theory of regular variation. Simulation studies to demonstrate the finite-sample efficacy of the new gradient estimation across a wealth of bivariate distributions belonging to some max-domain of attraction that enjoy the asymptotic independence property. Our leading application illustrates how asymptotic independence can be discerned from monsoon-related rainfall occurrences at different locations in Ghana. The considerations involved in extending this framework to the estimation of the extreme value index attached to univariate domains of attraction associated with heavy-tailed distributions are briefly discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2112.02899v4</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jennifer Israelsson, Emily Black, Claudia Neves, David Walshaw</dc:creator>
    </item>
    <item>
      <title>Quasi-Score Matching Estimation for Spatial Autoregressive Model with Random Weights Matrix and Regressors</title>
      <link>https://arxiv.org/abs/2305.19721</link>
      <description>arXiv:2305.19721v2 Announce Type: replace-cross 
Abstract: With the rapid advancements in technology for data collection, the application of the spatial autoregressive (SAR) model has become increasingly prevalent in real-world analysis, particularly when dealing with large datasets. However, the commonly used quasi-maximum likelihood estimation (QMLE) for the SAR model is not computationally scalable to handle the data with a large size. In addition, when establishing the asymptotic properties of the parameter estimators of the SAR model, both weights matrix and regressors are assumed to be nonstochastic in classical spatial econometrics, which is perhaps not realistic in real applications. Motivated by the machine learning literature, this paper proposes quasi-score matching estimation for the SAR model. This new estimation approach is developed based on the likelihood, but significantly reduces the computational complexity of the QMLE. The asymptotic properties of parameter estimators under the random weights matrix and regressors are established, which provides a new theoretical framework for the asymptotic inference of the SAR-type models. The usefulness of the quasi-score matching estimation and its asymptotic inference is illustrated via extensive simulation studies and a case study of an anti-conflict social network experiment for middle school students.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.19721v2</guid>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xuan Liang, Tao Zou</dc:creator>
    </item>
    <item>
      <title>Doubly-Robust Functional Average Treatment Effect Estimation</title>
      <link>https://arxiv.org/abs/2501.06024</link>
      <description>arXiv:2501.06024v2 Announce Type: replace-cross 
Abstract: Understanding causal relationships in the presence of complex, structured data remains a central challenge in modern statistics and science in general. While traditional causal inference methods are well-suited for scalar outcomes, many scientific applications demand tools capable of handling functional data -- outcomes observed as functions over continuous domains such as time or space. Motivated by this need, we propose DR-FoS, a novel method for estimating the Functional Average Treatment Effect (FATE) in observational studies with functional outcomes. DR-FoS exhibits double robustness properties, ensuring consistent estimation of FATE even if either the outcome or the treatment assignment model is misspecified. By leveraging recent advances in functional data analysis and causal inference, we establish the asymptotic properties of the estimator, proving its convergence to a Gaussian process. This guarantees valid inference with simultaneous confidence bands across the entire functional domain. Through extensive simulations, we show that DR-FoS achieves robust performance under a wide range of model specifications. Finally, we illustrate the utility of DR-FoS in a real-world application, analyzing functional outcomes to uncover meaningful causal insights in the SHARE (Survey of Health, Aging and Retirement in Europe) dataset.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.06024v2</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lorenzo Testa, Tobia Boschi, Francesca Chiaromonte, Edward H. Kennedy, Matthew Reimherr</dc:creator>
    </item>
    <item>
      <title>Mining and Intervention of Social Networks Information Cocoon Based on Multi-Layer Network Community Detection</title>
      <link>https://arxiv.org/abs/2504.21357</link>
      <description>arXiv:2504.21357v2 Announce Type: replace-cross 
Abstract: With the rapid development of information technology and the widespread utilization of recommendation algorithms, users are able to access information more conveniently, while the content they receive tends to be homogeneous. Homogeneous viewpoints and preferences tend to cluster users into sub-networks, leading to group polarization and increasing the likelihood of forming information cocoons. This paper aims to handle information cocoon phenomena in debates on social media. In order to investigate potential user connections, we construct a double-layer network that incorporates two dimensions: relational ties and feature-based similarity between users. Based on the structure of the multi-layer network, we promote two graph auto-encoder (GAE) based community detection algorithms, which can be applied to the partition and determination of information cocoons. This paper tests these two algorithms on Cora, Citeseer, and synthetic datasets, comparing them with existing multi-layer network unsupervised community detection algorithms. Numerical experiments illustrate that the algorithms proposed in this paper significantly improve prediction accuracy indicator NMI (normalized mutual information) and network topology indicator Q. Additionally, an influence-based intervention measure on which algorithms can operate is proposed. Through the Markov states transition model, we simulate the intervention effects, which illustrate that our community detection algorithms play a vital role in partitioning and determining information cocoons. Simultaneously, our intervention strategy alleviates the polarization of viewpoints and the formation of information cocoons with minimal intervention effort.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.21357v2</guid>
      <category>cs.SI</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Suwen Yang, Lei Shi</dc:creator>
    </item>
  </channel>
</rss>
