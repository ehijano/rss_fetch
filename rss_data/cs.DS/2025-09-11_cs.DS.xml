<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 11 Sep 2025 04:00:19 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 11 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Dynamic, Self-balancing k-d Tree</title>
      <link>https://arxiv.org/abs/2509.08148</link>
      <description>arXiv:2509.08148v1 Announce Type: new 
Abstract: The original description of the k-d tree recognized that rebalancing techniques, such as used to build an AVL tree or a red-black tree, are not applicable to a k-d tree, because these techniques involve cyclic exchange (aka rotation) of tree nodes, which destroys the sorted order of the k-d tree. For this reason, a static k-d tree is often built from all of the k-dimensional data en masse. However, it is possible to build a dynamic k-d tree that self-balances when necessary after insertion or deletion of each individual k-dimensional datum. This article describes insertion and deletion algorithms for a dynamic k-d tree, and measures their performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.08148v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 11 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Russell A. Brown</dc:creator>
    </item>
    <item>
      <title>Enumeration kernels for Vertex Cover and Feedback Vertex Set</title>
      <link>https://arxiv.org/abs/2509.08475</link>
      <description>arXiv:2509.08475v1 Announce Type: new 
Abstract: Enumerative kernelization is a recent and promising area sitting at the intersection of parameterized complexity and enumeration algorithms. Its study began with the paper of Creignou et al. [Theory Comput. Syst., 2017], and development in the area has started to accelerate with the work of Golovach et al. [J. Comput. Syst. Sci., 2022]. The latter introduced polynomial-delay enumeration kernels and applied them in the study of structural parameterizations of the \textsc{Matching Cut} problem and some variants. Few other results, mostly on \textsc{Longest Path} and some generalizations of \textsc{Matching Cut}, have also been developed. However, little success has been seen in enumeration versions of \textsc{Vertex Cover} and \textsc{Feedback Vertex Set}, some of the most studied problems in kernelization. In this paper, we address this shortcoming. Our first result is a polynomial-delay enumeration kernel with $2k$ vertices for \textsc{Enum Vertex Cover}, where we wish to list all solutions with at most $k$ vertices. This is obtained by developing a non-trivial lifting algorithm for the classical crown decomposition reduction rule, and directly improves upon the kernel with $\mathcal{O}(k^2)$ vertices derived from the work of Creignou et al. Our other result is a polynomial-delay enumeration kernel with $\mathcal{O}(k^3)$ vertices and edges for \textsc{Enum Feedback Vertex Set}; the proof is inspired by some ideas of Thomass\'e [TALG, 2010], but with a weaker bound on the kernel size due to difficulties in applying the $q$-expansion technique.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.08475v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 11 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Marin Bougeret, Guilherme C. M. Gomes, Vinicius F. dos Santos, Ignasi Sau</dc:creator>
    </item>
    <item>
      <title>Checking and producing word attractors</title>
      <link>https://arxiv.org/abs/2509.08503</link>
      <description>arXiv:2509.08503v1 Announce Type: new 
Abstract: The article focuses on word (or string) attractors, which are sets of positions related to the text compression efficiency of the underlying word. The article presents two combinatorial algorithms based on Suffix automata or Directed Acyclic Word Graphs. The first algorithm decides in linear time whether a set of positions on the word is an attractor of the word. The second algorithm generates an attractor for a given word in a greedy manner. Although this problem is NP-hard, the algorithm is efficient and produces very small attractors for several well-known families of words.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.08503v1</guid>
      <category>cs.DS</category>
      <category>cs.FL</category>
      <pubDate>Thu, 11 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marie-Pierre B\'eal, Maxime Crochemore, Giuseppe Romana</dc:creator>
    </item>
    <item>
      <title>FeynmanDD: Quantum Circuit Analysis with Classical Decision Diagrams</title>
      <link>https://arxiv.org/abs/2509.08276</link>
      <description>arXiv:2509.08276v1 Announce Type: cross 
Abstract: Applications of decision diagrams in quantum circuit analysis have been an active research area. Our work introduces FeynmanDD, a new method utilizing standard and multi-terminal decision diagrams for quantum circuit simulation and equivalence checking. Unlike previous approaches that exploit patterns in quantum states and operators, our method explores useful structures in the path integral formulation, essentially transforming the analysis into a counting problem. The method then employs efficient counting algorithms using decision diagrams as its underlying computational engine. Through comprehensive theoretical analysis and numerical experiments, we demonstrate FeynmanDD's capabilities and limitations in quantum circuit analysis, highlighting the value of this new BDD-based approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.08276v1</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <pubDate>Thu, 11 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/978-3-031-98685-7_2</arxiv:DOI>
      <dc:creator>Ziyuan Wang, Bin Cheng, Longxiang Yuan, Zhengfeng Ji</dc:creator>
    </item>
    <item>
      <title>Dorst-Smeulders Coding for Arbitrary Binary Words</title>
      <link>https://arxiv.org/abs/2509.08684</link>
      <description>arXiv:2509.08684v1 Announce Type: cross 
Abstract: A binary word is Sturmian if the occurrences of each letter are balanced, in the sense that in any two factors of the same length, the difference between the number of occurrences of the same letter is at most 1. In digital geometry, Sturmian words correspond to discrete approximations of straight line segments in the Euclidean plane. The Dorst-Smeulders coding, introduced in 1984, is a 4-tuple of integers that uniquely represents a Sturmian word $w$, enabling its reconstruction using $|w|$ modular operations, making it highly efficient in practice. In this paper, we present a linear-time algorithm that, given a binary input word $w$, computes the Dorst-Smeulders coding of its longest Sturmian prefix. This forms the basis for computing the Dorst-Smeulders coding of an arbitrary binary word $w$, which is a minimal decomposition (in terms of the number of factors) of $w$ into Sturmian words, each represented by its Dorst-Smeulders coding. This coding could be leveraged in compression schemes where the input is transformed into a binary word composed of long Sturmian segments. Although the algorithm is conceptually simple and can be implemented in just a few lines of code, it is grounded in a deep analysis of the structural properties of Sturmian words.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.08684v1</guid>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>cs.FL</category>
      <category>math.CO</category>
      <pubDate>Thu, 11 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Alessandro De Luca (Universit\`a di Napoli Federico II, Italy), Gabriele Fici (Universit\`a di Palermo, Italy)</dc:creator>
    </item>
    <item>
      <title>Computing Tree Decompositions with Small Independence Number</title>
      <link>https://arxiv.org/abs/2207.09993</link>
      <description>arXiv:2207.09993v4 Announce Type: replace 
Abstract: The independence number of a tree decomposition is the maximum of the independence numbers of the subgraphs induced by its bags. The tree-independence number of a graph is the minimum independence number of a tree decomposition of it. Several NP-hard graph problems, like maximum weight independent set, can be solved in time n^{O(k)} if the input n-vertex graph is given together with a tree decomposition of independence number k. Yolov, in [SODA 2018], gave an algorithm that, given an n-vertex graph G and an integer k, in time n^{O(k^3)} either constructs a tree decomposition of G whose independence number is O(k^3) or correctly reports that the tree-independence number of G is larger than k.
  In this paper, we first give an algorithm for computing the tree-independence number with a better approximation ratio and running time and then prove that our algorithm is, in some sense, the best one can hope for. More precisely, our algorithm runs in time 2^{O(k^2)} n^{O(k)} and either outputs a tree decomposition of G with independence number at most $8k$, or determines that the tree-independence number of G is larger than k. This implies 2^{O(k^2)} n^{O(k)}-time algorithms for various problems, like maximum weight independent set, parameterized by the tree-independence number k without needing the decomposition as an input. Assuming Gap-ETH, an n^{\Omega(k)} factor in the running time is unavoidable for any approximation algorithm for the tree-independence number.
  Our second result is that the exact computation of the tree-independence number is para-NP-hard: We show that for every constant k \ge 4 it is NP-hard to decide if a given graph has the tree-independence number at most k.</description>
      <guid isPermaLink="false">oai:arXiv.org:2207.09993v4</guid>
      <category>cs.DS</category>
      <category>math.CO</category>
      <pubDate>Thu, 11 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Cl\'ement Dallard, Fedor V. Fomin, Petr A. Golovach, Tuukka Korhonen, Martin Milani\v{c}</dc:creator>
    </item>
    <item>
      <title>Subset Sum in Near-Linear Pseudopolynomial Time and Polynomial Space</title>
      <link>https://arxiv.org/abs/2508.04726</link>
      <description>arXiv:2508.04726v2 Announce Type: replace 
Abstract: Given a multiset $A = \{a_1, \dots, a_n\}$ of positive integers and a target integer $t$, the Subset Sum problem asks if there is a subset of $A$ that sums to $t$. Bellman's [1957] classical dynamic programming algorithm runs in $O(nt)$ time and $O(t)$ space. Since then, much work has been done to reduce both the time and space usage.
  Notably, Bringmann [SODA 2017] uses a two-step color-coding technique to obtain a randomized algorithm that runs in $\tilde{O}(n+t)$ time and $\tilde{O}(t)$ space. Jin, Vyas and Williams [SODA 2021] build upon the algorithm given by Bringmann, using a clever algebraic trick first seen in Kane's Logspace algorithm, to obtain an $\tilde{O}(nt)$ time and $\tilde{O}(\log(nt))$ space randomized algorithm. A SETH-based lower-bound established by Abboud et al. [SODA 2019] shows that Bringmann's algorithm is likely to have near-optimal time complexity.
  We build on the techniques used by Jin et al. to obtain a randomized algorithm running in $\tilde{O}(n+t)$ time and $\tilde{O}(n^2 + n \log^2 t)$ space, resulting in an algorithm with near-optimal runtime that also runs in polynomial space. We use a multipoint evaluation-based approach to speed up a bottleneck step in their algorithm.
  We also provide a simple polynomial space deterministic algorithm that runs in $\tilde{O}(n^2t)$ time and $\tilde{O}(n \log^2 t)$ space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.04726v2</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Thu, 11 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Thejas Radhika Sajith</dc:creator>
    </item>
    <item>
      <title>Compressibility Measures and Succinct Data Structures for Piecewise Linear Approximations</title>
      <link>https://arxiv.org/abs/2509.07827</link>
      <description>arXiv:2509.07827v2 Announce Type: replace 
Abstract: We study the problem of deriving compressibility measures for Piecewise Linear Approximations (PLAs), i.e., error-bounded approximations of a set of two-dimensional increasing data points using a sequence of segments. Such approximations are widely used tools in implementing many learned data structures, which mix learning models with traditional algorithmic design blocks to exploit regularities in the underlying data distribution, providing novel and effective space-time trade-offs. We introduce the first lower bounds to the cost of storing PLAs in two settings, namely compression and indexing. We then compare these compressibility measures to known data structures, and show that they are asymptotically optimal up to a constant factor from the space lower bounds. Finally, we design the first data structures for the aforementioned settings that achieve the space lower bounds plus small additive terms, which turn out to be succinct in most practical cases. Our data structures support the efficient retrieval and evaluation of a segment in the (compressed) PLA for a given $x$-value, which is a core operation in any learned data structure relying on PLAs. As a result, our paper offers the first theoretical analysis of the maximum compressibility achievable by PLA-based learned data structures, and provides novel storage schemes for PLAs offering strong theoretical guarantees while also suggesting simple and efficient practical implementations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.07827v2</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 11 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Paolo Ferragina, Filippo Lari</dc:creator>
    </item>
    <item>
      <title>Tight Lieb-Robinson Bound for approximation ratio in Quantum Annealing</title>
      <link>https://arxiv.org/abs/2311.12732</link>
      <description>arXiv:2311.12732v2 Announce Type: replace-cross 
Abstract: Quantum annealing (QA) holds promise for optimization problems in quantum computing, especially for combinatorial optimization. This analog framework attracts attention for its potential to address complex problems. Its gate-based homologous, QAOA with proven performance, has brought lots of attention to the NISQ era. Several numerical benchmarks try to classify these two metaheuristics however, classical computational power highly limits the performance insights. In this work, we introduce a new parametrized version of QA enabling a precise 1-local analysis of the algorithm. We develop a tight Lieb-Robinson bound for regular graphs, achieving the best-known numerical value to analyze QA locally. Studying MaxCut over cubic graph as a benchmark optimization problem, we show that a linear-schedule QA with a 1-local analysis achieves an approximation ratio over 0.7020, outperforming any known 1-local algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.12732v2</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <pubDate>Thu, 11 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Arthur Braida, Simon Martiel, Ioan Todinca</dc:creator>
    </item>
    <item>
      <title>Induced Minor Models. I. Structural Properties and Algorithmic Consequences</title>
      <link>https://arxiv.org/abs/2402.08332</link>
      <description>arXiv:2402.08332v3 Announce Type: replace-cross 
Abstract: A graph $H$ is said to be an induced minor of a graph $G$ if $H$ can be obtained from $G$ by a sequence of vertex deletions and edge contractions. Equivalently, $H$ is an induced minor of $G$ if there exists an induced minor model of $H$ in $G$, that is, a collection of pairwise disjoint subsets of vertices of $G$ labeled by the vertices of $H$, each inducing a connected subgraph in $G$, such that two vertices of $H$ are adjacent if and only if there is an edge in $G$ between the corresponding subsets.
  In this paper, we investigate structural properties of induced minor models, including bounds on treewidth and chromatic number of the subgraphs induced by minimal induced minor models. It is known that for some graphs $H$, testing whether a given graph $G$ contains $H$ as an induced minor is an NP-complete problem. Nevertheless, as algorithmic applications of our structural results, we make use of recent developments regarding tree-independence number to show that if $H$ is the $4$-wheel, the $5$-vertex complete graph minus an edge, or a complete bipartite graph $K_{2,q}$, then there is a polynomial-time algorithm to find in a given graph $G$ an induced minor model of $H$ in $G$, if there is one. We also develop an alternative polynomial-time algorithm for recognizing graphs that do not contain $K_{2,3}$ as an induced minor, which revolves around the idea of detecting the induced subgraphs whose presence is forced when the input graph contains $K_{2,3}$ as an induced minor, using the so-called shortest path detector. It turns out that all these induced subgraphs are Truemper configurations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.08332v3</guid>
      <category>math.CO</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <pubDate>Thu, 11 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicolas Bousquet, Cl\'ement Dallard, Ma\"el Dumas, Claire Hilaire, Martin Milani\v{c}, Anthony Perez, Nicolas Trotignon</dc:creator>
    </item>
    <item>
      <title>Statistical-Computational Trade-offs for Recursive Adaptive Partitioning Estimators</title>
      <link>https://arxiv.org/abs/2411.04394</link>
      <description>arXiv:2411.04394v3 Announce Type: replace-cross 
Abstract: Models based on recursive adaptive partitioning such as decision trees and their ensembles are popular for high-dimensional regression as they can potentially avoid the curse of dimensionality. Because empirical risk minimization (ERM) is computationally infeasible, these models are typically trained using greedy algorithms. Although effective in many cases, these algorithms have been empirically observed to get stuck at local optima. We explore this phenomenon in the context of learning sparse regression functions over $d$ binary features, showing that when the true regression function $f^*$ does not satisfy Abbe et al. (2022)'s Merged Staircase Property (MSP), greedy training requires $\exp(\Omega(d))$ to achieve low estimation error. Conversely, when $f^*$ does satisfy MSP, greedy training can attain small estimation error with only $O(\log d)$ samples. This dichotomy mirrors that of two-layer neural networks trained with stochastic gradient descent (SGD) in the mean-field regime, thereby establishing a head-to-head comparison between SGD-trained neural networks and greedy recursive partitioning estimators. Furthermore, ERM-trained recursive partitioning estimators achieve low estimation error with $O(\log d)$ samples irrespective of whether $f^*$ satisfies MSP, thereby demonstrating a statistical-computational trade-off for greedy training. Our proofs are based on a novel interpretation of greedy recursive partitioning using stochastic process theory and a coupling technique that may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04394v3</guid>
      <category>stat.ML</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 11 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yan Shuo Tan, Jason M. Klusowski, Krishnakumar Balasubramanian</dc:creator>
    </item>
    <item>
      <title>On the twin-width of near-regular graphs</title>
      <link>https://arxiv.org/abs/2504.02342</link>
      <description>arXiv:2504.02342v2 Announce Type: replace-cross 
Abstract: Twin-width is a recently introduced graph parameter based on the repeated contraction of near-twins. It has shown remarkable utility in algorithmic and structural graph theory, as well as in finite model theory -- particularly since first-order model checking is fixed-parameter tractable when a witness certifying small twin-width is provided. However, the behavior of twin-width in specific graph classes, particularly cubic graphs, remains poorly understood. While cubic graphs are known to have unbounded twin-width, no explicit cubic graph of twin-width greater than 4 is known.
  This paper explores this phenomenon in regular and near-regular graph classes. We show that extremal graphs of bounded degree and high twin-width are asymmetric, partly explaining their elusiveness. Additionally, we establish bounds for circulant and d-degenerate graphs, and examine strongly regular graphs, which exhibit similar behavior to cubic graphs. Our results include determining the twin-width of Johnson graphs over 2-sets, and cyclic Latin square graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.02342v2</guid>
      <category>math.CO</category>
      <category>cs.DS</category>
      <pubDate>Thu, 11 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.dam.2025.07.044</arxiv:DOI>
      <arxiv:journal_reference>Discrete Applied Mathematics 379 (2026) 177-193</arxiv:journal_reference>
      <dc:creator>Irene Heinrich, Ferdinand Ihringer, Simon Ra{\ss}mann, Lena Volk</dc:creator>
    </item>
    <item>
      <title>Permutation-Avoiding FFT-Based Convolution</title>
      <link>https://arxiv.org/abs/2506.12718</link>
      <description>arXiv:2506.12718v2 Announce Type: replace-cross 
Abstract: Fast Fourier Transform (FFT) libraries are widely used for evaluating discrete convolutions. Most FFT implementations follow some variant of the Cooley-Tukey framework, in which the transform is decomposed into butterfly operations and index-reversal permutations. While butterfly operations dominate the floating-point operation count, the memory access patterns induced by index-reversal permutations significantly degrade the FFT's arithmetic intensity. When performing discrete convolution, the three sets of index-reversal permutations which occur in FFT-based implementations using Cooley-Tukey frameworks cancel out, thus paving the way to implementations free of any permutation. To the best of our knowledge, such permutation-free variants of FFT-based discrete convolution are not commonly used in practice, making such kernels worth investigating. Here, we look into such permutation-avoiding convolution procedures for multi-dimensional cases within a general radix Cooley-Tukey framework. We perform numerical experiments to benchmark the algorithms presented against state-of-the-art FFT-based convolution implementations. Our results suggest that developers of FFT libraries should consider supporting permutation-avoiding convolution kernels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.12718v2</guid>
      <category>math.NA</category>
      <category>cs.DS</category>
      <category>cs.MS</category>
      <category>cs.NA</category>
      <pubDate>Thu, 11 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicolas Venkovic, Hartwig Anzt</dc:creator>
    </item>
  </channel>
</rss>
