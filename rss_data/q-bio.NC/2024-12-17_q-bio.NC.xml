<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 18 Dec 2024 02:55:45 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Shannon information and integrated information: message and meaning</title>
      <link>https://arxiv.org/abs/2412.10626</link>
      <description>arXiv:2412.10626v1 Announce Type: new 
Abstract: Information theory, introduced by Shannon, has been extremely successful and influential as a mathematical theory of communication. Shannon's notion of information does not consider the meaning of the messages being communicated but only their probability. Even so, computational approaches regularly appeal to "information processing" to study how meaning is encoded and decoded in natural and artificial systems. Here, we contrast Shannon information theory with integrated information theory (IIT), which was developed to account for the presence and properties of consciousness. IIT considers meaning as integrated information and characterizes it as a structure, rather than as a message or code. In principle, IIT's axioms and postulates allow one to "unfold" a cause-effect structure from a substrate in a state, a structure that fully defines the intrinsic meaning of an experience and its contents. It follows that, for the communication of meaning, the cause-effect structures of sender and receiver must be similar.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.10626v1</guid>
      <category>q-bio.NC</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alireza Zaeemzadeh, Giulio Tononi</dc:creator>
    </item>
    <item>
      <title>Exbodiment: The Mind Made Matter</title>
      <link>https://arxiv.org/abs/2412.10957</link>
      <description>arXiv:2412.10957v1 Announce Type: new 
Abstract: Exbodiment describes mind outsourced to engineered matter and how matter reeducates mind. The constraints of exbodied matter encode elements of thought, channel decision-making, and constitute an important part of an extended computational phenotype. Here I provide an introduction and brief cultural history of exbodiment in music, natural history, cognition, and astrobiology. The "Helix of Exbodiment" is introduced to illustrate continuous feedback between mind and matter.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.10957v1</guid>
      <category>q-bio.NC</category>
      <category>physics.pop-ph</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>David C. Krakauer</dc:creator>
    </item>
    <item>
      <title>The lack of asymmetry of the Maxwell centroids, and of ocular dominance, in persons with dyslexia</title>
      <link>https://arxiv.org/abs/2412.12053</link>
      <description>arXiv:2412.12053v1 Announce Type: new 
Abstract: While the existence of an asymmetry between the two Maxwell centroids at the centre of the two foveas recorded using a foveascope, leads to the ocular dominance in good readers, the lack of asymmetry in most of the observers with dyslexia leads to their non-dominance and their difficulties in reading and writing. Indeed, the lack of asymmetry between the two main roads to the brain, i.e. the two optical nerves, leads to perturbations in the brain central connectivity, namely between the two hemispheres inducing too robust interhemispheric visual connections, beyond the critical period of 7-8 years. The symmetrical mirror-connections like b-d (observed for about 60% of children with dyslexia) or the non-symmetrical connections like b-b (35%) induce confusions and duplications in observers with dyslexia but remain erasable thanks to pulsed systems (glasses, lamps, screens. . .), using Hebbian processes in primary cortex synapses. The effect is instantaneous, non-invasive and compensates the lack of asymmetry. These systems help most of the observers with dyslexia to overcome their difficulties. The orthoptists and speech therapists can acquire and improve the mechanism to help the children to catch up, and perhaps be able to use the foveascope for an early diagnosis with young children.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.12053v1</guid>
      <category>q-bio.NC</category>
      <category>physics.bio-ph</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Albert Le Floch, Guy Ropars</dc:creator>
    </item>
    <item>
      <title>Adaptive Intelligence: leveraging insights from adaptive behavior in animals to build flexible AI systems</title>
      <link>https://arxiv.org/abs/2411.15234</link>
      <description>arXiv:2411.15234v2 Announce Type: replace 
Abstract: Biological intelligence is inherently adaptive -- animals continually adjust their actions based on environmental feedback. However, creating adaptive artificial intelligence (AI) remains a major challenge. The next frontier is to go beyond traditional AI to develop "adaptive intelligence," defined here as harnessing insights from biological intelligence to build agents that can learn online, generalize, and rapidly adapt to changes in their environment. Recent advances in neuroscience offer inspiration through studies that increasingly focus on how animals naturally learn and adapt their world models. In this Perspective, I will review the behavioral and neural foundations of adaptive biological intelligence, the parallel progress in AI, and explore brain-inspired approaches for building more adaptive algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15234v2</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mackenzie Weygandt Mathis</dc:creator>
    </item>
    <item>
      <title>Networks with many structural scales: a Renormalization Group perspective</title>
      <link>https://arxiv.org/abs/2406.19104</link>
      <description>arXiv:2406.19104v3 Announce Type: replace-cross 
Abstract: Scale invariance profoundly influences the dynamics and structure of complex systems, spanning from critical phenomena to network architecture. Here, we propose a precise definition of scale-invariant networks by leveraging the concept of a constant entropy-loss rate across scales in a renormalization-group coarse-graining setting. This framework enables us to differentiate between scale-free and scale-invariant networks, revealing distinct characteristics within each class. Furthermore, we offer a comprehensive inventory of genuinely scale-invariant networks, both natural and artificially constructed, demonstrating, e.g., that the human connectome exhibits notable features of scale invariance. Our findings open new avenues for exploring the scale-invariant structural properties crucial in biological and socio-technological systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19104v3</guid>
      <category>cond-mat.stat-mech</category>
      <category>cond-mat.dis-nn</category>
      <category>nlin.AO</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anna Poggialini, Pablo Villegas, Miguel A. Mu\~noz, Andrea Gabrielli</dc:creator>
    </item>
    <item>
      <title>Vision Language Models Know Law of Conservation without Understanding More-or-Less</title>
      <link>https://arxiv.org/abs/2410.00332</link>
      <description>arXiv:2410.00332v2 Announce Type: replace-cross 
Abstract: Conservation is a critical milestone of cognitive development considered to be supported by both the understanding of quantitative concepts and the reversibility of mental operations. To assess whether this critical component of human intelligence has emerged in Vision Language Models, we leverage the ConserveBench from CogDevelop2K, a data-intensive cognitive experiment benchmark for assaying the developmental trajectory of machine intelligence. The battery includes over 350 questions across four dimensions of physical quantities: volume, solid quantity, length, and number. The former two involve only transformational tasks, whereas the latter two also involve non-transformational tasks assessing the understanding of quantitative concepts alone. Surprisingly, we find that while VLMs are generally capable of conserving, they tend to fail at non-transformational tasks which success is typically considered to be entailed by the ability to conserve. This implies that the law of conservation, at least in concrete domains, may exist without corresponding conceptual understanding of quantity. $\href{https://growing-ai-like-a-child.github.io/pages/Conservation/}{Website}$</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00332v2</guid>
      <category>cs.AI</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dezhi Luo, Haiyun Lyu, Qingying Gao, Haoran Sun, Yijiang Li, Hokin Deng</dc:creator>
    </item>
    <item>
      <title>Neural networks that overcome classic challenges through practice</title>
      <link>https://arxiv.org/abs/2410.10596</link>
      <description>arXiv:2410.10596v2 Announce Type: replace-cross 
Abstract: Since the earliest proposals for neural network models of the mind and brain, critics have pointed out key weaknesses in these models compared to human cognitive abilities. Here we review recent work that uses metalearning to overcome several classic challenges by addressing the Problem of Incentive and Practice -- that is, providing machines with both incentives to improve specific skills and opportunities to practice those skills. This explicit optimization contrasts with more conventional approaches that hope the desired behavior will emerge through optimizing related but different objectives. We review applications of this principle to addressing four classic challenges for neural networks: systematic generalization, catastrophic forgetting, few-shot learning and multi-step reasoning. We also discuss the prospects for understanding aspects of human development through this framework, and whether natural environments provide the right incentives and practice for learning how to make challenging generalizations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10596v2</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kazuki Irie, Brenden M. Lake</dc:creator>
    </item>
  </channel>
</rss>
