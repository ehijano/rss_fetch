<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 09 Jul 2024 02:36:33 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 08 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Multi-Task Decision-Making for Multi-User 360 Video Processing over Wireless Networks</title>
      <link>https://arxiv.org/abs/2407.03426</link>
      <description>arXiv:2407.03426v1 Announce Type: new 
Abstract: We study a multi-task decision-making problem for 360 video processing in a wireless multi-user virtual reality (VR) system that includes an edge computing unit (ECU) to deliver 360 videos to VR users and offer computing assistance for decoding/rendering of video frames. However, this comes at the expense of increased data volume and required bandwidth. To balance this trade-off, we formulate a constrained quality of experience (QoE) maximization problem in which the rebuffering time and quality variation between video frames are bounded by user and video requirements. To solve the formulated multi-user QoE maximization, we leverage deep reinforcement learning (DRL) for multi-task rate adaptation and computation distribution (MTRC). The proposed MTRC approach does not rely on any predefined assumption about the environment and relies on video playback statistics (i.e., past throughput, decoding time, transmission time, etc.), video information, and the resulting performance to adjust the video bitrate and computation distribution. We train MTRC with real-world wireless network traces and 360 video datasets to obtain evaluation results in terms of the average QoE, peak signal-to-noise ratio (PSNR), rebuffering time, and quality variation. Our results indicate that the MTRC improves the users' QoE compared to state-of-the-art rate adaptation algorithm. Specifically, we show a 5.97 dB to 6.44 dB improvement in PSNR, a 1.66X to 4.23X improvement in rebuffering time, and a 4.21 dB to 4.35 dB improvement in quality variation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03426v1</guid>
      <category>cs.NI</category>
      <category>cs.LG</category>
      <category>cs.MM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Babak Badnava, Jacob Chakareski, Morteza Hashemi</dc:creator>
    </item>
    <item>
      <title>Enhancing LR-FHSS Scalability Through Advanced Sequence Design and Demodulator Allocation</title>
      <link>https://arxiv.org/abs/2407.03490</link>
      <description>arXiv:2407.03490v1 Announce Type: new 
Abstract: The accelerating growth of the Internet of Things (IoT) and its integration with Low-Earth Orbit (LEO) satellites demand efficient, reliable, and scalable communication protocols. Among these, the Long-Range Frequency Hopping Spread Spectrum (LR-FHSS) modulation, tailored for LEO satellite IoT communications, sparks keen interest. This work presents a joint approach to enhancing the scalability of LR-FHSS, addressing the demand for massive connectivity. We deepen into Frequency Hopping Sequence (FHS) mechanisms within LR-FHSS, spotlighting the potential of leveraging Wide-Gap sequences. Concurrently, we introduce two novel demodulator allocation strategies, namely, ``Early-Decode" and ``Early-Drop," to optimize the utilization of LoRa-specific gateway decoding resources. Our research further validates these findings with extensive simulations, offering a comprehensive look into the future potential of LR-FHSS scalability in IoT settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03490v1</guid>
      <category>cs.NI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Diego Maldonado, Megumi Kaneko, Juan A. Fraire, Alexandre Guitton, Oana Iova, Herve Rivano</dc:creator>
    </item>
    <item>
      <title>Perfect simulation of Markovian load balancing queueing networks in equilibrium</title>
      <link>https://arxiv.org/abs/2407.03756</link>
      <description>arXiv:2407.03756v1 Announce Type: new 
Abstract: We define a wide class of Markovian load balancing networks of identical single-server infinite-buffer queues. These networks may implement classic parallel server or work stealing load balancing policies, and may be asymmetric, for instance due to topological constraints. The invariant laws are usually not known even up to normalizing constant. We provide three perfect simulation algorithms enabling Monte Carlo estimation of quantities of interest in equilibrium. The state space is infinite, and the algorithms use a dominating process provided by the network with uniform routing, in a coupling preserving a preorder which is related to the increasing convex order. It constitutes an order up to permutation of the coordinates, strictly weaker than the product order. The use of a preorder is novel in this context. The first algorithm is in direct time and uses Palm theory and acceptance rejection. Its duration is finite, a.s., but has infinite expectation. The two other algorithms use dominated coupling from the past; one achieves coalescence by simulating the dominating process into the past until it reaches the empty state, the other, valid for exchangeable policies, is a back-off sandwiching method. Their durations have some exponential moments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03756v1</guid>
      <category>cs.NI</category>
      <category>math.PR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Carl Graham (CMAP, ASCII)</dc:creator>
    </item>
    <item>
      <title>Your Mega-Constellations Can Be Slim:A Cost-Effective Approach for Constructing Survivable and Performant LEO Satellite Networks</title>
      <link>https://arxiv.org/abs/2407.03799</link>
      <description>arXiv:2407.03799v1 Announce Type: new 
Abstract: In this paper, we investigate an important research problem facing the upcoming satellite Internet: from a network perspective, how many satellites exactly do we need to construct a survivable and performant LSN? To answer this question, we first formulate the survivable and performant LSN design (SPLD) problem, which aims to find the minimum number of needed satellites to construct an LSN that can provide sufficient amount of redundant paths, required link capacity and acceptable latency for traffic carried by the LSN. Second, to efficiently solve the tricky SPLD problem, we propose MEGAREDUCE, a requirement-driven constellation optimization mechanism, which can calculate feasible solutions for SPLD in polynomial time. Finally, we conduct extensive trace-driven simulations to verify MEGAREDUCE's cost-effectiveness in constructing survivable and performant LSNs on demand, and showcase how MEGAREDUCE can help optimize the incremental deployment and long-term maintenance of future satellite Internet.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03799v1</guid>
      <category>cs.NI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zeqi Lai (Institute for Network Sciences,Cyberspace, Tsinghua University, Zhongguancun Laboratory), Yibo Wang (Institute for Network Sciences,Cyberspace, Tsinghua University, Zhongguancun Laboratory), Hewu Li (Institute for Network Sciences,Cyberspace, Tsinghua University, Zhongguancun Laboratory), Qian Wu (Institute for Network Sciences,Cyberspace, Tsinghua University, Zhongguancun Laboratory), Qi Zhang (Institute for Network Sciences,Cyberspace, Tsinghua University, Zhongguancun Laboratory), Yunan Hou (Institute for Network Sciences,Cyberspace, Tsinghua University, Zhongguancun Laboratory), Jun Liu (Institute for Network Sciences,Cyberspace, Tsinghua University, Zhongguancun Laboratory), Yuanjie Li (Institute for Network Sciences,Cyberspace, Tsinghua University, Zhongguancun Laboratory)</dc:creator>
    </item>
    <item>
      <title>Network Sovereignty: A Novel Metric and its Application on Network Design</title>
      <link>https://arxiv.org/abs/2407.03814</link>
      <description>arXiv:2407.03814v1 Announce Type: new 
Abstract: Most network planning problems in literature consider metrics such as cost, availability, and other technology-aware attributes. However, network operators now face new challenges in designing their networks to minimize their dependencies on manufacturers. A low dependency is associated with higher network robustness in case one or more manufacturers fail due to erroneous component design, geopolitical banning of manufacturers, or other reasons discussed in this work. Our work discusses network sovereignty, i.e., the ability to operate a network without dependencies on a particular manufacturer while minimizing the impact of simultaneous manufacturer failure(s). Network sovereignty is considered by solving the manufacturer assignment problem in the network such that robustness is maximized. The three main contributions of this work are (i) the discussion of network sovereignty as a special attribute of dependability, (ii) the introduction of a novel metric -- the Path Set Diversity (PSD) score to measure network sovereignty, and (iii) the introduction of Naga, an ILP formulation to maximize network sovereignty using the PSD score. We compare Naga's performance with centrality metrics-based heuristics and an availability-based optimization. Our work aims to be the foundation to guide network operators in increasing their network sovereignty.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03814v1</guid>
      <category>cs.NI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Shakthivelu Janardhanan, Maria Samonaki, Poul Einar Heegaard, Wolfgang Kellerer, Carmen Mas-Machuca</dc:creator>
    </item>
    <item>
      <title>Enhancing Physical Layer Security in LEO Satellite-Enabled IoT Network Communications</title>
      <link>https://arxiv.org/abs/2407.04077</link>
      <description>arXiv:2407.04077v1 Announce Type: new 
Abstract: The extensive deployment of Low Earth Orbit (LEO) satellites introduces significant security challenges for communication security issues in Internet of Things (IoT) networks. With the rising number of satellites potentially acting as eavesdroppers, integrating Physical Layer Security (PLS) into satellite communications has become increasingly critical. However, these studies are facing challenges such as dealing with dynamic topology difficulties, limitations in interference analysis, and the high complexity of performance evaluation. To address these challenges, for the first time, we investigate PLS strategies in satellite communications using the Stochastic Geometry (SG) analytical framework. We consider the uplink communication scenario in an LEO-enabled IoT network, where multi-tier satellites from different operators respectively serve as legitimate receivers and eavesdroppers. In this scenario, we derive low-complexity analytical expressions for the security performance metrics, namely availability probability, successful communication probability, and secure communication probability. By introducing the power allocation parameters, we incorporate the Artificial Noise (AN) technique, which is an important PLS strategy, into this analytical framework and evaluate the gains it brings to secure transmission. In addition to the AN technique, we also analyze the impact of constellation configuration, physical layer parameters, and network layer parameters on the aforementioned metrics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04077v1</guid>
      <category>cs.NI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Anna Talgat, Ruibo Wang, Mustafa A. Kishk, Mohamed-Slim Alouini</dc:creator>
    </item>
    <item>
      <title>Gemini: Integrating Full-fledged Sensing upon Millimeter Wave Communications</title>
      <link>https://arxiv.org/abs/2407.04174</link>
      <description>arXiv:2407.04174v1 Announce Type: new 
Abstract: Integrating millimeter wave (mmWave)technology in both communication and sensing is promising as it enables the reuse of existing spectrum and infrastructure without draining resources. Most existing systems piggyback sensing onto conventional communication modes without fully exploiting the potential of integrated sensing and communication (ISAC) in mmWave radios (not full-fledged). In this paper, we design and implement a full-fledged mmWave ISAC system Gemini; it delivers raw channel states to serve a broad category of sensing applications. We first propose the mmWave self-interference cancellation approach to extract the weak reflected signals for near-field sensing purposes. Then, we develop a joint optimization scheduling framework that can be utilized in accurate radar sensing while maximizing the communication throughput. Finally, we design a united fusion sensing algorithm to offer a better sensing performance via combining monostatic and bistatic modes. We evaluate our system in extensive experiments to demonstrate Gemini's capability of simultaneously operating sensing and communication, enabling mmWave ISAC to perform better than the commercial off-the-shelf mmWave radar for 5G cellular networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04174v1</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yilong Li, Zhe Chen, Jun Luo, Suman Banerjee</dc:creator>
    </item>
    <item>
      <title>Just-in-Time Packet State Prefetching</title>
      <link>https://arxiv.org/abs/2407.04344</link>
      <description>arXiv:2407.04344v1 Announce Type: new 
Abstract: Could information about future incoming packets be used to build more efficient CPU-based packet processors? Can such information be obtained accurately? This paper studies novel packet processing architectures that receive external hints about which packets are soon to arrive, thus enabling prefetching into fast cache memories of the state needed to process them, just-in-time for the packets' arrival. We explore possible approaches to (i) obtain such hints either from network devices or the end hosts in the communication and (ii) use these hints to better utilize cache memories. We show that such information (if accurate) can improve packet processing throughput by at least 50%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04344v1</guid>
      <category>cs.NI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Hamid Ghasemirahni, Alireza Farshin, Dejan Kostic, Marco Chiesa</dc:creator>
    </item>
    <item>
      <title>CBL: Compact Encoding of JSON-LD Data using CBOR and Bitmaps for Web of Things</title>
      <link>https://arxiv.org/abs/2407.04398</link>
      <description>arXiv:2407.04398v1 Announce Type: new 
Abstract: The concept of Web of Things (WoT) merges web technologies with knowledge graphs in the context of Internet of Things. Given its widespread adoption in representing and exchanging structured data online, JSON-LD could be an effective format for WoT. Nevertheless, its verbose nature may present challenges for resource-constrained IoT devices with limited bandwidth and memory capacities.
  In this paper, we present a novel approach to compactly represent JSON-LD data using the Concise Binary Object Representation (CBOR) and bitmaps. Our proposed method is named as CBL which stands for CBOR, Bitmap and List of Key-value pairs. CBL leverages the ideas from CBOR and HDT to achieve an efficient encoding of JSON-LD data.
  Results demonstrate that our approach provides savings up to 95.1% in terms of network overhead. This could be especially beneficial for IoT devices exchanging data over wireless networks. Moreover, our approach is more efficient than the current approach known as CBOR-LD, which is used to compact JSON-LD data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04398v1</guid>
      <category>cs.NI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Prudhvi Gudla, Kamal Singh</dc:creator>
    </item>
    <item>
      <title>Rethinking Image Compression on the Web with Generative AI</title>
      <link>https://arxiv.org/abs/2407.04542</link>
      <description>arXiv:2407.04542v1 Announce Type: new 
Abstract: The rapid growth of the Internet, driven by social media, web browsing, and video streaming, has made images central to the Web experience, resulting in significant data transfer and increased webpage sizes. Traditional image compression methods, while reducing bandwidth, often degrade image quality. This paper explores a novel approach using generative AI to reconstruct images at the edge or client-side. We develop a framework that leverages text prompts and provides additional conditioning inputs like Canny edges and color palettes to a text-to-image model, achieving up to 99.8% bandwidth savings in the best cases and 92.6% on average, while maintaining high perceptual similarity. Empirical analysis and a user study show that our method preserves image meaning and structure more effectively than traditional compression methods, offering a promising solution for reducing bandwidth usage and improving Internet affordability with minimal degradation in image quality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04542v1</guid>
      <category>cs.NI</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>eess.IV</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shayan Ali Hassan, Danish Humair, Ihsan Ayyub Qazi, Zafar Ayyub Qazi</dc:creator>
    </item>
    <item>
      <title>Wireless Spectrum in Rural Farmlands: Status, Challenges and Opportunities</title>
      <link>https://arxiv.org/abs/2407.04561</link>
      <description>arXiv:2407.04561v1 Announce Type: new 
Abstract: Due to factors such as low population density and expansive geographical distances, network deployment falls behind in rural regions, leading to a broadband divide. Wireless spectrum serves as the blood and flesh of wireless communications. Shared white spaces such as those in the TVWS and CBRS spectrum bands offer opportunities to expand connectivity, innovate, and provide affordable access to high-speed Internet in under-served areas without additional cost to expensive licensed spectrum. However, the current methods to utilize these white spaces are inefficient due to very conservative models and spectrum policies, causing under-utilization of valuable spectrum resources. This hampers the full potential of innovative wireless technologies that could benefit farmers, small Internet Service Providers (ISPs) or Mobile Network Operators (MNOs) operating in rural regions. This study explores the challenges faced by farmers and service providers when using shared spectrum bands to deploy their networks while ensuring maximum system performance and minimizing interference with other users. Additionally, we discuss how spatiotemporal spectrum models, in conjunction with database-driven spectrum-sharing solutions, can enhance the allocation and management of spectrum resources, ultimately improving the efficiency and reliability of wireless networks operating in shared spectrum bands.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04561v1</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mukaram Shahid, Kunal Das, Taimoor Ul Islam, Christ Somiah, Daji Qiao, Arsalan Ahmad, Jimming Song, Zhengyuan Zhu, Sarath Babu, Yong Guan, Tusher Chakraborty, Suraj Jog, Ranveer Chandra, Hongwei Zhang</dc:creator>
    </item>
    <item>
      <title>Experiences with Sub-Arctic Sensor Network Deployment and Feasibility of Geothermal Energy Harvesting</title>
      <link>https://arxiv.org/abs/2407.04594</link>
      <description>arXiv:2407.04594v1 Announce Type: new 
Abstract: This paper discusses the experiences gained from designing, deploying and maintaining low-power wireless sensor networks in three geothermally active remote locations in Iceland. The purpose of deploying the network was to collect soil temperature data and investigate the impact of global warming on (sub)Arctic climate and subsequent carbon release. Functional networks from three sites with no direct access to power and the internet have been providing researchers with insight into the warming impacts since 2021. The network employs low-power wireless sensor nodes equipped with DASH7 communication protocol, providing real-time data and remote access to sensors and instruments deployed in the field. In addition to discussing the architecture and deployment of the network, we conduct a primary analysis using models and methods to demonstrate the feasibility of harvesting energy from the temperature gradient between geothermally active soil and air.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04594v1</guid>
      <category>cs.NI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Priyesh Pappinisseri Puluckul, Maarten Weyn</dc:creator>
    </item>
    <item>
      <title>Charging Ahead: A Hierarchical Adversarial Framework for Counteracting Advanced Cyber Threats in EV Charging Stations</title>
      <link>https://arxiv.org/abs/2407.03729</link>
      <description>arXiv:2407.03729v1 Announce Type: cross 
Abstract: The increasing popularity of electric vehicles (EVs) necessitates robust defenses against sophisticated cyber threats. A significant challenge arises when EVs intentionally provide false information to gain higher charging priority, potentially causing grid instability. While various approaches have been proposed in existing literature to address this issue, they often overlook the possibility of attackers using advanced techniques like deep reinforcement learning (DRL) or other complex deep learning methods to achieve such attacks. In response to this, this paper introduces a hierarchical adversarial framework using DRL (HADRL), which effectively detects stealthy cyberattacks on EV charging stations, especially those leading to denial of charging. Our approach includes a dual approach, where the first scheme leverages DRL to develop advanced and stealthy attack methods that can bypass basic intrusion detection systems (IDS). Second, we implement a DRL-based scheme within the IDS at EV charging stations, aiming to detect and counter these sophisticated attacks. This scheme is trained with datasets created from the first scheme, resulting in a robust and efficient IDS. We evaluated the effectiveness of our framework against the recent literature approaches, and the results show that our IDS can accurately detect deceptive EVs with a low false alarm rate, even when confronted with attacks not represented in the training dataset.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03729v1</guid>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammed Al-Mehdhar, Abdullatif Albaseer, Mohamed Abdallah, Ala Al-Fuqaha</dc:creator>
    </item>
    <item>
      <title>Convolutional vs Large Language Models for Software Log Classification in Edge-Deployable Cellular Network Testing</title>
      <link>https://arxiv.org/abs/2407.03759</link>
      <description>arXiv:2407.03759v1 Announce Type: cross 
Abstract: Software logs generated by sophisticated network emulators in the telecommunications industry, such as VIAVI TM500, are extremely complex, often comprising tens of thousands of text lines with minimal resemblance to natural language. Only specialised expert engineers can decipher such logs and troubleshoot defects in test runs. While AI offers a promising solution for automating defect triage, potentially leading to massive revenue savings for companies, state-of-the-art large language models (LLMs) suffer from significant drawbacks in this specialised domain. These include a constrained context window, limited applicability to text beyond natural language, and high inference costs. To address these limitations, we propose a compact convolutional neural network (CNN) architecture that offers a context window spanning up to 200,000 characters and achieves over 96% accuracy (F1&gt;0.9) in classifying multifaceted software logs into various layers in the telecommunications protocol stack. Specifically, the proposed model is capable of identifying defects in test runs and triaging them to the relevant department, formerly a manual engineering process that required expert knowledge. We evaluate several LLMs; LLaMA2-7B, Mixtral 8x7B, Flan-T5, BERT and BigBird, and experimentally demonstrate their shortcomings in our specialized application. Despite being lightweight, our CNN significantly outperforms LLM-based approaches in telecommunications log classification while minimizing the cost of production. Our defect triaging AI model is deployable on edge devices without dedicated hardware and widely applicable across software logs in various industries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03759v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Achintha Ihalage, Sayed M. Taheri, Faris Muhammad, Hamed Al-Raweshidy</dc:creator>
    </item>
    <item>
      <title>Multi-Time Scale Service Caching and Pricing in MEC Systems with Dynamic Program Popularity</title>
      <link>https://arxiv.org/abs/2407.03804</link>
      <description>arXiv:2407.03804v1 Announce Type: cross 
Abstract: In mobile edge computing systems, base stations (BSs) equipped with edge servers can provide computing services to users to reduce their task execution time. However, there is always a conflict of interest between the BS and users. The BS prices the service programs based on user demand to maximize its own profit, while the users determine their offloading strategies based on the prices to minimize their costs. Moreover, service programs need to be pre-cached to meet immediate computing needs. Due to the limited caching capacity and variations in service program popularity, the BS must dynamically select which service programs to cache. Since service caching and pricing have different needs for adjustment time granularities, we propose a two-time scale framework to jointly optimize service caching, pricing and task offloading. For the large time scale, we propose a game-nested deep reinforcement learning algorithm to dynamically adjust service caching according to the estimated popularity information. For the small time scale, by modeling the interaction between the BS and users as a two-stage game, we prove the existence of the equilibrium under incomplete information and then derive the optimal pricing and offloading strategies. Extensive simulations based on a real-world dataset demonstrate the efficiency of the proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03804v1</guid>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yiming Chen, Xingyuan Hu, Bo Gu, Shimin Gong, Zhou Su</dc:creator>
    </item>
    <item>
      <title>Pathfinder: Exploring Path Diversity for Assessing Internet Censorship Inconsistency</title>
      <link>https://arxiv.org/abs/2407.04213</link>
      <description>arXiv:2407.04213v1 Announce Type: cross 
Abstract: Internet censorship is typically enforced by authorities to achieve information control for a certain group of Internet users. So far existing censorship studies have primarily focused on country-level characterization because (1) in many cases, censorship is enabled by governments with nationwide policies and (2) it is usually hard to control how the probing packets are routed to trigger censorship in different networks inside a country. However, the deployment and implementation of censorship could be highly diverse at the ISP level. In this paper, we investigate Internet censorship from a different perspective by scrutinizing the diverse censorship deployment inside a country. Specifically, by leveraging an end-to-end measurement framework, we deploy multiple geo-distributed back-end control servers to explore various paths from one single vantage point. The generated traffic with the same domain but different control servers' IPs could be forced to traverse different transit networks, thereby being examined by different censorship devices if present. Through our large-scale experiments and in-depth investigation, we reveal that the diversity of Internet censorship caused by different routing paths inside a country is prevalent, implying that (1) the implementations of centralized censorship are commonly incomplete or flawed and (2) decentralized censorship is also common. Moreover, we identify that different hosting platforms also result in inconsistent censorship activities due to different peering relationships with the ISPs in a country. Finally, we present extensive case studies in detail to illustrate the configurations that lead to censorship inconsistency and explore the causes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04213v1</guid>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaoqin Liang, Guannan Liu, Lin Jin, Shuai Hao, Haining Wang</dc:creator>
    </item>
    <item>
      <title>A Semantic-Aware Multiple Access Scheme for Distributed, Dynamic 6G-Based Applications</title>
      <link>https://arxiv.org/abs/2401.06308</link>
      <description>arXiv:2401.06308v2 Announce Type: replace 
Abstract: The emergence of the semantic-aware paradigm presents opportunities for innovative services, especially in the context of 6G-based applications. Although significant progress has been made in semantic extraction techniques, the incorporation of semantic information into resource allocation decision-making is still in its early stages, lacking consideration of the requirements and characteristics of future systems. In response, this paper introduces a novel formulation for the problem of multiple access to the wireless spectrum. It aims to optimize the utilization-fairness trade-off, using the $\alpha$-fairness metric, while accounting for user data correlation by introducing the concepts of self- and assisted throughputs. Initially, the problem is analyzed to identify its optimal solution. Subsequently, a Semantic-Aware Multi-Agent Double and Dueling Deep Q-Learning (SAMA-D3QL) technique is proposed. This method is grounded in Model-free Multi-Agent Deep Reinforcement Learning (MADRL), enabling the user equipment to autonomously make decisions regarding wireless spectrum access based solely on their local individual observations. The efficiency of the proposed technique is evaluated through two scenarios: single-channel and multi-channel. The findings illustrate that, across a spectrum of $\alpha$ values, association matrices, and channels, SAMA-D3QL consistently outperforms alternative approaches. This establishes it as a promising candidate for facilitating the realization of future federated, dynamically evolving applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.06308v2</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hamidreza Mazandarani, Masoud Shokrnezhad, Tarik Taleb</dc:creator>
    </item>
    <item>
      <title>Graph Neural Networks as an Enabler of Terahertz-based Flow-guided Nanoscale Localization over Highly Erroneous Raw Data</title>
      <link>https://arxiv.org/abs/2307.05551</link>
      <description>arXiv:2307.05551v4 Announce Type: replace-cross 
Abstract: Contemporary research advances in nanotechnology and material science are rooted in the emergence of nanodevices as a versatile tool that harmonizes sensing, computing, wireless communication, data storage, and energy harvesting. These devices offer novel pathways for disease diagnostics, treatment, and monitoring within the bloodstreams. Ensuring precise localization of events of diagnostic interest, which underpins the concept of flow-guided in-body nanoscale localization, would provide an added diagnostic value to the detected events. Raw data generated by the nanodevices is pivotal for this localization and consist of an event detection indicator and the time elapsed since the last passage of a nanodevice through the heart. The energy constraints of the nanodevices lead to intermittent operation and unreliable communication, intrinsically affecting this data. This posits a need for comprehensively modelling the features of this data. These imperfections also have profound implications for the viability of existing flow-guided localization approaches, which are ill-prepared to address the intricacies of the environment. Our first contribution lies in an analytical model of raw data for flow-guided localization, dissecting how communication and energy capabilities influence the nanodevices' data output. This model acts as a vital bridge, reconciling idealized assumptions with practical challenges of flow-guided localization. Toward addressing these practical challenges, we also present an integration of Graph Neural Networks (GNNs) into the flow-guided localization paradigm. GNNs excel in capturing complex dynamic interactions inherent to the localization of events sensed by the nanodevices. Our results highlight the potential of GNNs not only to enhance localization accuracy but also extend coverage to encompass the entire bloodstream.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.05551v4</guid>
      <category>cs.LG</category>
      <category>cs.ET</category>
      <category>cs.NI</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gerard Calvo Bartra, Filip Lemic, Guillem Pascual, Aina P\'erez Rodas, Jakob Struye, Carmen Delgado, Xavier Costa P\'erez</dc:creator>
    </item>
  </channel>
</rss>
