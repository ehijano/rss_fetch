<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 22 Jan 2025 05:01:52 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Discrete time stochastic impulse control with delay</title>
      <link>https://arxiv.org/abs/2501.10444</link>
      <description>arXiv:2501.10444v1 Announce Type: new 
Abstract: We study a class of infinite-horizon impulse control problems with execution delay in discrete time. Using probabilistic methods, particularly the notion of the Snell envelope of processes, we construct an optimal strategy among all admissible strategies for both risk-neutral and risk-sensitive utility functions. Furthermore, we establish the existence of bounded $\epsilon$-optimal strategies. This framework provides a robust approach to handling execution delays in discrete-time stochastic systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10444v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Said Hamad\`ene (LMM), Boualem Djehiche (KTH)</dc:creator>
    </item>
    <item>
      <title>The Mathematics of Artificial Intelligence</title>
      <link>https://arxiv.org/abs/2501.10465</link>
      <description>arXiv:2501.10465v1 Announce Type: new 
Abstract: This overview article highlights the critical role of mathematics in artificial intelligence (AI), emphasizing that mathematics provides tools to better understand and enhance AI systems. Conversely, AI raises new problems and drives the development of new mathematics at the intersection of various fields. This article focuses on the application of analytical and probabilistic tools to model neural network architectures and better understand their optimization. Statistical questions (particularly the generalization capacity of these networks) are intentionally set aside, though they are of crucial importance. We also shed light on the evolution of ideas that have enabled significant advances in AI through architectures tailored to specific tasks, each echoing distinct mathematical techniques. The goal is to encourage more mathematicians to take an interest in and contribute to this exciting field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10465v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gabriel Peyr\'e</dc:creator>
    </item>
    <item>
      <title>Generalized TCP-RED dynamical model for Internet congestion control</title>
      <link>https://arxiv.org/abs/2501.10473</link>
      <description>arXiv:2501.10473v1 Announce Type: new 
Abstract: Adaptive management of traffic congestion in the Internet is a complex problem that can gain useful insights from a dynamical approach. In this paper we propose and analyze a one-dimensional, discrete-time nonlinear model for Internet congestion control at the routers. Specifically, the states correspond to the average queue sizes of the incoming data packets and the dynamical core consists of a monotone or unimodal mapping with a unique fixed point. This model generalizes a previous one in that additional control parameters are introduced via the data packet drop probability with the objective of enhancing stability. To make the analysis more challenging, the original model was shown to exhibit the usual features of low-dimensional chaos with respect to several system and control parameters, e.g., positive Lyapunov exponents and Feigenbaum-like bifurcation diagrams. We concentrate first on the theoretical aspects that may promote the unique stationary state of the system to a global attractor, which in our case amounts to global stability. In a second step, those theoretical results are translated into stability domains for robust setting of the new control parameters in practical applications. Numerical simulations confirm that the new parameters make it possible to extend the stability domains, in comparison with previous results. Therefore, the present work may lead to an adaptive congestion control algorithm with a more stable performance than other algorithms currently in use.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10473v1</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.cnsns.2019.105075</arxiv:DOI>
      <arxiv:journal_reference>Communications in Nonlinear Science and Numerical Simulation, 2020, V.82</arxiv:journal_reference>
      <dc:creator>Jos\'e M. Amig\'o, Guillem Duran, Angel Gim\'enez, Oscar Mart\'inez-Bonastre, Jos\'e Valero</dc:creator>
    </item>
    <item>
      <title>Multiclass Queue Scheduling Under Slowdown: An Approximate Dynamic Programming Approach</title>
      <link>https://arxiv.org/abs/2501.10523</link>
      <description>arXiv:2501.10523v1 Announce Type: new 
Abstract: In many service systems, especially those in healthcare, customer waiting times can result in increased service requirements. Such service slowdowns can significantly impact system performance. Therefore, it is important to properly account for their impact when designing scheduling policies. Scheduling under wait-dependent service times is challenging, especially when multiple customer classes are heterogeneously affected by waiting. In this work, we study scheduling policies in multiclass, multiserver queues with wait-dependent service slowdowns. We propose a simulation-based Approximate Dynamic Programming (ADP) algorithm to find close-to-optimal scheduling policies. The ADP algorithm (i) represents the policy using classifiers based on the index policy structure, (ii) leverages a coupling method to estimate the differences of the relative value functions directly, and (iii) uses adaptive sampling for efficient state-space exploration. Through extensive numerical experiments, we illustrate that the ADP algorithm generates close-to-optimal policies that outperform well-known benchmarks. We also provide insights into the structure of the optimal policy, which reveals an important trade-off between instantaneous cost reduction and preventing the system from reaching high-cost equilibria. Lastly, we conduct a case study on scheduling admissions into rehabilitation care to illustrate the effectiveness of the ADP algorithm in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10523v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jing Dong, Berk G\"org\"ul\"u, Vahid Sarhangian</dc:creator>
    </item>
    <item>
      <title>Generic uniqueness and conjugate points for optimal control problems</title>
      <link>https://arxiv.org/abs/2501.10572</link>
      <description>arXiv:2501.10572v1 Announce Type: new 
Abstract: The paper is concerned with an optimal control problem on $\mathbb{R}^n$, where the dynamics is linear w.r.t.~the control functions. For a terminal cost $\psi$ in a $mathcal{G}_\delta$ set of $\mathcal{C}^4(\mathbb{R}^n)$ (i.e., in a countable intersection of open dense subsets), two main results are proved.Namely: the set $\Gamma_\psi\subset\mathbb{R}^n$ of conjugate points is closed, with locally bounded $(n-2)$-dimensional Hausdorff measure. Moreover, the set of initial points $y\in \mathbb{R}^n\setminus\Gamma_\psi$, which admit two or more globally optimal trajectories, is contained in the union of a locally finite family of embedded manifolds. In particular, the value function is continuously differentiable on an open, dense subset of $\mathbb{R}^n$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10572v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alberto Bressan, Marco Mazzola, Khai T. Nguyen</dc:creator>
    </item>
    <item>
      <title>On a geometric graph-covering problem related to optimal safety-landing-site location</title>
      <link>https://arxiv.org/abs/2501.10742</link>
      <description>arXiv:2501.10742v1 Announce Type: new 
Abstract: We propose integer-programming formulations for an optimal safety-landing site (SLS) location problem that arises in the design of urban air-transportation networks. We first develop a set-cover based approach for the case where the candidate location set is finite and composed of points, and we link the problems to solvable cases that have been studied. We then use a mixed-integer second-order cone program to model the situation where the locations of SLSs are restricted to convex sets only. Finally, we introduce strong fixing, which we found to be very effective in reducing the size of integer programs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10742v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Claudia D'Ambrosio, Marcia Fampa, Jon Lee, Felipe Sinnecker</dc:creator>
    </item>
    <item>
      <title>Risk-Averse Antibiotics Time Machine Problem</title>
      <link>https://arxiv.org/abs/2501.10769</link>
      <description>arXiv:2501.10769v1 Announce Type: new 
Abstract: Antibiotic resistance, which is a serious healthcare issue, emerges due to uncontrolled and repeated antibiotic use that causes bacteria to mutate and develop resistance to antibiotics. The Antibiotics Time Machine Problem aims to come up with treatment plans that maximize the probability of reversing these mutations. Motivated by the severity of the problem, we develop a risk-averse approach and formulate a scenario-based mixed-integer linear program with a conditional value-at-risk objective function. We propose a risk-averse scenario batch decomposition algorithm that partitions the scenarios into manageable risk-averse subproblems, enabling the construction of lower and upper bounds. We develop several algorithmic enhancements in the form of stronger no-good cuts and symmetry breaking constraints in addition to scenario regrouping and warm starting. We conduct extensive computational experiments for static and dynamic versions of the problem on a real dataset and demonstrate the effectiveness of our approach. Our results suggest that risk-averse solutions can achieve significantly better worst-case performance compared to risk-neutral solutions with a slight decrease in terms of the average performance, especially for the dynamic version. Although our methodology is presented in the context of the Antibiotics Time Machine Problem, it can be adapted to other risk-averse problem settings in which the decision variables come from special ordered sets of type one.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10769v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Deniz Tuncer, Burak Kocuk</dc:creator>
    </item>
    <item>
      <title>Supervised Large Neighbourhood Search for MIPs</title>
      <link>https://arxiv.org/abs/2501.10778</link>
      <description>arXiv:2501.10778v1 Announce Type: new 
Abstract: Large Neighbourhood Search (LNS) is a powerful heuristic framework for solving Mixed-Integer Programming (MIP) problems. However, designing effective variable selection strategies in LNS remains challenging, especially for diverse sets of problems. In this paper, we propose an approach that integrates Machine Learning (ML) within the destroy operator of LNS for MIPs with a focus on minimal offline training. We implement a modular LNS matheuristic as a test bench to compare different LNS heuristics, including our ML-enhanced LNS. Experimental results on the MIPLIB 2017 dataset demonstrate that the matheuristic can significantly improve the performance of state-of-the-art solvers like Gurobi and SCIP. We conduct analyses on noisy oracles to explore the impact of prediction accuracy on solution quality. Additionally, we develop techniques to enhance the ML model through loss adjustments and sampling routines. Our findings suggest that while random LNS remains competitive, our Supervised LNS (SLNS) outperforms other baselines and helps set the foundation for future research on ML for LNS methods that are both efficient and general.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10778v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Charly Robinson La Rocca, Jean-Fran\c{c}ois Cordeau, Emma Frejinger</dc:creator>
    </item>
    <item>
      <title>Non-Expansive Mappings in Two-Time-Scale Stochastic Approximation: Finite-Time Analysis</title>
      <link>https://arxiv.org/abs/2501.10806</link>
      <description>arXiv:2501.10806v1 Announce Type: new 
Abstract: Two-time-scale stochastic approximation is an iterative algorithm used in applications such as optimization, reinforcement learning, and control. Finite-time analysis of these algorithms has primarily focused on fixed point iterations where both time-scales have contractive mappings. In this paper, we study two-time-scale iterations, where the slower time-scale has a non-expansive mapping. For such algorithms, the slower time-scale can be considered a stochastic inexact Krasnoselskii-Mann iteration. We show that the mean square error decays at a rate $O(1/k^{1/4-\epsilon})$, where $\epsilon&gt;0$ is arbitrarily small. We also show almost sure convergence of iterates to the set of fixed points. We show the applicability of our framework by applying our results to minimax optimization, linear stochastic approximation, and Lagrangian optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10806v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>stat.ML</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Siddharth Chandak</dc:creator>
    </item>
    <item>
      <title>Automatic Calibration of Mesoscopic Traffic Simulation Using Vehicle Trajectory Data</title>
      <link>https://arxiv.org/abs/2501.10934</link>
      <description>arXiv:2501.10934v1 Announce Type: new 
Abstract: Traffic simulation models have long been popular in modern traffic planning and operation applications. Efficient calibration of simulation models is usually a crucial step in a simulation study. However, traditional calibration procedures are often resource-intensive and time-consuming, limiting the broader adoption of simulation models. In this study, a vehicle trajectory-based automatic calibration framework for mesoscopic traffic simulation is proposed. The framework incorporates behavior models from both the demand and the supply sides of a traffic network. An optimization-based network flow estimation model is designed for demand and route choice calibration. Dimensionality reduction techniques are incorporated to define the zoning system and the path choice set. A stochastic approximation model is established for capacity and driving behavior parameter calibration. The applicability and performance of the calibration framework are demonstrated through a case study for the City of Birmingham network in Michigan.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10934v1</guid>
      <category>math.OC</category>
      <category>physics.comp-ph</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ran Sun, Zihao Wang, Xingmin Wang, Henry X. Liu</dc:creator>
    </item>
    <item>
      <title>Multi-View Clustering Meets High-Dimensional Mixed Data: A Fusion Regularized Method</title>
      <link>https://arxiv.org/abs/2501.10972</link>
      <description>arXiv:2501.10972v1 Announce Type: new 
Abstract: Multi-view clustering leverages consistent and complementary information across multiple views to provide more comprehensive insights than analysis of single-view data. However, the heterogeneity and redundancy of high-dimensional mixed multi-view data pose significant challenges to the existing clustering techniques. In this paper, we propose a novel multi-view fusion regularized clustering method with adaptive group sparsity, enabling reliable clustering while effectively capturing local features. Technically, for multi-view data with mixed features exhibiting different distributions, different losses or divergence metrics are considered with a collective fusion penalty to obtain common groups. Moreover, the non-convex group sparsity consisting of inter-group sparsity and intra-group sparsity is utilized to screen informative features, thereby enhancing the robustness. Furthermore, we develop an effective proximal alternating direction method of multipliers (ADMM) and each subproblem admits a closed-form solution. It is rigorously proven that this algorithm globally converges to a Karush-Kuhn-Tucker (KKT) point, while establishing the equivalence between local minimum points and KKT points within a certain region. Extensive numerical experiments on both simulated and real data validate the superior performance of the presented method in clustering accuracy and feature selection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10972v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiangru Xing, Yan Li, Xin Wang, Huangyue Chen, Xianchao Xiu</dc:creator>
    </item>
    <item>
      <title>Global Independence of Irrelevant Alternatives, State-Salient Decision Rules and the Strict Condorcet Choice Function</title>
      <link>https://arxiv.org/abs/2501.10986</link>
      <description>arXiv:2501.10986v1 Announce Type: new 
Abstract: We present a simple proof of a well-known axiomatic characterization of state-salient decision rules, using Weak Dominance Criterion and Global Independence of Irrelevant Alternatives. Subsequently we provide a simple axiomatic characterization of the Strict-Condorcet choice function on the domain of all preference profiles that have a strict-Condorcet winner, assuming that if the first two ranks are occupied by the same two alternatives in all states of nature, then the chosen alternative will be the one from these two that is preferred to the other with probability greater than half-provided such an alternative exists. We also show that this result is not valid if we extend the domain to the set of all preference profiles that have a unique weak-Condorcet winner.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10986v1</guid>
      <category>math.OC</category>
      <category>econ.TH</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Somdeb Lahiri</dc:creator>
    </item>
    <item>
      <title>A Regularized Online Newton Method for Stochastic Convex Bandits with Linear Vanishing Noise</title>
      <link>https://arxiv.org/abs/2501.11127</link>
      <description>arXiv:2501.11127v1 Announce Type: new 
Abstract: We study a stochastic convex bandit problem where the subgaussian noise parameter is assumed to decrease linearly as the learner selects actions closer and closer to the minimizer of the convex loss function. Accordingly, we propose a Regularized Online Newton Method (RONM) for solving the problem, based on the Online Newton Method (ONM) of arXiv:2406.06506. Our RONM reaches a polylogarithmic regret in the time horizon $n$ when the loss function grows quadratically in the constraint set, which recovers the results of arXiv:2402.12042 in linear bandits. Our analyses rely on the growth rate of the precision matrix $\Sigma_t^{-1}$ in ONM and we find that linear growth solves the question exactly. These analyses also help us obtain better convergence rates when the loss function grows faster. We also study and analyze two new bandit models: stochastic convex bandits with noise scaled to a subgaussian parameter function and convex bandits with stochastic multiplicative noise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11127v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jingxin Zhan, Yuchen Xin, Kaicheng Jin, Zhihua Zhang</dc:creator>
    </item>
    <item>
      <title>Bounding the Settling Time of Finite-Time Stable Systems using Sum of Squares</title>
      <link>https://arxiv.org/abs/2501.11255</link>
      <description>arXiv:2501.11255v1 Announce Type: new 
Abstract: Finite-time stability (FTS) of a differential equation guarantees that solutions reach a given equilibrium point in finite time, where the time of convergence depends on the initial state of the system. For traditional stability notions such as exponential stability, the convex optimization framework of Sum-of-Squares (SoS) enables the computation of polynomial Lyapunov functions to certify stability. However, finite-time stable systems are characterized by non-Lipschitz, non-polynomial vector fields, rendering standard SoS methods inapplicable. To this end, in this paper, we show that the computation of a non-polynomial Lyapunov function certifying finite-time stability can be reformulated as computation of a polynomial one under a particular transformation that we develop in this work. As a result, SoS can be utilized to compute a Lyapunov function for FTS. This Lyapunov function can then be used to obtain a bound on the settling time. We first present this approach for the scalar case and then extend it to the multivariate case. Numerical examples demonstrate the effectiveness of our approach in both certifying finite-time stability and computing accurate settling time bounds. This work represents the first combination of SoS programming with settling time bounds for finite-time stable systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11255v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sengiyumva Kisole, Kunal Garg, Matthew Peet</dc:creator>
    </item>
    <item>
      <title>Relax-and-round strategies for solving the Unit Commitment problem with AC Power Flow constraints</title>
      <link>https://arxiv.org/abs/2501.11355</link>
      <description>arXiv:2501.11355v1 Announce Type: new 
Abstract: The Unit Commitment problem with AC power flow constraints (UC-ACOPF) is a non-convex mixed-integer nonlinear programming (MINLP) problem encountered in power systems. Its combination of combinatorial complexity and non-convex nonlinear constraints makes it particularly challenging. A common approach to tackle this issue is to relax the integrality condition, but this often results in infeasible solutions. Consequently, rounding heuristics are frequently employed to restore integer feasibility. This paper addresses recent advancements in heuristics aimed at quickly obtaining feasible solutions for the UC-ACOPF problem, focusing specifically on direct relax-and-round strategies. We propose a model-based heuristic that rescales the solution of the integer-relaxed problem before rounding. Furthermore, we introduce rounding formulas designed to enforce combinatorial constraints and aim to maintain AC feasibility in the resulting solutions. These methodologies are compared against standard direct rounding techniques in the literature, applied to a 6-bus and a 118-bus test systems. Additionally, we integrate the proposed heuristics into an implementation of the Feasibility Pump (FP) method, demonstrating their utility and potential to enhance existing rounding strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11355v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>D. G\'omez, S. G\"ottlich, A. R\'ios, P. Salgado</dc:creator>
    </item>
    <item>
      <title>Lagrangian Duality for Mixed-Integer Semidefinite Programming: Theory and Algorithms</title>
      <link>https://arxiv.org/abs/2501.11397</link>
      <description>arXiv:2501.11397v1 Announce Type: new 
Abstract: This paper presents the Lagrangian duality theory for mixed-integer semidefinite programming (MISDP). We derive the Lagrangian dual problem and prove that the resulting Lagrangian dual bound dominates the bound obtained from the continuous relaxation of the MISDP problem. We present a hierarchy of Lagrangian dual bounds by exploiting the theory of integer positive semidefinite matrices and propose three algorithms for obtaining those bounds. Our algorithms are variants of well-known algorithms for minimizing non-differentiable convex functions. The numerical results on the max-$k$-cut problem show that the Lagrangian dual bounds are substantially stronger than the semidefinite programming bound obtained by relaxing integrality, already for lower levels in the hierarchy. Computational costs for computing our bounds are small.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11397v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Frank de Meijer, Renata Sotirov</dc:creator>
    </item>
    <item>
      <title>A Survey of Exact and Approximation Algorithms for Linear-Parametric Optimization Problems</title>
      <link>https://arxiv.org/abs/2501.11544</link>
      <description>arXiv:2501.11544v1 Announce Type: new 
Abstract: Linear-parametric optimization, where multiple objectives are combined into a single objective using linear combinations with parameters as coefficients, has numerous links to other fields in optimization and a wide range of application areas. In this survey, we provide a comprehensive overview of structural results and algorithmic strategies for solving linear-parametric optimization problems exactly and approximately. Transferring concepts from related areas such as multi-objective optimization provides further relevant results. The survey consists of two parts: First, we list strategies that work in a general fashion and do not rely on specific problem structures. Second, we look at well-studied parametric optimization problems and cover both important theoretical results and specialized algorithmic approaches for these problems. Among these problems are parametric variants of shortest path problems, minimum cost flow and maximum flow problems, spanning tree problems, the knapsack problem, and matching problems. Overall, we cover the results from 128 publications (and refer to 33 supplemental works) published between 1963 and 2024.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11544v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Levin Nemesch, Stefan Ruzika, Clemens Thielen, Alina Wittmann</dc:creator>
    </item>
    <item>
      <title>Improved Mixing and Pressure Loss Formulations for Gas Network Optimization</title>
      <link>https://arxiv.org/abs/2501.11608</link>
      <description>arXiv:2501.11608v1 Announce Type: new 
Abstract: Non-convex, nonlinear gas network optimization models are used to determine the feasibility of flows on existing networks given constraints on network flows, gas mixing, and pressure loss along pipes. This work improves two existing gas network models: a discrete mixed-integer nonlinear program (MINLP) that uses binary variables to model positive and negative flows, and a continuous nonlinear program (NLP) that implements complementarity constraints with continuous variables. We introduce cuts to expedite the MINLP and we formulate two new pressure loss models that leverage the flow-splitting variables: one that is highly accurate and another that is simpler but less accurate. In computational tests using the global solver BARON our cuts and accurate pressure loss improves: (1) the average run time of the MINLP by a factor of 35, (2) the stability of the MINLP by solving every tested instance within 2.5 minutes (the baseline model timed out on 25% of instances), (3) the stability of the NLP by solving more instances than the baseline. Our simpler pressure loss model further improved run times in the MINLP (by a factor of 48 versus the baseline MINLP), but was unstable in the context of the NLP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11608v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Geonhee Kim, Christopher Lourenco, Daphne Skipper, Luze Xu</dc:creator>
    </item>
    <item>
      <title>Fully Adaptive Zeroth-Order Method for Minimizing Functions with Compressible Gradients</title>
      <link>https://arxiv.org/abs/2501.11616</link>
      <description>arXiv:2501.11616v1 Announce Type: new 
Abstract: We propose an adaptive zeroth-order method for minimizing differentiable functions with $L$-Lipschitz continuous gradients. The method is designed to take advantage of the eventual compressibility of the gradient of the objective function, but it does not require knowledge of the approximate sparsity level $s$ or the Lipschitz constant $L$ of the gradient. We show that the new method performs no more than $O\left(n^{2}\epsilon^{-2}\right)$ function evaluations to find an $\epsilon$-approximate stationary point of an objective function with $n$ variables. Assuming additionally that the gradients of the objective function are compressible, we obtain an improved complexity bound of $O\left(s\log\left(n\right)\epsilon^{-2}\right)$ function evaluations, which holds with high probability. Preliminary numerical results illustrate the efficiency of the proposed method and demonstrate that it can significantly outperform its non-adaptive counterpart.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11616v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Geovani Nunes Grapiglia, Daniel McKenzie</dc:creator>
    </item>
    <item>
      <title>On a Lemma by Br\'ezis and Haraux</title>
      <link>https://arxiv.org/abs/2501.11662</link>
      <description>arXiv:2501.11662v1 Announce Type: new 
Abstract: We propose several applications of an often overlooked part of the 1976 paper by Br\'ezis and Haraux, in which the celebrated Br\'ezis--Haraux theorem was established. Our results unify and extend various existing ones on the range of a composite monotone operator and provide new insight into the seminal work by Br\'ezis and Haraux.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11662v1</guid>
      <category>math.OC</category>
      <category>math.FA</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Minh N. B\`ui</dc:creator>
    </item>
    <item>
      <title>A Decomposition Framework for Nonlinear Nonconvex Two-Stage Optimization</title>
      <link>https://arxiv.org/abs/2501.11700</link>
      <description>arXiv:2501.11700v1 Announce Type: new 
Abstract: We propose a new decomposition framework for continuous nonlinear constrained two-stage optimization, where both first- and second-stage problems can be nonconvex. A smoothing technique based on an interior-point formulation renders the optimal solution of the second-stage problem differentiable with respect to the first-stage parameters. As a consequence, efficient off-the-shelf optimization packages can be utilized. We show that the solution of the nonconvex second-stage problem behaves locally like a differentiable function so that existing proofs can be applied for the global convergence of the first-stage. We also prove fast local convergence of the algorithm as the barrier parameter is driven to zero. Numerical experiments for large-scale instances demonstrate the computational advantages of the decomposition framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11700v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuchen Lou, Xinyi Luo, Andreas W\"achter, Ermin Wei</dc:creator>
    </item>
    <item>
      <title>Distributed Saddle-Point Dynamics in Multilayer Networks</title>
      <link>https://arxiv.org/abs/2501.11808</link>
      <description>arXiv:2501.11808v1 Announce Type: new 
Abstract: Multilayer networks provide a more advanced and comprehensive framework for modeling real-world systems compared to traditional single-layer and multiplex networks. Unlike single-layer models, multilayer networks have multiple interacting layers, each with unique topological features. In this paper, we generalize previously developed results for distributed optimization in multiplex networks to the more general case of multilayer networks by employing a tensor formalism to represent multilayer networks and their tensor-Laplacian diffusion dynamics. Although multiplex networks are a special case of multilayer networks, where each layer has the same number of replica nodes connected one-to-one, this generalized framework removes the need for replica nodes, allowing variability in both topology and number of nodes across layers. This approach provides a fully generalized structure for distributed optimization in multilayer networks and enables more complex interlayer connections. We derive the multilayer combinatorial Laplacian tensor and extend the distributed gradient descent algorithm. We provide a theoretical analysis of the convergence of algorithms. Numerical examples validate our approach, and we explore the impact of heterogeneous layer topologies and complex interlayer dynamics on consensus time, underscoring their implications for real-world multilayer systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11808v1</guid>
      <category>math.OC</category>
      <category>physics.app-ph</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christian D. Rodr\'iguez-Camargo, Andr\'es F. Urquijo-Rodr\'iguez, Eduardo Mojica-Nava</dc:creator>
    </item>
    <item>
      <title>Finding the nearest bounded-real port-Hamiltonian system</title>
      <link>https://arxiv.org/abs/2501.11903</link>
      <description>arXiv:2501.11903v1 Announce Type: new 
Abstract: In this paper, we consider linear time-invariant continuous control systems which are bounded real, also known as scattering passive. Our main theoretical contribution is to show the equivalence between such systems and port-Hamiltonian (PH) systems whose factors satisfy certain linear matrix inequalities. Based on this result, we propose a formulation for the problem of finding the nearest bounded-real system to a given system, and design an algorithm combining alternating optimization and Nesterov's fast gradient method. This formulation also allows us to check whether a given system is bounded real by solving a semidefinite program, and provide a PH parametrization for it. We illustrate our proposed algorithms on real and synthetic data sets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11903v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.NA</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Karim Cherifi, Nicolas Gillis, Punit Sharma</dc:creator>
    </item>
    <item>
      <title>Stabilizing Optimal Control for Nonlinear Stochastic Systems: A Parametric Gradient-Based Approach</title>
      <link>https://arxiv.org/abs/2501.11915</link>
      <description>arXiv:2501.11915v1 Announce Type: new 
Abstract: This study proposes a method for designing stabilizing suboptimal controllers for nonlinear stochastic systems. These systems include time-invariant stochastic parameters that represent uncertainty of dynamics, posing two key difficulties in optimal control. Firstly, the time-invariant stochastic nature violates the principle of optimality and Hamilton-Jacobi equations, which are fundamental tools for solving optimal control problems. Secondly, nonlinear systems must be robustly stabilized against these stochastic parameters. To overcome these difficulties simultaneously, this study presents a parametric-gradient-based method with a penalty function. A controller and cost function are parameterized using basis functions, and a gradient method is employed to optimize the controller by minimizing the parameterized cost function. Crucial challenges in this approach are parameterizing the cost function appropriately and deriving the gradient of the cost. This study provides explicit formulations of an optimally parameterized cost and its gradient. Furthermore, a suitable penalty function is proposed to ensure robust stability, even when using the gradient method. Consequently, the gradient method produces a suboptimal feedback controller that guarantees the robust stability. The effectiveness of the proposed method is demonstrated through numerical simulations, highlighting its performance in comparison with other baseline methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11915v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuji Ito, Kenji Fujimoto</dc:creator>
    </item>
    <item>
      <title>Towards Solutions of Manipulation Tasks via Optimal Control of Projected Dynamical Systems</title>
      <link>https://arxiv.org/abs/2501.11946</link>
      <description>arXiv:2501.11946v1 Announce Type: new 
Abstract: We introduce a modeling framework for manipulation planning based on the formulation of the dynamics as a projected dynamical system. This method uses implicit signed distance functions and their gradients to formulate an equivalent gradient complementarity system. The optimal control problem is then solved via a direct method, discretized using finite-elements with switch detection. An extension to this approach is provided in the form of a friction formulation commonly used in quasi-static models. We show that this approach is able to generate trajectories for problems including multiple pushers, friction, and non-convex objects modeled as unions of convex ellipsoids with reasonable computational effort.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11946v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anton Pozharskiy, Armin Nurkanovi\'c, Moritz Diehl</dc:creator>
    </item>
    <item>
      <title>Growth model with externalities for energetic transition via MFG with common external variable</title>
      <link>https://arxiv.org/abs/2501.11988</link>
      <description>arXiv:2501.11988v1 Announce Type: new 
Abstract: This article introduces a novel mean-field game model for multi-sector economic growth in which a dynamically evolving externality, influenced by the collective actions of agents, plays a central role. Building on classical growth theories and integrating environmental considerations, the framework incorporates common noise to capture shared uncertainties among agents about the externality variable. We demonstrate the existence and uniqueness of a strong mean-field game equilibrium by reformulating the equilibrium conditions as a Forward-Backward Stochastic Differential Equation under the stochastic maximum principle and establishing a contraction argument to ensure a unique solution. We provide a numerical resolution for a specified model using a fixed-point approach combined with neural network approximations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11988v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pierre Lavigne, Quentin Petit, Xavier Warin</dc:creator>
    </item>
    <item>
      <title>Gram-like matrix preserving extensions of noncommutative polynomials to sum of Hermitian Squares</title>
      <link>https://arxiv.org/abs/2501.12063</link>
      <description>arXiv:2501.12063v1 Announce Type: new 
Abstract: Given a nonnegative noncommutative polynomial $f$, equivalently a sum of Hermitian squares (SOHS), there exists a positive semidefinite Gram matrix that encrypts all essential information of $f$. There are no available methods for extending a noncommutative polynomial to a SOHS keeping the Gram matrices unperturbed. As a remedy, we introduce an equally significant notion of Gram-like matrices and provide linear algebraic techniques to get the desired extensions. We further use positive semidefinite completion problem to get SOHS and provide criteria in terms of chordal graphs and 2-regular projective algebraic sets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12063v1</guid>
      <category>math.OC</category>
      <category>math.AC</category>
      <category>math.AG</category>
      <category>math.FA</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arijit Mukherjee, Arindam Sutradhar</dc:creator>
    </item>
    <item>
      <title>MirrorCBO: A consensus-based optimization method in the spirit of mirror descent</title>
      <link>https://arxiv.org/abs/2501.12189</link>
      <description>arXiv:2501.12189v1 Announce Type: new 
Abstract: In this work we propose MirrorCBO, a consensus-based optimization (CBO) method which generalizes standard CBO in the same way that mirror descent generalizes gradient descent. For this we apply the CBO methodology to a swarm of dual particles and retain the primal particle positions by applying the inverse of the mirror map, which we parametrize as the subdifferential of a strongly convex function $\phi$. In this way, we combine the advantages of a derivative-free non-convex optimization algorithm with those of mirror descent. As a special case, the method extends CBO to optimization problems with convex constraints. Assuming bounds on the Bregman distance associated to $\phi$, we provide asymptotic convergence results for MirrorCBO with explicit exponential rate. Another key contribution is an exploratory numerical study of this new algorithm across different application settings, focusing on (i) sparsity-inducing optimization, and (ii) constrained optimization, demonstrating the competitive performance of MirrorCBO. We observe empirically that the method can also be used for optimization on (non-convex) submanifolds of Euclidean space, can be adapted to mirrored versions of other recent CBO variants, and that it inherits from mirror descent the capability to select desirable minimizers, like sparse ones. We also include an overview of recent CBO approaches for constrained optimization and compare their performance to MirrorCBO.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12189v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Leon Bungert, Franca Hoffmann, Doh Yeon Kim, Tim Roith</dc:creator>
    </item>
    <item>
      <title>Convergence of time-delayed opinion dynamics with complex interaction types</title>
      <link>https://arxiv.org/abs/2501.12219</link>
      <description>arXiv:2501.12219v1 Announce Type: new 
Abstract: In opinion dynamics, time delays in agent-to-agent interactions are ubiquitous, which can substantially disrupt the dynamical processes rooted in agents' opinion exchange, decision-making, and feedback mechanisms. However, a thorough comprehension of quantitative impacts of time delays on the opinion evolution, considering diverse interaction types and system dynamics, remains absent. In this paper, we conduct a systematic investigation into the convergence and the associated rate of time-delayed opinion dynamics with diverse interaction types in both discrete-time and continuous-time systems. For the discrete-time system, we commence by establishing sufficient conditions for its convergence on arbitrary signed interaction networks. These conditions show that the convergence is determined solely by the topology of the interaction network and remains impervious to the magnitude of the time delay. Subsequently, we examine the influence of random and other interaction types on the convergence rate and discover that time delays tend to decelerate this rate. Regarding the continuous-time system, we derive the feasible domain of the delay that ensures the convergence of opinion dynamics, revealing that, unlike the discrete-time scenarios, large time delays can instigate the divergence of opinions. Specifically, we prove that for both random and other interaction types, small delays can expedite the convergence of continuous-time system. Finally, we present simulation examples to demonstrate the effectiveness and robustness of our research findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12219v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Lingling Yao, Aming Li</dc:creator>
    </item>
    <item>
      <title>Fast sparse optimization via adaptive shrinkage</title>
      <link>https://arxiv.org/abs/2501.12236</link>
      <description>arXiv:2501.12236v1 Announce Type: new 
Abstract: The need for fast sparse optimization is emerging, e.g., to deal with large-dimensional data-driven problems and to track time-varying systems. In the framework of linear sparse optimization, the iterative shrinkage-thresholding algorithm is a valuable method to solve Lasso, which is particularly appreciated for its ease of implementation. Nevertheless, it converges slowly. In this paper, we develop a proximal method, based on logarithmic regularization, which turns out to be an iterative shrinkage-thresholding algorithm with adaptive shrinkage hyperparameter. This adaptivity substantially enhances the trajectory of the algorithm, in a way that yields faster convergence, while keeping the simplicity of the original method. Our contribution is twofold: on the one hand, we derive and analyze the proposed algorithm; on the other hand, we validate its fast convergence via numerical experiments and we discuss the performance with respect to state-of-the-art algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12236v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Vito Cerone, Sophie M. Fosson, Diego Regruto</dc:creator>
    </item>
    <item>
      <title>Lie-Bracket Nash Equilibrium Seeking with Bounded Update Rates for Noncooperative Games</title>
      <link>https://arxiv.org/abs/2501.12256</link>
      <description>arXiv:2501.12256v1 Announce Type: new 
Abstract: This paper proposes a novel approach for local convergence to Nash equilibrium in quadratic noncooperative games based on a distributed Lie-bracket extremum seeking control scheme. This is the first instance of noncooperative games being tackled in a model-free fashion integrated with the extremum seeking method of bounded update rates. In particular, the stability analysis is carried out using Lie-bracket approximation and Lyapunov's direct method. We quantify the size of the ultimate small residual sets around the Nash equilibrium and illustrate the theoretical results numerically on an example in an oligopoly setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12256v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Victor Hugo Pereira Rodrigues, Tiago Roux Oliveira, Miroslav Krstic, Tamer Basar</dc:creator>
    </item>
    <item>
      <title>Spatial exponential decay of perturbations in optimal control of general evolution equations</title>
      <link>https://arxiv.org/abs/2501.12279</link>
      <description>arXiv:2501.12279v1 Announce Type: new 
Abstract: We analyze the robustness of optimally controlled evolution equations with respect to spatially localized perturbations. We prove that if the involved operators are domain-uniformly stabilizable and detectable, then these localized perturbations only have a local effect on the optimal solution. We characterize this domain-uniform stabilizability and detectability for the transport equation with constant transport velocity, showing that even for unitary semigroups, optimality implies exponential damping. Finally, we extend our result to the case of a space-dependent transport velocity. Numerical examples in one space dimension complement the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12279v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.AP</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Simone G\"ottlich, Benedikt Oppeneiger, Manuel Schaller, Karl Worthmann</dc:creator>
    </item>
    <item>
      <title>Extending the Leader-First Follower Structure for Bearing-only Formation Control on Directed Graphs</title>
      <link>https://arxiv.org/abs/2501.12355</link>
      <description>arXiv:2501.12355v1 Announce Type: new 
Abstract: This work proposes an extension to the leader-first follower (LFF) class of graphs used to solve the bearing-only formation control problem over directed graphs. The first contribution provides an equilibrium, stability, and convergence analysis for a one-follower, multi-leader system (which is not an LFF graph). We then propose an extension to the LFF structure, termed \emph{ordered} LFF graphs, that allows for additional forward directed edges to be included. Using the results of the one-follower multi-leader system we show that the ordered LFF graphs can be used to solve the directed bearing-only formation control problem. We also show that these structures offer improved convergence speed as compared to the LFF graphs. Numerical simulations are provided to validate the results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12355v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiacheng Shi, Daniel Zelazo</dc:creator>
    </item>
    <item>
      <title>Ensemble control of n-level quantum systems with a scalar control</title>
      <link>https://arxiv.org/abs/2501.12357</link>
      <description>arXiv:2501.12357v1 Announce Type: new 
Abstract: In this paper we discuss how a general bilinear finite-dimensional closed quantum system with dispersed parameters can be steered between eigenstates. We show that, under suitable conditions on the separation of spectral gaps and the boundedness of parameter dispersion, rotating wave and adiabatic approximations can be employed in cascade to achieve population inversion between arbitrary eigenstates. We propose an explicit control law and test numerically the sharpness of the conditions on several examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12357v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruikang Liang, Ugo Boscain, Mario Sigalotti</dc:creator>
    </item>
    <item>
      <title>An algorithm for determining the state of a non-stationary dynamic system for assessing fire safety control in an enterprise by the method of integrated indicators</title>
      <link>https://arxiv.org/abs/2501.10380</link>
      <description>arXiv:2501.10380v1 Announce Type: cross 
Abstract: Analysis of the scientific literature showed that a lot of work is devoted to assessing the effectiveness of fire safety management in an enterprise. It is worth noting that today there is no universal method for the integrated assessment of fire safety management, taking into account the interconnectedness of all enterprise subsystems and the influence of environmental factors. One of the original approaches to assessing the effectiveness of the fire safety management system is the method of integral indicators. The method of integral indicators is used in the algorithm for analyzing the state of a dynamic non-stationary system for assessing fire safety management in an enterprise. The algorithm is implemented in the author's complex of programs described in the text of the article. In the simulation, an analysis of 1.2 million values is performed on a well-studied economic object with the spaces identified at each time step: actual data, control and environmental parameters. In the experiment, the basic mode of operation of the enterprise does not contain the implementation of a fire safety management strategy. The research showed significant changes in the values of the integral indicator characterizing the state of the enterprise during the implementation of the fire safety management system at the enterprise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10380v1</guid>
      <category>cs.CY</category>
      <category>math.OC</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1088/1757-899X/919/4/042014</arxiv:DOI>
      <arxiv:journal_reference>IOP Conf. Ser.: Mater. Sci. Eng. 919 042014 (2020)</arxiv:journal_reference>
      <dc:creator>Sergey Masaev, Andrey Minkin, Dmitriy Edimichev</dc:creator>
    </item>
    <item>
      <title>Assessment of the application of the Universal Competencies</title>
      <link>https://arxiv.org/abs/2501.10381</link>
      <description>arXiv:2501.10381v1 Announce Type: cross 
Abstract: Application of Universal Competencies in Russian educational institutions is very important. Based on them, educational standards are invented. However, there is no universal assessment of the application of the Universal Competencies in practice. The main idea of the research is a general assessment of the application of universal competencies. For this, the activity of the enterprise is modeled. The enterprise process model is combined with the Universal Competencies. Further, the measurement is made by a universal indicator. The analysis of the dynamics of the universal indicator proves the existence of an assessment of the application of the Universal Competencies at a production facility. The integral indicator is a universal assessment of the application of the Universal Competencies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10381v1</guid>
      <category>cs.CY</category>
      <category>math.OC</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1088/1742-6596/1691/1/012020</arxiv:DOI>
      <arxiv:journal_reference>J. Phys.: Conf. Ser. 1691 012020 (2020)</arxiv:journal_reference>
      <dc:creator>Sergey Masaev, Georgiy Dorrer, Andrey Minkin, Aleksey Bogdanov, Yass Salal</dc:creator>
    </item>
    <item>
      <title>Computing Capacity-Cost Functions for Continuous Channels in Wasserstein Space</title>
      <link>https://arxiv.org/abs/2501.10670</link>
      <description>arXiv:2501.10670v1 Announce Type: cross 
Abstract: This paper investigates the problem of computing capacity-cost (C-C) functions for continuous channels. Motivated by the Kullback-Leibler divergence (KLD) proximal reformulation of the classical Blahut-Arimoto (BA) algorithm, the Wasserstein distance is introduced to the proximal term for the continuous case, resulting in an iterative algorithm related to the Wasserstein gradient descent. Practical implementation involves moving particles along the negative gradient direction of the objective function's first variation in the Wasserstein space and approximating integrals by the importance sampling (IS) technique. Such formulation is also applied to the rate-distortion (R-D) function for continuous source spaces and thus provides a unified computation framework for both problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10670v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xinyang Li, Vlad C. Andrei, Ullrich J. M\"onich, Fan Liu, Holger Boche</dc:creator>
    </item>
    <item>
      <title>Stability of neural ODEs by a control over the expansivity of their flows</title>
      <link>https://arxiv.org/abs/2501.10740</link>
      <description>arXiv:2501.10740v1 Announce Type: cross 
Abstract: We propose a method to enhance the stability of a neural ordinary differential equation (neural ODE) by means of a control over the Lipschitz constant $C$ of its flow. Since it is known that $C$ depends on the logarithmic norm of the Jacobian matrix associated with the neural ODE, we tune this parameter at our convenience by suitably perturbing the Jacobian matrix with a perturbation as small as possible in Frobenius norm. We do so by introducing an optimization problem for which we propose a nested two-level algorithm. For a given perturbation size, the inner level computes the optimal perturbation with a fixed Frobenius norm, while the outer level tunes the perturbation amplitude. We embed the proposed algorithm in the training of the neural ODE to improve its stability. Numerical experiments on the MNIST and FashionMNIST datasets show that an image classifier including a neural ODE in its architecture trained according to our strategy is more stable than the same classifier trained in the classical way, and therefore, it is more robust and less vulnerable to adversarial attacks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10740v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arturo De Marinis, Nicola Guglielmi, Stefano Sicilia, Francesco Tudisco</dc:creator>
    </item>
    <item>
      <title>Changing the ranking in eigenvector centrality of a weighted graph by small perturbations</title>
      <link>https://arxiv.org/abs/2501.10745</link>
      <description>arXiv:2501.10745v1 Announce Type: cross 
Abstract: In this article, we consider eigenvector centrality for the nodes of a graph and study the robustness (and stability) of this popular centrality measure. For a given weighted graph $\G$ (both directed and undirected), we consider the associated weighted adiacency matrix $A$, which by definition is a non-negative matrix. Eigenvector centrality consists of ranking the elements of the graph according to the corresponding entries of the Perron eigenvector of $A$, which is associated with the positive eigenvalue with largest modulus.
  An indicator of the robustness of eigenvector centrality consists in looking for a nearby perturbed graph $\widetilde{\G}$, with the same structure as $\G$ (i.e., with the same vertices and edges), but with a weighted adiacency matrix $\widetilde A$ such that the highest $m$ entries ($m \ge 2$) of the Perron eigenvector of $\widetilde A$ coalesce, making the ranking at the highest level ambiguous. To compute a solution to this matrix nearness problem, a nested iterative algorithm is proposed that makes use of a constrained gradient system of matrix differential equations (possibly on a low-rank manifold) in the inner iteration and a one-dimensional optimization of the perturbation size in the outer iteration.
  The proposed algorithm produces the {\em optimal} perturbation (i.e., the one with smallest Frobenius norm) of the graph, which causes the looked-for coalescence, which is a measure of the sensitivity of the graph. The methodology is formulated in terms of graphs but applies to any nonnegative matrix, with potential applications in fields like population models, consensus dynamics, economics, etc.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10745v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Michele Benzi, Nicola Guglielmi</dc:creator>
    </item>
    <item>
      <title>Which price to pay? Auto-tuning building MPC controller for optimal economic cost</title>
      <link>https://arxiv.org/abs/2501.10859</link>
      <description>arXiv:2501.10859v1 Announce Type: cross 
Abstract: Model predictive control (MPC) controller is considered for temperature management in buildings but its performance heavily depends on hyperparameters. Consequently, MPC necessitates meticulous hyperparameter tuning to attain optimal performance under diverse contracts. However, conventional building controller design is an open-loop process without critical hyperparameter optimization, often leading to suboptimal performance due to unexpected environmental disturbances and modeling errors. Furthermore, these hyperparameters are not adapted to different pricing schemes and may lead to non-economic operations. To address these issues, we propose an efficient performance-oriented building MPC controller tuning method based on a cutting-edge efficient constrained Bayesian optimization algorithm, CONFIG, with global optimality guarantees. We demonstrate that this technique can be applied to efficiently deal with real-world DSM program selection problems under customized black-box constraints and objectives. In this study, a simple MPC controller, which offers the advantages of reduced commissioning costs, enhanced computational efficiency, was optimized to perform on a comparable level to a delicately designed and computationally expensive MPC controller. The results also indicate that with an optimized simple MPC, the monthly electricity cost of a household can be reduced by up to 26.90% compared with the cost when controlled by a basic rule-based controller under the same constraints. Then we compared 12 real electricity contracts in Belgium for a household family with customized black-box occupant comfort constraints. The results indicate a monthly electricity bill saving up to 20.18% when the most economic contract is compared with the worst one, which again illustrates the significance of choosing a proper electricity contract.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10859v1</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiarui Yu, Jicheng Shi, Wenjie Xu, Colin N. Jones</dc:creator>
    </item>
    <item>
      <title>Classical and Deep Reinforcement Learning Inventory Control Policies for Pharmaceutical Supply Chains with Perishability and Non-Stationarity</title>
      <link>https://arxiv.org/abs/2501.10895</link>
      <description>arXiv:2501.10895v1 Announce Type: cross 
Abstract: We study inventory control policies for pharmaceutical supply chains, addressing challenges such as perishability, yield uncertainty, and non-stationary demand, combined with batching constraints, lead times, and lost sales. Collaborating with Bristol-Myers Squibb (BMS), we develop a realistic case study incorporating these factors and benchmark three policies--order-up-to (OUT), projected inventory level (PIL), and deep reinforcement learning (DRL) using the proximal policy optimization (PPO) algorithm--against a BMS baseline based on human expertise. We derive and validate bounds-based procedures for optimizing OUT and PIL policy parameters and propose a methodology for estimating projected inventory levels, which are also integrated into the DRL policy with demand forecasts to improve decision-making under non-stationarity. Compared to a human-driven policy, which avoids lost sales through higher holding costs, all three implemented policies achieve lower average costs but exhibit greater cost variability. While PIL demonstrates robust and consistent performance, OUT struggles under high lost sales costs, and PPO excels in complex and variable scenarios but requires significant computational effort. The findings suggest that while DRL shows potential, it does not outperform classical policies in all numerical experiments, highlighting 1) the need to integrate diverse policies to manage pharmaceutical challenges effectively, based on the current state-of-the-art, and 2) that practical problems in this domain seem to lack a single policy class that yields universally acceptable performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10895v1</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Francesco Stranieri, Chaaben Kouki, Willem van Jaarsveld, Fabio Stella</dc:creator>
    </item>
    <item>
      <title>Packing Dijoins in Weighted Chordal Digraphs</title>
      <link>https://arxiv.org/abs/2501.10918</link>
      <description>arXiv:2501.10918v1 Announce Type: cross 
Abstract: In a digraph, a dicut is a cut where all the arcs cross in one direction. A dijoin is a subset of arcs that intersects every dicut. Edmonds and Giles conjectured that in a weighted digraph, the minimum weight of a dicut is equal to the maximum size of a packing of dijoins. This has been disproved. However, the unweighted version conjectured by Woodall remains open. We prove that the Edmonds-Giles conjecture is true if the underlying undirected graph is chordal. We also give a strongly polynomial time algorithm to construct such a packing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10918v1</guid>
      <category>math.CO</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>G\'erard Cornu\'ejols, Siyue Liu, R. Ravi</dc:creator>
    </item>
    <item>
      <title>Self-CephaloNet: A Two-stage Novel Framework using Operational Neural Network for Cephalometric Analysis</title>
      <link>https://arxiv.org/abs/2501.10984</link>
      <description>arXiv:2501.10984v1 Announce Type: cross 
Abstract: Cephalometric analysis is essential for the diagnosis and treatment planning of orthodontics. In lateral cephalograms, however, the manual detection of anatomical landmarks is a time-consuming procedure. Deep learning solutions hold the potential to address the time constraints associated with certain tasks; however, concerns regarding their performance have been observed. To address this critical issue, we proposed an end-to-end cascaded deep learning framework (Self-CepahloNet) for the task, which demonstrated benchmark performance over the ISBI 2015 dataset in predicting 19 dental landmarks. Due to their adaptive nodal capabilities, Self-ONN (self-operational neural networks) demonstrate superior learning performance for complex feature spaces over conventional convolutional neural networks. To leverage this attribute, we introduced a novel self-bottleneck in the HRNetV2 (High Resolution Network) backbone, which has exhibited benchmark performance on the ISBI 2015 dataset for the dental landmark detection task. Our first-stage results surpassed previous studies, showcasing the efficacy of our singular end-to-end deep learning model, which achieved a remarkable 70.95% success rate in detecting cephalometric landmarks within a 2mm range for the Test1 and Test2 datasets. Moreover, the second stage significantly improved overall performance, yielding an impressive 82.25% average success rate for the datasets above within the same 2mm distance. Furthermore, external validation was conducted using the PKU cephalogram dataset. Our model demonstrated a commendable success rate of 75.95% within the 2mm range.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10984v1</guid>
      <category>cs.CV</category>
      <category>math.OC</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Md. Shaheenur Islam Sumon, Khandaker Reajul Islam, Tanzila Rafique, Gazi Shamim Hassan, Md. Sakib Abrar Hossain, Kanchon Kanti Podder, Noha Barhom, Faleh Tamimi, Abdulrahman Alqahtani, Muhammad E. H. Chowdhury</dc:creator>
    </item>
    <item>
      <title>A mixed finite elements approximation of inverse source problems for the wave equation with variable coefficients using observability</title>
      <link>https://arxiv.org/abs/2501.11352</link>
      <description>arXiv:2501.11352v1 Announce Type: cross 
Abstract: We consider an inverse problem for the linear one-dimensional wave equation with variable coefficients consisting in determining an unknown source term from a boundary observation. A method to obtain approximations of this inverse problem using a space discretization based on a mixed finite element method is proposed and analyzed. Its stability and convergence relay on a new uniform boundary observability property with respect to the discretization parameter.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11352v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Carlos Castro, Sorin Micu</dc:creator>
    </item>
    <item>
      <title>Global Regularity Estimates for Optimal Transport via Entropic Regularisation</title>
      <link>https://arxiv.org/abs/2501.11382</link>
      <description>arXiv:2501.11382v1 Announce Type: cross 
Abstract: We develop a general approach to prove global regularity estimates for quadratic optimal transport using the entropic regularisation of the problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11382v1</guid>
      <category>math.FA</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nathael Gozlan, Maxime Sylvestre</dc:creator>
    </item>
    <item>
      <title>Large deviations for sticky-reflecting Brownian motion with boundary diffusion</title>
      <link>https://arxiv.org/abs/2501.11394</link>
      <description>arXiv:2501.11394v1 Announce Type: cross 
Abstract: We study a Schilder-type large deviation principle for sticky-reflected Brownian motion with boundary diffusion, both at the static and sample path level in the short-time limit. A sharp transition for the rate function occurs, depending on whether the tangential boundary diffusion is faster or slower than in the interior of the domain. The resulting intrinsic distance naturally gives rise to a novel optimal transport model, where motion and kinetic energy are treated differently in the interior and along the boundary.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11394v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jean-Baptiste Casteras (IECL, GFM), Leonard Monsaingeon (IECL, GFM), Luca Nenna (LMO, PARMA)</dc:creator>
    </item>
    <item>
      <title>Global Exponential Stabilization for a Simplified Fluid-Particle Interaction System</title>
      <link>https://arxiv.org/abs/2501.11446</link>
      <description>arXiv:2501.11446v1 Announce Type: cross 
Abstract: This work considers a system coupling a viscous Burgers equation (aimed to describe a simplified model of $1D$ fluid flow) with the ODE describing the motion of a point mass moving inside the fluid. The point mass is possibly under the action of a feedback control. Our main contributions are that we prove two global exponential stability results. More precisely, we first show that the velocity field corresponding to the free dynamics case is globally exponentially stable. We next show that, in the presence of the feedback control both the velocity field and the distance from the mass point to a prescribed target position decay exponentially. The proofs of these results heavily rely on the use of a special test function allowing both to prove that the mass point stays away from the boundary and to construct a perturbed Lyapunov function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11446v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marius Tucsnak, Zhuo Xu</dc:creator>
    </item>
    <item>
      <title>Riemannian Optimization for Holevo Capacity</title>
      <link>https://arxiv.org/abs/2501.11576</link>
      <description>arXiv:2501.11576v1 Announce Type: cross 
Abstract: Computing the classical capacity of a noisy quantum channel is crucial for understanding the limits of communication over quantum channels. However, its evaluation remains challenging due to the difficulty of computing the Holevo capacity and the even greater difficulty of regularization. In this work, we formulate the computation of the Holevo capacity as an optimization problem on a product manifold constructed from probability distributions and their corresponding pure input states for a quantum channel. A Riemannian gradient descent algorithm is proposed to solve the problem, providing lower bounds on the classical capacity of general quantum channels and outperforming existing methods in numerical experiments in both efficiency and scale.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11576v1</guid>
      <category>quant-ph</category>
      <category>math.OC</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chengkai Zhu, Renfeng Peng, Bin Gao, Xin Wang</dc:creator>
    </item>
    <item>
      <title>Randomized Kaczmarz Methods with Beyond-Krylov Convergence</title>
      <link>https://arxiv.org/abs/2501.11673</link>
      <description>arXiv:2501.11673v1 Announce Type: cross 
Abstract: Randomized Kaczmarz methods form a family of linear system solvers which converge by repeatedly projecting their iterates onto randomly sampled equations. While effective in some contexts, such as highly over-determined least squares, Kaczmarz methods are traditionally deemed secondary to Krylov subspace methods, since this latter family of solvers can exploit outliers in the input's singular value distribution to attain fast convergence on ill-conditioned systems.
  In this paper, we introduce Kaczmarz++, an accelerated randomized block Kaczmarz algorithm that exploits outlying singular values in the input to attain a fast Krylov-style convergence. Moreover, we show that Kaczmarz++ captures large outlying singular values provably faster than popular Krylov methods, for both over- and under-determined systems. We also develop an optimized variant for positive semidefinite systems, called CD++, demonstrating empirically that it is competitive in arithmetic operations with both CG and GMRES on a collection of benchmark problems. To attain these results, we introduce several novel algorithmic improvements to the Kaczmarz framework, including adaptive momentum acceleration, Tikhonov-regularized projections, and a memoization scheme for reusing information from previously sampled equation~blocks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11673v1</guid>
      <category>math.NA</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Micha{\l} Derezi\'nski, Deanna Needell, Elizaveta Rebrova, Jiaming Yang</dc:creator>
    </item>
    <item>
      <title>Simultaneously decoding the unknown stationary state and function parameters for mean field games</title>
      <link>https://arxiv.org/abs/2501.11955</link>
      <description>arXiv:2501.11955v1 Announce Type: cross 
Abstract: Mean field games (MFGs) offer a versatile framework for modeling large-scale interactive systems across multiple domains. This paper builds upon a previous work, by developing a state-of-the-art unified approach to decode or design the unknown stationary state of MFGs, in addition to the underlying parameter functions governing their behavior. This result is novel, even in the general realm of inverse problems for nonlinear PDEs. By enabling agents to distill crucial insights from observed data and unveil intricate hidden structures and unknown states within MFG systems, our approach surmounts a significant obstacle, enhancing the applicability of MFGs in real-world scenarios. This advancement not only enriches our understanding of MFG dynamics but also broadens the scope for their practical deployment in various contexts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11955v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongyu Liu, Catharine W. K. Lo</dc:creator>
    </item>
    <item>
      <title>Characterization of Invariance, Periodic Solutions and Optimization of Dynamic Financial Networks</title>
      <link>https://arxiv.org/abs/2501.12156</link>
      <description>arXiv:2501.12156v1 Announce Type: cross 
Abstract: Cascading failures, such as bankruptcies and defaults, pose a serious threat for the resilience of the global financial system. Indeed, because of the complex investment and cross-holding relations within the system, failures can occur as a result of the propagation of a financial collapse from one organization to another. While this problem has been studied in depth from a static angle, namely, when the system is at an equilibrium, we take a different perspective and study the corresponding dynamical system. The contribution of this paper is threefold. First, we carry out a systematic analysis of the regions of attraction and invariance of the system orthants, defined by the positive and negative values of the organizations' equity. Second, we investigate periodic solutions and show through a counterexample that there could exist periodic solutions of period greater than 2. Finally, we study the problem of finding the smallest cash injection that would bring the system to the maximal invariant region of the positive orthant.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12156v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Leonardo Stella, Dario Bauso, Franco Blanchini, Patrizio Colaneri</dc:creator>
    </item>
    <item>
      <title>FOCUS: First Order Concentrated Updating Scheme</title>
      <link>https://arxiv.org/abs/2501.12243</link>
      <description>arXiv:2501.12243v1 Announce Type: cross 
Abstract: Large language models (LLMs) demonstrate remarkable performance, and improving their pre-training process appears to be key to enhancing their capabilities further. Based on the documented success of Adam, learning rate decay, and weight decay, we hypothesize that the pre-training loss landscape features a narrowing valley structure. Through experiments with synthetic loss functions, we discover that when gradient query noise is high relative to the valley's sharpness, Adam's performance falls behind that of Signum because Adam reduces the effective step size too drastically. This observation led us to develop FOCUS, an optimizer that enhances Signum by incorporating attraction toward moving averaged parameters, allowing it to handle noise better while maintaining larger step sizes. In training GPT-2, FOCUS proves to be more stable than Signum and faster than Adam. These results suggest that gradient noise may be an underappreciated limiting factor in LLM training, and FOCUS offers promising solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12243v1</guid>
      <category>cs.LG</category>
      <category>cs.CL</category>
      <category>math.OC</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yizhou Liu, Ziming Liu, Jeff Gore</dc:creator>
    </item>
    <item>
      <title>Accelerated Gradient and Skew-Symmetric Splitting Methods for a Class of Monotone Operator Equations</title>
      <link>https://arxiv.org/abs/2303.09009</link>
      <description>arXiv:2303.09009v2 Announce Type: replace 
Abstract: A class of monotone operator equations, which can be decomposed into sum of the gradient of a strongly convex function and a linear and skew-symmetric operator, is considered in this work. Based on discretization of the generalized gradient flow, gradient and skew-symmetric splitting (GSS) methods are proposed and proved to converge in linear rates. To further accelerate the convergence, an accelerated gradient flow is proposed and accelerated gradient and skew-symmetric splitting (AGSS) methods are developed, which extends the acceleration among the existing works on the convex minimization to a more general class of monotone operator equations. In particular, when applied to smooth saddle point systems with bilinear coupling, a linear convergent method with optimal lower iteration complexity is proposed. The robustness and efficiency of GSS and AGSS methods are verified via extensive numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.09009v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Long Chen, Jingrong Wei</dc:creator>
    </item>
    <item>
      <title>Nonconvex Stochastic Bregman Proximal Gradient Method with Application to Deep Learning</title>
      <link>https://arxiv.org/abs/2306.14522</link>
      <description>arXiv:2306.14522v5 Announce Type: replace 
Abstract: Stochastic gradient methods for minimizing nonconvex composite objective functions typically rely on the Lipschitz smoothness of the differentiable part, but this assumption fails in many important problem classes like quadratic inverse problems and neural network training, leading to instability of the algorithms in both theory and practice. To address this, we propose a family of stochastic Bregman proximal gradient (SBPG) methods that only require smooth adaptivity. SBPG replaces the quadratic approximation in SGD with a Bregman proximity measure, offering a better approximation model that handles non-Lipschitz gradients in nonconvex objectives. We establish the convergence properties of vanilla SBPG and show it achieves optimal sample complexity in the nonconvex setting. Experimental results on quadratic inverse problems demonstrate SBPG's robustness in terms of stepsize selection and sensitivity to the initial point. Furthermore, we introduce a momentum-based variant, MSBPG, which enhances convergence by relaxing the mini-batch size requirement while preserving the optimal oracle complexity. We apply MSBPG to the training of deep neural networks, utilizing a polynomial kernel function to ensure smooth adaptivity of the loss function. Experimental results on benchmark datasets confirm the effectiveness and robustness of MSBPG in training neural networks. Given its negligible additional computational cost compared to SGD in large-scale optimization, MSBPG shows promise as a universal open-source optimizer for future applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.14522v5</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Kuangyu Ding, Jingyang Li, Kim-Chuan Toh</dc:creator>
    </item>
    <item>
      <title>Accelerated Affine-Invariant Convergence Rates of the Frank-Wolfe Algorithm with Open-Loop Step-Sizes</title>
      <link>https://arxiv.org/abs/2310.04096</link>
      <description>arXiv:2310.04096v3 Announce Type: replace 
Abstract: Recent papers have shown that the Frank-Wolfe algorithm (FW) with open-loop step-sizes exhibits rates of convergence faster than the iconic $\mathcal{O}(t^{-1})$ rate. In particular, when the minimizer of a strongly convex function over a polytope lies in the relative interior of a feasible region face, the FW with open-loop step-sizes $\eta_t = \frac{\ell}{t+\ell}$ for $\ell \in \mathbb{N}_{\geq 2}$ has accelerated convergence $\mathcal{O}(t^{-2})$ in contrast to the rate $\Omega(t^{-1-\epsilon})$ attainable with more complex line-search or short-step step-sizes. Given the relevance of this scenario in data science problems, research has grown to explore the settings enabling acceleration in open-loop FW. However, despite FW's well-known affine invariance, existing acceleration results for open-loop FW are affine-dependent. This paper remedies this gap in the literature by merging two recent research trajectories: affine invariance (Wirth et al., 2023b) and open-loop step-sizes (Pena, 2021). In particular, we extend all known non-affine-invariant convergence rates for FW with open-loop step-sizes to affine-invariant results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.04096v3</guid>
      <category>math.OC</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s10107-024-02180-2</arxiv:DOI>
      <dc:creator>Elias Wirth, Javier Pena, Sebastian Pokutta</dc:creator>
    </item>
    <item>
      <title>Time-inconsistent mean-field stopping problems: A regularized equilibrium approach</title>
      <link>https://arxiv.org/abs/2311.00381</link>
      <description>arXiv:2311.00381v3 Announce Type: replace 
Abstract: This paper studies the mean-field Markov decision process (MDP) with the centralized stopping under the non-exponential discount. The problem differs fundamentally from most existing studies on mean-field optimal control/stopping due to its time inconsistency by nature. We look for the subgame perfect relaxed equilibria, namely the randomized stopping policies that satisfy the time-consistent planning with future selves from the perspective of the social planner. On the other hand, unlike many previous studies on time-inconsistent stopping where the decreasing impatience plays a key role, we are interested in the general discount function without imposing any conditions. As a result, the study on the relaxed equilibrium becomes necessary as the pure-strategy equilibrium may not exist in general. We formulate relaxed equilibria as fixed points of a complicated operator, whose existence is challenging by a direct method. To overcome the obstacles, we first introduce the auxiliary problem under the entropy regularization on the randomized policy and the discount function, and establish the existence of the regularized equilibria as fixed points to an auxiliary operator via Schauder fixed point theorem. Next, we show that the regularized equilibrium converges as the regularization parameter $\lambda$ tends to $0$ and the limit corresponds to a fixed point to the original operator, and hence is a relaxed equilibrium. We also establish some connections between the mean-field MDP and the N-agent MDP when $N$ is sufficiently large in our time-inconsistent setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.00381v3</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiang Yu, Fengyi Yuan</dc:creator>
    </item>
    <item>
      <title>Top Feasible-Arm Subset Identification in Constrained Multi-Armed Bandit with Limited Budget</title>
      <link>https://arxiv.org/abs/2401.08845</link>
      <description>arXiv:2401.08845v2 Announce Type: replace 
Abstract: We present an algorithm, "constrained successive accept or reject (CSAR)," for the problem of identifying the subset of top feasible-arms from a given finite set of arms with the limited sampling-budget equal to a given time-horizon when the sequential dynamics of the arms follows the model of a constrained multi-armed bandit. We provide a finite-time upper bound on the probability of the incorrect identification by CSAR that converges to zero with an exponential rate in the sampling-budget.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.08845v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hyeong Soo Chang</dc:creator>
    </item>
    <item>
      <title>Constrained Hellinger-Kantorovich barycenters: least-cost soft and conic multi-marginal formulations</title>
      <link>https://arxiv.org/abs/2402.11268</link>
      <description>arXiv:2402.11268v2 Announce Type: replace 
Abstract: We show that the problem of finding the barycenter in the Hellinger-Kantorovich setting admits a least-cost soft multi-marginal formulation, provided that a one-sided hard marginal constraint is introduced. The constrained approach is then shown to admit a conic multi-marginal reformulation based on defining a single joint multi-marginal perspective cost function in the conic multi-marginal formulation, as opposed to separate two-marginal perspective cost functions for each two-marginal problem in the coupled-two-marginal formulation, as was studied previously in literature. We further establish that, as in the Wasserstein metric, the recently introduced framework of unbalanced multi-marginal optimal transport can be reformulated using the notion of the least cost. Subsequently, we discuss an example when input measures are Dirac masses and numerically solve an example for Gaussian measures. Finally, we also explore why the constrained approach can be seen as a natural extension of a Wasserstein space barycenter to the unbalanced setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.11268v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1137/24M1639804</arxiv:DOI>
      <dc:creator>Maciej Buze</dc:creator>
    </item>
    <item>
      <title>Useful Compact Representations for Data-Fitting</title>
      <link>https://arxiv.org/abs/2403.12206</link>
      <description>arXiv:2403.12206v2 Announce Type: replace 
Abstract: For minimization problems without 2nd derivative information, methods that estimate Hessian matrices can be very effective. However, conventional techniques generate dense matrices that are prohibitive for large problems. Limited-memory compact representations express the dense arrays in terms of a low rank representation and have become the state-of-the-art for software implementations on large deterministic problems. We develop new compact representations that are parameterized by a choice of vectors and that reduce to existing well known formulas for special choices. We demonstrate effectiveness of the compact representations for large eigenvalue computations, tensor factorizations and nonlinear regressions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12206v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.CO</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Johannes J. Brust</dc:creator>
    </item>
    <item>
      <title>Projection-free computation of robust controllable sets with constrained zonotopes</title>
      <link>https://arxiv.org/abs/2403.13730</link>
      <description>arXiv:2403.13730v2 Announce Type: replace 
Abstract: We study the problem of computing robust controllable sets for discrete-time linear systems with additive uncertainty. We propose a tractable and scalable approach to inner- and outer-approximate robust controllable sets using constrained zonotopes, when the additive uncertainty set is a symmetric, convex, and compact set. Our least-squares-based approach uses novel closed-form approximations of the Pontryagin difference between a constrained zonotopic minuend and a symmetric, convex, and compact subtrahend. Unlike existing approaches, our approach does not rely on convex optimization solvers, and is projection-free for ellipsoidal and zonotopic uncertainty sets. We also propose a least-squares-based approach to compute a convex, polyhedral outer-approximation to constrained zonotopes, and characterize sufficient conditions under which all these approximations are exact. We demonstrate the computational efficiency and scalability of our approach in several case studies, including the design of abort-safe rendezvous trajectories for a spacecraft in near-rectilinear halo orbit under uncertainty. Our approach can inner-approximate a 20-step robust controllable set for a 100-dimensional linear system in under 15 seconds on a standard computer.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.13730v2</guid>
      <category>math.OC</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Abraham P. Vinod, Avishai Weiss, Stefano Di Cairano</dc:creator>
    </item>
    <item>
      <title>Finite convergence of the Moment-SOS hierarchy for polynomial matrix optimization</title>
      <link>https://arxiv.org/abs/2403.17241</link>
      <description>arXiv:2403.17241v2 Announce Type: replace 
Abstract: This paper studies the matrix Moment-SOS hierarchy for solving polynomial matrix optimization. Our first result is to show the finite convergence of this hierarchy, if the nondegeneracy condition, strict complementarity condition and second order sufficient condition hold at every minimizer, under the Archimedean property. A useful criterion for detecting the finite convergence is the flat truncation. Our second result is to show that every minimizer of the moment relaxation must have a flat truncation when the relaxation order is big enough, under the above mentioned optimality conditions. These results give connections between nonlinear semidefinite optimization theory and Moment-SOS methods for solving polynomial matrix optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.17241v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lei Huang, Jiawang Nie</dc:creator>
    </item>
    <item>
      <title>Patient Transport in Hospitals: A Literature Review of Operations Research and Management Science Methods</title>
      <link>https://arxiv.org/abs/2404.03282</link>
      <description>arXiv:2404.03282v2 Announce Type: replace 
Abstract: Most activities in hospitals require the presence of the patient. Delays in patient transport can disrupt operations, potentially resulting in idle staff, underutilized equipment, and postponed procedures, which in turn lead to lost revenue, unnecessary costs across many different areas and departments, and lower patient satisfaction. Consequently, patient transport planning is a central operational task in hospitals. This paper provides the first literature review of Operations Research and Management Science approaches for non-emergency, intra-hospital patient transport. We structure the different patient transport problems considered in the literature according to several main characteristics and introduce a five-field notation that allows for a concise representation of different problem variants. We then analyze the relevant literature with respect to different aspects related to the considered problem variant, the employed modeling and solution techniques, as well as the data used and the level of practical implementation achieved. Based on our literature analysis and semi-structured interviews with hospital practitioners, we compare current hospital practices and the existing literature, identify research gaps, and formulate an agenda for relevant future research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03282v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tom Lorenz Klein, Clemens Thielen</dc:creator>
    </item>
    <item>
      <title>Robotic Sorting Systems: Robot Management and Layout Design Optimization</title>
      <link>https://arxiv.org/abs/2404.04832</link>
      <description>arXiv:2404.04832v3 Announce Type: replace 
Abstract: In the contemporary logistics industry, automation plays a pivotal role in enhancing production efficiency and expanding industrial scale. Autonomous mobile robots, in particular, have become integral to the modernization efforts in warehouses. One noteworthy application in robotic warehousing is the robotic sorting system (RSS), distinguished by its characteristics such as cost-effectiveness, simplicity, scalability, and adaptable throughput control. While previous research has focused on analyzing the efficiency of RSS, it often assumed an ideal robot management system ignoring potential queuing delays by assuming constant travel times. This study relaxes this assumption and explores the quantitative relationship between RSS configuration parameters and system throughput. We introduce a novel robot traffic management method, named the rhythmic control for sorting scenario (RC-S), for RSS operations, equipped with an estimation formula establishing the relationship between system performance and configurations. Simulations validate that RC-S reduces average service time by 10.3\% compared to the classical cooperative A* algorithm, while also improving throughput and runtime. Based on the performance analysis of RC-S, we further develop a layout optimization model for RSS, considering RSS configuration, desired throughput, and costs, to minimize expenses and determine the best layout. Numerical studies show that at lower throughput levels, facility costs dominate, while at higher throughput levels, labor costs prevail. Additionally, due to traffic efficiency limitations, RSS is well-suited for small-scale operations like end-of-supply-chain distribution centers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.04832v3</guid>
      <category>math.OC</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Tong Zhao, Xi Lin, Fang He, Hanwen Dai</dc:creator>
    </item>
    <item>
      <title>Generalized Bayesian Nash Equilibrium with Continuous Type and Action Spaces</title>
      <link>https://arxiv.org/abs/2405.19721</link>
      <description>arXiv:2405.19721v2 Announce Type: replace 
Abstract: Bayesian game is a strategic decision-making model where each player's type parameter characterizing its own objective is private information: each player knows its own type but not its rivals' types, and Bayesian Nash equilibrium (BNE) is an outcome of this game where each player makes a strategic optimal decision according to its own type under the Nash conjecture. In this paper, we advance the literature by considering a generalized Bayesian game where each player's action space depends on its own type parameter and the rivals' actions. This reflects the fact that in practical applications, a firm's feasible action is often related to its own type (e.g. marginal cost) and the rivals' actions (e.g. common resource constraints in a competitive market). Under some moderate conditions, we demonstrate existence of continuous generalized Bayesian Nash equilibria (GBNE) and uniqueness of such an equilibrium when each player's action space is only dependent on its type. In the case that each player's action space is also dependent on rivals' actions, we give a simple example to show that uniqueness of GBNE is not guaranteed under standard monotone conditions. To compute an approximate GBNE, we restrict each player's response function to the space of polynomial functions of its type parameter and consequently convert the GBNE problem to a stochastic generalized Nash equilibrium problem (SGNE). To justify the approximation, we discuss convergence of the approximation scheme. Some preliminary numerical test results show that the approximation scheme works well.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.19721v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuan Tao, Huifu Xu</dc:creator>
    </item>
    <item>
      <title>Inverting Laguerre tessellations: Recovering tessellations from the volumes and centroids of their cells using optimal transport</title>
      <link>https://arxiv.org/abs/2406.00871</link>
      <description>arXiv:2406.00871v2 Announce Type: replace 
Abstract: In this paper we study an inverse problem in convex geometry, inspired by a problem in materials science. Firstly, we consider the question of whether a Laguerre tessellation (a partition by convex polytopes) can be recovered from only the volumes and centroids of its cells. We show that this problem has a unique solution and give a constructive way of computing it using optimal transport theory and convex optimisation. Secondly, we consider the problem of fitting a Laguerre tessellation to synthetic volume and centroid data. Given some target volumes and centroids, we seek a Laguerre tessellation such that the difference between the volumes and centroids of its cells and the target volumes and centroids is minimised. For an appropriate objective function and suitable data, we prove that local minimisers of this problem can be constructed using convex optimisation. We also illustrate our results numerically. There is great interest in the computational materials science community in fitting Laguerre tessellations to electron backscatter diffraction (EBSD) and x-ray diffraction images of polycrystalline materials. As an application of our results we fit a 2D Laguerre tessellation to an EBSD image of steel.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00871v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David P. Bourne, Mason Pearce, Steven M. Roper</dc:creator>
    </item>
    <item>
      <title>A Stochastic Objective-Function-Free Adaptive Regularization Method with Optimal Complexity</title>
      <link>https://arxiv.org/abs/2407.08018</link>
      <description>arXiv:2407.08018v4 Announce Type: replace 
Abstract: A fully stochastic second-order adaptive-regularization method for unconstrained nonconvex optimization is presented which never computes the objective-function value, but yet achieves the optimal $\mathcal{O}(\epsilon^{-3/2})$ complexity bound for finding first-order critical points. The method is noise-tolerant and the inexactness conditions required for convergence depend on the history of past steps. Applications to cases where derivative evaluation is inexact and to minimization of finite sums by sampling are discussed. Numerical experiments on large binary classification problems illustrate the potential of the new method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.08018v4</guid>
      <category>math.OC</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Serge Gratton, Sadok Jerad, Philippe L. Toint</dc:creator>
    </item>
    <item>
      <title>Solvability and Optimal Controls of Impulsive Stochastic Evolution Equations in Hilbert Spaces</title>
      <link>https://arxiv.org/abs/2407.13496</link>
      <description>arXiv:2407.13496v3 Announce Type: replace 
Abstract: This paper investigates the solvability and optimal control of a class of impulsive stochastic differential equations (SDEs) within a Hilbert space setting. First, we establish the existence and uniqueness of mild solutions for the proposed impulsive stochastic system, leveraging fixed-point theorems and appropriate analytical techniques. Next, we identify and derive the necessary conditions for the existence of optimal control pairs, ensuring the feasibility and effectiveness of the control solutions. Finally, to validate and demonstrate the practical applicability of our theoretical findings, we provide a detailed example showcasing the utility of the results in real-world scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13496v3</guid>
      <category>math.OC</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Javad A. Asadzade, Nazim I. Mahmudov</dc:creator>
    </item>
    <item>
      <title>Quantitative convergence for mean field control with common noise and degenerate idiosyncratic noise</title>
      <link>https://arxiv.org/abs/2409.14053</link>
      <description>arXiv:2409.14053v2 Announce Type: replace 
Abstract: We consider the convergence problem in the setting of mean field control with common noise and degenerate idiosyncratic noise. Our main results establish a rate of convergence of the finite-dimensional value functions $V^N$ towards the mean field value function $U$. In the case that the idiosyncratic noise is constant (but possibly degenerate), we obtain the rate $N^{-1/(d+7)}$, which is close to the conjectured optimal rate $N^{-1/d}$, and improves on the existing literature even in the non-degenerate setting. In the case that the idiosyncratic noise can be both non-constant and degenerate, the argument is more complicated, and we instead find the rate $N^{-1/(3d + 19)}$. Our proof strategy builds on the one initiated in [Daudin, Delarue, Jackson - JFA, 2024] in the case of non-degenerate idiosyncratic noise and zero common noise, which consists of approximating $U$ by more regular functions which are almost subsolutions of the infinite-dimensional Hamilton-Jacobi equation solved by $U$. Because of the different noise structure, several new steps are necessary in order to produce an appropriate mollification scheme. In addition to our main convergence results, we investigate the case of zero idiosyncratic noise, and show that sharper results can be obtained there by purely control-theoretic arguments. We also provide examples to demonstrate that the value function is sensitive to the choice of admissible controls in the zero noise setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.14053v2</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <category>math.PR</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alekos Cecchin, Samuel Daudin, Joe Jackson, Mattia Martini</dc:creator>
    </item>
    <item>
      <title>Barrier Function for Bilevel Optimization with Coupled Lower-Level Constraints: Formulation, Approximation and Algorithms</title>
      <link>https://arxiv.org/abs/2410.10670</link>
      <description>arXiv:2410.10670v4 Announce Type: replace 
Abstract: In this paper, we consider bilevel optimization problem where the lower-level has coupled constraints, i.e. the constraints depend both on the upper- and lower-level variables. In particular, we consider two settings for the lower-level problem. The first is when the objective is strongly convex and the constraints are convex with respect to the lower-level variable; The second is when the lower-level is a linear program. We propose to utilize a barrier function reformulation to translate the problem into an unconstrained problem. By developing a series of new techniques, we proved that both the hyperfunction value and hypergradient of the barrier reformulated problem (uniformly) converge to those of the original problem under minimal assumptions. Further, to overcome the non-Lipschitz smoothness of hyperfunction and lower-level problem for barrier reformulated problems, we design an adaptive algorithm that ensures a non-asymptotic convergence guarantee. We also design an algorithm that converges to the stationary point of the original problem asymptotically under certain assumptions. The proposed algorithms require minimal assumptions, and to our knowledge, they are the first with convergence guarantees when the lower-level problem is a linear program. Numerical experiments are conducted to show the effectiveness of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10670v4</guid>
      <category>math.OC</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaotian Jiang, Jiaxiang Li, Mingyi Hong, Shuzhong Zhang</dc:creator>
    </item>
    <item>
      <title>Optimization Algorithm Design via Electric Circuits</title>
      <link>https://arxiv.org/abs/2411.02573</link>
      <description>arXiv:2411.02573v2 Announce Type: replace 
Abstract: We present a novel methodology for convex optimization algorithm design using ideas from electric RLC circuits. Given an optimization problem, the first stage of the methodology is to design an appropriate electric circuit whose continuous-time dynamics converge to the solution of the optimization problem at hand. Then, the second stage is an automated, computer-assisted discretization of the continuous-time dynamics, yielding a provably convergent discrete-time algorithm. Our methodology recovers many classical (distributed) optimization algorithms and enables users to quickly design and explore a wide range of new algorithms with convergence guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.02573v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stephen P. Boyd, Tetiana Parshakova, Ernest K. Ryu, Jaewook J. Suh</dc:creator>
    </item>
    <item>
      <title>Dynamic Programming: From Local Optimality to Global Optimality</title>
      <link>https://arxiv.org/abs/2411.11062</link>
      <description>arXiv:2411.11062v2 Announce Type: replace 
Abstract: In the theory of dynamic programming, an optimal policy is a policy whose lifetime value dominates that of all other policies from every possible initial condition in the state space. This raises a natural question: when does optimality from a single state imply optimality from every state? We show that, in a general setting, irreducibility of the transition kernel is sufficient for this property. Our results have important implications for modern policy-based algorithms used to solve large-scale dynamic programs in reinforcement learning and other fields.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11062v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>John Stachurski, Jingni Yang, Ziyue Yang</dc:creator>
    </item>
    <item>
      <title>A Simplification Method for Inequality Constraints in Integer Binary Encoding HOBO Formulations</title>
      <link>https://arxiv.org/abs/2501.09670</link>
      <description>arXiv:2501.09670v3 Announce Type: replace 
Abstract: This study proposes a novel method for simplifying inequality constraints in Higher-Order Binary Optimization (HOBO) formulations. The proposed method addresses challenges associated with Quadratic Unconstrained Binary Optimization (QUBO) formulations, specifically the increased computational complexity and reduced solution accuracy caused by the introduction of slack variables and the resulting growth in auxiliary qubits. By efficiently integrating constraints, the method enhances the computational efficiency and accuracy of both quantum and classical solvers. The effectiveness of the proposed approach is demonstrated through numerical experiments applied to combinatorial optimization problems. The results indicate that this method expands the applicability of quantum algorithms to high-dimensional problems and improves the practicality of classical optimization solvers for optimization problems involving inequality constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.09670v3</guid>
      <category>math.OC</category>
      <category>quant-ph</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuichiro Minato</dc:creator>
    </item>
    <item>
      <title>Dual Cheeger Constants, Signless 1-Laplacians and Maxcut</title>
      <link>https://arxiv.org/abs/1607.00489</link>
      <description>arXiv:1607.00489v2 Announce Type: replace-cross 
Abstract: The first nontrivial lower bound of the worst-case approximation ratio for the maxcut problem was achieved via the dual Cheeger problem, whose optimal value is referred to the dual Cheeger constant $h^+$, and later improved through its modification $\widehat{h}^+$. However, the dual Cheeger problem and its modification themselves are relatively unexplored, especially lack of effective approximate algorithms. To this end, we first derive equivalent spectral formulations of $h^+$ and $\widehat{h}^+$ within the framework of the nonlinear spectral theory of signless 1-Laplacian, present their interactions with the Laplacian matrix and 1-Laplacian, and then use them to develop an inverse power algorithm that leverages the local linearity of the objective functions involved. We prove that the inverse power algorithm monotonically converges to a ternary-valued eigenvector, and provide the approximate values of $h^+$ and $\widehat{h}^+$ on G-set for the first time. The recursive spectral cut algorithm for the maxcut problem can be enhanced by integrating into the inverse power algorithms, leading to significantly improved approximate values on G-set. Finally, we show that the lower bound of the worst-case approximation ratio for the maxcut problem within the recursive spectral cut framework can not be improved beyond $0.769$.</description>
      <guid isPermaLink="false">oai:arXiv.org:1607.00489v2</guid>
      <category>math.SP</category>
      <category>math.CO</category>
      <category>math.OC</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sihong Shao, Chuan Yang, Dong Zhang</dc:creator>
    </item>
    <item>
      <title>Infinite-dimensional port-Hamiltonian systems with a stationary interface</title>
      <link>https://arxiv.org/abs/2301.08967</link>
      <description>arXiv:2301.08967v3 Announce Type: replace-cross 
Abstract: We consider two systems of two conservation laws that are defined on complementary, one-dimensional spatial intervals and coupled by an interface as a single port-Hamiltonian system. In case of a fixed interface position, we characterize the boundary and interface conditions for which the associated port-Hamiltonian operator generates a contraction semigroup. Furthermore, we present sufficient conditions for the exponential stability of the generated $C_0$-semigroup. The results are illustrated by the example of two acoustic waveguides coupled by a membrane interface.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.08967v3</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexander Kilian, Bernhard Maschke, Andrii Mironchenko, Fabian Wirth</dc:creator>
    </item>
    <item>
      <title>On the Convergence of the Gradient Descent Method with Stochastic Fixed-point Rounding Errors under the Polyak-Lojasiewicz Inequality</title>
      <link>https://arxiv.org/abs/2301.09511</link>
      <description>arXiv:2301.09511v2 Announce Type: replace-cross 
Abstract: When training neural networks with low-precision computation, rounding errors often cause stagnation or are detrimental to the convergence of the optimizers; in this paper we study the influence of rounding errors on the convergence of the gradient descent method for problems satisfying the Polyak-\Lojasiewicz inequality. Within this context, we show that, in contrast, biased stochastic rounding errors may be beneficial since choosing a proper rounding strategy eliminates the vanishing gradient problem and forces the rounding bias in a descent direction. Furthermore, we obtain a bound on the convergence rate that is stricter than the one achieved by unbiased stochastic rounding. The theoretical analysis is validated by comparing the performances of various rounding strategies when optimizing several examples using low-precision fixed-point number formats.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.09511v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lu Xia, Michiel E. Hochstenbach, Stefano Massei</dc:creator>
    </item>
    <item>
      <title>When does subtracting a rank-one approximation decrease tensor rank?</title>
      <link>https://arxiv.org/abs/2303.14985</link>
      <description>arXiv:2303.14985v4 Announce Type: replace-cross 
Abstract: Subtracting a critical rank-one approximation from a matrix always results in a matrix with a lower rank. This is not true for tensors in general. Motivated by this, we ask the question: what is the closure of the set of those tensors for which subtracting some of its critical rank-one approximation from it and repeating the process we will eventually get to zero? In this article, we show how to construct this variety of tensors and we show how this is connected to the bottleneck points of the variety of rank-one tensors (and in general to the singular locus of the hyperdeterminant), and how this variety can be equal to and in some cases be more than (weakly) orthogonally decomposable tensors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.14985v4</guid>
      <category>math.AG</category>
      <category>math.MG</category>
      <category>math.OC</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Emil Horobet, Ettore Teixeira Turatti</dc:creator>
    </item>
    <item>
      <title>SLowcal-SGD: Slow Query Points Improve Local-SGD for Stochastic Convex Optimization</title>
      <link>https://arxiv.org/abs/2304.04169</link>
      <description>arXiv:2304.04169v2 Announce Type: replace-cross 
Abstract: We consider distributed learning scenarios where M machines interact with a parameter server along several communication rounds in order to minimize a joint objective function. Focusing on the heterogeneous case, where different machines may draw samples from different data-distributions, we design the first local update method that provably benefits over the two most prominent distributed baselines: namely Minibatch-SGD and Local-SGD. Key to our approach is a slow querying technique that we customize to the distributed setting, which in turn enables a better mitigation of the bias caused by local updates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.04169v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tehila Dahan, Kfir Y. Levy</dc:creator>
    </item>
    <item>
      <title>On Semidefinite Relaxations for Matrix-Weighted State-Estimation Problems in Robotics</title>
      <link>https://arxiv.org/abs/2308.07275</link>
      <description>arXiv:2308.07275v4 Announce Type: replace-cross 
Abstract: In recent years, there has been remarkable progress in the development of so-called certifiable perception methods, which leverage semidefinite, convex relaxations to find global optima of perception problems in robotics. However, many of these relaxations rely on simplifying assumptions that facilitate the problem formulation, such as an isotropic measurement noise distribution. In this paper, we explore the tightness of the semidefinite relaxations of matrix-weighted (anisotropic) state-estimation problems and reveal the limitations lurking therein: matrix-weighted factors can cause convex relaxations to lose tightness. In particular, we show that the semidefinite relaxations of localization problems with matrix weights may be tight only for low noise levels. To better understand this issue, we introduce a theoretical connection between the posterior uncertainty of the state estimate and the certificate matrix obtained via convex relaxation. With this connection in mind, we empirically explore the factors that contribute to this loss of tightness and demonstrate that redundant constraints can be used to regain it. As a second technical contribution of this paper, we show that the state-of-the-art relaxation of scalar-weighted SLAM cannot be used when matrix weights are considered. We provide an alternate formulation and show that its SDP relaxation is not tight (even for very low noise levels) unless specific redundant constraints are used. We demonstrate the tightness of our formulations on both simulated and real-world data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.07275v4</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TRO.2024.3475220</arxiv:DOI>
      <arxiv:journal_reference>IEEE Transactions on Robotics, vol. 40, pp. 4805-4824, 2024</arxiv:journal_reference>
      <dc:creator>Connor Holmes, Frederike D\"umbgen, Timothy D Barfoot</dc:creator>
    </item>
    <item>
      <title>When Location Shapes Choice: Placement Optimization of Substitutable Products</title>
      <link>https://arxiv.org/abs/2310.08568</link>
      <description>arXiv:2310.08568v3 Announce Type: replace-cross 
Abstract: Strategic product placement can have a strong influence on customer purchase behavior in physical stores as well as online platforms. Motivated by this, we consider the problem of optimizing the placement of substitutable products in designated display locations to maximize the expected revenue of the seller. We model the customer behavior as a two-stage process: first, the customer visits a subset of display locations according to a browsing distribution; second, the customer chooses at most one product from the displayed products at those locations according to a choice model. Our goal is to design a general algorithm that can select and place the products optimally for any browsing distribution and choice model, and we call this the Placement problem. We give a randomized algorithm that utilizes an $\alpha$-approximate algorithm for cardinality constrained assortment optimization and outputs a $\frac{\Theta(\alpha)}{\log m}$-approximate solution (in expectation) for Placement with $m$ display locations, i.e., our algorithm outputs a solution with value at least $\frac{\Omega(\alpha)}{\log m}$ factor of the optimal and this is tight in the worst case. We also give algorithms with stronger guarantees in some special cases. In particular, we give a deterministic $\frac{\Omega(1)}{\log m}$-approximation algorithm for the Markov choice model, and a tight $(1-1/e)$-approximation algorithm for the problem when products have identical prices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.08568v3</guid>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Omar El Housni, Rajan Udwani</dc:creator>
    </item>
    <item>
      <title>On non-approximability of zero loss global ${\mathcal L}^2$ minimizers by gradient descent in Deep Learning</title>
      <link>https://arxiv.org/abs/2311.07065</link>
      <description>arXiv:2311.07065v2 Announce Type: replace-cross 
Abstract: We analyze geometric aspects of the gradient descent algorithm in Deep Learning (DL), and give a detailed discussion of the circumstance that in underparametrized DL networks, zero loss minimization can generically not be attained. As a consequence, we conclude that the distribution of training inputs must necessarily be non-generic in order to produce zero loss minimizers, both for the method constructed in [Chen-Munoz Ewald 2023, 2024], or for gradient descent [Chen 2025] (which assume clustering of training data).</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.07065v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas Chen, Patricia Mu\~noz Ewald</dc:creator>
    </item>
    <item>
      <title>Generalized convergence of the deep BSDE method: a step towards fully-coupled FBSDEs and applications in stochastic control</title>
      <link>https://arxiv.org/abs/2403.18552</link>
      <description>arXiv:2403.18552v2 Announce Type: replace-cross 
Abstract: We are concerned with high-dimensional coupled FBSDE systems approximated by the deep BSDE method of Han et al. (2018). It was shown by Han and Long (2020) that the errors induced by the deep BSDE method admit a posteriori estimate depending on the loss function, whenever the backward equation only couples into the forward diffusion through the Y process. We generalize this result to drift coefficients that may also depend on Z, and give sufficient conditions for convergence under standard assumptions. The resulting conditions are directly verifiable for any equation. Consequently, unlike in earlier theory, our convergence analysis enables the treatment of FBSDEs stemming from stochastic optimal control problems. In particular, we provide a theoretical justification for the non-convergence of the deep BSDE method observed in recent literature, and present direct guidelines for when convergence can be guaranteed in practice. Our theoretical findings are supported by several numerical experiments in high-dimensional settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.18552v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Balint Negyesi, Zhipeng Huang, Cornelis W. Oosterlee</dc:creator>
    </item>
    <item>
      <title>Fast Last-Iterate Convergence of Learning in Games Requires Forgetful Algorithms</title>
      <link>https://arxiv.org/abs/2406.10631</link>
      <description>arXiv:2406.10631v2 Announce Type: replace-cross 
Abstract: Self-play via online learning is one of the premier ways to solve large-scale two-player zero-sum games, both in theory and practice. Particularly popular algorithms include optimistic multiplicative weights update (OMWU) and optimistic gradient-descent-ascent (OGDA). While both algorithms enjoy $O(1/T)$ ergodic convergence to Nash equilibrium in two-player zero-sum games, OMWU offers several advantages including logarithmic dependence on the size of the payoff matrix and $\widetilde{O}(1/T)$ convergence to coarse correlated equilibria even in general-sum games. However, in terms of last-iterate convergence in two-player zero-sum games, an increasingly popular topic in this area, OGDA guarantees that the duality gap shrinks at a rate of $O(1/\sqrt{T})$, while the best existing last-iterate convergence for OMWU depends on some game-dependent constant that could be arbitrarily large. This begs the question: is this potentially slow last-iterate convergence an inherent disadvantage of OMWU, or is the current analysis too loose? Somewhat surprisingly, we show that the former is true. More generally, we prove that a broad class of algorithms that do not forget the past quickly all suffer the same issue: for any arbitrarily small $\delta&gt;0$, there exists a $2\times 2$ matrix game such that the algorithm admits a constant duality gap even after $1/\delta$ rounds. This class of algorithms includes OMWU and other standard optimistic follow-the-regularized-leader algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.10631v2</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yang Cai, Gabriele Farina, Julien Grand-Cl\'ement, Christian Kroer, Chung-Wei Lee, Haipeng Luo, Weiqiang Zheng</dc:creator>
    </item>
    <item>
      <title>Wasserstein Distributionally Robust Shallow Convex Neural Networks</title>
      <link>https://arxiv.org/abs/2407.16800</link>
      <description>arXiv:2407.16800v2 Announce Type: replace-cross 
Abstract: In this work, we propose Wasserstein distributionally robust shallow convex neural networks (WaDiRo-SCNNs) to provide reliable nonlinear predictions when subject to adverse and corrupted datasets. Our approach is based on a new convex training program for $\ReLU$-based shallow neural networks which allows us to cast the problem as an exact, tractable reformulation of its order-1 Wasserstein distributionally robust counterpart. Our training procedure is conservative, has low stochasticity, is solvable with open-source solvers, and is scalable to large industrial deployments. We provide out-of-sample performance guarantees, show that hard convex physical constraints can be enforced in the training program, and propose a mixed-integer convex post-training verification program to evaluate model stability. WaDiRo-SCNN aims to make neural networks safer for critical applications, such as in the energy sector. Finally, we numerically demonstrate the performance of our model on a synthetic experiment, a real-world power system application, i.e., the prediction of non-residential buildings' hourly energy consumption in the context of virtual power plants, and on benchmark datasets. The experimental results are convincing and showcase the strengths of the proposed model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.16800v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Julien Pallage, Antoine Lesage-Landry</dc:creator>
    </item>
    <item>
      <title>Numerical Analysis for a Hyperbolic PDE-Constrained Optimization Problem in Acoustic Full Waveform Inversion</title>
      <link>https://arxiv.org/abs/2407.19273</link>
      <description>arXiv:2407.19273v2 Announce Type: replace-cross 
Abstract: This paper explores a fully discrete approximation for a nonlinear hyperbolic PDE-constrained optimization problem (P) with applications in acoustic full waveform inversion. The optimization problem is primarily complicated by the hyperbolic character and the second-order bilinear structure in the governing wave equation. While the control parameter is discretized using the piecewise constant elements, the state discretization is realized through an auxiliary first-order system along with the leapfrog time-stepping method and continuous piecewise linear elements. The resulting fully discrete minimization problem ($\text{P}_h$) is shown to be well-defined. Furthermore, building upon a suitable CFL-condition, we prove stability and uniform convergence of the state discretization. Our final result is the strong convergence result for ($\text{P}_h$) in the following sense: Given a local minimizer $\overline \nu$ of (P) satisfying a reasonable growth condition, there exists a sequence of local minimizers of ($\text{P}_h$) converging strongly towards $\overline \nu$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.19273v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luis Ammann, Irwin Yousept</dc:creator>
    </item>
    <item>
      <title>Learning rheological parameters of non-Newtonian fluids from velocimetry data</title>
      <link>https://arxiv.org/abs/2408.02604</link>
      <description>arXiv:2408.02604v3 Announce Type: replace-cross 
Abstract: We solve a Bayesian inverse Navier-Stokes (N-S) problem that assimilates velocimetry data in order to jointly reconstruct the flow field and learn the unknown N-S parameters. By incorporating a Carreau shear-thinning viscosity model into the N-S problem, we devise an algorithm that learns the most likely Carreau parameters of a shear-thinning fluid, and estimates their uncertainties, from velocimetry data alone. We then conduct a flow-MRI experiment to obtain velocimetry data of an axisymmetric laminar jet through an idealised medical device (FDA nozzle) for a blood analogue fluid. We show that the algorithm can successfully reconstruct the flow field by learning the most likely Carreau parameters, and that the learned parameters are in very good agreement with rheometry measurements. The algorithm accepts any algebraic effective viscosity model, as long as the model is differentiable, and it can be extended to more complicated non-Newtonian fluids (e.g. Oldroyd-B fluid) if a viscoelastic model is incorporated into the N-S problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02604v3</guid>
      <category>physics.flu-dyn</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexandros Kontogiannis, Richard Hodgkinson, Emily L. Manchester</dc:creator>
    </item>
    <item>
      <title>Free Lunch in the Forest: Functionally-Identical Pruning of Boosted Tree Ensembles</title>
      <link>https://arxiv.org/abs/2408.16167</link>
      <description>arXiv:2408.16167v2 Announce Type: replace-cross 
Abstract: Tree ensembles, including boosting methods, are highly effective and widely used for tabular data. However, large ensembles lack interpretability and require longer inference times. We introduce a method to prune a tree ensemble into a reduced version that is "functionally identical" to the original model. In other words, our method guarantees that the prediction function stays unchanged for any possible input. As a consequence, this pruning algorithm is lossless for any aggregated metric. We formalize the problem of functionally identical pruning on ensembles, introduce an exact optimization model, and provide a fast yet highly effective method to prune large ensembles. Our algorithm iteratively prunes considering a finite set of points, which is incrementally augmented using an adversarial model. In multiple computational experiments, we show that our approach is a "free lunch", significantly reducing the ensemble size without altering the model's behavior. Thus, we can preserve state-of-the-art performance at a fraction of the original model's size.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.16167v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Youssouf Emine, Alexandre Forel, Idriss Malek, Thibaut Vidal</dc:creator>
    </item>
    <item>
      <title>Optimization Hyper-parameter Laws for Large Language Models</title>
      <link>https://arxiv.org/abs/2409.04777</link>
      <description>arXiv:2409.04777v3 Announce Type: replace-cross 
Abstract: Large Language Models have driven significant AI advancements, yet their training is resource-intensive and highly sensitive to hyper-parameter selection. While scaling laws provide valuable guidance on model size and data requirements, they fall short in choosing dynamic hyper-parameters, such as learning-rate (LR) schedules, that evolve during training. To bridge this gap, we present Optimization Hyper-parameter Laws (Opt-Laws), a framework that effectively captures the relationship between hyper-parameters and training outcomes, enabling the pre-selection of potential optimal schedules. Grounded in stochastic differential equations, Opt-Laws introduce novel mathematical interpretability and offer a robust theoretical foundation for some popular LR schedules. Our extensive validation across diverse model sizes and data scales demonstrates Opt-Laws' ability to accurately predict training loss and identify optimal LR schedule candidates in pre-training, continual training, and fine-tuning scenarios. This approach significantly reduces computational costs while enhancing overall model performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.04777v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xingyu Xie, Kuangyu Ding, Shuicheng Yan, Kim-Chuan Toh, Tianwen Wei</dc:creator>
    </item>
    <item>
      <title>Optimization and Generalization Guarantees for Weight Normalization</title>
      <link>https://arxiv.org/abs/2409.08935</link>
      <description>arXiv:2409.08935v2 Announce Type: replace-cross 
Abstract: Weight normalization (WeightNorm) is widely used in practice for the training of deep neural networks and modern deep learning libraries have built-in implementations of it. In this paper, we provide the first theoretical characterizations of both optimization and generalization of deep WeightNorm models with smooth activation functions. For optimization, from the form of the Hessian of the loss, we note that a small Hessian of the predictor leads to a tractable analysis. Thus, we bound the spectral norm of the Hessian of WeightNorm networks and show its dependence on the network width and weight normalization terms--the latter being unique to networks without WeightNorm. Then, we use this bound to establish training convergence guarantees under suitable assumptions for gradient decent. For generalization, we use WeightNorm to get a uniform convergence based generalization bound, which is independent from the width and depends sublinearly on the depth. Finally, we present experimental results which illustrate how the normalization terms and other quantities of theoretical interest relate to the training of WeightNorm networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08935v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pedro Cisneros-Velarde, Zhijie Chen, Sanmi Koyejo, Arindam Banerjee</dc:creator>
    </item>
    <item>
      <title>A geodesic convexity-like structure for the polar decomposition of a square matrix</title>
      <link>https://arxiv.org/abs/2412.13990</link>
      <description>arXiv:2412.13990v2 Announce Type: replace-cross 
Abstract: We make a full landscape analysis of the (generally non-convex) orthogonal Procrustes problem. This problem is equivalent to computing the polar factor of a square matrix. We reveal a convexity-like structure, which explains the already established tractability of the problem and show that gradient descent in the orthogonal group computes the polar factor of a square matrix with linear convergence rate if the matrix is invertible and with an algebraic one if the matrix is singular. These results are similar to the ones of Alimisis and Vandereycken (2024) for the symmetric eigenvalue problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13990v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Foivos Alimisis, Bart Vandereycken</dc:creator>
    </item>
    <item>
      <title>A System of BSDEs with Singular Terminal Values Arising in Optimal Liquidation with Regime Switching</title>
      <link>https://arxiv.org/abs/2412.19058</link>
      <description>arXiv:2412.19058v2 Announce Type: replace-cross 
Abstract: We study a stochastic control problem with regime switching arising in an optimal liquidation problem with dark pools and multiple regimes. The new feature of this model is that it introduces a system of BSDEs with jumps and with singular terminal values, which appears in literature for the first time. The existence result for this system is obtained. As a result, we solve the stochastic control problem with regime switching. More importantly, the uniqueness result of this system is also obtained, in contrast to merely minimal solutions established in most related literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.19058v2</guid>
      <category>q-fin.MF</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guanxing Fu, Xiaomin Shi, Zuo Quan Xu</dc:creator>
    </item>
    <item>
      <title>Gradient Equilibrium in Online Learning: Theory and Applications</title>
      <link>https://arxiv.org/abs/2501.08330</link>
      <description>arXiv:2501.08330v2 Announce Type: replace-cross 
Abstract: We present a new perspective on online learning that we refer to as gradient equilibrium: a sequence of iterates achieves gradient equilibrium if the average of gradients of losses along the sequence converges to zero. In general, this condition is not implied by nor implies sublinear regret. It turns out that gradient equilibrium is achievable by standard online learning methods such as gradient descent and mirror descent with constant step sizes (rather than decaying step sizes, as is usually required for no regret). Further, as we show through examples, gradient equilibrium translates into an interpretable and meaningful property in online prediction problems spanning regression, classification, quantile estimation, and others. Notably, we show that the gradient equilibrium framework can be used to develop a debiasing scheme for black-box predictions under arbitrary distribution shift, based on simple post hoc online descent updates. We also show that post hoc gradient updates can be used to calibrate predicted quantiles under distribution shift, and that the framework leads to unbiased Elo scores for pairwise preference prediction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08330v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anastasios N. Angelopoulos, Michael I. Jordan, Ryan J. Tibshirani</dc:creator>
    </item>
    <item>
      <title>Gradient Descent Converges Linearly to Flatter Minima than Gradient Flow in Shallow Linear Networks</title>
      <link>https://arxiv.org/abs/2501.09137</link>
      <description>arXiv:2501.09137v2 Announce Type: replace-cross 
Abstract: We study the gradient descent (GD) dynamics of a depth-2 linear neural network with a single input and output. We show that GD converges at an explicit linear rate to a global minimum of the training loss, even with a large stepsize -- about $2/\textrm{sharpness}$. It still converges for even larger stepsizes, but may do so very slowly. We also characterize the solution to which GD converges, which has lower norm and sharpness than the gradient flow solution. Our analysis reveals a trade off between the speed of convergence and the magnitude of implicit regularization. This sheds light on the benefits of training at the ``Edge of Stability'', which induces additional regularization by delaying convergence and may have implications for training more complex models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.09137v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pierfrancesco Beneventano, Blake Woodworth</dc:creator>
    </item>
    <item>
      <title>Reducing real-time complexity via sub-control Lyapunov functions: from theory to experiments</title>
      <link>https://arxiv.org/abs/2501.09143</link>
      <description>arXiv:2501.09143v2 Announce Type: replace-cross 
Abstract: The techniques to design control Lyapunov functions (CLF), along with a proper stabilizing feedback, possibly in the presence of constraints, often provide control laws that are too complex for proper implementation online, especially when an optimization problem is involved. In this work, we show how to acquire an alternative, computationally attractive feedback. Given a nominal CLF and a nominal state feedback, we say that a different positive definite function is a Sub-control Lyapunov function (SCLF) if its Lyapunov derivative is negative-definite and bounded above by the Lyapunov derivative of the nominal function with the nominal control. It turns out that if we consider a family of basis functions, then a SCLF can be computed by linear programming, with an infinite number of constraints. The idea is that although the offline computational burden to achieve the new controller and solve the linear program is considerable, the online computational burden is drastically reduced. Comprehensive simulations and experiments on drone control are conducted to demonstrate the effectiveness of the study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.09143v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 22 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Huu-Thinh Do, Franco Blanchini, Stefano Miani, Ionela Prodan</dc:creator>
    </item>
  </channel>
</rss>
