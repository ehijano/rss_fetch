<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.EM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.EM</link>
    <description>econ.EM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.EM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 31 Mar 2025 04:00:14 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 31 Mar 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Two Level Nested and Sequential Logit</title>
      <link>https://arxiv.org/abs/2503.21808</link>
      <description>arXiv:2503.21808v1 Announce Type: new 
Abstract: This technical note provides comprehensive derivations of fundamental equations in two-level nested and sequential logit models for analyzing hierarchical choice structures. We present derivations of the Berry (1994) inversion formula, nested inclusive values computation, and multi-level market share equations, complementing existing literature. While conceptually distinct, nested and sequential logit models share mathematical similarities and, under specific distributional assumptions, yield identical inversion formulas-offering valuable analytical insights. These notes serve as a practical reference for researchers implementing multi-level discrete choice models in empirical applications, particularly in industrial organization and demand estimation contexts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.21808v1</guid>
      <category>econ.EM</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Mon, 31 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Davide Luparello</dc:creator>
    </item>
    <item>
      <title>An Artificial Trend Index for Private Consumption Using Google Trends</title>
      <link>https://arxiv.org/abs/2503.21981</link>
      <description>arXiv:2503.21981v1 Announce Type: new 
Abstract: In recent years, the use of databases that analyze trends, sentiments or news to make economic projections or create indicators has gained significant popularity, particularly with the Google Trends platform. This article explores the potential of Google search data to develop a new index that improves economic forecasts, with a particular focus on one of the key components of economic activity: private consumption (64\% of GDP in Peru). By selecting and estimating categorized variables, machine learning techniques are applied, demonstrating that Google data can identify patterns to generate a leading indicator in real time and improve the accuracy of forecasts. Finally, the results show that Google's "Food" and "Tourism" categories significantly reduce projection errors, highlighting the importance of using this information in a segmented manner to improve macroeconomic forecasts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.21981v1</guid>
      <category>econ.EM</category>
      <category>stat.ML</category>
      <pubDate>Mon, 31 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Juan Tenorio, Heidi Alpiste, Jakelin Rem\'on, Arian Segil</dc:creator>
    </item>
    <item>
      <title>tempdisagg: A Python Framework for Temporal Disaggregation of Time Series Data</title>
      <link>https://arxiv.org/abs/2503.22054</link>
      <description>arXiv:2503.22054v1 Announce Type: new 
Abstract: tempdisagg is a modern, extensible, and production-ready Python framework for temporal disaggregation of time series data. It transforms low-frequency aggregates into consistent, high-frequency estimates using a wide array of econometric techniques-including Chow-Lin, Denton, Litterman, Fernandez, and uniform interpolation-as well as enhanced variants with automated estimation of key parameters such as the autocorrelation coefficient rho. The package introduces features beyond classical methods, including robust ensemble modeling via non-negative least squares optimization, post-estimation correction of negative values under multiple aggregation rules, and optional regression-based imputation of missing values through a dedicated Retropolarizer module. Architecturally, it follows a modular design inspired by scikit-learn, offering a clean API for validation, modeling, visualization, and result interpretation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.22054v1</guid>
      <category>econ.EM</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <pubDate>Mon, 31 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Jaime Vera-Jaramillo</dc:creator>
    </item>
    <item>
      <title>Inference on effect size after multiple hypothesis testing</title>
      <link>https://arxiv.org/abs/2503.22369</link>
      <description>arXiv:2503.22369v1 Announce Type: new 
Abstract: Significant treatment effects are often emphasized when interpreting and summarizing empirical findings in studies that estimate multiple, possibly many, treatment effects. Under this kind of selective reporting, conventional treatment effect estimates may be biased and their corresponding confidence intervals may undercover the true effect sizes. We propose new estimators and confidence intervals that provide valid inferences on the effect sizes of the significant effects after multiple hypothesis testing. Our methods are based on the principle of selective conditional inference and complement a wide range of tests, including step-up tests and bootstrap-based step-down tests. Our approach is scalable, allowing us to study an application with over 370 estimated effects. We justify our procedure for asymptotically normal treatment effect estimators. We provide two empirical examples that demonstrate bias correction and confidence interval adjustments for significant effects. The magnitude and direction of the bias correction depend on the correlation structure of the estimated effects and whether the interpretation of the significant effects depends on the (in)significance of other effects.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.22369v1</guid>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 31 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Andreas Dzemski, Ryo Okui, Wenjie Wang</dc:creator>
    </item>
    <item>
      <title>Semiparametric Triple Difference Estimators</title>
      <link>https://arxiv.org/abs/2502.19788</link>
      <description>arXiv:2502.19788v2 Announce Type: replace 
Abstract: The triple difference causal inference framework is an extension of the well-known difference-in-differences framework. It relaxes the parallel trends assumption of the difference-in-differences framework through leveraging data from an auxiliary domain. Despite being commonly applied in empirical research, the triple difference framework has received relatively limited attention in the statistics literature. Specifically, investigating the intricacies of identification and the design of robust and efficient estimators for this framework has remained largely unexplored. This work aims to address these gaps in the literature. From the identification standpoint, we present outcome regression and weighting methods to identify the average treatment effect on the treated in both panel data and repeated cross-section settings. For the latter, we relax the commonly made assumption of time-invariant covariates. From the estimation perspective, we consider semiparametric estimators for the triple difference framework in both panel data and repeated cross-sections settings. These estimators are based upon the cross-fitting technique, and flexible machine learning tools can be used to estimate the nuisance components. We demonstrate that our proposed estimators are doubly robust, and we characterize the conditions under which they are consistent and asymptotically normal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.19788v2</guid>
      <category>econ.EM</category>
      <category>stat.ME</category>
      <pubDate>Mon, 31 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sina Akbari, Negar Kiyavash, AmirEmad Ghassami</dc:creator>
    </item>
    <item>
      <title>Policy Learning with Competing Agents</title>
      <link>https://arxiv.org/abs/2204.01884</link>
      <description>arXiv:2204.01884v5 Announce Type: replace-cross 
Abstract: Decision makers often aim to learn a treatment assignment policy under a capacity constraint on the number of agents that they can treat. When agents can respond strategically to such policies, competition arises, complicating estimation of the optimal policy. In this paper, we study capacity-constrained treatment assignment in the presence of such interference. We consider a dynamic model where the decision maker allocates treatments at each time step and heterogeneous agents myopically best respond to the previous treatment assignment policy. When the number of agents is large but finite, we show that the threshold for receiving treatment under a given policy converges to the policy's mean-field equilibrium threshold. Based on this result, we develop a consistent estimator for the policy gradient. In a semi-synthetic experiment with data from the National Education Longitudinal Study of 1988, we demonstrate that this estimator can be used for learning capacity-constrained policies in the presence of strategic behavior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2204.01884v5</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>econ.EM</category>
      <pubDate>Mon, 31 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Roshni Sahoo, Stefan Wager</dc:creator>
    </item>
  </channel>
</rss>
