<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.NA</link>
    <description>math.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 09 Aug 2024 04:00:49 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 09 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Error Bounds for Open Quantum Systems with Harmonic Bosonic Bath</title>
      <link>https://arxiv.org/abs/2408.04009</link>
      <description>arXiv:2408.04009v1 Announce Type: new 
Abstract: We investigate the dependence of physical observable of open quantum systems with Bosonic bath on the bath correlation function. We provide an error estimate of the difference of physical observable induced by the variation of bath correlation function, based on diagrammatic and combinatorial arguments. This gives a mathematically rigorous justification of the result in [Mascherpa et al, Phys Rev Lett 2017].</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04009v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>quant-ph</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kaizhao Liu, Jianfeng Lu</dc:creator>
    </item>
    <item>
      <title>A hybrid interpolation ACA accelerated method for parabolic boundary integral operators</title>
      <link>https://arxiv.org/abs/2408.04080</link>
      <description>arXiv:2408.04080v1 Announce Type: new 
Abstract: We consider piecewise polynomial discontinuous Galerkin discretizations of boundary integral reformulations of the heat equation. The resulting linear systems are dense and block-lower triangular and hence can be solved by block forward elimination. For the fast evaluation of the history part, the matrix is subdivided into a family of sub-matrices according to the temporal separation. Separated blocks are approximated by Chebyshev interpolation of the heat kernel in time. For the spatial variable, we propose an adaptive cross approximation (ACA) framework to obtain a data-sparse approximation of the entire matrix. We analyse how the ACA tolerance must be adjusted to the temporal separation and present numerical results for a benchmark problem to confirm the theoretical estimates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04080v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sivaram Ambikasaran, Ritesh Khan, Johannes Tausch, Sihao Wang</dc:creator>
    </item>
    <item>
      <title>Splitting Methods for Computing Matrix Functions (Elements) Based on Non-Zero Diagonals Positions</title>
      <link>https://arxiv.org/abs/2408.04128</link>
      <description>arXiv:2408.04128v1 Announce Type: new 
Abstract: In applications, we often need to compute functions of matrices, such as banded matrices, the Kronecker sum of banded matrices, Toeplitz matrices, and many other types, which all share the common feature that their non-zero elements are concentrated around certain diagonals. We approximate matrix functions by considering the positions of non-zero diagonals in the original matrix. Focusing on non-zero diagonals provides us with simple algorithms to be used as tools to reduce complexity of other algorithms for computing matrix functions. Here, we first establish a decay bound for elements of matrix functions using the non-zero diagonals. Then, we develop methods that involve dividing the problem of computing matrix functions into functions of some submatrices of the original matrix. The size of these submatrices depends on the positions and number of non-zero diagonals in a monomial of the original matrix, ranging from degree zero to a given degree. For Toeplitz matrices, we demonstrate that our method turns to a simpler algorithm and works more efficiently. The convergence analysis of our proposed methods is conducted by establishing connections to the best polynomial approximation. When only specific elements or the trace of matrix functions are required, we derive submatrices from the original matrix based solely on the indices of the elements of interest. Additionally, for the special case of banded-symmetric Toeplitz matrices, we derive an approximation for elements of matrix functions with geometrically reducing error, using closed-form formulas that depend solely on the indices of the elements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04128v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Majed Hamadi, Nezam Mahdavi-Amiri</dc:creator>
    </item>
    <item>
      <title>R-adaptive DeepONet: Learning Solution Operators for PDEs with Discontinuous Solutions Using an R-adaptive Strategy</title>
      <link>https://arxiv.org/abs/2408.04157</link>
      <description>arXiv:2408.04157v1 Announce Type: new 
Abstract: DeepONet has recently been proposed as a representative framework for learning nonlinear mappings between function spaces. However, when it comes to approximating solution operators of partial differential equations (PDEs) with discontinuous solutions, DeepONet poses a foundational approximation lower bound due to its linear reconstruction property. Inspired by the moving mesh (R-adaptive) method, we propose an R-adaptive DeepONet method, which contains the following components: (1) the output data representation is transformed from the physical domain to the computational domain using the equidistribution principle; (2) the maps from input parameters to the solution and the coordinate transformation function over the computational domain are learned using DeepONets separately; (3) the solution over the physical domain is obtained via post-processing methods such as the (linear) interpolation method. Additionally, we introduce a solution-dependent weighting strategy in the training process to reduce the final error. We establish an upper bound for the reconstruction error based on piecewise linear interpolation and show that the introduced R-adaptive DeepONet can reduce this bound. Moreover, for two prototypical PDEs with sharp gradients or discontinuities, we prove that the approximation error decays at a superlinear rate with respect to the trunk basis size, unlike the linear decay observed in vanilla DeepONets. Therefore, the R-adaptive DeepONet overcomes the limitations of DeepONet, and can reduce the approximation error for problems with discontinuous solutions. Numerical experiments on PDEs with discontinuous solutions, including the linear advection equation, the Burgers' equation with low viscosity, and the compressible Euler equations of gas dynamics, are conducted to verify the advantages of the R-adaptive DeepONet over available variants of DeepONet.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04157v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yameng Zhu, Jingrun Chen, Weibing Deng</dc:creator>
    </item>
    <item>
      <title>Solving high-dimensional Hamilton-Jacobi-Bellman equation with functional hierarchical tensor</title>
      <link>https://arxiv.org/abs/2408.04209</link>
      <description>arXiv:2408.04209v1 Announce Type: new 
Abstract: This work proposes a novel numerical scheme for solving the high-dimensional Hamilton-Jacobi-Bellman equation with a functional hierarchical tensor ansatz. We consider the setting of stochastic control, whereby one applies control to a particle under Brownian motion. In particular, the existence of diffusion presents a new challenge to conventional tensor network methods for deterministic optimal control. To overcome the difficulty, we use a general regression-based formulation where the loss term is the Bellman consistency error combined with a Sobolev-type penalization term. We propose two novel sketching-based subroutines for obtaining the tensor-network approximation to the action-value functions and the value functions, which greatly accelerate the convergence for the subsequent regression phase. We apply the proposed approach successfully to two challenging control problems with Ginzburg-Landau potential in 1D and 2D with 64 variables.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04209v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xun Tang, Nan Sheng, Lexing Ying</dc:creator>
    </item>
    <item>
      <title>Explicit expression and fast algorithms for the inverse of some matrices arising from implicit time integration</title>
      <link>https://arxiv.org/abs/2408.04316</link>
      <description>arXiv:2408.04316v1 Announce Type: new 
Abstract: In this paper, we first present an explicit expression for the inverse\emph{} of a type of matrices. As special applications, the inverse of some matrices arising from implicit time integration techniques, such as the well-known implicit Runge-Kutta schemes and block implicit methods, can also be explicitly determined. Adiitionally, we introduce three fast algorithms for computing the elements of the inverse of these matrices in $O(n^2)$ arithmetic operations, i.e., the first one is based on Traub algorithm for fast inversion of Vandermonde matrices, while the other two utilize the special structure of the matrices. Finally, some symbolic and numerical results are presented to show that our algorithms are both highly efficient and accurate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04316v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Li Shishun, Wei Huile</dc:creator>
    </item>
    <item>
      <title>Sensitivity analysis of fractional linear systems based on random walks with negligible memory usage</title>
      <link>https://arxiv.org/abs/2408.04351</link>
      <description>arXiv:2408.04351v1 Announce Type: new 
Abstract: A random walk-based method is proposed to efficiently compute the solution of a large class of fractional in time linear systems of differential equations (linear F-ODE systems), along with the derivatives with respect to the system parameters. Such a method is unbiased and unconditionally stable, and can therefore be used to provide an unbiased estimation of individual entries of the solution, or the full solution. By using stochastic differentiation techniques, it can be used as well to provide unbiased estimators of the sensitivities of the solution with respect to the problem parameters without any additional computational cost. The time complexity of the algorithm is discussed here, along with suitable variance bounds, which prove in practice the convergence of the algorithm. Finally, several test cases were run to assess the validity of the algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04351v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andr\'es Centeno, Juan A. Acebr\'on, Jos\'e Monteiro</dc:creator>
    </item>
    <item>
      <title>Efficient finite element schemes for a phase field model of two-phase incompressible flows with different densities</title>
      <link>https://arxiv.org/abs/2408.04371</link>
      <description>arXiv:2408.04371v1 Announce Type: new 
Abstract: In this paper, we present two multiple scalar auxiliary variable (MSAV)-based, finite element numerical schemes for the Abels-Garcke-Gr{\"u}n (AGG) model, which is a thermodynamically consistent phase field model of two-phase incompressible flows with different densities. Both schemes are decoupled, linear, second-order in time, and the numerical implementation turns out to be straightforward. The first scheme solves the Navier-Stokes equations in a saddle point formulation, while the second one employs the artificial compressibility method, leading to a fully decoupled structure with a time-independent pressure update equation. In terms of computational cost, only a sequence of independent elliptic or saddle point systems needs to be solved at each time step. At a theoretical level, the unique solvability and unconditional energy stability (with respect to a modified energy functional) of the proposed schemes are established. In addition, comprehensive numerical simulations are performed to verify the effectiveness and robustness of the proposed schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04371v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.jcp.2024.113331</arxiv:DOI>
      <dc:creator>Jiancheng Wang, Maojun Li, Cheng Wang</dc:creator>
    </item>
    <item>
      <title>A Space-Time Multigrid Method for Space-Time Finite Element Discretizations of Parabolic and Hyperbolic PDEs</title>
      <link>https://arxiv.org/abs/2408.04372</link>
      <description>arXiv:2408.04372v1 Announce Type: new 
Abstract: We present a space-time multigrid method based on tensor-product space-time finite element discretizations. The method is facilitated by the matrix-free capabilities of the {\ttfamily deal.II} library. It addresses both high-order continuous and discontinuous variational time discretizations with spatial finite element discretizations. The effectiveness of multigrid methods in large-scale stationary problems is well established. However, their application in the space-time context poses significant challenges, mainly due to the construction of suitable smoothers. To address these challenges, we develop a space-time cell-wise additive Schwarz smoother and demonstrate its effectiveness on the heat and acoustic wave equations. The matrix-free framework of the {\ttfamily deal.II} library supports various multigrid strategies, including $h$-, $p$-, and $hp$-refinement across spatial and temporal dimensions. Extensive empirical evidence, provided through scaling and convergence tests on high-performance computing platforms, demonstrate high performance on perturbed meshes and problems with heterogeneous and discontinuous coefficients. Throughputs of over a billion degrees of freedom per second are achieved on problems with more than a trillion global degrees of freedom. The results prove that the space-time multigrid method can effectively solve complex problems in high-fidelity simulations and show great potential for use in coupled problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04372v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nils Margenberg, Peter Munch</dc:creator>
    </item>
    <item>
      <title>Row-aware Randomized SVD with applications</title>
      <link>https://arxiv.org/abs/2408.04503</link>
      <description>arXiv:2408.04503v1 Announce Type: new 
Abstract: The randomized singular value decomposition proposed in [12] has certainly become one of the most well-established randomization-based algorithms in numerical linear algebra. The key ingredient of the entire procedure is the computation of a subspace which is close to the column space of the target matrix $\mathbf{A}$ up to a certain probabilistic confidence. In this paper we propose a modification to the standard randomized SVD procedure which leads, in general, to better approximations to $\text{Range}(\mathbf{A})$ at the same computational cost. To this end, we explicitly construct information from the row space of $\mathbf{A}$ enhancing the quality of our approximation. We also observe that very few pieces of information from $\text{Range}(\mathbf{A}^T)$ are indeed necessary. We thus design a variant of our algorithm equipped with a subsampling step which largely increases the efficiency of our procedure while attaining competitive accuracy records. Our findings are supported by both theoretical analysis and numerical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04503v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Davide Palitta, Sascha Portaro</dc:creator>
    </item>
    <item>
      <title>Sharp error bounds for edge-element discretisations of the high-frequency Maxwell equations</title>
      <link>https://arxiv.org/abs/2408.04507</link>
      <description>arXiv:2408.04507v1 Announce Type: new 
Abstract: We prove sharp wavenumber-explicit error bounds for first- or second-type-N\'ed\'elec-element (a.k.a. edge-element) conforming discretisations, of arbitrary (fixed) order, of the variable-coefficient time-harmonic Maxwell equations posed in a bounded domain with perfect electric conductor (PEC) boundary conditions. The PDE coefficients are allowed to be piecewise regular and complex-valued; this set-up therefore includes scattering from a PEC obstacle and/or variable real-valued coefficients, with the radiation condition approximated by a perfectly matched layer (PML).
  In the analysis of the $h$-version of the finite-element method, with fixed polynomial degree $p$, applied to the time-harmonic Maxwell equations, the $\textit{asymptotic regime}$ is when the meshwidth, $h$, is small enough (in a wavenumber-dependent way) that the Galerkin solution is quasioptimal independently of the wavenumber, while the $\textit{preasymptotic regime}$ is the complement of the asymptotic regime.
  The results of this paper are the first preasymptotic error bounds for the time-harmonic Maxwell equations using first-type N\'ed\'elec elements or higher-than-lowest-order second-type N\'ed\'elec elements. Furthermore, they are the first wavenumber-explicit results, even in the asymptotic regime, for Maxwell scattering problems with a non-empty scatterer.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04507v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Th\'eophile Chaumont-Frelet, Jeffrey Galkowski, Euan A. Spence</dc:creator>
    </item>
    <item>
      <title>Asymptotically optimal $t$-design curves on $S^3$</title>
      <link>https://arxiv.org/abs/2408.04044</link>
      <description>arXiv:2408.04044v1 Announce Type: cross 
Abstract: A $\textit{spherical $t$-design curve}$ was defined by Ehler and Gr\"{o}chenig to be a continuous, piecewise smooth, closed curve on the sphere with finitely many self-intersections whose associated line integral applied to any polynomial of degree $t$ or less evaluates to the average of this polynomial on the sphere. These authors posed the problem of proving that there exist sequences $\{\gamma_t\}_{t\in\Bbb N}$ of $t$-design curves on $S^d$ of asymptotically optimal length $\ell(\gamma_t)=\Theta(t^{d-1})$ as $t\to\infty$ and solved this problem for $d=2$. This work solves the problem for $d=3$ by proving existence of a constant $\mathcal C&gt;0$ such that for any $C&gt;\mathcal C$ and $t\in\Bbb N_+$, there exists a $t$-design curve with no self-intersections on $S^3$ of length $Ct^2$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04044v1</guid>
      <category>math.MG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ayodeji Lindblad</dc:creator>
    </item>
    <item>
      <title>Visibility Analysis of the Sun as Viewed from Multiple Spacecraft at the Sun-Earth Lagrange Points</title>
      <link>https://arxiv.org/abs/2408.04208</link>
      <description>arXiv:2408.04208v1 Announce Type: cross 
Abstract: Beyond the Sun-Earth line, spacecraft equipped with various solar telescopes are intended to be deployed at several different vantage points in the heliosphere to carry out coordinated, multi-view observations of the Sun and its dynamic activities. In this context, we investigate solar visibility by imaging instruments onboard the spacecraft orbiting the Sun-Earth Lagrange points L1, L4 and L5, respectively. An optimal arrival time for vertical periodic orbits stationed at L4 and L5 is determined based on geometric considerations that ensure maximum visibility of solar poles or higher latitudes per year. For a different set of orbits around the three Lagrange points (L1, L4 and L5), we calculate the visibility of the solar surface (i.e., observation days per year) as a function of the solar latitude. We also analyze where the solar limb viewed from one of the three Sun-Earth Lagrange points under consideration is projected onto the solar surface visible to the other two. This analysis particularly aims at determining the feasibility of studying solar eruptions, such as flares and coronal mass ejections, with coordinated observations of off-limb erupting coronal structures and their on-disk magnetic footpoints. In addition, visibility analysis of a feature (such as sunspots) on the solar surface is made for multiple spacecraft in various types of orbits with different inclinations to quantify the improvement in continuous tracking of the target feature for studying its long-term evolution from emergence, growth and to decay. A comprehensive comparison of observations from single (L1), double (L1 and L4) and multi-space missions (L1, L4 and L5) is carried out through our solar visibility analysis, and this may help us to design future space missions of constructing multiple solar observatories at the Sun-Earth Lagrange points.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04208v1</guid>
      <category>astro-ph.SR</category>
      <category>astro-ph.EP</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.space-ph</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jinsung Lee, Sung-Hong Park, Arik Posner, Kyung-Suk Cho, Jaemyung Ahn</dc:creator>
    </item>
    <item>
      <title>Numerical analysis of the stochastic Stefan problem</title>
      <link>https://arxiv.org/abs/2306.12668</link>
      <description>arXiv:2306.12668v3 Announce Type: replace 
Abstract: The gradient discretisation method (GDM) -- a generic framework encompassing many numerical methods -- is studied for a general stochastic Stefan problem with multiplicative noise. The convergence of the numerical solutions is proved by compactness method using discrete functional analysis tools, Skorohod theorem and the martingale representation theorem. The generic convergence results established in the GDM framework are applicable to a range of different numerical methods, including for example mass-lumped finite elements, but also some finite volume methods, mimetic methods, lowest-order virtual element methods, etc. Theoretical results are complemented by numerical tests based on two methods that fit in GDM framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.12668v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jerome Droniou, Muhammad Awais Khan, Kim Ngan Le</dc:creator>
    </item>
    <item>
      <title>Reduced projection method for photonic moir\'e lattices</title>
      <link>https://arxiv.org/abs/2309.09238</link>
      <description>arXiv:2309.09238v3 Announce Type: replace 
Abstract: This paper presents a reduced projection method for the solution of quasiperiodic Schr\"{o}dinger eigenvalue problems for photonic moir\'e lattices. Using the properties of the Schr\"{o}dinger operator in higher-dimensional space via a projection matrix, we rigorously prove that the generalized Fourier coefficients of the eigenfunctions exhibit faster decay rate along a fixed direction associated with the projection matrix. An efficient reduction strategy of the basis space is then proposed to reduce the degrees of freedom significantly. Rigorous error estimates of the proposed reduced projection method are provided, indicating that a small portion of the degrees of freedom is sufficient to achieve the same level of accuracy as the classical projection method. We present numerical examples of photonic moir\'e lattices in one and two dimensions to demonstrate the accuracy and efficiency of our proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.09238v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zixuan Gao, Zhenli Xu, Zhiguo Yang</dc:creator>
    </item>
    <item>
      <title>Enhancing ASR Performance through OCR Word Frequency Analysis: Theoretical Foundations</title>
      <link>https://arxiv.org/abs/2405.02995</link>
      <description>arXiv:2405.02995v3 Announce Type: replace 
Abstract: As the interest in large language models grows, the importance of accuracy in automatic speech recognition has become more pronounced. This is particularly true for lectures that include specialized terminology, where the success rate of traditional ASR models tends to be low, posing a challenging problem. A method to improve ASR performance for specialized terminology using the word frequency difference approach has been proposed. Through experiments and data analysis, we investigated whether this proposal effectively addressed this issue. In addition, we introduced the power law as the theoretical foundation for the relative frequency methodology mentioned in this approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.02995v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>cs.SD</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kyudan Jung, Nam-Joon Kim, Hyun Gon Ryu, Hyuk-Jae Lee</dc:creator>
    </item>
    <item>
      <title>A note on eigenvalues and singular values of variable Toeplitz matrices and matrix-sequences, with application to variable two-step BDF approximations to parabolic equations</title>
      <link>https://arxiv.org/abs/2407.00792</link>
      <description>arXiv:2407.00792v3 Announce Type: replace 
Abstract: Here, we consider a more general class of matrix-sequences and we prove that they belong to the maximal $*$-algebra of generalized locally Toeplitz (GLT) matrix-sequences. Then, we identify the associated GLT symbols and GLT momentary symbols in the general setting and in the specific case, by providing in both cases a spectral and singular value analysis. More specifically, we use the GLT tools in order to study the asymptotic behaviour of the eigenvalues and singular values of the considered BDF matrix-sequences, in connection with the given non-uniform grids. Numerical examples, visualizations, and open problems end the present work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00792v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nikos Barakitis, Valerio Loi, Stefano Serra-Capizzano</dc:creator>
    </item>
    <item>
      <title>Column and row subset selection using nuclear scores: algorithms and theory for Nystr\"{o}m approximation, CUR decomposition, and graph Laplacian reduction</title>
      <link>https://arxiv.org/abs/2407.01698</link>
      <description>arXiv:2407.01698v2 Announce Type: replace 
Abstract: Column selection is an essential tool for structure-preserving low-rank approximation, with wide-ranging applications across many fields, such as data science, machine learning, and theoretical chemistry. In this work, we develop unified methodologies for fast, efficient, and theoretically guaranteed column selection. First we derive and implement a sparsity-exploiting deterministic algorithm applicable to tasks including kernel approximation and CUR decomposition. Next, we develop a matrix-free formalism relying on a randomization scheme satisfying guaranteed concentration bounds, applying this construction both to CUR decomposition and to the approximation of matrix functions of graph Laplacians. Importantly, the randomization is only relevant for the computation of the scores that we use for column selection, not the selection itself given these scores. For both deterministic and matrix-free algorithms, we bound the performance favorably relative to the expected performance of determinantal point process (DPP) sampling and, in select scenarios, that of exactly optimal subset selection. The general case requires new analysis of the DPP expectation. Finally, we demonstrate strong real-world performance of our algorithms on a diverse set of example approximation tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.01698v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mark Fornace, Michael Lindsey</dc:creator>
    </item>
    <item>
      <title>Mixed Precision Block-Jacobi Preconditioner: Algorithms, Performance Evaluation and Feature Analysis</title>
      <link>https://arxiv.org/abs/2407.15973</link>
      <description>arXiv:2407.15973v2 Announce Type: replace 
Abstract: In this paper, we propose two mixed precision algorithms for Block-Jacobi preconditioner(BJAC): a fixed low precision strategy and an adaptive precision strategy. We evaluate the performance improvement of the proposed mixed precision BJAC preconditioners combined with the preconditioned conjugate gradient algorithm using problems including diffusion equations and radiation hydrodynamics equations. Numerical results show that, compared to the uniform high precision PCG algorithm, the mixed precision preconditioners can achieve speedups from 1.3 to 1.8 without sacrificing accuracy. Furthermore, we observe the phenomenon of convergence delay in some test cases for the mixed precision preconditioners, and further analyse the matrix features associate with the convergence delay behavior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.15973v2</guid>
      <category>math.NA</category>
      <category>cs.MS</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ningxi Tian, Silu Huang, Xiaowen Xu</dc:creator>
    </item>
    <item>
      <title>Partial-differential-algebraic equations of nonlinear dynamics by Physics-Informed Neural-Network: (I) Operator splitting and framework assessment</title>
      <link>https://arxiv.org/abs/2408.01914</link>
      <description>arXiv:2408.01914v2 Announce Type: replace 
Abstract: Several forms for constructing novel physics-informed neural-networks (PINN) for the solution of partial-differential-algebraic equations based on derivative operator splitting are proposed, using the nonlinear Kirchhoff rod as a prototype for demonstration. The open-source DeepXDE is likely the most well documented framework with many examples. Yet, we encountered some pathological problems and proposed novel methods to resolve them. Among these novel methods are the PDE forms, which evolve from the lower-level form with fewer unknown dependent variables to higher-level form with more dependent variables, in addition to those from lower-level forms. Traditionally, the highest-level form, the balance-of-momenta form, is the starting point for (hand) deriving the lowest-level form through a tedious (and error prone) process of successive substitutions. The next step in a finite element method is to discretize the lowest-level form upon forming a weak form and linearization with appropriate interpolation functions, followed by their implementation in a code and testing. The time-consuming tedium in all of these steps could be bypassed by applying the proposed novel PINN directly to the highest-level form. We developed a script based on JAX. While our JAX script did not show the pathological problems of DDE-T (DDE with TensorFlow backend), it is slower than DDE-T. That DDE-T itself being more efficient in higher-level form than in lower-level form makes working directly with higher-level form even more attractive in addition to the advantages mentioned further above. Since coming up with an appropriate learning-rate schedule for a good solution is more art than science, we systematically codified in detail our experience running optimization through a normalization/standardization of the network-training process so readers can reproduce our results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01914v2</guid>
      <category>math.NA</category>
      <category>cs.AI</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Loc Vu-Quoc, Alexander Humer</dc:creator>
    </item>
    <item>
      <title>OpenLB User Guide: Associated with Release 1.6 of the Code</title>
      <link>https://arxiv.org/abs/2307.11752</link>
      <description>arXiv:2307.11752v2 Announce Type: replace-cross 
Abstract: OpenLB is an object-oriented implementation of LBM. It is the first implementation of a generic platform for LBM programming, which is shared with the open source community (GPLv2). Since the first release in 2007, the code has been continuously improved and extended which is documented by thirteen releases as well as the corresponding release notes which are available on the OpenLB website (https://www.openlb.net). The OpenLB code is written in C++ and is used by application programmers as well as developers, with the ability to implement custom models OpenLB supports complex data structures that allow simulations in complex geometries and parallel execution using MPI, OpenMP and CUDA on high-performance computers. The source code uses the concepts of interfaces and templates, so that efficient, direct and intuitive implementations of the LBM become possible. The efficiency and scalability has been checked and proved by code reviews. This user manual and a source code documentation by DoxyGen are available on the OpenLB project website.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.11752v2</guid>
      <category>cs.MS</category>
      <category>cs.DC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Adrian Kummerl\"ander, Samuel J. Avis, Halim Kusumaatmaja, Fedor Bukreev, Michael Crocoll, Davide Dapelo, Simon Gro{\ss}mann, Nicolas Hafen, Shota Ito, Julius Je{\ss}berger, Eliane Kummer, Jan E. Marquardt, Johanna M\"odl, Tim Pertzel, Franti\v{s}ek Prinz, Florian Raichle, Martin Sadric, Maximilian Schecher, Dennis Teutscher, Stephan Simonis, Mathias J. Krause</dc:creator>
    </item>
    <item>
      <title>Robust and accurate simulations of flows over orography using non-conforming meshes</title>
      <link>https://arxiv.org/abs/2402.07759</link>
      <description>arXiv:2402.07759v3 Announce Type: replace-cross 
Abstract: We systematically validate the static local mesh refinement capabilities of a recently proposed IMEX-DG scheme implemented in the framework of the deal.II library. Non-conforming meshes are employed in atmospheric flow simulations to increase the resolution around complex orography. A number of numerical experiments based on classical benchmarks with idealized as well as real orography profiles demonstrate that simulations with the refined mesh are stable for long lead times and no spurious effects arise at the interfaces of mesh regions with different resolutions. Moreover, correct values of the momentum flux are retrieved and the correct large-scale orographic response is established. Hence, large-scale orography-driven flow features can be simulated without loss of accuracy using a much lower total amount of degrees of freedom. In a context of spatial resolutions approaching the hectometric scale in numerical weather prediction models, these results support the use of locally refined, non-conforming meshes as a reliable and effective tool to greatly reduce the dependence of atmospheric models on orographic wave drag parametrizations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.07759v3</guid>
      <category>physics.ao-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.flu-dyn</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Giuseppe Orlando, Tommaso Benacchio, Luca Bonaventura</dc:creator>
    </item>
    <item>
      <title>Suboptimality bounds for trace-bounded SDPs enable a faster and scalable low-rank SDP solver SDPLR+</title>
      <link>https://arxiv.org/abs/2406.10407</link>
      <description>arXiv:2406.10407v2 Announce Type: replace-cross 
Abstract: Semidefinite programs (SDPs) and their solvers are powerful tools with many applications in machine learning and data science. Designing scalable SDP solvers is challenging because by standard the positive semidefinite decision variable is an $n \times n$ dense matrix, even though the input is often $n \times n$ sparse matrices. However, the information in the solution may not correspond to a full-rank dense matrix as shown by Barvinok and Pataki. Two decades ago, Burer and Monteiro developed an SDP solver $\texttt{SDPLR}$ that optimizes over a low-rank factorization instead of the full matrix. This greatly decreases the storage cost and works well for many problems. The original solver $\texttt{SDPLR}$ tracks only the primal infeasibility of the solution, limiting the technique's flexibility to produce moderate accuracy solutions. We use a suboptimality bound for trace-bounded SDP problems that enables us to track the progress better and perform early termination. We then develop $\texttt{SDPLR+}$, which starts the optimization with an extremely low-rank factorization and dynamically updates the rank based on the primal infeasibility and suboptimality. This further speeds up the computation and saves the storage cost. Numerical experiments on Max Cut, Minimum Bisection, Cut Norm, and Lov\'{a}sz Theta problems with many recent memory-efficient scalable SDP solvers demonstrate its scalability up to problems with million-by-million decision variables and it is often the fastest solver to a moderate accuracy of $10^{-2}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.10407v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yufan Huang, David F. Gleich</dc:creator>
    </item>
  </channel>
</rss>
