<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.med-ph updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.med-ph</link>
    <description>physics.med-ph updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.med-ph" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 24 Jun 2024 04:03:15 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 24 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Deep-Learning Approach for Tissue Classification using Acoustic Waves during Ablation with an Er:YAG Laser (Updated)</title>
      <link>https://arxiv.org/abs/2406.14570</link>
      <description>arXiv:2406.14570v1 Announce Type: new 
Abstract: Today's mechanical tools for bone cutting (osteotomy) cause mechanical trauma that prolongs the healing process. Medical device manufacturers aim to minimize this trauma, with minimally invasive surgery using laser cutting as one innovation. This method ablates tissue using laser light instead of mechanical tools, reducing post-surgery healing time. A reliable feedback system is crucial during laser surgery to prevent damage to surrounding tissues. We propose a tissue classification method analyzing acoustic waves generated during laser ablation, demonstrating its applicability in an ex-vivo experiment. The ablation process with a microsecond pulsed Er:YAG laser produces acoustic waves, acquired with an air-coupled transducer. These waves were used to classify five porcine tissue types: hard bone, soft bone, muscle, fat, and skin. For automated tissue classification, we compared five Neural Network (NN) approaches: a one-dimensional Convolutional Neural Network (CNN) with time-dependent input, a Fully-connected Neural Network (FcNN) with either the frequency spectrum or principal components of the frequency spectrum as input, and a combination of a CNN and an FcNN with time-dependent data and its frequency spectrum as input. Consecutive acoustic waves were used to improve classification accuracy. Grad-Cam identified the activation map of the frequencies, showing low frequencies as the most important for this task. Our results indicated that combining time-dependent data with its frequency spectrum achieved the highest classification accuracy (65.5%-75.5%). We also found that using the frequency spectrum alone was sufficient, with no additional benefit from applying Principal Components Analysis (PCA).</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.14570v1</guid>
      <category>physics.med-ph</category>
      <category>cs.AI</category>
      <category>eess.IV</category>
      <category>q-bio.TO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Carlo Seppi, Philippe C. Cattin</dc:creator>
    </item>
    <item>
      <title>A novel optical assay system for bilirubin concentration measurement in whole blood</title>
      <link>https://arxiv.org/abs/2406.14816</link>
      <description>arXiv:2406.14816v1 Announce Type: new 
Abstract: As a biomarker for liver disease, bilirubin has been utilized in prognostic scoring systems for cirrhosis. While laboratory-based methods are used to determine bilirubin levels in clinical settings, they do not readily lend themselves to applications outside of hospitals. Consequently, bilirubin monitoring for cirrhotic patients is often performed only intermittently; thus, episodes requiring clinical interventions could be missed. This work investigates the feasibility of measuring bilirubin concentration in whole porcine blood samples using dual-wavelength transmission measurement. A compact and low-cost dual-wavelength transmission measurement setup is developed and optimized to measure whole blood bilirubin concentrations. Using small volumes of whole porcine blood (72 {\mu}L), we measured the bilirubin concentration within a range corresponding to healthy individuals and cirrhotic patients (1.2-30 mg/dL). We demonstrate that bilirubin levels can be estimated with a positive correlation (R-square &gt; 0.95) and an accuracy of +/- 1.7 mg/dL, with higher reliability in cirrhotic bilirubin concentrations (&gt; 4 mg/dL), critical for high-risk patients. The optical and electronic components utilized are economical and can be readily integrated into a miniature, low-cost, and user-friendly system. This could provide a pathway for point-of-care monitoring of blood bilirubin outside of medical facilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.14816v1</guid>
      <category>physics.med-ph</category>
      <category>eess.SP</category>
      <category>physics.bio-ph</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TBME.2021.3111150</arxiv:DOI>
      <arxiv:journal_reference>IEEE Transactions on Biomedical Engineering 69.2 (2021): 983-990</arxiv:journal_reference>
      <dc:creator>Jean Pierre Ndabakuranye, Anushi E. Rajapaksa, Genia Burchall, Shiqiang Li, Steven Prawer, Arman Ahnood</dc:creator>
    </item>
    <item>
      <title>3D-Localization of Single Point-Like Gamma Sources with a Coded Aperture Camera</title>
      <link>https://arxiv.org/abs/2406.15048</link>
      <description>arXiv:2406.15048v1 Announce Type: new 
Abstract: 3D-localization of gamma sources has the potential to improve the outcome of radio-guided surgery. The goal of this paper is to analyze the localization accuracy for point-like sources with a single coded aperture camera. We both simulated and measured a point-like $^{241}$Am source at $17$ positions distributed within the field of view of an experimental gamma camera. The setup includes a 0.11mm thick tungsten sheet with a MURA mask of rank $31$ and pinholes of $0.08$mm in diameter and a detector based on the photon counting readout circuit Timepix3. Two methods, namely an iterative search (ISL) including either a symmetric Gaussian fitting or an exponentially modified Gaussian fitting (EMG) and a center of mass method were compared to estimate the 3D source position. Considering the decreasing axial resolution with source-to-mask distance, the EMG improved the results by a factor of $4$ compared to the Gaussian fitting based on the simulated data. Overall, we obtained a mean localization error of $0.77$mm on the simulated and $2.64$mm on the experimental data in the imaging range of $20$mm to $100$ mm. This paper shows that despite the low axial resolution, point-like sources in the nearfield can be localized as well as with more sophisticated imaging devices such as stereo cameras. The influence of the source size and the photon count on the imaging and localization accuracy remains an important issue for further research. The acquired datasets and the localization methods of this research are publicly available on GitHub at "https://zenodo.org/records/11449544".</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15048v1</guid>
      <category>physics.med-ph</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tobias Mei{\ss}ner, Laura Antonia Cerbone, Paolo Russo, Werner Nahm, J\"urgen Hesser</dc:creator>
    </item>
    <item>
      <title>Unsupervised Bayesian Generation of Synthetic CT from CBCT Using Patient-Specific Score-Based Prior</title>
      <link>https://arxiv.org/abs/2406.15219</link>
      <description>arXiv:2406.15219v1 Announce Type: new 
Abstract: Background: Cone-beam computed tomography (CBCT) scans, performed fractionally (e.g., daily or weekly), are widely utilized for patient alignment in the image-guided radiotherapy (IGRT) process, thereby making it a potential imaging modality for the implementation of adaptive radiotherapy (ART) protocols. Nonetheless, significant artifacts and incorrect Hounsfield unit (HU) values hinder their application in quantitative tasks such as target and organ segmentations and dose calculation. Therefore, acquiring CT-quality images from the CBCT scans is essential to implement online ART in clinical settings.
  Purpose: This work aims to develop an unsupervised learning method using the patient-specific diffusion model for CBCT-based synthetic CT (sCT) generation to improve the image quality of CBCT.
  Methods: The proposed method is in an unsupervised framework that utilizes a patient-specific score-based model as the image prior alongside a customized total variation (TV) regularization to enforce coherence across different transverse slices. The score-based model is unconditionally trained using the same patient's planning CT (pCT) images to characterize the manifold of CT-quality images and capture the unique anatomical information of the specific patient. The efficacy of the proposed method was assessed on images from anatomical sites including head and neck (H&amp;N) cancer, pancreatic cancer, and lung cancer. The performance of the proposed CBCT correction method was evaluated using quantitative metrics including mean absolute error (MAE), peak signal-to-noise ratio (PSNR), and normalized cross-correlation (NCC). Additionally, the proposed algorithm was benchmarked against two other unsupervised diffusion model-based CBCT correction algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15219v1</guid>
      <category>physics.med-ph</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junbo Peng, Yuan Gao, Chih-Wei Chang, Richard Qiu, Tonghe Wang, Aparna Kesarwala, Kailin Yang, Jacob Scott, David Yu, Xiaofeng Yang</dc:creator>
    </item>
    <item>
      <title>Towards a second generation of metascintillators using the Purcell effect</title>
      <link>https://arxiv.org/abs/2406.15058</link>
      <description>arXiv:2406.15058v1 Announce Type: cross 
Abstract: This study focuses on advancing metascintillators to break the 100 ps barrier and approach the 10 ps target. We exploit nanophotonic features, specifically the Purcell effect, to shape and enhance the scintillation properties of the first-generation metascintillator. We demonstrate that a faster emission is achievable along with a more efficient conversion efficiency. This results in a coincidence time resolution improved by a factor of 1.6, crucial for TOF-PET applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15058v1</guid>
      <category>physics.optics</category>
      <category>physics.comp-ph</category>
      <category>physics.ins-det</category>
      <category>physics.med-ph</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Avner Shultzman, Roman Sch\"utz, Yaniv Kurman, Neta Lahav, George Dosovitskiy, Charles Roques-Carmes, Yehonadav Bekenstein, Georgios Konstantinou, Riccardo Latella, Lei Zhang, Francis Loignon-Houle, Antonio J. Gonzalez, Jos\'e Mar\'ia Benlloch, Ido Kaminer, Paul Lecoq</dc:creator>
    </item>
  </channel>
</rss>
