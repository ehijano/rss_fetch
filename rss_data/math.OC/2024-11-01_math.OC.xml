<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 01 Nov 2024 04:00:29 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Tightening convex relaxations of trained neural networks: a unified approach for convex and S-shaped activations</title>
      <link>https://arxiv.org/abs/2410.23362</link>
      <description>arXiv:2410.23362v1 Announce Type: new 
Abstract: The non-convex nature of trained neural networks has created significant obstacles in their incorporation into optimization models. Considering the wide array of applications that this embedding has, the optimization and deep learning communities have dedicated significant efforts to the convexification of trained neural networks. Many approaches to date have considered obtaining convex relaxations for each non-linear activation in isolation, which poses limitations in the tightness of the relaxations. Anderson et al. (2020) strengthened these relaxations and provided a framework to obtain the convex hull of the graph of a piecewise linear convex activation composed with an affine function; this effectively convexifies activations such as the ReLU together with the affine transformation that precedes it. In this article, we contribute to this line of work by developing a recursive formula that yields a tight convexification for the composition of an activation with an affine function for a wide scope of activation functions, namely, convex or ``S-shaped". Our approach can be used to efficiently compute separating hyperplanes or determine that none exists in various settings, including non-polyhedral cases. We provide computational experiments to test the empirical benefits of these convex approximations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.23362v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pablo Carrasco, Gonzalo Mu\~noz</dc:creator>
    </item>
    <item>
      <title>A Dynamic Strategic Plan for the Transition to a Clean Bus Fleet using Multi-Stage Stochastic Programming with a Case Study in Istanbul</title>
      <link>https://arxiv.org/abs/2410.23387</link>
      <description>arXiv:2410.23387v1 Announce Type: new 
Abstract: In recent years, the transition to clean bus fleets has accelerated. Although this transition might bring environmental and economic benefits, it requires a long-term strategic plan due to the large investment costs involved. This paper proposes a multi-stage stochastic program to optimize strategic plans for the clean bus fleet transition that explicitly considers the uncertainty scenarios in the cost and efficiency improvements of clean buses. Our optimization model minimizes the total expected cost subject to emission targets, budget restrictions and several other operational considerations. We propose a new forecasting approach that captures the correlation between these improvements to obtain realistic future pathways for Battery Electric Buses (BEBs) and Hydrogen Fuel Cell Buses (HFCBs), which are then given to the multi-stage stochastic program as scenarios. We also utilize a physics-based model for BEBs to accurately capture their energy consumption and recharging needs. As a case study, we focus on the complex public bus network of Istanbul, which aims to transition to a clean bus fleet by 2050. Utilizing real datasets, we solve a five-stage stochastic program spanning a 25-year planning horizon that involves 256 scenarios to obtain dynamic strategic plans that can be used by the policy makers. Our results suggest that BEBs are more advantageous than HFCBs, even in slow BEB but fast HFCB development scenarios. We also conduct several sensitivity analyses to understand the effects of the intermediate emission targets, budget limitations and energy prices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.23387v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Neman Karimi, Burak Kocuk, Tugce Yuksel</dc:creator>
    </item>
    <item>
      <title>Plug-and-play superiorization</title>
      <link>https://arxiv.org/abs/2410.23401</link>
      <description>arXiv:2410.23401v1 Announce Type: new 
Abstract: The superiorization methodology (SM) is an optimization heuristic in which an iterative algorithm, which aims to solve a particular problem, is ``superiorized'' to promote solutions that are improved with respect to some secondary criterion. This superiorization is achieved by perturbing iterates of the algorithm in nonascending directions of a prescribed function that penalizes undesirable characteristics in the solution; the solution produced by the superiorized algorithm should therefore be improved with respect to the value of this function. In this paper, we broaden the SM to allow for the perturbations to be introduced by an arbitrary procedure instead, using a plug-and-play approach. This allows for operations such as image denoisers or deep neural networks, which have applications to a broad class of problems, to be incorporated within the superiorization methodology. As proof of concept, we perform numerical simulations involving low-dose and sparse-view computed tomography image reconstruction, comparing the plug-and-play approach to a conventionally superiorized algorithm, as well as a post-processing approach. The plug-and-play approach provides comparable or better image quality in most cases, while also providing advantages in terms of computing time, and data fidelity of the solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.23401v1</guid>
      <category>math.OC</category>
      <category>physics.med-ph</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jon Henshaw, Aviv Gibali, Thomas Humphries</dc:creator>
    </item>
    <item>
      <title>Heterogeneous Min-Max Multi-Vehicle Multi-Depot Traveling Salesman Problem: Heuristics and Computational Results</title>
      <link>https://arxiv.org/abs/2410.23449</link>
      <description>arXiv:2410.23449v1 Announce Type: new 
Abstract: In this paper, a heuristic for a heterogeneous min-max multi-vehicle multi-depot traveling salesman problem is proposed, wherein heterogeneous vehicles start from given depot locations and need to cover a given set of targets. In the considered problem, vehicles can be structurally heterogeneous due to different vehicle speeds and/or functionally heterogeneous due to different vehicle-target assignments originating from different sensing capabilities of vehicles. The proposed heuristic for the considered problem has three stages: an initialization stage to generate an initial feasible solution, a local search stage to improve the incumbent solution by searching through different neighborhoods, and a perturbation/shaking stage, wherein the incumbent solution is perturbed to break from a local minimum. In this study, three types of neighborhood searches are employed. Furthermore, two different methods for constructing the initial feasible solution are considered, and multiple variations in the neighborhoods considered are explored in this study. The considered variations and construction methods are evaluated on a total of 128 instances generated with varying vehicle-to-target ratios, distribution for generating the targets, and vehicle-target assignment and are benchmarked against the best-known heuristic for this problem. Two heuristics were finally proposed based on the importance provided to objective value or computation time through extensive computational studies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.23449v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Deepak Prakash Kumar, Sivakumar Rathinam, Swaroop Darbha, Trevor Bihl</dc:creator>
    </item>
    <item>
      <title>A graph-based algorithm for the non-stationary lot-sizing problem with penalty scheme</title>
      <link>https://arxiv.org/abs/2410.23480</link>
      <description>arXiv:2410.23480v1 Announce Type: new 
Abstract: This paper introduces a graph-based algorithm for solving single-item, single-location inventory lot-sizing problems under non-stationary stochastic demand using the $(R_t, S_t)$ policy and a penalty cost scheme. The proposed method relaxes the original mixed-integer linear programming (MILP) model by eliminating non-negative order quantity constraints and formulating it as a shortest-path problem on a weighted directed acyclic graph. A repetitive augmentation procedure is proposed to resolve any infeasibility in the solution. This procedure consists of three stages: (1) filtration, (2) repeated augmentation by redirecting, reconnecting, and duplicating between newly introduced and existing nodes to adjust the graph and eliminate negative replenishment orders, and (3) re-optimising. The effectiveness and computational efficiency of the proposed approach are assessed through extensive experiments on 1,620 test instances across various demand patterns and parameter settings. The results show that 195 instances required augmentation, mainly those with high penalty costs, low fixed ordering costs, large demand variability, and extended planning horizons. The efficiency of the algorithm for instances with extended planning horizon scenarios demonstrates its suitability for use in real-world scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.23480v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiyuan Ma, Roberto Rossi, Thomas Archibald</dc:creator>
    </item>
    <item>
      <title>On Cost-Sensitive Distributionally Robust Log-Optimal Portfolio</title>
      <link>https://arxiv.org/abs/2410.23536</link>
      <description>arXiv:2410.23536v1 Announce Type: new 
Abstract: This paper addresses a novel \emph{cost-sensitive} distributionally robust log-optimal portfolio problem, where the investor faces \emph{ambiguous} return distributions, and a general convex transaction cost model is incorporated. The uncertainty in the return distribution is quantified using the \emph{Wasserstein} metric, which captures distributional ambiguity. We establish conditions that ensure robustly survivable trades for all distributions in the Wasserstein ball under convex transaction costs. By leveraging duality theory, we approximate the infinite-dimensional distributionally robust optimization problem with a finite convex program, enabling computational tractability for mid-sized portfolios. Empirical studies using S\&amp;P 500 data validate our theoretical framework: without transaction costs, the optimal portfolio converges to an equal-weighted allocation, while with transaction costs, the portfolio shifts slightly towards the risk-free asset, reflecting the trade-off between cost considerations and optimal allocation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.23536v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>q-fin.CP</category>
      <category>q-fin.PM</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chung-Han Hsieh, Xiao-Rou Yu</dc:creator>
    </item>
    <item>
      <title>Coach Reservation for Groups Requests</title>
      <link>https://arxiv.org/abs/2410.23542</link>
      <description>arXiv:2410.23542v1 Announce Type: new 
Abstract: Passenger transportation is a core aspect of a railway company's business, with ticket sales playing a central role in generating revenue. Profitable operations in this context rely heavily on the effectiveness of reject-or-assign policies for coach reservations. As in traditional revenue management, uncertainty in demand presents a significant challenge, particularly when seat availability is limited and passengers have varying itineraries. We extend traditional models from the literature by addressing both offline and online versions of the coach reservation problem for group requests, where two or more passengers must be seated in the same coach. For the offline case, in which all requests are known in advance, we propose an exact mathematical programming formulation that incorporates a first-come, first-served fairness condition, ensuring compliance with transportation regulations. We also propose algorithms for online models of the problem, in which requests are only revealed upon arrival, and the reject-or-assign decisions must be made in real-time. Our analysis for one of these models overcomes known barriers in the packing literature, yielding strong competitive ratio guarantees when group sizes are relatively small compared to coach capacity - a common scenario in practice. Using data from Shinkansen Tokyo-Shin-Osaka line, our numerical experiments demonstrate the practical effectiveness of the proposed policies. Our work provides compelling evidence supporting the adoption of fairness constraints, as revenue losses are minimal, and simple algorithms are sufficient for real-time decision-making. Moreover, our findings provide a strong support for the adoption of fairness in the railway industry and highlight the financial viability of a regulatory framework that allows railway companies to delay coach assignments if they adhere to stricter rules regarding request rejections.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.23542v1</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Carlos H. Cardonha, Arvind U. Raghunathan</dc:creator>
    </item>
    <item>
      <title>Online Convex Optimization with Memory and Limited Predictions</title>
      <link>https://arxiv.org/abs/2410.23574</link>
      <description>arXiv:2410.23574v1 Announce Type: new 
Abstract: We study the problem of online convex optimization with memory and predictions over a horizon $T$. At each time step, a decision maker is given some limited predictions of the cost functions from a finite window of future time steps, i.e., values of the cost function at certain decision points in the future. The decision maker then chooses an action and incurs a cost given by a convex function that depends on the actions chosen in the past. We propose an algorithm to solve this problem and show that the dynamic regret of the algorithm decays exponentially with the prediction window length. Our algorithm contains two general subroutines that work for wider classes of problems. The first subroutine can solve general online convex optimization with memory and bandit feedback with $\sqrt{T}$-dynamic regret with respect to $T$. The second subroutine is a zeroth-order method that can be used to solve general convex optimization problems with a linear convergence rate that matches the best achievable rate of first-order methods for convex optimization. The key to our algorithm design and analysis is the use of truncated Gaussian smoothing when querying the decision points for obtaining the predictions. We complement our theoretical results using numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.23574v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lintao Ye, Zhengmiao Wang, Zhi-Wei Liu, Ming Chi, Xiaoling Wang, Housheng Su</dc:creator>
    </item>
    <item>
      <title>Edges' Riemannian energy analysis for synchronization of multi-agent nonlinear systems over undirected weighted graphs</title>
      <link>https://arxiv.org/abs/2410.23700</link>
      <description>arXiv:2410.23700v1 Announce Type: new 
Abstract: In this note we investigate the problem of global exponential synchronization of multi-agent systems described by nonlinear input affine dynamics. We consider the case of networks described by undirected connected graphs possibly without leader. We present a set of sufficient conditions based on a Riemannian metric approach in order to design a state-feedback distributed control law. Then, we study the convergence properties of the overall network. By exploiting the properties of the edge Laplacian we construct a Lyapunov function that allows to conclude global exponential synchronization of the overall network.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.23700v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.automatica.2024.111950</arxiv:DOI>
      <dc:creator>Vincent Andrieu (CNRS, LAGEPP), Daniele Astolfi (CNRS, LAGEPP), Alexandre Cellier-Devaux (LAGEPP)</dc:creator>
    </item>
    <item>
      <title>Exploring chordal sparsity in semidefinite programming with sparse plus low-rank data matrices</title>
      <link>https://arxiv.org/abs/2410.23849</link>
      <description>arXiv:2410.23849v1 Announce Type: new 
Abstract: Semidefinite programming (SDP) problems are challenging to solve because of their high dimensionality. However, solving sparse SDP problems with small tree-width are known to be relatively easier because: (1) they can be decomposed into smaller multi-block SDP problems through chordal conversion; (2) they have low-rank optimal solutions. In this paper, we study more general SDP problems whose coefficient matrices have sparse plus low-rank (SPLR) structure. We develop a unified framework to convert such problems into sparse SDP problems with bounded tree-width. Based on this, we derive rank bounds for SDP problems with SPLR structure, which are tight in the worst case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.23849v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tianyun Tang, Kim-Chuan Toh</dc:creator>
    </item>
    <item>
      <title>On semismooth$^*$ path-following method and uniformity of strong metric subregularity at/around the reference point</title>
      <link>https://arxiv.org/abs/2410.23871</link>
      <description>arXiv:2410.23871v1 Announce Type: new 
Abstract: This paper investigates a path-following method inspired by the semismooth$^*$ approach for solving algebraic inclusions, with a primary emphasis on the role of uniform subregularity. Uniform subregularity is crucial for ensuring the robustness and stability of path-following methods, as it provides a framework to uniformly control the distance between the input and the solution set across a continuous path. We explore the problem of finding a mapping $ x: \mathbb{R} \longrightarrow \mathbb{R}^n $ that satisfies $ 0 \in F(t, x(t)) $ for each $ t \in [0, T] $, where $ F $ is a set-valued mapping from $ \mathbb{R} \times \mathbb{R}^n $ to $ \mathbb{R}^n $. The paper discusses two approaches: the first considers mappings with uniform semismooth$^*$ properties along continuous paths, leading to a consistent grid error throughout the interval, while the second examines mappings exhibiting pointwise semismooth$^*$ properties at individual points along the path. The uniform strong subregularity framework is integrated into these approaches to strengthen the stability of solution trajectories and improve algorithmic convergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.23871v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tom\'a\v{s} Roubal, Jan Valdman</dc:creator>
    </item>
    <item>
      <title>Optimization over convex polyhedra via Hadamard parametrizations</title>
      <link>https://arxiv.org/abs/2410.23874</link>
      <description>arXiv:2410.23874v1 Announce Type: new 
Abstract: In this paper, we study linearly constrained optimization problems (LCP). After applying Hadamard parametrization, the feasible set of the parametrized problem (LCPH) becomes an algebraic variety, with conducive geometric properties which we explore in depth. We derive explicit formulas for the tangent cones and second-order tangent sets associated with the parametrized polyhedra. Based on these formulas, we develop a procedure to recover the Lagrangian multipliers associated with the constraints to verify the optimality conditions of the given primal variable without requiring additional constraint qualifications. Moreover, we develop a systematic way to stratify the variety into a disjoint union of finitely many Riemannian manifolds. This leads us to develop a hybrid algorithm combining Riemannian optimization and projected gradient to solve (LCP) with convergence guarantees. Numerical experiments are conducted to verify the effectiveness of our method compared with various state-of-the-art algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.23874v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tianyun Tang, Kim-Chuan Toh</dc:creator>
    </item>
    <item>
      <title>A dynamic programming principle for multiperiod control problems with bicausal constraints</title>
      <link>https://arxiv.org/abs/2410.23927</link>
      <description>arXiv:2410.23927v1 Announce Type: new 
Abstract: We consider multiperiod stochastic control problems with non-parametric uncertainty on the underlying probabilistic model. We derive a new metric on the space of probability measures, called the adapted $(p, \infty)$--Wasserstein distance $\mathcal{AW}_p^\infty$ with the following properties: (1) the adapted $(p, \infty)$--Wasserstein distance generates a topology that guarantees continuity of stochastic control problems and (2) the corresponding $\mathcal{AW}_p^\infty$-distributionally robust optimization (DRO) problem can be computed via a dynamic programming principle involving one-step Wasserstein-DRO problems. If the cost function is semi-separable, then we further show that a minimax theorem holds, even though balls with respect to $\mathcal{AW}_p^\infty$ are neither convex nor compact in general. We also derive first-order sensitivity results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.23927v1</guid>
      <category>math.OC</category>
      <category>q-fin.MF</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruslan Mirmominov, Johannes Wiesel</dc:creator>
    </item>
    <item>
      <title>Sparse Approximation in Lattices and Semigroups</title>
      <link>https://arxiv.org/abs/2410.23990</link>
      <description>arXiv:2410.23990v1 Announce Type: new 
Abstract: Given an integer or a non-negative integer solution $x$ to a system $Ax = b$, where the number of non-zero components of $x$ is at most $n$. This paper addresses the following question: How closely can we approximate $b$ with $Ay$, where $y$ is an integer or non-negative integer solution constrained to have at most $k$ non-zero components with $k&lt;n$? We establish upper and lower bounds for this question in general. In specific cases, these bounds match. The key finding is that the quality of the approximation increases exponentially as $k$ goes to $n$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.23990v1</guid>
      <category>math.OC</category>
      <category>cs.DM</category>
      <category>math.CO</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Stefan Kuhlmann, Timm Oertel, Robert Weismantel</dc:creator>
    </item>
    <item>
      <title>Optimal control problems driven by nonlinear degenerate Fokker-Planck equations</title>
      <link>https://arxiv.org/abs/2410.24000</link>
      <description>arXiv:2410.24000v1 Announce Type: new 
Abstract: The well-posedness of a class of optimal control problems is analysed, where the state equation couples a nonlinear degenerate Fokker-Planck equation with a system of Ordinary Differential Equations (ODEs). Such problems naturally arise as mean-field limits of Stochastic Differential models for multipopulation dynamics, where a large number of agents (followers) is steered through parsimonious intervention on a selected class of leaders. The proposed approach combines stability estimates for measure solutions of nonlinear degenerate Fokker-Planck equations with a general framework of assumptions on the cost functional, ensuring compactness and lower semicontinuity properties. The Lie structure of the state equations allows one for considering non-Lipschitz nonlinearities, provided some suitable dissipativity assumptions are considered in addition to non-Euclidean H\"{o}lder and sublinearity conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.24000v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <category>math.PR</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Francesca Anceschi, Giacomo Ascione, Daniele Castorina, Francesco Solombrino</dc:creator>
    </item>
    <item>
      <title>Attention is All You Need to Optimize Wind Farm Operations and Maintenance</title>
      <link>https://arxiv.org/abs/2410.24052</link>
      <description>arXiv:2410.24052v1 Announce Type: new 
Abstract: Operations and maintenance (O&amp;M) is a fundamental problem in wind energy systems with far reaching implications for reliability and profitability. Optimizing O&amp;M is a multi-faceted decision optimization problem that requires a careful balancing act across turbine level failure risks, operational revenues, and maintenance crew logistics. The resulting O&amp;M problems are typically solved using large-scale mixed integer programming (MIP) models, which yield computationally challenging problems that require either long-solution times, or heuristics to reach a solution. To address this problem, we introduce a novel decision-making framework for wind farm O&amp;M that builds on a multi-head attention (MHA) models, an emerging artificial intelligence methods that are specifically designed to learn in rich and complex problem settings. The development of proposed MHA framework incorporates a number of modeling innovations that allows explicit embedding of MIP models within an MHA structure. The proposed MHA model (i) significantly reduces the solution time from hours to seconds, (ii) guarantees feasibility of the proposed solutions considering complex constraints that are omnipresent in wind farm O&amp;M, (iii) results in significant solution quality compared to the conventional MIP formulations, and (iv) exhibits significant transfer learning capability across different problem settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.24052v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Iman Kazemian, Murat Yildirim, Paritosh Ramanan</dc:creator>
    </item>
    <item>
      <title>Lagrangian Reformulation for Nonconvex Optimization: Tailoring Problems to Specialized Solvers</title>
      <link>https://arxiv.org/abs/2410.24111</link>
      <description>arXiv:2410.24111v1 Announce Type: new 
Abstract: In recent years, there has been a surge of interest in studying different ways to reformulate nonconvex optimization problems, especially those that involve binary variables. This interest surge is due to advancements in computing technologies, such as quantum and Ising devices, as well as improvements in quantum and classical optimization solvers that take advantage of particular formulations of nonconvex problems to tackle their solutions. Our research characterizes the equivalence between equality-constrained nonconvex optimization problems and their Lagrangian relaxation, enabling the aforementioned new technologies to solve these problems. In addition to filling a crucial gap in the literature, our results are readily applicable to many important situations in practice. To obtain these results, we bridge between specific optimization problem characteristics and broader, classical results on Lagrangian duality for general nonconvex problems. Further, our approach takes a comprehensive approach to the question of equivalence between problem formulations. We consider this question not only from the perspective of the problem's objective but also from the viewpoint of its solution. This perspective, often overlooked in existing literature, is particularly relevant for problems featuring continuous and binary variables.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.24111v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rodolfo A. Quintero, Juan C. Vera, Luis F. Zuluaga</dc:creator>
    </item>
    <item>
      <title>Convex optimization with $p$-norm oracles</title>
      <link>https://arxiv.org/abs/2410.24158</link>
      <description>arXiv:2410.24158v1 Announce Type: new 
Abstract: In recent years, there have been significant advances in efficiently solving $\ell_s$-regression using linear system solvers and $\ell_2$-regression [Adil-Kyng-Peng-Sachdeva, J. ACM'24]. Would efficient $\ell_p$-norm solvers lead to even faster rates for solving $\ell_s$-regression when $2 \leq p &lt; s$? In this paper, we give an affirmative answer to this question and show how to solve $\ell_s$-regression using $\tilde{O}(n^{\frac{\nu}{1+\nu}})$ iterations of solving smoothed $\ell_s$ regression problems, where $\nu := \frac{1}{p} - \frac{1}{s}$. To obtain this result, we provide improved accelerated rates for convex optimization problems when given access to an $\ell_p^s(\lambda)$-proximal oracle, which, for a point $c$, returns the solution of the regularized problem $\min_{x} f(x) + \lambda \|x-c\|_p^s$. Additionally, we show that the rates we establish for the $\ell_p^s(\lambda)$-proximal oracle are near-optimal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.24158v1</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Deeksha Adil, Brian Bullins, Arun Jambulapati, Aaron Sidford</dc:creator>
    </item>
    <item>
      <title>Derivative-Free Data-Driven Control of Continuous-Time Linear Time-Invariant Systems</title>
      <link>https://arxiv.org/abs/2410.24167</link>
      <description>arXiv:2410.24167v1 Announce Type: new 
Abstract: This paper develops a data-driven stabilization method for continuous-time linear time-invariant systems with theoretical guarantees and no need for signal derivatives. The framework, based on linear matrix inequalities (LMIs), is illustrated in the state-feedback and single-input single-output output-feedback scenarios. Similar to discrete-time approaches, we rely solely on input and state/output measurements. To avoid differentiation, we employ low-pass filters of the available signals that, rather than approximating the derivatives, reconstruct a non-minimal realization of the plant. With access to the filter states and their derivatives, we can solve LMIs derived from sample batches of the available signals to compute a dynamic controller that stabilizes the plant. The effectiveness of the framework is showcased through numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.24167v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alessandro Bosso, Marco Borghesi, Andrea Iannelli, Giuseppe Notarstefano, Andrew R. Teel</dc:creator>
    </item>
    <item>
      <title>A Framework for the Solution of Tree-Coupled Saddle-Point Systems</title>
      <link>https://arxiv.org/abs/2410.23385</link>
      <description>arXiv:2410.23385v1 Announce Type: cross 
Abstract: We consider the solution of saddle-point systems with a tree-based block structure, introducing a parallelizable direct method for their solution. As our key contribution, we then propose several structure-exploiting preconditioners to be used during applications of the MINRES and GMRES algorithms and analyze their properties. We adapt several concepts originating in the field of multigrid methods, obtaining a variety of problem-adapted multi-level methods. We analyze the complexity of all algorithms, and derive a number of results on eigenvalues of the preconditioned system and convergence of iterative methods. We validate our theoretical findings through a range of numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.23385v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christoph Hansknecht, Bernhard Heinzelreiter, John W. Pearson, Andreas Potschka</dc:creator>
    </item>
    <item>
      <title>Multi-fidelity Machine Learning for Uncertainty Quantification and Optimization</title>
      <link>https://arxiv.org/abs/2410.23482</link>
      <description>arXiv:2410.23482v1 Announce Type: cross 
Abstract: In system analysis and design optimization, multiple computational models are typically available to represent a given physical system. These models can be broadly classified as high-fidelity models, which provide highly accurate predictions but require significant computational resources, and low-fidelity models, which are computationally efficient but less accurate. Multi-fidelity methods integrate high- and low-fidelity models to balance computational cost and predictive accuracy. This perspective paper provides an in-depth overview of the emerging field of machine learning-based multi-fidelity methods, with a particular emphasis on uncertainty quantification and optimization. For uncertainty quantification, a particular focus is on multi-fidelity graph neural networks, compared with multi-fidelity polynomial chaos expansion. For optimization, our emphasis is on multi-fidelity Bayesian optimization, offering a unified perspective on multi-fidelity priors and proposing an application strategy when the objective function is an integral or a weighted sum. We highlight the current state of the art, identify critical gaps in the literature, and outline key research opportunities in this evolving field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.23482v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1615/JMachLearnModelComput.2024055786</arxiv:DOI>
      <arxiv:journal_reference>Journal of Machine Learning for Modeling and Computing, Vol. 5, No. 4, pp. 77--94, (2024)</arxiv:journal_reference>
      <dc:creator>Ruda Zhang, Negin Alemazkoor</dc:creator>
    </item>
    <item>
      <title>Sample-Efficient Agnostic Boosting</title>
      <link>https://arxiv.org/abs/2410.23632</link>
      <description>arXiv:2410.23632v1 Announce Type: cross 
Abstract: The theory of boosting provides a computational framework for aggregating approximate weak learning algorithms, which perform marginally better than a random predictor, into an accurate strong learner. In the realizable case, the success of the boosting approach is underscored by a remarkable fact that the resultant sample complexity matches that of a computationally demanding alternative, namely Empirical Risk Minimization (ERM). This in particular implies that the realizable boosting methodology has the potential to offer computational relief without compromising on sample efficiency.
  Despite recent progress, in agnostic boosting, where assumptions on the conditional distribution of labels given feature descriptions are absent, ERM outstrips the agnostic boosting methodology in being quadratically more sample efficient than all known agnostic boosting algorithms. In this paper, we make progress on closing this gap, and give a substantially more sample efficient agnostic boosting algorithm than those known, without compromising on the computational (or oracle) complexity. A key feature of our algorithm is that it leverages the ability to reuse samples across multiple rounds of boosting, while guaranteeing a generalization error strictly better than those obtained by blackbox applications of uniform convergence arguments. We also apply our approach to other previously studied learning problems, including boosting for reinforcement learning, and demonstrate improved results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.23632v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Udaya Ghai, Karan Singh</dc:creator>
    </item>
    <item>
      <title>$\psi$DAG: Projected Stochastic Approximation Iteration for DAG Structure Learning</title>
      <link>https://arxiv.org/abs/2410.23862</link>
      <description>arXiv:2410.23862v1 Announce Type: cross 
Abstract: Learning the structure of Directed Acyclic Graphs (DAGs) presents a significant challenge due to the vast combinatorial search space of possible graphs, which scales exponentially with the number of nodes. Recent advancements have redefined this problem as a continuous optimization task by incorporating differentiable acyclicity constraints. These methods commonly rely on algebraic characterizations of DAGs, such as matrix exponentials, to enable the use of gradient-based optimization techniques. Despite these innovations, existing methods often face optimization difficulties due to the highly non-convex nature of DAG constraints and the per-iteration computational complexity. In this work, we present a novel framework for learning DAGs, employing a Stochastic Approximation approach integrated with Stochastic Gradient Descent (SGD)-based optimization techniques. Our framework introduces new projection methods tailored to efficiently enforce DAG constraints, ensuring that the algorithm converges to a feasible local minimum. With its low iteration complexity, the proposed method is well-suited for handling large-scale problems with improved computational efficiency. We demonstrate the effectiveness and scalability of our framework through comprehensive experimental evaluations, which confirm its superior performance across various settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.23862v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Klea Ziu, Slavom\'ir Hanzely, Loka Li, Kun Zhang, Martin Tak\'a\v{c}, Dmitry Kamzolov</dc:creator>
    </item>
    <item>
      <title>New Combinatorial Insights for Monotone Apportionment</title>
      <link>https://arxiv.org/abs/2410.23869</link>
      <description>arXiv:2410.23869v1 Announce Type: cross 
Abstract: The apportionment problem constitutes a fundamental problem in democratic societies: How to distribute a fixed number of seats among a set of states in proportion to the states' populations? This--seemingly simple--task has led to a rich literature and has become well known in the context of the US House of Representatives. In this paper, we connect the design of monotone apportionment methods to classic problems from discrete geometry and combinatorial optimization and explore the extent to which randomization can enhance proportionality.
  We first focus on the well-studied family of stationary divisor methods, which satisfy the strong population monotonicity property, and show that this family produces only a slightly superlinear number of different outputs as a function of the number of states. While our upper and lower bounds leave a small gap, we show that--surprisingly--closing this gap would solve a long-standing open problem from discrete geometry, known as the complexity of $k$-levels in line arrangements. The main downside of divisor methods is their violation of the quota axiom, i.e., every state should receive $\lfloor q_i\rfloor$ or $\lceil q_i\rceil$ seats, where $q_i$ is the proportional share of the state. As we show that randomizing over divisor methods can only partially overcome this issue, we propose a relaxed version of divisor methods in which the total number of seats may slightly deviate from the house size. By randomizing over them, we can simultaneously satisfy population monotonicity, quota, and ex-ante proportionality.
  Finally, we turn our attention to quota-compliant methods that are house-monotone, i.e., no state may lose a seat when the house size is increased. We provide a polyhedral characterization based on network flows, which implies a simple description of all ex-ante proportional randomized methods that are house-monotone and quota-compliant.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.23869v1</guid>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <category>math.OC</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Javier Cembrano, Jos\'e Correa, Ulrike Schmidt-Kraepelin, Alexandros Tsigonias-Dimitriadis, Victor Verdugo</dc:creator>
    </item>
    <item>
      <title>Transformer-based Model Predictive Control: Trajectory Optimization via Sequence Modeling</title>
      <link>https://arxiv.org/abs/2410.23916</link>
      <description>arXiv:2410.23916v1 Announce Type: cross 
Abstract: Model predictive control (MPC) has established itself as the primary methodology for constrained control, enabling general-purpose robot autonomy in diverse real-world scenarios. However, for most problems of interest, MPC relies on the recursive solution of highly non-convex trajectory optimization problems, leading to high computational complexity and strong dependency on initialization. In this work, we present a unified framework to combine the main strengths of optimization-based and learning-based methods for MPC. Our approach entails embedding high-capacity, transformer-based neural network models within the optimization process for trajectory generation, whereby the transformer provides a near-optimal initial guess, or target plan, to a non-convex optimization problem. Our experiments, performed in simulation and the real world onboard a free flyer platform, demonstrate the capabilities of our framework to improve MPC convergence and runtime. Compared to purely optimization-based approaches, results show that our approach can improve trajectory generation performance by up to 75%, reduce the number of solver iterations by up to 45%, and improve overall MPC runtime by 7x without loss in performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.23916v1</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/LRA.2024.3466069</arxiv:DOI>
      <arxiv:journal_reference>IEEE Robotics and Automation Letters, vol. 9, n. 11, pp. 9820-9827, Nov. 2024</arxiv:journal_reference>
      <dc:creator>Davide Celestini, Daniele Gammelli, Tommaso Guffanti, Simone D'Amico, Elisa Capello, Marco Pavone</dc:creator>
    </item>
    <item>
      <title>Scalable Kernel Inverse Optimization</title>
      <link>https://arxiv.org/abs/2410.23952</link>
      <description>arXiv:2410.23952v1 Announce Type: cross 
Abstract: Inverse Optimization (IO) is a framework for learning the unknown objective function of an expert decision-maker from a past dataset. In this paper, we extend the hypothesis class of IO objective functions to a reproducing kernel Hilbert space (RKHS), thereby enhancing feature representation to an infinite-dimensional space. We demonstrate that a variant of the representer theorem holds for a specific training loss, allowing the reformulation of the problem as a finite-dimensional convex optimization program. To address scalability issues commonly associated with kernel methods, we propose the Sequential Selection Optimization (SSO) algorithm to efficiently train the proposed Kernel Inverse Optimization (KIO) model. Finally, we validate the generalization capabilities of the proposed KIO model and the effectiveness of the SSO algorithm through learning-from-demonstration tasks on the MuJoCo benchmark.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.23952v1</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Youyuan Long, Tolga Ok, Pedro Zattoni Scroccaro, Peyman Mohajerin Esfahani</dc:creator>
    </item>
    <item>
      <title>Distributing Intelligence in 6G Programmable Data Planes for Effective In-Network Deployment of an Active Intrusion Detection System</title>
      <link>https://arxiv.org/abs/2410.24013</link>
      <description>arXiv:2410.24013v1 Announce Type: cross 
Abstract: The problem of attacks on new generation network infrastructures is becoming increasingly relevant, given the widening of the attack surface of these networks resulting from the greater number of devices that will access them in the future (sensors, actuators, vehicles, household appliances, etc.). Approaches to the design of intrusion detection systems must evolve and go beyond the traditional concept of perimeter control to build on new paradigms that exploit the typical characteristics of future 5G and 6G networks, such as in-network computing and intelligent programmable data planes. The aim of this research is to propose a disruptive paradigm in which devices in a typical data plane of a future programmable network have %classification and anomaly detection capabilities and cooperate in a fully distributed fashion to act as an ML-enabled Active Intrusion Detection System "embedded" into the network. The reported proof-of-concept experiments demonstrate that the proposed paradigm allows working effectively and with a good level of precision while occupying overall less CPU and RAM resources of the devices involved.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.24013v1</guid>
      <category>cs.NI</category>
      <category>cs.CR</category>
      <category>math.OC</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mattia G. Spina, Floriano De Rango, Edoardo Scalzo, Francesca Guerriero, Antonio Iera</dc:creator>
    </item>
    <item>
      <title>Natural gradient and parameter estimation for quantum Boltzmann machines</title>
      <link>https://arxiv.org/abs/2410.24058</link>
      <description>arXiv:2410.24058v1 Announce Type: cross 
Abstract: Thermal states play a fundamental role in various areas of physics, and they are becoming increasingly important in quantum information science, with applications related to semi-definite programming, quantum Boltzmann machine learning, Hamiltonian learning, and the related task of estimating the parameters of a Hamiltonian. Here we establish formulas underlying the basic geometry of parameterized thermal states, and we delineate quantum algorithms for estimating the values of these formulas. More specifically, we prove formulas for the Fisher--Bures and Kubo--Mori information matrices of parameterized thermal states, and our quantum algorithms for estimating their matrix elements involve a combination of classical sampling, Hamiltonian simulation, and the Hadamard test. These results have applications in developing a natural gradient descent algorithm for quantum Boltzmann machine learning, which takes into account the geometry of thermal states, and in establishing fundamental limitations on the ability to estimate the parameters of a Hamiltonian, when given access to thermal-state samples. For the latter task, and for the special case of estimating a single parameter, we sketch an algorithm that realizes a measurement that is asymptotically optimal for the estimation task. We finally stress that the natural gradient descent algorithm developed here can be used for any machine learning problem that employs the quantum Boltzmann machine ansatz.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.24058v1</guid>
      <category>quant-ph</category>
      <category>cond-mat.stat-mech</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dhrumil Patel, Mark M. Wilde</dc:creator>
    </item>
    <item>
      <title>An Efficient Dynamic Resource Allocation Framework for Evolutionary Bilevel Optimization</title>
      <link>https://arxiv.org/abs/2410.24081</link>
      <description>arXiv:2410.24081v1 Announce Type: cross 
Abstract: Bilevel optimization problems are characterized by an interactive hierarchical structure, where the upper level seeks to optimize its strategy while simultaneously considering the response of the lower level. Evolutionary algorithms are commonly used to solve complex bilevel problems in practical scenarios, but they face significant resource consumption challenges due to the nested structure imposed by the implicit lower-level optimality condition. This challenge becomes even more pronounced as problem dimensions increase. Although recent methods have enhanced bilevel convergence through task-level knowledge sharing, further efficiency improvements are still hindered by redundant lower-level iterations that consume excessive resources while generating unpromising solutions. To overcome this challenge, this paper proposes an efficient dynamic resource allocation framework for evolutionary bilevel optimization, named DRC-BLEA. Compared to existing approaches, DRC-BLEA introduces a novel competitive quasi-parallel paradigm, in which multiple lower-level optimization tasks, derived from different upper-level individuals, compete for resources. A continuously updated selection probability is used to prioritize execution opportunities to promising tasks. Additionally, a cooperation mechanism is integrated within the competitive framework to further enhance efficiency and prevent premature convergence. Experimental results compared with chosen state-of-the-art algorithms demonstrate the effectiveness of the proposed method. Specifically, DRC-BLEA achieves competitive accuracy across diverse problem sets and real-world scenarios, while significantly reducing the number of function evaluations and overall running time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.24081v1</guid>
      <category>cs.NE</category>
      <category>math.OC</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Dejun Xu, Kai Ye, Zimo Zheng, Tao Zhou, Gary G. Yen, Min Jiang</dc:creator>
    </item>
    <item>
      <title>Satellite Safe Margin: Fast solutions for Conjunction Analysis</title>
      <link>https://arxiv.org/abs/2410.24092</link>
      <description>arXiv:2410.24092v1 Announce Type: cross 
Abstract: The amount of debris in orbit has increased significantly over the years. With the recent growth of interest in space exploration, conjunction assessment has become a central issue. One important metric to evaluate conjunction risk is the miss distance. However, this metric does not intrinsically take into account uncertainty distributions. Some work has been developed to consider the uncertainty associated with the position of the orbiting objects, in particular, to know if these uncertainty distributions overlap (e.g., ellipsoids when considering Gaussian distributions). With this work, we present fast solutions to not only check if the ellipsoids overlap but to compute the distance between them, which we call margin. We present two fast solution methods for two different paradigms: when the best-known data from both objects can be centralized (e.g., debris-satellite conjunctions) and when the most precise covariances cannot be shared (conjunctions of satellites owned by different operators). Our methods are both accurate and fast, being able to process 15,000 conjunctions per minute with the centralized solution and approximately 490 conjunctions per minute with the distributed solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.24092v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ricardo N. Ferreira, Marta Guimar\~aes, Cl\'audia Soares</dc:creator>
    </item>
    <item>
      <title>Data-Driven Learning of Two-Stage Beamformers in Passive IRS-Assisted Systems with Inexact Oracles</title>
      <link>https://arxiv.org/abs/2410.24154</link>
      <description>arXiv:2410.24154v1 Announce Type: cross 
Abstract: We develop an efficient data-driven and model-free unsupervised learning algorithm for achieving fully passive intelligent reflective surface (IRS)-assisted optimal short/long-term beamforming in wireless communication networks. The proposed algorithm is based on a zeroth-order stochastic gradient ascent methodology, suitable for tackling two-stage stochastic nonconvex optimization problems with continuous uncertainty and unknown (or "black-box") terms present in the objective function, via the utilization of inexact evaluation oracles. We showcase that the algorithm can operate under realistic and general assumptions, and establish its convergence rate close to some stationary point of the associated two-stage (i.e., short/long-term) problem, particularly in cases where the second-stage (i.e., short-term) beamforming problem (e.g., transmit precoding) is solved inexactly using an arbitrary (inexact) oracle. The proposed algorithm is applicable on a wide variety of IRS-assisted optimal beamforming settings, while also being able to operate without (cascaded) channel model assumptions or knowledge of channel statistics, and over arbitrary IRS physical configurations; thus, no active sensing capability at the IRS(s) is needed. Our algorithm is numerically demonstrated to be very effective in a range of experiments pertaining to a well-studied MISO downlink model, including scenarios demanding physical IRS tuning (e.g., directly through varactor capacitances), even in large-scale regimes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.24154v1</guid>
      <category>eess.SP</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Spyridon Pougkakiotis, Hassaan Hashmi, Dionysis Kalogerias</dc:creator>
    </item>
    <item>
      <title>Understanding Optimization in Deep Learning with Central Flows</title>
      <link>https://arxiv.org/abs/2410.24206</link>
      <description>arXiv:2410.24206v1 Announce Type: cross 
Abstract: Optimization in deep learning remains poorly understood, even in the simple setting of deterministic (i.e. full-batch) training. A key difficulty is that much of an optimizer's behavior is implicitly determined by complex oscillatory dynamics, referred to as the "edge of stability." The main contribution of this paper is to show that an optimizer's implicit behavior can be explicitly captured by a "central flow:" a differential equation which models the time-averaged optimization trajectory. We show that these flows can empirically predict long-term optimization trajectories of generic neural networks with a high degree of numerical accuracy. By interpreting these flows, we reveal for the first time 1) the precise sense in which RMSProp adapts to the local loss landscape, and 2) an "acceleration via regularization" mechanism, wherein adaptive optimizers implicitly navigate towards low-curvature regions in which they can take larger steps. This mechanism is key to the efficacy of these adaptive optimizers. Overall, we believe that central flows constitute a promising tool for reasoning about optimization in deep learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.24206v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jeremy M. Cohen, Alex Damian, Ameet Talwalkar, Zico Kolter, Jason D. Lee</dc:creator>
    </item>
    <item>
      <title>Robust Gaussian Processes via Relevance Pursuit</title>
      <link>https://arxiv.org/abs/2410.24222</link>
      <description>arXiv:2410.24222v1 Announce Type: cross 
Abstract: Gaussian processes (GPs) are non-parametric probabilistic regression models that are popular due to their flexibility, data efficiency, and well-calibrated uncertainty estimates. However, standard GP models assume homoskedastic Gaussian noise, while many real-world applications are subject to non-Gaussian corruptions. Variants of GPs that are more robust to alternative noise models have been proposed, and entail significant trade-offs between accuracy and robustness, and between computational requirements and theoretical guarantees. In this work, we propose and study a GP model that achieves robustness against sparse outliers by inferring data-point-specific noise levels with a sequential selection procedure maximizing the log marginal likelihood that we refer to as relevance pursuit. We show, surprisingly, that the model can be parameterized such that the associated log marginal likelihood is strongly concave in the data-point-specific noise variances, a property rarely found in either robust regression objectives or GP marginal likelihoods. This in turn implies the weak submodularity of the corresponding subset selection problem, and thereby proves approximation guarantees for the proposed algorithm. We compare the model's performance relative to other approaches on diverse regression and Bayesian optimization tasks, including the challenging but common setting of sparse corruptions of the labels within or close to the function range.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.24222v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Sebastian Ament, Elizabeth Santorella, David Eriksson, Ben Letham, Maximilian Balandat, Eytan Bakshy</dc:creator>
    </item>
    <item>
      <title>Non-Euclidean Monotone Operator Theory and Applications</title>
      <link>https://arxiv.org/abs/2303.11273</link>
      <description>arXiv:2303.11273v2 Announce Type: replace 
Abstract: While monotone operator theory is often studied on Hilbert spaces, many interesting problems in machine learning and optimization arise naturally in finite-dimensional vector spaces endowed with non-Euclidean norms, such as diagonally-weighted $\ell_{1}$ or $\ell_{\infty}$ norms. This paper provides a natural generalization of monotone operator theory to finite-dimensional non-Euclidean spaces. The key tools are weak pairings and logarithmic norms. We show that the resolvent and reflected resolvent operators of non-Euclidean monotone mappings exhibit similar properties to their counterparts in Hilbert spaces. Furthermore, classical iterative methods and splitting methods for finding zeros of monotone operators are shown to converge in the non-Euclidean case. We apply our theory to equilibrium computation and Lipschitz constant estimation of recurrent neural networks, obtaining novel iterations and tighter upper bounds via forward-backward splitting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.11273v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexander Davydov, Saber Jafarpour, Anton V. Proskurnikov, Francesco Bullo</dc:creator>
    </item>
    <item>
      <title>Revisiting Subgradient Method: Complexity and Convergence Beyond Lipschitz Continuity</title>
      <link>https://arxiv.org/abs/2305.14161</link>
      <description>arXiv:2305.14161v2 Announce Type: replace 
Abstract: The subgradient method is one of the most fundamental algorithmic schemes for nonsmooth optimization. The existing complexity and convergence results for this method are mainly derived for Lipschitz continuous objective functions. In this work, we first extend the typical iteration complexity results for the subgradient method to cover non-Lipschitz convex and weakly convex minimization. Specifically, for the convex case, we can drive the suboptimality gap to below $\varepsilon$ in $\mathcal{O}( \varepsilon^{-2} )$ iterations; for the weakly convex case, we can drive the gradient norm of the Moreau envelope of the objective function to below $\varepsilon$ in $\mathcal{O}( \varepsilon^{-4} )$ iterations. Then, we provide convergence results for the subgradient method in the non-Lipschitz setting when proper diminishing rules on the step size are used. In particular, when $f$ is convex, we establish an $\mathcal{O}(\log(k)/\sqrt{k})$ rate of convergence in terms of the suboptimality gap, where $k$ represents the iteration count. With an additional quadratic growth property, the rate is improved to $\mathcal{O}(1/k)$ in terms of the squared distance to the optimal solution set. When $f$ is weakly convex, asymptotic convergence is established. Our results neither require any modification to the subgradient method nor impose any growth condition on the subgradients, while our analysis is surprisingly simple. To further illustrate the wide applicability of our framework, we extend the aforementioned iteration complexity results to cover the truncated subgradient, the stochastic subgradient, and the proximal subgradient methods for non-Lipschitz convex / weakly convex objective functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.14161v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s10013-024-00715-w</arxiv:DOI>
      <dc:creator>Xiao Li, Lei Zhao, Daoli Zhu, Anthony Man-Cho So</dc:creator>
    </item>
    <item>
      <title>Necessary and Sufficient Conditions for Data-driven Model Reference Control</title>
      <link>https://arxiv.org/abs/2310.11159</link>
      <description>arXiv:2310.11159v2 Announce Type: replace 
Abstract: The objective of model reference control is to design a controller that regulates the system's behavior so as to match a specified reference model. This paper investigates necessary and sufficient conditions for model reference control from a data-driven perspective, when only a set of data generated by the system is utilized to directly accomplish the matching. Noiseless and noisy data settings are both considered. Notably, all methods we propose build on the concept of data informativity and do not rely on persistently exciting data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.11159v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TAC.2024.3490669</arxiv:DOI>
      <dc:creator>Jiwei Wang, Simone Baldi, Henk J. van Waarde</dc:creator>
    </item>
    <item>
      <title>Complexity of Adagrad and other first-order methods for nonconvex optimization problems with bounds and convex constraints</title>
      <link>https://arxiv.org/abs/2406.15793</link>
      <description>arXiv:2406.15793v2 Announce Type: replace 
Abstract: A parametric class of trust-region algorithms for constrained nonconvex optimization is analyzed, where the objective function is never computed. By defining appropriate first-order stationarity criteria, we are able to extend the Adagrad method to the newly considered problem and retrieve the standard complexity rate of the projected gradient method that uses both the gradient and objective function values. Furthermore, we propose an additional iteration-dependent scaling with slightly inferior theoretical guarantees. In both cases, the bounds are essentially sharp, and curvature information can be used to compute the stepsize. Initial experimental results for noisy bound-constrained instances illustrate the benefits of the objective-free approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15793v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Serge Gratton, Sadok Jerad, Philippe L. Toint</dc:creator>
    </item>
    <item>
      <title>On disjunction convex hulls by lifting</title>
      <link>https://arxiv.org/abs/2407.15244</link>
      <description>arXiv:2407.15244v2 Announce Type: replace 
Abstract: We study the natural extended-variable formulation for the disjunction of $n+1$ polytopes in $\mathbb{R}^d$. We demonstrate that the convex hull $D$ in the natural extended-variable space $\mathbb{R}^{d+n}$ is given by full optimal big-M lifting (i) when $d\leq 2$ (and that it is not generally true for $d\geq 3$), and also (ii) under some technical conditions, when the polytopes have a common facet-describing constraint matrix, for arbitrary $d\geq 1$ and $n\geq 1$. We give a broad family of examples with $d\geq 3$ and $n=1$, where the convex hull is not described after employing all full optimal big-M lifting inequalities, but it is described after one round of MIR inequalities. Additionally, we give some general results on the polyhedral structure of $D$, and we demonstrate that all facets of $D$ can be enumerated in polynomial time when $d$ is fixed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.15244v2</guid>
      <category>math.OC</category>
      <category>math.CO</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yushan Qu, Jon Lee</dc:creator>
    </item>
    <item>
      <title>QICS: Quantum Information Conic Solver</title>
      <link>https://arxiv.org/abs/2410.17803</link>
      <description>arXiv:2410.17803v2 Announce Type: replace 
Abstract: We introduce QICS (Quantum Information Conic Solver), an open-source primal-dual interior point solver fully implemented in Python, which is focused on solving optimization problems arising in quantum information theory. QICS has the ability to solve optimization problems involving the quantum relative entropy, noncommutative perspectives of operator convex functions, and related functions. It also includes an efficient semidefinite programming solver which exploits sparsity, as well as support for Hermitian matrices. QICS is also currently supported by the Python optimization modelling software PICOS. This paper aims to document the implementation details of the algorithm and cone oracles used in QICS, and serve as a reference guide for the software. Additionally, we showcase extensive numerical experiments which demonstrate that QICS outperforms state-of-the-art quantum relative entropy programming solvers, and has comparable performance to state-of-the-art semidefinite programming solvers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.17803v2</guid>
      <category>math.OC</category>
      <category>quant-ph</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kerry He, James Saunderson, Hamza Fawzi</dc:creator>
    </item>
    <item>
      <title>Generator Subadditive Functions for Mixed-Integer Programs</title>
      <link>https://arxiv.org/abs/2410.21467</link>
      <description>arXiv:2410.21467v2 Announce Type: replace 
Abstract: For equality-constrained linear mixed-integer programs (MIP) defined by rational data, it is known that the subadditive dual is a strong dual and that there exists an optimal solution of a particular form, termed generator subadditive function. Motivated by these results, we explore the connection between Lagrangian duality, subadditive duality and generator subadditive functions for general equality-constrained MIPs where the vector of variables is constrained to be in a monoid. We show that strong duality holds via generator subadditive functions under certain conditions. For the case when the monoid is defined by the set of all mixed-integer points contained in a convex cone, we show that strong duality holds under milder conditions and over a more restrictive set of dual functions. Finally, we provide some examples of applications of our results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.21467v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gustavo Ivan Angulo Olivares, Burak Kocuk, Diego Moran Ramirez</dc:creator>
    </item>
    <item>
      <title>Infeasible Deterministic, Stochastic, and Variance-Reduction Algorithms for Optimization under Orthogonality Constraints</title>
      <link>https://arxiv.org/abs/2303.16510</link>
      <description>arXiv:2303.16510v2 Announce Type: replace-cross 
Abstract: Orthogonality constraints naturally appear in many machine learning problems, from principal component analysis to robust neural network training. They are usually solved using Riemannian optimization algorithms, which minimize the objective function while enforcing the constraint. However, enforcing the orthogonality constraint can be the most time-consuming operation in such algorithms. Recently, Ablin &amp; Peyr\'e (2022) proposed the landing algorithm, a method with cheap iterations that does not enforce the orthogonality constraints but is attracted towards the manifold in a smooth manner. This article provides new practical and theoretical developments for the landing algorithm. First, the method is extended to the Stiefel manifold, the set of rectangular orthogonal matrices. We also consider stochastic and variance reduction algorithms when the cost function is an average of many functions. We demonstrate that all these methods have the same rate of convergence as their Riemannian counterparts that exactly enforce the constraint, and converge to the manifold. Finally, our experiments demonstrate the promise of our approach to an array of machine-learning problems that involve orthogonality constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.16510v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pierre Ablin, Simon Vary, Bin Gao, P. -A. Absil</dc:creator>
    </item>
    <item>
      <title>The isoperimetric problem for convex hulls and the large deviations rate functionals of random walks</title>
      <link>https://arxiv.org/abs/2306.12359</link>
      <description>arXiv:2306.12359v2 Announce Type: replace-cross 
Abstract: We study the asymptotic behaviour of the most likely trajectories of a planar random walk that result in large deviations of the area of their convex hull. If the Laplace transform of the increments is finite on $R^2$, such a scaled limit trajectory $h$ solves the inhomogeneous anisotropic isoperimetric problem for the convex hull, where the usual length of $h$ is replaced by the large deviations rate functional $\int_0^1 I(h'(t)) dt$ and $I$ is the rate function of the increments. Assuming that the distribution of increments is not supported on a half-plane, we show that the optimal trajectories are convex and satisfy the Euler-Lagrange equation, which we solve explicitly for every $I$. The shape of these trajectories resembles the optimizers in the isoperimetric inequality for the Minkowski plane, found by Busemann (1947).</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.12359v2</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vladislav Vysotsky</dc:creator>
    </item>
    <item>
      <title>On optimal tracking portfolio in incomplete markets: The reinforcement learning approach</title>
      <link>https://arxiv.org/abs/2311.14318</link>
      <description>arXiv:2311.14318v2 Announce Type: replace-cross 
Abstract: This paper studies an infinite horizon optimal tracking portfolio problem using capital injection in incomplete market models. The benchmark process is modelled by a geometric Brownian motion with zero drift driven by some unhedgeable risk. The relaxed tracking formulation is adopted where the fund account compensated by the injected capital needs to outperform the benchmark process at any time, and the goal is to minimize the cost of the discounted total capital injection. When model parameters are known, we formulate the equivalent auxiliary control problem with reflected state dynamics, for which the classical solution of the HJB equation with Neumann boundary condition is obtained explicitly. When model parameters are unknown, we introduce the exploratory formulation for the auxiliary control problem with entropy regularization and develop the continuous-time q-learning algorithm in models of reflected diffusion processes. In some illustrative numerical example, we show the satisfactory performance of the q-learning algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.14318v2</guid>
      <category>q-fin.PM</category>
      <category>math.OC</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lijun Bo, Yijie Huang, Xiang Yu</dc:creator>
    </item>
    <item>
      <title>Decision-Focused Learning with Directional Gradients</title>
      <link>https://arxiv.org/abs/2402.03256</link>
      <description>arXiv:2402.03256v4 Announce Type: replace-cross 
Abstract: We propose a novel family of decision-aware surrogate losses, called Perturbation Gradient (PG) losses, for the predict-then-optimize framework. The key idea is to connect the expected downstream decision loss with the directional derivative of a particular plug-in objective, and then approximate this derivative using zeroth order gradient techniques. Unlike the original decision loss which is typically piecewise constant and discontinuous, our new PG losses is a Lipschitz continuous, difference of concave functions that can be optimized using off-the-shelf gradient-based methods. Most importantly, unlike existing surrogate losses, the approximation error of our PG losses vanishes as the number of samples grows. Hence, optimizing our surrogate loss yields a best-in-class policy asymptotically, even in misspecified settings. This is the first such result in misspecified settings, and we provide numerical evidence confirming our PG losses substantively outperform existing proposals when the underlying model is misspecified.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.03256v4</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Huang, Vishal Gupta</dc:creator>
    </item>
    <item>
      <title>Epsilon-Greedy Thompson Sampling to Bayesian Optimization</title>
      <link>https://arxiv.org/abs/2403.00540</link>
      <description>arXiv:2403.00540v3 Announce Type: replace-cross 
Abstract: Bayesian optimization (BO) has become a powerful tool for solving simulation-based engineering optimization problems thanks to its ability to integrate physical and mathematical understandings, consider uncertainty, and address the exploitation-exploration dilemma. Thompson sampling (TS) is a preferred solution for BO to handle the exploitation-exploration trade-off. While it prioritizes exploration by generating and minimizing random sample paths from probabilistic models -- a fundamental ingredient of BO -- TS weakly manages exploitation by gathering information about the true objective function after it obtains new observations. In this work, we improve the exploitation of TS by incorporating the $\varepsilon$-greedy policy, a well-established selection strategy in reinforcement learning. We first delineate two extremes of TS, namely the generic TS and the sample-average TS. The former promotes exploration, while the latter favors exploitation. We then adopt the $\varepsilon$-greedy policy to randomly switch between these two extremes. Small and large values of $\varepsilon$ govern exploitation and exploration, respectively. By minimizing two benchmark functions and solving an inverse problem of a steel cantilever beam, we empirically show that $\varepsilon$-greedy TS equipped with an appropriate $\varepsilon$ is more robust than its two extremes, matching or outperforming the better of the generic TS and the sample-average TS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.00540v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1115/1.4066858</arxiv:DOI>
      <dc:creator>Bach Do, Taiwo Adebiyi, Ruda Zhang</dc:creator>
    </item>
    <item>
      <title>Differentially Private Optimization with Sparse Gradients</title>
      <link>https://arxiv.org/abs/2404.10881</link>
      <description>arXiv:2404.10881v2 Announce Type: replace-cross 
Abstract: Motivated by applications of large embedding models, we study differentially private (DP) optimization problems under sparsity of individual gradients. We start with new near-optimal bounds for the classic mean estimation problem but with sparse data, improving upon existing algorithms particularly for the high-dimensional regime. Building on this, we obtain pure- and approximate-DP algorithms with almost optimal rates for stochastic convex optimization with sparse gradients; the former represents the first nearly dimension-independent rates for this problem. Finally, we study the approximation of stationary points for the empirical loss in approximate-DP optimization and obtain rates that depend on sparsity instead of dimension, modulo polylogarithmic factors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10881v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Badih Ghazi, Crist\'obal Guzm\'an, Pritish Kamath, Ravi Kumar, Pasin Manurangsi</dc:creator>
    </item>
    <item>
      <title>Parameter-free Clipped Gradient Descent Meets Polyak</title>
      <link>https://arxiv.org/abs/2405.15010</link>
      <description>arXiv:2405.15010v2 Announce Type: replace-cross 
Abstract: Gradient descent and its variants are de facto standard algorithms for training machine learning models. As gradient descent is sensitive to its hyperparameters, we need to tune the hyperparameters carefully using a grid search. However, the method is time-consuming, particularly when multiple hyperparameters exist. Therefore, recent studies have analyzed parameter-free methods that adjust the hyperparameters on the fly. However, the existing work is limited to investigations of parameter-free methods for the stepsize, and parameter-free methods for other hyperparameters have not been explored. For instance, although the gradient clipping threshold is a crucial hyperparameter in addition to the stepsize for preventing gradient explosion issues, none of the existing studies have investigated parameter-free methods for clipped gradient descent. Therefore, in this study, we investigate the parameter-free methods for clipped gradient descent. Specifically, we propose Inexact Polyak Stepsize, which converges to the optimal solution without any hyperparameters tuning, and its convergence rate is asymptotically independent of $L$ under $L$-smooth and $(L_0, L_1)$-smooth assumptions of the loss function, similar to that of clipped gradient descent with well-tuned hyperparameters. We numerically validated our convergence results using a synthetic function and demonstrated the effectiveness of our proposed methods using LSTM, Nano-GPT, and T5.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15010v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuki Takezawa, Han Bao, Ryoma Sato, Kenta Niwa, Makoto Yamada</dc:creator>
    </item>
    <item>
      <title>Operator World Models for Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2406.19861</link>
      <description>arXiv:2406.19861v2 Announce Type: replace-cross 
Abstract: Policy Mirror Descent (PMD) is a powerful and theoretically sound methodology for sequential decision-making. However, it is not directly applicable to Reinforcement Learning (RL) due to the inaccessibility of explicit action-value functions. We address this challenge by introducing a novel approach based on learning a world model of the environment using conditional mean embeddings. Leveraging tools from operator theory we derive a closed-form expression of the action-value function in terms of the world model via simple matrix operations. Combining these estimators with PMD leads to POWR, a new RL algorithm for which we prove convergence rates to the global optimum. Preliminary experiments in finite and infinite state settings support the effectiveness of our method</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19861v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>The Thirty-eighth Annual Conference on Neural Information Processing Systems, 2024</arxiv:journal_reference>
      <dc:creator>Pietro Novelli, Marco Prattic\`o, Massimiliano Pontil, Carlo Ciliberto</dc:creator>
    </item>
    <item>
      <title>Efficient Federated Learning against Heterogeneous and Non-stationary Client Unavailability</title>
      <link>https://arxiv.org/abs/2409.17446</link>
      <description>arXiv:2409.17446v2 Announce Type: replace-cross 
Abstract: Addressing intermittent client availability is critical for the real-world deployment of federated learning algorithms. Most prior work either overlooks the potential non-stationarity in the dynamics of client unavailability or requires substantial memory/computation overhead. We study federated learning in the presence of heterogeneous and non-stationary client availability, which may occur when the deployment environments are uncertain, or the clients are mobile. The impacts of heterogeneity and non-stationarity on client unavailability can be significant, as we illustrate using FedAvg, the most widely adopted federated learning algorithm. We propose FedAPM, which includes novel algorithmic structures that (i) compensate for missed computations due to unavailability with only $O(1)$ additional memory and computation with respect to standard FedAvg, and (ii) evenly diffuse local updates within the federated learning system through implicit gossiping, despite being agnostic to non-stationary dynamics. We show that FedAPM converges to a stationary point of even non-convex objectives while achieving the desired linear speedup property. We corroborate our analysis with numerical experiments over diversified client unavailability dynamics on real-world data sets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.17446v2</guid>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ming Xiang, Stratis Ioannidis, Edmund Yeh, Carlee Joe-Wong, Lili Su</dc:creator>
    </item>
    <item>
      <title>An Accelerated Algorithm for Stochastic Bilevel Optimization under Unbounded Smoothness</title>
      <link>https://arxiv.org/abs/2409.19212</link>
      <description>arXiv:2409.19212v2 Announce Type: replace-cross 
Abstract: This paper investigates a class of stochastic bilevel optimization problems where the upper-level function is nonconvex with potentially unbounded smoothness and the lower-level problem is strongly convex. These problems have significant applications in sequential data learning, such as text classification using recurrent neural networks. The unbounded smoothness is characterized by the smoothness constant of the upper-level function scaling linearly with the gradient norm, lacking a uniform upper bound. Existing state-of-the-art algorithms require $\widetilde{O}(1/\epsilon^4)$ oracle calls of stochastic gradient or Hessian/Jacobian-vector product to find an $\epsilon$-stationary point. However, it remains unclear if we can further improve the convergence rate when the assumptions for the function in the population level also hold for each random realization almost surely (e.g., Lipschitzness of each realization of the stochastic gradient). To address this issue, we propose a new Accelerated Bilevel Optimization algorithm named AccBO. The algorithm updates the upper-level variable by normalized stochastic gradient descent with recursive momentum and the lower-level variable by the stochastic Nesterov accelerated gradient descent algorithm with averaging. We prove that our algorithm achieves an oracle complexity of $\widetilde{O}(1/\epsilon^3)$ to find an $\epsilon$-stationary point. Our proof relies on a novel lemma characterizing the dynamics of stochastic Nesterov accelerated gradient descent algorithm under distribution drift with high probability for the lower-level variable, which is of independent interest and also plays a crucial role in analyzing the hypergradient estimation error over time. Experimental results on various tasks confirm that our proposed algorithm achieves the predicted theoretical acceleration and significantly outperforms baselines in bilevel optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19212v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaochuan Gong, Jie Hao, Mingrui Liu</dc:creator>
    </item>
    <item>
      <title>Multiple Gaussian process models based global sensitivity analysis and efficient optimization of in vitro mRNA transcription process</title>
      <link>https://arxiv.org/abs/2410.11976</link>
      <description>arXiv:2410.11976v3 Announce Type: replace-cross 
Abstract: The in vitro transcription (IVT) process is a critical step in RNA production. To ensure the efficiency of RNA manufacturing, it is essential to optimize and identify its key influencing factors. In this study, multiple Gaussian Process (GP) models are used to perform efficient optimization and global sensitivity analysis (GSA). Firstly, multiple GP models were constructed using the data from multiple experimental replicates, accurately capturing the complexities of the IVT process. Then GSA was conducted to determine the dominant reaction factors, specifically the concentrations of reactants NTP and Mg across all data-driven models. Concurrently, a multi-start optimization algorithm was applied to these GP models to identify optimal operational conditions that maximize RNA yields across all surrogate models. These optimized conditions are subsequently validated through additional experimental data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11976v3</guid>
      <category>q-bio.QM</category>
      <category>math.OC</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Min Tao, Adithya Nair, Ioanna Kalospyrou, Robert A Milton, Mabrouka Maamra, Zoltan Kis, Joan Cordiner, Solomon F Brown</dc:creator>
    </item>
    <item>
      <title>State-Dependent Linear Utility Functions for Monetary Returns</title>
      <link>https://arxiv.org/abs/2410.19030</link>
      <description>arXiv:2410.19030v2 Announce Type: replace-cross 
Abstract: We present a theory of expected utility with state-dependent linear utility function for monetary returns, that includes results on first order stochastic dominance, mean-preserving spread, increasing-concave linear utility profiles and risk aversion. As an application of the expected utility theory developed here, we analyze the contract that a monopolist would offer in an insurance market that allowed for partial coverage of loss. We also define a utility function for monetary returns that in a certain sense reconciles state-dependent constant average utility of money with loss aversion and the Friedman-Savage hypothesis. As an immediate consequence of such a utility function, we obtain a profile of state-dependent linear utility functions for monetary returns, where states of nature correspond to mutually disjoint intervals in which monetary gains and losses may occur.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.19030v2</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <category>math.OC</category>
      <category>q-fin.PM</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Somdeb Lahiri</dc:creator>
    </item>
  </channel>
</rss>
