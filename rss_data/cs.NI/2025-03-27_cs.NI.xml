<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 28 Mar 2025 01:55:55 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 27 Mar 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Deploying an Aerial Reconfigurable Intelligent Surface for Vehicle-to-Vehicle Communications (PL: Wykorzystanie powietrznych prze{\l}\k{a}czalnych inteligentnych powierzchni do komunikacji mi\k{e}dzypojazdowej)</title>
      <link>https://arxiv.org/abs/2503.20057</link>
      <description>arXiv:2503.20057v1 Announce Type: new 
Abstract: This paper addresses the deployment of a drone equipped with a reconfigurable intelligent surface (RIS), creating a drone relay station (DRS) to enhance the connectivity of vehicle-to-vehicle (V2V) pairs on the ground. The trajectory of the DRS is optimized to quickly reach the best location for maximizing throughput. Additionally, the presence of an interfering node is considered, and an analytical solution is derived to determine the optimal orientation of the DRS at each time step, minimizing interference to the receiver. Simulation results confirm the effectiveness of the proposed framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.20057v1</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Thu, 27 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.15199/59.2024.4.80</arxiv:DOI>
      <arxiv:journal_reference>Telecommunication Review - Telecommunication News, 2024, no. 4, pp. 360-363</arxiv:journal_reference>
      <dc:creator>Salim Janji</dc:creator>
    </item>
    <item>
      <title>Sequential Task Assignment and Resource Allocation in V2X-Enabled Mobile Edge Computing</title>
      <link>https://arxiv.org/abs/2503.20256</link>
      <description>arXiv:2503.20256v1 Announce Type: new 
Abstract: Nowadays, the convergence of Mobile Edge Computing (MEC) and vehicular networks has emerged as a vital facilitator for the ever-increasing intelligent onboard applications. This paper introduces a multi-tier task offloading mechanism for MEC-enabled vehicular networks leveraging vehicle-to-everything (V2X) communications. The study focuses on applications with sequential subtasks and explores two tiers of collaboration. In the vehicle tier, we design a needing vehicle (NV)-helping vehicle (HV) matching scheme and inter-vehicle collaborative computation is studied, with joint optimization of task offloading decision, communication, and computation resource allocation to minimize energy consumption and meet latency requirements. In the roadside unit (RSU) tier, collaboration among RSUs is investigated to address multi-access issues of bandwidth and computation resources for multiple vehicles. A two-step method is proposed to solve the subchannel allocation problem. Detailed experiments are conducted to demonstrate the effectiveness of the proposed method and assess the impact of different parameters on system energy consumption.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.20256v1</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Thu, 27 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yufei Ye, Shijian Gao, Xinhu Zheng, Liuqing Yang</dc:creator>
    </item>
    <item>
      <title>MAnycast Reloaded: a Tool for an Open, Fast, Responsible and Efficient Daily Anycast Census</title>
      <link>https://arxiv.org/abs/2503.20554</link>
      <description>arXiv:2503.20554v1 Announce Type: new 
Abstract: IP anycast is a widely adopted technique in which an address is replicated at multiple locations, to, e.g., reduce latency and enhance resilience. Due to anycast's crucial role on the modern Internet, earlier research introduced tools to perform anycast censuses. The first, iGreedy, uses latency measurements from geographically dispersed locations to map anycast deployments. The second, MAnycast2, uses anycast to perform a census of other anycast networks. MAnycast2's advantage is speed, performing an Internet-wide census in 3 hours, but it suffers from problems with accuracy and precision. Inversely, iGreedy is highly accurate but much slower. On top of that, iGreedy has a much higher probing cost.
  In this paper we address the shortcomings of both systems and present MAnycast Reloaded (MAnycastR). Taking MAnycast2 as a basis, we completely redesign its measurement pipeline, and add support for distributed probing, additional protocols (UDP, TCP and IPv6) and latency measurements similar to iGreedy. We validate MAnycastR on an anycast testbed with 32 globally distributed nodes, compare against an external anycast production deployment and extensive latency measurements with RIPE Atlas, and cross-check over 60% of detected anycast prefixes against operator ground truth. This shows that MAnycastR achieves high accuracy and precision. We make continual daily MAnycastR censuses available to the community and release the source code of the tool under a permissive open source license.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.20554v1</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 27 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Remi Hendriks, Matthew Luckie, Mattijs Jonker, Raffaele Sommese, Roland van Rijswijk-Deij</dc:creator>
    </item>
    <item>
      <title>SoK: Decoding the Enigma of Encrypted Network Traffic Classifiers</title>
      <link>https://arxiv.org/abs/2503.20093</link>
      <description>arXiv:2503.20093v1 Announce Type: cross 
Abstract: The adoption of modern encryption protocols such as TLS 1.3 has significantly challenged traditional network traffic classification (NTC) methods. As a consequence, researchers are increasingly turning to machine learning (ML) approaches to overcome these obstacles. In this paper, we comprehensively analyze ML-based NTC studies, developing a taxonomy of their design choices, benchmarking suites, and prevalent assumptions impacting classifier performance. Through this systematization, we demonstrate widespread reliance on outdated datasets, oversights in design choices, and the consequences of unsubstantiated assumptions. Our evaluation reveals that the majority of proposed encrypted traffic classifiers have mistakenly utilized unencrypted traffic due to the use of legacy datasets. Furthermore, by conducting 348 feature occlusion experiments on state-of-the-art classifiers, we show how oversights in NTC design choices lead to overfitting, and validate or refute prevailing assumptions with empirical evidence. By highlighting lessons learned, we offer strategic insights, identify emerging research directions, and recommend best practices to support the development of real-world applicable NTC methodologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.20093v1</guid>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <pubDate>Thu, 27 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nimesha Wickramasinghe, Arash Shaghaghi, Gene Tsudik, Sanjay Jha</dc:creator>
    </item>
    <item>
      <title>Bandwidth Allocation for Cloud-Augmented Autonomous Driving</title>
      <link>https://arxiv.org/abs/2503.20127</link>
      <description>arXiv:2503.20127v1 Announce Type: cross 
Abstract: Autonomous vehicle (AV) control systems increasingly rely on ML models for tasks such as perception and planning. Current practice is to run these models on the car's local hardware due to real-time latency constraints and reliability concerns, which limits model size and thus accuracy. Prior work has observed that we could augment current systems by running larger models in the cloud, relying on faster cloud runtimes to offset the cellular network latency. However, prior work does not account for an important practical constraint: limited cellular bandwidth. We show that, for typical bandwidth levels, proposed techniques for cloud-augmented AV models take too long to transfer data, thus mostly falling back to the on-car models and resulting in no accuracy improvement.
  In this work, we show that realizing cloud-augmented AV models requires intelligent use of this scarce bandwidth, i.e. carefully allocating bandwidth across tasks and providing multiple data compression and model options. We formulate this as a resource allocation problem to maximize car utility, and present our system \sysname which achieves an increase in average model accuracy by up to 15 percentage points on driving scenarios from the Waymo Open Dataset.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.20127v1</guid>
      <category>cs.RO</category>
      <category>cs.NI</category>
      <pubDate>Thu, 27 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Peter Schafhalter, Alexander Krentsel, Joseph E. Gonzalez, Sylvia Ratnasamy, Scott Shenker, Ion Stoica</dc:creator>
    </item>
    <item>
      <title>CNN+Transformer Based Anomaly Traffic Detection in UAV Networks for Emergency Rescue</title>
      <link>https://arxiv.org/abs/2503.20355</link>
      <description>arXiv:2503.20355v1 Announce Type: cross 
Abstract: The unmanned aerial vehicle (UAV) network has gained significant attentions in recent years due to its various applications. However, the traffic security becomes the key threatening public safety issue in an emergency rescue system due to the increasing vulnerability of UAVs to cyber attacks in environments with high heterogeneities. Hence, in this paper, we propose a novel anomaly traffic detection architecture for UAV networks based on the software-defined networking (SDN) framework and blockchain technology. Specifically, SDN separates the control and data plane to enhance the network manageability and security. Meanwhile, the blockchain provides decentralized identity authentication and data security records. Beisdes, a complete security architecture requires an effective mechanism to detect the time-series based abnormal traffic. Thus, an integrated algorithm combining convolutional neural networks (CNNs) and Transformer (CNN+Transformer) for anomaly traffic detection is developed, which is called CTranATD. Finally, the simulation results show that the proposed CTranATD algorithm is effective and outperforms the individual CNN, Transformer, and LSTM algorithms for detecting anomaly traffic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.20355v1</guid>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <pubDate>Thu, 27 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yulu Han, Ziye Jia, Sijie He, Yu Zhang, Qihui Wu</dc:creator>
    </item>
    <item>
      <title>UB-Mesh: a Hierarchically Localized nD-FullMesh Datacenter Network Architecture</title>
      <link>https://arxiv.org/abs/2503.20377</link>
      <description>arXiv:2503.20377v1 Announce Type: cross 
Abstract: As the Large-scale Language Models (LLMs) continue to scale, the requisite computational power and bandwidth escalate. To address this, we introduce UB-Mesh, a novel AI datacenter network architecture designed to enhance scalability, performance, cost-efficiency and availability. Unlike traditional datacenters that provide symmetrical node-to-node bandwidth, UB-Mesh employs a hierarchically localized nD-FullMesh network topology. This design fully leverages the data locality of LLM training, prioritizing short-range, direct interconnects to minimize data movement distance and reduce switch usage.
  Although UB-Mesh's nD-FullMesh topology offers several theoretical advantages, its concrete architecture design, physical implementation and networking system optimization present new challenges. For the actual construction of UB-Mesh, we first design the UB-Mesh-Pod architecture, which is based on a 4D-FullMesh topology. UB-Mesh-Pod is implemented via a suite of hardware components that serve as the foundational building blocks, including specifically-designed NPU, CPU, Low-Radix-Switch (LRS), High-Radix-Switch (HRS), NICs and others. These components are interconnected via a novel Unified Bus (UB) technique, which enables flexible IO bandwidth allocation and hardware resource pooling. For networking system optimization, we propose advanced routing mechanism named All-Path-Routing (APR) to efficiently manage data traffic. These optimizations, combined with topology-aware performance enhancements and robust reliability measures like 64+1 backup design, result in 2.04x higher cost-efficiency, 7.2% higher network availability compared to traditional Clos architecture and 95%+ linearity in various LLM training tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.20377v1</guid>
      <category>cs.AR</category>
      <category>cs.NI</category>
      <pubDate>Thu, 27 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Heng Liao, Bingyang Liu, Xianping Chen, Zhigang Guo, Chuanning Cheng, Jianbing Wang, Xiangyu Chen, Peng Dong, Rui Meng, Wenjie Liu, Zhe Zhou, Ziyang Zhang, Yuhang Gai, Cunle Qian, Yi Xiong, Zhongwu Cheng, Jing Xia, Yuli Ma, Xi Chen, Wenhua Du, Shizhong Xiao, Chungang Li, Yong Qin, Liudong Xiong, Zhou Yu, Lv Chen, Lei Chen, Buyun Wang, Pei Wu, Junen Gao, Xiaochu Li, Jian He, Shizhuan Yan, Bill McColl</dc:creator>
    </item>
    <item>
      <title>State-Aware Perturbation Optimization for Robust Deep Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2503.20613</link>
      <description>arXiv:2503.20613v1 Announce Type: cross 
Abstract: Recently, deep reinforcement learning (DRL) has emerged as a promising approach for robotic control. However, the deployment of DRL in real-world robots is hindered by its sensitivity to environmental perturbations. While existing whitebox adversarial attacks rely on local gradient information and apply uniform perturbations across all states to evaluate DRL robustness, they fail to account for temporal dynamics and state-specific vulnerabilities. To combat the above challenge, we first conduct a theoretical analysis of white-box attacks in DRL by establishing the adversarial victim-dynamics Markov decision process (AVD-MDP), to derive the necessary and sufficient conditions for a successful attack. Based on this, we propose a selective state-aware reinforcement adversarial attack method, named STAR, to optimize perturbation stealthiness and state visitation dispersion. STAR first employs a soft mask-based state-targeting mechanism to minimize redundant perturbations, enhancing stealthiness and attack effectiveness. Then, it incorporates an information-theoretic optimization objective to maximize mutual information between perturbations, environmental states, and victim actions, ensuring a dispersed state-visitation distribution that steers the victim agent into vulnerable states for maximum return reduction. Extensive experiments demonstrate that STAR outperforms state-of-the-art benchmarks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.20613v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 27 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zongyuan Zhang, Tianyang Duan, Zheng Lin, Dong Huang, Zihan Fang, Zekai Sun, Ling Xiong, Hongbin Liang, Heming Cui, Yong Cui</dc:creator>
    </item>
    <item>
      <title>Probabilistic Forecasting for Network Resource Analysis in Integrated Terrestrial and Non-Terrestrial Networks</title>
      <link>https://arxiv.org/abs/2503.20658</link>
      <description>arXiv:2503.20658v1 Announce Type: cross 
Abstract: Efficient resource management is critical for Non-Terrestrial Networks (NTNs) to provide consistent, high-quality service in remote and under-served regions. While traditional single-point prediction methods, such as Long-Short Term Memory (LSTM), have been used in terrestrial networks, they often fall short in NTNs due to the complexity of satellite dynamics, signal latency and coverage variability. Probabilistic forecasting, which quantifies the uncertainties of the predictions, is a robust alternative. In this paper, we evaluate the application of probabilistic forecasting techniques, in particular SFF, to NTN resource allocation scenarios. Our results show their effectiveness in predicting bandwidth and capacity requirements in different NTN segments of probabilistic forecasting compared to single-point prediction techniques such as LSTM. The results show the potential of black probabilistic forecasting models to provide accurate and reliable predictions and to quantify their uncertainty, making them indispensable for optimizing NTN resource allocation. At the end of the paper, we also present application scenarios and a standardization roadmap for the use of probabilistic forecasting in integrated Terrestrial Network (TN)-NTN environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.20658v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <pubDate>Thu, 27 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cristian J. Vaca-Rubio, Vaishnavi Kasuluru, Engin Zeydan, Luis Blanco, Roberto Pereira, Marius Caus, Kapal Dev</dc:creator>
    </item>
    <item>
      <title>Elastic Federated Learning over Open Radio Access Network (O-RAN) for Concurrent Execution of Multiple Distributed Learning Tasks</title>
      <link>https://arxiv.org/abs/2305.02109</link>
      <description>arXiv:2305.02109v5 Announce Type: replace 
Abstract: Federated learning (FL) is a popular distributed machine learning (ML) technique in Internet of Things (IoT) networks, where resource-constrained devices collaboratively train ML models while preserving data privacy. However, implementation of FL over 5G-and-beyond wireless networks faces key challenges caused by (i) dynamics of the wireless network conditions and (ii) the coexistence of multiple FL-services in the system. In this paper, we unveil two key phenomena that arise from these challenges: over/under-provisioning of resources and perspective-driven load balancing, both of which significantly impact FL performance in IoT environments. We take the first steps towards addressing these phenomena by proposing a novel distributed ML architecture called elastic FL (EFL). EFL unleashes the full potential of Open RAN (O-RAN) systems and introduces an elastic resource provisioning methodology to execute FL-services. It further constitutes a multi-time-scale FL management system that introduces three dedicated network control functionalities tailored for FL-services, including (i) non-real-time (non-RT) system descriptor, which trains ML-based applications to predict both system and FL-related dynamics and parameters; (ii) near-RT FL controller, which handles O-RAN slicing and mobility management for the seamless execution of FL-services; (iii) FL MAC scheduler, which conducts real-time resource allocation to the end clients of various FL-services. We finally prototype EFL to demonstrate its potential in improving the performance of FL-services.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.02109v5</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Thu, 27 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Payam Abdisarabshali, Nicholas Accurso, Filippo Malandra, Weifeng Su, Seyyedali Hosseinalipour</dc:creator>
    </item>
    <item>
      <title>Joint Task Offloading and User Scheduling in 5G MEC under Jamming Attacks</title>
      <link>https://arxiv.org/abs/2501.13227</link>
      <description>arXiv:2501.13227v2 Announce Type: replace-cross 
Abstract: In this paper, we propose a novel joint task offloading and user scheduling (JTO-US) framework for 5G mobile edge computing (MEC) systems under security threats from jamming attacks. The goal is to minimize the delay and the ratio of dropped tasks, taking into account both communication and computation delays. The system model includes a 5G network equipped with MEC servers and an adversarial on-off jammer that disrupts communication. The proposed framework optimally schedules tasks and users to minimize the impact of jamming while ensuring that high-priority tasks are processed efficiently. Genetic algorithm (GA) is used to solve the optimization problem, and the results are compared with benchmark methods such as GA without considering jamming effect, Shortest Job First (SJF), and Shortest Deadline First (SDF). The simulation results demonstrate that the proposed JTO-US framework achieves the lowest drop ratio and effectively manages priority tasks, outperforming existing methods. Particularly, when the jamming probability is 0.8, the proposed framework mitigates the jammer's impact by reducing the drop ratio to 63%, compared to 89% achieved by the next best method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13227v2</guid>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <pubDate>Thu, 27 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mohammadreza Amini, Burak Kantarci, Claude D'Amours, Melike Erol-Kantarci</dc:creator>
    </item>
  </channel>
</rss>
