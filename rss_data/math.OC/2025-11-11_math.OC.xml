<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 12 Nov 2025 02:45:43 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Signal and Image Recovery with Scale and Signed Permutation Invariant Sparsity-Promoting Functions</title>
      <link>https://arxiv.org/abs/2511.05777</link>
      <description>arXiv:2511.05777v1 Announce Type: new 
Abstract: Sparse signal recovery has been a cornerstone of advancements in data processing and imaging. Recently, the squared ratio of $\ell_1$ to $\ell_2$ norms, $(\ell_1/\ell_2)^2$, has been introduced as a sparsity-prompting function, showing superior performance compared to traditional $\ell_1$ minimization, particularly in challenging scenarios with high coherence and dynamic range. This paper explores the integration of the proximity operator of $(\ell_1/\ell_2)^2$ and $\ell_1/\ell_2$ into efficient optimization frameworks, including the Accelerated Proximal Gradient (APG) and Alternating Direction Method of Multipliers (ADMM). We rigorously analyze the convergence properties of these algorithms and demonstrate their effectiveness in compressed sensing and image restoration applications. Numerical experiments highlight the advantages of our proposed methods in terms of recovery accuracy and computational efficiency, particularly under noise and high-coherence conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.05777v1</guid>
      <category>math.OC</category>
      <category>eess.SP</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jianqing Jia, Ashley Prater-Bennette, Lixin Shen</dc:creator>
    </item>
    <item>
      <title>History-Aware Adaptive High-Order Tensor Regularization</title>
      <link>https://arxiv.org/abs/2511.05788</link>
      <description>arXiv:2511.05788v1 Announce Type: new 
Abstract: In this paper, we develop a new adaptive regularization method for minimizing a composite function, which is the sum of a $p$th-order ($p \ge 1$) Lipschitz continuous function and a simple, convex, and possibly nonsmooth function. We use a history of local Lipschitz estimates to adaptively select the current regularization parameter, an approach we %have termed
  shall term the {\it history-aware adaptive regularization method}. Our method matches the complexity guarantees of the standard $p$th-order tensor method that require a known Lipschitz constant, for both convex and nonconvex objectives. In the nonconvex case, the number of iterations required to find an $(\epsilon_g,\epsilon_H)$-approximate second-order stationary point is bounded by $\mathcal{O}(\max\{\epsilon_g^{-(p+1)/p}, \epsilon_H^{-(p+1)/(p-1)}\})$. For convex functions, the iteration complexity improves to $\mathcal{O}(\epsilon^{-1/p})$ when finding an $\epsilon$-approximate optimal point. Furthermore, we propose several variants of this method. For practical consideration, we introduce cyclic and sliding-window strategies for choosing proper historical Lipschitz estimates, which mitigate the limitation of overly conservative updates. Theoretically, we introduce Nesterov's acceleration to develop an accelerated version for convex objectives, which attains an iteration complexity of $\mathcal{O}(\epsilon^{-1/(p+1)})$. Finally, extensive numerical experiments are conducted to demonstrate the effectiveness of our adaptive approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.05788v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chang He, Bo Jiang, Yuntian Jiang, Chuwen Zhang, Shuzhong Zhang</dc:creator>
    </item>
    <item>
      <title>Introduction to Bilevel Optimization: A perspective from Variational Analysis</title>
      <link>https://arxiv.org/abs/2511.05793</link>
      <description>arXiv:2511.05793v1 Announce Type: new 
Abstract: Lecture Notes based on the course given at Toulouse School of Economics, on Fall 2024. It contains a quick introduction to the field of bilevel optimization, following a perspective from Variational Analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.05793v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David Salas</dc:creator>
    </item>
    <item>
      <title>IoT-based Fresh Produce Supply Chain Under Uncertainty: An Adaptive Optimization Framework</title>
      <link>https://arxiv.org/abs/2511.05920</link>
      <description>arXiv:2511.05920v1 Announce Type: new 
Abstract: Fruits and vegetables form a vital component of the global economy; however, their distribution poses complex logistical challenges due to high perishability, supply fluctuations, strict quality and safety standards, and environmental sensitivity. In this paper, we propose an adaptive optimization model that accounts for delays, travel time, and associated temperature changes impacting produce shelf life, and compare it against traditional approaches such as Robust Optimization, Distributionally Robust Optimization, and Stochastic Programming. Additionally, we conduct a series of computational experiments using Internet of Things (IoT) sensor data to evaluate the performance of our proposed model. Our study demonstrates that the proposed adaptive model achieves a higher shelf life, extending it by over 18\% compared to traditional optimization models, by dynamically mitigating temperature deviations through a temperature feedback mechanism. The promising results demonstrate the potential of this approach to improve both the freshness and efficiency of logistics systems an aspect often neglected in previous works.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.05920v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Chirag Seth, Mehrdad Pirnia, James H Bookbinder</dc:creator>
    </item>
    <item>
      <title>A PDE Perspective on Generative Diffusion Models</title>
      <link>https://arxiv.org/abs/2511.05940</link>
      <description>arXiv:2511.05940v1 Announce Type: new 
Abstract: Score-based diffusion models have emerged as a powerful class of generative methods, achieving state-of-the-art performance across diverse domains. Despite their empirical success, the mathematical foundations of those models remain only partially understood, particularly regarding the stability and consistency of the underlying stochastic and partial differential equations governing their dynamics.
  In this work, we develop a rigorous partial differential equation (PDE) framework for score-based diffusion processes. Building on the Li--Yau differential inequality for the heat flow, we prove well-posedness and derive sharp $L^p$-stability estimates for the associated score-based Fokker--Planck dynamics, providing a mathematically consistent description of their temporal evolution. Through entropy stability methods, we further show that the reverse-time dynamics of diffusion models concentrate on the data manifold for compactly supported data distributions and a broad class of initialization schemes, with a concentration rate of order $\sqrt{t}$ as $t \to 0$.
  These results yield a theoretical guarantee that, under exact score guidance, diffusion trajectories return to the data manifold while preserving imitation fidelity. Our findings also provide practical insights for designing diffusion models, including principled criteria for score-function construction, loss formulation, and stopping-time selection. Altogether, this framework provides a quantitative understanding of the trade-off between generative capacity and imitation fidelity, bridging rigorous analysis and model design within a unified mathematical perspective.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.05940v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>math.AP</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kang Liu, Enrique Zuazua</dc:creator>
    </item>
    <item>
      <title>Solving exact and noisy rank-one tensor completion with semidefinite programming</title>
      <link>https://arxiv.org/abs/2511.06062</link>
      <description>arXiv:2511.06062v1 Announce Type: new 
Abstract: Consider recovering a rank-one tensor of size $n_1 \times \cdots \times n_d$ from exact or noisy observations of a few of its entries. We tackle this problem via semidefinite programming (SDP). We derive deterministic combinatorial conditions on the observation mask $\Omega$ (the set of observed indices) under which our SDPs solve the exact completion and achieve robust recovery in the noisy regime. These conditions can be met with as few as $\bigl(\sum_{i=1}^d n_i\bigr) - d + 1$ observations for special $\Omega$. When $\Omega$ is uniformly random, our conditions hold with $O\!\bigl((\prod_{i=1}^d n_i)^{1/2}\,\mathrm{polylog}(\prod_{i=1}^d n_i)\bigr)$ observations. Prior works mostly focus on the uniformly random case, ignoring the practical relevance of structured masks. For $d=2$ (matrix completion), our propagation condition holds if and only if the completion problem admits a unique solution. Our results apply to tensors of arbitrary order and cover both exact and noisy settings. In contrast to much of the literature, our guarantees rely solely on the combinatorial structure of the observation mask, without incoherence assumptions on the ground-truth tensor or uniform randomness of the samples. Preliminary computational experiments show that our SDP methods solve tensor completion problems using significantly fewer observations than alternative methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06062v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Diego Cifuentes, Zhuorui Li</dc:creator>
    </item>
    <item>
      <title>Assessing On-Demand Mobility Services and Policy Impacts: A Case Study from Chengdu, China</title>
      <link>https://arxiv.org/abs/2511.06074</link>
      <description>arXiv:2511.06074v1 Announce Type: new 
Abstract: The rapid expansion of ride-hailing services has significantly reshaped urban on-demand mobility patterns, but it still remains unclear how they perform relative to traditional street-hailing services and how effective are related policy interventions. This study presents a simulation framework integrating a graph theory-based trip-vehicle matching mechanism with real cruising taxi operations data to simulate ride-hailing services in Chengdu, China. The performances of the two on-demand mobility service modes (i.e., ride-hailing and street-hailing) are evaluated in terms of three key performance indicators: average passenger waiting time (APWT), average deadheading miles (ADM), and average deadheading energy consumption (ADEC). We further examine the impacts of spatiotemporal characteristics and three types of policies: fleet size management, geofencing, and demand management, on the performance of ride-hailing services. Results show that under the same fleet size and trip demand as street-hailing taxis, ride-hailing services without cruising achieve substantial improvements, reducing APWT, ADM, and ADEC by 81\%, 75\%, and 72.1\%, respectively. These improvements are most pronounced during midnight low-demand hours and in remote areas such as airports. Our analysis also reveals that for ride-hailing service, (1) expanding fleet size yields diminishing marginal benefits; (2) geofencing worsens overall performance while it improves the performance of serving all trips within the city center; and (3) demand-side management targeting trips to high-attraction and low-demand areas can effectively reduce passenger waiting time without increasing deadheading costs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06074v1</guid>
      <category>math.OC</category>
      <category>cs.CY</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Youkai Wu, Zhaoxia Guo, Qi Liu abd Stein W. Wallace</dc:creator>
    </item>
    <item>
      <title>Differential inclusions and quasi-Lyapunov functions</title>
      <link>https://arxiv.org/abs/2511.06100</link>
      <description>arXiv:2511.06100v1 Announce Type: new 
Abstract: A sufficient condition for existence of a solution of a differential inclusion with a uniformly bounded right-hand side that has nonempty closed (possibly nonconvex) values is obtained. An Olech-type result is obtained as a corollary. An example, which originates from the Fuller problem from optimal control theory, is given to demonstrate the applicability of the main result.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06100v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Martin Ivanov, Mikhail Krastanov, Nadezhda Ribarska</dc:creator>
    </item>
    <item>
      <title>Digital Twins and Their Applications in Modeling Different Levels of Manufacturing Systems: A Review</title>
      <link>https://arxiv.org/abs/2511.06119</link>
      <description>arXiv:2511.06119v1 Announce Type: new 
Abstract: Digital Twin (DT) has gained great interest as an innovative technology in Industry 4.0 that enables advanced modeling, simulation, and optimization of service and manufacturing systems. This article provides an extensive review of the literature on digital twins (DTs) and their utilization at the levels of product/production line, production system, and enterprise, and considers how they have been applied under real industrial conditions. This article classifies the types of DTs as well as modeling technologies of DT and applications in different fields, with particular focus on the research of strengths and limitations of Discrete Event Simulation (DES) for systems modelling. A generic structure for DT is proposed, outlining the essential components and flow of data. Case studies demonstrate the benefits of DTs for increased efficiency, reduced downtime, and improved lifecycle management, as well as challenges caused by the complexity of data integration and cybersecurity risk, and high implementation costs. This paper contributes to the growing body of knowledge by identifying both the opportunities and barriers to widespread DT adoption. This study concludes that while DTs offer transformative capabilities for enhancing efficiency and decision-making, overcoming these challenges is crucial for realizing their widespread adoption and impact across service and manufacturing sectors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06119v1</guid>
      <category>math.OC</category>
      <category>cs.SE</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sarow Saeedi</dc:creator>
    </item>
    <item>
      <title>A Note on Optimal Product Pricing</title>
      <link>https://arxiv.org/abs/2511.06156</link>
      <description>arXiv:2511.06156v1 Announce Type: new 
Abstract: We consider the problem of choosing prices of a set of products so as to maximize profit, taking into account self-elasticity and cross-elasticity, subject to constraints on the prices. We show that this problem can be formulated as maximizing the sum of a convex and concave function. We compare three methods for finding a locally optimal approximate solution. The first is based on the convex-concave procedure, and involves solving a short sequence of convex problems. Another one uses a custom minorize-maximize method, and involves solving a sequence of quadratic programs. The final method is to use a general purpose nonlinear programming method. In numerical examples all three converge reliably to the same local maximum, independent of the starting prices, leading us to believe that the prices found are likely globally optimal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06156v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maximilian Schaller, Stephen Boyd</dc:creator>
    </item>
    <item>
      <title>A Dual Method for Minimax Quadratic Programming</title>
      <link>https://arxiv.org/abs/2511.06180</link>
      <description>arXiv:2511.06180v1 Announce Type: new 
Abstract: This paper investigates minimax quadratic programming problems with coupled inequality constraints. By leveraging a duality theorem, we develop a dual algorithm that extends the dual active set method to the minimax setting, transforming the original inequality constrained problem into a sequence of equality constrained subproblems. Under a suitable assumption, we prove that the associated S-pairs do not repeat and that the algorithm terminates in a finite number of iterations, guaranteed by the monotonic decrease of the objective function value. To ensure numerical stability and efficiency, the algorithm is implemented using Cholesky factorization and Givens rotations. Numerical experiments on both randomly generated minimax quadratic programs and illustrative applications demonstrate the accuracy, stability, and computational effectiveness of the proposed algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06180v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wenhui Ren, Liwei Zhang</dc:creator>
    </item>
    <item>
      <title>Intelligent-Based Neural Networks and Optimal Control of Fractional Order Ebola Virus Dynamics</title>
      <link>https://arxiv.org/abs/2511.06303</link>
      <description>arXiv:2511.06303v1 Announce Type: new 
Abstract: Ebola virus disease is a severe hemorrhagic fever with rapid transmission through infected fluids and surfaces. We develop a fractional-order model using Caputo derivatives to capture memory effects in disease dynamics. An eight-compartment structure distinguishes symptomatic, asymptomatic, and post-mortem transmission pathways. We prove global well-posedness, derive the basic reproduction number $\mathcal{R}_0$, and establish stability theorems. Sensitivity analysis shows $\mathcal{R}_0$ is most sensitive to transmission rate, incubation period, and deceased infectivity. Treatment-safe burial synergy achieves 86.5\% morbidity-mortality control, with safe burial being most effective. Our disease-informed neural network achieves near-perfect predictive accuracy ($R^2$: 0.991-0.999, 99.1-99.9\% accuracy), closely matching real epidemic behavior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06303v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Noor Muhammad (School of Mathematics, Sichuan University, Chengdu, China), Md. Nur Alam (Department of Mathematics, Pabna University of Science &amp; Technology, Pabna-6600, Bangladesh), Zhang Shiqing (School of Mathematics, Sichuan University, Chengdu, China)</dc:creator>
    </item>
    <item>
      <title>Krylov Subspace Acceleration for First-Order Splitting Methods in Convex Quadratic Programming</title>
      <link>https://arxiv.org/abs/2511.06323</link>
      <description>arXiv:2511.06323v2 Announce Type: new 
Abstract: We propose an acceleration scheme for first-order methods (FOMs) for convex quadratic programs (QPs) that is analogous to Anderson acceleration and the Generalized Minimal Residual algorithm for linear systems. We motivate our proposed method from the observation that FOMs applied to QPs typically consist of piecewise-affine operators. We describe our Krylov subspace acceleration scheme, contrasting it with existing Anderson acceleration schemes and showing that it largely avoids the latter's well-known ill-conditioning issues in regions of slow convergence. We demonstrate the performance of our scheme relative to Anderson acceleration using standard collections of problems from model predictive control and statistical learning applications. We show that our method is faster than Anderson acceleration across the board in terms of iteration count, and in many cases in computation time, particularly for optimal control and for problems solved to high accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06323v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gabriel Berk Pereira, Paul J. Goulart</dc:creator>
    </item>
    <item>
      <title>Integer L-Shaped Method with Non-Supporting No-Good Optimality Cuts</title>
      <link>https://arxiv.org/abs/2511.06340</link>
      <description>arXiv:2511.06340v1 Announce Type: new 
Abstract: Two-stage stochastic mixed-integer linear programs with mixed-integer recourse arise in many practical applications but are computationally challenging due to their large size and the presence of integer decisions in both stages. The integer L-shaped method with alternating cuts is a widely used decomposition algorithm for these problems, relying on optimality cuts generated using subproblems to iteratively refine the master problem. A key computational bottleneck in this approach is solving the mixed-integer subproblems to optimality in order to generate separating cuts. This work proposes a modification to the integer L-shaped method with alternating cuts to allow for efficient generation of no-good optimality cuts that are separating for the current master problem solutions without being supporting hyperplanes of the feasible region. These separating cuts are derived from subproblems that are terminated before the optimal solution is found or proven to be optimal, reducing the computational effort required for cut generation. Additionally, an updated optimality cut generation function is proposed to account for the various complexities introduced by this early termination strategy. The effectiveness of the proposed method is demonstrated through two case studies on industrially relevant problems from the literature, which illustrate its advantages in handling large-scale instances with complex mixed-integer subproblems. In these cases, the method achieves substantial reductions in solution time or optimality gap compared to the standard integer L-shaped method with alternating cuts, with performance improvements that increase with mixed-integer subproblem size and complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06340v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Benjamin P. Riley, Prodromos Daoutidis, Qi Zhang</dc:creator>
    </item>
    <item>
      <title>A Poisson Jump-driven SDE Approach to Distributed Gradient Descent with Sparse Communication</title>
      <link>https://arxiv.org/abs/2511.06379</link>
      <description>arXiv:2511.06379v1 Announce Type: new 
Abstract: To bridge the gap between idealised communication models and the stochastic reality of networked systems, we introduce a framework for embedding asynchronous communication directly into algorithm dynamics using stochastic differential equations (SDE) driven by Poisson Jumps. We apply this communication-aware design to the continuous-time gradient flow, yielding a distributed algorithm where updates occur via sparse Poisson events. Our analysis establishes communication rate bounds for asymptotic stability and, crucially, a higher, yet sparse, rate that provably any desired exponential convergence performance slower than the nominal, centralized flow. These theoretical results, shown for unconstrained quadratic optimisation, are validated by a numerical simulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06379v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marc Weber, John Paul Strachan, Christian Ebenbauer</dc:creator>
    </item>
    <item>
      <title>Online Subspace Learning on Flag Manifolds for System Identification</title>
      <link>https://arxiv.org/abs/2511.06416</link>
      <description>arXiv:2511.06416v1 Announce Type: new 
Abstract: Data-driven control methods based on subspace representations are powerful but are often limited to linear time-invariant systems where the model order is known. A key challenge is developing online data-driven control algorithms for time-varying systems, especially when the system's complexity is unknown or changes over time. To address this, we propose a novel online subspace learning framework that operates on flag manifolds. Our algorithm leverages streaming data to recursively track an ensemble of nested subspaces, allowing it to adapt to varying system dimensions without prior knowledge of the true model order. We show that our algorithm is a generalization of the Grassmannian Recursive Algorithm for Tracking. The learned subspace models are then integrated into a data-driven simulation framework to perform prediction for unknown dynamical systems. The effectiveness of this approach is demonstrated through a case study where the proposed adaptive predictor successfully handles abrupt changes in system dynamics and outperforms several baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06416v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Dian Jin, Jeremy Coulson</dc:creator>
    </item>
    <item>
      <title>Feature weighting for data analysis via evolutionary simulation</title>
      <link>https://arxiv.org/abs/2511.06454</link>
      <description>arXiv:2511.06454v1 Announce Type: new 
Abstract: We analyze an algorithm for assigning weights prior to scalarization in discrete multi-objective problems arising from data analysis. The algorithm evolves the weights (the relevance of features) by a replicator-type dynamic on the standard simplex, with update indices computed from a normalized data matrix. We prove that the resulting sequence converges globally to a unique interior equilibrium, yielding non-degenerate limiting weights. The method, originally inspired by evolutionary game theory, differs from standard weighting schemes in that it is analytically tractable with provable convergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06454v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aris Daniilidis, Alberto Dom\'inguez Corella, Philipp Wissgott</dc:creator>
    </item>
    <item>
      <title>On Driftless Systems with m controls and 2m or 2m-1 states that are Flat by Pure Prolongation</title>
      <link>https://arxiv.org/abs/2511.06511</link>
      <description>arXiv:2511.06511v1 Announce Type: new 
Abstract: It is widely recognized that no tractable necessary and sufficient conditions exist for determining whether a system is, in general, differentially flat. However, specific cases do provide such conditions. For instance, driftless systems with two inputs have known necessary and sufficient conditions. For driftless systems with three or more inputs, the available conditions are only sufficient. This paper presents new findings on determining whether a system with m inputs and $2m$ or $2m-1$ states is flat by pure prolongation, a specific subclass of differential flatness. While this condition is more restrictive than general differential flatness, the algorithm for computing flat outputs remains remarkably simple, and the verification requirements are relatively lenient. Moreover, the conditions proposed in this work broaden the class of systems recognized as differentially flat, as our sufficient condition differs from existing criteria.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06511v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.DG</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jean L\'evine, Jaume Franch</dc:creator>
    </item>
    <item>
      <title>Block Scheduling in Two-stage Outpatient Clinics: Appointment Template Design</title>
      <link>https://arxiv.org/abs/2511.06557</link>
      <description>arXiv:2511.06557v1 Announce Type: new 
Abstract: Increasing the efficiency and effectiveness of the healthcare system is a challenge faced worldwide. Many outpatient clinics have implemented two-stage service systems, with both a physician and physician assistant, to enhance capacity and reduce costs. Some patients only visit a physician assistant while some patients visit both providers depending on their patient type. However, minimizing provider idle time and overtime while reducing patient waiting time is challenging in two-stage service systems. Thus, our objective is to find daily appointment templates, based on block scheduling, that minimize a weighted sum of these metrics. A block schedule divides the overall schedule into several time blocks and assigns patients of different types into each block in proportion to their daily demand to balance the workload throughout the day. Since the problem is shown to be strongly $\mathcal{NP}$-Hard, we develop a heuristic algorithm that provides a no-idle time appointment template that is easily implementable. We expand our study to include stochastic service times and show that our algorithm yields an efficient block schedule under practically relevant conditions. The algorithm is able to provide a solution similar in cost to the stochastic model when patient wait time costs are low by maintaining lower physician idle times with at most a 16 minute/patient increase in patient wait times. Comparing our heuristic to a First Come, First Appointment scheduling rule, we show that our heuristic is able to better minimize provider idle time, which mimics many real-life settings where clinics prioritize the efficiency of the healthcare providers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06557v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pelin Ke\c{s}rit, Chelliah Sriskandarajah, Jon M. Stauffer</dc:creator>
    </item>
    <item>
      <title>Accelerated Proximal Gradient Methods in the affine-quadratic case: Strong convergence and limit identification</title>
      <link>https://arxiv.org/abs/2511.06560</link>
      <description>arXiv:2511.06560v1 Announce Type: new 
Abstract: Recent works by Bot-Fadili-Nguyen (arXiv:2510.22715) and by Jang-Ryu (arXiv:2510.23513) resolve long-standing iterate convergence questions for accelerated (proximal) gradient methods. In particular, Bot-Fadili-Nguyen prove weak convergence of discrete accelerated gradient descent (AGD) iterates and, crucially, convergence of the accelerated proximal gradient (APG) method in the composite setting, with extensions to infinite-dimensional Hilbert spaces. In parallel, Jang-Ryu establish point convergence for the continuous-time accelerated flow and for discrete AGD in finite dimensions.
  These results leave open which minimizer is selected by the iterates. We answer this in the affine-quadratic setting: when initialized at the same point, the difference between the proximal gradient (PGM) and APG iterates converges weakly to zero. Consequently, APG converges weakly to the best approximation of the initial point in the solution set. Moreover, under mild assumptions on the parameter sequence, we obtain strong convergence of APG. The result is tight: a two-dimensional example shows that coincidence of the APG and PGM limits is specific to the affine-quadratic regime and does not hold in general.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06560v1</guid>
      <category>math.OC</category>
      <category>math.FA</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Walaa M. Moursi, Andrew Naguib, Viktor Pavlovic, Stephen A. Vavasis</dc:creator>
    </item>
    <item>
      <title>Stochastic Optimal Impulse Controls with Changing Running Costs</title>
      <link>https://arxiv.org/abs/2511.06628</link>
      <description>arXiv:2511.06628v1 Announce Type: new 
Abstract: This paper is concerned with stochastic impulse control problems in which the running cost changes depending on the impulse control. Because of such a dependence, it brings several difficulties when the usual dynamic programming principle is to be used. The corresponding Hamilton-Jacobi-Bellman (HJB) equation (a quasi-variational inequality) is derived, which contains a parameter. The value function is a unique viscosity solution to this HJB equation by a classical argument. Further, inspired by the derivation of the Pontryagin type maximum principle for stochastic optimal controls with a non-convex control domain, we have established the maximum principle for our stochastic optimal impulse controls, allowing perturbations in optimal impulse moments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06628v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuchen Cao, Jiongmin Yong</dc:creator>
    </item>
    <item>
      <title>Adam symmetry theorem: characterization of the convergence of the stochastic Adam optimizer</title>
      <link>https://arxiv.org/abs/2511.06675</link>
      <description>arXiv:2511.06675v1 Announce Type: new 
Abstract: Beside the standard stochastic gradient descent (SGD) method, the Adam optimizer due to Kingma &amp; Ba (2014) is currently probably the best-known optimization method for the training of deep neural networks in artificial intelligence (AI) systems. Despite the popularity and the success of Adam it remains an \emph{open research problem} to provide a rigorous convergence analysis for Adam even for the class of strongly convex SOPs. In one of the main results of this work we establish convergence rates for Adam in terms of the number of gradient steps (convergence rate \nicefrac{1}{2} w.r.t. the size of the learning rate), the size of the mini-batches (convergence rate 1 w.r.t. the size of the mini-batches), and the size of the second moment parameter of Adam (convergence rate 1 w.r.t. the distance of the second moment parameter to 1) for the class of strongly convex SOPs. In a further main result of this work, which we refer to as \emph{Adam symmetry theorem}, we illustrate the optimality of the established convergence rates by proving for a special class of simple quadratic strongly convex SOPs that Adam converges as the number of gradient steps increases to infinity to the solution of the SOP (the unique minimizer of the strongly convex objective function) if and \emph{only} if the random variables in the SOP (the data in the SOP) are \emph{symmetrically distributed}. In particular, in the standard case where the random variables in the SOP are not symmetrically distributed we \emph{disprove} that Adam converges to the minimizer of the SOP as the number of Adam steps increases to infinity. We also complement the conclusions of our convergence analysis and the Adam symmetry theorem by several numerical simulations that indicate the sharpness of the established convergence rates and that illustrate the practical appearance of the phenomena revealed in the \emph{Adam symmetry theorem}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06675v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Steffen Dereich, Thang Do, Arnulf Jentzen, Philippe von Wurstemberger</dc:creator>
    </item>
    <item>
      <title>Bilevel Learning via Inexact Stochastic Gradient Descent</title>
      <link>https://arxiv.org/abs/2511.06774</link>
      <description>arXiv:2511.06774v1 Announce Type: new 
Abstract: Bilevel optimization is a central tool in machine learning for high-dimensional hyperparameter tuning. Its applications are vast; for instance, in imaging it can be used for learning data-adaptive regularizers and optimizing forward operators in variational regularization. These problems are large in many ways: a lot of data is usually available to train a large number of parameters, calling for stochastic gradient-based algorithms. However, exact gradients with respect to parameters (so-called hypergradients) are not available, and their precision is usually linearly related to computational cost. Hence, algorithms must solve the problem efficiently without unnecessary precision. The design of such methods is still not fully understood, especially regarding how accuracy requirements and step size schedules affect theoretical guarantees and practical performance. Existing approaches introduce stochasticity at both the upper level (e.g., in sampling or mini-batch estimates) and the lower level (e.g., in solving the inner problem) to improve generalization, but they typically fix the number of lower-level iterations, which conflicts with asymptotic convergence assumptions. In this work, we advance the theory of inexact stochastic bilevel optimization. We prove convergence and establish rates under decaying accuracy and step size schedules, showing that with optimal configurations convergence occurs at an $\mathcal{O}(k^{-1/4})$ rate in expectation. Experiments on image denoising and inpainting with convex ridge regularizers and input-convex networks confirm our analysis: decreasing step sizes improve stability, accuracy scheduling is more critical than step size strategy, and adaptive preconditioning (e.g., Adam) further boosts performance. These results bridge theory and practice, providing convergence guarantees and practical guidance for large-scale imaging problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06774v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohammad Sadegh Salehi, Subhadip Mukherjee, Lindon Roberts, Matthias J. Ehrhardt</dc:creator>
    </item>
    <item>
      <title>Convergence of Actor-Critic Learning for Mean Field Games and Mean Field Control in Continuous Spaces</title>
      <link>https://arxiv.org/abs/2511.06812</link>
      <description>arXiv:2511.06812v1 Announce Type: new 
Abstract: We establish the convergence of the deep actor-critic reinforcement learning algorithm presented in [Angiuli et al., 2023a] in the setting of continuous state and action spaces with an infinite discrete-time horizon. This algorithm provides solutions to Mean Field Game (MFG) or Mean Field Control (MFC) problems depending on the ratio between two learning rates: one for the value function and the other for the mean field term. In the MFC case, to rigorously identify the limit, we introduce a discretization of the state and action spaces, following the approach used in the finite-space case in [Angiuli et al., 2023b]. The convergence proofs rely on a generalization of the two-timescale framework introduced in [Borkar, 1997]. We further extend our convergence results to Mean Field Control Games, which involve locally cooperative and globally competitive populations. Finally, we present numerical experiments for linear-quadratic problems in one and two dimensions, for which explicit solutions are available.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06812v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jean-Pierre Fouque, Mathieu Lauri\`ere, Mengrui Zhang</dc:creator>
    </item>
    <item>
      <title>On the diameter of subgradient sequences in o-minimal structures</title>
      <link>https://arxiv.org/abs/2511.06868</link>
      <description>arXiv:2511.06868v1 Announce Type: new 
Abstract: We study subgradient sequences of locally Lipschitz functions definable in a polynomially bounded o-minimal structure. We show that the diameter of any subgradient sequence is related to the variation in function values, with error terms dominated by a double summation of step sizes. Consequently, we prove that bounded subgradient sequences converge if the step sizes are of order $1/k$. The proof uses Lipschitz $L$-regular stratifications in o-minimal structures to analyze subgradient sequences via their projections onto different strata.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06868v1</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lexiao Lai, Mingzhi Song</dc:creator>
    </item>
    <item>
      <title>Reinforcement Learning Framework For Stochastic Optimal Control Problem Under Model Uncertainty</title>
      <link>https://arxiv.org/abs/2511.06881</link>
      <description>arXiv:2511.06881v1 Announce Type: new 
Abstract: We develop a continuous-time entropy-regularized reinforcement learning framework under model uncertainty. By applying Sion's minimax theorem, we transform the intractable robust control problem into an equivalent standard entropy-regularized stochastic control problem, facilitating reinforcement learning algorithms. We establish sufficient conditions for the theorem's validity and demonstrate our approach on linear-quadratic problems with uncertain model parameters following Bernoulli and uniform distributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06881v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiaxuan Hou, Lifeng Wei</dc:creator>
    </item>
    <item>
      <title>Structured Symmetric Tensors</title>
      <link>https://arxiv.org/abs/2511.06966</link>
      <description>arXiv:2511.06966v1 Announce Type: new 
Abstract: In this paper, we study structured symmetric tensors. We introduce several new classes of structured symmetric tensors: completely decomposable (CD) tensors, strictly sum of squares (SSOS) tensors and SOS$^*$ tensors. CD tensors have applications in data analysis and signal processing. Complete Hankel tensors are CD tensors. SSOS tensors are defined as SOS tensors with a positive definite Gram matrix, ensuring structural stability under perturbations. The SOS$^*$ cone is defined as the dual cone of the SOS tensor cone, with characterizations via moment matrices and polynomial nonnegativity. We study the relations among completely positive (CP) cones, CD cones, sum of squares (SOS) cones, positive semidefinite (PSD) cones and copositive (COP) cones. We identify the interiors of PSD, SOS, CP, COP and CD cones for even-order tensors. These characterizations are crucial for interior-point methods and stability analysis in polynomial and tensor optimization. We generalize the classical Schur product theorem to CD and CP tensors, including the case of strongly completely decomposable (SCD) and strongly completely positive (SCP) tensors. We identify equivalence between strictly CD (SCD) and positive definite (PD) for CD tensors. This result establishes a key link between the spanning property of decomposition vectors and positive definiteness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06966v1</guid>
      <category>math.OC</category>
      <category>math.RA</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liqun Qi, Chunfeng Cui, Yi Xu</dc:creator>
    </item>
    <item>
      <title>A Relaxed Control Problem With $L^\infty$ Cost and Jump Dynamics Motivated by Cyber Risks Insurance</title>
      <link>https://arxiv.org/abs/2511.07030</link>
      <description>arXiv:2511.07030v1 Announce Type: new 
Abstract: This paper has a double aim. One the one hand, we introduce a uni-nodal network model for cyber risks with firewalled edges and SIR intra-edge spreading. In connection to this, we formulate an insurance problem in which one seeks the running maximal reputation index against all control strategies of the companies represented by edges. On the other hand, we seek to characterize the value function with $L^\infty$ cost through linear programming techniques and more standard Hamilton-Jacobi integro-differential inequalities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.07030v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dan Goreac (LAMA), Juan Li, Pangbo Wang</dc:creator>
    </item>
    <item>
      <title>Augmented Lagrangian methods for fully convex composite optimization</title>
      <link>https://arxiv.org/abs/2511.07117</link>
      <description>arXiv:2511.07117v1 Announce Type: new 
Abstract: This paper is concerned with augmented Lagrangian methods for the treatment of fully convex composite optimization problems. We extend the classical relationship between augmented Lagrangian methods and the proximal point algorithm to the inexact and safeguarded scheme in order to state global primal-dual convergence results. Our analysis distinguishes the regular case, where a stationary minimizer exists, and the irregular case, where all minimizers are nonstationary. Furthermore, we suggest an elastic modification of the standard safeguarding scheme which preserves primal convergence properties while guaranteeing convergence of the dual sequence to a multiplier in the regular situation. Although important for nonconvex problems, the standard safeguarding mechanism leads to weaker convergence guarantees for convex problems than the classical augmented Lagrangian method. Our elastic safeguarding scheme combines the advantages of both while avoiding their shortcomings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.07117v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alberto De Marchi, Tim Hoheisel, Patrick Mehlitz</dc:creator>
    </item>
    <item>
      <title>Branch and price for nonlinear production-maintenance scheduling in complex machinery</title>
      <link>https://arxiv.org/abs/2511.07143</link>
      <description>arXiv:2511.07143v1 Announce Type: new 
Abstract: This paper proposes a mixed-integer nonlinear programming approach for joint scheduling of long-term maintenance decisions and short-term production for groups of complex machines with multiple interacting components. We introduce an abstract model where the production and the condition of machines are described by convex functions, allowing the model to be employed for various application areas fitting the scheme. We develop a branch-and-price algorithm to solve this problem, enhanced with acceleration techniques to find primal solutions and reduce the number of pricing rounds. An experimental comparison of this approach to solving the compact formulation directly demonstrates the benefit of the decomposition approach, in particular in larger instances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.07143v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jo\~ao Dion\'isio, Ambros Gleixner, Jo\~ao Pedro Pedroso, Ksenia Bestuzheva</dc:creator>
    </item>
    <item>
      <title>Minimization of eddy currents in permanent magnets of an electric machine with shape derivatives</title>
      <link>https://arxiv.org/abs/2511.07217</link>
      <description>arXiv:2511.07217v1 Announce Type: new 
Abstract: In this work we deal with the shape optimization of an electric machine considering time-dependent effects such as eddy currents. The considered electric machine is an interior permanent magnet synchronous machine and we minimize the average dissipated power due to the eddy currents in the magnets over a period of time corresponding to a rotation, while at the same time maximizing the average torque. Our approach is based on the computation of the shape derivative which -- beside the computation of a time discretization of time-dependent state problem -- also involves solving a a time discretization of a time-dependent adjoint problem. The challenge of this problem is related to the dependency of each one of the N time steps of the adjoint problem on two different time steps, due to the use of finite difference in the calculation of eddy current losses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.07217v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alessio Cesarano, Peter Gangl</dc:creator>
    </item>
    <item>
      <title>Passive and reciprocal linear time-and-space-invariant systems</title>
      <link>https://arxiv.org/abs/2511.07258</link>
      <description>arXiv:2511.07258v1 Announce Type: new 
Abstract: Reciprocity is a fundamental symmetry property observed across many physical domains, including acoustics, elasticity, electromagnetics, and thermodynamics. In systems and control theory, it provides key insights into the internal structure of linear time-invariant (LTI) systems and is closely linked to properties such as passivity, relaxation, and time-reversibility. This paper extends the concept of reciprocity to linear time-and-space-invariant (LTSI) systems, a class of infinite-dimensional systems with spatio-temporal dynamics. It is suggested that, analogously to the LTI case, combining the internal properties of reciprocity and (impedance) passivity entails physical state-space realizations. This is of particular relevance for infinite-dimensional systems, where issues of unboundedness can be detrimental to the well-posedness of the system. The results are motivated and illustrated with a physical example.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.07258v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Brayan M. Shali, Rodolphe Sepulchre</dc:creator>
    </item>
    <item>
      <title>Exact output tracking for the one-dimensional heat equation and applications to the interpolation problem in Gevrey classes of order 2</title>
      <link>https://arxiv.org/abs/2511.07326</link>
      <description>arXiv:2511.07326v1 Announce Type: new 
Abstract: This paper provides a complete characterization of the Dirichlet boundary outputs that can be exactly tracked in the one-dimensional heat equation with Neumann boundary control. The problem consists in describing the set of boundary traces generated by square-integrable controls over a finite or infinite time horizon. We show that these outputs form a precise functional space related to Gevrey regularity of order 2. In the infinite-time case, the trackable outputs are precisely those functions whose successive derivatives satisfy a weighted summability condition, which corresponds to specific Gevrey classes. For finite-time horizons, an additional compatibility condition involving the reachable space of the system provides a full characterization. The analysis relies on Fourier-Laplace transform, properties of Hardy spaces, the flatness method, and a new Plancherel-type theorem for Hilbert spaces of Gevrey functions. Beyond control theory, our results yield an optimal solution to the classical interpolation problem in Gevrey-$2$ classes, which improves results of Mitjagin on the optimal loss factor. The techniques developed here also extend to variants of the heat system with different boundary conditions or observation points.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.07326v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lucas Davron, Pierre Lissy</dc:creator>
    </item>
    <item>
      <title>Roundabout Constrained Convex Generators: A Unified Framework for Multiply-Connected Reachable Sets</title>
      <link>https://arxiv.org/abs/2511.07330</link>
      <description>arXiv:2511.07330v1 Announce Type: new 
Abstract: This paper introduces Roundabout Constrained Convex Generators (RCGs), a set representation framework for modeling multiply connected regions in control and verification applications. The RCG representation extends the constrained convex generators framework by incorporating an inner exclusion zone, creating sets with topological holes that naturally arise in collision avoidance and safety-critical control problems. We present two equivalent formulations: a set difference representation that provides geometric intuition and a unified parametric representation that facilitates computational implementation. The paper establishes closure properties under fundamental operations, including linear transformations, Minkowski sums, and intersections with convex generator sets. We derive special cases, including roundabout zonotopes and roundabout ellipsotopes, which offer computational advantages for specific norm selections. The framework maintains compatibility with existing optimization solvers while enabling the representation of non-convex feasible regions that were previously challenging to model efficiently.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.07330v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Peng Xie, Sabin Diaconescu, Florin Stoican, Amr Alanwar</dc:creator>
    </item>
    <item>
      <title>Universal Reduced-Operator Method and High-Order Global Curvature Bounds</title>
      <link>https://arxiv.org/abs/2511.07341</link>
      <description>arXiv:2511.07341v1 Announce Type: new 
Abstract: In this paper, we develop a new concept of Global Curvature Bound for an arbitrary nonlinear operator between abstract metric spaces. We use this notion to characterize the global complexity of high-order algorithms solving composite variational problems, which include convex minimization and min-max problems. We develop the new universal Reduced-Operator Method, which automatically achieves the fastest universal rate within our class, while our analysis does not need any specific assumptions about smoothness of the target nonlinear operator. Every step of our universal method of order $p \geq 1$ requires access to the $p$-th order derivative of the operator and the solution of a strictly monotone doubly regularized subproblem. For $p = 1$, this corresponds to computing the standard Jacobian matrix of the operator and solving a simple monotone subproblem, which can be handled using different methods of Convex Optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.07341v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nikita Doikov, Yurii Nesterov</dc:creator>
    </item>
    <item>
      <title>Policy Learning for Perturbance-wise Linear Quadratic Control Problem</title>
      <link>https://arxiv.org/abs/2511.07388</link>
      <description>arXiv:2511.07388v1 Announce Type: new 
Abstract: We study finite horizon linear quadratic control with additive noise in a perturbancewise framework that unifies the classical model, a constraint embedded affine policy class, and a distributionally robust formulation with a Wasserstein ambiguity set. Based on an augmented affine representation, we model feasibility as an affine perturbation and unknown noise as distributional perturbation from samples, thereby addressing constrained implementation and model uncertainty in a single scheme. First, we construct an implementable policy gradient method that accommodates nonzero noise means estimated from data. Second, we analyze its convergence under constant stepsizes chosen as simple polynomials of problem parameters, ensuring global decrease of the value function. Finally, numerical studies: mean variance portfolio allocation and dynamic benchmark tracking on real data, validating stable convergence and illuminating sensitivity tradeoffs across horizon length, trading cost intensity, state penalty scale, and estimation window.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.07388v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haoran Zhang, Wenhao Zhang, Xianping Wu</dc:creator>
    </item>
    <item>
      <title>Solving bilevel optimization via sequential minimax optimization</title>
      <link>https://arxiv.org/abs/2511.07398</link>
      <description>arXiv:2511.07398v1 Announce Type: new 
Abstract: In this paper we propose a sequential minimax optimization (SMO) method for solving a class of constrained bilevel optimization problems in which the lower-level part is a possibly nonsmooth convex optimization problem, while the upper-level part is a possibly nonconvex optimization problem. Specifically, SMO applies a first-order method to solve a sequence of minimax subproblems, which are obtained by employing a hybrid of modified augmented Lagrangian and penalty schemes on the bilevel optimization problems. Under suitable assumptions, we establish an operation complexity of $O(\varepsilon^{-7}\log\varepsilon^{-1})$ and $O(\varepsilon^{-6}\log\varepsilon^{-1})$, measured in terms of fundamental operations, for SMO in finding an $\varepsilon$-KKT solution of the bilevel optimization problems with merely convex and strongly convex lower-level objective functions, respectively. The latter result improves the previous best-known operation complexity by a factor of $\varepsilon^{-1}$. Preliminary numerical results demonstrate significantly superior computational performance compared to the recently developed first-order penalty method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.07398v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.ML</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhaosong Lu, Sanyou Mei</dc:creator>
    </item>
    <item>
      <title>A multi parallel mixed-model disassembly line and its balancing optimization for fuel vehicles and pure electric vehicles</title>
      <link>https://arxiv.org/abs/2511.05559</link>
      <description>arXiv:2511.05559v1 Announce Type: cross 
Abstract: With the continuous growth of the number of end-of-life vehicles and the rapid increase in the ownership of pure electric vehicles, the automobile disassembly industry is facing the challenge of transitioning from the traditional fuel vehicles to the mixed disassembly of fuel vehicles and pure electric vehicles. In order to cope with the uncertainty of recycling quantity and the demand of mixed-model disassembly of multiple vehicle types, this paper designs a multi-parallel mixed-model disassembly line (MPMDL), and constructs a corresponding mixed-integer planning model for the equilibrium optimization problem of this disassembly line with the optimization objectives of the minimum number of workstations, the minimum fatigue level of workers and the minimum energy consumption. Combining the differences in disassembly processes between fuel vehicles and pure electric vehicles, an improved non-dominated sorting multi-objective genetic algorithm (INSGA-III) based on the distribution of feasible solutions and dynamic search resource allocation is designed to solve this multi-objective dynamic balance optimization problem, and the two-stage dynamic adjustment strategy is adopted to realize the adaptive adjustment of the disassembly line under the uncertainty of the recycling quantity, and, recently, arithmetic validation is carried out. The results show that the proposed method can effectively improve the resource utilization efficiency, reduce energy consumption, alleviate the workers' load, and provide multiple high-quality disassembly solutions under the multi-objective trade-off. Compared with mainstream multi-objective optimization algorithms, the INSGA-III algorithm shows significant advantages in terms of solution quality, convergence and stability. This study provides a green, efficient and flexible solution for hybrid disassembly of fuel and pure electric vehicles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.05559v1</guid>
      <category>cs.NE</category>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qi Wang, Qingtao Liu, Jingxiang Lv, Xinji Wei, Jiongqi Guo, Panyu Yu, Yibo Guo</dc:creator>
    </item>
    <item>
      <title>Gradient Projection onto Historical Descent Directions for Communication-Efficient Federated Learning</title>
      <link>https://arxiv.org/abs/2511.05593</link>
      <description>arXiv:2511.05593v1 Announce Type: cross 
Abstract: Federated Learning (FL) enables decentralized model training across multiple clients while optionally preserving data privacy. However, communication efficiency remains a critical bottleneck, particularly for large-scale models. In this work, we introduce two complementary algorithms: ProjFL, designed for unbiased compressors, and ProjFL+EF, tailored for biased compressors through an Error Feedback mechanism. Both methods rely on projecting local gradients onto a shared client-server subspace spanned by historical descent directions, enabling efficient information exchange with minimal communication overhead. We establish convergence guarantees for both algorithms under strongly convex, convex, and non-convex settings. Empirical evaluations on standard FL classification benchmarks with deep neural networks show that ProjFL and ProjFL+EF achieve accuracy comparable to existing baselines while substantially reducing communication costs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.05593v1</guid>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arnaud Descours (UCBL), L\'eonard Deroose, Jan Ramon</dc:creator>
    </item>
    <item>
      <title>Conformal Prediction-Driven Adaptive Sampling for Digital Twins of Water Distribution Networks</title>
      <link>https://arxiv.org/abs/2511.05610</link>
      <description>arXiv:2511.05610v1 Announce Type: cross 
Abstract: Digital Twins (DTs) for Water Distribution Networks (WDNs) require accurate state estimation with limited sensors. Uniform sampling often wastes resources across nodes with different uncertainty. We propose an adaptive framework combining LSTM forecasting and Conformal Prediction (CP) to estimate node-wise uncertainty and focus sensing on the most uncertain points. Marginal CP is used for its low computational cost, suitable for real-time DTs. Experiments on Hanoi, Net3, and CTOWN show 33-34% lower demand error than uniform sampling at 40% coverage and maintain 89.4-90.2% empirical coverage with only 5-10% extra computation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.05610v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Mohammadhossein Homaei, Oscar Mogollon Gutierrez, Ruben Molano, Andres Caro, Mar Avila</dc:creator>
    </item>
    <item>
      <title>Network and Risk Analysis of Surety Bonds</title>
      <link>https://arxiv.org/abs/2511.05691</link>
      <description>arXiv:2511.05691v1 Announce Type: cross 
Abstract: Surety bonds are financial agreements between a contractor (principal) and obligee (project owner) to complete a project. However, most large-scale projects involve multiple contractors, creating a network and introducing the possibility of incomplete obligations to propagate and result in project failures. Typical models for risk assessment assume independent failure probabilities within each contractor. However, we take a network approach, modeling the contractor network as a directed graph where nodes represent contractors and project owners and edges represent contractual obligations with associated financial records. To understand risk propagation throughout the contractor network, we extend the celebrated Friedkin-Johnsen model and introduce a stochastic process to simulate principal failures across the network. From a theoretical perspective, we show that under natural monotonicity conditions on the contractor network, incorporating network effects leads to increases in both the average risk and the tail probability mass of the loss distribution (i.e. larger right-tail risk) for the surety organization. We further use data from a partnering insurance company to validate our findings, estimating an approximately 2% higher exposure when accounting for network effects.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.05691v1</guid>
      <category>q-fin.RM</category>
      <category>cs.SI</category>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tamara Broderick, Ali Jadbabaie, Vanessa Lin, Manuel Quintero, Arnab Sarker, Sean R. Sinclair</dc:creator>
    </item>
    <item>
      <title>The Complexity of Stackelberg Pricing Games</title>
      <link>https://arxiv.org/abs/2511.05700</link>
      <description>arXiv:2511.05700v1 Announce Type: cross 
Abstract: We consider Stackelberg pricing games, which are also known as bilevel pricing problems, or combinatorial price-setting problems. This family of problems consists of games between two players: the leader and the follower. There is a market that is partitioned into two parts: the part of the leader and the part of the leader's competitors. The leader controls one part of the market and can freely set the prices for products. By contrast, the prices of the competitors' products are fixed and known in advance. The follower, then, needs to solve a combinatorial optimization problem in order to satisfy their own demands, while comparing the leader's offers to the offers of the competitors. Therefore, the leader has to hit the intricate balance of making an attractive offer to the follower, while at the same time ensuring that their own profit is maximized.
  Pferschy, Nicosia, Pacifici, and Schauer considered the Stackelberg pricing game where the follower solves a knapsack problem. They raised the question whether this problem is complete for the second level of the polynomial hierarchy, i.e., $\Sigma^p_2$-complete. The same conjecture was also made by B\"ohnlein, Schaudt, and Schauer. In this paper, we positively settle this conjecture. Moreover, we show that this result holds actually in a much broader context: The Stackelberg pricing game is $\Sigma^p_2$-complete for over 50 NP-complete problems, including most classics such as TSP, vertex cover, clique, subset sum, etc. This result falls in line of recent meta-theorems about higher complexity in the polynomial hierarchy by Gr\"une and Wulf.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.05700v1</guid>
      <category>cs.GT</category>
      <category>cs.CC</category>
      <category>math.CO</category>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christoph Gr\"une, Dorothee Henke, Eva Rotenberg, Lasse Wulf</dc:creator>
    </item>
    <item>
      <title>TOPSIS-like metaheuristic for LABS problem</title>
      <link>https://arxiv.org/abs/2511.05778</link>
      <description>arXiv:2511.05778v1 Announce Type: cross 
Abstract: This paper presents the application of socio-cognitive mutation operators inspired by the TOPSIS method to the Low Autocorrelation Binary Sequence (LABS) problem. Traditional evolutionary algorithms, while effective, often suffer from premature convergence and poor exploration-exploitation balance. To address these challenges, we introduce socio-cognitive mutation mechanisms that integrate strategies of following the best solutions and avoiding the worst. By guiding search agents to imitate high-performing solutions and avoid poor ones, these operators enhance both solution diversity and convergence efficiency. Experimental results demonstrate that TOPSIS-inspired mutation outperforms the base algorithm in optimizing LABS sequences. The study highlights the potential of socio-cognitive learning principles in evolutionary computation and suggests directions for further refinement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.05778v1</guid>
      <category>cs.NE</category>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/978-3-032-03705-3_24</arxiv:DOI>
      <arxiv:journal_reference>Artificial Intelligence and Soft Computing - ICAISC 2025, Lecture Notes in Computer Science, 15948, 280-291</arxiv:journal_reference>
      <dc:creator>Aleksandra Urba\'nczyk, Bogumi{\l}a Papiernik, Piotr Magiera, Piotr Urba\'nczyk, Aleksander Byrski</dc:creator>
    </item>
    <item>
      <title>Equilibrium Portfolio Selection under Utility-Variance Analysis of Log Returns in Incomplete Markets</title>
      <link>https://arxiv.org/abs/2511.05861</link>
      <description>arXiv:2511.05861v1 Announce Type: cross 
Abstract: This paper investigates a time-inconsistent portfolio selection problem in the incomplete mar ket model, integrating expected utility maximization with risk control. The objective functional
  balances the expected utility and variance on log returns, giving rise to time inconsistency and
  motivating the search of a time-consistent equilibrium strategy. We characterize the equilibrium
  via a coupled quadratic backward stochastic differential equation (BSDE) system and establish
  the existence theory in two special cases: (i) two Brownian motions driven the price dynamics
  and the factor process are independent with $\rho = 0$; (ii) the trading strategy is constrained to
  be bounded. For the general case with correlation coefficient $\rho \neq 0$, we introduce the notion
  of an approximate time-consistent equilibrium. By employing the solution structure from the
  equilibrium in the case $\rho = 0$, we can construct an approximate time-consistent equilibrium in
  the general case with an error of order $O(\rho^2)$. Numerical examples and financial insights based
  on deep learning algorithms are also presented.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.05861v1</guid>
      <category>q-fin.PM</category>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yue Cao, Zongxia Liang, Sheng Wang, Xiang Yu</dc:creator>
    </item>
    <item>
      <title>Product-Form Distribution and Reversibility of Inhomogeneous Symmetric Simple Exclusion Process with Open Boundaries</title>
      <link>https://arxiv.org/abs/2511.05881</link>
      <description>arXiv:2511.05881v1 Announce Type: cross 
Abstract: We consider an inhomogeneous symmetric simple exclusion process on a one-dimensional lattice with open boundary conditions. The time scale is continuous. Particles of different types arrive to the utmost left and the utmost right site. If a particle is in a site that is neither the utmost left site nor the utmost right site, then the particle moves onto one site to the left or to the right. If a particle is either in the utmost left site or the utmost right site, then the particle leaves the system or moves onto one cell to the right or to the left, respectively. An arrival or a transfer of particle is possible only to a vacant site. The rate of arrival, exit or movement of a particle depends on its type and does not depend on the site from that the particle arrives or exits and on the direction the movement. The stationary distribution of the system states probabilities has been found. This distribution turns out to be multiplicative in the sense that the probability of the site state does not depend on the states of the other sites in the stationary mode, and the steady probability of any state of the system is equal to the product of the site states steady probabilities, and the probability of site ocupancy is the same as the server occupancy probability for M/G/1/0 loss system. We have found the arrival rate and the average sojourn time have been found. We have proved the reversibility of the process in time under the additional condition that the rate of arrival of a particle of prescribed type is equal to the rate of this type particle departure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.05881v1</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marina V. Yashina, Alexander G. Tatashev</dc:creator>
    </item>
    <item>
      <title>Hybrid second-order gradient histogram based global low-rank sparse regression for robust face recognition</title>
      <link>https://arxiv.org/abs/2511.05893</link>
      <description>arXiv:2511.05893v1 Announce Type: cross 
Abstract: Low-rank sparse regression models have been widely applied in the field of face recognition. To further address the challenges caused by complex occlusions and illumination variations, this paper proposes a Hybrid Second-Order Gradient Histogram based Global Low-Rank Sparse Regression (H2H-GLRSR) model. Specifically, a novel feature descriptor called the Hybrid Second-Order Gradient Histogram (H2H) is first designed to more effectively characterize the local structural features of facial images. Then, this descriptor is integrated with the Sparse Regularized Nuclear Norm based Matrix Regression (SR$\_$NMR). Moreover, a global low-rank constraint is imposed on the residual matrix, enabling the model to better capture the global correlations inherent in structured noise. Experimental results demonstrate that the proposed method significantly outperforms existing regression-based classification approaches under challenging scenarios involving occlusions, illumination changes, and unconstrained environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.05893v1</guid>
      <category>cs.CV</category>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongxia Li, Ying Ji, Yongxin Dong, Yuehua Feng</dc:creator>
    </item>
    <item>
      <title>The Schr\"odinger Bridge Problem for Jump Diffusions with Regime Switching</title>
      <link>https://arxiv.org/abs/2511.06079</link>
      <description>arXiv:2511.06079v1 Announce Type: cross 
Abstract: The Schr\"odinger bridge problem (SBP) aims at finding the measure $\hat{\mathbf{P}}$ on a certain path space which possesses the desired state-space distributions $\rho_0$ at time $0$ and $\rho_T$ at time $T$ while minimizing the KL divergence from a reference path measure $\mathbf{R}$. This work focuses on the SBP in the case when $\mathbf{R}$ is the path measure of a jump diffusion with regime switching, which is a Markov process that combines the dynamics of a jump diffusion with interspersed discrete events representing changing environmental states. To the best of our knowledge, the SBP in such a setting has not been previously studied.
  In this paper, we conduct a comprehensive analysis of the dynamics of the SBP solution $\hat{\mathbf{P}}$ in the regime-switching jump-diffusion setting. In particular, we show that $\hat{\mathbf{P}}$ is again a path measure of a regime-switching jump diffusion; under proper assumptions, we establish various properties of $\hat{\mathbf{P}}$ from both a stochastic calculus perspective and an analytic viewpoint. In addition, as an demonstration of the general theory developed in this work, we examine a concrete unbalanced SBP (uSBP) from the angle of a regime-switching SBP, where we also obtain novel results in the realm of uSBP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06079v1</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrei Zlotchevski, Linan Chen</dc:creator>
    </item>
    <item>
      <title>A Multi-Criterion Approach to Smart EV Charging with CO2 Emissions and Cost Minimization</title>
      <link>https://arxiv.org/abs/2511.06131</link>
      <description>arXiv:2511.06131v1 Announce Type: cross 
Abstract: In this work, we propose a novel three-step framework for smart electric vehicle (EV) charging that jointly minimizes charging costs and CO2 emissions. Drawing inspiration from the classical Unit Commitment Problem (UCP), we first design a linear model to determine the optimal power generation mix over a 24-hour horizon, using real-world data from Vietnam, a country with a highly carbon intensive energy system. This allows us to estimate time-varying CO2 emissions and translate them into an emission cost signal. We then incorporate this environmental cost into a smart charging optimization model, formulated as a linear program (LP). Numerical simulations confirm that the proposed strategy significantly outperforms a baseline First-In-First-Served (FIFS) approach, achieving notable reductions in both CO2 emissions and charging costs also compared to another optimization approach. The results demonstrate the potential of this multiobjective optimization framework to support more sustainable and cost-efficient EV charging strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06131v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Luca Ambrosino, Khai Manh Nguyen, Minh Binh Vu, Riadh Zorgati, Laurent El Ghaoui, Giuseppe C. Calafiore</dc:creator>
    </item>
    <item>
      <title>Real-Time Bundle Adjustment for Ultra-High-Resolution UAV Imagery Using Adaptive Patch-Based Feature Tracking</title>
      <link>https://arxiv.org/abs/2511.06152</link>
      <description>arXiv:2511.06152v1 Announce Type: cross 
Abstract: Real-time processing of UAV imagery is crucial for applications requiring urgent geospatial information, such as disaster response, where rapid decision-making and accurate spatial data are essential. However, processing high-resolution imagery in real time presents significant challenges due to the computational demands of feature extraction, matching, and bundle adjustment (BA). Conventional BA methods either downsample images, sacrificing important details, or require extensive processing time, making them unsuitable for time-critical missions. To overcome these limitations, we propose a novel real-time BA framework that operates directly on fullresolution UAV imagery without downsampling. Our lightweight, onboard-compatible approach divides each image into user-defined patches (e.g., NxN grids, default 150x150 pixels) and dynamically tracks them across frames using UAV GNSS/IMU data and a coarse, globally available digital surface model (DSM). This ensures spatial consistency for robust feature extraction and matching between patches. Overlapping relationships between images are determined in real time using UAV navigation system, enabling the rapid selection of relevant neighbouring images for localized BA. By limiting optimization to a sliding cluster of overlapping images, including those from adjacent flight strips, the method achieves real-time performance while preserving the accuracy of global BA. The proposed algorithm is designed for seamless integration into the DLR Modular Aerial Camera System (MACS), supporting largearea mapping in real time for disaster response, infrastructure monitoring, and coastal protection. Validation on MACS datasets with 50MP images demonstrates that the method maintains precise camera orientations and high-fidelity mapping across multiple strips, running full bundle adjustment in under 2 seconds without GPU acceleration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06152v1</guid>
      <category>cs.CV</category>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.5194/isprs-annals-X-2-W2-2025-73-2025</arxiv:DOI>
      <dc:creator>Selim Ahmet Iz, Francesco Nex, Norman Kerle, Henry Meissner, Ralf Berger</dc:creator>
    </item>
    <item>
      <title>Non-Radial Solution Structures for Quasilinear Hamilton--Jacobi--Bellman Equations in Bounded Settings</title>
      <link>https://arxiv.org/abs/2511.06277</link>
      <description>arXiv:2511.06277v1 Announce Type: cross 
Abstract: We study quasilinear Hamilton--Jacobi--Bellman equations on bounded smooth convex domains. We show that the quasilinear Hamilton--Jacobi--Bellman equations arise naturally from stochastic optimal control problems with exit-time costs. The PDE is obtained via dynamic programming applied to controlled It\^{o} diffusions, providing both a probabilistic interpretation and a rigorous derivation. Our result establishes existence and uniqueness of positive classical solutions under sub-quadratic growth conditions on the source term. The constructive proofs, based on monotone iteration and barrier techniques, also provide a framework for algorithmic implementation with applications in production planning and image restoration. We provide complete detailed proofs with rigorous estimates and establish the connection to stochastic control theory through the dynamic programming principle.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06277v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dragos-Patru Covei</dc:creator>
    </item>
    <item>
      <title>Coherency Analysis in Nonlinear Heterogeneous Power Networks: A Blended Dynamics Approach</title>
      <link>https://arxiv.org/abs/2511.06306</link>
      <description>arXiv:2511.06306v1 Announce Type: cross 
Abstract: Power system coherency refers to the phenomenon that machines in a power network exhibit similar frequency responses after disturbances, and is foundational for model reduction and control design. Despite abundant empirical observations, the understanding of coherence in complex power networks remains incomplete where the dynamics could be highly heterogeneous, nonlinear, and increasingly affected by persistent disturbances such as renewable energy fluctuations. To bridge this gap, this paper extends the blended dynamics approach, originally rooted in consensus analysis of multi-agent systems, to develop a novel coherency analysis in power networks. We show that the frequency responses of coherent machines coupled by nonlinear power flow can be approximately represented by the blended dynamics, which is a weighted average of nonlinear heterogeneous nodal dynamics, even under time-varying disturbances. Specifically, by developing novel bounds on the difference between the trajectories of nodal dynamics and the blended dynamics, we identify two key factors -- either high network connectivity or small time-variation rate of disturbances -- that contribute to coherence. They enable the nodal frequencies to rapidly approach the blended-dynamics trajectory from arbitrary initial state. Furthermore, they ensure the frequencies closely follow this trajectory in the long term, even when the system does not settle to an equilibrium. These insights contribute to the understanding of power system coherency and are further supported by simulation results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06306v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yixuan Liu, Yingzhu Liu, Pengcheng You</dc:creator>
    </item>
    <item>
      <title>Scalable Verification of Neural Control Barrier Functions Using Linear Bound Propagation</title>
      <link>https://arxiv.org/abs/2511.06341</link>
      <description>arXiv:2511.06341v1 Announce Type: cross 
Abstract: Control barrier functions (CBFs) are a popular tool for safety certification of nonlinear dynamical control systems. Recently, CBFs represented as neural networks have shown great promise due to their expressiveness and applicability to a broad class of dynamics and safety constraints. However, verifying that a trained neural network is indeed a valid CBF is a computational bottleneck that limits the size of the networks that can be used. To overcome this limitation, we present a novel framework for verifying neural CBFs based on piecewise linear upper and lower bounds on the conditions required for a neural network to be a CBF. Our approach is rooted in linear bound propagation (LBP) for neural networks, which we extend to compute bounds on the gradients of the network. Combined with McCormick relaxation, we derive linear upper and lower bounds on the CBF conditions, thereby eliminating the need for computationally expensive verification procedures. Our approach applies to arbitrary control-affine systems and a broad range of nonlinear activation functions. To reduce conservatism, we develop a parallelizable refinement strategy that adaptively refines the regions over which these bounds are computed. Our approach scales to larger neural networks than state-of-the-art verification procedures for CBFs, as demonstrated by our numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06341v1</guid>
      <category>cs.LG</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nikolaus Vertovec, Frederik Baymler Mathiesen, Thom Badings, Luca Laurenti, Alessandro Abate</dc:creator>
    </item>
    <item>
      <title>DyKAF: Dynamical Kronecker Approximation of the Fisher Information Matrix for Gradient Preconditioning</title>
      <link>https://arxiv.org/abs/2511.06477</link>
      <description>arXiv:2511.06477v1 Announce Type: cross 
Abstract: Recently, optimizers that explicitly treat weights as matrices, rather than flattened vectors, have demonstrated their effectiveness. This perspective naturally leads to structured approximations of the Fisher matrix as preconditioners, where the matrix view induces a Kronecker-factorized form that enables memory-efficient representation. However, constructing such approximations both efficiently and accurately remains an open challenge, since obtaining the optimal factorization is resource-intensive and practical methods therefore rely on heuristic design choices. In this work, we introduce a novel approach that leverages projector-splitting integrators to construct effective preconditioners. Our optimizer, DyKAF (Dynamical Kronecker Approximation of the Fisher Matrix), consistently improves the Fisher matrix approximation quality. Experiments on large language model pre-training and fine-tuning demonstrate that DyKAF outperforms existing optimizers across a range of evaluation metrics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06477v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nikolay Yudin, Ekaterina Grishina, Andrey Veprikov, Alexandr Beznosikov, Maxim Rakhuba</dc:creator>
    </item>
    <item>
      <title>Bridging Theory and Practice: A Stochastic Learning-Optimization Model for Resilient Automotive Supply Chains</title>
      <link>https://arxiv.org/abs/2511.06479</link>
      <description>arXiv:2511.06479v1 Announce Type: cross 
Abstract: Supply chain disruptions and volatile demand pose significant challenges to the UK automotive industry, which relies heavily on Just-In-Time (JIT) manufacturing. While qualitative studies highlight the potential of integrating Artificial Intelligence (AI) with traditional optimization, a formal, quantitative demonstration of this synergy is lacking. This paper introduces a novel stochastic learning-optimization framework that integrates Bayesian inference with inventory optimization for supply chain management (SCM). We model a two-echelon inventory system subject to stochastic demand and supply disruptions, comparing a traditional static optimization policy against an adaptive policy where Bayesian learning continuously updates parameter estimates to inform stochastic optimization. Our simulations over 365 periods across three operational scenarios demonstrate that the integrated approach achieves 7.4\% cost reduction in stable environments and 5.7\% improvement during supply disruptions, while revealing important limitations during sudden demand shocks due to the inherent conservatism of Bayesian updating. This work provides mathematical validation for practitioner observations and establishes a formal framework for understanding AI-driven supply chain resilience, while identifying critical boundary conditions for successful implementation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06479v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Muhammad Shahnawaz, Adeel Safder</dc:creator>
    </item>
    <item>
      <title>Optimistic Online-to-Batch Conversions for Accelerated Convergence and Universality</title>
      <link>https://arxiv.org/abs/2511.06597</link>
      <description>arXiv:2511.06597v1 Announce Type: cross 
Abstract: In this work, we study offline convex optimization with smooth objectives, where the classical Nesterov's Accelerated Gradient (NAG) method achieves the optimal accelerated convergence. Extensive research has aimed to understand NAG from various perspectives, and a recent line of work approaches this from the viewpoint of online learning and online-to-batch conversion, emphasizing the role of optimistic online algorithms for acceleration. In this work, we contribute to this perspective by proposing novel optimistic online-to-batch conversions that incorporate optimism theoretically into the analysis, thereby significantly simplifying the online algorithm design while preserving the optimal convergence rates. Specifically, we demonstrate the effectiveness of our conversions through the following results: (i) when combined with simple online gradient descent, our optimistic conversion achieves the optimal accelerated convergence; (ii) our conversion also applies to strongly convex objectives, and by leveraging both optimistic online-to-batch conversion and optimistic online algorithms, we achieve the optimal accelerated convergence rate for strongly convex and smooth objectives, for the first time through the lens of online-to-batch conversion; (iii) our optimistic conversion can achieve universality to smoothness -- applicable to both smooth and non-smooth objectives without requiring knowledge of the smoothness coefficient -- and remains efficient as non-universal methods by using only one gradient query in each iteration. Finally, we highlight the effectiveness of our optimistic online-to-batch conversions by a precise correspondence with NAG.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06597v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yu-Hu Yan, Peng Zhao, Zhi-Hua Zhou</dc:creator>
    </item>
    <item>
      <title>Wireless Sensor Networks Nodes Clustering and Optimization Based on Fuzzy C-Means and Water Strider Algorithms</title>
      <link>https://arxiv.org/abs/2511.06735</link>
      <description>arXiv:2511.06735v1 Announce Type: cross 
Abstract: Wireless sensor networks (WSNs) face critical challenges in energy management and network lifetime optimization due to limited battery resources and communication overhead. This study introduces a novel hybrid clustering protocol that integrates the Water Strider Algorithm (WSA) with Fuzzy C-Means (FCM) clustering to achieve superior energy efficiency and network longevity. The proposed WSA-FCM method employs WSA for global optimization of cluster-head positions and FCM for refined node membership assignment with fuzzy boundaries. Through extensive experimentation across networks of 200-800 nodes with 10 independent simulation runs, the method demonstrates significant improvements: First Node Death (FND) delayed by 16.1% ($678\pm12$ vs $584\pm18$ rounds), Last Node Death (LND) extended by 11.9% ($1,262\pm8$ vs $1,128\pm11$ rounds), and 37.4% higher residual energy retention ($5.47\pm0.09$ vs $3.98\pm0.11$ J) compared to state-of-the-art hybrid methods. Intra-cluster distances are reduced by 19.4% with statistical significance (p &lt; 0.001). Theoretical analysis proves convergence guarantees and complexity bounds of $O(n\times c\times T)$, while empirical scalability analysis demonstrates near-linear scaling behaviour. The method outperforms recent hybrid approaches including MOALO-FCM, MSSO-MST, Fuzzy+HHO, and GWO-FCM across all performance metrics with rigorous statistical validation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06735v1</guid>
      <category>cs.DC</category>
      <category>eess.SP</category>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <arxiv:DOI>10.22266/ijies2025.1231.37</arxiv:DOI>
      <arxiv:journal_reference>International Journal of Intelligent Engineering and Systems, Vol.18, No.11, 2025, pp. 598-612</arxiv:journal_reference>
      <dc:creator>Raya Majid Alsharfa, Mahmood Mohassel Feghhi, Majid Hameed Majeed</dc:creator>
    </item>
    <item>
      <title>Transforming Strategic Games into Biform Games: Applications in Allocation Mechanisms and Green Technology Investment</title>
      <link>https://arxiv.org/abs/2511.06858</link>
      <description>arXiv:2511.06858v1 Announce Type: cross 
Abstract: As Aumann stated, cooperation and non-cooperation are different ways of viewing the same game, with the main difference being whether players can reach a binding cooperative agreement. In the real world, many games often coexist competition and cooperation. Based on the above reasons, we propose a method to transform strategic games into a biform game model, which retains the characteristics of cooperative games while considering the ultimate goal of players to maximize their own interests. Furthermore, based on this biform game model, we analyze the impact of two different distribution methods, namely marginalism and egalitarianism, on the game results. As an application, we analyze how food producers seek maximum profits through cooperative pricing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06858v1</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiang Shuwen, Luo Enquan, Yang Yanlong</dc:creator>
    </item>
    <item>
      <title>A Convergent Algorithm Based on Deterministic Approximation for a Large Class of Regime-Switching Generalized Stochastic Game-Theoretic Riccati Differential Equations</title>
      <link>https://arxiv.org/abs/2511.06920</link>
      <description>arXiv:2511.06920v1 Announce Type: cross 
Abstract: This paper proposes a novel iterative algorithm to compute the stabilizing solution of regime-switching stochastic game-theoretic Riccati differential equations with periodic coefficients. The method decomposes the original complex stochastic problem into a sequence of deterministic subproblems. By sequentially solving for the minimal solutions of the Riccati differential equations in each subproblem, a sequence of matrix-valued functions is constructed. Leveraging the comparison theorem, the monotonicity, boundedness, and convergence of the iterative sequence are rigorously proven. Numerical experiments verifies algorithm effectiveness and stability. To the best of our knowledge, this is the first general computational approach developed for this class of problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06920v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yiyuan Wang</dc:creator>
    </item>
    <item>
      <title>Analysis of Traffic Congestion in North Campus, Delhi University Using Continuous Time Models</title>
      <link>https://arxiv.org/abs/2511.06921</link>
      <description>arXiv:2511.06921v1 Announce Type: cross 
Abstract: This project investigates traffic congestion within North Campus, Delhi University (DU), using continuous time simulations implemented in UXSim to model vehicle movement and interaction. The study focuses on several key intersections, identifies recurring congestion points, and evaluates the effectiveness of conventional traffic management measures. Implementing signal timing optimization and modest intersection reconfiguration resulted in measurable improvements in simulated traffic flow. The results provide practical insights for local traffic management and illustrate the value of continuous time simulation methods for informing short-term interventions and longer-term planning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06921v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Siddhartha Mahajan, Harsh Raj, Sonam Tanwar</dc:creator>
    </item>
    <item>
      <title>On the Redundant Distributed Observability of Mixed Traffic Transportation Systems</title>
      <link>https://arxiv.org/abs/2511.06950</link>
      <description>arXiv:2511.06950v1 Announce Type: cross 
Abstract: In this paper, the problem of distributed state estimation of human-driven vehicles (HDVs) by connected autonomous vehicles (CAVs) is investigated in mixed traffic transportation systems. Toward this, a distributed observable state-space model is derived, which paves the way for estimation and observability analysis of HDVs in mixed traffic scenarios. In this direction, first, we obtain the condition on the network topology to satisfy the distributed observability, i.e., the condition such that each HDV state is observable to every CAV via information-exchange over the network. It is shown that strong connectivity of the network, along with the proper design of the observer gain, is sufficient for this. A distributed observer is then designed by locally sharing estimates/observations of each CAV with its neighborhood. Second, in case there exist faulty sensors or unreliable observation data, we derive the condition for redundant distributed observability as a $q$-node/link-connected network design. This redundancy is achieved by extra information-sharing over the network and implies that a certain number of faulty sensors and unreliable links can be isolated/removed without losing the observability. Simulation results are provided to illustrate the effectiveness of the proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06950v1</guid>
      <category>eess.SY</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>M. Doostmohammadian, U. A. Khan, N. Meskin</dc:creator>
    </item>
    <item>
      <title>A Provably-Correct and Robust Convex Model for Smooth Separable NMF</title>
      <link>https://arxiv.org/abs/2511.07109</link>
      <description>arXiv:2511.07109v1 Announce Type: cross 
Abstract: Nonnegative matrix factorization (NMF) is a linear dimensionality reduction technique for nonnegative data, with applications such as hyperspectral unmixing and topic modeling. NMF is a difficult problem in general (NP-hard), and its solutions are typically not unique. To address these two issues, additional constraints or assumptions are often used. In particular, separability assumes that the basis vectors in the NMF are equal to some columns of the input matrix. In that case, the problem is referred to as separable NMF (SNMF) and can be solved in polynomial-time with robustness guarantees, while identifying a unique solution. However, in real-world scenarios, due to noise or variability, multiple data points may lie near the basis vectors, which SNMF does not leverage. In this work, we rely on the smooth separability assumption, which assumes that each basis vector is close to multiple data points. We explore the properties of the corresponding problem, referred to as smooth SNMF (SSNMF), and examine how it relates to SNMF and orthogonal NMF. We then propose a convex model for SSNMF and show that it provably recovers the sought-after factors, even in the presence of noise. We finally adapt an existing fast gradient method to solve this convex model for SSNMF, and show that it compares favorably with state-of-the-art methods on both synthetic and hyperspectral datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.07109v1</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>eess.SP</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junjun Pan, Valentin Leplat, Michael Ng, Nicolas Gillis</dc:creator>
    </item>
    <item>
      <title>SMiLE: Provably Enforcing Global Relational Properties in Neural Networks</title>
      <link>https://arxiv.org/abs/2511.07208</link>
      <description>arXiv:2511.07208v1 Announce Type: cross 
Abstract: Artificial Intelligence systems are increasingly deployed in settings where ensuring robustness, fairness, or domain-specific properties is essential for regulation compliance and alignment with human values. However, especially on Neural Networks, property enforcement is very challenging, and existing methods are limited to specific constraints or local properties (defined around datapoints), or fail to provide full guarantees. We tackle these limitations by extending SMiLE, a recently proposed enforcement framework for NNs, to support global relational properties (defined over the entire input space). The proposed approach scales well with model complexity, accommodates general properties and backbones, and provides full satisfaction guarantees. We evaluate SMiLE on monotonicity, global robustness, and individual fairness, on synthetic and real data, for regression and classification tasks. Our approach is competitive with property-specific baselines in terms of accuracy and runtime, and strictly superior in terms of generality and level of guarantees. Overall, our results emphasize the potential of the SMiLE framework as a platform for future research and applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.07208v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Matteo Francobaldi, Michele Lombardi, Andrea Lodi</dc:creator>
    </item>
    <item>
      <title>Identification of Source Terms in the Ginzburg-Landau Equation from Final Data</title>
      <link>https://arxiv.org/abs/2511.07345</link>
      <description>arXiv:2511.07345v1 Announce Type: cross 
Abstract: In this article, we study an inverse problem consisting in the identification of a space-time dependent source term in the Ginzburg-Landau equation from final-time observations. We adopt a weak-solution framework and analyze Tikhonov's functional, deriving an explicit gradient formula via an adjoint system and proving its Lipschitz continuity. We then establish existence and uniqueness results for quasi-solutions, and validate the theory with numerical experiments based on iterative methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.07345v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Roberto Morales,  Javier-Ram\'irez-Ganga</dc:creator>
    </item>
    <item>
      <title>Transformers Provably Learn Chain-of-Thought Reasoning with Length Generalization</title>
      <link>https://arxiv.org/abs/2511.07378</link>
      <description>arXiv:2511.07378v1 Announce Type: cross 
Abstract: The ability to reason lies at the core of artificial intelligence (AI), and challenging problems usually call for deeper and longer reasoning to tackle. A crucial question about AI reasoning is whether models can extrapolate learned reasoning patterns to solve harder tasks with longer chain-of-thought (CoT). In this work, we present a theoretical analysis of transformers learning on synthetic state-tracking tasks with gradient descent. We mathematically prove how the algebraic structure of state-tracking problems governs the degree of extrapolation of the learned CoT. Specifically, our theory characterizes the length generalization of transformers through the mechanism of attention concentration, linking the retrieval robustness of the attention layer to the state-tracking task structure of long-context reasoning. Moreover, for transformers with limited reasoning length, we prove that a recursive self-training scheme can progressively extend the range of solvable problem lengths. To our knowledge, we provide the first optimization guarantee that constant-depth transformers provably learn $\mathsf{NC}^1$-complete problems with CoT, significantly going beyond prior art confined in $\mathsf{TC}^0$, unless the widely held conjecture $\mathsf{TC}^0 \neq \mathsf{NC}^1$ fails. Finally, we present a broad set of experiments supporting our theoretical results, confirming the length generalization behaviors and the mechanism of attention concentration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.07378v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yu Huang, Zixin Wen, Aarti Singh, Yuejie Chi, Yuxin Chen</dc:creator>
    </item>
    <item>
      <title>Wasserstein-Cram\'er-Rao Theory of Unbiased Estimation</title>
      <link>https://arxiv.org/abs/2511.07414</link>
      <description>arXiv:2511.07414v1 Announce Type: cross 
Abstract: The quantity of interest in the classical Cram\'er-Rao theory of unbiased estimation (e.g., the Cram\'er-Rao lower bound, its exact attainment for exponential families, and asymptotic efficiency of maximum likelihood estimation) is the variance, which represents the instability of an estimator when its value is compared to the value for an independently-sampled data set from the same distribution. In this paper we are interested in a quantity which represents the instability of an estimator when its value is compared to the value for an infinitesimal additive perturbation of the original data set; we refer to this as the "sensitivity" of an estimator. The resulting theory of sensitivity is based on the Wasserstein geometry in the same way that the classical theory of variance is based on the Fisher-Rao (equivalently, Hellinger) geometry, and this insight allows us to determine a collection of results which are analogous to the classical case: a Wasserstein-Cram\'er-Rao lower bound for the sensitivity of any unbiased estimator, a characterization of models in which there exist unbiased estimators achieving the lower bound exactly, and some concrete results that show that the Wasserstein projection estimator achieves the lower bound asymptotically. We use these results to treat many statistical examples, sometimes revealing new optimality properties for existing estimators and other times revealing entirely new estimators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.07414v1</guid>
      <category>math.ST</category>
      <category>math.OC</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicol\'as Garc\'ia Trillos, Adam Quinn Jaffe, Bodhisattva Sen</dc:creator>
    </item>
    <item>
      <title>Last-Iterate Convergence of Adaptive Riemannian Gradient Descent for Equilibrium Computation</title>
      <link>https://arxiv.org/abs/2306.16617</link>
      <description>arXiv:2306.16617v2 Announce Type: replace 
Abstract: Equilibrium computation on Riemannian manifolds provides a unifying framework for numerous problems in machine learning and data analytics. One of the simplest yet most fundamental methods is Riemannian gradient descent (RGD). While its Euclidean counterpart has been extensively studied, it remains unclear how the manifold curvature affects RGD in game-theoretic settings. This paper addresses this gap by establishing new convergence results for \textit{geodesic strongly monotone} games. Our key result shows that RGD attains last-iterate linear convergence in a \textit{geometry-agnostic} fashion, a key property for applications in machine learning. We extend this guarantee to stochastic and adaptive variants -- SRGD and FARGD -- and establish that: (i) the sample complexity of SRGD is geometry-agnostic and optimal with respect to noise; (ii) FARGD matches the convergence rate of its non-adaptive counterpart up to constant factors, while avoiding reliance on the condition number. Overall, this paper presents the first geometry-agnostic last-iterate convergence analysis for games beyond the Euclidean settings, underscoring the surprising power of RGD -- despite its simplicity -- in solving a wide spectrum of machine learning problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.16617v2</guid>
      <category>math.OC</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yang Cai, Michael I. Jordan, Tianyi Lin, Argyris Oikonomou, Emmanouil-Vasileios Vlatakis-Gkaragkounis</dc:creator>
    </item>
    <item>
      <title>Implementing a unified solver for nonlinearly constrained optimization</title>
      <link>https://arxiv.org/abs/2406.13454</link>
      <description>arXiv:2406.13454v2 Announce Type: replace 
Abstract: SQP and interior-point methods (also referred to as Lagrange-Newton methods) typically share key algorithmic components, such as strategies for computing descent directions and mechanisms that promote global convergence. Building on this insight, we introduce a unifying framework with eight building blocks that abstracts the workflows of Lagrange-Newton methods. We then present Uno, a modular C++ solver that implements our unifying framework and allows the automatic combination of a wide range of strategies with no programming effort from the user. Uno is meant to (1) organize mathematical optimization strategies into a coherent hierarchy; (2) offer a wide range of efficient and robust methods that can be compared for a given instance; (3) enable researchers to experiment with novel optimization strategies; and (4) reduce the cost of development and maintenance of multiple optimization solvers. Uno's software design allows user to compose new customized solvers for emerging optimization areas such as robust optimization or optimization problems with complementarity constraints, while building on reliable nonlinear optimization techniques. We demonstrate that Uno is highly competitive against state-of-the-art solvers filterSQP, IPOPT, SNOPT, MINOS, LANCELOT, LOQO, and CONOPT on a subset of 429 small problems from the CUTE collection. Uno is available as open-source software under the MIT license at https://github.com/cvanaret/Uno and via its C, Julia, Python, Fortran, and AMPL interfaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.13454v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Charlie Vanaret, Sven Leyffer</dc:creator>
    </item>
    <item>
      <title>Methods for Optimization Problems with Markovian Stochasticity and Non-Euclidean Geometry</title>
      <link>https://arxiv.org/abs/2408.01848</link>
      <description>arXiv:2408.01848v2 Announce Type: replace 
Abstract: This paper examines a variety of classical optimization problems, including well-known minimization tasks and more general variational inequalities. We consider a stochastic formulation of these problems, and unlike most previous work, we take into account the complex Markov nature of the noise. We also consider the geometry of the problem in an arbitrary non-Euclidean setting, and propose four methods based on the Mirror Descent iteration technique. Theoretical analysis is provided for smooth and convex minimization problems and variational inequalities with Lipschitz and monotone operators. The convergence guarantees obtained are optimal for first-order stochastic methods, as evidenced by the lower bound estimates provided in this paper.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01848v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vladimir Solodkin, Andrew Veprikov, Aleksandr Beznosikov</dc:creator>
    </item>
    <item>
      <title>Finite sample learning of moving targets</title>
      <link>https://arxiv.org/abs/2408.04406</link>
      <description>arXiv:2408.04406v3 Announce Type: replace 
Abstract: We consider a moving target that we seek to learn from samples. Our results extend randomized techniques developed in control and optimization for a constant target to the case where the target is changing. We derive a novel bound on the number of samples that are required to construct a probably approximately correct (PAC) estimate of the target. Furthermore, when the moving target is a convex polytope, we provide a constructive method of generating the PAC estimate using a mixed integer linear program (MILP). The proposed method is demonstrated on an application to autonomous emergency braking.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04406v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nikolaus Vertovec, Kostas Margellos, Maria Prandini</dc:creator>
    </item>
    <item>
      <title>Serial and Parallel Two-Column Probing for Mixed-Integer Programming</title>
      <link>https://arxiv.org/abs/2408.16927</link>
      <description>arXiv:2408.16927v2 Announce Type: replace 
Abstract: Probing in mixed-integer programming (MIP) is a technique of temporarily fixing variables to discover implications that are useful to branch-and-cut solvers. Such fixing is typically performed one variable at a time -- this paper develops instead a two-column probing scheme that instead fixes a pair of variables per iteration. Although the scheme involves more work per iteration compared to the one-column approach, stronger implied bounds as well as more conflicts identified may compensate. Indeed, our prototype implementation was awarded first prize at the MIP Workshop 2024 Computational Competition on novel presolving approaches. This paper presents the aforementioned (serial) prototype and additionally develops an efficient parallelization, leveraging hardware acceleration to further improve overall solve times. Compared to serial two-column probing, our parallel version sacrifices some strength per-pair probed in exchange for greatly increasing the total number of such probings; computational experiments demonstrate its promise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.16927v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yongzheng Dai, Chen Chen</dc:creator>
    </item>
    <item>
      <title>Gradient descent with adaptive stepsize converges (nearly) linearly under fourth-order growth</title>
      <link>https://arxiv.org/abs/2409.19791</link>
      <description>arXiv:2409.19791v2 Announce Type: replace 
Abstract: A prevalent belief among optimization specialists is that linear convergence of gradient descent is contingent on the function growing quadratically away from its minimizers. In this work, we argue that this belief is inaccurate. We show that gradient descent with an adaptive stepsize converges at a local (nearly) linear rate on any smooth function that merely exhibits fourth-order growth away from its minimizer. The adaptive stepsize we propose arises from an intriguing decomposition theorem: any such function admits a smooth manifold around the optimal solution -- which we call the ravine -- so that the function grows at least quadratically away from the ravine and has constant order growth along it. The ravine allows one to interlace many short gradient steps with a single long Polyak gradient step, which together ensure rapid convergence to the minimizer. We illustrate the theory and algorithm on the problems of matrix sensing and factorization and learning a single neuron in the overparameterized regime.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19791v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Damek Davis, Dmitriy Drusvyatskiy, Liwei Jiang</dc:creator>
    </item>
    <item>
      <title>Singular Perturbations of Nonlocal HJB Equations in Multiscale Stochastic Control</title>
      <link>https://arxiv.org/abs/2410.22141</link>
      <description>arXiv:2410.22141v3 Announce Type: replace 
Abstract: This paper investigates a class of multiscale stochastic control problems driven by $\alpha$-stable L\'evy noises, where the controlled dynamics evolve across separate slow and fast time scales. The associated value functions are governed by a family of nonlocal Hamilton-Jacobi-Bellman (HJB) equations subject to singular perturbations. By employing the perturbed test function method, we carefully analyze this singular perturbation problem and derive a limiting effective equation as the time-scale separation parameter $\varepsilon$ approaches zero. This limiting equation characterizes the value function of the averaged control problem, thereby establishing a rigorous averaging principle for the original multiscale system. The effective Hamiltonian-along with the corresponding averaged control problem is obtained by averaging with respect to the invariant measure of the fast process. Moreover, we provide a probabilistic proof of convergence and establish an explicit convergence rate for the value functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.22141v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qi Zhang, Yanjie Zhang, Ao Zhang</dc:creator>
    </item>
    <item>
      <title>Optimization via Strategic Law of Large Numbers</title>
      <link>https://arxiv.org/abs/2412.05604</link>
      <description>arXiv:2412.05604v5 Announce Type: replace 
Abstract: This paper proposes a unified framework for the global optimization of a continuous function in a bounded rectangular domain. Specifically, we show that: (1) under the optimal strategy for a two-armed decision model, the sample mean converges to a global optimizer under the Strategic Law of Large Numbers, and (2) a sign-based strategy built upon the solution of a parabolic PDE is asymptotically optimal. Motivated by this result, we propose a class of {\bf S}trategic {\bf M}onte {\bf C}arlo {\bf O}ptimization (SMCO) algorithms, which uses a simple strategy that makes coordinate-wise two-armed decisions based on the signs of the partial gradient of the original function being optimized over (without the need of solving PDEs). While this simple strategy is not generally optimal, we show that it is sufficient for our SMCO algorithm to converge to local optimizer(s) from a single starting point, and to global optimizers under a growing set of starting points. Numerical studies demonstrate the suitability of our SMCO algorithms for global optimization, and illustrate the promise of our theoretical framework and practical approach. For a wide range of test functions with challenging optimization landscapes (including ReLU neural networks with square and hinge loss), our SMCO algorithms converge to the global maximum accurately and robustly, using only a small set of starting points (at most 100 for dimensions up to 1000) and a small maximum number of iterations (200). In fact, our algorithms outperform many state-of-the-art global optimizers, as well as local algorithms augmented with the same set of starting points as ours.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05604v5</guid>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaohong Chen, Zengjing Chen, Wayne Yuan Gao, Xiaodong Yan, Guodong Zhang</dc:creator>
    </item>
    <item>
      <title>The exact subgraph hierarchy and its vertex-transitive variant for the stable set problem for Paley graphs</title>
      <link>https://arxiv.org/abs/2412.12958</link>
      <description>arXiv:2412.12958v2 Announce Type: replace 
Abstract: The stability number of a graph, defined as the cardinality of the largest set of pairwise non-adjacent vertices, is NP-hard to compute. The exact subgraph hierarchy (ESH) provides a sequence of increasingly tighter upper bounds on the stability number, starting with the Lov\'asz theta function at the first level and including all exact subgraph constraints of subgraphs of order $k$ into the semidefinite program to compute the Lov\'asz theta function at level $k$.
  In this paper, we investigate the ESH for Paley graphs, a class of strongly regular, vertex-transitive graphs. We show that for Paley graphs, the bounds obtained from the ESH remain the Lov\'asz theta function up to a certain threshold level, i.e., the bounds of the ESH do not improve up to a certain level.
  To overcome this limitation, we introduce the vertex-transitive ESH for the stable set problem for vertex-transitive graphs such as Paley graphs. We prove that this new hierarchy provides upper bounds on the stability number of vertex-transitive graphs that are at least as tight as those obtained from the ESH. Additionally, our computational experiments reveal that the vertex-transitive ESH produces superior bounds compared to the ESH for Paley graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.12958v2</guid>
      <category>math.OC</category>
      <category>cs.DM</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.dam.2025.09.014.</arxiv:DOI>
      <dc:creator>Elisabeth Gaar, Dunja Pucher</dc:creator>
    </item>
    <item>
      <title>Stochastic interior-point methods for smooth conic optimization with applications</title>
      <link>https://arxiv.org/abs/2412.12987</link>
      <description>arXiv:2412.12987v3 Announce Type: replace 
Abstract: Conic optimization plays a crucial role in many machine learning (ML) problems. However, practical algorithms for conic constrained ML problems with large datasets are often limited to specific use cases, as stochastic algorithms for general conic optimization remain underdeveloped. To fill this gap, we introduce a stochastic interior-point method (SIPM) framework for general conic optimization, along with four novel SIPM variants leveraging distinct stochastic gradient estimators. Under mild assumptions, we establish the iteration complexity of our proposed SIPMs, which, up to a polylogarithmic factor, match the best-known {results} in stochastic unconstrained optimization. Finally, our numerical experiments on robust linear regression, multi-task relationship learning, and clustering data streams demonstrate the effectiveness and efficiency of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.12987v3</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chuan He, Zhanwang Deng</dc:creator>
    </item>
    <item>
      <title>A Decomposition Framework for Nonlinear Nonconvex Two-Stage Optimization</title>
      <link>https://arxiv.org/abs/2501.11700</link>
      <description>arXiv:2501.11700v2 Announce Type: replace 
Abstract: We propose a new decomposition framework for continuous nonlinear constrained two-stage optimization, where both first- and second-stage problems can be nonconvex. A smoothing technique based on an interior-point formulation renders the optimal solution of the second-stage problem differentiable with respect to the first-stage parameters. As a consequence, efficient off-the-shelf optimization packages can be utilized. We show that the solution of the nonconvex second-stage problem behaves locally like a differentiable function so that existing proofs can be applied to prove the convergence of the iterates to first-order optimal points for the first-stage. We also prove fast local convergence of the algorithm as the barrier parameter is driven to zero. Numerical experiments for large-scale instances demonstrate the computational advantages of the decomposition framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11700v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuchen Lou, Xinyi Luo, Andreas W\"achter, Ermin Wei</dc:creator>
    </item>
    <item>
      <title>Differentially Private Linear Programming: Reduced Sub-Optimality and Guaranteed Constraint Satisfaction</title>
      <link>https://arxiv.org/abs/2501.19315</link>
      <description>arXiv:2501.19315v2 Announce Type: replace 
Abstract: Linear programming is a fundamental tool in a wide range of decision systems. However, without privacy protections, sharing the solution to a linear program may reveal information about the underlying data used to formulate it, which may be sensitive. Therefore, in this paper we introduce an approach for protecting sensitive data while formulating and solving a linear program. First, we prove that this method perturbs objectives and constraints in a way that makes them differentially private. Then, we show that (i) privatized problems always have solutions, and (ii) their solutions satisfy the constraints in their corresponding original, non-private problems. The latter result solves an open problem in the literature. Next, we analytically bound the expected sub-optimality of solutions that is induced by privacy. Numerical simulations show that, under a typical privacy setup, the solution produced by our method yields a $65\%$ reduction in sub-optimality compared to the state of the art.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.19315v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexander Benvenuti, Brendan Bialy, Miriam Dennis, Matthew Hale</dc:creator>
    </item>
    <item>
      <title>The Influence of an Adjoint Mismatch on the Primal-Dual Douglas-Rachford Method</title>
      <link>https://arxiv.org/abs/2503.24141</link>
      <description>arXiv:2503.24141v2 Announce Type: replace 
Abstract: The primal-dual Douglas-Rachford method is a well-known algorithm to solve optimization problems written as convex-concave saddle-point problems. Each iteration involves solving a linear system involving a linear operator and its adjoint. However, in practical applications it is often computationally favorable to replace the adjoint operator by a computationally more efficient approximation. This leads to an adjoint mismatch. In this paper, we analyze the convergence of the primal-dual Douglas-Rachford method under the presence of an adjoint mismatch. We provide mild conditions that guarantee the existence of a fixed point and find an upper bound on the error of the primal solution. Furthermore, we establish step sizes in the strongly convex setting that guarantee linear convergence under mild conditions. Additionally, we provide an alternative method that can also be derived from the Douglas-Rachford method and is also guaranteed to converge in this setting. Moreover, we illustrate our results both for an academic and a real-world inspired example.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.24141v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Emanuele Naldi, Felix Schneppe</dc:creator>
    </item>
    <item>
      <title>A Generating Polynomial Based Two-Stage Optimization Method for Tensor Rank Decomposition</title>
      <link>https://arxiv.org/abs/2504.00313</link>
      <description>arXiv:2504.00313v3 Announce Type: replace 
Abstract: The tensor rank decomposition, also known as canonical polyadic(CP) or simply tensor decomposition, has a long history in multilinear algebra. However, computing a rank decomposition becomes particularly challenging when the rank lies between its largest and second-largest dimensions. Moreover, for high-order tensor decompositions, a common approach is to first find a decomposition of its flattening order-3 tensor, where a significant gap often exists between the largest and the second-largest dimension, also making this case crucial in practice. For such a case, traditional optimization methods, such as the nonlinear least squares or alternating least squares methods, often fail to produce correct tensor decompositions. There are also direct methods that solve tensor decompositions algebraically. However, these methods usually require the tensor decomposition to be unique and can be computationally expensive, especially when the tensor rank is high. This paper introduces a new generating polynomial (GP) based two-stage algorithm for finding the order-3 nonsymmetric tensor decomposition, even when the tensor decomposition is not unique, assuming the rank does not exceed the largest dimension. The proposed method reformulates the tensor decomposition problem into two sequential optimization problems. Notably, if the first-stage optimization yields a partial solution, it will be effectively utilized in the second stage. We establish the theoretical equivalence between the CP decomposition and the global minimizers of those two-stage optimization problems. Numerical experiments demonstrate that our approach is very efficient and robust, capable of finding tensor decompositions in scenarios where the current state-of-the-art methods often fail.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.00313v3</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zequn Zheng, Hongchao Zhang, Guangming Zhou</dc:creator>
    </item>
    <item>
      <title>Revisiting Stochastic Approximation and Stochastic Gradient Descent</title>
      <link>https://arxiv.org/abs/2505.11343</link>
      <description>arXiv:2505.11343v3 Announce Type: replace 
Abstract: In this paper, we introduce a new approach to proving the convergence of the Stochastic Approximation (SA) and the Stochastic Gradient Descent (SGD) algorithms. The new approach is based on a concept called GSLLN (Generalized Strong Law of Large Numbers), which extends the traditional SLLN. Using this concept, we provide sufficient conditions for convergence, which effectively decouple the properties of the function whose zero we are trying to find, from the properties of the measurement errors (noise sequence). The new approach provides an alternative to the two widely used approaches, namely the ODE approach and the martingale approach, and also permits a wider class of noise signals than either of the two known approaches. In particular, the ``noise'' or measurement error \textit{need not} have a finite second moment, and under suitable conditions, not even a finite mean. By adapting this method of proof, we also derive sufficient conditions for the convergence of zero-order SGD, wherein the stochastic gradient is computed using $2d$ function evaluations, but no gradient computations. The sufficient conditions derived here are the weakest to date, thus leading to a considerable expansion of the applicability of SA and SGD theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.11343v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rajeeva Laxman Karandikar, Bhamidi Visweswara Rao, Mathukumalli Vidyasagar</dc:creator>
    </item>
    <item>
      <title>A New Inexact Manifold Proximal Linear Algorithm with Adaptive Stopping Criteria</title>
      <link>https://arxiv.org/abs/2508.19234</link>
      <description>arXiv:2508.19234v2 Announce Type: replace 
Abstract: This paper proposes a new inexact manifold proximal linear (IManPL) algorithm for solving nonsmooth, nonconvex composite optimization problems over an embedded submanifold. At each iteration, IManPL solves a convex subproblem inexactly, guided by two adaptive stopping criteria. We establish convergence guarantees and show that IManPL achieves the best first-order oracle complexity for solving this class of problems. Numerical experiments on sparse spectral clustering and sparse principal component analysis demonstrate that our methods outperform existing approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.19234v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhong Zheng, Xin Yu, Shiqian Ma, Lingzhou Xue</dc:creator>
    </item>
    <item>
      <title>The Intermodal Railroad Blocking and Railcar Fleet-Management Planning Problem</title>
      <link>https://arxiv.org/abs/2510.20597</link>
      <description>arXiv:2510.20597v2 Announce Type: replace 
Abstract: Rail is a cost-effective and relatively low-emission mode for transporting intermodal containers over long distances. This paper addresses tactical planning of intermodal railroad operations by introducing a new problem that simultaneously considers three consolidation processes and the management of a heterogeneous railcar fleet. We model the problem with a scheduled service network design with resource management (SSND-RM) formulation, expressed as an integer linear program. While such formulations are challenging to solve at scale, we demonstrate that our problem can be tackled with a general-purpose solver when provided with high-quality warm-start solutions. To this end, we design a construction heuristic inspired by a relax-and-fix procedure. We evaluate the methodology on realistic, large-scale instances from our industrial partner, the Canadian National Railway Company: a North American Class I railroad. The computational experiments show that the proposed approach efficiently solves practically relevant instances, and that solutions to the SSND-RM formulation yield substantially more accurate capacity estimations compared to those obtained from simpler baseline models. Managerial insights from our study highlight that ignoring railcar fleet management or container loading constraints can lead to a severe underestimation of required capacity, which may result in costly operational inefficiencies. Furthermore, our results show that the use of multi-platform railcars improves overall capacity utilization and benefits the network, even if they can locally lead to less efficient loading as measured by terminal-level slot utilization performance indicators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.20597v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Julie Kienzle, Serge Bisaillon, Teodor Gabriel Crainic, Emma Frejinger</dc:creator>
    </item>
    <item>
      <title>A Family of Convex Models to Achieve Fairness through Dispersion Control</title>
      <link>https://arxiv.org/abs/2510.23791</link>
      <description>arXiv:2510.23791v3 Announce Type: replace 
Abstract: Controlling the dispersion of a subset of decision variables in an optimization problem is crucial for enforcing fairness or load-balancing across a wide range of applications. Building on the well-known equivalence of finite-dimensional norms, the note develops a family of parameterized convex models that regulate the dispersion of a vector of decision-variable values through its coefficient of variation. Each model contains a single parameter that takes a value in the interval $[0,1]$. When the parameter is set to zero, the model imposes only a trivial constraint on the optimization problem; when set to one, it enforces equality of all the decision variables. As the parameter varies, the coefficient of variation is provably bounded above by a monotonic function of that parameter. The note also presents theoretical results that relate the space of feasible solutions to all the models. Finally it compares the models' solution quality on a variant of the assignment problem that regulates the dispersion in the assignment costs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.23791v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Abhay Singh Bhadoriya, Deepjyoti Deka, Kaarthik Sundar</dc:creator>
    </item>
    <item>
      <title>Nonasymptotic Convergence Rates for Plug-and-Play Methods With MMSE Denoisers</title>
      <link>https://arxiv.org/abs/2510.27211</link>
      <description>arXiv:2510.27211v3 Announce Type: replace 
Abstract: It is known that the minimum-mean-squared-error (MMSE) denoiser under Gaussian noise can be written as a proximal operator, which suffices for asymptotic convergence of plug-and-play (PnP) methods but does not reveal the structure of the induced regularizer or give convergence rates. We show that the MMSE denoiser corresponds to a regularizer that can be written explicitly as an upper Moreau envelope of the negative log-marginal density, which in turn implies that the regularizer is 1-weakly convex. Using this property, we derive (to the best of our knowledge) the first sublinear convergence guarantee for PnP proximal gradient descent with an MMSE denoiser. We validate the theory with a one-dimensional synthetic study that recovers the implicit regularizer. We also validate the theory with imaging experiments (deblurring and computed tomography), which exhibit the predicted sublinear behavior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.27211v3</guid>
      <category>math.OC</category>
      <category>eess.SP</category>
      <category>stat.ML</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Henry Pritchard, Rahul Parhi</dc:creator>
    </item>
    <item>
      <title>Accelerating Trust-Region Methods: An Attempt to Balance Global and Local Efficiency</title>
      <link>https://arxiv.org/abs/2511.00680</link>
      <description>arXiv:2511.00680v2 Announce Type: replace 
Abstract: Historically speaking, it is hard to balance the global and local efficiency of second-order optimization algorithms. For instance, the classical Newton's method possesses excellent local convergence but lacks global guarantees, often exhibiting divergence when the starting point is far from the optimal solution~\cite{more1982newton,dennis1996numerical}. In contrast, accelerated second-order methods offer strong global convergence guarantees, yet they tend to converge with slower local rate~\cite{carmon2022optimal,chen2022accelerating,jiang2020unified}. Existing second-order methods struggle to balance global and local performance, leaving open the question of how much we can globally accelerate the second-order methods while maintaining excellent local convergence guarantee. In this paper, we tackle this challenge by proposing for the first time the accelerated trust-region-type methods, and leveraging their unique primal-dual information. Our primary technical contribution is \emph{Accelerating with Local Detection}, which utilizes the Lagrange multiplier to detect local regions and achieves a global complexity of $\tilde{O}(\epsilon^{-1/3})$, while maintaining quadratic local convergence. We further explore the trade-off when pushing the global convergence to the limit. In particular, we propose the \emph{Accelerated Trust-Region Extragradient Method} that has a global near-optimal rate of $\tilde{O}(\epsilon^{-2/7})$ but loses the quadratic local convergence. This reveals a phase transition in accelerated trust-region type methods: the excellent local convergence can be maintained when achieving a moderate global acceleration but becomes invalid when pursuing the extreme global efficiency. Numerical experiments further confirm the results indicated by our convergence analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00680v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuntian Jiang, Chuwen Zhang, Bo Jiang, Yinyu Ye</dc:creator>
    </item>
    <item>
      <title>Disciplined Biconvex Programming</title>
      <link>https://arxiv.org/abs/2511.01813</link>
      <description>arXiv:2511.01813v2 Announce Type: replace 
Abstract: We introduce disciplined biconvex programming (DBCP), a modeling framework for specifying and solving biconvex optimization problems. Biconvex optimization problems arise in various applications, including machine learning, signal processing, computational science, and control. Solving a biconvex optimization problem in practice usually resolves to heuristic methods based on alternate convex search (ACS), which iteratively optimizes over one block of variables while keeping the other fixed, so that the resulting subproblems are convex and can be efficiently solved. However, designing and implementing an ACS solver for a specific biconvex optimization problem usually requires significant effort from the user, which can be tedious and error-prone. DBCP extends the principles of disciplined convex programming to biconvex problems, allowing users to specify biconvex optimization problems in a natural way based on a small number of syntax rules. The resulting problem can then be automatically split and transformed into convex subproblems, for which a customized ACS solver is then generated and applied. DBCP allows users to quickly experiment with different biconvex problem formulations, without expertise in convex optimization. We implement DBCP into the open source Python package dbcp, as an extension to the famous domain specific language CVXPY for convex optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01813v2</guid>
      <category>math.OC</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>cs.MS</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hao Zhu, Joschka Boedecker</dc:creator>
    </item>
    <item>
      <title>Fiedler-Based Characterization and Identification of Leaders in Semi-Autonomous Networks</title>
      <link>https://arxiv.org/abs/2511.02317</link>
      <description>arXiv:2511.02317v3 Announce Type: replace 
Abstract: This paper addresses the problem of identifying leader nodes in semi-autonomous consensus networks from observed agent dynamics. Using the grounded Laplacian formulation, we derive spectral conditions that ensure the components of the Fiedler vector associated with leader and follower nodes are distinct. Building on the foundation, we emply the notion of relative tempo from prio works as an observable quantity that relates agents' steady-state velocities to the Fiedler vector. This relationship enables the development of a data-driven algorithm that reconstructs the Fiedler vector - and consequently identifies the leader set - using only steady-state velocity measurements, without requiring knowledge of the network topology. The proposed approach is validated through nuerical examples, demonstrating how spectral properties and relative tempo measurements can be combined to reveal hidden leadership structures in consensus networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.02317v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Evyatar Matmon, Daniel Zelazo</dc:creator>
    </item>
    <item>
      <title>Hidden Convexity in Queueing Models</title>
      <link>https://arxiv.org/abs/2511.03955</link>
      <description>arXiv:2511.03955v2 Announce Type: replace 
Abstract: We study the joint control of arrival and service rates in queueing systems with the objective of minimizing long-run expected cost minus revenue. Although the objective function is non-convex, first-order methods have been empirically observed to converge to globally optimal solutions. This paper provides a theoretical foundation for this empirical phenomenon by characterizing the optimization landscape and identifying a hidden convexity: the problem admits a convex reformulation after an appropriate change of variables. Leveraging this hidden convexity, we establish the Polyak-Lojasiewicz-Kurdyka (PLK) condition for the original control problem, which excludes spurious local minima and ensures global convergence for first-order methods. Our analysis applies to a broad class of $GI/GI/1$ queueing models, including those with Gamma-distributed interarrival and service times. As a key ingredient in the proof, we establish a new convexity property of the expected queue length under a square-root transformation of the traffic intensity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.03955v2</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Xin Chen, Linwei Xin, Minda Zhao</dc:creator>
    </item>
    <item>
      <title>Refuting spectral compatibility of quantum marginals</title>
      <link>https://arxiv.org/abs/2211.06349</link>
      <description>arXiv:2211.06349v4 Announce Type: replace-cross 
Abstract: The spectral variant of the quantum marginal problem asks: Given prescribed spectra for a set of overlapping quantum marginals, does there exist a compatible joint state? The main idea of this work is a symmetry-reduced semidefinite programming hierarchy that detects when no such joint state exists. The hierarchy is complete, in the sense that it detects every incompatible set of spectra. The refutations it provides are dimension-free, certifying incompatibility in all local dimensions. The hierarchy also applies to the sums of Hermitian matrices problem, the compatibility of local unitary invariants, for certifying vanishing Kronecker coefficients, and to optimize over equivariant state polynomials.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.06349v4</guid>
      <category>quant-ph</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Felix Huber, Nikolai Wyderka</dc:creator>
    </item>
    <item>
      <title>Optimization without Retraction on the Random Generalized Stiefel Manifold</title>
      <link>https://arxiv.org/abs/2405.01702</link>
      <description>arXiv:2405.01702v4 Announce Type: replace-cross 
Abstract: Optimization over the set of matrices $X$ that satisfy $X^\top B X = I_p$, referred to as the generalized Stiefel manifold, appears in many applications involving sampled covariance matrices such as the canonical correlation analysis (CCA), independent component analysis (ICA), and the generalized eigenvalue problem (GEVP). Solving these problems is typically done by iterative methods that require a fully formed $B$. We propose a cheap stochastic iterative method that solves the optimization problem while having access only to random estimates of $B$. Our method does not enforce the constraint in every iteration; instead, it produces iterations that converge to critical points on the generalized Stiefel manifold defined in expectation. The method has lower per-iteration cost, requires only matrix multiplications, and has the same convergence rates as its Riemannian optimization counterparts that require the full matrix $B$. Experiments demonstrate its effectiveness in various machine learning applications involving generalized orthogonality constraints, including CCA, ICA, and the GEVP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.01702v4</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>Proceedings of the 41st International Conference on Machine Learning (ICML 2024), PMLR 235 (2024), 49226-49248</arxiv:journal_reference>
      <dc:creator>Simon Vary, Pierre Ablin, Bin Gao, P. -A. Absil</dc:creator>
    </item>
    <item>
      <title>Uniform Convergence of Adversarially Robust Classifiers</title>
      <link>https://arxiv.org/abs/2406.14682</link>
      <description>arXiv:2406.14682v2 Announce Type: replace-cross 
Abstract: In recent years there has been significant interest in the effect of different types of adversarial perturbations in data classification problems. Many of these models incorporate the adversarial power, which is an important parameter with an associated trade-off between accuracy and robustness. This work considers a general framework for adversarially-perturbed classification problems, in a large data or population-level limit. In such a regime, we demonstrate that as adversarial strength goes to zero that optimal classifiers converge to the Bayes classifier in the Hausdorff distance. This significantly strengthens previous results, which generally focus on $L^1$-type convergence. The main argument relies upon direct geometric comparisons and is inspired by techniques from geometric measure theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.14682v2</guid>
      <category>math.AP</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rachel Morris, Ryan Murray</dc:creator>
    </item>
    <item>
      <title>Understanding Forgetting in LLM Supervised Fine-Tuning and Preference Learning -- A Convex Optimization Perspective</title>
      <link>https://arxiv.org/abs/2410.15483</link>
      <description>arXiv:2410.15483v4 Announce Type: replace-cross 
Abstract: The post-training of LLMs, which typically consists of the supervised fine-tuning (SFT) stage and the preference learning stage (RLHF or DPO), is crucial to effective and safe LLM applications. The widely adopted approach in post-training popular open-source LLMs is to sequentially perform SFT and RLHF/DPO. However, this is suboptimal in terms of SFT and RLHF/DPO trade-off: the LLM gradually forgets about the first stage's training when undergoing the second stage's training. This sequential paradigm persists largely due to its simplicity and modularity, which make it easier to implement and manage at scale despite its limitations. We theoretically prove the sub-optimality of sequential post-training and propose a practical joint post-training framework which has theoretical convergence guarantees and empirically outperforms sequential post-training framework, with up to 23% overall performance improvement across multiple LLM evaluation benchmarks, while having minimal computational overhead. Our code is available at https://github.com/heshandevaka/XRIGHT.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15483v4</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Heshan Fernando, Han Shen, Parikshit Ram, Yi Zhou, Horst Samulowitz, Nathalie Baracaldo, Tianyi Chen</dc:creator>
    </item>
    <item>
      <title>Distributional Surgery for Language Model Activations</title>
      <link>https://arxiv.org/abs/2501.15758</link>
      <description>arXiv:2501.15758v2 Announce Type: replace-cross 
Abstract: Language models, while capable of generating remarkably coherent and seemingly accurate text, can occasionally produce undesirable content, including harmful or toxic outputs. In this paper, we present a new two-stage approach to detect and mitigate undesirable content generations by rectifying activations. First, we train an ensemble of layerwise classifiers to detect undesirable content using activations by minimizing a smooth surrogate of the risk-aware score. Then, for detected undesirable contents, we propose layerwise distributional steering policies that transform the attention heads. These policies are computed through principled semidefinite programming, which aims to minimally perturb the attention distribution while probabilistically guaranteeing the effectiveness of the editions. Empirical evaluations across multiple language models and datasets show that our method outperforms baselines in reducing the generation of undesirable output.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.15758v2</guid>
      <category>cs.LG</category>
      <category>cs.CL</category>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bao Nguyen, Binh Nguyen, Duy Nguyen, Viet Anh Nguyen</dc:creator>
    </item>
    <item>
      <title>A High-Speed Time-Optimal Trajectory Generation Strategy via a Two-layer Planning Model</title>
      <link>https://arxiv.org/abs/2503.11072</link>
      <description>arXiv:2503.11072v3 Announce Type: replace-cross 
Abstract: MPC (Model predictive control)-based motion planning and trajectory generation are essential in applications such as unmanned aerial vehicles, robotic manipulators, and rocket control. However, the real-time implementation of such optimization-based planning faces significant challenges arising from non-convex problem structures and inherent limitations of nonlinear programming -- notably the difficulty in guaranteeing solution quality and the unpredictability of computation time. To improve robustness and computational efficiency, this paper introduces a two-layer motion planning algorithm for intelligent ground vehicles based on convex optimization. The proposed algorithm iteratively constructs discrete optimal control subproblems with small, fixed terminal times, referred to as planning cycles. Each planning cycle is further solved within progressively constructed convex sets generated by utilizing customized search algorithms. The entire solution to the original problem is obtained by incrementally composing the solutions of these subproblems. The proposed algorithm demonstrates enhanced reliability and significantly reduced computation time. We support our approach with theoretical analysis under practical assumptions and numerical experiments. Comparative results with standard sequential convex programming (SCP) methods demonstrate the superiority of our method -- include a significant improved computational speed under dynamic environments while maintain a near optimal final time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.11072v3</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haotian Tan, Yuan-Hua Ni</dc:creator>
    </item>
    <item>
      <title>A two-player voting game in Euclidean space</title>
      <link>https://arxiv.org/abs/2504.01713</link>
      <description>arXiv:2504.01713v3 Announce Type: replace-cross 
Abstract: Given a finite set $S$ of points in $\mathbb{R}^d$, which we regard as the locations of voters on a $d$-dimensional political `spectrum', two candidates (Alice and Bob) select one point in $\mathbb{R}^d$ each, in an attempt to get as many votes as possible. Alice goes first and Bob goes second, and then each voter simply votes for the candidate closer to them in terms of Euclidean distance. If a voter's distance from the two candidates is the same, they vote for nobody. We give a geometric characterization of the sets $S$ for which each candidate wins, assuming that Alice wins if they get an equal number of votes. We also show that, if not all the voters lie on a single line, then, whenever Alice has a winning strategy, there is a unique winning point for her. We also provide an algorithm which decides whether Alice has a winning point, and determines the location of that point, both in finite (in fact polynomial) time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.01713v3</guid>
      <category>math.CO</category>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stelios Stylianou</dc:creator>
    </item>
    <item>
      <title>It\^o-Wentzell-Lions formulae for flows of full and conditional measures on semimartingales</title>
      <link>https://arxiv.org/abs/2505.13155</link>
      <description>arXiv:2505.13155v3 Announce Type: replace-cross 
Abstract: In this paper, we establish the It\^o-Wentzell-Lions formulae for flows of both full and conditional measures on general semimartingales. This generalizes the existing works on flows of measures on It\^o processes. The key technical components involve an appropriate approximation of random fields by cylindrical functions and localization techniques. Moreover, we present the specific formulae in two special cases, including It\^o-Wentzell-Lions formulae for time-space-measure-dependent functions and for functions driven by Poisson random measures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13155v3</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liu Jisheng, Zhang Jing</dc:creator>
    </item>
    <item>
      <title>From Average-Iterate to Last-Iterate Convergence in Games: A Reduction and Its Applications</title>
      <link>https://arxiv.org/abs/2506.03464</link>
      <description>arXiv:2506.03464v2 Announce Type: replace-cross 
Abstract: The convergence of online learning algorithms in games under self-play is a fundamental question in game theory and machine learning. Among various notions of convergence, last-iterate convergence is particularly desirable, as it reflects the actual decisions made by the learners and captures the day-to-day behavior of the learning dynamics. While many algorithms are known to converge in the average-iterate, achieving last-iterate convergence typically requires considerably more effort in both the design and the analysis of the algorithm. Somewhat surprisingly, we show in this paper that for a large family of games, there exists a simple black-box reduction that transforms the average iterates of an uncoupled learning dynamics into the last iterates of a new uncoupled learning dynamics, thus also providing a reduction from last-iterate convergence to average-iterate convergence. Our reduction applies to games where each player's utility is linear in both their own strategy and the joint strategy of all opponents. This family includes two-player bimatrix games and generalizations such as multi-player polymatrix games. By applying our reduction to the Optimistic Multiplicative Weights Update algorithm, we obtain new state-of-the-art last-iterate convergence rates for uncoupled learning dynamics in multi-player zero-sum polymatrix games: (1) an $O(\frac{\log d}{T})$ last-iterate convergence rate under gradient feedback, representing an exponential improvement in the dependence on the dimension $d$ (i.e., the maximum number of actions available to either player); and (2) an $\widetilde{O}(d^{\frac{1}{5}} T^{-\frac{1}{5}})$ last-iterate convergence rate under bandit feedback, improving upon the previous best rates of $\widetilde{O}(\sqrt{d} T^{-\frac{1}{8}})$ and $\widetilde{O}(\sqrt{d} T^{-\frac{1}{6}})$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.03464v2</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yang Cai, Haipeng Luo, Chen-Yu Wei, Weiqiang Zheng</dc:creator>
    </item>
    <item>
      <title>Gordian split links in the Gehring ropelength problem</title>
      <link>https://arxiv.org/abs/2506.04644</link>
      <description>arXiv:2506.04644v2 Announce Type: replace-cross 
Abstract: A thick link is a link in $\mathbb{R}^3$ such that each component of the link lies at distance at least $1$ from every other component. Strengthening the notion of thickness, we define a thickly embedded link to be a thick link whose open radius-$\tfrac{1}{2}$ normal disk bundles of all components are embedded. The Gehring ropelength problem asks how large the sum of the lengths of the components of a thick (respectively thickly embedded) link must be, given the link homotopy (respectively isotopy) class of the link. A thick homotopy (isotopy) is a link homotopy (isotopy) of a thick (thickly embedded) link that preserves thickness throughout, and such that during the homotopy the total length of the link never exceeds the initial total length. These notions of thick homotopy and isotopy are more permissive than other notions of physical link isotopies in which the length of each individual component must remain constant. We construct an explicit example of a thickly embedded 4-component link which is topologically split but cannot be split by a thick homotopy, and thick links in every homotopy class with 2 components that are non-global local minima for ropelength. This is the first time such local minima for ropelength have been explicitly constructed. In particular, we construct a thick 2-component link in the link homotopy class of the unlink which cannot be split through a thick homotopy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04644v2</guid>
      <category>math.GT</category>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Friedrich Bauermeister</dc:creator>
    </item>
    <item>
      <title>Linear toroidal-inertial waves on a differentially rotating sphere with application to helioseismology: Modeling, forward and inverse problems</title>
      <link>https://arxiv.org/abs/2507.20488</link>
      <description>arXiv:2507.20488v3 Announce Type: replace-cross 
Abstract: This paper develops a mathematical framework for interpreting observations of solar inertial waves in an idealized setting. Under the assumption of purely toroidal linear waves on the sphere, the stream function of the flow satisfies a fourth-order scalar equation. We prove well-posedness of wave solutions under explicit conditions on differential rotation. Moreover, we study the inverse problem of simultaneously reconstructing viscosity and differential rotation parameters from either complete or partial surface data. We establish convergence guarantee of iterative regularization methods by verifying the tangential cone condition, and prove local unique identifiability of the unknown parameters. Numerical experiments with Nesterov-Landweber iteration confirm reconstruction robustness across different observation strategies and noise levels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.20488v3</guid>
      <category>math.AP</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tram Thi Ngoc Nguyen, Damien Fournier, Laurent Gizon, Thorsten Hohage</dc:creator>
    </item>
    <item>
      <title>Sparse Narrow-Band Topology Optimization for Large-Scale Thermal-Fluid Applications</title>
      <link>https://arxiv.org/abs/2508.04261</link>
      <description>arXiv:2508.04261v2 Announce Type: replace-cross 
Abstract: We propose a fluid-based topology optimization methodology for convective heat-transfer problems that can manage an extensive number of design variables, enabling the fine geometric features required for the next generation of heat-exchangers design. Building on the classical Borrvall-Petersson formulation for the Stokes flow, we introduce an optimization algorithm that focuses computational effort on the fluid-solid interface, where it is most needed. To address the high cost of repeated forward and adjoint analyses and to avoid leakage through nominally solid regions, we exclude fictitious solid voxels from the analysis by imposing the no-slip boundary conditions in the vicinity of the fluid-solid interface. In contrast to the prior approaches, the fictitious solids are also excluded from the global optimization problem via reducing it to a sequence of local narrow-band subproblems with a variable design space. The contribution of our method is that large-scale optimization can be solved efficiently by continuous simplex method while reliably obtaining binary designs without additional filtering or projection. We demonstrate efficiency of the method on multiple examples, including the optimization of a two-fluid heat exchanger at $Pe=10^4$ on a $370^3$ grid comprising $5\times10^7$ design variables using only a single desktop workstation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.04261v2</guid>
      <category>physics.flu-dyn</category>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vladislav Pimanov, Alexandre T. R. Guibert, John-Paul Sabino, Michael Stoia, H. Alicia Kim</dc:creator>
    </item>
    <item>
      <title>Aircraft routing: periodicity and complexity</title>
      <link>https://arxiv.org/abs/2508.05532</link>
      <description>arXiv:2508.05532v2 Announce Type: replace-cross 
Abstract: The aircraft routing problem is one of the most studied problems of operations research applied to aircraft management. It involves assigning flights to aircraft while ensuring regular visits to maintenance bases. This paper examines two aspects of the problem.
  First, we explore the relationship between periodic instances, where flights are the same every day, and periodic solutions. The literature has implicitly assumed-without discussion-that periodic instances necessitate periodic solutions, and even periodic solutions in a stronger form, where every two airplanes perform either the exact same cyclic sequence of flights, or completely disjoint cyclic sequences. However, enforcing such periodicity may eliminate feasible solutions. We prove that, when regular maintenance is required at most every four days, there always exist periodic solutions of this form.
  Second, we consider the computational hardness of the problem. Even if many papers in this area refer to the NP-hardness of the aircraft routing problem, such a result is only available in the literature for periodic instances. We establish its NP-hardness for a non-periodic version. Polynomiality of a special but natural case is also proven.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.05532v2</guid>
      <category>cs.DM</category>
      <category>math.OC</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fr\'ed\'eric Meunier, Axel Parmentier, Nour ElHouda Tellache</dc:creator>
    </item>
    <item>
      <title>MDNS: Masked Diffusion Neural Sampler via Stochastic Optimal Control</title>
      <link>https://arxiv.org/abs/2508.10684</link>
      <description>arXiv:2508.10684v2 Announce Type: replace-cross 
Abstract: We study the problem of learning a neural sampler to generate samples from discrete state spaces where the target probability mass function $\pi\propto\mathrm{e}^{-U}$ is known up to a normalizing constant, which is an important task in fields such as statistical physics, machine learning, combinatorial optimization, etc. To better address this challenging task when the state space has a large cardinality and the distribution is multi-modal, we propose $\textbf{M}$asked $\textbf{D}$iffusion $\textbf{N}$eural $\textbf{S}$ampler ($\textbf{MDNS}$), a novel framework for training discrete neural samplers by aligning two path measures through a family of learning objectives, theoretically grounded in the stochastic optimal control of the continuous-time Markov chains. We validate the efficiency and scalability of MDNS through extensive experiments on various distributions with distinct statistical properties, where MDNS learns to accurately sample from the target distributions despite the extremely high problem dimensions and outperforms other learning-based baselines by a large margin. A comprehensive study of ablations and extensions is also provided to demonstrate the efficacy and potential of the proposed framework. Our code is available at https://github.com/yuchen-zhu-zyc/MDNS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10684v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuchen Zhu, Wei Guo, Jaemoo Choi, Guan-Horng Liu, Yongxin Chen, Molei Tao</dc:creator>
    </item>
  </channel>
</rss>
