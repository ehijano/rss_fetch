<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 18 Mar 2024 04:00:26 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 18 Mar 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>On the Impact of Co-Optimizing Station Locations, Trip Assignment, and Charging Schedules for Electric Buses</title>
      <link>https://arxiv.org/abs/2403.09763</link>
      <description>arXiv:2403.09763v1 Announce Type: new 
Abstract: As many public transportation systems around the world transition to electric buses, the planning and operation of fleets can be improved via tailored decision-support tools. In this work, we study the impact of jointly locating charging facilities, assigning electric buses to trips, and determining when and where to charge the buses. We propose a mixed integer linear program that co-optimizes planning and operational decisions jointly and an iterated local search heuristic to solve large-scale instances. Herein, we use a concurrent scheduler algorithm to generate an initial feasible solution, which serves as a starting point for our iterated local search algorithm. In the sequential case, we first optimize trip assignments and charging locations. Charging schedules are then determined after fixing the optimal decisions from the first level. The joint model, on the other hand, integrates charge scheduling within the local search procedure. The solution quality of the joint and sequential iterated local search models are compared for multiple real-world bus transit networks. Our results demonstrate that joint models can help further improve operating costs by 14.1% and lower total costs by about 4.1% on average compared with sequential models. In addition, energy consumption costs and contracted power capacity costs have been reduced significantly due to our integrated planning approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.09763v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rito Brata Nath, Tarun Rambha, Maximilian Schiffer</dc:creator>
    </item>
    <item>
      <title>One-shot Learning for MIPs with SOS1 Constraints</title>
      <link>https://arxiv.org/abs/2403.09815</link>
      <description>arXiv:2403.09815v1 Announce Type: new 
Abstract: Efficient algorithms and solvers are required to provide optimal or near-optimal solutions quickly and enable organizations to react promptly to dynamic situations such as supply chain disruptions or changing customer demands. State-of-the-art mixed-integer programming (MIP) solvers are crafted to tackle a wide variety of problems, yet many real-world situations are characterized by problem instances that originate from a narrow distribution. This has inspired the creation of tailored approaches that exploit historical data to inform heuristic design. Deep learning (DL) methods are typically used in this context to extract patterns from data, but they require large datasets and comprehensive hyperparameter tuning for strong performance. This article describes a one-shot learning heuristic that leverages solutions discovered within the branch-and-bound tree to construct a model with minimal overhead. We evaluate our method on the locomotive assignment problem (LAP) and sets of MIPLIB instances that contain constraints based on special ordered sets of type 1. Experimental results include a comparison with multiple primal heuristics and state-of-the-art MIP solvers. We show that the method is most effective with CPLEX in terms of the average primal gap.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.09815v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Charly Robinson La Rocca, Jean-Fran\c{c}ois Cordeau, Emma Frejinger</dc:creator>
    </item>
    <item>
      <title>A Refined Proximal Algorithm for Nonconvex Multiobjective Optimization in Hilbert Spaces</title>
      <link>https://arxiv.org/abs/2403.09922</link>
      <description>arXiv:2403.09922v1 Announce Type: new 
Abstract: This paper is devoted to general nonconvex problems of multiobjective optimization in Hilbert spaces. Based on Mordukhovich's limiting subgradients, we define a new notion of Pareto critical points for such problems, establish necessary optimality conditions for them, and then employ these conditions to develop a refined version of the vectorial proximal point algorithm with providing its detailed convergence analysis. The obtained results largely extend those initiated by Bonnel, Iusem and Svaiter \cite{Bonnel2005} for convex vector optimization problems and by Bento et al. \cite{Bento2018} for nonconvex finite-dimensional problems in terms of Clarke's generalized gradients.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.09922v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>G. C. Bento, J. X. Cruz Neto, J. O. Lopes, B. S. Mordukhovich, P. R. Silva Filho</dc:creator>
    </item>
    <item>
      <title>Integer Points in Arbitrary Convex Cones: The Case of the PSD and SOC Cones</title>
      <link>https://arxiv.org/abs/2403.09927</link>
      <description>arXiv:2403.09927v1 Announce Type: new 
Abstract: We investigate the semigroup of integer points inside a convex cone. We extend classical results in integer linear programming to integer conic programming. We show that the semigroup associated with nonpolyhedral cones can sometimes have a notion of finite generating set. We show this is true for the cone of positive semidefinite matrices (PSD) and the second-order cone (SOC). Both cones have a finite generating set of integer points, similar in spirit to Hilbert bases, under the action of a finitely generated group. We also extend notions of total dual integrality, Gomory-Chv\'{a}tal closure, and Carath\'{e}odory rank to integer points in arbitrary cones.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.09927v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jes\'us A. De Loera, Brittney Marsters, Luze Xu, Shixuan Zhang</dc:creator>
    </item>
    <item>
      <title>Second-Order Strong Optimality and Second-Order Duality for Nonsmooth Constrained Multiobjective Fractional Programming Problems</title>
      <link>https://arxiv.org/abs/2403.10093</link>
      <description>arXiv:2403.10093v1 Announce Type: new 
Abstract: This paper investigates constrained nonsmooth multiobjective fractional programming problem (NMFP) in real Banach spaces. It derives a quotient calculus rule for computing the first- and second-order Clarke derivatives of fractional functions involving locally Lipschitz functions. A novel second-order Abadie-type regularity condition is presented, defined with the help of the Clarke directional derivative and the P\'ales-Zeidan second-order directional derivative. We establish both first- and second-order strong necessary optimality conditions, which contain some new information on multipliers and imply the strong KKT necessary conditions, for a Borwein-type properly efficient solution of NMFP by utilizing generalized directional derivatives. Moreover, it derives second-order sufficient optimality conditions for NMFP under a second-order generalized convexity assumption. Additionally, we derive duality results between NMFP and its second-order dual problem under some appropriate conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.10093v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiawei Chen, Luyu Liu, Yibing Lv, Debdas Ghosh, Jen-Chih Yao</dc:creator>
    </item>
    <item>
      <title>Fast Generation of Feasible Trajectories in Direct Optimal Control</title>
      <link>https://arxiv.org/abs/2403.10115</link>
      <description>arXiv:2403.10115v1 Announce Type: new 
Abstract: This paper examines the question of finding feasible points to discrete-time optimal control problems. The optimization problem of finding a feasible trajectory is transcribed to an unconstrained optimal control problem. An efficient algorithm, called FP-DDP, is proposed that solves the resulting problem using Differential Dynamic Programming preserving feasibility with respect to the system dynamics in every iteration. Notably, FP-DDP admits global and rapid local convergence properties induced by a combination of a Levenberg-Marquardt method and an Armijo-type line search. The efficiency of FP-DDP is demonstrated against established methods such as Direct Multiple Shooting, Direct Single Shooting, and state-of-the-art solvers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.10115v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David Kiessling, Katrin Baumg\"artner, Wilm Decr\'e, Jan Swevers, Moritz Diehl</dc:creator>
    </item>
    <item>
      <title>On a globally convergent semismooth* Newton method in nonsmooth nonconvex optimzation</title>
      <link>https://arxiv.org/abs/2403.10142</link>
      <description>arXiv:2403.10142v1 Announce Type: new 
Abstract: In this paper we present GSSN, a globalized SCD semismooth* Newton method for solving nonsmooth nonconvex optimization problems. The global convergence properties of the method are ensured by the proximal gradient method, whereas locally superlinear convergence is established via the SCD semismooth* Newton method under quite weak assumptions. The Newton direction is based on the SC (subspace containing) derivative of the subdifferential mapping and can be computed by the (approximate) solution of an equality-constrained quadratic program. Special attention is given to the efficient numerical implementation of the overall method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.10142v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>H. Gfrerer</dc:creator>
    </item>
    <item>
      <title>An efficient asymptotic DC method for sparse and low-rank matrix recovery</title>
      <link>https://arxiv.org/abs/2403.10180</link>
      <description>arXiv:2403.10180v1 Announce Type: new 
Abstract: The optimization problem of sparse and low-rank matrix recovery is considered, which involves a least squares problem with a rank constraint and a cardinality constraint. To overcome the challenges posed by these constraints, an asymptotic difference-of-convex (ADC) method that employs a Moreau smoothing approach and an exact penalty approach is proposed to transform this problem into a DC programming format gradually. To solve the gained DC programming, by making full use of its DC structure, an efficient inexact DC algorithm with sieving strategy (siDCA) is introduced. The subproblem of siDCA is solved by an efficient dual-based semismooth Newton method. The convergence of the solution sequence generated by siDCA is proved. To illustrate the effectiveness of ADC-siDCA, matrix recovery experiments on nonnegative and positive semidefinite matrices. The numerical results are compared with those obtained using a successive DC approximation minimization method and a penalty proximal alternating linearized minimization approach. The outcome of the comparison indicates that ADC-siDCA surpasses the other two methods in terms of efficiency and recovery error. Additionally, numerical experiments on sparse phase retrieval demonstrate that ADC-siDCA is a valuable tool for recovering sparse and low-rank Hermitian matrices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.10180v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mingcai Ding, Xiaoliang Song, Bo Yu</dc:creator>
    </item>
    <item>
      <title>Comparison of Proximal First-Order Primal and Primal-Dual algorithms via Performance Estimation</title>
      <link>https://arxiv.org/abs/2403.10209</link>
      <description>arXiv:2403.10209v1 Announce Type: new 
Abstract: Selecting the fastest algorithm for a specific signal/image processing task is a challenging question. We propose an approach based on the Performance Estimation Problem framework that numerically and automatically computes the worst-case performance of a given optimization method on a class of functions. We first propose a computer-assisted analysis and comparison of several first-order primal optimization methods, namely, the gradient method, the forward-backward, Peaceman-Rachford, and Douglas-Rachford splittings. We tighten the existing convergence results of these algorithms and extend them to new classes of functions. Our analysis is then extended and evaluated in the context of the primal-dual Chambolle-Pock and Condat-V\~u methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.10209v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nizar Bousselmi, Nelly Pustelnik, Julien M. Hendrickx, Fran\c{c}ois Glineur</dc:creator>
    </item>
    <item>
      <title>A General Non-Strict Finsler's Lemma</title>
      <link>https://arxiv.org/abs/2403.10306</link>
      <description>arXiv:2403.10306v1 Announce Type: new 
Abstract: In this paper, we present a general non-strict Finsler's lemma. This result is general in the sense that it does not impose any restrictions on the involved matrices and, thereby, is more broadly applicable than existing non-strict versions of Finsler's lemma that do impose such restrictions. In fact, we show that this new non-strict formulation generalizes both the original strict Finsler's lemma as well as an existing non-strict version. To further illustrate its usefulness, we showcase applications of the non-strict Finsler's lemma in deriving a closed-form solution to the non-strict projection lemma, and a matrix Finsler's lemma, which is useful for data-driven control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.10306v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>T. J. Meijer, K. J. A. Scheres, S. van den Eijnden, T. Holicki, C. W. Scherer, W. P. M. H. Heemels</dc:creator>
    </item>
    <item>
      <title>Learning of Nash Equilibria in Risk-Averse Games</title>
      <link>https://arxiv.org/abs/2403.10399</link>
      <description>arXiv:2403.10399v1 Announce Type: new 
Abstract: This paper considers risk-averse learning in convex games involving multiple agents that aim to minimize their individual risk of incurring significantly high costs. Specifically, the agents adopt the conditional value at risk (CVaR) as a risk measure with possibly different risk levels. To solve this problem, we propose a first-order risk-averse leaning algorithm, in which the CVaR gradient estimate depends on an estimate of the Value at Risk (VaR) value combined with the gradient of the stochastic cost function. Although estimation of the CVaR gradients using finitely many samples is generally biased, we show that the accumulated error of the CVaR gradient estimates is bounded with high probability. Moreover, assuming that the risk-averse game is strongly monotone, we show that the proposed algorithm converges to the risk-averse Nash equilibrium. We present numerical experiments on a Cournot game example to illustrate the performance of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.10399v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zifan Wang, Yi Shen, Michael M. Zavlanos, Karl H. Johansson</dc:creator>
    </item>
    <item>
      <title>Quantization Avoids Saddle Points in Distributed Optimization</title>
      <link>https://arxiv.org/abs/2403.10423</link>
      <description>arXiv:2403.10423v1 Announce Type: new 
Abstract: Distributed nonconvex optimization underpins key functionalities of numerous distributed systems, ranging from power systems, smart buildings, cooperative robots, vehicle networks to sensor networks. Recently, it has also merged as a promising solution to handle the enormous growth in data and model sizes in deep learning. A fundamental problem in distributed nonconvex optimization is avoiding convergence to saddle points, which significantly degrade optimization accuracy. We discover that the process of quantization, which is necessary for all digital communications, can be exploited to enable saddle-point avoidance. More specifically, we propose a stochastic quantization scheme and prove that it can effectively escape saddle points and ensure convergence to a second-order stationary point in distributed nonconvex optimization. With an easily adjustable quantization granularity, the approach allows a user to control the number of bits sent per iteration and, hence, to aggressively reduce the communication overhead. Numerical experimental results using distributed optimization and learning problems on benchmark datasets confirm the effectiveness of the approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.10423v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yanan Bo, Yongqiang Wang</dc:creator>
    </item>
    <item>
      <title>Convergence and Trade-Offs in Riemannian Gradient Descent and Riemannian Proximal Point</title>
      <link>https://arxiv.org/abs/2403.10429</link>
      <description>arXiv:2403.10429v1 Announce Type: new 
Abstract: In this work, we analyze two of the most fundamental algorithms in geodesically convex optimization: Riemannian gradient descent and (possibly inexact) Riemannian proximal point. We quantify their rates of convergence and produce different variants with several trade-offs. Crucially, we show the iterates naturally stay in a ball around an optimizer, of radius depending on the initial distance and, in some cases, on the curvature. In contrast, except for limited cases, previous works bounded the maximum distance between iterates and an optimizer only by assumption, leading to incomplete analyses and unquantified rates. We also provide an implementable inexact proximal point algorithm yielding new results on minmax problems, and we prove several new useful properties of Riemannian proximal methods: they work when positive curvature is present, the proximal operator does not move points away from any optimizer, and we quantify the smoothness of its induced Moreau envelope. Further, we explore beyond our theory with empirical tests.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.10429v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David Mart\'inez-Rubio, Christophe Roux, Sebastian Pokutta</dc:creator>
    </item>
    <item>
      <title>A Short Review on Novel Approaches for Maximum Clique Problem: from Classical algorithms to Graph Neural Networks and Quantum algorithms</title>
      <link>https://arxiv.org/abs/2403.09742</link>
      <description>arXiv:2403.09742v1 Announce Type: cross 
Abstract: This manuscript provides a comprehensive review of the Maximum Clique Problem, a computational problem that involves finding subsets of vertices in a graph that are all pairwise adjacent to each other. The manuscript covers in a simple way classical algorithms for solving the problem and includes a review of recent developments in graph neural networks and quantum algorithms. The review concludes with benchmarks for testing classical as well as new learning, and quantum algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.09742v1</guid>
      <category>cs.AI</category>
      <category>cond-mat.dis-nn</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>quant-ph</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Raffaele Marino, Lorenzo Buffoni, Bogdan Zavalnij</dc:creator>
    </item>
    <item>
      <title>Revealing hidden physical nonclassicality with nonnegative polynomials</title>
      <link>https://arxiv.org/abs/2403.09807</link>
      <description>arXiv:2403.09807v1 Announce Type: cross 
Abstract: Understanding quantum phenomena which go beyond classical concepts is a focus of modern quantum physics. Here, we show how the theory of nonnegative polynomials emerging around Hilbert's 17th problem, can be used to optimally exploit data capturing the nonclassical nature of light. Specifically, we show that nonnegative polynomials can reveal nonclassicality in data even when it is hidden from standard detection methods up to now. Moreover, the abstract language of nonnegative polynomials also leads to a unified mathematical approach to nonclassicality for light and spin systems, allowing us to map methods for one to the other. Conversely, the physical problems arising also inspire several mathematical insights into characterisation of nonnegative polynomials.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.09807v1</guid>
      <category>quant-ph</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ties-A. Ohst, Benjamin Yadin, Birte Ostermann, Timo de Wolff, Otfried G\"uhne, Hai-Chau Nguyen</dc:creator>
    </item>
    <item>
      <title>Global Convergence Guarantees for Federated Policy Gradient Methods with Adversaries</title>
      <link>https://arxiv.org/abs/2403.09940</link>
      <description>arXiv:2403.09940v1 Announce Type: cross 
Abstract: Federated Reinforcement Learning (FRL) allows multiple agents to collaboratively build a decision making policy without sharing raw trajectories. However, if a small fraction of these agents are adversarial, it can lead to catastrophic results. We propose a policy gradient based approach that is robust to adversarial agents which can send arbitrary values to the server. Under this setting, our results form the first global convergence guarantees with general parametrization. These results demonstrate resilience with adversaries, while achieving sample complexity of order $\tilde{\mathcal{O}}\left( \frac{1}{\epsilon^2} \left( \frac{1}{N-f} + \frac{f^2}{(N-f)^2}\right)\right)$, where $N$ is the total number of agents and $f$ is the number of adversarial agents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.09940v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Swetha Ganesh, Jiayu Chen, Gugan Thoppe, Vaneet Aggarwal</dc:creator>
    </item>
    <item>
      <title>Compositionally Verifiable Vector Neural Lyapunov Functions for Stability Analysis of Interconnected Nonlinear Systems</title>
      <link>https://arxiv.org/abs/2403.10007</link>
      <description>arXiv:2403.10007v1 Announce Type: cross 
Abstract: While there has been increasing interest in using neural networks to compute Lyapunov functions, verifying that these functions satisfy the Lyapunov conditions and certifying stability regions remain challenging due to the curse of dimensionality. In this paper, we demonstrate that by leveraging the compositional structure of interconnected nonlinear systems, it is possible to verify neural Lyapunov functions for high-dimensional systems beyond the capabilities of current satisfiability modulo theories (SMT) solvers using a monolithic approach. Our numerical examples employ neural Lyapunov functions trained by solving Zubov's partial differential equation (PDE), which characterizes the domain of attraction for individual subsystems. These examples show a performance advantage over sums-of-squares (SOS) polynomial Lyapunov functions derived from semidefinite programming.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.10007v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jun Liu, Yiming Meng, Maxwell Fitzsimmons, Ruikun Zhou</dc:creator>
    </item>
    <item>
      <title>LyZNet: A Lightweight Python Tool for Learning and Verifying Neural Lyapunov Functions and Regions of Attraction</title>
      <link>https://arxiv.org/abs/2403.10013</link>
      <description>arXiv:2403.10013v1 Announce Type: cross 
Abstract: In this paper, we describe a lightweight Python framework that provides integrated learning and verification of neural Lyapunov functions for stability analysis. The proposed tool, named LyZNet, learns neural Lyapunov functions using physics-informed neural networks (PINNs) to solve Zubov's equation and verifies them using satisfiability modulo theories (SMT) solvers. What distinguishes this tool from others in the literature is its ability to provide verified regions of attraction close to the domain of attraction. This is achieved by encoding Zubov's partial differential equation (PDE) into the PINN approach. By embracing the non-convex nature of the underlying optimization problems, we demonstrate that in cases where convex optimization, such as semidefinite programming, fails to capture the domain of attraction, our neural network framework proves more successful. The tool also offers automatic decomposition of coupled nonlinear systems into a network of low-dimensional subsystems for compositional verification. We illustrate the tool's usage and effectiveness with several numerical examples, including both non-trivial low-dimensional nonlinear systems and high-dimensional systems. The repository of the tool can be found at https://git.uwaterloo.ca/hybrid-systems-lab/lyznet.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.10013v1</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jun Liu, Yiming Meng, Maxwell Fitzsimmons, Ruikun Zhou</dc:creator>
    </item>
    <item>
      <title>Unified Projection-Free Algorithms for Adversarial DR-Submodular Optimization</title>
      <link>https://arxiv.org/abs/2403.10063</link>
      <description>arXiv:2403.10063v1 Announce Type: cross 
Abstract: This paper introduces unified projection-free Frank-Wolfe type algorithms for adversarial continuous DR-submodular optimization, spanning scenarios such as full information and (semi-)bandit feedback, monotone and non-monotone functions, different constraints, and types of stochastic queries. For every problem considered in the non-monotone setting, the proposed algorithms are either the first with proven sub-linear $\alpha$-regret bounds or have better $\alpha$-regret bounds than the state of the art, where $\alpha$ is a corresponding approximation bound in the offline setting. In the monotone setting, the proposed approach gives state-of-the-art sub-linear $\alpha$-regret bounds among projection-free algorithms in 7 of the 8 considered cases while matching the result of the remaining case. Additionally, this paper addresses semi-bandit and bandit feedback for adversarial DR-submodular optimization, advancing the understanding of this optimization area.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.10063v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CC</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohammad Pedramfar, Yididiya Y. Nadew, Christopher J. Quinn, Vaneet Aggarwal</dc:creator>
    </item>
    <item>
      <title>Euclidean rectifiability of sub-Finsler spheres in free-Carnot groups of step 2</title>
      <link>https://arxiv.org/abs/2403.10196</link>
      <description>arXiv:2403.10196v1 Announce Type: cross 
Abstract: We consider 2-step free-Carnot groups equipped with sub-Finsler distances. We prove that the metric spheres are codimension-one rectifiable from the Euclidean viewpoint. The result is obtained by studying how the Lipschitz constant for the distance function behaves near abnormal geodesics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.10196v1</guid>
      <category>math.MG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Enrico Le Donne, Luca Nalon</dc:creator>
    </item>
    <item>
      <title>Optimal Control of Stationary Doubly Diffusive Flows on Two and Three Dimensional Bounded Lipschitz Domains: Numerical Analysis</title>
      <link>https://arxiv.org/abs/2403.10282</link>
      <description>arXiv:2403.10282v1 Announce Type: cross 
Abstract: In this work, we propose fully nonconforming, locally exactly divergence-free discretizations based on lowest order Crouziex-Raviart finite element and piecewise constant spaces to study the optimal control of stationary double diffusion model presented in [B\"urger, M\'endez, Ruiz-Baier, SINUM (2019), 57:1318-1343]. The well-posedness of the discrete uncontrolled state and adjoint equations are discussed using discrete lifting and fixed point arguments, and convergence results are derived rigorously under minimal regularity. Building upon our recent work [Tushar, Khan, Mohan arXiv (2023)], we prove the local optimality of a reference control using second-order sufficient optimality condition for the control problem, and use it along with an optimize-then-discretize approach to prove optimal order a priori error estimates for the control, state and adjoint variables upto the regularity of the solution. The optimal control is computed using a primal-dual active set strategy as a semi-smooth Newton method and computational tests validate the predicted error decay rates and illustrate the proposed scheme's applicability to optimal control of thermohaline circulation problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.10282v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Jai Tushar, Arbaz Khan, Manil T. Mohan</dc:creator>
    </item>
    <item>
      <title>Multi-Source Localization and Data Association for Time-Difference of Arrival Measurements</title>
      <link>https://arxiv.org/abs/2403.10329</link>
      <description>arXiv:2403.10329v1 Announce Type: cross 
Abstract: In this work, we consider the problem of localizing multiple signal sources based on time-difference of arrival (TDOA) measurements. In the blind setting, in which the source signals are not known, the localization task is challenging due to the data association problem. That is, it is not known which of the TDOA measurements correspond to the same source. Herein, we propose to perform joint localization and data association by means of an optimal transport formulation. The method operates by finding optimal groupings of TDOA measurements and associating these with candidate source locations. To allow for computationally feasible localization in three-dimensional space, an efficient set of candidate locations is constructed using a minimal multilateration solver based on minimal sets of receiver pairs. In numerical simulations, we demonstrate that the proposed method is robust both to measurement noise and TDOA detection errors. Furthermore, it is shown that the data association provided by the proposed method allows for statistically efficient estimates of the source locations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.10329v1</guid>
      <category>eess.SP</category>
      <category>cs.SD</category>
      <category>eess.AS</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gabrielle Flood, Filip Elvander</dc:creator>
    </item>
    <item>
      <title>A Mean-Field Game of Market Entry: Portfolio Liquidation with Trading Constraints</title>
      <link>https://arxiv.org/abs/2403.10441</link>
      <description>arXiv:2403.10441v1 Announce Type: cross 
Abstract: We consider both $N$-player and mean-field games of optimal portfolio liquidation in which the players are not allowed to change the direction of trading. Players with an initially short position of stocks are only allowed to buy while players with an initially long position are only allowed to sell the stock. Under suitable conditions on the model parameters we show that the games are equivalent to games of timing where the players need to determine the optimal times of market entry and exit. We identify the equilibrium entry and exit times and prove that equilibrium mean-trading rates can be characterized in terms of the solutions to a highly non-linear higher-order integral equation with endogenous terminal condition. We prove the existence of a unique solution to the integral equation from which we obtain the existence of a unique equilibrium both in the mean-field and the $N$-player game.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.10441v1</guid>
      <category>q-fin.MF</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Guanxing Fu, Paul P. Hager, Ulrich Horst</dc:creator>
    </item>
    <item>
      <title>Existence of optimal controls for stochastic Volterra equations</title>
      <link>https://arxiv.org/abs/2207.05169</link>
      <description>arXiv:2207.05169v2 Announce Type: replace 
Abstract: We provide sufficient conditions that guarantee the existence of relaxed optimal controls in the weak formulation of stochastic control problems for stochastic Volterra equations (SVEs). Our study can be applied to rough processes that arise when the kernel appearing in the controlled SVE is singular at zero. The existence of relaxed optimal policies relies on the interaction between integrability hypotheses on the kernel and growth conditions on the running cost functional and the coefficients of the controlled SVEs. Under classical convexity assumptions, we can also deduce the existence of optimal strict controls.</description>
      <guid isPermaLink="false">oai:arXiv.org:2207.05169v2</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>q-fin.MF</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andr\'es C\'ardenas, Sergio Pulido, Rafael Serrano</dc:creator>
    </item>
    <item>
      <title>Inertial Quasi-Newton Methods for Monotone Inclusion: Efficient Resolvent Calculus and Primal-Dual Methods</title>
      <link>https://arxiv.org/abs/2209.14019</link>
      <description>arXiv:2209.14019v3 Announce Type: replace 
Abstract: We introduce an inertial quasi-Newton Forward-Backward Splitting Algorithm to solve a class of monotone inclusion problems. While the inertial step is computationally cheap, in general, the bottleneck is the evaluation of the resolvent operator. A change of the metric makes its computation hard even for (otherwise in the standard metric) simple operators. In order to fully exploit the advantage of adapting the metric, we develop a new efficient resolvent calculus for a low-rank perturbed standard metric, which accounts exactly for quasi-Newton metrics. Moreover, we prove the convergence of our algorithms, including linear convergence rates in case one of the two considered operators is strongly monotone. Beyond the general monotone inclusion setup, we instantiate a novel inertial quasi-Newton Primal-Dual Hybrid Gradient Method for solving saddle point problems. The favourable performance of our inertial quasi-Newton PDHG method is demonstrated on several numerical experiments in image processing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.14019v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shida Wang, Jalal Fadili, Peter Ochs</dc:creator>
    </item>
    <item>
      <title>First-Order Methods for Nonsmooth Nonconvex Functional Constrained Optimization with or without Slater Points</title>
      <link>https://arxiv.org/abs/2212.00927</link>
      <description>arXiv:2212.00927v3 Announce Type: replace 
Abstract: Constrained optimization problems where both the objective and constraints may be nonsmooth and nonconvex arise across many learning and data science settings. In this paper, we show for any Lipschitz, weakly convex objectives and constraints, a simple first-order method finds a feasible, $\epsilon$-stationary point at a convergence rate of $O(\epsilon^{-4})$ without relying on compactness or Constraint Qualification (CQ). When CQ holds, this convergence is measured by approximately satisfying the Karush-Kuhn-Tucker conditions. When CQ fails, we guarantee the attainment of weaker Fritz-John conditions. As an illustrative example, our method stably converges on piecewise quadratic SCAD regularized problems despite frequent violations of constraint qualification. The considered algorithm is similar to those of "Quadratically regularized subgradient methods for weakly convex optimization with weakly convex constraints" by Ma et al. and "Stochastic first-order methods for convex and nonconvex functional constrained optimization" by Boob et al. (whose guarantees further assume compactness and CQ), iteratively taking inexact proximal steps, computed via an inner loop applying a switching subgradient method to a strongly convex constrained subproblem. Our non-Lipschitz analysis of the switching subgradient method appears to be new and may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.00927v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhichao Jia, Benjamin Grimmer</dc:creator>
    </item>
    <item>
      <title>Interpolation Conditions for Linear Operators and Applications to Performance Estimation Problems</title>
      <link>https://arxiv.org/abs/2302.08781</link>
      <description>arXiv:2302.08781v3 Announce Type: replace 
Abstract: The Performance Estimation Problem methodology makes it possible to determine the exact worst-case performance of an optimization method. In this work, we generalize this framework to first-order methods involving linear operators. This extension requires an explicit formulation of interpolation conditions for those linear operators. We consider the class of linear operators $\mathcal{M}:x \mapsto Mx$ where matrix $M$ has bounded singular values, and the class of linear operators where $M$ is symmetric and has bounded eigenvalues. We describe interpolation conditions for these classes, i.e. necessary and sufficient conditions that, given a list of pairs $\{(x_i,y_i)\}$, characterize the existence of a linear operator mapping $x_i$ to $y_i$ for all $i$. Using these conditions, we first identify the exact worst-case behavior of the gradient method applied to the composed objective $h\circ \mathcal{M}$, and observe that it always corresponds to $\mathcal{M}$ being a scaling operator. We then investigate the Chambolle-Pock method applied to $f+g\circ \mathcal{M}$, and improve the existing analysis to obtain a proof of the exact convergence rate of the primal-dual gap. In addition, we study how this method behaves on Lipschitz convex functions, and obtain a numerical convergence rate for the primal accuracy of the last iterate. We also show numerically that averaging iterates is beneficial in this setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.08781v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nizar Bousselmi, Julien M. Hendrickx, Fran\c{c}ois Glineur</dc:creator>
    </item>
    <item>
      <title>The Non-Strict Projection Lemma</title>
      <link>https://arxiv.org/abs/2305.08735</link>
      <description>arXiv:2305.08735v2 Announce Type: replace 
Abstract: The projection lemma (often also referred to as the elimination lemma) is one of the most powerful and useful tools in the context of linear matrix inequalities for system analysis and control. In its traditional formulation, the projection lemma only applies to strict inequalities, however, in many applications we naturally encounter non-strict inequalities. As such, we present, in this note, a non-strict projection lemma that generalizes both its original strict formulation as well as an earlier non-strict version. We demonstrate several applications of our result in robust linear-matrix-inequality-based marginal stability analysis and stabilization, a matrix S-lemma, which is useful in (direct) data-driven control applications, and matrix dilation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.08735v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TAC.2024.3371374</arxiv:DOI>
      <dc:creator>T. J. Meijer, T. Holicki, S. J. A. M. van den Eijnden, C. W. Scherer, W. P. M. H. Heemels</dc:creator>
    </item>
    <item>
      <title>Modeling Nonlinear Control Systems via Koopman Control Family: Universal Forms and Subspace Invariance Proximity</title>
      <link>https://arxiv.org/abs/2307.15368</link>
      <description>arXiv:2307.15368v2 Announce Type: replace 
Abstract: This paper introduces the Koopman Control Family (KCF), a mathematical framework for modeling general discrete-time nonlinear control systems with the aim of providing a solid theoretical foundation for the use of Koopman-based methods in systems with inputs. We demonstrate that the concept of KCF captures the behavior of nonlinear control systems on a (potentially infinite-dimensional) function space. By employing a generalized notion of subspace invariance under the KCF, we establish a universal form for finite-dimensional models, which encompasses the commonly used linear, bilinear, and linear switched models as specific instances. In cases where the subspace is not invariant under the KCF, we propose a method for approximating models in general form and characterize the model's accuracy using the concept of invariance proximity. We end by discussing how the proposed framework naturally lends itself to data-driven modeling of control systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.15368v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Masih Haseli, Jorge Cort\'es</dc:creator>
    </item>
    <item>
      <title>Neur2RO: Neural Two-Stage Robust Optimization</title>
      <link>https://arxiv.org/abs/2310.04345</link>
      <description>arXiv:2310.04345v2 Announce Type: replace 
Abstract: Robust optimization provides a mathematical framework for modeling and solving decision-making problems under worst-case uncertainty. This work addresses two-stage robust optimization (2RO) problems (also called adjustable robust optimization), wherein first-stage and second-stage decisions are made before and after uncertainty is realized, respectively. This results in a nested min-max-min optimization problem which is extremely challenging computationally, especially when the decisions are discrete. We propose Neur2RO, an efficient machine learning-driven instantiation of column-and-constraint generation (CCG), a classical iterative algorithm for 2RO. Specifically, we learn to estimate the value function of the second-stage problem via a novel neural network architecture that is easy to optimize over by design. Embedding our neural network into CCG yields high-quality solutions quickly as evidenced by experiments on two 2RO benchmarks, knapsack and capital budgeting. For knapsack, Neur2RO finds solutions that are within roughly $2\%$ of the best-known values in a few seconds compared to the three hours of the state-of-the-art exact branch-and-price algorithm; for larger and more complex instances, Neur2RO finds even better solutions. For capital budgeting, Neur2RO outperforms three variants of the $k$-adaptability algorithm, particularly on the largest instances, with a 10 to 100-fold reduction in solution time. Our code and data are available at https://github.com/khalil-research/Neur2RO.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.04345v2</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Justin Dumouchelle, Esther Julien, Jannis Kurtz, Elias B. Khalil</dc:creator>
    </item>
    <item>
      <title>Fast projection onto the intersection of simplex and singly linear constraint and its generalized Jacobian</title>
      <link>https://arxiv.org/abs/2310.10388</link>
      <description>arXiv:2310.10388v2 Announce Type: replace 
Abstract: Solving the distributional worst-case in the distributionally robust optimization problem is equivalent to finding the projection onto the intersection of simplex and singly linear inequality constraint, which is an important ingredient in the design of some first-order efficient algorithms. This paper focuses on efficient algorithms for computing the projection onto the intersection of simplex and singly linear inequality constraint. We apply an algorithm based on Lagrangian relaxation approach and secant method (LRSA) to find this projection. From the perspective of Lagrangian duality, we also develop an common algorithm based on semismooth Newton method (Ssn) for solving the dual of the projection problem. Numerical experiments demonstrate that LRSA outperforms Ssn algorithm and the state-of-the-art optimization solver called Gurobi. Moreover, we derive the explicit formulas for the generalized HS-Jacobian of the projection, which plays an important role in designing second-order nonsmooth Newton algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.10388v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weimi Zhou, Yong-Jin Liu</dc:creator>
    </item>
    <item>
      <title>On convergence analysis of feedback control with integral action and discontinuous relay perturbation</title>
      <link>https://arxiv.org/abs/2311.03724</link>
      <description>arXiv:2311.03724v2 Announce Type: replace 
Abstract: We consider third-order dynamic systems which have integral feedback action and discontinuous relay disturbance. More specifically for applications, our focus is on the integral plus state-feedback control of motion systems with the discontinuous Coulomb-type friction. We resume the attractive stiction region, where the hybrid system has also solutions in Filippov sense, while the motion trajectories remain in an idle state (that we call `stiction') until the sliding-mode condition becomes violated through the integral action. We analyze the conditions for occurrence of the slowly converging stick-slip cycles. We also show that the hybrid system is globally but only asymptotically and almost always not exponentially stable. A particular case of exponential convergence can appear for some initial values, assuming the characteristic equation of the linear subsystem has only the real roots. Illustrative numerical examples are provided alongside with the developed analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.03724v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Ruderman</dc:creator>
    </item>
    <item>
      <title>Sparsity and integrality gap transference bounds for integer programs</title>
      <link>https://arxiv.org/abs/2311.06605</link>
      <description>arXiv:2311.06605v2 Announce Type: replace 
Abstract: We obtain new transference bounds that connect two active areas of research: proximity and sparsity of solutions to integer programs. Specifically, we study the additive integrality gap of the integer linear programs min{cx: x in P, x integer}, where P={x: Ax=b, x nonnegative} is a polyhedron in the standard form determined by an integer mxn matrix A and an integer vector b. The main result of the paper shows that the integrality gap drops exponentially in the size of support of the optimal solutions that correspond to the vertices of the integer hull of the polyhedron P. Additionally, we obtain a new proximity bound that estimates the distance from any point of P to its nearest integer point in P. The proofs make use of the results from the geometry of numbers and convex geometry.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.06605v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Iskander Aliev, Marcel Celaya, Martin Henk</dc:creator>
    </item>
    <item>
      <title>BP-MPC: Optimizing the Closed-Loop Performance of MPC using BackPropagation</title>
      <link>https://arxiv.org/abs/2312.15521</link>
      <description>arXiv:2312.15521v2 Announce Type: replace 
Abstract: Model predictive control (MPC) is pervasive in research and industry. However, designing the cost function and the constraints of the MPC to maximize closed-loop performance remains an open problem. To achieve optimal tuning, we propose a backpropagation scheme that solves a policy optimization problem with nonlinear system dynamics and MPC policies. We enforce the system dynamics using linearization and allow the MPC problem to contain elements that depend on the current system state and on past MPC solutions. Moreover, we propose a simple extension that can deal with losses of feasibility. Our approach, unlike other methods in the literature, enjoys convergence guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.15521v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Riccardo Zuliani, Efe C. Balta, John Lygeros</dc:creator>
    </item>
    <item>
      <title>Controlling the Rates of a Chain of Harmonic Oscillators with a Point Langevin Thermostat</title>
      <link>https://arxiv.org/abs/2401.06536</link>
      <description>arXiv:2401.06536v3 Announce Type: replace 
Abstract: We consider the control problem for an infinite chain of coupled harmonic oscillators with a Langevin thermostat at the origin. We study the effect of two types of open-loop boundary controls, impulsive control and linear memory-feedback control, in the high frequency limit. We investigate their action on the reflection-transmission coefficients for the wave energy for the scattering of the thermostat. Our study shows that impulsive boundary controls have no impact on the rates and are thus not appropriate to act on the system, despite their physical meaning and relevance. In contrast, the second kind of control that we propose, which is less standard and uses the past of the state solution of the system, is adequate and relevant. We prove that any triple of rates satisfying appropriate assumptions is asymptotically reachable thanks to linear memory-feedback controls that we design explicitly.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.06536v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Amirali Hannani, Minh-Binh Tran, Minh Nhat Phung, Emmanuel Tr\'elat</dc:creator>
    </item>
    <item>
      <title>A Constrained Tracking Controller for Ramp and Sinusoidal Reference Signals using Robust Positive Invariance</title>
      <link>https://arxiv.org/abs/2403.08987</link>
      <description>arXiv:2403.08987v2 Announce Type: replace 
Abstract: This paper proposes an output feedback controller capable of ensuring steady-state offset-free tracking for ramp and sinusoidal reference signals while ensuring local stability and state and input constraints fulfillment. The proposed solution is derived by jointly exploiting the internal model principle, polyhedral robust positively invariant arguments, and the Extended Farkas' Lemma. In particular, by considering a generic class of output feedback controller equipped with a feedforward term, a proportional effect, and a double integrator, we offline design the controller's gains by means of a single bilinear optimization problem. A peculiar feature of the proposed design is that the sets of all the admissible reference signals and the plant's initial conditions are also offline determined. Simulation results are provided to testify to the effectiveness of the proposed tracking controller and its capability to deal with both state and input constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.08987v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Geovana Franca dos Santos, Eugenio B. Castelan, Walter Lucia</dc:creator>
    </item>
    <item>
      <title>Relationship between General MP and DPP for the Stochastic Recursive Optimal Control Problem With Jumps: Viscosity Solution Framework</title>
      <link>https://arxiv.org/abs/2403.09044</link>
      <description>arXiv:2403.09044v2 Announce Type: replace 
Abstract: This paper is concerned with the relationship between general maximum principle and dynamic programming principle for the stochastic recursive optimal control problem with jumps, where the control domain is not necessarily convex. Relations among the adjoint processes, the generalized Hamiltonian function and the value function are proved, under the assumption of a smooth value function and within the framework of viscosity solutions, respectively. Some examples are given to illustrate the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.09044v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Bin Wang, Jingtao Shi</dc:creator>
    </item>
    <item>
      <title>Long-time behaviour of deterministic Mean Field Games with non-monotone interactions</title>
      <link>https://arxiv.org/abs/2304.09509</link>
      <description>arXiv:2304.09509v2 Announce Type: replace-cross 
Abstract: We consider deterministic Mean Field Games (MFG) in all Euclidean space with a cost functional continuous with respect to the distribution of the agents and attaining its minima in a compact set. We first show that the static MFG with such a cost has an equilibrium, and we build from it a solution of the ergodic MFG system of 1st order PDEs with the same cost. Next we address the long-time limit of the solutions to finite horizon MFG with cost functional satisfying various additional assumptions, but not the classical Lasry-Lions monotonicity condition. Instead we assume that the cost has the same set of minima for all measures describing the population. We prove the convergence of the distribution of the agents and of the value function to a solution of the ergodic MFG system as the horizon of the game tends to infinity, extending to this class of MFG some results of weak KAM theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.09509v2</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Martino Bardi, Hicham Kouhkouh</dc:creator>
    </item>
    <item>
      <title>Learning Constrained Optimization with Deep Augmented Lagrangian Methods</title>
      <link>https://arxiv.org/abs/2403.03454</link>
      <description>arXiv:2403.03454v2 Announce Type: replace-cross 
Abstract: Learning to Optimize (LtO) is a problem setting in which a machine learning (ML) model is trained to emulate a constrained optimization solver. Learning to produce optimal and feasible solutions subject to complex constraints is a difficult task, but is often made possible by restricting the input space to a limited distribution of related problems. Most LtO methods focus on directly learning solutions to the primal problem, and applying correction schemes or loss function penalties to encourage feasibility. This paper proposes an alternative approach, in which the ML model is trained instead to predict dual solution estimates directly, from which primal estimates are constructed to form dual-feasible solution pairs. This enables an end-to-end training scheme is which the dual objective is maximized as a loss function, and solution estimates iterate toward primal feasibility, emulating a Dual Ascent method. First it is shown that the poor convergence properties of classical Dual Ascent are reflected in poor convergence of the proposed training scheme. Then, by incorporating techniques from practical Augmented Lagrangian methods, we show how the training scheme can be improved to learn highly accurate constrained optimization solvers, for both convex and nonconvex problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.03454v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>James Kotary, Ferdinando Fioretto</dc:creator>
    </item>
    <item>
      <title>Scalable Distributed Optimization of Multi-Dimensional Functions Despite Byzantine Adversaries</title>
      <link>https://arxiv.org/abs/2403.06502</link>
      <description>arXiv:2403.06502v2 Announce Type: replace-cross 
Abstract: The problem of distributed optimization requires a group of networked agents to compute a parameter that minimizes the average of their local cost functions. While there are a variety of distributed optimization algorithms that can solve this problem, they are typically vulnerable to "Byzantine" agents that do not follow the algorithm. Recent attempts to address this issue focus on single dimensional functions, or assume certain statistical properties of the functions at the agents. In this paper, we provide two resilient, scalable, distributed optimization algorithms for multi-dimensional functions. Our schemes involve two filters, (1) a distance-based filter and (2) a min-max filter, which each remove neighborhood states that are extreme (defined precisely in our algorithms) at each iteration. We show that these algorithms can mitigate the impact of up to $F$ (unknown) Byzantine agents in the neighborhood of each regular agent. In particular, we show that if the network topology satisfies certain conditions, all of the regular agents' states are guaranteed to converge to a bounded region that contains the minimizer of the average of the regular agents' functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06502v2</guid>
      <category>cs.MA</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kananart Kuwaranancharoen, Lei Xin, Shreyas Sundaram</dc:creator>
    </item>
  </channel>
</rss>
