<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.data-an updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.data-an</link>
    <description>physics.data-an updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.data-an" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 19 Feb 2025 03:00:51 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Analysis of the autocorrelation function for time series with higher-order temporal correlations: An exponential case</title>
      <link>https://arxiv.org/abs/2502.11043</link>
      <description>arXiv:2502.11043v1 Announce Type: cross 
Abstract: Temporal correlations in the time series observed in various systems have been characterized by the autocorrelation function. Such correlations can be explained by heavy-tailed interevent time distributions as well as by correlations between interevent times. The latter is called higher-order temporal correlations, and they have been captured by the notion of bursts; a burst indicates a set of consecutive events that rapidly occur within a short time period and are separated from other bursts by long time intervals. The number of events in the burst is called a burst size. Some empirical analyses have shown that consecutive burst sizes are correlated with each other. To study the impact of such correlations on the autocorrelation function, we devise a model generating a time series with higher-order temporal correlations by employing the copula method. We successfully derive the analytical solution of the autocorrelation function of the model time series for arbitrary distributions of interevent times and burst sizes when consecutive burst sizes are correlated. For the demonstration of our analysis, we adopt exponential distributions of interevent times and burst sizes to understand how the correlations between consecutive burst sizes affect the decaying behavior of the autocorrelation function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.11043v1</guid>
      <category>physics.comp-ph</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Min-ho Yu, Hang-Hyun Jo</dc:creator>
    </item>
    <item>
      <title>SFTs: a scalable data-analysis framework for long-duration gravitational-wave signals</title>
      <link>https://arxiv.org/abs/2502.11823</link>
      <description>arXiv:2502.11823v1 Announce Type: cross 
Abstract: We introduce a framework based on Short-time Fourier Transforms (SFTs) to analyze long-duration gravitational wave signals from compact binaries. Targeted systems include binary neutron stars observed by third-generation ground-based detectors and massive black-hole binaries observed by the LISA space mission. In short, ours is an extremely fast, scalable, and parallelizable implementation of the gravitational-wave inner product, a core operation of gravitational-wave matched filtering. By operating on disjoint data segments, SFTs allow for efficient handling of noise non-stationarities, data gaps, and detector-induced signal modulations. We present a pilot application to early warning problems in both ground- and space-based next-generation detectors. Overall, SFTs reduce the computing cost of evaluating an inner product by three to five orders of magnitude, depending on the specific application, with respect to a standard approach. We release public tools to operate using the SFT framework, including a vectorized and hardware-accelerated re-implementation of a time-domain waveform. The inner product is the key building block of all gravitational-wave data treatments; by speeding up this low-level element so massively, SFTs provide an extremely promising solution for current and future gravitational-wave data-analysis problem</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.11823v1</guid>
      <category>gr-qc</category>
      <category>astro-ph.HE</category>
      <category>astro-ph.IM</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rodrigo Tenorio, Davide Gerosa</dc:creator>
    </item>
    <item>
      <title>Exploring the BSM parameter space with Neural Network aided Simulation-Based Inference</title>
      <link>https://arxiv.org/abs/2502.11928</link>
      <description>arXiv:2502.11928v1 Announce Type: cross 
Abstract: Some of the issues that make sampling parameter spaces of various beyond the Standard Model (BSM) scenarios computationally expensive are the high dimensionality of the input parameter space, complex likelihoods, and stringent experimental constraints. In this work, we explore likelihood-free approaches, leveraging neural network-aided Simulation-Based Inference (SBI) to alleviate this issue. We focus on three amortized SBI methods: Neural Posterior Estimation (NPE), Neural Likelihood Estimation (NLE), and Neural Ratio Estimation (NRE) and perform a comparative analysis through the validation test known as the \textit{ Test of Accuracy with Random Points} (TARP), as well as through posterior sample efficiency and computational time. As an example, we focus on the scalar sector of the phenomenological minimal supersymmetric SM (pMSSM) and observe that the NPE method outperforms the others and generates correct posterior distributions of the parameters with a minimal number of samples. The efficacy of this framework will be more evident with additional experimental data, especially for high dimensional parameter space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.11928v1</guid>
      <category>hep-ph</category>
      <category>hep-ex</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Atrideb Chatterjee, Arghya Choudhury, Sourav Mitra, Arpita Mondal, Subhadeep Mondal</dc:creator>
    </item>
    <item>
      <title>Sampling the full hierarchical population posterior distribution in gravitational-wave astronomy</title>
      <link>https://arxiv.org/abs/2502.12156</link>
      <description>arXiv:2502.12156v1 Announce Type: cross 
Abstract: We present a full sampling of the hierarchical population posterior distribution of merging black holes using current gravitational-wave data. We directly tackle the the most relevant intrinsic parameter space made of the binary parameters (masses, spin magnitudes, spin directions, redshift) of all the events entering the GWTC-3 LIGO/Virgo/KAGRA catalog, as well as the hyperparameters of the underlying population of sources. This results in a parameter space of about 500 dimensions, in contrast with current investigations where the targeted dimensionality is drastically reduced by marginalizing over all single-event parameters. In particular, we have direct access to (i) population parameters, (ii) population-informed single-event parameters, and (iii) correlations between these two sets of parameters. Our implementation relies on modern probabilistic programming languages and Hamiltonian Monte Carlo, with a continuous interpolation of single-event posterior probabilities. Sampling the full hierarchical problem is feasible, as demonstrated here, and advantageous as it removes some (but not all) of the Monte Carlo integrations that enter the likelihood together with the related variances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12156v1</guid>
      <category>gr-qc</category>
      <category>astro-ph.CO</category>
      <category>astro-ph.HE</category>
      <category>astro-ph.IM</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michele Mancarella, Davide Gerosa</dc:creator>
    </item>
    <item>
      <title>Optimal Low-Depth Quantum Signal-Processing Phase Estimation</title>
      <link>https://arxiv.org/abs/2407.01583</link>
      <description>arXiv:2407.01583v2 Announce Type: replace-cross 
Abstract: Quantum effects like entanglement and coherent amplification can be used to drastically enhance the accuracy of quantum parameter estimation beyond classical limits. However, challenges such as decoherence and time-dependent errors hinder Heisenberg-limited amplification. We introduce Quantum Signal-Processing Phase Estimation algorithms that are robust against these challenges and achieve optimal performance as dictated by the Cram\'{e}r-Rao bound. These algorithms use quantum signal transformation to decouple interdependent phase parameters into largely orthogonal ones, ensuring that time-dependent errors in one do not compromise the accuracy of learning the other. Combining provably optimal classical estimation with near-optimal quantum circuit design, our approach achieves a standard deviation accuracy of $10^{-4}$ radians for estimating unwanted swap angles in superconducting two-qubit experiments, using low-depth ($&lt;10$) circuits. This represents up to two orders of magnitude improvement over existing methods. Theoretically and numerically, we demonstrate the optimality of our algorithm against time-dependent phase errors, observing that the variance of the time-sensitive parameter $\varphi$ scales faster than the asymptotic Heisenberg scaling in the small-depth regime. Our results are rigorously validated against the quantum Fisher information, confirming our protocol's ability to achieve unmatched precision for two-qubit gate learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.01583v2</guid>
      <category>quant-ph</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1038/s41467-025-56724-x</arxiv:DOI>
      <arxiv:journal_reference>Nature Communications 16, no. 1 (2025): 1504</arxiv:journal_reference>
      <dc:creator>Yulong Dong, Jonathan A. Gross, Murphy Yuezhen Niu</dc:creator>
    </item>
    <item>
      <title>Learning Interpretable Hierarchical Dynamical Systems Models from Time Series Data</title>
      <link>https://arxiv.org/abs/2410.04814</link>
      <description>arXiv:2410.04814v2 Announce Type: replace-cross 
Abstract: In science, we are often interested in obtaining a generative model of the underlying system dynamics from observed time series. While powerful methods for dynamical systems reconstruction (DSR) exist when data come from a single domain, how to best integrate data from multiple dynamical regimes and leverage it for generalization is still an open question. This becomes particularly important when individual time series are short, and group-level information may help to fill in for gaps in single-domain data. Here we introduce a hierarchical framework that enables to harvest group-level (multi-domain) information while retaining all single-domain characteristics, and showcase it on popular DSR benchmarks, as well as on neuroscience and medical data. In addition to faithful reconstruction of all individual dynamical regimes, our unsupervised methodology discovers common low-dimensional feature spaces in which datasets with similar dynamics cluster. The features spanning these spaces were further dynamically highly interpretable, surprisingly in often linear relation to control parameters that govern the dynamics of the underlying system. Finally, we illustrate transfer learning and generalization to new parameter regimes, paving the way toward DSR foundation models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04814v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.DS</category>
      <category>nlin.CD</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Manuel Brenner, Elias Weber, Georgia Koppe, Daniel Durstewitz</dc:creator>
    </item>
    <item>
      <title>Diffractive Magic Cube Network with Super-high Capacity Enabled by Mechanical Reconfiguration</title>
      <link>https://arxiv.org/abs/2412.20693</link>
      <description>arXiv:2412.20693v2 Announce Type: replace-cross 
Abstract: Multiplexing and dynamic reconfigurable metasurfaces have been extensively studied to enhance system capacity in response to the challenges posed by the exponential growth of optical information. Among them, the mechanically reconfigurable strategy offers a cost-effective and low-complexity approach for capacity enhancement. However, the channel numbers achieved in current studies are insufficient for practical applications because of inadequate mechanical transformations and suboptimal optimization methods. In this article, a diffractive magic cube network (DMCN) is proposed to advance the multiplexing capacity of mechanically reconfigurable metasurfaces. We utilized the deep diffractive neural network (D2NN) model to jointly optimize the subset of channels generated by the combination of three mechanical operations, permutation, translation, and rotation. The 144-channel holograms, 108-channel single-focus/multi-focus, and 60-channel orbital angular momentum (OAM) beam/comb generation were numerically achieved and experimentally validated using a spatial light modulator (SLM) and a reflective mirror. Our strategy not only provides a novel paradigm to improve metasurface capacity to super-high level with low crosstalk, but also paves the way for new advancements in optical storage, computing, communication, and photolithography.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.20693v2</guid>
      <category>physics.optics</category>
      <category>physics.app-ph</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Peijie Feng, Fubei Liu, Yuanfeng Liu, Mingzhe Chong, Zongkun Zhang, Qian Zhao, Jingbo Sun, Ji Zhou, Yunhua Tan</dc:creator>
    </item>
    <item>
      <title>Interpretable and Equation-Free Response Theory for Complex Systems</title>
      <link>https://arxiv.org/abs/2502.07908</link>
      <description>arXiv:2502.07908v2 Announce Type: replace-cross 
Abstract: Response theory provides a pathway for understanding the sensitivity of a system and, more in general, to predict how its statistical properties change as a possibly time-dependent perturbation is applied. Recently discovered general forms of the celebrated Fluctuation-Dissipation Theorem allow for expressing response operators as correlation functions of suitably defined observables in the unperturbed state, also when such a state is far from equilibrium. In the case of complex and multiscale systems, to achieved enhanced practical applicability, response theory must be interpretable, capable of focusing of relevant timescales, and amenable to implemented by data-driven approaches that are potentially equation-agnostic. Complex systems typically exhibit a hierarchy of temporal behaviors, and unresolved or undesired timescales can obscure the dominant mechanisms driving macroscopic responses. As an element of this desired framework, in the spirit of Markov state modelling, we propose here a comprehensive analysis of the linear and nonlinear response of Markov chains to general time-dependent perturbations. We obtain simple and easily implementable formulas that can be used to predict the response of observables as well as higher-order correlations of the system. The methodology proposed here can be implemented in a purely data-driven setting and even if we do not know the underlying evolution equations. The use of algebraic expansions inspired by Koopmanism allow to elucidate the role of different time scales and find explicit and interpretable expressions for the Green's functions at all orders. This is a major advantage of the framework proposed here. We illustrate our methodology in a very simple yet instructive metastable system. Finally, our results provide a dynamical foundation for the Prony method, which is commonly used for the statistical analysis of discrete time signals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.07908v2</guid>
      <category>cond-mat.stat-mech</category>
      <category>nlin.CD</category>
      <category>physics.comp-ph</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Valerio Lucarini</dc:creator>
    </item>
  </channel>
</rss>
