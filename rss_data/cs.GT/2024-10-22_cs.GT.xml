<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 23 Oct 2024 02:08:05 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Double Distributionally Robust Bid Shading for First Price Auctions</title>
      <link>https://arxiv.org/abs/2410.14864</link>
      <description>arXiv:2410.14864v1 Announce Type: new 
Abstract: Bid shading has become a standard practice in the digital advertising industry, in which most auctions for advertising (ad) opportunities are now of first price type. Given an ad opportunity, performing bid shading requires estimating not only the value of the opportunity but also the distribution of the highest bid from competitors (i.e. the competitive landscape). Since these two estimates tend to be very noisy in practice, first-price auction participants need a bid shading policy that is robust against relatively significant estimation errors. In this work, we provide a max-min formulation in which we maximize the surplus against an adversary that chooses a distribution both for the value and the competitive landscape, each from a Kullback-Leibler-based ambiguity set. As we demonstrate, the two ambiguity sets are essential to adjusting the shape of the bid-shading policy in a principled way so as to effectively cope with uncertainty. Our distributionally robust bid shading policy is efficient to compute and systematically outperforms its non-robust counterpart on real datasets provided by Yahoo DSP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14864v1</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yanlin Qu, Ravi Kant, Yan Chen, Brendan Kitts, San Gultekin, Aaron Flores, Jose Blanchet</dc:creator>
    </item>
    <item>
      <title>Switchback Price Experiments with Forward-Looking Demand</title>
      <link>https://arxiv.org/abs/2410.14904</link>
      <description>arXiv:2410.14904v1 Announce Type: new 
Abstract: We consider a retailer running a switchback experiment for the price of a single product, with infinite supply. In each period, the seller chooses a price $p$ from a set of predefined prices that consist of a reference price and a few discounted price levels. The goal is to estimate the demand gradient at the reference price point, with the goal of adjusting the reference price to improve revenue after the experiment. In our model, in each period, a unit mass of buyers arrives on the market, with values distributed based on a time-varying process. Crucially, buyers are forward looking with a discounted utility and will choose to not purchase now if they expect to face a discounted price in the near future. We show that forward-looking demand introduces bias in naive estimators of the demand gradient, due to intertemporal interference. Furthermore, we prove that there is no estimator that uses data from price experiments with only two price points that can recover the correct demand gradient, even in the limit of an infinitely long experiment with an infinitesimal price discount. Moreover, we characterize the form of the bias of naive estimators. Finally, we show that with a simple three price level experiment, the seller can remove the bias due to strategic forward-looking behavior and construct an estimator for the demand gradient that asymptotically recovers the truth.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14904v1</guid>
      <category>cs.GT</category>
      <category>econ.EM</category>
      <category>econ.TH</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yifan Wu, Ramesh Johari, Vasilis Syrgkanis, Gabriel Y. Weintraub</dc:creator>
    </item>
    <item>
      <title>Mind the Remaining: Mechanism Design for Robust Federated Unlearning</title>
      <link>https://arxiv.org/abs/2410.15045</link>
      <description>arXiv:2410.15045v1 Announce Type: new 
Abstract: Federated Unlearning (FU) aims to remove target clients' influence from trained models for privacy regulations. However, due to data distribution shifts, it can introduce side effects, including global model performance degradation and uneven impacts on the remaining clients. These effects potentially cause remaining clients to deviate, threatening the system's robustness. To address these challenges, we present a novel and robust mechanism modeling a Stackelberg game for FU. In this game, the server designs an optimal payment to stimulate remaining clients to participate in FU, ensuring unlearning effectiveness and stability. In response, the remaining clients strategically determine their participation level to maximize profit, accounting for offered payments and unlearning impacts. In modeling FU outcomes, we develop, for the first time, a comprehensive framework analytically capturing FU-induced side effects for both the server and clients. Based on this, we establish utility functions for the server and clients in FU, inherently determining their dynamic strategic decision-making. Our rigorous equilibrium analysis reveals how data heterogeneity affects the side effects in their utility and decision-making. Additionally, we develop a low-complexity algorithm for the non-convex optimization problem, enabling efficient computation of the equilibrium.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15045v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiaqi Shao, Tao Lin, Bing Luo</dc:creator>
    </item>
    <item>
      <title>Relay Incentive Mechanisms Using Wireless Power Transfer in Non-Cooperative Networks</title>
      <link>https://arxiv.org/abs/2410.15214</link>
      <description>arXiv:2410.15214v1 Announce Type: new 
Abstract: This paper studies the use of a multi-attribute auction in a communication system to bring about efficient relaying in a non-cooperative setting. We consider a system where a source seeks to offload data to an access point (AP) while balancing both the timeliness and energy-efficiency of the transmission. A deep fade in the communication channel (due to, e.g., a line-of-sight blockage) makes direct communication costly, and the source may alternatively rely on non-cooperative UEs to act as relays. We propose a multi-attribute auction to select a UE and to determine the duration and power of the transmission, with payments to the UE taking the form of energy sent via wireless power transfer (WPT). The quality of the channel from a UE to the AP constitutes private information, and bids consist of a transmission time and transmission power. We show that under a second-preferred-offer auction, truthful bidding by all candidate UEs forms a Nash Equilibrium. However, this auction is not incentive compatible, and we present a modified auction in which truthful bidding is in fact a dominant strategy. Extensive numerical experimentation illustrates the efficacy of our approach, which we compare to a cooperative baseline. We demonstrate that with as few as two candidates, our improved mechanism leads to as much as a 76% reduction in energy consumption, and that with as few as three candidates, the transmission time decreases by as much as 55%. Further, we see that as the number of candidates increases, the performance of our mechanism approaches that of the cooperative baseline. Overall, our findings highlight the potential of multi-attribute auctions to enhance the efficiency of data transfer in non-cooperative settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15214v1</guid>
      <category>cs.GT</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Winston Hurst, Yasamin Mostofi</dc:creator>
    </item>
    <item>
      <title>A Machine Learning Approach to Detect Strategic Behavior from Large-Population Observational Data Applied to Game Mode Prediction on a Team-Based Video Game</title>
      <link>https://arxiv.org/abs/2410.15684</link>
      <description>arXiv:2410.15684v1 Announce Type: new 
Abstract: Modeling the strategic behavior of agents in a real-world multi-agent system using existing state-of-the-art computational game-theoretic tools can be a daunting task, especially when only the actions taken by the agents can be observed. Before attempting such a task, it would be useful to gain insight into whether or not agents are in fact acting strategically at all, from a game-theoretic perspective. In this paper, we present an initial step toward addressing this problem by proposing a general approach based on machine learning fundamentals for detecting potentially strategic behavior. We instantiate the approach by applying state-of-the-art machine learning tools for model selection and performance evaluation of prediction models in the context of detecting the strategic behavior of players for game mode selection in the multiplayer online video game Heroes of the Storm. Specifically, as a baseline, we first train neural networks to predict players' game mode selections using only information about the state of the player themselves. Then, we train a new set of neural networks using the same architectures, this time incorporating "historical co-play" features that encode players' past interactions with other players. We find that including these new features led to statistically significant improvements in game mode prediction accuracy, providing a sufficiently strong signal that players indeed make decisions strategically, which justifies the development of more complex computational game-theoretic tools in the hope of improving modeling and predictive power. We discuss remaining research work about potential approaches to validate the effectiveness of this initial step to detect strategic behavior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15684v1</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Boshen Wang, Luis E. Ortiz</dc:creator>
    </item>
    <item>
      <title>A Fair Allocation is Approximately Optimal for Indivisible Chores, or Is It?</title>
      <link>https://arxiv.org/abs/2410.15738</link>
      <description>arXiv:2410.15738v1 Announce Type: new 
Abstract: In this paper, we study the allocation of indivisible chores and consider the problem of finding a fair allocation that is approximately efficient. We shift our attention from the multiplicative approximation to the additive one. Our results are twofold, with (1) bounding how the optimal social cost escalates resulting from fairness requirements and (2) presenting the hardness of approximation for the problems of finding fair allocations with the minimum social cost. To quantify the escalation, we introduce cost of fairness (CoF) $\unicode{x2014}$ an alternative to the price of fairness (PoF) $\unicode{x2014}$ to bound the difference (v.s. ratio for PoF) between the optimal social cost with and without fairness constraints in the worst-case instance. We find that CoF is more informative than PoF for chores in the sense that the PoF is infinity regarding all EQX (equitable up to any item), EQ1 (equitable up to one item) and EF1 (envy-free up to one item), while the CoF is $n$ regarding EQX and 1 regarding EQ1 and EF1, where $n$ is the number of agents. For inapproximability, we present a detailed picture of hardness of approximation. We prove that finding the optimal EQX allocation within an additive approximation factor of $n$ is NP-hard for any $n \geq 2$ where $n$ is the number of agents and the cost functions are normalized to 1. For EQ1 and EF1, the problem is NP-hard when the additive factor is a constant and $n \geq 3$. When $n = 2$, we design additive approximation schemes for EQ1 and EF1.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15738v1</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bo Li, Ankang Sun, Shiji Xing</dc:creator>
    </item>
    <item>
      <title>Constrained Truthful Obnoxious Two-Facility Location with Optional Preferences</title>
      <link>https://arxiv.org/abs/2410.16131</link>
      <description>arXiv:2410.16131v1 Announce Type: new 
Abstract: We consider a truthful facility location problem with agents that have private positions on the line of real numbers and known optional preferences over two obnoxious facilities that must be placed at locations chosen from a given set of candidate ones. Each agent wants to be as far away as possible from the facilities that affect her, and our goal is to design mechanisms that decide where to place the facilities so as to maximize the total happiness of the agents as well as provide the right incentives to them to truthfully report their positions. We consider separately the setting in which all agents are affected by both facilities (i.e., they have non-optional preferences) and the general optional setting. We show tight bounds on the approximation ratio of deterministic strategyproof mechanisms for both settings, and almost tight bounds for randomized mechanisms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.16131v1</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Panagiotis Kanellopoulos, Alexandros A. Voudouris</dc:creator>
    </item>
    <item>
      <title>A positional $\mathbf{\Pi}^0_3$-complete objective</title>
      <link>https://arxiv.org/abs/2410.14688</link>
      <description>arXiv:2410.14688v1 Announce Type: cross 
Abstract: We study zero-sum turn-based games on graphs. In this note, we show the existence of a game objective that is $\mathbf{\Pi}^0_3$-complete for the Borel hierarchy and that is positional, i.e., for which positional strategies suffice for the first player to win over arenas of arbitrary cardinality. To the best of our knowledge, this is the first known such objective; all previously known positional objectives are in $\mathbf{\Sigma}^0_3$. The objective in question is a qualitative variant of the well-studied total-payoff objective, where the goal is to maximise the sum of weights.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14688v1</guid>
      <category>cs.CC</category>
      <category>cs.FL</category>
      <category>cs.GT</category>
      <category>cs.LO</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Antonio Casares, Pierre Ohlmann, Pierre Vandenhove</dc:creator>
    </item>
    <item>
      <title>Optimizing Individualized Incentives from Grid Measurements and Limited Knowledge of Agent Behavior</title>
      <link>https://arxiv.org/abs/2410.14936</link>
      <description>arXiv:2410.14936v1 Announce Type: cross 
Abstract: As electrical generation becomes more distributed and volatile, and loads become more uncertain, controllability of distributed energy resources (DERs), regardless of their ownership status, will be necessary for grid reliability. Grid operators lack direct control over end-users' grid interactions, such as energy usage, but incentives can influence behavior -- for example, an end-user that receives a grid-driven incentive may adjust their consumption or expose relevant control variables in response. A key challenge in studying such incentives is the lack of data about human behavior, which usually motivates strong assumptions, such as distributional assumptions on compliance or rational utility-maximization. In this paper, we propose a general incentive mechanism in the form of a constrained optimization problem -- our approach is distinguished from prior work by modeling human behavior (e.g., reactions to an incentive) as an arbitrary unknown function. We propose feedback-based optimization algorithms to solve this problem that each leverage different amounts of information and/or measurements. We show that each converges to an asymptotically stable incentive with (near)-optimality guarantees given mild assumptions on the problem. Finally, we evaluate our proposed techniques in voltage regulation simulations on standard test beds. We test a variety of settings, including those that break assumptions required for theoretical convergence (e.g., convexity, smoothness) to capture realistic settings. In this evaluation, our proposed algorithms are able to find near-optimal incentives even when the reaction to an incentive is modeled by a theoretically difficult (yet realistic) function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14936v1</guid>
      <category>eess.SY</category>
      <category>cs.GT</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Adam Lechowicz, Joshua Comden, Andrey Bernstein</dc:creator>
    </item>
    <item>
      <title>DPVS-Shapley:Faster and Universal Contribution Evaluation Component in Federated Learning</title>
      <link>https://arxiv.org/abs/2410.15093</link>
      <description>arXiv:2410.15093v1 Announce Type: cross 
Abstract: In the current era of artificial intelligence, federated learning has emerged as a novel approach to addressing data privacy concerns inherent in centralized learning paradigms. This decentralized learning model not only mitigates the risk of data breaches but also enhances the system's scalability and robustness. However, this approach introduces a new challenge: how to fairly and accurately assess the contribution of each participant. Developing an effective contribution evaluation mechanism is crucial for federated learning. Such a mechanism incentivizes participants to actively contribute their data and computational resources, thereby improving the overall performance of the federated learning system. By allocating resources and rewards based on the size of the contributions, it ensures that each participant receives fair treatment, fostering sustained engagement.Currently, Shapley value-based methods are widely used to evaluate participants' contributions, with many researchers proposing modifications to adapt these methods to real-world scenarios. In this paper, we introduce a component called Dynamic Pruning Validation Set Shapley (DPVS-Shapley). This method accelerates the contribution assessment process by dynamically pruning the original dataset without compromising the evaluation's accuracy. Furthermore, this component can assign different weights to various samples, thereby allowing clients capable of distinguishing difficult examples to receive higher contribution scores.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15093v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CR</category>
      <category>cs.GT</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ketin Yin, Zonghao Guo, ZhengHan Qin</dc:creator>
    </item>
    <item>
      <title>Patrol Security Game: Defending Against Adversary with Freedom in Attack Timing, Location, and Duration</title>
      <link>https://arxiv.org/abs/2410.15600</link>
      <description>arXiv:2410.15600v1 Announce Type: cross 
Abstract: We explored the Patrol Security Game (PSG), a robotic patrolling problem modeled as an extensive-form Stackelberg game, where the attacker determines the timing, location, and duration of their attack. Our objective is to devise a patrolling schedule with an infinite time horizon that minimizes the attacker's payoff. We demonstrated that PSG can be transformed into a combinatorial minimax problem with a closed-form objective function. By constraining the defender's strategy to a time-homogeneous first-order Markov chain (i.e., the patroller's next move depends solely on their current location), we proved that the optimal solution in cases of zero penalty involves either minimizing the expected hitting time or return time, depending on the attacker model, and that these solutions can be computed efficiently. Additionally, we observed that increasing the randomness in the patrol schedule reduces the attacker's expected payoff in high-penalty cases. However, the minimax problem becomes non-convex in other scenarios. To address this, we formulated a bi-criteria optimization problem incorporating two objectives: expected maximum reward and entropy. We proposed three graph-based algorithms and one deep reinforcement learning model, designed to efficiently balance the trade-off between these two objectives. Notably, the third algorithm can identify the optimal deterministic patrol schedule, though its runtime grows exponentially with the number of patrol spots. Experimental results validate the effectiveness and scalability of our solutions, demonstrating that our approaches outperform state-of-the-art baselines on both synthetic and real-world crime datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15600v1</guid>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>cs.RO</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hao-Tsung Yang, Ting-Kai Weng, Ting-Yu Chang, Kin Sum Liu, Shan Lin, Jie Gao, Shih-Yu Tsai</dc:creator>
    </item>
    <item>
      <title>Playing Divide-and-Choose Given Uncertain Preferences</title>
      <link>https://arxiv.org/abs/2207.03076</link>
      <description>arXiv:2207.03076v2 Announce Type: replace 
Abstract: We study the classic divide-and-choose method for equitably allocating divisible goods between two players who are rational, self-interested Bayesian agents. The players have additive values for the goods. The prior distributions on those values are common knowledge. We consider both the cases of independent values and values that are correlated across players (as occurs when there is a common-value component).
  We describe the structure of optimal divisions in the divide-and-choose game and identify several cases where it is possible to efficiently compute equilibria. An approximation algorithm is presented for the case when the distribution over the chooser's value for each good follows a normal distribution, along with a randomized approximation algorithm for the case of uniform distributions over intervals.
  A mixture of analytic results and computational simulations illuminates several striking differences between optimal strategies in the cases of known versus unknown preferences. Most notably, given unknown preferences, the divider has a compelling "diversification" incentive in creating the chooser's two options. This incentive leads to multiple goods being divided at equilibrium, quite contrary to the divider's optimal strategy when preferences are known.
  In many contexts, such as buy-and-sell provisions between partners, or in judging fairness, it is important to assess the relative expected utilities of the divider and chooser. Those utilities, we show, depend on the players' levels of knowledge about each other's values, the correlations between the players' values, and the number of goods being divided. Under fairly mild assumptions, we show that the chooser is strictly better off for a small number of goods, while the divider is strictly better off for a large number of goods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2207.03076v2</guid>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jamie Tucker-Foltz, Richard Zeckhauser</dc:creator>
    </item>
    <item>
      <title>Computing Optimal Commitments to Strategies and Outcome-Conditional Utility Transfers</title>
      <link>https://arxiv.org/abs/2402.06626</link>
      <description>arXiv:2402.06626v3 Announce Type: replace 
Abstract: Prior work has studied the computational complexity of computing optimal strategies to commit to in Stackelberg or leadership games, where a leader commits to a strategy which is observed by one or more followers. We extend this setting to one where the leader can additionally commit to outcome-conditional utility transfers. We characterize the computational complexity of finding optimal strategies in normal-form and Bayesian games, giving a mix of efficient algorithms and NP-hardness results. Finally, we allow the leader to also commit to a signaling scheme which induces a correlated equilibrium. In this setting, optimal commitments can be found in polynomial time for arbitrarily many players.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.06626v3</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nathaniel Sauerberg, Caspar Oesterheld</dc:creator>
    </item>
    <item>
      <title>Mechanism Design for LLM Fine-tuning with Multiple Reward Models</title>
      <link>https://arxiv.org/abs/2405.16276</link>
      <description>arXiv:2405.16276v3 Announce Type: replace 
Abstract: Fine-tuning large language models (LLMs) to aggregate multiple preferences has attracted considerable research attention. With aggregation algorithms advancing, a potential economic scenario arises where fine-tuning services are provided to agents with different preferences. In this context, agents may benefit from strategically misreporting their preferences, which could affect the fine-tuned outcomes. This paper addresses such incentive issues by framing it as a mechanism design problem: an LLM provider determines the fine-tuning objective (training rule) and the pricing scheme (payment rule) for agents. We primarily focus on a representative class of training rules that maximize social welfare subject to certain regularizations, referred to as \tr\ rules. Firstly, we show that under most circumstances, truthful reporting is sub-optimal with simply a training rule, thereby highlighting the necessity of payments. Secondly, we design affine maximizer payment rules that implement \tr\ rules in dominant-strategy incentive compatibility (DSIC). We characterize sufficient conditions for payment equivalence properties. For a training rule that satisfies these conditions, we have found all the payment rules that implement it in DSIC, as they only differ by a constant term irrelevant to agents' reports from each other. Thirdly, we demonstrate that our mechanism is approximately DSIC even with perturbed input, showcasing its robustness against the inevitable errors in real-world applications. Experiments on real LLM setups further confirm the practical implications of our results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16276v3</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haoran Sun, Yurong Chen, Siwei Wang, Wei Chen, Xiaotie Deng</dc:creator>
    </item>
    <item>
      <title>A Differentially Private Energy Trading Mechanism Approaching Social Optimum</title>
      <link>https://arxiv.org/abs/2410.04787</link>
      <description>arXiv:2410.04787v2 Announce Type: replace 
Abstract: This paper proposes a differentially private energy trading mechanism for prosumers in peer-to-peer (P2P) markets, offering provable privacy guarantees while approaching the Nash equilibrium with nearly socially optimal efficiency. We first model the P2P energy trading as a (generalized) Nash game and prove the vulnerability of traditional distributed algorithms to privacy attacks through an adversarial inference model. To address this challenge, we develop a privacy-preserving Nash equilibrium seeking algorithm incorporating carefully calibrated Laplacian noise. We prove that the proposed algorithm achieves $\epsilon$-differential privacy while converging in expectation to the Nash equilibrium with a suitable stepsize. Numerical experiments are conducted to evaluate the algorithm's robustness against privacy attacks, convergence behavior, and optimality compared to the non-private solution. Results demonstrate that our mechanism effectively protects prosumers' sensitive information while maintaining near-optimal market outcomes, offering a practical approach for privacy-preserving coordination in P2P markets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04787v2</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yuji Cao, Yue Chen</dc:creator>
    </item>
  </channel>
</rss>
