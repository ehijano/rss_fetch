<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 12 Mar 2024 04:00:22 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 12 Mar 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Lateral Control of Brain-Controlled Vehicle Based on SVM Probability Output Model</title>
      <link>https://arxiv.org/abs/2403.05762</link>
      <description>arXiv:2403.05762v1 Announce Type: new 
Abstract: The non-stationary characteristics of EEG signal and the individual differences of brain-computer interfaces (BCIs) lead to poor performance in the control process of the brain-controlled vehicles (BCVs). In this paper, by combining steady-state visual evoked potential (SSVEP) interactive interface, brain instructions generation module and vehicle lateral control module, a probabilistic output model based on support vector machine (SVM) is proposed for BCV lateral control to improve the driving performance. Firstly, a filter bank common spatial pattern (FBCSP) algorithm is introduced into the brain instructions generation module, which can improve the off-line decoding performance. Secondly, a sigmod-fitting SVM (SF-SVM) is trained based on the sigmod-fitting method and the lateral control module is developed, which can produce all commands in the form of probability instead of specific single command. Finally, a pre-experiment and two road-keeping experiments are conducted. In the pre-experiment, the experiment results show that, the average highest off-line accuracy among subjects is 95.64\%, while for those in the online stage, the average accuracy is only 84.44\%. In the road-keeping experiments, the task completion rate in the two designed scenes increased by 25.6\% and 20\%, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05762v1</guid>
      <category>q-bio.NC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongguang Pan, Xinyu Yu, Yong Yang</dc:creator>
    </item>
    <item>
      <title>Online Multi-spectral Neuron Tracing</title>
      <link>https://arxiv.org/abs/2403.06251</link>
      <description>arXiv:2403.06251v1 Announce Type: new 
Abstract: In this paper, we propose an online multi-spectral neuron tracing method with uniquely designed modules, where no offline training are required. Our method is trained online to update our enhanced discriminative correlation filter to conglutinate the tracing process. This distinctive offline-training-free schema differentiates us from other training-dependent tracing approaches like deep learning methods since no annotation is needed for our method. Besides, compared to other tracing methods requiring complicated set-up such as for clustering and graph multi-cut, our approach is much easier to be applied to new images. In fact, it only needs a starting bounding box of the tracing neuron, significantly reducing users' configuration effort. Our extensive experiments show that our training-free and easy-configured methodology allows fast and accurate neuron reconstructions in multi-spectral images.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06251v1</guid>
      <category>q-bio.NC</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Bin Duan, Yuzhang Shang, Dawen Cai, Yan Yan</dc:creator>
    </item>
    <item>
      <title>Are you sure? Modelling Drivers' Confidence Judgments in Left-Turn Gap Acceptance Decisions</title>
      <link>https://arxiv.org/abs/2403.06496</link>
      <description>arXiv:2403.06496v1 Announce Type: new 
Abstract: When a person makes a decision, it is automatically accompanied by a subjective probability judgment of the decision being correct, in other words, a confidence judgment. A better understanding of the mechanisms responsible for these confidence judgments could provide novel insights into human behavior. However, so far confidence judgments have been mostly studied in simplistic laboratory tasks while little is known about confidence in naturalistic dynamic tasks such as driving. In this study, we made a first attempt of connecting fundamental research on confidence with naturalistic driver behavior. We investigated the confidence of drivers in left-turn gap acceptance decisions in a driver simulator experiment (N=17). We found that confidence in these decisions depends on the size of the gap to the oncoming vehicle. Specifically, confidence increased with the gap size for trials in which the gap was accepted, and decreased with the gap size for rejected gaps. Similarly to more basic tasks, confidence was negatively related to the response times and correlated with action dynamics during decision execution. Finally, we found that confidence judgments can be captured with an extended dynamic drift-diffusion model. In the model, the drift rate of the evidence accumulator as well as the decision boundaries are functions of the gap size. Furthermore, we demonstrated that allowing for post-decision evidence accumulation in the model increases its ability to describe confidence judgments in rejected gap decisions. Overall, our study confirmed that principles known from fundamental confidence research extend to confidence judgments in dynamic decisions during a naturalistic task.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06496v1</guid>
      <category>q-bio.NC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arkady Zgonnikov, Floor Bontje</dc:creator>
    </item>
    <item>
      <title>Closed-loop control of gamma oscillations in the brain connections through the transcranial stimulations</title>
      <link>https://arxiv.org/abs/2403.06794</link>
      <description>arXiv:2403.06794v1 Announce Type: new 
Abstract: The reconstruction of brain neural network connections occurs not only during the infancy and early childhood stages of brain development, but also in patients with cognitive impairment in middle and old age under the therapy with stimulated external interference, such as the non-invasive repetitive transcranial magnetic stimulation (rTMS) and the transcranial direct current stimulation(tDCS). However, until now, it is not clear how brain stimulation triggers and controls the reconstruction of neural network connections in the brain. This paper combines the EEG data analysis and the cortical neuronal network modeling methods. On one hand, an E-I balanced cortical neural network model was constructed under a long-lasting external stimulation of sinusoidal-exponential form TMS or square-wave tDCS was introduced into the network model for simulate the treatment process for the brain connections. On the other hand, by combining Butterworth filter and functional connectivity algorithm, the paper analyzes the relations between the attentional gamma oscillation responses and the brain connection based on the publicly available EEGs during the pre-tDCS and post-tDCS treatment phases. Firstly, the simulation results indicate that, during long-lasting external stimulations of tDCS/rTMS, The sustained gamma oscillation was found to trigger more release of BDNF from astrocytes to participate in the positively reshaping the excitatory neuronal network connection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06794v1</guid>
      <category>q-bio.NC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xuan Zhang, Duoyu Feng, Djibrina Barry, Jiajia Li</dc:creator>
    </item>
    <item>
      <title>A Feature-based Generalizable Prediction Model for Both Perceptual and Abstract Reasoning</title>
      <link>https://arxiv.org/abs/2403.05641</link>
      <description>arXiv:2403.05641v1 Announce Type: cross 
Abstract: A hallmark of human intelligence is the ability to infer abstract rules from limited experience and apply these rules to unfamiliar situations. This capacity is widely studied in the visual domain using the Raven's Progressive Matrices. Recent advances in deep learning have led to multiple artificial neural network models matching or even surpassing human performance. However, while humans can identify and express the rule underlying these tasks with little to no exposure, contemporary neural networks often rely on massive pattern-based training and cannot express or extrapolate the rule inferred from the task. Furthermore, most Raven's Progressive Matrices or Raven-like tasks used for neural network training used symbolic representations, whereas humans can flexibly switch between symbolic and continuous perceptual representations. In this work, we present an algorithmic approach to rule detection and application using feature detection, affine transformation estimation and search. We applied our model to a simplified Raven's Progressive Matrices task, previously designed for behavioral testing and neuroimaging in humans. The model exhibited one-shot learning and achieved near human-level performance in the symbolic reasoning condition of the simplified task. Furthermore, the model can express the relationships discovered and generate multi-step predictions in accordance with the underlying rule. Finally, the model can reason using continuous patterns. We discuss our results and their relevance to studying abstract reasoning in humans, as well as their implications for improving intelligent machines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05641v1</guid>
      <category>cs.AI</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Quan Do, Thomas M. Morin, Chantal E. Stern, Michael E. Hasselmo</dc:creator>
    </item>
    <item>
      <title>Geometric Neural Network based on Phase Space for BCI decoding</title>
      <link>https://arxiv.org/abs/2403.05645</link>
      <description>arXiv:2403.05645v1 Announce Type: cross 
Abstract: The integration of Deep Learning (DL) algorithms on brain signal analysis is still in its nascent stages compared to their success in fields like Computer Vision, especially in Brain-Computer Interface (BCI), where the brain activity is decoded to control external devices without requiring muscle control. Electroencephalography (EEG) is a widely adopted choice for designing BCI systems due to its non-invasive and cost-effective nature and excellent temporal resolution. Still, it comes at the expense of limited training data, poor signal-to-noise, and a large variability across and within-subject recordings. Finally, setting up a BCI system with many electrodes takes a long time, hindering the widespread adoption of reliable DL architectures in BCIs outside research laboratories. To improve adoption, we need to improve user comfort using, for instance, reliable algorithms that operate with few electrodes. \textbf{Approach:} Our research aims to develop a DL algorithm that delivers effective results with a limited number of electrodes. Taking advantage of the Augmented Covariance Method with SPDNet, we propose the SPDNet$_{\psi}$ architecture and analyze its performance and computational impact, as well as the interpretability of the results. The evaluation is conducted on 5-fold cross-validation, using only three electrodes positioned above the Motor Cortex. The methodology was tested on nearly 100 subjects from several open-source datasets using the Mother Of All BCI Benchmark (MOABB) framework. \textbf{Main results:} The results of our SPDNet$_{\psi}$ demonstrate that the augmented approach combined with the SPDNet significantly outperforms all the current state-of-the-art DL architecture in MI decoding. \textbf{Significance:} This new architecture is explainable, with a low number of trainable parameters and a reduced carbon footprint.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05645v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Igor Carrara, Bruno Aristimunha, Marie-Constance Corsi, Raphael Y. de Camargo, Sylvain Chevallier, Th\'eodore Papadopoulo</dc:creator>
    </item>
    <item>
      <title>Cracking the neural code for word recognition in convolutional neural networks</title>
      <link>https://arxiv.org/abs/2403.06159</link>
      <description>arXiv:2403.06159v1 Announce Type: cross 
Abstract: Learning to read places a strong challenge on the visual system. Years of expertise lead to a remarkable capacity to separate highly similar letters and encode their relative positions, thus distinguishing words such as FORM and FROM, invariantly over a large range of sizes and absolute positions. How neural circuits achieve invariant word recognition remains unknown. Here, we address this issue by training deep neural network models to recognize written words and then analyzing how reading-specialized units emerge and operate across different layers of the network. With literacy, a small subset of units becomes specialized for word recognition in the learned script, similar to the "visual word form area" of the human brain. We show that these units are sensitive to specific letter identities and their distance from the blank space at the left or right of a word, thus acting as "space bigrams". These units specifically encode ordinal positions and operate by pooling across low and high-frequency detector units from early layers of the network. The proposed neural code provides a mechanistic insight into how information on letter identity and position is extracted and allow for invariant word recognition, and leads to predictions for reading behavior, error patterns, and the neurophysiology of reading.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06159v1</guid>
      <category>cs.CV</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aakash Agrawal, Stanislas Dehaene</dc:creator>
    </item>
    <item>
      <title>Membrane Interactions in Alzheimer`s Treatment Strategies with Multitarget Molecules</title>
      <link>https://arxiv.org/abs/2403.06331</link>
      <description>arXiv:2403.06331v1 Announce Type: cross 
Abstract: Addressing Alzheimer's disease (AD) requires innovative strategies beyond current single-target drugs. This Letter to the Editor suggests that multitarget molecules, especially those targeting neuronal membrane protection, could offer a comprehensive approach to AD therapy, advocating for further research into their mechanisms and therapeutic potential.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06331v1</guid>
      <category>q-bio.BM</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pablo Zambrano</dc:creator>
    </item>
    <item>
      <title>Joint-Embedding Masked Autoencoder for Self-supervised Learning of Dynamic Functional Connectivity from the Human Brain</title>
      <link>https://arxiv.org/abs/2403.06432</link>
      <description>arXiv:2403.06432v1 Announce Type: cross 
Abstract: Graph Neural Networks (GNNs) have shown promise in learning dynamic functional connectivity for distinguishing phenotypes from human brain networks. However, obtaining extensive labeled clinical data for training is often resource-intensive, making practical application difficult. Leveraging unlabeled data thus becomes crucial for representation learning in a label-scarce setting. Although generative self-supervised learning techniques, especially masked autoencoders, have shown promising results in representation learning in various domains, their application to dynamic graphs for dynamic functional connectivity remains underexplored, facing challenges in capturing high-level semantic representations. Here, we introduce the Spatio-Temporal Joint Embedding Masked Autoencoder (ST-JEMA), drawing inspiration from the Joint Embedding Predictive Architecture (JEPA) in computer vision. ST-JEMA employs a JEPA-inspired strategy for reconstructing dynamic graphs, which enables the learning of higher-level semantic representations considering temporal perspectives, addressing the challenges in fMRI data representation learning. Utilizing the large-scale UK Biobank dataset for self-supervised learning, ST-JEMA shows exceptional representation learning performance on dynamic functional connectivity demonstrating superiority over previous methods in predicting phenotypes and psychiatric diagnoses across eight benchmark fMRI datasets even with limited samples and effectiveness of temporal reconstruction on missing data scenarios. These findings highlight the potential of our approach as a robust representation learning method for leveraging label-scarce fMRI data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06432v1</guid>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jungwon Choi, Hyungi Lee, Byung-Hoon Kim, Juho Lee</dc:creator>
    </item>
    <item>
      <title>Reconstructing Visual Stimulus Images from EEG Signals Based on Deep Visual Representation Model</title>
      <link>https://arxiv.org/abs/2403.06532</link>
      <description>arXiv:2403.06532v1 Announce Type: cross 
Abstract: Reconstructing visual stimulus images is a significant task in neural decoding, and up to now, most studies consider the functional magnetic resonance imaging (fMRI) as the signal source. However, the fMRI-based image reconstruction methods are difficult to widely applied because of the complexity and high cost of the acquisition equipments. Considering the advantages of low cost and easy portability of the electroencephalogram (EEG) acquisition equipments, we propose a novel image reconstruction method based on EEG signals in this paper. Firstly, to satisfy the high recognizability of visual stimulus images in fast switching manner, we build a visual stimuli image dataset, and obtain the EEG dataset by a corresponding EEG signals collection experiment. Secondly, the deep visual representation model(DVRM) consisting of a primary encoder and a subordinate decoder is proposed to reconstruct visual stimuli. The encoder is designed based on the residual-in-residual dense blocks to learn the distribution characteristics between EEG signals and visual stimulus images, while the decoder is designed based on the deep neural network to reconstruct the visual stimulus image from the learned deep visual representation. The DVRM can fit the deep and multiview visual features of human natural state and make the reconstructed images more precise. Finally, we evaluate the DVRM in the quality of the generated images on our EEG dataset. The results show that the DVRM have good performance in the task of learning deep visual representation from EEG signals and generating reconstructed images that are realistic and highly resemble the original images.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06532v1</guid>
      <category>eess.IV</category>
      <category>cs.CV</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongguang Pan, Zhuoyi Li, Yunpeng Fu, Xuebin Qin, Jianchen Hu</dc:creator>
    </item>
    <item>
      <title>{\epsilon}-Neural Thompson Sampling of Deep Brain Stimulation for Parkinson Disease Treatment</title>
      <link>https://arxiv.org/abs/2403.06814</link>
      <description>arXiv:2403.06814v1 Announce Type: cross 
Abstract: Deep Brain Stimulation (DBS) stands as an effective intervention for alleviating the motor symptoms of Parkinson's disease (PD). Traditional commercial DBS devices are only able to deliver fixed-frequency periodic pulses to the basal ganglia (BG) regions of the brain, i.e., continuous DBS (cDBS). However, they in general suffer from energy inefficiency and side effects, such as speech impairment. Recent research has focused on adaptive DBS (aDBS) to resolve the limitations of cDBS. Specifically, reinforcement learning (RL) based approaches have been developed to adapt the frequencies of the stimuli in order to achieve both energy efficiency and treatment efficacy. However, RL approaches in general require significant amount of training data and computational resources, making it intractable to integrate RL policies into real-time embedded systems as needed in aDBS. In contrast, contextual multi-armed bandits (CMAB) in general lead to better sample efficiency compared to RL. In this study, we propose a CMAB solution for aDBS. Specifically, we define the context as the signals capturing irregular neuronal firing activities in the BG regions (i.e., beta-band power spectral density), while each arm signifies the (discretized) pulse frequency of the stimulation. Moreover, an {\epsilon}-exploring strategy is introduced on top of the classic Thompson sampling method, leading to an algorithm called {\epsilon}-Neural Thompson sampling ({\epsilon}-NeuralTS), such that the learned CMAB policy can better balance exploration and exploitation of the BG environment. The {\epsilon}-NeuralTS algorithm is evaluated using a computation BG model that captures the neuronal activities in PD patients' brains. The results show that our method outperforms both existing cDBS methods and CMAB baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06814v1</guid>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hao-Lun Hsu, Qitong Gao, Miroslav Pajic</dc:creator>
    </item>
    <item>
      <title>Extraction and Recovery of Spatio-Temporal Structure in Latent Dynamics Alignment with Diffusion Models</title>
      <link>https://arxiv.org/abs/2306.06138</link>
      <description>arXiv:2306.06138v2 Announce Type: replace 
Abstract: In the field of behavior-related brain computation, it is necessary to align raw neural signals against the drastic domain shift among them. A foundational framework within neuroscience research posits that trial-based neural population activities rely on low-dimensional latent dynamics, thus focusing on the latter greatly facilitates the alignment procedure. Despite this field's progress, existing methods ignore the intrinsic spatio-temporal structure during the alignment phase. Hence, their solutions usually lead to poor quality in latent dynamics structures and overall performance. To tackle this problem, we propose an alignment method ERDiff, which leverages the expressivity of the diffusion model to preserve the spatio-temporal structure of latent dynamics. Specifically, the latent dynamics structures of the source domain are first extracted by a diffusion model. Then, under the guidance of this diffusion model, such structures are well-recovered through a maximum likelihood alignment procedure in the target domain. We first demonstrate the effectiveness of our proposed method on a synthetic dataset. Then, when applied to neural recordings from the non-human primate motor cortex, under both cross-day and inter-subject settings, our method consistently manifests its capability of preserving the spatiotemporal structure of latent dynamics and outperforms existing approaches in alignment goodness-of-fit and neural decoding performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.06138v2</guid>
      <category>q-bio.NC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yule Wang, Zijing Wu, Chengrui Li, Anqi Wu</dc:creator>
    </item>
    <item>
      <title>Discovering Dynamic Effective Connectome of Brain with Bayesian Dynamic DAG Learning</title>
      <link>https://arxiv.org/abs/2309.07080</link>
      <description>arXiv:2309.07080v3 Announce Type: replace 
Abstract: Understanding the complex mechanisms of the brain can be unraveled by extracting the Dynamic Effective Connectome (DEC). Recently, score-based Directed Acyclic Graph (DAG) discovery methods have shown significant improvements in extracting the causal structure and inferring effective connectivity. However, learning DEC through these methods still faces two main challenges: one with the fundamental impotence of high-dimensional dynamic DAG discovery methods and the other with the low quality of fMRI data. In this paper, we introduce Bayesian Dynamic DAG learning with M-matrices Acyclicity characterization (BDyMA) method to address the challenges in discovering DEC. The presented dynamic causal model enables us to discover direct feedback loop edges as well. Leveraging an unconstrained framework in the BDyMA method leads to more accurate results in detecting high-dimensional networks, achieving sparser outcomes, making it particularly suitable for extracting DEC. Additionally, the score function of the BDyMA method allows the incorporation of prior knowledge into the process of dynamic causal discovery which further enhances the accuracy of results. Comprehensive simulations on synthetic data and experiments on Human Connectome Project (HCP) data demonstrate that our method can handle both of the two main challenges, yielding more accurate and reliable DEC compared to state-of-the-art and traditional methods. Additionally, we investigate the trustworthiness of DTI data as prior knowledge for DEC discovery and show the improvements in DEC discovery when the DTI data is incorporated into the process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.07080v3</guid>
      <category>q-bio.NC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Abdolmahdi Bagheri, Mohammad Pasande, Kevin Bello, Babak Nadjar Araabi, Alireza Akhondi-Asl</dc:creator>
    </item>
    <item>
      <title>BrainKnow -- Extracting, Linking, and Associating Neuroscience Knowledge</title>
      <link>https://arxiv.org/abs/2403.04346</link>
      <description>arXiv:2403.04346v2 Announce Type: replace-cross 
Abstract: The vast accumulation of neuroscience knowledge presents a challenge for researchers to timely and accurately locate the specific information they require. Constructing a knowledge engine that automatically extracts and organizes information from academic papers can provide researchers with timely and accurate informational services. We present the Brain Knowledge Engine (BrainKnow), which extracts and integrates neuroscience knowledge from published papers from PubMed. BrainKnow comprises a substantial repository, containing 3,626,931 relations spanning a broad spectrum of 37,011 neuroscience concepts extracted from 1817744 articles. The relations in BrainKnow can be accessed and navigated through a user-friendly web interface. Additionally, BrainKnow employs graph network algorithms for the recommendation and visualization of knowledge. BrainKnow is capable of automatic real-time updates. BrainKnow represents the first neuroscience knowledge graph that not only integrates knowledge in-depth but also facilitates fully automated updates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.04346v2</guid>
      <category>cs.DL</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Cunqing Huangfu, Yi Zeng, Yuwei Wang, Dongsheng Wang, Zizhe Ruan</dc:creator>
    </item>
  </channel>
</rss>
