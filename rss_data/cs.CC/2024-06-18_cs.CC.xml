<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CC</link>
    <description>cs.CC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 19 Jun 2024 04:00:00 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 19 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Assembly Theory and its Relationship with Computational Complexity</title>
      <link>https://arxiv.org/abs/2406.12176</link>
      <description>arXiv:2406.12176v1 Announce Type: new 
Abstract: Assembly theory (AT) quantifies selection using the assembly equation and identifies complex objects that occur in abundance based on two measurements, assembly index and copy number. The assembly index is determined by the minimal number of recursive joining operations necessary to construct an object from basic parts, and the copy number is how many of the given object(s) are observed. Together these allow defining a quantity, called Assembly, which captures the amount of causation required to produce the observed objects in the sample. AT's focus on how selection generates complexity offers a distinct approach to that of computational complexity theory which focuses on minimum descriptions via compressibility. To explore formal differences between the two approaches, we show several simple and explicit mathematical examples demonstrating that the assembly index, itself only one piece of the theoretical framework of AT, is formally not equivalent to other commonly used complexity measures from computer science and information theory including Huffman encoding and Lempel-Ziv-Welch compression.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12176v1</guid>
      <category>cs.CC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Christopher Kempes, Sara I. Walker, Michael Lachmann, Leroy Cronin</dc:creator>
    </item>
    <item>
      <title>Parameterized Shortest Path Reconfiguration</title>
      <link>https://arxiv.org/abs/2406.12717</link>
      <description>arXiv:2406.12717v1 Announce Type: new 
Abstract: An st-shortest path, or st-path for short, in a graph G is a shortest (induced) path from s to t in G. Two st-paths are said to be adjacent if they differ on exactly one vertex. A reconfiguration sequence between two st-paths P and Q is a sequence of adjacent st-paths starting from P and ending at Q. Deciding whether there exists a reconfiguration sequence between two given $st$-paths is known to be PSPACE-complete, even on restricted classes of graphs such as graphs of bounded bandwidth (hence pathwidth). On the positive side, and rather surprisingly, the problem is polynomial-time solvable on planar graphs. In this paper, we study the parameterized complexity of the Shortest Path Reconfiguration (SPR) problem. We show that SPR is W[1]-hard parameterized by k + \ell, even when restricted to graphs of bounded (constant) degeneracy; here k denotes the number of edges on an st-path, and \ell denotes the length of a reconfiguration sequence from P to Q. We complement our hardness result by establishing the fixed-parameter tractability of SPR parameterized by \ell and restricted to nowhere-dense classes of graphs. Additionally, we establish fixed-parameter tractability of SPR when parameterized by the treedepth, by the cluster-deletion number, or by the modular-width of the input graph.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12717v1</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicolas Bousquet, Kshitij Gajjar, Abhiruk Lahiri, Amer E. Mouawad</dc:creator>
    </item>
    <item>
      <title>Tight Streaming Lower Bounds for Deterministic Approximate Counting</title>
      <link>https://arxiv.org/abs/2406.12149</link>
      <description>arXiv:2406.12149v1 Announce Type: cross 
Abstract: We study the streaming complexity of $k$-counter approximate counting. In the $k$-counter approximate counting problem, we are given an input string in $[k]^n$, and we are required to approximate the number of each $j$'s ($j\in[k]$) in the string. Typically we require an additive error $\leq\frac{n}{3(k-1)}$ for each $j\in[k]$ respectively, and we are mostly interested in the regime $n\gg k$. We prove a lower bound result that the deterministic and worst-case $k$-counter approximate counting problem requires $\Omega(k\log(n/k))$ bits of space in the streaming model, while no non-trivial lower bounds were known before. In contrast, trivially counting the number of each $j\in[k]$ uses $O(k\log n)$ bits of space. Our main proof technique is analyzing a novel potential function.
  Our lower bound for $k$-counter approximate counting also implies the optimality of some other streaming algorithms. For example, we show that the celebrated Misra-Gries algorithm for heavy hitters [MG82] has achieved optimal space usage.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12149v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yichuan Wang</dc:creator>
    </item>
    <item>
      <title>Orbit-blocking words and the average-case complexity of Whitehead's problem in the free group of rank 2</title>
      <link>https://arxiv.org/abs/2406.12322</link>
      <description>arXiv:2406.12322v1 Announce Type: cross 
Abstract: Let F_2 denote the free group of rank 2. Our main technical result of independent interest is: for any element u of F_2, there is g in F_2 such that no cyclically reduced image of u under an automorphism of F_2 contains g as a subword. We then address computational complexity of the following version of the Whitehead automorphism problem: given a fixed u in F_2, decide, on an input v in F_2 of length n, whether or not v is an automorphic image of u. We show that there is an algorithm that solves this problem and has constant (i.e., independent of n) average-case complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12322v1</guid>
      <category>math.GR</category>
      <category>cs.CC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lucy Hyde, Siobhan O'Connor, Vladimir Shpilrain</dc:creator>
    </item>
    <item>
      <title>Hardness of monadic second-order formulae over succinct graphs</title>
      <link>https://arxiv.org/abs/2302.04522</link>
      <description>arXiv:2302.04522v2 Announce Type: replace 
Abstract: Our main result is a succinct counterpoint to Courcelle's meta-theorem as follows: every arborescent monadic second-order (MSO) property is either NP-hard or coNP-hard over graphs given by succinct representations.  Succint representations are Boolean circuits computing the adjacency relation.  Arborescent properties are those which have infinitely many models and countermodels with bounded treewidth.  Moreover, we explore what happens when the arborescence condition is dropped and show that, under a reasonable complexity assumption, the previous dichotomy fails, even for questions expressible in first-order logic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.04522v2</guid>
      <category>cs.CC</category>
      <category>cs.LO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guilhem Gamard (MOCQUA), Pierre Guillon (I2M), K\'evin Perrot (LIS), Guillaume Theyssier (I2M)</dc:creator>
    </item>
    <item>
      <title>Completeness in the Polynomial Hierarchy for many natural Problems in Bilevel and Robust Optimization</title>
      <link>https://arxiv.org/abs/2311.10540</link>
      <description>arXiv:2311.10540v2 Announce Type: replace 
Abstract: Because $\Sigma^p_2$- and $\Sigma^p_3$-hardness proofs are usually tedious and difficult, not so many complete problems for these classes are known. This is especially true in the areas of min-max regret robust optimization, network interdiction, most vital vertex problems, blocker problems, and two-stage adjustable robust optimization problems. Even though these areas are well-researched for over two decades and one would naturally expect many (if not most) of the problems occurring in these areas to be complete for the above classes, almost no completeness results exist in the literature. We address this lack of knowledge by introducing over 70 new $\Sigma^p_2$-complete and $\Sigma^p_3$-complete problems. We achieve this result by proving a new meta-theorem, which shows $\Sigma^p_2$- and $\Sigma^p_3$-completeness simultaneously for a huge class of problems. The majority of all earlier publications on $\Sigma^p_2$- and $\Sigma^p_3$-completeness in said areas are special cases of our meta-theorem. Our precise result is the following: We introduce a large list of problems for which the meta-theorem is applicable (including clique, vertex cover, knapsack, TSP, facility location and many more). For every problem on this list, we show: The interdiction/minimum cost blocker/most vital nodes problem (with element costs) is $\Sigma^p_2$-complete. The min-max-regret problem with interval uncertainty is $\Sigma^p_2$-complete. The two-stage adjustable robust optimization problem with discrete budgeted uncertainty is $\Sigma^p_3$-complete. In summary, our work reveals the interesting insight that a large amount of NP-complete problems have the property that their min-max versions are 'automatically' $\Sigma^p_2$-complete.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.10540v2</guid>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christoph Gr\"une, Lasse Wulf</dc:creator>
    </item>
    <item>
      <title>On Efficiently Representing Regular Languages as RNNs</title>
      <link>https://arxiv.org/abs/2402.15814</link>
      <description>arXiv:2402.15814v2 Announce Type: replace-cross 
Abstract: Recent work by Hewitt et al. (2020) provides an interpretation of the empirical success of recurrent neural networks (RNNs) as language models (LMs). It shows that RNNs can efficiently represent bounded hierarchical structures that are prevalent in human language. This suggests that RNNs' success might be linked to their ability to model hierarchy. However, a closer inspection of Hewitt et al.'s (2020) construction shows that it is not inherently limited to hierarchical structures. This poses a natural question: What other classes of LMs can RNNs efficiently represent? To this end, we generalize Hewitt et al.'s (2020) construction and show that RNNs can efficiently represent a larger class of LMs than previously claimed -- specifically, those that can be represented by a pushdown automaton with a bounded stack and a specific stack update function. Altogether, the efficiency of representing this diverse class of LMs with RNN LMs suggests novel interpretations of their inductive bias.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.15814v2</guid>
      <category>cs.CL</category>
      <category>cs.CC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anej Svete, Robin Shing Moon Chan, Ryan Cotterell</dc:creator>
    </item>
    <item>
      <title>Transformers Can Represent $n$-gram Language Models</title>
      <link>https://arxiv.org/abs/2404.14994</link>
      <description>arXiv:2404.14994v2 Announce Type: replace-cross 
Abstract: Existing work has analyzed the representational capacity of the transformer architecture by means of formal models of computation. However, the focus so far has been on analyzing the architecture in terms of language \emph{acceptance}. We contend that this is an ill-suited problem in the study of \emph{language models} (LMs), which are definitionally \emph{probability distributions} over strings. In this paper, we focus on the relationship between transformer LMs and $n$-gram LMs, a simple and historically relevant class of language models. We show that transformer LMs using the hard or sparse attention mechanisms can exactly represent any $n$-gram LM, giving us a concrete lower bound on their probabilistic representational capacity. This provides a first step towards understanding the mechanisms that transformer LMs can use to represent probability distributions over strings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.14994v2</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.CC</category>
      <category>cs.FL</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anej Svete, Ryan Cotterell</dc:creator>
    </item>
  </channel>
</rss>
