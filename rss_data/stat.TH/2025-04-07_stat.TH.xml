<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.TH updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.TH</link>
    <description>stat.TH updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.TH" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 07 Apr 2025 04:00:21 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Kullback-Leibler Consistency of $p$-dimensional P\'olya Tree Posteriors and Differential Entropy Estimation</title>
      <link>https://arxiv.org/abs/2504.02950</link>
      <description>arXiv:2504.02950v1 Announce Type: new 
Abstract: We exploit the multiplicative structure of P\'olya Tree priors for density and differential entropy estimation in $p$-dimensions. We establish: (i) a representation theorem of entropy functionals and (ii) conditions on the parameters of P\'olya Trees to obtain Kullback-Leibler and Total Variation consistency for vectors with compact support. Those results motivate a novel differential entropy estimator that is consistent in probability for compact supported vectors under mild conditions. In order to enable applications of both results, we also provide a theoretical motivation for the truncation of Univariate P\'olya Trees at level $3 \log_2 n $.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.02950v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Fernando Corr\^ea, Rafael Bassi Stern, Julio Michael Stern</dc:creator>
    </item>
    <item>
      <title>E-variables for hypotheses generated by constraints</title>
      <link>https://arxiv.org/abs/2504.02974</link>
      <description>arXiv:2504.02974v1 Announce Type: new 
Abstract: An e-variable for a family of distributions $\mathcal{P}$ is a nonnegative random variable whose expected value under every distribution in $\mathcal{P}$ is at most one. E-variables have recently been recognized as fundamental objects in hypothesis testing, and a rapidly growing body of work has attempted to derive admissible or optimal e-variables for various families $\mathcal{P}$. In this paper, we study classes $\mathcal{P}$ that are specified by constraints. Simple examples include bounds on the moments, but our general theory covers arbitrary sets of measurable constraints. Our main results characterize the set of all e-variables for such classes, as well as maximal ones. Three case studies illustrate the scope of our theory: finite constraint sets, one-sided sub-$\psi$ distributions, and distributions invariant under a group of symmetries. In particular, we generalize recent results of Clerico (2024a) by dropping all assumptions on the constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.02974v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Martin Larsson, Aaditya Ramdas, Johannes Ruf</dc:creator>
    </item>
    <item>
      <title>A Lanczos-Based Algorithmic Approach for Spike Detection in Large Sample Covariance Matrices</title>
      <link>https://arxiv.org/abs/2504.03066</link>
      <description>arXiv:2504.03066v1 Announce Type: new 
Abstract: We introduce a new approach for estimating the number of spikes in a general class of spiked covariance models without directly computing the eigenvalues of the sample covariance matrix. This approach is based on the Lanczos algorithm and the asymptotic properties of the associated Jacobi matrix and its Cholesky factorization. A key aspect of the analysis is interpreting the eigenvector spectral distribution as a perturbation of its asymptotic counterpart. The specific exponential-type asymptotics of the Jacobi matrix enables an efficient approximation of the Stieltjes transform of the asymptotic spectral distribution via a finite continued fraction. As a consequence, we also obtain estimates for the density of the asymptotic distribution and the location of outliers. We provide consistency guarantees for our proposed estimators, proving their convergence in the high-dimensional regime. We demonstrate that, when applied to standard spiked covariance models, our approach outperforms existing methods in computational efficiency and runtime, while still maintaining robustness to exotic population covariances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03066v1</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.CO</category>
      <category>stat.TH</category>
      <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Charbel Abi Younes, Xiucai Ding, Thomas Trogdon</dc:creator>
    </item>
    <item>
      <title>Adaptive sparse variational approximations for Gaussian process regression</title>
      <link>https://arxiv.org/abs/2504.03321</link>
      <description>arXiv:2504.03321v1 Announce Type: new 
Abstract: Accurate tuning of hyperparameters is crucial to ensure that models can generalise effectively across different settings. In this paper, we present theoretical guarantees for hyperparameter selection using variational Bayes in the nonparametric regression model. We construct a variational approximation to a hierarchical Bayes procedure, and derive upper bounds for the contraction rate of the variational posterior in an abstract setting. The theory is applied to various Gaussian process priors and variational classes, resulting in minimax optimal rates. Our theoretical results are accompanied with numerical analysis both on synthetic and real world data sets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03321v1</guid>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dennis Nieman, Botond Szab\'o</dc:creator>
    </item>
    <item>
      <title>Eigen-inference by Marchenko-Pastur inversion</title>
      <link>https://arxiv.org/abs/2504.03390</link>
      <description>arXiv:2504.03390v1 Announce Type: new 
Abstract: A new formula for Marchenko-Pastur inversion is derived and used for inference of population linear spectral statistics. The formula allows for estimation of the Stieltjes transform of the population spectral distribution $s_H(z)$, when $z$ is sufficiently far from the support of the population spectral distribution $H$. If the dimension $d$ and the sample size $n$ go to infinity simultaneously such that $\frac{d}{n} \rightarrow c&gt;0$, the estimation error is shown to be asymptotically less than $\frac{n^{\varepsilon}}{n}$ for arbitrary $\varepsilon &gt; 0$. By integrating along a curve around the support of $H$, estimators for population linear spectral statistics are constructed, which benefit from this convergence speed of $\frac{n^{\varepsilon}}{n}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03390v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ben Deitmar</dc:creator>
    </item>
    <item>
      <title>On the rate of convergence of an over-parametrized deep neural network regression estimate learned by gradient descent</title>
      <link>https://arxiv.org/abs/2504.03405</link>
      <description>arXiv:2504.03405v1 Announce Type: new 
Abstract: Nonparametric regression with random design is considered.
  The $L_2$ error with integration with respect to the design
  measure is used as the error criterion.
  An over-parametrized deep neural network
  regression estimate
  with logistic activation function
  is defined, where all weights are learned
  by gradient descent. It is shown that the estimate
  achieves a nearly optimal rate of convergence in case
  that the regression function is $(p,C)$--smooth.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03405v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Kohler</dc:creator>
    </item>
    <item>
      <title>On empirical Hodge Laplacians under the manifold hypothesis</title>
      <link>https://arxiv.org/abs/2504.03427</link>
      <description>arXiv:2504.03427v1 Announce Type: new 
Abstract: Given i.i.d. observations uniformly distributed on a closed submanifold of the Euclidean space, we study higher-order generalizations of graph Laplacians, so-called Hodge Laplacians on graphs, as approximations of the Laplace-Beltrami operator on differential forms. Our main result is a high-probability error bound for the associated Dirichlet forms. This bound improves existing Dirichlet form error bounds for graph Laplacians in the context of Laplacian Eigenmaps, and it provides insights into the Betti numbers studied in topological data analysis and the complementing positive part of the spectrum.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03427v1</guid>
      <category>math.ST</category>
      <category>math.DG</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jan-Paul Lerch, Martin Wahl</dc:creator>
    </item>
    <item>
      <title>Identifiability of VAR(1) model in a stationary setting</title>
      <link>https://arxiv.org/abs/2504.03466</link>
      <description>arXiv:2504.03466v1 Announce Type: new 
Abstract: We consider a classical First-order Vector AutoRegressive (VAR(1)) model, where we interpret the autoregressive interaction matrix as influence relationships among the components of the VAR(1) process that can be encoded by a weighted directed graph. A majority of previous work studies the structural identifiability of the graph based on time series observations and therefore relies on dynamical information. In this work we assume that an equilibrium exists, and study instead the identifiability of the graph from the stationary distribution, meaning that we seek a way to reconstruct the influence graph underlying the dynamic network using only static information. We use an approach from algebraic statistics that characterizes models using the Jacobian matroids associated with the parametrization of the models, and we introduce sufficient graphical conditions under which different graphs yield distinct steady-state distributions. Additionally, we illustrate how our results could be applied to characterize networks inspired by ecological research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03466v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bixuan Liu</dc:creator>
    </item>
    <item>
      <title>Beyond Smoothness and Convexity: Optimization via sampling</title>
      <link>https://arxiv.org/abs/2504.02831</link>
      <description>arXiv:2504.02831v1 Announce Type: cross 
Abstract: This work explores a novel perspective on solving nonconvex and nonsmooth optimization problems by leveraging sampling based methods. Instead of treating the objective function purely through traditional (often deterministic) optimization approaches, we view it as inducing a target distribution.We then draw samples from this distribution using Markov Chain Monte Carlo (MCMC) techniques, particularly Langevin Dynamics (LD), to locate regions of low function values. By analyzing the convergence properties of LD in both KL divergence and total variation distance, we establish explicit bounds on how many iterations are required for the induced distribution to approximate the target. We also provide probabilistic guarantees that an appropriately drawn sample will lie within a desired neighborhood of the global minimizer, even when the objective is nonconvex or nonsmooth.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.02831v1</guid>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nahom Seyoum, Haoxiang You</dc:creator>
    </item>
    <item>
      <title>Dynamic Investment Strategies Through Market Classification and Volatility: A Machine Learning Approach</title>
      <link>https://arxiv.org/abs/2504.02841</link>
      <description>arXiv:2504.02841v1 Announce Type: cross 
Abstract: This study introduces a dynamic investment framework to enhance portfolio management in volatile markets, offering clear advantages over traditional static strategies. Evaluates four conventional approaches : equal weighted, minimum variance, maximum diversification, and equal risk contribution under dynamic conditions. Using K means clustering, the market is segmented into ten volatility-based states, with transitions forecasted by a Bayesian Markov switching model employing Dirichlet priors and Gibbs sampling. This enables real-time asset allocation adjustments. Tested across two asset sets, the dynamic portfolio consistently achieves significantly higher risk-adjusted returns and substantially higher total returns, outperforming most static methods. By integrating classical optimization with machine learning and Bayesian techniques, this research provides a robust strategy for optimizing investment outcomes in unpredictable market environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.02841v1</guid>
      <category>q-fin.PM</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jinhui Li, Wenjia Xie, Luis Seco</dc:creator>
    </item>
    <item>
      <title>High-dimensional ridge regression with random features for non-identically distributed data with a variance profile</title>
      <link>https://arxiv.org/abs/2504.03035</link>
      <description>arXiv:2504.03035v1 Announce Type: cross 
Abstract: The behavior of the random feature model in the high-dimensional regression framework has become a popular issue of interest in the machine learning literature}. This model is generally considered for feature vectors $x_i = \Sigma^{1/2} x_i'$, where $x_i'$ is a random vector made of independent and identically distributed (iid) entries, and $\Sigma$ is a positive definite matrix representing the covariance of the features.
  In this paper, we move beyond {\CB this standard assumption by studying the performances of the random features model in the setting of non-iid feature vectors}. Our approach is related to the analysis of the spectrum of large random matrices through random matrix theory (RMT) {\CB and free probability} results. We turn to the analysis of non-iid data by using the notion of variance profile {\CB which} is {\CB well studied in RMT.} Our main contribution is then the study of the limits of the training and {\CB prediction} risks associated to the ridge estimator in the random features model when its dimensions grow. We provide asymptotic equivalents of these risks that capture the behavior of ridge regression with random features in a {\CB high-dimensional} framework. These asymptotic equivalents, {\CB which prove to be sharp in numerical experiments}, are retrieved by adapting, to our setting, established results from operator-valued free probability theory. Moreover, {\CB for various classes of random feature vectors that have not been considered so far in the literature}, our approach allows to show the appearance of the double descent phenomenon when the ridge regularization parameter is small enough.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03035v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Issa-Mbenard Dabo, J\'er\'emie Bigot</dc:creator>
    </item>
    <item>
      <title>A computational transition for detecting multivariate shuffled linear regression by low-degree polynomials</title>
      <link>https://arxiv.org/abs/2504.03097</link>
      <description>arXiv:2504.03097v1 Announce Type: cross 
Abstract: In this paper, we study the problem of multivariate shuffled linear regression, where the correspondence between predictors and responses in a linear model is obfuscated by a latent permutation. Specifically, we investigate the model $Y=\tfrac{1}{\sqrt{1+\sigma^2}}(\Pi_* X Q_* + \sigma Z)$, where $X$ is an $n*d$ standard Gaussian design matrix, $Z$ is an $n*m$ Gaussian noise matrix, $\Pi_*$ is an unknown $n*n$ permutation matrix, and $Q_*$ is an unknown $d*m$ on the Grassmanian manifold satisfying $Q_*^{\top} Q_* = \mathbb I_m$.
  Consider the hypothesis testing problem of distinguishing this model from the case where $X$ and $Y$ are independent Gaussian random matrices of sizes $n*d$ and $n*m$, respectively. Our results reveal a phase transition phenomenon in the performance of low-degree polynomial algorithms for this task. (1) When $m=o(d)$, we show that all degree-$D$ polynomials fail to distinguish these two models even when $\sigma=0$, provided with $D^4=o\big( \tfrac{d}{m} \big)$. (2) When $m=d$ and $\sigma=\omega(1)$, we show that all degree-$D$ polynomials fail to distinguish these two models provided with $D=o(\sigma)$. (3) When $m=d$ and $\sigma=o(1)$, we show that there exists a constant-degree polynomial that strongly distinguish these two models. These results establish a smooth transition in the effectiveness of low-degree polynomial algorithms for this problem, highlighting the interplay between the dimensions $m$ and $d$, the noise level $\sigma$, and the computational complexity of the testing task.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03097v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhangsong Li</dc:creator>
    </item>
    <item>
      <title>Existence and non-existence of consistent estimators in supercritical controlled branching processes</title>
      <link>https://arxiv.org/abs/2504.03389</link>
      <description>arXiv:2504.03389v1 Announce Type: cross 
Abstract: We consider the problem of estimating the parameters of a supercritical controlled branching process consistently from a single observed trajectory of population size counts. Our goal is to establish which parameters can and cannot be consistently estimated. When a parameter can be consistently estimated, we derive an explicit expression for the estimator. We address these questions in three scenarios: when the distribution of the control function distribution is known, when it is unknown, and when progenitor numbers are observed alongside population size counts. Our results offer a theoretical justification for the common practice in population ecology of estimating demographic and environmental stochasticity using separate observation schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03389v1</guid>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Peter Braunsteins, Sophie Hautphenne, James Kerlidis</dc:creator>
    </item>
    <item>
      <title>Stochastic Optimization with Optimal Importance Sampling</title>
      <link>https://arxiv.org/abs/2504.03560</link>
      <description>arXiv:2504.03560v1 Announce Type: cross 
Abstract: Importance Sampling (IS) is a widely used variance reduction technique for enhancing the efficiency of Monte Carlo methods, particularly in rare-event simulation and related applications. Despite its power, the performance of IS is often highly sensitive to the choice of the proposal distribution and frequently requires stochastic calibration techniques. While the design and analysis of IS have been extensively studied in estimation settings, applying IS within stochastic optimization introduces a unique challenge: the decision and the IS distribution are mutually dependent, creating a circular optimization structure. This interdependence complicates both the analysis of convergence for decision iterates and the efficiency of the IS scheme. In this paper, we propose an iterative gradient-based algorithm that jointly updates the decision variable and the IS distribution without requiring time-scale separation between the two. Our method achieves the lowest possible asymptotic variance and guarantees global convergence under convexity of the objective and mild assumptions on the IS distribution family. Furthermore, we show that these properties are preserved under linear constraints by incorporating a recent variant of Nesterov's dual averaging method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03560v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liviu Aolaritei, Bart P. G. Van Parys, Henry Lam, Michael I. Jordan</dc:creator>
    </item>
    <item>
      <title>Quickest Change Detection for Multiple Data Streams Using the James-Stein Estimator</title>
      <link>https://arxiv.org/abs/2404.05486</link>
      <description>arXiv:2404.05486v2 Announce Type: replace 
Abstract: The problem of quickest change detection is studied in the context of detecting an arbitrary unknown mean-shift in multiple independent Gaussian data streams. The James-Stein estimator is used in constructing detection schemes that exhibit strong detection performance both asymptotically and non-asymptotically. Our results indicate that utilizing the James-Stein estimator in the recently developed window-limited CuSum test constitutes a uniform improvement over its typical maximum likelihood variant. That is, the proposed James-Stein version achieves a smaller detection delay simultaneously for all possible post-change parameter values and every false alarm rate constraint, as long as the number of parallel data streams is greater than three. Additionally, an alternative detection procedure that utilizes the James-Stein estimator is shown to have asymptotic detection delay properties that compare favorably to existing tests. The second-order asymptotic detection delay term is reduced in a predefined low-dimensional subspace of the parameter space, while second-order asymptotic minimaxity is preserved. The results are verified in simulations, where the proposed schemes are shown to achieve smaller detection delays compared to existing alternatives, especially when the number of data streams is large.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.05486v2</guid>
      <category>math.ST</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>stat.TH</category>
      <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Topi Halme, Venugopal V. Veeravalli, Visa Koivunen</dc:creator>
    </item>
    <item>
      <title>Optimal low-rank approximations for linear Gaussian inverse problems on Hilbert spaces, Part I: posterior covariance approximation</title>
      <link>https://arxiv.org/abs/2411.01112</link>
      <description>arXiv:2411.01112v3 Announce Type: replace 
Abstract: For linear inverse problems with Gaussian priors and Gaussian observation noise, the posterior is Gaussian, with mean and covariance determined by the conditioning formula. Using the Feldman-Hajek theorem, we analyse the prior-to-posterior update and its low-rank approximation for infinite-dimensional Hilbert parameter spaces and finite-dimensional observations. We show that the posterior distribution differs from the prior on a finite-dimensional subspace, and construct low-rank approximations to the posterior covariance, while keeping the mean fixed. Since in infinite dimensions, not all low-rank covariance approximations yield approximate posterior distributions which are equivalent to the posterior and prior distribution, we characterise the low-rank covariance approximations which do yield this equivalence, and their respective inverses, or `precisions'. For such approximations, a family of measure approximation problems is solved by identifying the low-rank approximations which are optimal for various losses simultaneously. These loss functions include the family of R\'enyi divergences, the Amari $\alpha$-divergences for $\alpha\in(0,1)$, the Hellinger metric and the Kullback-Leibler divergence. Our results extend those of Spantini et al. (SIAM J. Sci. Comput. 2015) to Hilbertian parameter spaces, and provide theoretical underpinning for the construction of low-rank approximations of discretised versions of the infinite-dimensional inverse problem, by formulating discretisation independent results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.01112v3</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Giuseppe Carere, Han Cheng Lie</dc:creator>
    </item>
    <item>
      <title>Affine calculus for constrained minima of the Kullback-Leibler divergence</title>
      <link>https://arxiv.org/abs/2502.02177</link>
      <description>arXiv:2502.02177v3 Announce Type: replace 
Abstract: The non-parametric version of Amari's dually affine Information Geometry provides a practical calculus to perform computations of interest in statistical machine learning. The method uses the notion of a statistical bundle, a mathematical structure that includes both probability densities and random variables to capture the spirit of Fisherian statistics. We focus on computations involving a constrained minimization of the Kullback-Leibler divergence. We show how to obtain neat and principled versions of known computation in applications such as mean-field approximation, adversarial generative models, and variational Bayes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02177v3</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.3390/stats8020025</arxiv:DOI>
      <arxiv:journal_reference>Stats 2025, 8(2), 25</arxiv:journal_reference>
      <dc:creator>Giovanni Pistone</dc:creator>
    </item>
    <item>
      <title>Optimal low-rank approximations for linear Gaussian inverse problems on Hilbert spaces, Part I: posterior covariance approximation</title>
      <link>https://arxiv.org/abs/2503.24020</link>
      <description>arXiv:2503.24020v2 Announce Type: replace 
Abstract: For linear inverse problems with Gaussian priors and Gaussian observation noise, the posterior is Gaussian, with mean and covariance determined by the conditioning formula. Using the Feldman-Hajek theorem, we analyse the prior-to-posterior update and its low-rank approximation for infinite-dimensional Hilbert parameter spaces and finite-dimensional observations. We show that the posterior distribution differs from the prior on a finite-dimensional subspace, and construct low-rank approximations to the posterior covariance, while keeping the mean fixed. Since in infinite dimensions, not all low-rank covariance approximations yield approximate posterior distributions which are equivalent to the posterior and prior distribution, we characterise the low-rank covariance approximations which do yield this equivalence, and their respective inverses, or `precisions'. For such approximations, a family of measure approximation problems is solved by identifying the low-rank approximations which are optimal for various losses simultaneously. These loss functions include the family of R\'enyi divergences, the Amari $\alpha$-divergences for $\alpha\in(0,1)$, the Hellinger metric and the Kullback-Leibler divergence. Our results extend those of Spantini et al. (SIAM J. Sci. Comput. 2015) to Hilbertian parameter spaces, and provide theoretical underpinning for the construction of low-rank approximations of discretised versions of the infinite-dimensional inverse problem, by formulating discretization independent results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.24020v2</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Giuseppe Carere, Han Cheng Lie</dc:creator>
    </item>
    <item>
      <title>Adaptive functional principal components analysis</title>
      <link>https://arxiv.org/abs/2306.16091</link>
      <description>arXiv:2306.16091v4 Announce Type: replace-cross 
Abstract: Functional data analysis almost always involves smoothing discrete observations into curves, because they are never observed in continuous time and rarely without error. Although smoothing parameters affect the subsequent inference, data-driven methods for selecting these parameters are not well-developed, frustrated by the difficulty of using all the information shared by curves while being computationally efficient. On the one hand, smoothing individual curves in an isolated, albeit sophisticated way, ignores useful signals present in other curves. On the other hand, bandwidth selection by automatic procedures such as cross-validation after pooling all the curves together quickly become computationally unfeasible due to the large number of data points. In this paper we propose a new data-driven, adaptive kernel smoothing, specifically tailored for functional principal components analysis through the derivation of sharp, explicit risk bounds for the eigen-elements. The minimization of these quadratic risk bounds provide refined, yet computationally efficient bandwidth rules for each eigen-element separately. Both common and independent design cases are allowed. Rates of convergence for the estimators are derived. An extensive simulation study, designed in a versatile manner to closely mimic the characteristics of real data sets supports our methodological contribution. An illustration on a real data application is provided.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.16091v4</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Sunny G. W. Wang, Valentin Patilea, Nicolas Klutchnikoff</dc:creator>
    </item>
    <item>
      <title>Structured Matrix Learning under Arbitrary Entrywise Dependence and Estimation of Markov Transition Kernel</title>
      <link>https://arxiv.org/abs/2401.02520</link>
      <description>arXiv:2401.02520v2 Announce Type: replace-cross 
Abstract: The problem of structured matrix estimation has been studied mostly under strong noise dependence assumptions. This paper considers a general framework of noisy low-rank-plus-sparse matrix recovery, where the noise matrix may come from any joint distribution with arbitrary dependence across entries. We propose an incoherent-constrained least-square estimator and prove its tightness both in the sense of deterministic lower bound and matching minimax risks under various noise distributions. To attain this, we establish a novel result asserting that the difference between two arbitrary low-rank incoherent matrices must spread energy out across its entries; in other words, it cannot be too sparse, which sheds light on the structure of incoherent low-rank matrices and may be of independent interest. We then showcase the applications of our framework to several important statistical machine learning problems. In the problem of estimating a structured Markov transition kernel, the proposed method achieves the minimax optimality and the result can be extended to estimating the conditional mean operator, a crucial component in reinforcement learning. The applications to multitask regression and structured covariance estimation are also presented. We propose an alternating minimization algorithm to approximately solve the potentially hard optimization problem. Numerical results corroborate the effectiveness of our method which typically converges in a few steps.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.02520v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jinhang Chai, Jianqing Fan</dc:creator>
    </item>
    <item>
      <title>Contextual Dynamic Pricing: Algorithms, Optimality, and Local Differential Privacy Constraints</title>
      <link>https://arxiv.org/abs/2406.02424</link>
      <description>arXiv:2406.02424v3 Announce Type: replace-cross 
Abstract: We study contextual dynamic pricing problems where a firm sells products to $T$ sequentially-arriving consumers, behaving according to an unknown demand model. The firm aims to minimize its regret over a clairvoyant that knows the model in advance. The demand follows a generalized linear model (GLM), allowing for stochastic feature vectors in $\mathbb R^d$ encoding product and consumer information. We first show the optimal regret is of order $\sqrt{dT}$, up to logarithmic factors, improving existing upper bounds by a $\sqrt{d}$ factor. This optimal rate is materialized by two algorithms: a confidence bound-type algorithm and an explore-then-commit (ETC) algorithm. A key insight is an intrinsic connection between dynamic pricing and contextual multi-armed bandit problems with many arms with a careful discretization. We further study contextual dynamic pricing under local differential privacy (LDP) constraints. We propose a stochastic gradient descent-based ETC algorithm achieving regret upper bounds of order $d\sqrt{T}/\epsilon$, up to logarithmic factors, where $\epsilon&gt;0$ is the privacy parameter. The upper bounds with and without LDP constraints are matched by newly constructed minimax lower bounds, characterizing costs of privacy. Moreover, we extend our study to dynamic pricing under mixed privacy constraints, improving the privacy-utility tradeoff by leveraging public data. This is the first time such setting is studied in the dynamic pricing literature and our theoretical results seamlessly bridge dynamic pricing with and without LDP. Extensive numerical experiments and real data applications are conducted to illustrate the efficiency and practical value of our algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.02424v3</guid>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zifeng Zhao, Feiyu Jiang, Yi Yu</dc:creator>
    </item>
    <item>
      <title>The Central Role of the Loss Function in Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2409.12799</link>
      <description>arXiv:2409.12799v3 Announce Type: replace-cross 
Abstract: This paper illustrates the central role of loss functions in data-driven decision making, providing a comprehensive survey on their influence in cost-sensitive classification (CSC) and reinforcement learning (RL). We demonstrate how different regression loss functions affect the sample efficiency and adaptivity of value-based decision making algorithms. Across multiple settings, we prove that algorithms using the binary cross-entropy loss achieve first-order bounds scaling with the optimal policy's cost and are much more efficient than the commonly used squared loss. Moreover, we prove that distributional algorithms using the maximum likelihood loss achieve second-order bounds scaling with the policy variance and are even sharper than first-order bounds. This in particular proves the benefits of distributional RL. We hope that this paper serves as a guide analyzing decision making algorithms with varying loss functions, and can inspire the reader to seek out better loss functions to improve any decision making algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.12799v3</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kaiwen Wang, Nathan Kallus, Wen Sun</dc:creator>
    </item>
    <item>
      <title>A New Design-Based Variance Estimator for Finely Stratified Experiments</title>
      <link>https://arxiv.org/abs/2503.10851</link>
      <description>arXiv:2503.10851v2 Announce Type: replace-cross 
Abstract: This paper considers the problem of design-based inference for the average treatment effect in finely stratified experiments. Here, by "design-based'' we mean that the only source of uncertainty stems from the randomness in treatment assignment; by "finely stratified'' we mean units are first stratified into groups of size k according to baseline covariates and then, within each group, a fixed number l &lt; k are assigned uniformly at random to treatment and the remainder to control. In this setting, we first show under mild conditions that inference using the difference-in-means estimator requires an estimator of its variance that is at least asymptotically upward-biased. We then present a novel estimator of the variance and show that it is upward-biased; furthermore, the magnitude of the bias depends in a natural way on the quality of the stratification. Importantly, this estimator remains well-defined even in the setting in which l = 1 or k - l = 1. We then compare our estimator with some well-known estimators that have been proposed previously for this case. We first show that, while these estimators are also upward-biased, the magnitude of their bias does not change in the natural way with the quality of stratification. To further discriminate among these estimators, we introduce a framework motivated by a thought experiment in which the finite population can be modeled as having been drawn once in an i.i.d. fashion from a well-behaved probability distribution. In this framework, we argue that our estimator dominates the others in terms of limiting bias, and that these improvements are strict except under exceptionally strong restrictions on the treatment effects. Finally, we illustrate our theoretical results through a simulation study, which reveals that our estimator can lead to substantially more precise inferences, especially when the quality of stratification is high.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.10851v2</guid>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuehao Bai, Xun Huang, Joseph P. Romano, Azeem M. Shaikh, Max Tabord-Meehan</dc:creator>
    </item>
  </channel>
</rss>
