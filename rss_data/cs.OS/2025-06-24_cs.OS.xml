<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.OS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.OS</link>
    <description>cs.OS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.OS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 25 Jun 2025 01:42:13 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 24 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>VeriLocc: End-to-End Cross-Architecture Register Allocation via LLM</title>
      <link>https://arxiv.org/abs/2506.17506</link>
      <description>arXiv:2506.17506v1 Announce Type: cross 
Abstract: Modern GPUs evolve rapidly, yet production compilers still rely on hand-crafted register allocation heuristics that require substantial re-tuning for each hardware generation. We introduce VeriLocc, a framework that combines large language models (LLMs) with formal compiler techniques to enable generalizable and verifiable register allocation across GPU architectures. VeriLocc fine-tunes an LLM to translate intermediate representations (MIRs) into target-specific register assignments, aided by static analysis for cross-architecture normalization and generalization and a verifier-guided regeneration loop to ensure correctness. Evaluated on matrix multiplication (GEMM) and multi-head attention (MHA), VeriLocc achieves 85-99% single-shot accuracy and near-100% pass@100. Case study shows that VeriLocc discovers more performant assignments than expert-tuned libraries, outperforming rocBLAS by over 10% in runtime.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.17506v1</guid>
      <category>cs.CL</category>
      <category>cs.OS</category>
      <pubDate>Tue, 24 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lesheng Jin, Zhenyuan Ruan, Haohui Mai, Jingbo Shang</dc:creator>
    </item>
    <item>
      <title>ConsumerBench: Benchmarking Generative AI Applications on End-User Devices</title>
      <link>https://arxiv.org/abs/2506.17538</link>
      <description>arXiv:2506.17538v1 Announce Type: cross 
Abstract: The recent shift in Generative AI (GenAI) applications from cloud-only environments to end-user devices introduces new challenges in resource management, system efficiency, and user experience. This paper presents ConsumerBench, a comprehensive benchmarking framework designed to evaluate the system efficiency and response time of GenAI models running on end-user devices. Unlike existing benchmarks that assume exclusive model access on dedicated GPUs, ConsumerBench simulates realistic multi-application scenarios executing concurrently on constrained hardware. Furthermore, ConsumerBench supports customizable workflows that simulate complex tasks requiring coordination among multiple applications. ConsumerBench captures both application-level metrics, including latency and Service Level Objective (SLO) attainment, and system-level metrics like CPU/GPU utilization and memory bandwidth. Through extensive experiments, ConsumerBench reveals inefficiencies in resource sharing, unfair scheduling under greedy allocation, and performance pitfalls of static model server configurations. The paper also provides practical insights for model developers and system designers, highlighting the benefits of custom kernels tailored to consumer-grade GPU architectures and the value of implementing SLO-aware scheduling strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.17538v1</guid>
      <category>cs.DC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.OS</category>
      <pubDate>Tue, 24 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yile Gu, Rohan Kadekodi, Hoang Nguyen, Keisuke Kamahori, Yiyu Liu, Baris Kasikci</dc:creator>
    </item>
    <item>
      <title>Supporting Deterministic Traffic on Standard NICs</title>
      <link>https://arxiv.org/abs/2506.17877</link>
      <description>arXiv:2506.17877v1 Announce Type: cross 
Abstract: Networked mission-critical applications (e.g., avionic control and industrial automation systems) require deterministic packet transmissions to support a range of sensing and control tasks with stringent timing constraints. While specialized network infrastructure (e.g., time-sensitive networking (TSN) switches) provides deterministic data transport across the network, achieving strict end-to-end timing guarantees requires equally capable end devices to support deterministic traffic. These end devices, however, often employ general-purpose computing platforms like standard PCs, which lack native support for deterministic traffic and suffer from unpredictable delays introduced by their software stack and system architecture. Although specialized NICs with hardware scheduling offload can mitigate this problem, the limited compatibility hinders their widespread adoption, particularly for cost-sensitive applications or in legacy devices.
  To fill this gap, this paper proposes a novel software-based driver model, namely KeepON, to enable the support of deterministic packet transmissions on end devices equipped with standard NICs. The key idea of KeepON is to have the NIC keep on transmitting fixed-size data chunks as placeholders, thereby maintaining a predictable temporal transmission pattern. The real-time packets generated by the mission-critical application(s) will then be precisely inserted into this stream by replacing placeholders at the designated position to ensure their accurate transmission time. We implement and evaluate KeepON by modifying the network driver on a Raspberry Pi using its standard NIC. Our experiments demonstrate that KeepON can achieve x162 times scheduling accuracy comparable to its default driver, and x2.6 times compared to hardware-based solution, thus enabling precise timing control on standard commodity hardware.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.17877v1</guid>
      <category>cs.NI</category>
      <category>cs.OS</category>
      <pubDate>Tue, 24 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chuanyu Xue, Tianyu Zhang, Andrew Loveless, Song Han</dc:creator>
    </item>
    <item>
      <title>ASC-Hook: fast and transparent system call hook for Arm</title>
      <link>https://arxiv.org/abs/2412.05784</link>
      <description>arXiv:2412.05784v4 Announce Type: replace-cross 
Abstract: Intercepting system calls is crucial for tools that aim to modify or monitor application behavior. However, existing system call interception tools on the ARM platform still suffer from limitations in terms of performance and completeness. This paper presents an efficient and comprehensive binary rewriting framework, ASC-Hook, specifically designed for intercepting system calls on the ARM platform. ASC-Hook addresses two key challenges on the ARM architecture: the misalignment of the target address caused by directly replacing the SVC instruction with br x8, and the return to the original control flow after system call interception. This is achieved through a hybrid replacement strategy and our specially designed trampoline mechanism. By implementing multiple completeness strategies specifically for system calls, we ensured comprehensive and thorough interception. Experimental results show that ASC-Hook reduces overhead to at least 1/29 of that of existing system call interception tools. We conducted extensive performance evaluations of ASC-Hook, and the average performance loss for system call-intensive applications is 3.7\% .</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05784v4</guid>
      <category>cs.AR</category>
      <category>cs.OS</category>
      <category>cs.PF</category>
      <category>cs.PL</category>
      <pubDate>Tue, 24 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3735452.3735524</arxiv:DOI>
      <dc:creator>Yang Shen (National University of Defense Technology), Min Xie (National University of Defense Technology), Wenzhe Zhang (National University of Defense Technology), Tao Wu (Changsha University of Science,Technology)</dc:creator>
    </item>
  </channel>
</rss>
