<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.AP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.AP</link>
    <description>stat.AP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.AP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 06 May 2024 04:00:25 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 06 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Sensitivity analysis for matching on high-dimensional predictors: A case study of racial disparity in US mortality</title>
      <link>https://arxiv.org/abs/2405.01694</link>
      <description>arXiv:2405.01694v1 Announce Type: new 
Abstract: Matching on a low dimensional vector of scalar covariates consists of constructing groups of individuals in which each individual in a group is within a pre-specified distance from an individual in another group. However, matching in high dimensional spaces is more challenging because the distance can be sensitive to implementation details, caliper width, and measurement error of observations. To partially address these problems, we propose to use extensive sensitivity analyses and identify the main sources of variation and bias. We illustrate these concepts by examining the racial disparity in all-cause mortality in the US using the National Health and Nutrition Examination Survey (NHANES 2003-2006). In particular, we match African Americans to Caucasian Americans on age, gender, BMI and objectively measured physical activity (PA). PA is measured every minute using accelerometers for up to seven days and then transformed into an empirical distribution of all of the minute-level observations. The Wasserstein metric is used as the measure of distance between these participant-specific distributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.01694v1</guid>
      <category>stat.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marina Hernandez, Ciprian Crainiceanu</dc:creator>
    </item>
    <item>
      <title>Bayesian Learning of Clinically Meaningful Sepsis Phenotypes in Northern Tanzania</title>
      <link>https://arxiv.org/abs/2405.01746</link>
      <description>arXiv:2405.01746v1 Announce Type: new 
Abstract: Sepsis is a life-threatening condition caused by a dysregulated host response to infection. Recently, researchers have hypothesized that sepsis consists of a heterogeneous spectrum of distinct subtypes, motivating several studies to identify clusters of sepsis patients that correspond to subtypes, with the long-term goal of using these clusters to design subtype-specific treatments. Therefore, clinicians rely on clusters having a concrete medical interpretation, usually corresponding to clinically meaningful regions of the sample space that have a concrete implication to practitioners. In this article, we propose Clustering Around Meaningful Regions (CLAMR), a Bayesian clustering approach that explicitly models the medical interpretation of each cluster center. CLAMR favors clusterings that can be summarized via meaningful feature values, leading to medically significant sepsis patient clusters. We also provide details on measuring the effect of each feature on the clustering using Bayesian hypothesis tests, so one can assess what features are relevant for cluster interpretation. Our focus is on clustering sepsis patients from Moshi, Tanzania, where patients are younger and the prevalence of HIV infection is higher than in previous sepsis subtyping cohorts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.01746v1</guid>
      <category>stat.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexander Dombowsky, David B. Dunson, Deng B. Madut, Matthew P. Rubach, Amy H. Herring</dc:creator>
    </item>
    <item>
      <title>Quantifying the Causal Effect of Financial Literacy Courses on Financial Health</title>
      <link>https://arxiv.org/abs/2405.01789</link>
      <description>arXiv:2405.01789v1 Announce Type: new 
Abstract: In this study, we investigate the causal effect of financial literacy education on a composite financial health score constructed from 17 self-reported financial health and distress metrics ranging from spending habits to confidence in ability to repay debt to day-to-day financial skill. Leveraging data from the 2021 National Financial Capability Study, we find a significant and positive average treatment effect of financial literacy education on financial health. To test the robustness of this effect, we utilize a variety of causal estimators (Generalized Lin's estimator, 1:1 propensity matching, IPW, and AIPW) and conduct sensitivity analysis using alternate health outcome scoring and varying caliper strengths. Our results are robust to these changes. The robust positive effect of financial literacy education on financial health found here motivates financial education for all individuals and holds implications for policymakers seeking to address the worsening debt problem in the U.S, though the relatively small magnitude of effect demands further research by experts in the domain of financial health.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.01789v1</guid>
      <category>stat.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel Frees, Arnav Gangal, Charles Shaviro</dc:creator>
    </item>
    <item>
      <title>A comparison of regression models for static and dynamic prediction of a prognostic outcome during admission in electronic health care records</title>
      <link>https://arxiv.org/abs/2405.01986</link>
      <description>arXiv:2405.01986v1 Announce Type: new 
Abstract: Objective Hospitals register information in the electronic health records (EHR) continuously until discharge or death. As such, there is no censoring for in-hospital outcomes. We aimed to compare different dynamic regression modeling approaches to predict central line-associated bloodstream infections (CLABSI) in EHR while accounting for competing events precluding CLABSI. Materials and Methods We analyzed data from 30,862 catheter episodes at University Hospitals Leuven from 2012 and 2013 to predict 7-day risk of CLABSI. Competing events are discharge and death. Static models at catheter onset included logistic, multinomial logistic, Cox, cause-specific hazard, and Fine-Gray regression. Dynamic models updated predictions daily up to 30 days after catheter onset (i.e. landmarks 0 to 30 days), and included landmark supermodel extensions of the static models, separate Fine-Gray models per landmark time, and regularized multi-task learning (RMTL). Model performance was assessed using 100 random 2:1 train-test splits. Results The Cox model performed worst of all static models in terms of area under the receiver operating characteristic curve (AUC) and calibration. Dynamic landmark supermodels reached peak AUCs between 0.741-0.747 at landmark 5. The Cox landmark supermodel had the worst AUCs (&lt;=0.731) and calibration up to landmark 7. Separate Fine-Gray models per landmark performed worst for later landmarks, when the number of patients at risk was low. Discussion and Conclusion Categorical and time-to-event approaches had similar performance in the static and dynamic settings, except Cox models. Ignoring competing risks caused problems for risk prediction in the time-to-event framework (Cox), but not in the categorical framework (logistic regression).</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.01986v1</guid>
      <category>stat.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shan Gao, Elena Albu, Hein Putter, Pieter Stijnen, Frank Rademakers, Veerle Cossey, Yves Debaveye, Christel Janssens, Ben Van Calster, Laure Wynants</dc:creator>
    </item>
    <item>
      <title>Predictive Decision Synthesis for Portfolios: Betting on Better Models</title>
      <link>https://arxiv.org/abs/2405.01598</link>
      <description>arXiv:2405.01598v1 Announce Type: cross 
Abstract: We discuss and develop Bayesian dynamic modelling and predictive decision synthesis for portfolio analysis. The context involves model uncertainty with a set of candidate models for financial time series with main foci in sequential learning, forecasting, and recursive decisions for portfolio reinvestments. The foundational perspective of Bayesian predictive decision synthesis (BPDS) defines novel, operational analysis and resulting predictive and decision outcomes. A detailed case study of BPDS in financial forecasting of international exchange rate time series and portfolio rebalancing, with resulting BPDS-based decision outcomes compared to traditional Bayesian analysis, exemplifies and highlights the practical advances achievable under the expanded, subjective Bayesian approach that BPDS defines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.01598v1</guid>
      <category>q-fin.PM</category>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Emily Tallman, Mike West</dc:creator>
    </item>
    <item>
      <title>Identification of SNPs in genomes using GRAMEP, an alignment-free method based on the Principle of Maximum Entropy</title>
      <link>https://arxiv.org/abs/2405.01715</link>
      <description>arXiv:2405.01715v1 Announce Type: cross 
Abstract: Advances in high throughput sequencing technologies provide a large number of genomes to be analyzed, so computational methodologies play a crucial role in analyzing and extracting knowledge from the data generated. Investigating genomic mutations is critical because of their impact on chromosomal evolution, genetic disorders, and diseases. It is common to adopt aligning sequences for analyzing genomic variations, however, this approach can be computationally expensive and potentially arbitrary in scenarios with large datasets. Here, we present a novel method for identifying single nucleotide polymorphisms (SNPs) in DNA sequences from assembled genomes. This method uses the principle of maximum entropy to select the most informative k-mers specific to the variant under investigation. The use of this informative k-mer set enables the detection of variant-specific mutations in comparison to a reference sequence. In addition, our method offers the possibility of classifying novel sequences with no need for organism-specific information. GRAMEP demonstrated high accuracy in both in silico simulations and analyses of real viral genomes, including Dengue, HIV, and SARS-CoV-2. Our approach maintained accurate SARS-CoV-2 variant identification while demonstrating a lower computational cost compared to the gold-standard statistical tools. The source code for this proof-of-concept implementation is freely available at https://github.com/omatheuspimenta/GRAMEP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.01715v1</guid>
      <category>q-bio.GN</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>stat.AP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Matheus Henrique Pimenta-Zanon, Andr\'e Yoshiaki Kashiwabara, Andr\'e Lu\'is Laforga Vanzela, Fabricio Martins Lopes</dc:creator>
    </item>
    <item>
      <title>The m-th Longest Runs of Multivariate Random Sequences</title>
      <link>https://arxiv.org/abs/2405.01747</link>
      <description>arXiv:2405.01747v1 Announce Type: cross 
Abstract: The distributions of the $m$-th longest runs of multivariate random sequences are considered. For random sequences made up of $k$ kinds of letters, the lengths of the runs are sorted in two ways to give two definitions of run length ordering. In one definition, the lengths of the runs are sorted separately for each letter type. In the second definition, the lengths of all the runs are sorted together. Exact formulas are developed for the distributions of the m-th longest runs for both definitions. The derivations are based on a two-step method that is applicable to various other runs-related distributions, such as joint distributions of several letter types and multiple run lengths of a single letter type.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.01747v1</guid>
      <category>math.CO</category>
      <category>stat.AP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s10463-015-0551-8</arxiv:DOI>
      <arxiv:journal_reference>Ann Inst Stat Math 69, 497-512 (2017)</arxiv:journal_reference>
      <dc:creator>Yong Kong</dc:creator>
    </item>
    <item>
      <title>Joint distribution of rises, falls, and number of runs in random sequences</title>
      <link>https://arxiv.org/abs/2405.01748</link>
      <description>arXiv:2405.01748v1 Announce Type: cross 
Abstract: By using the matrix formulation of the two-step approach to the distributions of runs, a recursive relation and an explicit expression are derived for the generating function of the joint distribution of rises and falls for multivariate random sequences in terms of generating functions of individual letters, from which the generating functions of the joint distribution of rises, falls, and number of runs are obtained. An explicit formula for the joint distribution of rises and falls with arbitrary specification is also obtained.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.01748v1</guid>
      <category>math.CO</category>
      <category>stat.AP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1080/03610926.2017.1414261</arxiv:DOI>
      <arxiv:journal_reference>Communications in Statistics - Theory and Methods, 48(3) (2019)</arxiv:journal_reference>
      <dc:creator>Yong Kong</dc:creator>
    </item>
    <item>
      <title>Handling missing data when estimating causal effects with Targeted Maximum Likelihood Estimation</title>
      <link>https://arxiv.org/abs/2112.05274</link>
      <description>arXiv:2112.05274v4 Announce Type: replace-cross 
Abstract: Targeted Maximum Likelihood Estimation (TMLE) is increasingly used for doubly robust causal inference, but how missing data should be handled when using TMLE with data-adaptive approaches is unclear. Based on the Victorian Adolescent Health Cohort Study, we conducted a simulation study to evaluate eight missing data methods in this context: complete-case analysis, extended TMLE incorporating outcome-missingness model, missing covariate missing indicator method, five multiple imputation (MI) approaches using parametric or machine-learning models. Six scenarios were considered, varying in exposure/outcome generation models (presence of confounder-confounder interactions) and missingness mechanisms (whether outcome influenced missingness in other variables and presence of interaction/non-linear terms in missingness models). Complete-case analysis and extended TMLE had small biases when outcome did not influence missingness in other variables. Parametric MI without interactions had large bias when exposure/outcome generation models included interactions. Parametric MI including interactions performed best in bias and variance reduction across all settings, except when missingness models included a non-linear term. When choosing a method to handle missing data in the context of TMLE, researchers must consider the missingness mechanism and, for MI, compatibility with the analysis method. In many settings, a parametric MI approach that incorporates interactions and non-linearities is expected to perform well.</description>
      <guid isPermaLink="false">oai:arXiv.org:2112.05274v4</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1093/aje/kwae012</arxiv:DOI>
      <arxiv:journal_reference>Am J Epidemiol. 2024 Feb 22:kwae012. Epub ahead of print. PMID: 38400653</arxiv:journal_reference>
      <dc:creator>S. Ghazaleh Dashti, Katherine J. Lee, Julie A. Simpson, Ian R. White, John B. Carlin, Margarita Moreno-Betancur</dc:creator>
    </item>
  </channel>
</rss>
