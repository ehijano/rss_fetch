<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.HC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.HC</link>
    <description>cs.HC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.HC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 17 May 2024 04:00:08 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 17 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>AKN_Regie: a bridge between digital and performing arts</title>
      <link>https://arxiv.org/abs/2405.09574</link>
      <description>arXiv:2405.09574v1 Announce Type: new 
Abstract: In parallel with the dissemination of information technology, we note the persistence of frontiers within creative practices, in particular between the digital arts and the performing arts. Crossings of these frontiers brought to light the need for a common appropriation of digital issues. As a result of this appropriation, the AvatarStaging platform and its software dimension AKN_Regie will be described in their use to direct avatars on a mixed theatre stage. Developed with the Blueprint visual language within Epic Games' Unreal Engine, AKN_Regie offers a user interface accessible to non-programming artists. This feature will be used to describe two perspectives of appropriation of the tool: the Plugin perspective for these users and the Blueprint perspective for programming artists who want to improve the tool. These two perspectives are then completed by a C++ perspective that aligns AKN_Regie with the language with which the engine itself is programmed. The circulations between these three perspectives are finally studied by drawing on work on the ecology of collective intelligence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.09574v1</guid>
      <category>cs.HC</category>
      <category>cs.GR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>Samuel Szoniecky; Malek Ghenima; Imad Saleh. Fronti{\`e}res num{\'e}riques. Actes du 5{\`e}me colloque international sur les fronti{\`e}res num{\'e}riques (2023), Europia, pp.272-282, 2024, 979-10-90094-67-3</arxiv:journal_reference>
      <dc:creator>Georges Gagner\'e (INREV)</dc:creator>
    </item>
    <item>
      <title>Beyond Repetition: The Role of Varied Questioning and Feedback in Knowledge Generalization</title>
      <link>https://arxiv.org/abs/2405.09655</link>
      <description>arXiv:2405.09655v1 Announce Type: new 
Abstract: This study examines the effects of question type and feedback on learning outcomes in a hybrid graduate-level course. By analyzing data from 32 students over 30,198 interactions, we assess the efficacy of unique versus repeated questions and the impact of feedback on student learning. The findings reveal students demonstrate significantly better knowledge generalization when encountering unique questions compared to repeated ones, even though they perform better with repeated opportunities. Moreover, we find that the timing of explanatory feedback is a more robust predictor of learning outcomes than the practice opportunities themselves. These insights suggest that educational practices and technological platforms should prioritize a variety of questions to enhance the learning process. The study also highlights the critical role of feedback; opportunities preceding feedback are less effective in enhancing learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.09655v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3657604.3664688</arxiv:DOI>
      <dc:creator>Gautam Yadav, Paulo F. Carvalho, Elizabeth A. McLaughlin, Kenneth R. Koedinger</dc:creator>
    </item>
    <item>
      <title>Modeling User Preferences via Brain-Computer Interfacing</title>
      <link>https://arxiv.org/abs/2405.09691</link>
      <description>arXiv:2405.09691v1 Announce Type: new 
Abstract: Present Brain-Computer Interfacing (BCI) technology allows inference and detection of cognitive and affective states, but fairly little has been done to study scenarios in which such information can facilitate new applications that rely on modeling human cognition. One state that can be quantified from various physiological signals is attention. Estimates of human attention can be used to reveal preferences and novel dimensions of user experience. Previous approaches have tackled these incredibly challenging tasks using a variety of behavioral signals, from dwell-time to click-through data, and computational models of visual correspondence to these behavioral signals. However, behavioral signals are only rough estimations of the real underlying attention and affective preferences of the users. Indeed, users may attend to some content simply because it is salient, but not because it is really interesting, or simply because it is outrageous. With this paper, we put forward a research agenda and example work using BCI to infer users' preferences, their attentional correlates towards visual content, and their associations with affective experience. Subsequently, we link these to relevant applications, such as information retrieval, personalized steering of generative models, and crowdsourcing population estimates of affective experiences.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.09691v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luis A. Leiva, Javier Ttraver, Alexandra Kawala-Sterniuk, Tuukka Ruotsalo</dc:creator>
    </item>
    <item>
      <title>Enhancing Saliency Prediction in Monitoring Tasks: The Role of Visual Highlights</title>
      <link>https://arxiv.org/abs/2405.09695</link>
      <description>arXiv:2405.09695v1 Announce Type: new 
Abstract: This study examines the role of visual highlights in guiding user attention in drone monitoring tasks, employing a simulated interface for observation. The experiment results show that such highlights can significantly expedite the visual attention on the corresponding area. Based on this observation, we leverage both the temporal and spatial information in the highlight to develop a new saliency model: the highlight-informed saliency model (HISM), to infer the visual attention change in the highlight condition. Our findings show the effectiveness of visual highlights in enhancing user attention and demonstrate the potential of incorporating these cues into saliency prediction models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.09695v1</guid>
      <category>cs.HC</category>
      <category>cs.CV</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3649902.3655652</arxiv:DOI>
      <dc:creator>Zekun Wu, Anna Maria Feit</dc:creator>
    </item>
    <item>
      <title>Discussing Risks and Benefits in the Future of Hybrid Rehabilitation and Fitness in Mixed Reality</title>
      <link>https://arxiv.org/abs/2405.10059</link>
      <description>arXiv:2405.10059v1 Announce Type: new 
Abstract: In a world where in-person context transitions more into remote and hybrid concepts, we should consider new concepts of interaction in health and rehabilitation and what advantages and disadvantages they bring. One of the rising topics is mixed reality, where we can use the advantages of immersive 3D, 360-degree environments. Meanwhile, physical activity is further decreasing and with it negative effects increase through sedentary behaviour or wrong and untrained movements. In this position paper, we discuss these new risks and potential benefits of mixed reality technology when used for rehabilitation and fitness. We conclude with suggesting better feedback and guidance for physical movement and tasks at home. Improving feedback and guidance for participants could be achieved through using new technologies like virtual reality and motion tracking.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10059v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jana Franceska Funke, Enrico Rukzio</dc:creator>
    </item>
    <item>
      <title>Mental Well-being Opportunities in Interacting and Reflecting with Personal Data Sculptures of EEG</title>
      <link>https://arxiv.org/abs/2405.10139</link>
      <description>arXiv:2405.10139v1 Announce Type: new 
Abstract: Data physicalization is a research area in quick expansion whose necessity and popularity are motivated by the pervasiveness of data in our everyday. While the reflective ability of personal data physicalization has been vastly documented, their mental health and emotional well-being benefits remain largely unexplored. We present a qualitative study where we create personal data sculptures of electroencephalograms (EEG) and mental activity, observe users' interactions with them, and analyze their reflections for hints of self-discovery and intended behavioral change. We argue that there is a ground for using personal data sculptures as prompts for reflection on mental well-being and motivators for self-caring, and that data sculptures for mental well-being are a finalized use of data physicalization worth exploring further.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10139v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maria Teresa Ortoleva, Rita Borgo, Alfie Abdul-Rahman</dc:creator>
    </item>
    <item>
      <title>Firefighters' Perceptions on Collaboration and Interaction with Autonomous Drones: Results of a Field Trial</title>
      <link>https://arxiv.org/abs/2405.10153</link>
      <description>arXiv:2405.10153v1 Announce Type: new 
Abstract: Applications of drones in emergency response, like firefighting, have been promoted in the past decade. As the autonomy of drones continues to improve, the ways in which they are integrated into firefighting teams and their impact on crews are changing. This demands more understanding of how firefighters perceive and interact with autonomous drones. This paper presents a drone-based system for emergency operations with which firefighters can interact through sound, lights, and a graphical user interface. We use interviews with stakeholders collected in two field trials to explore their perceptions of the interaction and collaboration with drones. Our result shows that firefighters perceived visual interaction as adequate. However, for audio instructions and interfaces, information overload emerges as an essential problem. The potential impact of drones on current work configurations may involve shifting the position of humans closer to supervisory decision-makers and changing the training structure and content.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10153v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3613904.3642061</arxiv:DOI>
      <arxiv:journal_reference>CHI '24: Proceedings of the CHI Conference on Human Factors in Computing Systems (2024), Article No.: 265, 1-19</arxiv:journal_reference>
      <dc:creator>Moyi Li, Dzmitry Katsiuba, Mateusz Dolata, Gerhard Schwabe</dc:creator>
    </item>
    <item>
      <title>"The Death of Wikipedia?" -- Exploring the Impact of ChatGPT on Wikipedia Engagement</title>
      <link>https://arxiv.org/abs/2405.10205</link>
      <description>arXiv:2405.10205v1 Announce Type: new 
Abstract: Wikipedia is one of the most popular websites in the world, serving as a major source of information and learning resource for millions of users worldwide. While motivations for its usage vary, prior research suggests shallow information gathering -- looking up facts and information or answering questions -- dominates over more in-depth usage. On the 22nd of November 2022, ChatGPT was released to the public and has quickly become a popular source of information, serving as an effective question-answering and knowledge gathering resource. Early indications have suggested that it may be drawing users away from traditional question answering services such as Stack Overflow, raising the question of how it may have impacted Wikipedia. In this paper, we explore Wikipedia user metrics across four areas: page views, unique visitor numbers, edit counts and editor numbers within twelve language instances of Wikipedia. We perform pairwise comparisons of these metrics before and after the release of ChatGPT and implement a panel regression model to observe and quantify longer-term trends. We find no evidence of a fall in engagement across any of the four metrics, instead observing that page views and visitor numbers increased in the period following ChatGPT's launch. However, we observe a lower increase in languages where ChatGPT was available than in languages where it was not, which may suggest ChatGPT's availability limited growth in those languages. Our results contribute to the understanding of how emerging generative AI tools are disrupting the Web ecosystem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10205v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Neal Reeves, Wenjie Yin, Elena Simperl, Miriam Redi</dc:creator>
    </item>
    <item>
      <title>How To Save A World: The Go-Along Interview as Game Preservation Methodology in Wurm Online</title>
      <link>https://arxiv.org/abs/2405.10208</link>
      <description>arXiv:2405.10208v1 Announce Type: new 
Abstract: Massively multiplayer online (MMO) games boomed in the late 1990s to 2000s. In parallel, ethnographic studies of these communities emerged, generally involving participant observation and interviews. Several decades on, many MMOs have been reconfigured, remastered or are potentially no longer accessible at all, which presents challenges for their continued study and long-term preservation. In this paper we explore the "go-along" methodology, in which a researcher joins a participant on a walk through a familiar place and asks them questions, as a qualitative research method applicable for the study and preservation of games culture. Though the methodology has been introduced in digital media studies, to date it has had limited application in digital games, if at all. We report on a pilot study exploring applications of the go-along method to the sandbox MMO Wurm Online; a persistent, player-directed world with a rich history. We report on our motivations for the work, our analysis of the resulting interviews, and our reflections on both the use of go-alongs in digital games, as well as the unique and inspiring culture and community of this lesser-known game.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10208v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3649921.3650017</arxiv:DOI>
      <dc:creator>Florence Smith Nicholls, Michael Cook</dc:creator>
    </item>
    <item>
      <title>A Design Trajectory Map of Human-AI Collaborative Reinforcement Learning Systems: Survey and Taxonomy</title>
      <link>https://arxiv.org/abs/2405.10214</link>
      <description>arXiv:2405.10214v1 Announce Type: new 
Abstract: Driven by the algorithmic advancements in reinforcement learning and the increasing number of implementations of human-AI collaboration, Collaborative Reinforcement Learning (CRL) has been receiving growing attention. Despite this recent upsurge, this area is still rarely systematically studied. In this paper, we provide an extensive survey, investigating CRL methods based on both interactive reinforcement learning algorithms and human-AI collaborative frameworks that were proposed in the past decade. We elucidate and discuss via synergistic analysis methods both the growth of the field and the state-of-the-art; we conceptualise the existing frameworks from the perspectives of design patterns, collaborative levels, parties and capabilities, and review interactive methods and algorithmic models. Specifically, we create a new Human-AI CRL Design Trajectory Map, as a systematic modelling tool for the selection of existing CRL frameworks, as well as a method of designing new CRL systems, and finally of improving future CRL designs. Furthermore, we elaborate generic Human-AI CRL challenges, providing the research community with a guide towards novel research directions. The aim of this paper is to empower researchers with a systematic framework for the design of efficient and 'natural' human-AI collaborative methods, making it possible to work on maximised realisation of humans' and AI's potentials.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10214v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhaoxing Li</dc:creator>
    </item>
    <item>
      <title>Co-Matching: Towards Human-Machine Collaborative Legal Case Matching</title>
      <link>https://arxiv.org/abs/2405.10248</link>
      <description>arXiv:2405.10248v1 Announce Type: new 
Abstract: Recent efforts have aimed to improve AI machines in legal case matching by integrating legal domain knowledge. However, successful legal case matching requires the tacit knowledge of legal practitioners, which is difficult to verbalize and encode into machines. This emphasizes the crucial role of involving legal practitioners in high-stakes legal case matching. To address this, we propose a collaborative matching framework called Co-Matching, which encourages both the machine and the legal practitioner to participate in the matching process, integrating tacit knowledge. Unlike existing methods that rely solely on the machine, Co-Matching allows both the legal practitioner and the machine to determine key sentences and then combine them probabilistically. Co-Matching introduces a method called ProtoEM to estimate human decision uncertainty, facilitating the probabilistic combination. Experimental results demonstrate that Co-Matching consistently outperforms existing legal case matching methods, delivering significant performance improvements over human- and machine-based matching in isolation (on average, +5.51% and +8.71%, respectively). Further analysis shows that Co-Matching also ensures better human-machine collaboration effectiveness. Our study represents a pioneering effort in human-machine collaboration for the matching task, marking a milestone for future collaborative matching studies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10248v1</guid>
      <category>cs.HC</category>
      <category>cs.IR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chen Huang, Xinwei Yang, Yang Deng, Wenqiang Lei, JianCheng Lv, Tat-Seng Chua</dc:creator>
    </item>
    <item>
      <title>IntelliExplain: Enhancing Interactive Code Generation through Natural Language Explanations for Non-Professional Programmers</title>
      <link>https://arxiv.org/abs/2405.10250</link>
      <description>arXiv:2405.10250v1 Announce Type: new 
Abstract: Large language models (LLMs) have exhibited a strong promise in automatically generating executable code from natural language descriptions, particularly with interactive features that allow users to engage in the code-generation process by instructing the LLM with iterative feedback. However, existing interaction paradigms often assume that users have expert knowledge to debug source code and are not optimized for non-professional programmers' use. This raises challenges in making interactive code generation more accessible for individuals with varying levels of programming expertise. To tackle these challenges, we present IntelliExplain, which offers a novel human-LLM interaction paradigm to enhance non-professional programmers' experience by enabling them to interact with source code via natural language explanations. Users interact with IntelliExplain by providing natural language corrective feedback on errors they identify from the explanations. Feedback is used by the system to revise the code, until the user is satisfied with explanations by the system of the code. Our user study demonstrates that users with IntelliExplain achieve a significantly higher success rate 11.6% and 25.3% better than with vanilla GPT-3.5, while also requiring 39.0% and 15.6% less time in Text-to-SQL and Python code generation tasks, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10250v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hao Yan, Thomas D. Latoza, Ziyu Yao</dc:creator>
    </item>
    <item>
      <title>Towards Bi-Hemispheric Emotion Mapping through EEG: A Dual-Stream Neural Network Approach</title>
      <link>https://arxiv.org/abs/2405.09551</link>
      <description>arXiv:2405.09551v1 Announce Type: cross 
Abstract: Emotion classification through EEG signals plays a significant role in psychology, neuroscience, and human-computer interaction. This paper addresses the challenge of mapping human emotions using EEG data in the Mapping Human Emotions through EEG Signals FG24 competition. Subjects mimic the facial expressions of an avatar, displaying fear, joy, anger, sadness, disgust, and surprise in a VR setting. EEG data is captured using a multi-channel sensor system to discern brain activity patterns. We propose a novel two-stream neural network employing a Bi-Hemispheric approach for emotion inference, surpassing baseline methods and enhancing emotion recognition accuracy. Additionally, we conduct a temporal analysis revealing that specific signal intervals at the beginning and end of the emotion stimulus sequence contribute significantly to improve accuracy. Leveraging insights gained from this temporal analysis, our approach offers enhanced performance in capturing subtle variations in the states of emotions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.09551v1</guid>
      <category>eess.SP</category>
      <category>cs.HC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David Freire-Obreg\'on, Daniel Hern\'andez-Sosa, Oliverio J. Santana, Javier Lorenzo-Navarro, Modesto Castrill\'on-Santana</dc:creator>
    </item>
    <item>
      <title>Manifold Integrated Gradients: Riemannian Geometry for Feature Attribution</title>
      <link>https://arxiv.org/abs/2405.09800</link>
      <description>arXiv:2405.09800v1 Announce Type: cross 
Abstract: In this paper, we dive into the reliability concerns of Integrated Gradients (IG), a prevalent feature attribution method for black-box deep learning models. We particularly address two predominant challenges associated with IG: the generation of noisy feature visualizations for vision models and the vulnerability to adversarial attributional attacks. Our approach involves an adaptation of path-based feature attribution, aligning the path of attribution more closely to the intrinsic geometry of the data manifold. Our experiments utilise deep generative models applied to several real-world image datasets. They demonstrate that IG along the geodesics conforms to the curved geometry of the Riemannian data manifold, generating more perceptually intuitive explanations and, subsequently, substantially increasing robustness to targeted attributional attacks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.09800v1</guid>
      <category>cs.LG</category>
      <category>cs.HC</category>
      <category>math.DG</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eslam Zaher, Maciej Trzaskowski, Quan Nguyen, Fred Roosta</dc:creator>
    </item>
    <item>
      <title>Revisiting OPRO: The Limitations of Small-Scale LLMs as Optimizers</title>
      <link>https://arxiv.org/abs/2405.10276</link>
      <description>arXiv:2405.10276v1 Announce Type: cross 
Abstract: Numerous recent works aim to enhance the efficacy of Large Language Models (LLMs) through strategic prompting. In particular, the Optimization by PROmpting (OPRO) approach provides state-of-the-art performance by leveraging LLMs as optimizers where the optimization task is to find instructions that maximize the task accuracy. In this paper, we revisit OPRO for automated prompting with relatively small-scale LLMs, such as LLaMa-2 family and Mistral 7B. Our investigation reveals that OPRO shows limited effectiveness in small-scale LLMs, with limited inference capabilities constraining optimization ability. We suggest future automatic prompting engineering to consider both model capabilities and computational costs. Additionally, for small-scale LLMs, we recommend direct instructions that clearly outline objectives and methodologies as robust prompt baselines, ensuring efficient and effective prompt engineering in ongoing research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10276v1</guid>
      <category>cs.CL</category>
      <category>cs.HC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>ACL Findings 2024</arxiv:journal_reference>
      <dc:creator>Tuo Zhang, Jinyue Yuan, Salman Avestimehr</dc:creator>
    </item>
    <item>
      <title>Societal Adaptation to Advanced AI</title>
      <link>https://arxiv.org/abs/2405.10295</link>
      <description>arXiv:2405.10295v1 Announce Type: cross 
Abstract: Existing strategies for managing risks from advanced AI systems often focus on affecting what AI systems are developed and how they diffuse. However, this approach becomes less feasible as the number of developers of advanced AI grows, and impedes beneficial use-cases as well as harmful ones. In response, we urge a complementary approach: increasing societal adaptation to advanced AI, that is, reducing the expected negative impacts from a given level of diffusion of a given AI capability. We introduce a conceptual framework which helps identify adaptive interventions that avoid, defend against and remedy potentially harmful uses of AI systems, illustrated with examples in election manipulation, cyberterrorism, and loss of control to AI decision-makers. We discuss a three-step cycle that society can implement to adapt to AI. Increasing society's ability to implement this cycle builds its resilience to advanced AI. We conclude with concrete recommendations for governments, industry, and third-parties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10295v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jamie Bernardi, Gabriel Mukobi, Hilary Greaves, Lennart Heim, Markus Anderljung</dc:creator>
    </item>
    <item>
      <title>SonifyAR: Context-Aware Sound Generation in Augmented Reality</title>
      <link>https://arxiv.org/abs/2405.07089</link>
      <description>arXiv:2405.07089v2 Announce Type: replace 
Abstract: Sound plays a crucial role in enhancing user experience and immersiveness in Augmented Reality (AR). However, current platforms lack support for AR sound authoring due to limited interaction types, challenges in collecting and specifying context information, and difficulty in acquiring matching sound assets. We present SonifyAR, an LLM-based AR sound authoring system that generates context-aware sound effects for AR experiences. SonifyAR expands the current design space of AR sound and implements a Programming by Demonstration (PbD) pipeline to automatically collect contextual information of AR events, including virtual content semantics and real world context. This context information is then processed by a large language model to acquire sound effects with Recommendation, Retrieval, Generation, and Transfer methods. To evaluate the usability and performance of our system, we conducted a user study with eight participants and created five example applications, including an AR-based science experiment, an improving case for AR headset safety, and an assisting example for low vision AR users.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07089v2</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xia Su, Jon E. Froehlich, Eunyee Koh, Chang Xiao</dc:creator>
    </item>
    <item>
      <title>Should agentic conversational AI change how we think about ethics? Characterising an interactional ethics centred on respect</title>
      <link>https://arxiv.org/abs/2401.09082</link>
      <description>arXiv:2401.09082v2 Announce Type: replace-cross 
Abstract: With the growing popularity of conversational agents based on large language models (LLMs), we need to ensure their behaviour is ethical and appropriate. Work in this area largely centres around the 'HHH' criteria: making outputs more helpful and honest, and avoiding harmful (biased, toxic, or inaccurate) statements. Whilst this semantic focus is useful when viewing LLM agents as mere mediums or output-generating systems, it fails to account for pragmatic factors that can make the same speech act seem more or less tactless or inconsiderate in different social situations. With the push towards agentic AI, wherein systems become increasingly proactive in chasing goals and performing actions in the world, considering the pragmatics of interaction becomes essential. We propose an interactional approach to ethics that is centred on relational and situational factors. We explore what it means for a system, as a social actor, to treat an individual respectfully in a (series of) interaction(s). Our work anticipates a set of largely unexplored risks at the level of situated social interaction, and offers practical suggestions to help agentic LLM technologies treat people well.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.09082v2</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lize Alberts, Geoff Keeling, Amanda McCroskery</dc:creator>
    </item>
    <item>
      <title>Red-Teaming for Generative AI: Silver Bullet or Security Theater?</title>
      <link>https://arxiv.org/abs/2401.15897</link>
      <description>arXiv:2401.15897v2 Announce Type: replace-cross 
Abstract: In response to rising concerns surrounding the safety, security, and trustworthiness of Generative AI (GenAI) models, practitioners and regulators alike have pointed to AI red-teaming as a key component of their strategies for identifying and mitigating these risks. However, despite AI red-teaming's central role in policy discussions and corporate messaging, significant questions remain about what precisely it means, what role it can play in regulation, and how it relates to conventional red-teaming practices as originally conceived in the field of cybersecurity. In this work, we identify recent cases of red-teaming activities in the AI industry and conduct an extensive survey of relevant research literature to characterize the scope, structure, and criteria for AI red-teaming practices. Our analysis reveals that prior methods and practices of AI red-teaming diverge along several axes, including the purpose of the activity (which is often vague), the artifact under evaluation, the setting in which the activity is conducted (e.g., actors, resources, and methods), and the resulting decisions it informs (e.g., reporting, disclosure, and mitigation). In light of our findings, we argue that while red-teaming may be a valuable big-tent idea for characterizing GenAI harm mitigations, and that industry may effectively apply red-teaming and other strategies behind closed doors to safeguard AI, gestures towards red-teaming (based on public definitions) as a panacea for every possible risk verge on security theater. To move toward a more robust toolbox of evaluations for generative AI, we synthesize our recommendations into a question bank meant to guide and scaffold future AI red-teaming practices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.15897v2</guid>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Feffer, Anusha Sinha, Wesley Hanwen Deng, Zachary C. Lipton, Hoda Heidari</dc:creator>
    </item>
  </channel>
</rss>
