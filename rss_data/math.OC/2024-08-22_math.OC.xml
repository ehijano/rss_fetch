<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 23 Aug 2024 04:00:46 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 23 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Distributed alternating gradient descent for convex semi-infinite programs over a network</title>
      <link>https://arxiv.org/abs/2408.11937</link>
      <description>arXiv:2408.11937v1 Announce Type: new 
Abstract: This paper presents a first-order distributed algorithm for solving a convex semi-infinite program (SIP) over a time-varying network. In this setting, the objective function associated with the optimization problem is a summation of a set of functions, each held by one node in a network. The semi-infinite constraint, on the other hand, is known to all agents. The nodes collectively aim to solve the problem using local data about the objective and limited communication capabilities depending on the network topology. Our algorithm is built on three key ingredients: consensus step, gradient descent in the local objective, and local gradient descent iterations in the constraint at a node when the estimate violates the semi-infinite constraint. The algorithm is constructed, and its parameters are prescribed in such a way that the iterates held by each agent provably converge to an optimizer. That is, as the algorithm progresses, the estimates achieve consensus, and the constraint violation and the error in the optimal value are bounded above by vanishing terms. A simulation example illustrates our results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.11937v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ashwin Aravind, Debasish Chatterjee, Ashish Cherukuri</dc:creator>
    </item>
    <item>
      <title>Convergence and Bound Computation for Chance Constrained Distributionally Robust Models using Sample Approximation</title>
      <link>https://arxiv.org/abs/2408.12018</link>
      <description>arXiv:2408.12018v1 Announce Type: new 
Abstract: This paper considers a distributionally robust chance constraint model with a general ambiguity set. We show that a sample based approximation of this model converges under suitable sufficient conditions. We also show that upper and lower bounds on the optimal value of the model can be estimated statistically. Specific ambiguity sets are discussed as examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.12018v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiaqi Lei, Sanjay Mehrotra</dc:creator>
    </item>
    <item>
      <title>HPR-LP: An implementation of an HPR method for solving linear programming</title>
      <link>https://arxiv.org/abs/2408.12179</link>
      <description>arXiv:2408.12179v1 Announce Type: new 
Abstract: In this paper, we introduce an HPR-LP solver, an implementation of a Halpern Peaceman-Rachford (HPR) method with semi-proximal terms for solving linear programming (LP). The HPR method enjoys the iteration complexity of $O(1/k)$ in terms of the Karush-Kuhn-Tucker residual and the objective error. Based on the complexity results, we design an adaptive strategy of restart and penalty parameter update to improve the efficiency and robustness of the HPR method. We conduct extensive numerical experiments on different LP benchmark datasets using NVIDIA A100-SXM4-80GB GPU in different stopping tolerances. Our solver's Julia version achieves a $\textbf{2.39x}$ to $\textbf{5.70x}$ speedup measured by SGM10 on benchmark datasets with presolve ($\textbf{2.03x}$ to $\textbf{4.06x}$ without presolve) over the award-winning solver PDLP with the tolerance of $10^{-8}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.12179v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kaihuang Chen, Defeng Sun, Yancheng Yuan, Guojun Zhang, Xinyuan Zhao</dc:creator>
    </item>
    <item>
      <title>A Fast and Effective Breakpoints Algorithm for the Quadratic Knapsack Problem</title>
      <link>https://arxiv.org/abs/2408.12183</link>
      <description>arXiv:2408.12183v1 Announce Type: new 
Abstract: The Quadratic Knapsack Problem (QKP) involves selecting a subset of elements that maximizes the sum of pairwise and singleton utilities without exceeding a given budget. We introduce a Breakpoints Algorithm for QKP, named QKBP, which is based on a technique proposed in Hochbaum (2009) for efficiently generating the concave envelope of the solutions to the relaxation of the problem for all values of the budget. Our approach utilizes the fact that breakpoints in the concave envelopes are optimal solutions for their respective budgets. For budgets between breakpoints, a fast greedy procedure derives high-quality solutions from the optimal solutions of adjacent breakpoints. The algorithm is highly scalable due to an efficient parametric cut procedure used to generate the concave envelope. This efficiency is further improved by a newly developed compact problem formulation. Our extensive computational study on both existing and new benchmark instances, with up to 10,000 elements, shows that while some leading algorithms perform well on a few instances, QKBP consistently delivers high-quality solutions regardless of instance size, density, or budget. Moreover, QKBP achieves these results in significantly faster running times than all leading algorithms. The source code of the QKBP algorithm, the benchmark instances, and the detailed results are publicly available on GitHub.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.12183v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dorit S. Hochbaum, Philipp Baumann, Olivier Goldschmidt, Yiqing Zhang</dc:creator>
    </item>
    <item>
      <title>Zeroth-Order Stochastic Mirror Descent Algorithms for Minimax Excess Risk Optimization</title>
      <link>https://arxiv.org/abs/2408.12209</link>
      <description>arXiv:2408.12209v1 Announce Type: new 
Abstract: The minimax excess risk optimization (MERO) problem is a new variation of the traditional distributionally robust optimization (DRO) problem, which achieves uniformly low regret across all test distributions under suitable conditions. In this paper, we propose a zeroth-order stochastic mirror descent (ZO-SMD) algorithm available for both smooth and non-smooth MERO to estimate the minimal risk of each distrbution, and finally solve MERO as (non-)smooth stochastic convex-concave (linear) minimax optimization problems. The proposed algorithm is proved to converge at optimal convergence rates of $\mathcal{O}\left(1/\sqrt{t}\right)$ on the estimate of $R_i^*$ and $\mathcal{O}\left(1/\sqrt{t}\right)$ on the optimization error of both smooth and non-smooth MERO. Numerical results show the efficiency of the proposed algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.12209v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhihao Gu, Zi Xu</dc:creator>
    </item>
    <item>
      <title>Optimal control of partial differential equations in PyTorch using automatic differentiation and neural network surrogates</title>
      <link>https://arxiv.org/abs/2408.12404</link>
      <description>arXiv:2408.12404v1 Announce Type: new 
Abstract: The take-home message of this paper is that solving optimal control problems can be computationally straightforward, provided that differentiable partial differential equation (PDE) solvers are available. Although this might seem to be a strong limitation and the development of differentiable PDE solvers might seem arduous, for many problems this is not the case. In particular, for linear partial differential equations, they are equivalent to a linear equation system. Therefore it is just sufficient to be able to solve linear equation systems in an automatic differentiation-capable library like PyTorch and be able to differentiate through the linear solver. Using open-source libraries, like torch_sparse_solve, we have easy to use differentiable direct solvers (here: KLU) at hand, which makes solving linear PDEs straightforward. For nonlinear PDEs, the approach above might be not sufficient, since we do not have an equivalent linear equation system for the underlying PDE. In this case, we can then use the library torch-fenics, which enables us to define PDEs using the finite element library FEniCS and then differentiate through this problem in PyTorch. We complement the proposed methodology with various optimal control problems constrained by stationary and instationary PDEs, linear and nonlinear PDEs (from Poisson to fluid-structure interaction), space-time and time-stepping formulations, parameter estimation, right-hand side control, initial condition control and boundary condition control, finite difference and finite element discretizations and neural network surrogates. All developments of this work are accompanied with the respective source codes published on GitHub.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.12404v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Denis Khimin, Julian Roth, Alexander Henkes, Thomas Wick</dc:creator>
    </item>
    <item>
      <title>Advancing Strategic Planning and Dynamic Control of Complex Projects</title>
      <link>https://arxiv.org/abs/2408.12422</link>
      <description>arXiv:2408.12422v1 Announce Type: new 
Abstract: Strategic project planning and dynamic control is essential for ensuring complex projects to be executed best-fit for common purpose. When best-for-project strategies are no longer conceivable for humans, there is a need for effective and efficient computer-aided decision support. To this end, standard simulation-driven evaluation and a-posteriori decision-making is often used instead of a combined simulation and optimisation approach that a-priori integrates the stakeholders goal orientation and risk management into a best-fit design solution. However, recently developed state-of-the-art planning and control methodologies that do already incorporate this integration still lack a stochastic representation and/or an associative multi-objective approach. This paper presents a new project management methodology, called Odycon (Open design and dynamic control), which dissolves the aforementioned shortcomings. To enable this, a generic mathematical statement is first formulated for project planning and dynamic control uniting technical logistical) capabilities, human goal-oriented behaviour, and stakeholders interests. Then, both Monte-Carlo simulation (MCS) and the Integrative Maximisation of Aggregated Preferences (IMAP) optimisation method are combined, resulting in a best-fit strategic planning and dynamic control methodology. Odycons use and added value are demonstrated for two applications: (1) a pure strategic planning of an offshore wind installation project, and (2) a pure dynamic control of a highway infrastructure construction project. Both applications demonstrate Odycons advances in concurrent and associative design and decision-making, offering best-fit for common purpose synthesis for different complex project phases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.12422v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>L. G. Teuber, H. J. van Heukelum, A. R. M. Wolfert</dc:creator>
    </item>
    <item>
      <title>Sum of squares approximations to energy functions</title>
      <link>https://arxiv.org/abs/2408.12478</link>
      <description>arXiv:2408.12478v1 Announce Type: new 
Abstract: Energy functions offer natural extensions of controllability and observability Gramians to nonlinear systems, enabling various applications such as computing reachable sets, optimizing actuator and sensor placement, performing balanced truncation, and designing feedback controllers. However, these extensions to nonlinear systems depend on solving Hamilton-Jacobi-Bellman (HJB) partial differential equations, which are infeasible for large-scale systems. Polynomial approximations are a viable alternative for modest-sized systems, but conventional polynomial approximations may yield negative values of the energy away from the origin. To address this issue, we explore polynomial approximations expressed as a sum of squares to ensure non-negative approximations. In this study, we focus on a reduced sum of squares polynomial where the coefficients are found through least-squares collocation -- minimizing the HJB residual at sample points within a desired neighborhood of the origin. We validate the accuracy of these approximations through a case study with a closed-form solution and assess their effectiveness for controlling a ring of van der Pol oscillators with a Laplacian-like coupling term and discretized Burgers equation with source terms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.12478v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hamza Adjerid, Jeff Borggaard</dc:creator>
    </item>
    <item>
      <title>Stochastic Compositional Minimax Optimization with Provable Convergence Guarantees</title>
      <link>https://arxiv.org/abs/2408.12505</link>
      <description>arXiv:2408.12505v1 Announce Type: new 
Abstract: Stochastic compositional minimax problems are prevalent in machine learning, yet there are only limited established on the convergence of this class of problems. In this paper, we propose a formal definition of the stochastic compositional minimax problem, which involves optimizing a minimax loss with a compositional structure either in primal , dual, or both primal and dual variables. We introduce a simple yet effective algorithm, stochastically Corrected stOchastic gradient Descent Ascent (CODA), which is a descent ascent type algorithm with compositional correction steps, and establish its convergence rate in aforementioned three settings. In the presence of the compositional structure in primal, the objective function typically becomes nonconvex in primal due to function composition. Thus, we consider the nonconvex-strongly-concave and nonconvex-concave settings and show that CODA can efficiently converge to a stationary point. In the case of composition on the dual, the objective function becomes nonconcave in the dual variable, and we demonstrate convergence in the strongly-convex-nonconcave and convex-nonconcave setting. In the case of composition on both variables, the primal and dual variables may lose convexity and concavity, respectively. Therefore, we anaylze the convergence in weakly-convex-weakly-concave setting. We also give a variance reduction version algorithm, CODA+, which achieves the best known rate on nonconvex-strongly-concave and nonconvex-concave compositional minimax problem. This work initiates the theoretical study of the stochastic compositional minimax problem on various settings and may inform modern machine learning scenarios such as domain adaptation or robust model-agnostic meta-learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.12505v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuyang Deng, Fuli Qiao, Mehrdad Mahdavi</dc:creator>
    </item>
    <item>
      <title>A disruption-restoration-based MILP model for elective surgical scheduling in a children's hospital using scenarios</title>
      <link>https://arxiv.org/abs/2408.12518</link>
      <description>arXiv:2408.12518v1 Announce Type: new 
Abstract: We consider the problem of scheduling elective surgeries in a Children's Hospital, where disruptions due to emergencies and no-shows may arise. We account for two features that occur in many pediatric settings: i) that it is not uncommon for pediatric patients to fall ill on the very day of their operation and, consequentially, to be unable to undergo surgery and ii) that operating rooms normally reserved for elective surgeries can be used to treat emergency cases. Elective surgeries are scheduled taking into account the time spent on the waiting list and the patient's priority, which considers the severity of their condition and their surgical deadline, generating a nominal schedule. This schedule is optimized in conjunction with a series of back-up schedules: in fact, back-up schedules shall be available in advance so as to guarantee that the operating rooms activity immediately recovers in case of a disruption. We propose an Integer Linear Programming-based approach for the problem. As there is no consolidated data on the features of both emergencies and no show, we enumerate a representative subset of the possible emergency and no-show scenarios and for each of them a back-up plan is designed. The approach reschedules patients in a way that minimizes disruption with respect to the nominal schedule and applies an as-soon-as-possible policy in case of emergencies to ensure that all patients receive timely care. The approach shows to be effective in managing disruptions, ensuring that the waiting list is managed properly, with a balanced mix of urgent and less urgent patients. Therefore, the approach provides an effective solution for scheduling patients in a pediatric hospital, taking into account the unique features of such facilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.12518v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Martina Doneda, Gloria Pelizzo, Sara Costanzo, Giuliana Carello</dc:creator>
    </item>
    <item>
      <title>Passivity-based Gradient-Play Dynamics for Distributed Generalized Nash Equilibrium Seeking</title>
      <link>https://arxiv.org/abs/2408.12536</link>
      <description>arXiv:2408.12536v1 Announce Type: new 
Abstract: We consider seeking generalized Nash equilibria (GNE) for noncooperative games with coupled nonlinear constraints over networks. We first revisit a well-known gradientplay dynamics from a passivity-based perspective, and address that the strict monotonicity on pseudo-gradients is a critical assumption to ensure the exact convergence of the dynamics. Then we propose two novel passivity-based gradient-play dynamics by introducing parallel feedforward compensators (PFCs) and output feedback compensators (OFCs). We show that the proposed dynamics can reach exact GNEs in merely monotone regimes if the PFCs are strictly passive or the OFCs are output strictly passive. Following that, resorting to passivity, we develop a unifying framework to generalize the gradient-play dynamics, and moreover, design a class of explicit passive-based dynamics with convergence guarantees. In addition, we explore the relation between the proposed dynamics and some existing methods, and extend our results to partial-decision information settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.12536v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weijian Li, Lacra Pavel</dc:creator>
    </item>
    <item>
      <title>Population Control of Giardia lamblia</title>
      <link>https://arxiv.org/abs/2408.12573</link>
      <description>arXiv:2408.12573v1 Announce Type: new 
Abstract: Giardia lamblia is a flagellate intestinal protozoan with global distribution causing the disease known as giardiasis. This parasite is responsable for 35.1% of outbreaks of diarrhea caused by contaminated water which and mainly affects children in whom it can cause physical and cognitive impairment. In this paper, we consider a model of population dynamics to represent the behavior of Giardia lamblia in vitro, taking into account its mutation characteristic that guarantees to the protozoan resistance to the drug metronidazole. Different from what is found in the literature, it is pursued as the control objective the extermination of the protozoan considering that the parameters of the model are uncertain and only the partial measurement of the state vector is possible. On these assumptions, a control law is designed and the stability of the closed-loop system is rigorously proved. Simulation and experimental results illustrate the benefits of the proposed population control method of Giardia lamblia.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.12573v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Victor Hugo Pereira Rodrigues, Maria Fantinatti, Tiago Roux Oliveira, Wilton dos Santos Freitas</dc:creator>
    </item>
    <item>
      <title>On the design of stabilizing FIR controllers</title>
      <link>https://arxiv.org/abs/2408.11959</link>
      <description>arXiv:2408.11959v1 Announce Type: cross 
Abstract: Recently, it has been observed that finite impulse response controllers are an excellent basis for encrypted control, where privacy-preserving controller evaluations via special cryptosystems are the main focus. Beneficial properties of FIR filters are also well-known from digital signal processing, which makes them preferable over infinite impulse response filters in many applications. Their appeal extends to feedback control, offering design flexibility grounded solely on output measurements. However, designing FIR controllers is challenging, which motivates this work. To address the design challenge, we initially show that FIR controller designs for linear systems can equivalently be stated as static or dynamic output feedback problems. After focusing on the existence of stabilizing FIR controllers for a given plant, we tailor two common design approaches for output feedback to the case of FIR controllers. Unfortunately, it will turn out that the FIR characteristics add further restrictions to the LMI-based approaches. Hence, we finally turn to designs building on non-convex optimization, which provide satisfactory results for a selection of benchmark systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.11959v1</guid>
      <category>eess.SY</category>
      <category>cs.CR</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Janis Adamek, Nils Schl\"uter, Moritz Schulze Darup</dc:creator>
    </item>
    <item>
      <title>Two-Timescale Gradient Descent Ascent Algorithms for Nonconvex Minimax Optimization</title>
      <link>https://arxiv.org/abs/2408.11974</link>
      <description>arXiv:2408.11974v1 Announce Type: cross 
Abstract: We provide a unified analysis of two-timescale gradient descent ascent (TTGDA) for solving structured nonconvex minimax optimization problems in the form of $\min_\textbf{x} \max_{\textbf{y} \in Y} f(\textbf{x}, \textbf{y})$, where the objective function $f(\textbf{x}, \textbf{y})$ is nonconvex in $\textbf{x}$ and concave in $\textbf{y}$, and the constraint set $Y \subseteq \mathbb{R}^n$ is convex and bounded. In the convex-concave setting, the single-timescale GDA achieves strong convergence guarantees and has been used for solving application problems arising from operations research and computer science. However, it can fail to converge in more general settings. Our contribution in this paper is to design the simple deterministic and stochastic TTGDA algorithms that efficiently find one stationary point of the function $\Phi(\cdot) := \max_{\textbf{y} \in Y} f(\cdot, \textbf{y})$. Specifically, we prove the theoretical bounds on the complexity of solving both smooth and nonsmooth nonconvex-concave minimax optimization problems. To our knowledge, this is the first systematic analysis of TTGDA for nonconvex minimax optimization, shedding light on its superior performance in training generative adversarial networks (GANs) and in solving other real-world application problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.11974v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tianyi Lin, Chi Jin, Michael. I. Jordan</dc:creator>
    </item>
    <item>
      <title>Data-driven MPC with terminal conditions in the Koopman framework</title>
      <link>https://arxiv.org/abs/2408.12457</link>
      <description>arXiv:2408.12457v1 Announce Type: cross 
Abstract: We investigate nonlinear model predictive control (MPC) with terminal conditions in the Koopman framework using extended dynamic mode decomposition (EDMD) to generate a data-based surrogate model for prediction and optimization. We rigorously show recursive feasibility and prove practical asymptotic stability w.r.t. the approximation accuracy. To this end, finite-data error bounds are employed. The construction of the terminal conditions is based on recently derived proportional error bounds to ensure the required Lyapunov decrease. Finally, we illustrate the effectiveness of the proposed data-driven predictive controller including the design procedure to construct the terminal region and controller.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.12457v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Karl Worthmann, Robin Str\"asser, Manuel Schaller, Julian Berberich, Frank Allg\"ower</dc:creator>
    </item>
    <item>
      <title>Non-overlapping Schwarz methods in time for parabolic optimal control problems</title>
      <link>https://arxiv.org/abs/2408.12512</link>
      <description>arXiv:2408.12512v1 Announce Type: cross 
Abstract: We present here the classical Schwarz method with a time domain decomposition applied to unconstrained parabolic optimal control problems. Unlike Dirichlet-Neumann and Neumann-Neumann algorithms, we find different properties based on the forward-backward structure of the optimality system. Variants can be found using only Dirichlet and Neumann transmission conditions. Some of these variants are only good smoothers, while others could lead to efficient solvers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.12512v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Martin Jakob Gander, Liu-Di Lu</dc:creator>
    </item>
    <item>
      <title>Accelerated stochastic approximation with state-dependent noise</title>
      <link>https://arxiv.org/abs/2307.01497</link>
      <description>arXiv:2307.01497v3 Announce Type: replace 
Abstract: We consider a class of stochastic smooth convex optimization problems under rather general assumptions on the noise in the stochastic gradient observation. As opposed to the classical problem setting in which the variance of noise is assumed to be uniformly bounded, herein we assume that the variance of stochastic gradients is related to the "sub-optimality" of the approximate solutions delivered by the algorithm. Such problems naturally arise in a variety of applications, in particular, in the well-known generalized linear regression problem in statistics. However, to the best of our knowledge, none of the existing stochastic approximation algorithms for solving this class of problems attain optimality in terms of the dependence on accuracy, problem parameters, and mini-batch size.
  We discuss two non-Euclidean accelerated stochastic approximation routines--stochastic accelerated gradient descent (SAGD) and stochastic gradient extrapolation (SGE)--which carry a particular duality relationship. We show that both SAGD and SGE, under appropriate conditions, achieve the optimal convergence rate, attaining the optimal iteration and sample complexities simultaneously. However, corresponding assumptions for the SGE algorithm are more general; they allow, for instance, for efficient application of the SGE to statistical estimation problems under heavy tail noises and discontinuous score functions. We also discuss the application of the SGE to problems satisfying quadratic growth conditions, and show how it can be used to recover sparse solutions. Finally, we report on some simulation experiments to illustrate numerical performance of our proposed algorithms in high-dimensional settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.01497v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sasila Ilandarideva, Anatoli Juditsky, Guanghui Lan, Tianjiao Li</dc:creator>
    </item>
    <item>
      <title>A variational approach to a cumulative distribution function estimation problem under stochastic ambiguity</title>
      <link>https://arxiv.org/abs/2309.00070</link>
      <description>arXiv:2309.00070v2 Announce Type: replace 
Abstract: We propose a method for finding a cumulative distribution function (cdf) that minimizes the distance to a given cdf, while belonging to an ambiguity set constructed relative to another cdf and, possibly, incorporating soft information. Our method embeds the family of cdfs onto the space of upper semicontinuous functions endowed with the hypo-distance. In this setting, we present an approximation scheme based on epi-splines, defined as piecewise polynomial functions, and use bounds for estimating the hypo-distance. Under appropriate hypotheses, we guarantee that the cluster points corresponding to the sequence of minimizers of the resulting approximating problems are solutions to a limiting problem. We describe a large class of functions that satisfy these hypotheses. The approximating method produces a linear-programming-based approximation scheme, enabling us to develop an algorithm from off-the-shelf solvers. The convergence of our proposed approximation is illustrated by numerical examples for the bivariate case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.00070v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Julio Deride, Johannes O. Royset, Fernanda Urrea</dc:creator>
    </item>
    <item>
      <title>Stochastic optimal control in Hilbert spaces: $C^{1,1}$ regularity of the value function and optimal synthesis via viscosity solutions</title>
      <link>https://arxiv.org/abs/2310.03181</link>
      <description>arXiv:2310.03181v3 Announce Type: replace 
Abstract: We study optimal control problems governed by abstract infinite dimensional stochastic differential equations using the dynamic programming approach. In the first part, we prove Lipschitz continuity, semiconcavity and semiconvexity of the value function under several sets of assumptions, and thus derive its $C^{1,1}$ regularity in the space variable. Based on this regularity result, we construct optimal feedback controls using the notion of the $B$-continuous viscosity solutions for the associated Hamilton--Jacobi--Bellman equation. This is done in the case when the noise coefficient is independent of the control variable. We also discuss applications of our results to optimal control problems for controlled stochastic reaction-diffusion equations and, under economic motivations, to stochastic delay differential equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.03181v3</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <category>math.PR</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Filippo de Feo, Andrzej \'Swi\k{e}ch, Lukas Wessels</dc:creator>
    </item>
    <item>
      <title>Two-Timescale Optimization Framework for Decentralized Linear-Quadratic Optimal Control</title>
      <link>https://arxiv.org/abs/2406.11168</link>
      <description>arXiv:2406.11168v3 Announce Type: replace 
Abstract: A $\mathcal{H}_2$-guaranteed decentralized linear-quadratic optimal control with convex parameterization and convex-bounded uncertainty is studied in this paper, where several sparsity promoting functions are added, respectively, into the $\mathcal{H}_2$ cost to penalize the number of communication links among decentralized controllers. Then, the sparse feedback gain is investigated to minimize the modified $\mathcal{H}_2$ cost together with the stability guarantee, and the corresponding main results are of three parts. First, the weighted-$\ell_1$ sparsity promoting function is of concern, and a two-timescale algorithm is developed based on the BSUM (Block Successive Upper-bound Minimization) framework and a primal-dual splitting approach. Second, the optimization problem induced by piecewise quadratic sparsity penalty is investigated, which exhibits an accelerated convergence rate. Third, the nonconvex sparse optimization problem with $\ell_0$-penalty is studied, which can be approximated by successive coordinatewise convex optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.11168v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lechen Feng, Yuan-Hua Ni, Xuebo Zhang</dc:creator>
    </item>
    <item>
      <title>Adaptive Sampling-Based Bi-Fidelity Stochastic Trust Region Method for Derivative-Free Stochastic Optimization</title>
      <link>https://arxiv.org/abs/2408.04625</link>
      <description>arXiv:2408.04625v2 Announce Type: replace 
Abstract: Bi-fidelity stochastic optimization is increasingly favored for streamlining optimization processes by employing a cost-effective low-fidelity (LF) function, with the goal of optimizing a more expensive high-fidelity (HF) function. In this paper, we introduce ASTRO-BFDF, a new adaptive sampling trust region method specifically designed for solving unconstrained bi-fidelity stochastic derivative-free optimization problems. Within ASTRO-BFDF, the LF function serves two purposes: first, to identify better iterates for the HF function when a high correlation between them is indicated by the optimization process, and second, to reduce the variance of the HF function estimates by Bi-fidelity Monte Carlo (BFMC). In particular, the sample sizes are dynamically determined with the option of employing either crude Monte Carlo or BFMC, while balancing optimization error and sampling error. We demonstrate that the iterates generated by ASTRO-BFDF converge to the first-order stationary point almost surely. Additionally, we numerically demonstrate the superiority of our proposed algorithm by testing it on synthetic problems and simulation optimization problems with discrete event simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04625v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yunsoo Ha, Juliane Mueller</dc:creator>
    </item>
    <item>
      <title>A Complete Set of Quadratic Constraints for Repeated ReLU and Generalizations</title>
      <link>https://arxiv.org/abs/2407.06888</link>
      <description>arXiv:2407.06888v2 Announce Type: replace-cross 
Abstract: This paper derives a complete set of quadratic constraints (QCs) for the repeated ReLU. The complete set of QCs is described by a collection of matrix copositivity conditions. We also show that only two functions satisfy all QCs in our complete set: the repeated ReLU and flipped ReLU. Thus our complete set of QCs bounds the repeated ReLU as tight as possible up to the sign invariance inherent in quadratic forms. We derive a similar complete set of incremental QCs for repeated ReLU, which can potentially lead to less conservative Lipschitz bounds for ReLU networks than the standard LipSDP approach. The basic constructions are also used to derive the complete sets of QCs for other piecewise linear activation functions such as leaky ReLU, MaxMin, and HouseHolder. Finally, we illustrate the use of the complete set of QCs to assess stability and performance for recurrent neural networks with ReLU activation functions. We rely on a standard copositivity relaxation to formulate the stability/performance condition as a semidefinite program. Simple examples are provided to illustrate that the complete sets of QCs and incremental QCs can yield less conservative bounds than existing sets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.06888v2</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sahel Vahedi Noori, Bin Hu, Geir Dullerud, Peter Seiler</dc:creator>
    </item>
    <item>
      <title>Generalised rank-constrained approximations of Hilbert-Schmidt operators on separable Hilbert spaces and applications</title>
      <link>https://arxiv.org/abs/2408.05104</link>
      <description>arXiv:2408.05104v2 Announce Type: replace-cross 
Abstract: In this work we solve, for given bounded operators $B,C$ and Hilbert--Schmidt operator $M$ acting on potentially infinite-dimensional separable Hilbert spaces, the reduced rank approximation problem, $\text{min}\{\Vert{M-BXC}\Vert_{HS}:\ \text{dim}\ \text{ran}(X)\leq r\}$. This extends the result of Sondermann (Statistische Hefte, 1986) and Friedland and Torokhti (SIAM J. Matrix Analysis and Applications, 2007), which studies this problem in the case of matrices $M$, $B$, $C$, $X$, and the analysis involves the Moore-Penrose inverse. In classical approximation problems that can be solved by the singular value decomposition or Moore--Penrose inverse, the solution satisfies a minimal norm property. Friedland and Torokhti also state such a minimal norm property of the solution. However, we show that this minimal norm property does not hold in general and give a modified minimality property that is satisfied in general. We also show that the solution may be discontinuous in infinite-dimensional settings. Necessary and sufficient conditions for continuity of the solutions are given and continuous approximations are constructed when such conditions are not met. Finally, we study problems from signal processing, reduced rank regression and linear operator learning under a rank constraint. We show that our theoretical results enable us to explicitly find the solutions to these problems and to fully characterise their existence, uniqueness and minimality property.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05104v2</guid>
      <category>math.FA</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Giuseppe Carere, Han Cheng Lie</dc:creator>
    </item>
    <item>
      <title>Regularization for Adversarial Robust Learning</title>
      <link>https://arxiv.org/abs/2408.09672</link>
      <description>arXiv:2408.09672v2 Announce Type: replace-cross 
Abstract: Despite the growing prevalence of artificial neural networks in real-world applications, their vulnerability to adversarial attacks remains a significant concern, which motivates us to investigate the robustness of machine learning models. While various heuristics aim to optimize the distributionally robust risk using the $\infty$-Wasserstein metric, such a notion of robustness frequently encounters computation intractability. To tackle the computational challenge, we develop a novel approach to adversarial training that integrates $\phi$-divergence regularization into the distributionally robust risk function. This regularization brings a notable improvement in computation compared with the original formulation. We develop stochastic gradient methods with biased oracles to solve this problem efficiently, achieving the near-optimal sample complexity. Moreover, we establish its regularization effects and demonstrate it is asymptotic equivalence to a regularized empirical risk minimization framework, by considering various scaling regimes of the regularization parameter and robustness level. These regimes yield gradient norm regularization, variance regularization, or a smoothed gradient norm regularization that interpolates between these extremes. We numerically validate our proposed method in supervised learning, reinforcement learning, and contextual learning and showcase its state-of-the-art performance against various adversarial attacks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09672v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jie Wang, Rui Gao, Yao Xie</dc:creator>
    </item>
  </channel>
</rss>
