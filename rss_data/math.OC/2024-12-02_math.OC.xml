<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 03 Dec 2024 04:25:35 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Collective steering in finite time: controllability on $\text{GL}^+(n,\mathbb{R})$</title>
      <link>https://arxiv.org/abs/2411.18766</link>
      <description>arXiv:2411.18766v1 Announce Type: new 
Abstract: We consider the problem of steering a collection of n particles that obey identical n-dimensional linear dynamics via a common state feedback law towards a rearrangement of their positions, cast as a controllability problem for a dynamical system evolving on the space of matrices with positive determinant. We show that such a task is always feasible and, moreover, that it can be achieved arbitrarily fast. We also show that an optimal feedback control policy to achieve a similar feat, may not exist. Furthermore, we show that there is no universal formula for a linear feedback control law to achieve a rearrangement, optimal or not, that is everywhere continuous with respect to the specifications. We conclude with partial results on the broader question of controllability of dynamics on orientation-preserving diffeomorphisms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.18766v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mahmoud Abdelgalil, Tryphon T. Georgiou</dc:creator>
    </item>
    <item>
      <title>Optimizing Image Retrieval with an Extended b-Metric Space</title>
      <link>https://arxiv.org/abs/2411.18800</link>
      <description>arXiv:2411.18800v1 Announce Type: new 
Abstract: This article provides a new approach on how to enhance data storage and retrieval in the Query By Image Content Systems (QBIC) by introducing the ${\rm NEM}_{\sigma}$ distance measure, satisfying the relaxed triangle inequality. By leveraging the concept of extended $b$-metric spaces, we address complex distance relationships, thereby improving the accuracy and efficiency of image database management. The use of ${\rm NEM}_{\sigma}$ facilitates better scalability and accuracy in large-scale image retrieval systems, optimizing both the storage and retrieval processes. The proposed method represents a significant advancement over traditional distance measures, offering enhanced flexibility and precision in the context of image content-based querying. Additionally, we take inspiration from ice flow models using ${\rm NEM}_{\sigma}$ and ${\rm NEM}_r$, adding dynamic and location-based factors to better capture details in images.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.18800v1</guid>
      <category>math.OC</category>
      <category>math.MG</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Abdelkader Belhenniche, Roman Chertovskih</dc:creator>
    </item>
    <item>
      <title>Sparse Polynomial Optimization with Matrix Constraints</title>
      <link>https://arxiv.org/abs/2411.18820</link>
      <description>arXiv:2411.18820v1 Announce Type: new 
Abstract: This paper studies the hierarchy of sparse matrix Moment-SOS relaxations for solving sparse polynomial optimization problems with matrix constraints. First, we prove a sufficient and necessary condition for the sparse hierarchy to be tight. Second, we discuss how to detect the tightness and extract minimizers. Third, for the convex case, we show that the hierarchy of the sparse matrix Moment-SOS relaxations is tight, under some general assumptions. In particular, we show that the sparse matrix Moment-SOS relaxation is tight for every order when the problem is SOS-convex. Numerical experiments are provided to show the efficiency of the sparse relaxations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.18820v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiawang Nie, Zheng Qu, Xindong Tang, Linghao Zhang</dc:creator>
    </item>
    <item>
      <title>Iteratively Regularized Gradient Tracking Methods for Optimal Equilibrium Seeking</title>
      <link>https://arxiv.org/abs/2411.18883</link>
      <description>arXiv:2411.18883v1 Announce Type: new 
Abstract: In noncooperative Nash games, equilibria are often inefficient. This is exemplified by the Prisoner's Dilemma and was first provably shown in the 1980s. Since then, understanding the quality of Nash equilibrium (NE) received considerable attention, leading to the emergence of inefficiency measures characterized by the best or the worst equilibrium. Traditionally, computing an optimal NE in monotone regimes is done through two-loop schemes which lack scalability and provable performance guarantees. The goal in this work lies in the development of among the first single-timescale distributed gradient tracking optimization methods for optimal NE seeking over networks. Our main contributions are as follows. By employing a regularization-based relaxation approach within two existing distributed gradient tracking methods, namely Push-Pull and DSGT, we devise and analyze two single-timescale iteratively regularized gradient tracking algorithms. The first method addresses computing the optimal NE over directed networks, while the second method addresses a stochastic variant of this problem over undirected networks. For both methods, we establish the convergence to the optimal NE and derive new convergence rate statements for the consensus error of the generated iterates. We provide preliminary numerical results on a Nash-Cournot game.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.18883v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuyang Qiu, Farzad Yousefian, Brian Zhang</dc:creator>
    </item>
    <item>
      <title>Backward Linear-Quadratic Mean Field Stochastic Differential Games: A Direct Method</title>
      <link>https://arxiv.org/abs/2411.18891</link>
      <description>arXiv:2411.18891v1 Announce Type: new 
Abstract: This paper studies a linear-quadratic mean-field game of stochastic large-population system, where the large-population system satisfies a class of $N$ weakly coupled linear backward stochastic differential equation. Different from the fixed-point approach commonly used to address large population problems, we first directly apply the maximum principle and decoupling techniques to solve a multi-agent problem, obtaining a centralized optimal strategy. Then, by letting $N$ tend to infinity, we establish a decentralized optimal strategy. Subsequently, we prove that the decentralized optimal strategy constitutes an $\epsilon$-Nash equilibrium for this game. Finally, we provide a numerical example to simulate our results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.18891v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Yu Si, Jingtao Shi</dc:creator>
    </item>
    <item>
      <title>Augmented Lagrange method for optimal control problems of parabolic equation with state constraints</title>
      <link>https://arxiv.org/abs/2411.18958</link>
      <description>arXiv:2411.18958v1 Announce Type: new 
Abstract: The augmented Lagrange method is employed to address the optimal control problem involving pointwise state constraints in parabolic equations. The strong convergence of the primal variables and the weak convergence of the dual variables are rigorously established. The sub-problems arising in the algorithm are solved using the Method of Successive Approximations (MSA), derived from Pontryagin's principle. Numerical experiments are provided to validate the convergence of the proposed algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.18958v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weilong You, Fu Zhang</dc:creator>
    </item>
    <item>
      <title>Distributed Dual Quaternion Extended Kalman Filtering for Spacecraft Pose Estimation</title>
      <link>https://arxiv.org/abs/2411.19033</link>
      <description>arXiv:2411.19033v1 Announce Type: new 
Abstract: In this paper, a distributed dual-quaternion multiplicative extended Kalman filter for the estimation of poses and velocities of individual satellites in a fleet of spacecraft is analyzed. The proposed algorithm uses both absolute and relative pose measurements between neighbouring satellites in a network, allowing each individual satellite to estimate its own pose and that of its neighbours. By utilizing the distributed Kalman consensus filter, a novel sensor and state-estimate fusion procedure is proposed that allows each satellite to improve its own state estimate by sharing data with its neighbours over a communication link. A leader-follower approach, whereby only a subset of the satellites have access to an absolute pose measurement is also examined. In this case, followers rely solely on the information provided by their neighbours, as well as relative pose measurements to those neighbours. The algorithm is tested extensively via numerical simulations, and it is shown that the approach provides a substantial improvement in performance over the scenario in which the satellites do not cooperate. A case study of satellites swarming an asteroid is presented, and the performance in the leader-follower scenario is also analyzed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19033v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mathias Hudoba de Badyn, Jonas Binz, Andrea Iannelli, Roy S. Smith</dc:creator>
    </item>
    <item>
      <title>Stochastic models for online optimization</title>
      <link>https://arxiv.org/abs/2411.19056</link>
      <description>arXiv:2411.19056v1 Announce Type: new 
Abstract: In this paper, we propose control-theoretic methods as tools for the design of online optimization algorithms that are able to address dynamic, noisy, and partially uncertain time-varying quadratic objective functions. Our approach introduces two algorithms specifically tailored for scenarios where the cost function follows a stochastic linear model. The first algorithm is based on a Kalman filter-inspired approach, leveraging state estimation techniques to account for the presence of noise in the evolution of the objective function. The second algorithm applies $\mathcal{H}_\infty$-robust control strategies to enhance performance under uncertainty, particularly in cases in which model parameters are characterized by a high variability.
  Through numerical experiments, we demonstrate that our algorithms offer significant performance advantages over the traditional gradient-based method and also over the optimization strategy proposed in arXiv:2205.13932 based on deterministic models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19056v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Umberto Casti, Sandro Zampieri</dc:creator>
    </item>
    <item>
      <title>An Adaptive Three-Stage Algorithm For Solving Adjustable Min-Max-Regret Problems</title>
      <link>https://arxiv.org/abs/2411.19174</link>
      <description>arXiv:2411.19174v1 Announce Type: new 
Abstract: This work uniquely combines an affine linear decision rule known from adjustable robustness with min-max-regret robustness. By doing so, the advantages of both concepts can be obtained with an adjustable solution that is not over-conservative. This combination results in a bilevel optimization problem. For solving this problem, a three-stage algorithm which uses adaptive discretization of the uncertainty set via two criteria is presented and its convergence is proven. The algorithm is applicable for an example of optimizing a robust pump operation plan for a drinking water supply system facing uncertain demand. The algorithm shows a notable ability to scale, presenting an opportunity to solve larger instances that might challenge existing optimization approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19174v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kerstin Schneider, Helene Krieg, Dimitri Nowak, Karl-Heinz K\"ufer</dc:creator>
    </item>
    <item>
      <title>Advances in Nonmonotone Proximal Gradient Methods merely with Local Lipschitz Assumptions in the Presense of Kurdyka-{\L}ojasiewicz Property: A Study of Average and Max Line Search</title>
      <link>https://arxiv.org/abs/2411.19256</link>
      <description>arXiv:2411.19256v1 Announce Type: new 
Abstract: The proximal gradient method is a standard approach to solve the composite minimization problems where the objective function is the sum of a continuously differentiable function and a lower semicontinuous, extended-valued function. For both monotone and nonmonotone proximal gradient methods, the convergence theory has traditionally replied heavily on the assumption of global Lipschitz continuity. Recent works have shown that the monotone proximal gradient method, even when the local Lipschitz continuity (rather than global) is assumed, converges to the stationarity globally in the presence of Kurdyka-{\L}ojasiewicz Property. However, how to extend these results from monotone proximal gradient method to nonmonotone proximal gradient method (NPG) remains an open question. In this manuscript, we consider two types of NPG: those combined with average line search and max line search, respectively. By partitioning of indices into two subsets, one of them aims to achieve a decrease in the functional sequence, we establish the global convergence and rate-of-convergence (same as the monotone version) results under the KL property, merely requiring the local Lipschitz assumption, and without an a priori knowledge of the iterative sequence being bounded. When our work is almost done, we noticed that [17] presented the analogous results for the NPG with average line search, whose partitioning of index set is totally different with ours. Drawing upon the findings in this manuscript and [17], we confidently conclude that the convergence theory of NPG is independent on the specific partitioning of the index set.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19256v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaoxi Jia, Kai Wang</dc:creator>
    </item>
    <item>
      <title>Online Policy Selection for Inventory Problems</title>
      <link>https://arxiv.org/abs/2411.19269</link>
      <description>arXiv:2411.19269v1 Announce Type: new 
Abstract: We tackle online inventory problems where at each time period the manager makes a replenishment decision based on partial historical information in order to meet demands and minimize costs. To solve such problems, we build upon recent works in online learning and control, use insights from inventory theory and propose a new algorithm called GAPSI. This algorithm follows a new feature-enhanced base-stock policy and deals with the troublesome question of non-differentiability which occurs in inventory problems. Our method is illustrated in the context of a complex and novel inventory system involving multiple products, lost sales, perishability, warehouse-capacity constraints and lead times. Extensive numerical simulations are conducted to demonstrate the good performances of our algorithm on real-world data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19269v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Massil Hihat, Adeline Fermanian</dc:creator>
    </item>
    <item>
      <title>Generalized Polyhedral DC Optimization Problems</title>
      <link>https://arxiv.org/abs/2411.19272</link>
      <description>arXiv:2411.19272v1 Announce Type: new 
Abstract: The problem of minimizing the difference of two lower semicontinuous, proper, convex functions (a DC function) on a nonempty closed convex set in a locally convex Hausdorff topological vector space is studied in this paper. The focus is made on the situations where either the second component of the objective function is a generalized polyhedral convex function or the first component of the objective function is a generalized polyhedral convex function and the constraint set is generalized polyhedral convex. Various results on optimality conditions, the local solution set, the global solution set, and solution algorithms via duality are obtained. Useful illustrative examples are considered.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19272v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vu Thi Huong, Duong Thi Kim Huyen, Nguyen Dong Yen</dc:creator>
    </item>
    <item>
      <title>Order acceptance and scheduling in capacitated job shops</title>
      <link>https://arxiv.org/abs/2411.19363</link>
      <description>arXiv:2411.19363v1 Announce Type: new 
Abstract: We consider a capacitated job shop problem with order acceptance. This research is motivated by the management of a research and development project pipeline for a company in the agricultural industry whose success depends on regularly releasing new and innovative products. The setting requires the consideration of multiple problem characteristics not commonly considered in scheduling research. Each job has a given release and due date and requires the execution of an individual sequence of operations on different machines (job shop). There is a set of machines of fixed capacity, each of which can process multiple operations simultaneously. Given that typically only a small percentage of jobs yield a commercially viable product, the number of potential jobs to schedule is in the order of several thousands. Due to limited capacity, not all jobs can be started. Instead, the objective is to maximize the throughput. Namely, to start as many jobs as possible. We present a Mixed Integer Programming (MIP) formulation of this problem and study how resource capacity and the option to delay jobs can impact research and development throughput. We show that the MIP formulation can prove optimality even for very large instances with less restrictive capacity constraints, while instances with a tight capacity are more challenging to solve.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19363v1</guid>
      <category>math.OC</category>
      <category>cs.DM</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Florian Lin{\ss}, Mike Hewitt, Janis S. Neufeld, Udo Buscher</dc:creator>
    </item>
    <item>
      <title>Feedback Nash equilibria for scalar N-player linear quadratic dynamic games</title>
      <link>https://arxiv.org/abs/2411.19377</link>
      <description>arXiv:2411.19377v1 Announce Type: new 
Abstract: Considering infinite-horizon, discrete-time, linear quadratic, N-player dynamic games with scalar dynamics, a graphical representation of feedback Nash equilibrium solutions is provided. This representation is utilised to derive conditions for the number and properties of different feedback Nash equilibria a game may admit. The results are illustrated via a numerical example.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19377v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Benita Nortmann, Mario Sassano, Thulasi Mylvaganam</dc:creator>
    </item>
    <item>
      <title>A Simple Introduction to the SiMPL Method for Density-Based Topology Optimization</title>
      <link>https://arxiv.org/abs/2411.19421</link>
      <description>arXiv:2411.19421v2 Announce Type: new 
Abstract: We introduce a novel method for solving density-based topology optimization problems: Sigmoidal Mirror descent with a Projected Latent variable (SiMPL). The SiMPL method (pronounced as "the simple method") optimizes a design using only first-order derivative information of the objective function. The bound constraints on the density field are enforced with the help of the (negative) Fermi--Dirac entropy, which is also used to define a non-symmetric distance function called a Bregman divergence on the set of admissible designs. This Bregman divergence leads to a simple update rule that is further simplified with the help of a so-called latent variable. Because the SiMPL method involves discretizing the latent variable, it produces a sequence of pointwise-feasible iterates, even when high-order finite elements are used in the discretization. Numerical experiments demonstrate that the method outperforms other popular first-order optimization algorithms. To outline the general applicability of the technique, we include examples with (self-load) compliance minimization and compliant mechanism optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19421v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dohyun Kim, Boyan Stefanov Lazarov, Thomas M. Surowiec, Brendan Keith</dc:creator>
    </item>
    <item>
      <title>An Optimal Switching Approach for Bird Migration</title>
      <link>https://arxiv.org/abs/2411.19467</link>
      <description>arXiv:2411.19467v1 Announce Type: new 
Abstract: Bird migration is an adaptive behavior ultimately aiming at optimizing survival and reproductive success. We propose an optimal switching model to study bird migration, where birds' migration behaviors are modeled as switching between different stochastic diffusion processes. For individual with perfect information, we formulate the Hamilton-Jacobi Bellman equations which are then solved numerically to obtain the expected payoff and corresponding optimal control. For individuals with partial information, we complement the dynamic programming method with stochastic simulations to study the optimal strategies and the effect of information in such a setting. Finally, we apply the model to address several specific biological questions by characterizing the optimal strategies of birds under different scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19467v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiawei Chu, King-Yeung Lam, Boyu Wang, Tong Wang</dc:creator>
    </item>
    <item>
      <title>A Simulation Framework for Ride-Hailing with Electric Vehicles</title>
      <link>https://arxiv.org/abs/2411.19471</link>
      <description>arXiv:2411.19471v1 Announce Type: new 
Abstract: This research presents a Python-based simulation framework designed to model electric vehicle (EV) on-demand transportation systems, with a focus on optimizing urban fleet operations. Built on a process-driven architecture, the system efficiently simulates EV fleet dynamics, including passenger matching, vehicle dispatching, and charging strategies, while enabling customization to address critical challenges such as charger placement, fleet management, and algorithm performance. We overcome the challenge of high dimensional state-space and non-Markovian system dynamics by executing processes asynchronously using SimPy and updating only the states that are affected by employing object-oriented programming. As a result, our simulation framework is capable of handling peak demand scenarios involving thousands of trips and completing multi-day scenarios in minutes. The modular design enables users to experiment with parameters, test algorithms, and integrate custom datasets, making the tool highly adaptable for diverse urban contexts. By providing a realistic and extensible platform, this adaptable, scalable, and open-source framework advances the optimization of EV fleet operations and offers a valuable resource for decision-makers and city planners navigating the transition to sustainable urban mobility solutions.
  We also present a case study using the NYC taxi dataset evaluating various dispatching algorithms, including closest vehicle dispatch, closest available vehicle dispatch, and power-of-d vehicle dispatch, and exploring charging approaches like continuous and nighttime charging. We propose a novel adaptive power-of-d dispatch policy, which dynamically adjusts to real-time conditions and demonstrates high throughputs when combined with adaptive charging policies that interrupt charging to meet demand during the peak and delay some of the charging to the nighttime.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19471v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chen Zhang, Sushil Varma</dc:creator>
    </item>
    <item>
      <title>Two Timescale EXTRA for Smooth Non-convex Distributed Optimization Problems</title>
      <link>https://arxiv.org/abs/2411.19483</link>
      <description>arXiv:2411.19483v1 Announce Type: new 
Abstract: Distributed non-convex optimization over multi-agent networks is a growing area of interest. In this paper, we propose a decentralized algorithm called Two Time Scale EXTRA (TT-EXTRA), which can be considered as a modified version of the well-known EXTRA algorithm. EXTRA is very general and is closely related to gradient tracking-based algorithms, such as DIGGING, as well as the Primal-Dual Gradient algorithm in distributed settings. It has been established that EXTRA achieves sublinear convergence to an exact minimizer in the convex case and linear convergence in the strongly convex case. However, a convergence analysis of EXTRA for non-convex scenarios remains absent in the current literature. We address this gap by proving that TT-EXTRA converges to a set of consensual first-order stationary points for non-convex distributed optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19483v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Zeyu Peng, Farhad Farokhi, Ye Pu</dc:creator>
    </item>
    <item>
      <title>Optimal management of open-channel raceway ponds for cultivation of algal biomass intended for bioenergy production</title>
      <link>https://arxiv.org/abs/2411.19615</link>
      <description>arXiv:2411.19615v1 Announce Type: new 
Abstract: In this work we present a novel methodology to deal with the optimal performance of raceways (open-channel ponds where the circulating wastewater, during its purification process, is used to grow algae that will be used as a source for the production of bioenergy). The maximization of algal productivity is addressed here within an optimal control framework for partial differential equations. Thus, after introducing a rigorously detailed mathematical formulation of the real-world control problem, we prove the existence of optimal solutions, we propose a numerical algorithm for its computational resolution and, finally, we show some results for the numerical optimization of a realistic case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19615v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>L. J. Alvarez-Vazquez, A. Martinez, M. E. Vazquez-Mendez</dc:creator>
    </item>
    <item>
      <title>Strong convergence of an inertial Tikhonov regularized dynamical system governed by a maximally comonotone operator</title>
      <link>https://arxiv.org/abs/2411.19693</link>
      <description>arXiv:2411.19693v1 Announce Type: new 
Abstract: In a Hilbert framework, we consider an inertial Tikhonov regularized dynamical system governed by a maximally comonotone operator, where the damping coefficient is proportional to the square root of the Tikhonov regularization parameter. Under an appropriate setting of the parameters, we prove the strong convergence of the trajectory of the proposed system towards the minimum norm element of zeros of the underlying maximally comonotone operator. When the Tikhonov regularization parameter reduces to $\frac{1}{t^q}$ with $0&lt;q&lt;1$, we further establish some convergence rate results of the trajectories. Finally, the validity of the proposed dynamical system is demonstrated by a numerical example.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19693v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zeng-Zhen Tan, Rong HU, Ya-Ping Fang</dc:creator>
    </item>
    <item>
      <title>Insensitizing controls of a volume-surface reaction-diffusion equation with dynamic boundary conditions</title>
      <link>https://arxiv.org/abs/2411.19760</link>
      <description>arXiv:2411.19760v1 Announce Type: new 
Abstract: This paper deals with the insensitizing controllability property of the quasilinear parabolic equation with dynamic boundary conditions. This problem can be reformulated as a null controllability problem for a cascade quasilinear system with dynamic boundary conditions. To this end, we approach the problem by first dealing with null controllability in the framework of an inhomogeneous linearized system. Next, we derive new estimates of control and state, allowing us to apply a local inversion theorem to obtain null controllability of the quasilinear system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19760v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Idriss Boutaayamoua, Fouad Et-tahri, Lahcen Maniar</dc:creator>
    </item>
    <item>
      <title>The modulating function method for state estimation and feedback of infinite-dimensional systems</title>
      <link>https://arxiv.org/abs/2411.19771</link>
      <description>arXiv:2411.19771v1 Announce Type: new 
Abstract: We investigate state feedback and observation for infinite-dimensional linear systems, including a variety of partial differential equations with boundary control and observation. We extend the modulating function approach to infinite-dimensional systems. This approach, simply put, involves reconstructing part of the state by convolving with null controls of the adjoint system. We show how this method aids in state reconstruction, and we also examine distributional solutions of the adjoint system, showing their ability to handle unbounded feedback operators. This enables us to use feedback from spatial point evaluations in partial differential equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19771v1</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <category>math.FA</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Folke Friedrich, Johann Reger, Timo Reis</dc:creator>
    </item>
    <item>
      <title>A Frank-Wolfe Algorithm for Oracle-based Robust Optimization</title>
      <link>https://arxiv.org/abs/2411.19848</link>
      <description>arXiv:2411.19848v1 Announce Type: new 
Abstract: We tackle robust optimization problems under objective uncertainty in the oracle model, i.e., when the deterministic problem is solved by an oracle. The oracle-based setup is favorable in many situations, e.g., when a compact formulation of the feasible region is unknown or does not exist. We propose an iterative method based on a Frank-Wolfe type algorithm applied to a smoothed version of the piecewise linear objective function. Our approach bridges several previous efforts from the literature, attains the best known oracle complexity for the problem and performs better than state-of-the-art on high-dimensional problem instances, in particular for larger uncertainty sets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19848v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mathieu Besan\c{c}on, Jannis Kurtz</dc:creator>
    </item>
    <item>
      <title>Contrasting the optimal resource allocation to cybersecurity and cyber insurance using prospect theory versus expected utility theory</title>
      <link>https://arxiv.org/abs/2411.18838</link>
      <description>arXiv:2411.18838v1 Announce Type: cross 
Abstract: Protecting against cyber-threats is vital for every organization and can be done by investing in cybersecurity controls and purchasing cyber insurance. However, these are interlinked since insurance premiums could be reduced by investing more in cybersecurity controls. The expected utility theory and the prospect theory are two alternative theories explaining decision-making under risk and uncertainty, which can inform strategies for optimizing resource allocation. While the former is considered a rational approach, research has shown that most people make decisions consistent with the latter, including on insurance uptakes. We compare and contrast these two approaches to provide important insights into how the two approaches could lead to different optimal allocations resulting in differing risk exposure as well as financial costs. We introduce the concept of a risk curve and show that identifying the nature of the risk curve is a key step in deriving the optimal resource allocation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.18838v1</guid>
      <category>econ.EM</category>
      <category>math.OC</category>
      <category>stat.OT</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Chaitanya Joshi, Jinming Yang, Sergeja Slapnicar, Ryan K L Ko</dc:creator>
    </item>
    <item>
      <title>Neural Operators for Predictor Feedback Control of Nonlinear Delay Systems</title>
      <link>https://arxiv.org/abs/2411.18964</link>
      <description>arXiv:2411.18964v1 Announce Type: cross 
Abstract: Predictor feedback designs are critical for delay-compensating controllers in nonlinear systems. However, these designs are limited in practical applications as predictors cannot be directly implemented, but require numerical approximation schemes. These numerical schemes, typically combining finite difference and successive approximations, become computationally prohibitive when the dynamics of the system are expensive to compute. To alleviate this issue, we propose approximating the predictor mapping via a neural operator. In particular, we introduce a new perspective on predictor designs by recasting the predictor formulation as an operator learning problem. We then prove the existence of an arbitrarily accurate neural operator approximation of the predictor operator. Under the approximated-predictor, we achieve semiglobal practical stability of the closed-loop nonlinear system. The estimate is semiglobal in a unique sense - namely, one can increase the set of initial states as large as desired but this will naturally increase the difficulty of training a neural operator approximation which appears practically in the stability estimate. Furthermore, we emphasize that our result holds not just for neural operators, but any black-box predictor satisfying a universal approximation error bound. From a computational perspective, the advantage of the neural operator approach is clear as it requires training once, offline and then is deployed with very little computational cost in the feedback controller. We conduct experiments controlling a 5-link robotic manipulator with different state-of-the-art neural operator architectures demonstrating speedups on the magnitude of $10^2$ compared to traditional predictor approximation schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.18964v1</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luke Bhan, Peijia Qin, Miroslav Krstic, Yuanyuan Shi</dc:creator>
    </item>
    <item>
      <title>Synergizing Decision Making and Trajectory Planning Using Two-Stage Optimization for Autonomous Vehicles</title>
      <link>https://arxiv.org/abs/2411.18974</link>
      <description>arXiv:2411.18974v1 Announce Type: cross 
Abstract: This paper introduces a local planner that synergizes the decision making and trajectory planning modules towards autonomous driving. The decision making and trajectory planning tasks are jointly formulated as a nonlinear programming problem with an integrated objective function. However, integrating the discrete decision variables into the continuous trajectory optimization leads to a mixed-integer programming (MIP) problem with inherent nonlinearity and nonconvexity. To address the challenge in solving the problem, the original problem is decomposed into two sub-stages, and a two-stage optimization (TSO) based approach is presented to ensure the coherence in outcomes for the two stages. The optimization problem in the first stage determines the optimal decision sequence that acts as an informed initialization. With the outputs from the first stage, the second stage necessitates the use of a high-fidelity vehicle model and strict enforcement of the collision avoidance constraints as part of the trajectory planning problem. We evaluate the effectiveness of our proposed planner across diverse multi-lane scenarios. The results demonstrate that the proposed planner simultaneously generates a sequence of optimal decisions and the corresponding trajectory that significantly improves driving performance in terms of driving safety and traveling efficiency as compared to alternative methods. Additionally, we implement the closed-loop simulation in CARLA, and the results showcase the effectiveness of the proposed planner to adapt to changing driving situations with high computational efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.18974v1</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenru Liu, Haichao Liu, Lei Zheng, Zhenmin Huang, Jun Ma</dc:creator>
    </item>
    <item>
      <title>Convex Regularization and Convergence of Policy Gradient Flows under Safety Constraints</title>
      <link>https://arxiv.org/abs/2411.19193</link>
      <description>arXiv:2411.19193v1 Announce Type: cross 
Abstract: This paper studies reinforcement learning (RL) in infinite-horizon dynamic decision processes with almost-sure safety constraints. Such safety-constrained decision processes are central to applications in autonomous systems, finance, and resource management, where policies must satisfy strict, state-dependent constraints. We consider a doubly-regularized RL framework that combines reward and parameter regularization to address these constraints within continuous state-action spaces. Specifically, we formulate the problem as a convex regularized objective with parametrized policies in the mean-field regime. Our approach leverages recent developments in mean-field theory and Wasserstein gradient flows to model policies as elements of an infinite-dimensional statistical manifold, with policy updates evolving via gradient flows on the space of parameter distributions. Our main contributions include establishing solvability conditions for safety-constrained problems, defining smooth and bounded approximations that facilitate gradient flows, and demonstrating exponential convergence towards global solutions under sufficient regularization. We provide general conditions on regularization functions, encompassing standard entropy regularization as a special case. The results also enable a particle method implementation for practical RL applications. The theoretical insights and convergence guarantees presented here offer a robust framework for safe RL in complex, high-dimensional decision-making problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19193v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Pekka Malo, Lauri Viitasaari, Antti Suominen, Eeva Vilkkumaa, Olli Tahvonen</dc:creator>
    </item>
    <item>
      <title>Controlling Participation in Federated Learning with Feedback</title>
      <link>https://arxiv.org/abs/2411.19242</link>
      <description>arXiv:2411.19242v1 Announce Type: cross 
Abstract: We address the problem of client participation in federated learning, where traditional methods typically rely on a random selection of a small subset of clients for each training round. In contrast, we propose FedBack, a deterministic approach that leverages control-theoretic principles to manage client participation in ADMM-based federated learning. FedBack models client participation as a discrete-time dynamical system and employs an integral feedback controller to adjust each client's participation rate individually, based on the client's optimization dynamics. We provide global convergence guarantees for our approach by building on the recent federated learning research. Numerical experiments on federated image classification demonstrate that FedBack achieves up to 50\% improvement in communication and computational efficiency over algorithms that rely on a random selection of clients.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19242v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Michael Cummins, Guner Dilsad Er, Michael Muehlebach</dc:creator>
    </item>
    <item>
      <title>L4acados: Learning-based models for acados, applied to Gaussian process-based predictive control</title>
      <link>https://arxiv.org/abs/2411.19258</link>
      <description>arXiv:2411.19258v1 Announce Type: cross 
Abstract: Incorporating learning-based models, such as Gaussian processes (GPs), into model predictive control (MPC) strategies can significantly improve control performance and online adaptation capabilities for real-world applications. Still, despite recent advances in numerical optimization and real-time GP inference, its widespread application is limited by the lack of an efficient and modular open-source implementation. This work aims at filling this gap by providing an efficient implementation of zero-order Gaussian process-based MPC in acados, as well as L4acados, a general framework for incorporating non-CasADi (learning-based) residual models in acados. By providing the required sensitivities via a user-defined Python module, L4acados enables the implementation of MPC controllers with learning-based residual models in acados, while supporting custom Jacobian approximations, as well as parallelization of sensitivity computations when preparing the quadratic subproblems. The computational efficiency of L4acados is benchmarked against available software using a neural network-based control example. Last, it is used demonstrate the performance of the zero-order GP-MPC method applied to two hardware examples: autonomous miniature racing, as well as motion control of a full-scale autonomous vehicle for an ISO lane change maneuver.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19258v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amon Lahr, Joshua N\"af, Kim P. Wabersich, Jonathan Frey, Pascal Siehl, Andrea Carron, Moritz Diehl, Melanie N. Zeilinger</dc:creator>
    </item>
    <item>
      <title>Fast Switching in Mixed-Integer Model Predictive Control</title>
      <link>https://arxiv.org/abs/2411.19300</link>
      <description>arXiv:2411.19300v1 Announce Type: cross 
Abstract: We derive stability results for finite control set and mixed-integer model predictive control and propose a unified theoretical framework. The presentation rests upon the inherent robustness properties of common model predictive control with stabilizing terminal conditions and techniques for solving mixed-integer optimal control problems by continuous optimization. Partial outer convexification and binary relaxation transform mixed-integer problems into common optimal control problems. We derive nominal asymptotic stability for the resulting relaxed system formulation and implement sum-up rounding to restore efficiently integer feasibility. If fast control switching is technically possible and inexpensive, we can approximate the relaxed system behavior in the state space arbitrarily close. We integrate input perturbed model predictive control with practical asymptotic stability. Numerical experiments support our theoretical findings and illustrate practical relevance of fast and systematic control switching.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19300v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Artemi Makarow, Christian Kirches</dc:creator>
    </item>
    <item>
      <title>Bilevel Programming for Pebbling Numbers of Lemke Graph Products</title>
      <link>https://arxiv.org/abs/2411.19314</link>
      <description>arXiv:2411.19314v1 Announce Type: cross 
Abstract: Given a configuration of indistinguishable pebbles on the vertices of a graph, a pebbling move consists of removing two pebbles from one vertex and placing one pebble on an adjacent vertex. The pebbling number of a graph is the least integer such that any configuration with that many pebbles and any target vertex, some sequence of pebbling moves can place a pebble on the target. Graham's conjecture asserts that the pebbling number of the cartesian product of two graphs is at most the product of the two graphs' pebbling numbers. Products of so-called Lemke graphs are widely thought to be the most likely counterexamples to Graham's conjecture, provided one exists.
  In this paper, we introduce a novel framework for computing pebbling numbers using bilevel optimization. We use this approach to algorithmically show that the pebbling numbers of all products of 8-vertex Lemke graphs are consistent with Graham's conjecture, with the added assumption that pebbles can only be placed on a set of at most four vertices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19314v1</guid>
      <category>math.CO</category>
      <category>math.OC</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jonad Pulaj, Kenan Wood, Carl Yerger</dc:creator>
    </item>
    <item>
      <title>Singular mean-field backward stochastic Volterra integral equations in infinite dimensional spaces</title>
      <link>https://arxiv.org/abs/2411.19433</link>
      <description>arXiv:2411.19433v1 Announce Type: cross 
Abstract: This paper investigates the well-posedness of singular mean-field backward stochastic Volterra integral equations (MF-BSVIEs) in infinite-dimensional spaces. We consider the equation:
  \[ X(t) = \Psi(t) + \int_t^b F\big(t, s, X(s), Z(t, s), Z(s, t), \mathbb{E}[X(s)], \mathbb{E}[Z(t, s)], \mathbb{E}[Z(s, t)]\big) ds - \int_t^b Z(t, s) dB_s, \]
  where the focus lies on establishing the existence and uniqueness of adapted M-solutions under appropriate conditions. A key contribution of this work is the development of essential lemmas that provide a rigorous foundation for analyzing the well-posedness of these equations. In addition, we extend our analysis to singular mean-field forward stochastic Volterra integral equations (MF-FSVIEs) in infinite-dimensional spaces, demonstrating their solvability and unique adapted solutions. Finally, we strengthen our theoretical results by applying them to derive stochastic maximum principles, showcasing the practical relevance of the proposed framework. These findings contribute to the growing body of research on mean-field stochastic equations and their applications in control theory and mathematical finance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19433v1</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Javad A. Asadzade, Nazim I. Mahmudov</dc:creator>
    </item>
    <item>
      <title>Lyapunov based dynamic controller designs for reach-and-avoid problems</title>
      <link>https://arxiv.org/abs/2411.19607</link>
      <description>arXiv:2411.19607v1 Announce Type: cross 
Abstract: Safe obstacle avoidance and target set stabilization for nonlinear systems using reactive feedback control is under consideration. Based only on local information and by considering virtual dynamics, a safe path is generated online. The control law for the virtual dynamics is combined with a feedback controller for the dynamics of interest, where Lyapunov arguments and forward invariance are used to ensure that the state of the system remains in a vicinity of the path. To allow for discrete decisions in the avoidance controller design, the closed-loop dynamics are formulated using the hybrid systems framework. The results are illustrated by a numerical example for unicycle dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19607v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lukas Lanza, Philipp Braun</dc:creator>
    </item>
    <item>
      <title>Ergodic optimal liquidations in DeFi</title>
      <link>https://arxiv.org/abs/2411.19637</link>
      <description>arXiv:2411.19637v1 Announce Type: cross 
Abstract: We address the liquidation problem arising from the credit risk management in decentralised finance (DeFi) by formulating it as an ergodic optimal control problem. In decentralised derivatives exchanges, liquidation is triggered whenever the parties fail to maintain sufficient collateral for their open positions. Consequently, effectively managing and liquidating disposal of positions accrued through liquidations is a critical concern for decentralised derivatives exchanges. By simplifying the model (linear temporary and permanent price impacts, simplified cash balance dynamics), we derive the closed-form solutions for the optimal liquidation strategies, which balance immediate executions with the temporary and permanent price impacts, and the optimal long-term average reward. Numerical simulations further highlight the effectiveness of the proposed optimal strategy and demonstrate that the simplified model closely approximates the original market environment. Finally, we provide the method for calibrating the parameters in the model from the available data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19637v1</guid>
      <category>q-fin.TR</category>
      <category>math.OC</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jialun Cao, David \v{S}i\v{s}ka</dc:creator>
    </item>
    <item>
      <title>A rounding and clustering-based exact algorithm for the p-center problem</title>
      <link>https://arxiv.org/abs/2411.19724</link>
      <description>arXiv:2411.19724v1 Announce Type: cross 
Abstract: The p-center problem consists in selecting p facilities from a set of possible sites and allocating a set of clients to them in such a way that the maximum distance between a client and the facility to which it is allocated is minimized. This paper proposes a new scalable exact solution algorithm based on client clustering and an iterative distance rounding procedure. The client clustering enables to initialize and update a subset of clients for which the p-center problem is iteratively solved. The rounding drastically reduces the number of distinct distances considered at each iteration. Our algorithm is tested on 396 benchmark instances with up to 1.9 million clients and facilities. We outperform the two state-of-the-art exact methods considered when p is not very small (i.e., p &gt; 5).</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19724v1</guid>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zacharie Ales, Cristian Duran-Matelunaa, Sourour Elloumi</dc:creator>
    </item>
    <item>
      <title>Optimality of Gerver's Sofa</title>
      <link>https://arxiv.org/abs/2411.19826</link>
      <description>arXiv:2411.19826v1 Announce Type: cross 
Abstract: We resolve the moving sofa problem by showing that Gerver's construction with 18 curve sections attains the maximum area $2.2195\cdots$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19826v1</guid>
      <category>math.MG</category>
      <category>math.CO</category>
      <category>math.OC</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jineon Baek</dc:creator>
    </item>
    <item>
      <title>A Mathematical Programming Approach to Optimal Classification Forests</title>
      <link>https://arxiv.org/abs/2211.10502</link>
      <description>arXiv:2211.10502v3 Announce Type: replace 
Abstract: This paper introduces Weighted Optimal Classification Forests (WOCFs), a new family of classifiers that takes advantage of an optimal ensemble of decision trees to derive accurate and interpretable classifiers. We propose a novel mathematical optimization-based methodology which simultaneously constructs a given number of trees, each of them providing a predicted class for the observations in the feature space. The classification rule is derived by assigning to each observation its most frequently predicted class among the trees. We provide a mixed integer linear programming formulation (MIP) for the problem and several novel MIP strengthening / scaling techniques. We report the results of our computational experiments, from which we conclude that our method has equal or superior performance compared with state-of-the-art tree-based classification methods for small to medium-sized instances. We also present three real-world case studies showing that our methodology has very interesting implications in terms of interpretability. Overall, WOCFs complement existing methods such as CART, Optimal Classification Trees, Random Forests and XGBoost. In addition to its Pareto improvement on accuracy and interpretability, we also see unique properties emerging in terms of different trees focusing on different feature variables. This provides nontrivial improvement in interpretability and usability of the trained model in terms of counterfactual explanation. Thus, despite the apparent computational challenge of WOCFs that limit the size of the problems that can be efficiently solved with current MIP, this is an important research direction that can lead to qualitatively different insights for researchers and complement the toolbox of practitioners for high stakes problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.10502v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>V\'ictor Blanco, Alberto Jap\'on, Justo Puerto, Peter Zhang</dc:creator>
    </item>
    <item>
      <title>Global convergence of the gradient method for functions definable in o-minimal structures</title>
      <link>https://arxiv.org/abs/2303.03534</link>
      <description>arXiv:2303.03534v5 Announce Type: replace 
Abstract: We consider the gradient method with variable step size for minimizing functions that are definable in o-minimal structures on the real field and differentiable with locally Lipschitz gradients. We prove that global convergence holds if continuous gradient trajectories are bounded, with the minimum gradient norm vanishing at the rate $o(1/k)$ if the step sizes are greater than a positive constant. If additionally the gradient is continuously differentiable, all saddle points are strict, and the step sizes are constant, then convergence to a local minimum holds almost surely over any bounded set of initial points.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.03534v5</guid>
      <category>math.OC</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s10107-023-01937-5</arxiv:DOI>
      <arxiv:journal_reference>Mathematical Programming 2023</arxiv:journal_reference>
      <dc:creator>C\'edric Josz</dc:creator>
    </item>
    <item>
      <title>An Augmented Lagrangian Approach to Composite Problems with a Random Linear Operator</title>
      <link>https://arxiv.org/abs/2305.01055</link>
      <description>arXiv:2305.01055v2 Announce Type: replace 
Abstract: We consider the minimization of a sum of a smooth function with a nonsmooth composite function, where the composition is applied on a random linear mapping. This random composite model encompasses many problems, and can especially capture realistic scenarios in which the data is sampled during the optimization process. We propose and analyze a method that combines the classical Augmented Lagrangian framework with a sampling mechanism and adaptive update of the penalty parameter. We show that every accumulation point of the sequence produced by our algorithm is almost surely a critical point.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.01055v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dan Greenstein, Nadav Hallak</dc:creator>
    </item>
    <item>
      <title>Regularized methods via cubic model subspace minimization for nonconvex optimization</title>
      <link>https://arxiv.org/abs/2306.14290</link>
      <description>arXiv:2306.14290v4 Announce Type: replace 
Abstract: Adaptive cubic regularization methods for solving nonconvex problems need the efficient computation of the trial step, involving the minimization of a cubic model. We propose a new approach in which this model is minimized in a low dimensional subspace that, in contrast to classic approaches, is reused for a number of iterations. Whenever the trial step produced by the low-dimensional minimization process is unsatisfactory, we employ a regularized Newton step whose regularization parameter is a by-product of the model minimization over the low-dimensional subspace. We show that the worst-case complexity of classic cubic regularized methods is preserved, despite the possible regularized Newton steps. We focus on the large class of problems for which (sparse) direct linear system solvers are available and provide several experimental results showing the very large gains of our new approach when compared to standard implementations of adaptive cubic regularization methods based on direct linear solvers. Our first choice as projection space for the low-dimensional model minimization is the polynomial Krylov subspace; nonetheless, we also explore the use of rational Krylov subspaces in case where the polynomial ones lead to less competitive numerical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.14290v4</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stefania Bellavia, Davide Palitta, Margherita Porcelli, Valeria Simoncini</dc:creator>
    </item>
    <item>
      <title>Linear-Quadratic Mean Field Control with Non-Convex Data</title>
      <link>https://arxiv.org/abs/2311.18292</link>
      <description>arXiv:2311.18292v2 Announce Type: replace 
Abstract: In this manuscript, we study a class of linear-quadratic (LQ) mean field control problems with a common noise and their corresponding $N$-particle systems. The mean field control problems considered are not standard LQ mean field control problems in the sense that their dependence on the mean field terms can be non-linear and non-convex. Therefore, all the existing methods to deal with LQ mean field control problems fail. The key idea to solve our LQ mean field control problem is to utilize the common noise. We first prove the global well-posedness of the corresponding Hamilton-Jacobi equations via the non-degeneracy of the common noise. In contrast to the LQ mean field games master equations, the Hamilton-Jacobi equations for the LQ mean field control problems can not be reduced to finite-dimensional PDEs. We then globally solve the Hamilton-Jacobi equations for $N$-particle systems. As byproducts, we derive the optimal quantitative convergence results from the $N$-particle systems to the mean field control problem and the propagation of chaos property for the related optimal trajectories. This paper extends the results in [{\sc M. Li, C. Mou, Z. Wu and C. Zhou}, \emph{Trans. Amer. Math. Soc.}, 376(06) (2023), pp.~4105--4143] to the LQ mean field control problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.18292v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mengzhen Li, Chenchen Mou, Zhen Wu, Chao Zhou</dc:creator>
    </item>
    <item>
      <title>BP-MPC: Optimizing the Closed-Loop Performance of MPC using BackPropagation</title>
      <link>https://arxiv.org/abs/2312.15521</link>
      <description>arXiv:2312.15521v3 Announce Type: replace 
Abstract: Model predictive control (MPC) is pervasive in research and industry. However, designing the cost function and the constraints of the MPC to maximize closed-loop performance remains an open problem. To achieve optimal tuning, we propose a backpropagation scheme that solves a policy optimization problem with nonlinear system dynamics and MPC policies. We enforce the system dynamics using linearization and allow the MPC problem to contain elements that depend on the current system state and on past MPC solutions. Moreover, we propose a simple extension that can deal with losses of feasibility. Our approach, unlike other methods in the literature, enjoys convergence guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.15521v3</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Riccardo Zuliani, Efe C. Balta, John Lygeros</dc:creator>
    </item>
    <item>
      <title>Complexity of linearized quadratic penalty for optimization with nonlinear equality constraints</title>
      <link>https://arxiv.org/abs/2402.15639</link>
      <description>arXiv:2402.15639v2 Announce Type: replace 
Abstract: In this paper we consider a nonconvex optimization problem with nonlinear equality constraints. We assume that both, the objective function and the functional constraints, are locally smooth. For solving this problem, we propose a linearized quadratic penalty method, i.e., we linearize the objective function and the functional constraints in the penalty formulation at the current iterate and add a quadratic regularization, thus yielding a subproblem that is easy to solve, and whose solution is the next iterate. Under a new adaptive regularization parameter choice, we provide convergence guarantees for the iterates of this method to an $\epsilon$ first-order optimal solution in $\mathcal{O}({\epsilon^{-2.5}})$ iterations. Finally, we show that when the problem data satisfy Kurdyka-Lojasiewicz property, e.g., are semialgebraic, the whole sequence generated by the proposed algorithm converges and we derive improved local convergence rates depending on the KL parameter. We validate the theory and the performance of the proposed algorithm by numerically comparing it with some existing methods from the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.15639v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/s10898-024-01456-3,</arxiv:DOI>
      <arxiv:journal_reference>Journal of Global Optimization, 2024</arxiv:journal_reference>
      <dc:creator>Lahcen El Bourkhissi, Ion Necoara</dc:creator>
    </item>
    <item>
      <title>On the Convergence Rates of Set Membership Estimation of Linear Systems with Disturbances Bounded by General Convex Sets</title>
      <link>https://arxiv.org/abs/2406.00574</link>
      <description>arXiv:2406.00574v2 Announce Type: replace 
Abstract: This paper studies the uncertainty set estimation of system parameters of linear dynamical systems with bounded disturbances, which is motivated by robust (adaptive) constrained control. Departing from the confidence bounds of least square estimation from the machine-learning literature, this paper focuses on a method commonly used in (robust constrained) control literature: set membership estimation (SME). SME tends to enjoy better empirical performance than LSE's confidence bounds when the system disturbances are bounded. However, the theoretical guarantees of SME are not fully addressed even for i.i.d. bounded disturbances. In the literature, SME's convergence has been proved for general convex supports of the disturbances, but SME's convergence rate assumes a special type of disturbance support: $ \ell_\infty $ ball. The main contribution of this paper is relaxing the assumption on the disturbance support and establishing the convergence rates of SME for general convex supports, which closes the gap on the applicability of the convergence and convergence rates results. Numerical experiments on SME and LSE's confidence bounds are also provided for different disturbance supports.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00574v2</guid>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haonan Xu, Yingying Li</dc:creator>
    </item>
    <item>
      <title>A Stochastic Objective-Function-Free Adaptive Regularization Method with Optimal Complexity</title>
      <link>https://arxiv.org/abs/2407.08018</link>
      <description>arXiv:2407.08018v3 Announce Type: replace 
Abstract: A fully stochastic second-order adaptive-regularization method for unconstrained nonconvex optimization is presented which never computes the objective-function value, but yet achieves the optimal $\mathcal{O}(\epsilon^{-3/2})$ complexity bound for finding first-order critical points. The method is noise-tolerant and the inexactness conditions required for convergence depend on the history of past steps. Applications to cases where derivative evaluation is inexact and to minimization of finite sums by sampling are discussed. Numerical experiments on large binary classification problems illustrate the potential of the new method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.08018v3</guid>
      <category>math.OC</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Serge Gratton, Sadok Jerad, Philippe L. Toint</dc:creator>
    </item>
    <item>
      <title>Computation of Generalized Derivatives for Abs-Smooth Functions by Backward Mode Algorithmic Differentiation and Implications to Deep Learning</title>
      <link>https://arxiv.org/abs/2407.09639</link>
      <description>arXiv:2407.09639v3 Announce Type: replace 
Abstract: Algorithmic differentiation (AD) tools allow to obtain gradient information of a continuously differentiable objective function in a computationally cheap way using the so-called backward mode. It is common practice to use the same tools even in the absence of differentiability, although the resulting vectors may not be generalized gradients in the sense of Clarke. The paper at hand focuses on objectives in which the non-differentiability arises solely from the evaluation of the absolute value function. In that case, an algebraic condition based on the evaluation procedure of the objective is identified, that guarantees that Clarke gradients are correctly computed without requiring any modifications of the AD tool in question. The analysis allows to prove that any standard AD tool is adequate to drive a stochastic generalized gradient descent method for training a dense neural network with ReLU activations. The same is true for generalized batch gradients or the full generalized gradient, provided that the AD tool makes a deterministic and agnostic choice for the derivative information of the absolute value at 0.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09639v3</guid>
      <category>math.OC</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lukas Baumg\"artner, Franz Bethke</dc:creator>
    </item>
    <item>
      <title>Viability for locally monotone evolution inclusions and lower semicontinuous solutions of Hamilton-Jacobi-Bellman equations in infinite dimensions</title>
      <link>https://arxiv.org/abs/2408.02915</link>
      <description>arXiv:2408.02915v2 Announce Type: replace 
Abstract: We establish necessary and sufficient conditions for viability of evolution inclusions with locally monotone operators in the sense of Liu and R\"ockner [J. Funct. Anal., 259 (2010), pp. 2902-2922]. This allows us to prove wellposedness of lower semicontinuous solutions of Hamilton-Jacobi-Bellman equations associated to the optimal control of evolution inclusions. Thereby, we generalize results in Bayraktar and Keller [J. Funct. Anal., 275 (2018), pp. 2096-2161] on Hamilton-Jacobi equations in infinite dimensions with monotone operators in several ways. First, we permit locally monotone operators. This extends the applicability of our theory to a wider class of equations such as Burgers' equations, reaction-diffusion equations, and 2D Navier-Stokes equations. Second, our results apply to optimal control problems with state constraints. Third, we have uniqueness of viscosity solutions. Our results on viability and lower semicontinuous solutions are new even in the case of monotone operators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02915v2</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jichao Jiang, Christian Keller</dc:creator>
    </item>
    <item>
      <title>Constant Payoff Property in Zero-Sum Stochastic Games with a Finite Horizon</title>
      <link>https://arxiv.org/abs/2409.05683</link>
      <description>arXiv:2409.05683v2 Announce Type: replace 
Abstract: This paper examines finite zero-sum stochastic games and demonstrates that when the game's duration is sufficiently long, there exists a pair of approximately optimal strategies such that the expected average payoff at any point in the game remains close to the value. This property, known as the \textit{constant payoff property}, was previously established only for absorbing games and discounted stochastic games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.05683v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas Ragel, Bruno Ziliotto</dc:creator>
    </item>
    <item>
      <title>Optimizing Flexibility in Power Systems by Maximizing the Region of Manageable Uncertainties</title>
      <link>https://arxiv.org/abs/2411.18178</link>
      <description>arXiv:2411.18178v2 Announce Type: replace 
Abstract: Motivated by the increasing need to hedge against load and generation uncertainty in the operation of power grids, we propose flexibility maximization during operation.
  We consider flexibility explicitly as the amount of uncertainty that can be handled while still ensuring nominal grid operation in the worst-case. We apply the proposed flexibility optimization in the context of a DC flow approximation. By using a corresponding parameterization, we can find the maximal range of uncertainty and a range for the manageable power transfer between two parts of a network subject to uncertainty.
  We formulate the corresponding optimization problem as an (existence-constrained) semi-infinite optimization problem and specialize an existing algorithm for its solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.18178v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aron Zingler, Stephane Fliscounakis, Patrick Panciatici, Alexander Mitsos</dc:creator>
    </item>
    <item>
      <title>Adan: Adaptive Nesterov Momentum Algorithm for Faster Optimizing Deep Models</title>
      <link>https://arxiv.org/abs/2208.06677</link>
      <description>arXiv:2208.06677v5 Announce Type: replace-cross 
Abstract: In deep learning, different kinds of deep networks typically need different optimizers, which have to be chosen after multiple trials, making the training process inefficient. To relieve this issue and consistently improve the model training speed across deep networks, we propose the ADAptive Nesterov momentum algorithm, Adan for short. Adan first reformulates the vanilla Nesterov acceleration to develop a new Nesterov momentum estimation (NME) method, which avoids the extra overhead of computing gradient at the extrapolation point. Then, Adan adopts NME to estimate the gradient's first- and second-order moments in adaptive gradient algorithms for convergence acceleration. Besides, we prove that Adan finds an $\epsilon$-approximate first-order stationary point within $\mathcal{O}(\epsilon^{-3.5})$ stochastic gradient complexity on the non-convex stochastic problems (e.g., deep learning problems), matching the best-known lower bound. Extensive experimental results show that Adan consistently surpasses the corresponding SoTA optimizers on vision, language, and RL tasks and sets new SoTAs for many popular networks and frameworks, e.g., ResNet, ConvNext, ViT, Swin, MAE, DETR, GPT-2, Transformer-XL, and BERT. More surprisingly, Adan can use half of the training cost (epochs) of SoTA optimizers to achieve higher or comparable performance on ViT, GPT-2, MAE, etc., and also shows great tolerance to a large range of minibatch size, e.g., from 1k to 32k. Code is released at https://github.com/sail-sg/Adan, and has been used in multiple popular deep learning frameworks or projects.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.06677v5</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xingyu Xie, Pan Zhou, Huan Li, Zhouchen Lin, Shuicheng Yan</dc:creator>
    </item>
    <item>
      <title>On Rank-Monotone Graph Operations and Minimal Obstruction Graphs for the Lov\'{a}sz--Schrijver SDP Hierarchy</title>
      <link>https://arxiv.org/abs/2401.01476</link>
      <description>arXiv:2401.01476v3 Announce Type: replace-cross 
Abstract: We study the lift-and-project rank of the stable set polytopes of graphs with respect to the Lov\'{a}sz--Schrijver SDP operator $\text{LS}_+$, with a particular focus on finding and characterizing the smallest graphs with a given $\text{LS}_+$-rank (the needed number of iterations of the $\text{LS}_+$ operator on the fractional stable set polytope to compute the stable set polytope). We introduce a generalized vertex-stretching operation that appears to be promising in generating $\text{LS}_+$-minimal graphs and study its properties. We also provide several new $\text{LS}_+$-minimal graphs, most notably the first known instances of $12$-vertex graphs with $\text{LS}_+$-rank $4$, which provides the first advance in this direction since Escalante, Montelar, and Nasini's discovery of a $9$-vertex graph with $\text{LS}_+$-rank $3$ in 2006.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.01476v3</guid>
      <category>cs.DM</category>
      <category>math.CO</category>
      <category>math.OC</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yu Hin Au, Levent Tun\c{c}el</dc:creator>
    </item>
    <item>
      <title>Moving-Horizon Estimators for Hyperbolic and Parabolic PDEs in 1-D</title>
      <link>https://arxiv.org/abs/2401.02516</link>
      <description>arXiv:2401.02516v2 Announce Type: replace-cross 
Abstract: Observers for PDEs are themselves PDEs. Therefore, producing real time estimates with such observers is computationally burdensome. For both finite-dimensional and ODE systems, moving-horizon estimators (MHE) are operators whose output is the state estimate, while their inputs are the initial state estimate at the beginning of the horizon as well as the measured output and input signals over the moving time horizon. In this paper we introduce MHEs for PDEs which remove the need for a numerical solution of an observer PDE in real time. We accomplish this using the PDE backstepping method which, for certain classes of both hyperbolic and parabolic PDEs, produces moving-horizon state estimates explicitly. Precisely, to explicitly produce the state estimates, we employ a backstepping transformation of a hard-to-solve observer PDE into a target observer PDE, which is explicitly solvable. The MHEs we propose are not new observer designs but simply the explicit MHE realizations, over a moving horizon of arbitrary length, of the existing backstepping observers. Our PDE MHEs lack the optimality of the MHEs that arose as duals of MPC, but they are given explicitly, even for PDEs. In the paper we provide explicit formulae for MHEs for both hyperbolic and parabolic PDEs, as well as simulation results that illustrate theoretically guaranteed convergence of the MHEs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.02516v2</guid>
      <category>eess.SY</category>
      <category>cs.AI</category>
      <category>cs.SY</category>
      <category>math.AP</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luke Bhan, Yuanyuan Shi, Iasson Karafyllis, Miroslav Krstic, James B. Rawlings</dc:creator>
    </item>
    <item>
      <title>Randomized Algorithms for Symmetric Nonnegative Matrix Factorization</title>
      <link>https://arxiv.org/abs/2402.08134</link>
      <description>arXiv:2402.08134v2 Announce Type: replace-cross 
Abstract: Symmetric Nonnegative Matrix Factorization (SymNMF) is a technique in data analysis and machine learning that approximates a symmetric matrix with a product of a nonnegative, low-rank matrix and its transpose. To design faster and more scalable algorithms for SymNMF we develop two randomized algorithms for its computation. The first algorithm uses randomized matrix sketching to compute an initial low-rank approximation to the input matrix and proceeds to rapidly compute a SymNMF of the approximation. The second algorithm uses randomized leverage score sampling to approximately solve constrained least squares problems. Many successful methods for SymNMF rely on (approximately) solving sequences of constrained least squares problems. We prove theoretically that leverage score sampling can approximately solve nonnegative least squares problems to a chosen accuracy with high probability. Additionally, we prove sampling complexity results for previously proposed hybrid sampling techniques which deterministically include high leverage score rows. This hybrid scheme is crucial for obtaining speeds ups in practice. Finally we demonstrate that both methods work well in practice by applying them to graph clustering tasks on large real world data sets. These experiments show that our methods approximately maintain solution quality and achieve significant speed ups for both large dense and large sparse problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.08134v2</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Koby Hayashi, Sinan G. Aksoy, Grey Ballard, Haesun Park</dc:creator>
    </item>
    <item>
      <title>Enhancing Privacy in Federated Learning through Local Training</title>
      <link>https://arxiv.org/abs/2403.17572</link>
      <description>arXiv:2403.17572v2 Announce Type: replace-cross 
Abstract: In this paper we propose the federated learning algorithm Fed-PLT to overcome the challenges of (i) expensive communications and (ii) privacy preservation. We address (i) by allowing for both partial participation and local training, which significantly reduce the number of communication rounds between the central coordinator and computing agents. The algorithm matches the state of the art in the sense that the use of local training demonstrably does not impact accuracy. Additionally, agents have the flexibility to choose from various local training solvers, such as (stochastic) gradient descent and accelerated gradient descent. Further, we investigate how employing local training can enhance privacy, addressing point (ii). In particular, we derive differential privacy bounds and highlight their dependence on the number of local training epochs. We assess the effectiveness of the proposed algorithm by comparing it to alternative techniques, considering both theoretical analysis and numerical results from a classification task.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.17572v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicola Bastianello, Changxin Liu, Karl H. Johansson</dc:creator>
    </item>
    <item>
      <title>A Pontryagin Perspective on Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2405.18100</link>
      <description>arXiv:2405.18100v2 Announce Type: replace-cross 
Abstract: Reinforcement learning has traditionally focused on learning state-dependent policies to solve optimal control problems in a closed-loop fashion. In this work, we introduce the paradigm of open-loop reinforcement learning where a fixed action sequence is learned instead. We present three new algorithms: one robust model-based method and two sample-efficient model-free methods. Rather than basing our algorithms on Bellman's equation from dynamic programming, our work builds on Pontryagin's principle from the theory of open-loop optimal control. We provide convergence guarantees and evaluate all methods empirically on a pendulum swing-up task, as well as on two high-dimensional MuJoCo tasks, significantly outperforming existing baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.18100v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Onno Eberhard, Claire Vernade, Michael Muehlebach</dc:creator>
    </item>
    <item>
      <title>LoCo: Low-Bit Communication Adaptor for Large-scale Model Training</title>
      <link>https://arxiv.org/abs/2407.04480</link>
      <description>arXiv:2407.04480v2 Announce Type: replace-cross 
Abstract: To efficiently train large-scale models, low-bit gradient communication compresses full-precision gradients on local GPU nodes into low-precision ones for higher gradient synchronization efficiency among GPU nodes. However, it often degrades training quality due to compression information loss. To address this, we propose the Low-bit Communication Adaptor (LoCo), which compensates gradients on local GPU nodes before compression, ensuring efficient synchronization without compromising training quality. Specifically, LoCo designs a moving average of historical compensation errors to stably estimate concurrent compression error and then adopts it to compensate for the concurrent gradient compression, yielding a less lossless compression. This mechanism allows it to be compatible with general optimizers like Adam and sharding strategies like FSDP. Theoretical analysis shows that integrating LoCo into full-precision optimizers like Adam and SGD does not impair their convergence speed on nonconvex problems. Experimental results show that across large-scale model training frameworks like Megatron-LM and PyTorch's FSDP, LoCo significantly improves communication efficiency, e.g., improving Adam's training speed by 14% to 40% without performance degradation on large language models like LLAMAs and MoE.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04480v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xingyu Xie, Zhijie Lin, Kim-Chuan Toh, Pan Zhou</dc:creator>
    </item>
    <item>
      <title>Beyond adaptive gradient: Fast-Controlled Minibatch Algorithm for large-scale optimization</title>
      <link>https://arxiv.org/abs/2411.15795</link>
      <description>arXiv:2411.15795v2 Announce Type: replace-cross 
Abstract: Adaptive gradient methods have been increasingly adopted by deep learning community due to their fast convergence and reduced sensitivity to hyper-parameters. However, these methods come with limitations, such as increased memory requirements for elements like moving averages and a poorly understood convergence theory. To overcome these challenges, we introduce F-CMA, a Fast-Controlled Mini-batch Algorithm with a random reshuffling method featuring a sufficient decrease condition and a line-search procedure to ensure loss reduction per epoch, along with its deterministic proof of global convergence to a stationary point. To evaluate the F-CMA, we integrate it into conventional training protocols for classification tasks involving both convolutional neural networks and vision transformer models, allowing for a direct comparison with popular optimizers. Computational tests show significant improvements, including a decrease in the overall training time by up to 68%, an increase in per-epoch efficiency by up to 20%, and in model accuracy by up to 5%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15795v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Corrado Coppola, Lorenzo Papa, Irene Amerini, Laura Palagi</dc:creator>
    </item>
  </channel>
</rss>
