<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.data-an updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.data-an</link>
    <description>physics.data-an updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.data-an" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 24 Jul 2024 05:46:16 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 24 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Unraveling Complexity: Singular Value Decomposition in Complex Experimental Data Analysis</title>
      <link>https://arxiv.org/abs/2407.16267</link>
      <description>arXiv:2407.16267v1 Announce Type: new 
Abstract: Analyzing complex experimental data with multiple parameters is challenging. We propose using Singular Value Decomposition (SVD) as an effective solution. This method, demonstrated through real experimental data analysis, surpasses conventional approaches in understanding complex physics data. Singular values and vectors distinguish and highlight various physical mechanisms and scales, revealing previously challenging elements. SVD emerges as a powerful tool for navigating complex experimental landscapes, showing promise for diverse experimental measurements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.16267v1</guid>
      <category>physics.data-an</category>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.mes-hall</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Judith F. Stein, Aviad Frydman, Richard Berkovits</dc:creator>
    </item>
    <item>
      <title>Universal emergence of local Zipf's law</title>
      <link>https://arxiv.org/abs/2407.15946</link>
      <description>arXiv:2407.15946v1 Announce Type: cross 
Abstract: A plethora of natural and socio-economic phenomena share a striking statistical regularity, that is the magnitude of elements decreases with a power law as a function of their position in a ranking of magnitude. Such regularity is commonly known as Zipf's law, and plenty of problem-specific explanations for its emergence have been provided in different fields. Yet, an explanation for Zipf's law ubiquity is currently lacking. In this paper, we demonstrate from first principles that Zipf's behavior naturally emerges as a local approximation to the order statistics generated by any ranking process. We validate our results against several relevant examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.15946v1</guid>
      <category>physics.soc-ph</category>
      <category>physics.data-an</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Davide Cugini, Andr\'e Timpanaro, Giacomo Livan, Giacomo Guarnieri</dc:creator>
    </item>
    <item>
      <title>Setting of the Poincar\'e section for accurately calculating the phase of rhythmic spatiotemporal dynamics</title>
      <link>https://arxiv.org/abs/2407.16080</link>
      <description>arXiv:2407.16080v1 Announce Type: cross 
Abstract: The synchronization analysis of limit-cycle oscillators is prevalent in many fields, including physics, chemistry, and life sciences. It relies on the phase calculation that utilizes measurements. However, the synchronization of spatiotemporal dynamics cannot be analyzed because a standardized method for calculating the phase has not been established. The presence of spatial structure complicates the determination of which measurements should be used for accurate phase calculation. To address this, we explore a method for calculating the phase from the time series of measurements taken at a single spatial grid point. The phase is calculated to increase linearly between event times when the measurement time series intersects the Poincar\'e section. The difference between the calculated phase and the isochron-based phase, resulting from the discrepancy between the isochron and the Poincar\'e section, is evaluated using a linear approximation near the limit-cycle solution. We found that the difference is small when measurements are taken from regions that dominate the rhythms of the entire spatiotemporal dynamics. Furthermore, we investigate an alternative method where the Poincar\'e section is applied to the time series obtained through orthogonal decomposition of the entire spatiotemporal dynamics. We present two decomposition schemes that utilize the principal component analysis. For illustration, the phase is calculated from the measurements of spatiotemporal dynamics exhibiting target waves or oscillating spots, simulated by weakly coupled FitzHugh-Nagumo reaction-diffusion models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.16080v1</guid>
      <category>nlin.AO</category>
      <category>physics.data-an</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Takahiro Arai, Yoji Kawamura, Toshio Aoyagi</dc:creator>
    </item>
    <item>
      <title>Neural information field filter</title>
      <link>https://arxiv.org/abs/2407.16502</link>
      <description>arXiv:2407.16502v1 Announce Type: cross 
Abstract: We introduce neural information field filter, a Bayesian state and parameter estimation method for high-dimensional nonlinear dynamical systems given large measurement datasets. Solving such a problem using traditional methods, such as Kalman and particle filters, is computationally expensive. Information field theory is a Bayesian approach that can efficiently reconstruct dynamical model state paths and calibrate model parameters from noisy measurement data. To apply the method, we parameterize the time evolution state path using the span of a finite linear basis. The existing method has to reparameterize the state path by initial states to satisfy the initial condition. Designing an expressive yet simple linear basis before knowing the true state path is crucial for inference accuracy but challenging. Moreover, reparameterizing the state path using the initial state is easy to perform for a linear basis, but is nontrivial for more complex and expressive function parameterizations, such as neural networks. The objective of this paper is to simplify and enrich the class of state path parameterizations using neural networks for the information field theory approach. To this end, we propose a generalized physics-informed conditional prior using an auxiliary initial state. We show the existing reparameterization is a special case. We parameterize the state path using a residual neural network that consists of a linear basis function and a Fourier encoding fully connected neural network residual function. The residual function aims to correct the error of the linear basis function. To sample from the intractable posterior distribution, we develop an optimization algorithm, nested stochastic variational inference, and a sampling algorithm, nested preconditioned stochastic gradient Langevin dynamics. A series of numerical and experimental examples verify and validate the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.16502v1</guid>
      <category>stat.ML</category>
      <category>physics.data-an</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kairui Hao, Ilias Bilionis</dc:creator>
    </item>
    <item>
      <title>CASTRO -- Efficient constrained sampling method for material and chemical experimental design</title>
      <link>https://arxiv.org/abs/2407.16567</link>
      <description>arXiv:2407.16567v1 Announce Type: cross 
Abstract: The exploration of multicomponent material composition space requires significant time and financial investments, necessitating efficient use of resources for statistically relevant compositions. This article introduces a novel methodology, implemented in the open-source CASTRO (ConstrAined Sequential laTin hypeRcube sampling methOd) software package, to overcome equality-mixture constraints and ensure comprehensive design space coverage. Our approach leverages Latin hypercube sampling (LHS) and LHS with multidimensional uniformity (LHSMDU) using a divide-and-conquer strategy to manage high-dimensional problems effectively. By incorporating previous experimental knowledge within a limited budget, our method strategically recommends a feasible number of experiments to explore the design space. We validate our methodology with two examples: a four-dimensional problem with near-uniform distributions and a nine-dimensional problem with additional mixture constraints, yielding specific component distributions. Our constrained sequential LHS or LHSMDU approach enables thorough design space exploration, proving robustness for experimental design. This research not only advances material science but also offers promising solutions for efficiency challenges in pharmaceuticals and chemicals. CASTRO and the case studies are available for free download on GitHub.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.16567v1</guid>
      <category>stat.CO</category>
      <category>cond-mat.mtrl-sci</category>
      <category>physics.data-an</category>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Christina Schenk, Maciej Haranczyk</dc:creator>
    </item>
    <item>
      <title>Error correction for encoded quantum annealing revisited</title>
      <link>https://arxiv.org/abs/2407.15480</link>
      <description>arXiv:2407.15480v2 Announce Type: replace-cross 
Abstract: F. Pastawski and J. Preskill discussed error correction of quantum annealing (QA) based on a parity-encoded spin system, known as the Sourlas-Lechner-Hauke-Zoller (SLHZ) system. They pointed out that the SLHZ system is closely related to a classical low-density parity-check (LDPC) code and demonstrated its error-correcting capability through a belief propagation (BP) algorithm assuming independent random spin-flip errors. In contrast, Ablash et al. suggested that the SLHZ system does not receive the benefits of post-readout decoding. The reason is that independent random spin-flips are not the most relevant error arising from sampling excited states during the annealing process, whether in closed or open system cases. In this work, we revisit this issue: we propose a very simple decoding algorithm to eliminate errors in the readout of SLHZ systems and show experimental evidence suggesting that SLHZ system exhibits error-correcting capability in decoding annealing readouts. Our new algorithm can be thought of as a bit-flipping algorithm for LDPC codes. Assuming an independent and identical noise model, we found that the performance of our algorithm is comparable to that of the BP algorithm. The error correcting-capability for the sampled readouts was investigated using Monte Carlo calculations that simulate the final time distribution of QA. The results show that the algorithm successfully eliminates errors in the sampled readouts under conditions where error-free state or even code state is not sampled at all. Our simulation suggests that decoding of annealing readouts will be successful if the correctable states can be sampled by annealing, and annealing can be considered to play a role as a pre-process of the classical decoding process. This knowledge will be useful for designing and developing practical QA based on the SLHZ system in the near future.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.15480v2</guid>
      <category>quant-ph</category>
      <category>physics.app-ph</category>
      <category>physics.data-an</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yoshihiro Nambu</dc:creator>
    </item>
  </channel>
</rss>
