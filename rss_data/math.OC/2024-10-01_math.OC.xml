<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 02 Oct 2024 02:03:00 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Adaptive Algorithms for Robust Phase Retrieval</title>
      <link>https://arxiv.org/abs/2409.19162</link>
      <description>arXiv:2409.19162v1 Announce Type: new 
Abstract: This paper considers the robust phase retrieval, which can be cast as a nonsmooth and nonconvex composite optimization problem. We propose two first-order algorithms with adaptive step sizes: the subgradient algorithm (AdaSubGrad) and the inexact proximal linear algorithm (AdaIPL). Our contribution lies in the novel design of adaptive step sizes based on quantiles of the absolute residuals. Local linear convergences of both algorithms are analyzed under different regimes for the hyper-parameters. Numerical experiments on synthetic datasets and image recovery also demonstrate that our methods are competitive against the existing methods in the literature utilizing predetermined (possibly impractical) step sizes, such as the subgradient methods and the inexact proximal linear method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19162v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhong Zheng, Necdet Serhat Aybat, Shiqian Ma, Lingzhou Xue</dc:creator>
    </item>
    <item>
      <title>Faster Acceleration for Steepest Descent</title>
      <link>https://arxiv.org/abs/2409.19200</link>
      <description>arXiv:2409.19200v1 Announce Type: new 
Abstract: We propose a new accelerated first-order method for convex optimization under non-Euclidean smoothness assumptions. In contrast to standard acceleration techniques, our approach uses primal-dual iterate sequences taken with respect to differing norms, which are then coupled using an implicitly determined interpolation parameter. For $\ell_p$ norm smooth problems in $d$ dimensions, our method provides an iteration complexity improvement of up to $O(d^{1-\frac{2}{p}})$ in terms of calls to a first-order oracle, thereby allowing us to circumvent long-standing barriers in accelerated non-Euclidean steepest descent.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19200v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Site Bai, Brian Bullins</dc:creator>
    </item>
    <item>
      <title>Distributed Optimization via Energy Conservation Laws in Dilated Coordinates</title>
      <link>https://arxiv.org/abs/2409.19279</link>
      <description>arXiv:2409.19279v1 Announce Type: new 
Abstract: Optimizing problems in a distributed manner is critical for systems involving multiple agents with private data. Despite substantial interest, a unified method for analyzing the convergence rates of distributed optimization algorithms is lacking. This paper introduces an energy conservation approach for analyzing continuous-time dynamical systems in dilated coordinates. Instead of directly analyzing dynamics in the original coordinate system, we establish a conserved quantity, akin to physical energy, in the dilated coordinate system. Consequently, convergence rates can be explicitly expressed in terms of the inverse time-dilation factor. Leveraging this generalized approach, we formulate a novel second-order distributed accelerated gradient flow with a convergence rate of $O\left(1/t^{2-\epsilon}\right)$ in time $t$ for $\epsilon&gt;0$. We then employ a semi second-order symplectic Euler discretization to derive a rate-matching algorithm with a convergence rate of $O\left(1/k^{2-\epsilon}\right)$ in $k$ iterations. To the best of our knowledge, this represents the most favorable convergence rate for any distributed optimization algorithm designed for smooth convex optimization. Its accelerated convergence behavior is benchmarked against various state-of-the-art distributed optimization algorithms on practical, large-scale problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19279v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.DS</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mayank Baranwal, Kushal Chakrabarti</dc:creator>
    </item>
    <item>
      <title>Analysis of the SiMPL method for density-based topology optimization</title>
      <link>https://arxiv.org/abs/2409.19341</link>
      <description>arXiv:2409.19341v1 Announce Type: new 
Abstract: We present a rigorous convergence analysis of a new method for density-based topology optimization: Sigmoidal Mirror descent with a Projected Latent variable. SiMPL provides point-wise bound preserving design updates and faster convergence than other popular first-order topology optimization methods. Due to its strong bound preservation, the method is exceptionally robust, as demonstrated in numerous examples here and in a companion article. Furthermore, it is easy to implement with clear structure and analytical expressions for the updates. Our analysis covers two versions of the method, characterized by the employed line search strategies. We consider a modified Armijo backtracking line search and a Bregman backtracking line search. Regardless of the line search algorithm, SiMPL delivers a strict monotone decrease in the objective function and further intuitive convergence properties, e.g., strong and pointwise convergence of the density variables on the active sets, norm convergence to zero of the increments, and more. In addition, the numerical experiments demonstrate apparent mesh-independent convergence of the algorithm and superior performance over the two most popular first-order methods in topology optimization: OC and MMA.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19341v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Brendan Keith, Dohyun Kim, Boyan S. Lazarov, Thomas M. Surowiec</dc:creator>
    </item>
    <item>
      <title>Second-order optimality conditions and stability for optimal control problems governed by viscous Camassa-Holm equations</title>
      <link>https://arxiv.org/abs/2409.19347</link>
      <description>arXiv:2409.19347v1 Announce Type: new 
Abstract: This work is a continuation of the previous one in [{\it Optimization} (2023)], where the existence of optimal solutions and first-order necessary optimality conditions in both Pontryagin's maximum principle form and the variational form were proved for a distributed optimal control problem governed by the three-dimensional viscous Camassa-Holm equations in bounded domains with the cost functional of a quite general form and pointwise control constraints. We will establish the second-order sufficient optimality conditions as well as the Lipschitz stability results of the control system with respect to perturbations of the initial data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19347v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Cung The Anh, Nguyen Hai Ha Giang</dc:creator>
    </item>
    <item>
      <title>A Proximal Modified Quasi-Newton Method for Nonsmooth Regularized Optimization</title>
      <link>https://arxiv.org/abs/2409.19428</link>
      <description>arXiv:2409.19428v1 Announce Type: new 
Abstract: We develop R2N, a modified quasi-Newton method for minimizing the sum of a $\mathcal{C}^1$ function $f$ and a lower semi-continuous prox-bounded $h$. Both $f$ and $h$ may be nonconvex. At each iteration, our method computes a step by minimizing the sum of a quadratic model of $f$, a model of $h$, and an adaptive quadratic regularization term. A step may be computed by a variant of the proximal-gradient method. An advantage of R2N over trust-region (TR) methods is that proximal operators do not involve an extra TR indicator. We also develop the variant R2DH, in which the model Hessian is diagonal, which allows us to compute a step without relying on a subproblem solver when $h$ is separable. R2DH can be used as standalone solver, but also as subproblem solver inside R2N. We describe non-monotone variants of both R2N and R2DH. Global convergence of a first-order stationarity measure to zero holds without relying on local Lipschitz continuity of $\nabla f$, while allowing model Hessians to grow unbounded, an assumption particularly relevant to quasi-Newton models. Under Lipschitz-continuity of $\nabla f$, we establish a tight worst-case complexity bound of $O(1 / \epsilon^{2/(1 - p)})$ to bring said measure below $\epsilon &gt; 0$, where $0 \leq p &lt; 1$ controls the growth of model Hessians. The latter must not diverge faster than $|\mathcal{S}_k|^p$, where $\mathcal{S}_k$ is the set of successful iterations up to iteration $k$. When $p = 1$, we establish the tight exponential complexity bound $O(\exp(c \epsilon^{-2}))$ where $c &gt; 0$ is a constant. We describe our Julia implementation and report numerical experience on a basis-pursuit problem, image denoising, minimum-rank matrix completion, and a nonlinear support vector machine. In particular, the minimum-rank problem cannot be solved directly at this time by a TR approach as corresponding proximal operators are not known analytically.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19428v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.13140/RG.2.2.21140.51840</arxiv:DOI>
      <dc:creator>Youssef Diouane, Mohamed Laghdaf Habiboullah, Dominique Orban</dc:creator>
    </item>
    <item>
      <title>Strong metric (sub)regularity in optimal control</title>
      <link>https://arxiv.org/abs/2409.19452</link>
      <description>arXiv:2409.19452v1 Announce Type: new 
Abstract: This is mainly a survey on the properties of Strong Metric Regularity (SMR) and Strong Metric subRegularity (SMsR) of mappings representing first order optimality conditions (so-called optimality mappings) of optimization problems in infinite dimensional spaces. The focus is on the optimality mappings associated with optimal control problems for ODE systems or PDEs. We especially emphasize an extension of the concepts of SMR and SMsR which involves two metrics either in the domain or in the image spaces. The paper shows the relevance of this extension in optimal control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19452v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicolai A. Jork, Nikolai P. Osmolovskii, Vladimir M. Veliov</dc:creator>
    </item>
    <item>
      <title>Variance-Reduced Gradient Estimator for Nonconvex Zeroth-Order Distributed Optimization</title>
      <link>https://arxiv.org/abs/2409.19567</link>
      <description>arXiv:2409.19567v1 Announce Type: new 
Abstract: This paper investigates distributed zeroth-order optimization for smooth nonconvex problems. We propose a novel variance-reduced gradient estimator, which randomly renovates one orthogonal direction of the true gradient in each iteration while leveraging historical snapshots for variance correction. By integrating this estimator with gradient tracking mechanism, we address the trade-off between convergence rate and sampling cost per zeroth-order gradient estimation that exists in current zeroth-order distributed optimization algorithms, which rely on either the 2-point or $2d$-point gradient estimators. We derive a convergence rate of $\mathcal{O}(d^{\frac{5}{2}}/m)$ for smooth nonconvex functions in terms of sampling number $m$ and problem dimension $d$. Numerical simulations comparing our algorithm with existing methods confirm the effectiveness and efficiency of the proposed gradient estimator.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19567v1</guid>
      <category>math.OC</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Huaiyi Mu, Yujie Tang, Zhongkui Li</dc:creator>
    </item>
    <item>
      <title>Robust Portfolio Selection under State-dependent Confidence Set</title>
      <link>https://arxiv.org/abs/2409.19571</link>
      <description>arXiv:2409.19571v1 Announce Type: new 
Abstract: This paper studies the robust portfolio selection problem under a state-dependent confidence set. The investor invests in a financial market with a risk-free asset and a risky asset. The ambiguity-averse investor faces uncertainty over the drift of the risky asset and updates posterior beliefs by Bayesian learning. The investor holds the belief that the unknown drift falls within a confidence set at a certain confidence level. The confidence set varies with both the observed state and time. By maximizing the expected CARA utility of terminal wealth under the worst-case scenario of the unknown drift, we derive and solve the associated HJBI equation. The robust optimal investment strategy is obtained in a semi-analytical form based on a PDE. We validate the existence and uniqueness of the PDE and demonstrate the optimality of the solution in the verification theorem. The robust optimal investment strategy consists of two components: myopic demand in the worst-case scenario and hedging demand. The robust optimal investment strategy is categorized into three regions: buying, selling, and small trading. Ambiguity aversion results in a more conservative robust optimal investment strategy. Additionally, with learning, the investor's uncertainty about the drift decreases over time, leading to increased risk exposure to the risky asset.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19571v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guohui Guan, Yuting Jia, Zongxia Liang</dc:creator>
    </item>
    <item>
      <title>A Riemannian Alternating Descent Ascent Algorithmic Framework for Nonconvex-Linear Minimax Problems on Riemannian Manifolds</title>
      <link>https://arxiv.org/abs/2409.19588</link>
      <description>arXiv:2409.19588v1 Announce Type: new 
Abstract: Recently, there has been growing interest in minimax problems on Riemannian manifolds due to their wide applications in machine learning and signal processing. Although many algorithms have been developed for minimax problems in the Euclidean setting, there are relatively few works studying minimax problems on manifolds. In this paper, we develop a flexible Riemannian alternating descent ascent (RADA) algorithmic framework for solving nonconvex-linear minimax problems on Riemannian manifolds. Within this framework, we propose two easy-to-implement yet efficient algorithms that alternately perform one or multiple projected/Riemannian gradient descent steps and a proximal gradient ascent step at each iteration. We show that the proposed RADA algorithmic framework can find both an $\varepsilon$-Riemannian-game-stationary point and an $\varepsilon$-Riemannian-optimization-stationary point of the considered problem within $\mathcal{O}(\varepsilon^{-3})$ iterations, achieving the best-known iteration complexity. We also reveal intriguing similarities and differences between the algorithms developed within our proposed framework and existing algorithms, which provide important insights into why the former outperform the latter. Lastly, we report numerical results on sparse principal component analysis (PCA), fair PCA, and sparse spectral clustering to demonstrate the superior performance of the proposed algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19588v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Meng Xu, Bo Jiang, Ya-Feng Liu, Anthony Man-Cho So</dc:creator>
    </item>
    <item>
      <title>Newton Method for Set Optimization Problems with Set-Valued Mapping of Finitely Many Vector-Valued Functions</title>
      <link>https://arxiv.org/abs/2409.19636</link>
      <description>arXiv:2409.19636v1 Announce Type: new 
Abstract: In this paper, we propose a Newton method for unconstrained set optimization problems to find its weakly minimal solutions with respect to lower set-less ordering. The objective function of the problem under consideration is given by finitely many strongly convex twice continuously differentiable vector-valued functions. At first, with the help of a family of vector optimization problems and the Gerstewitz scalarizing function, we identify a necessary optimality condition for weakly minimal solutions of the considered problem. In the proposed Newton method, we derive a sequence of iterative points that exhibits local convergence to a point which satisfies the derived necessary optimality condition for weakly minimal points. To find this sequence of iterates, we formulate a family of vector optimization problems with the help of a partition set concept. Then, we find a descent direction for this obtained family of vector optimization problems to progress from the current iterate to the next iterate. As the chosen vector optimization problem differed across the iterates, the proposed Newton method for set optimization problems is not a straight extension of that for vector optimization problems. A step-wise algorithm of the entire process is provided. The well-definedness and convergence of the proposed method are analyzed. To establish the convergence of the proposed algorithm under some regularity condition of the stationary points, we derive three key relations: a condition of nonstationarity, the boundedness of the norm of Newton direction, and the existence of step length that satisfies the Armijo condition. We obtain the local superlinear convergence of the proposed method under uniform continuity of the Hessian and local quadratic convergence under Lipschitz continuity of the Hessian.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19636v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Debdas Ghosh,  Anshika, Qamrul Hasan Ansari, Xiaopeng Zhao</dc:creator>
    </item>
    <item>
      <title>SymILO: A Symmetry-Aware Learning Framework for Integer Linear Optimization</title>
      <link>https://arxiv.org/abs/2409.19678</link>
      <description>arXiv:2409.19678v1 Announce Type: new 
Abstract: Integer linear programs (ILPs) are commonly employed to model diverse practical problems such as scheduling and planning. Recently, machine learning techniques have been utilized to solve ILPs. A straightforward idea is to train a model via supervised learning, with an ILP as the input and an optimal solution as the label. An ILP is symmetric if its variables can be permuted without changing the problem structure, resulting in numerous equivalent and optimal solutions. Randomly selecting an optimal solution as the label can introduce variability in the training data, which may hinder the model from learning stable patterns. In this work, we incorporate the intrinsic symmetry of ILPs and propose a novel training framework called SymILO. Specifically, we modify the learning task by introducing solution permutation along with neural network weights as learnable parameters and then design an alternating algorithm to jointly optimize the loss function. We evaluated our framework on ILPs with different symmetries, and computational results demonstrate that our symmetry-aware approach significantly outperforms the symmetry-agnostic ones. We conduct extensive experiments on ILPs involving different symmetries and the computational results demonstrate that our symmetry-aware approach significantly outperforms three existing methods -- achieving up to $50.3\%$, $66.5\%$, and $45.4\%$ improvements, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19678v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qian Chen, Tianjian Zhang, Linxin Yang, Qingyu Han, Akang Wang, Ruoyu Sun, Xiaodong Luo, Tsung-Hui Chang</dc:creator>
    </item>
    <item>
      <title>Dual Spectral Projected Gradient Method for Generalized Log-det Semidefinite Programming</title>
      <link>https://arxiv.org/abs/2409.19743</link>
      <description>arXiv:2409.19743v1 Announce Type: new 
Abstract: Log-det semidefinite programming (SDP) problems are optimization problems that often arise from Gaussian graphic models. A log-det SDP problem with an l1-norm term has been examined in many methods, and the dual spectral projected gradient (DSPG) method by Nakagaki et al.~in 2020 is designed to efficiently solve the dual problem of the log-det SDP by combining a non-monotone line-search projected gradient method with the step adjustment for positive definiteness. This paper extends the DSPG method for solving a generalized log-det SDP problem involving additional terms to cover more structures in Gaussian graphical models in a unified style. We establish the convergence of the proposed method to the optimal value. We conduct numerical experiments to illustrate the efficiency of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19743v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Charles Namchaisiri, Makoto Yamashita</dc:creator>
    </item>
    <item>
      <title>Gradient descent with adaptive stepsize converges (nearly) linearly under fourth-order growth</title>
      <link>https://arxiv.org/abs/2409.19791</link>
      <description>arXiv:2409.19791v1 Announce Type: new 
Abstract: A prevalent belief among optimization specialists is that linear convergence of gradient descent is contingent on the function growing quadratically away from its minimizers. In this work, we argue that this belief is inaccurate. We show that gradient descent with an adaptive stepsize converges at a local (nearly) linear rate on any smooth function that merely exhibits fourth-order growth away from its minimizer. The adaptive stepsize we propose arises from an intriguing decomposition theorem: any such function admits a smooth manifold around the optimal solution -- which we call the ravine -- so that the function grows at least quadratically away from the ravine and has constant order growth along it. The ravine allows one to interlace many short gradient steps with a single long Polyak gradient step, which together ensure rapid convergence to the minimizer. We illustrate the theory and algorithm on the problems of matrix sensing and factorization and learning a single neuron in the overparameterized regime.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19791v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Damek Davis, Dmitriy Drusvyatskiy, Liwei Jiang</dc:creator>
    </item>
    <item>
      <title>A graphical framework for global optimization of mixed-integer nonlinear programs</title>
      <link>https://arxiv.org/abs/2409.19794</link>
      <description>arXiv:2409.19794v1 Announce Type: new 
Abstract: While mixed-integer linear programming and convex programming solvers have advanced significantly over the past several decades, solution technologies for general mixed-integer nonlinear programs (MINLPs) have yet to reach the same level of maturity. Various problem structures across different application domains remain challenging to model and solve using modern global solvers, primarily due to the lack of efficient parsers and convexification routines for their complex algebraic representations. In this paper, we introduce a novel graphical framework for globally solving MINLPs based on decision diagrams (DDs), which enable the modeling of complex problem structures that are intractable for conventional solution techniques. We describe the core components of this framework, including a graphical reformulation of MINLP constraints, convexification techniques derived from the constructed graphs, efficient cutting plane methods to generate linear outer approximations, and a spatial branch-and-bound scheme with convergence guarantees. In addition to providing a global solution method for tackling challenging MINLPs, our framework addresses a longstanding gap in the DD literature by developing a general-purpose DD-based approach for solving general MINLPs. To demonstrate its capabilities, we apply our framework to solve instances from one of the most difficult classes of unsolved test problems in the MINLP Library, which are otherwise inadmissible for state-of-the-art global solvers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19794v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Danial Davarnia, Mohammadreza Kiaghadi</dc:creator>
    </item>
    <item>
      <title>Discrete Distributionally Robust Optimal Control with Explicitly Constrained Optimization</title>
      <link>https://arxiv.org/abs/2409.19860</link>
      <description>arXiv:2409.19860v1 Announce Type: new 
Abstract: Distributionally robust optimal control (DROC) is gaining interest. This study presents a reformulation method for discrete DROC (DDROC) problems to design optimal control policies under a worst-case distributional uncertainty. The reformulation of DDROC problems impacts both the utility of tractable improvements in continuous DROC problems and the inherent discretization modeling of DROC problems. DROC is believed to have tractability issues; namely, infinite inequalities emerge over the distribution space. Therefore, investigating tractable reformulation methods for these DROC problems is crucial. One such method utilizes the strong dualities of the worst-case expectations. However, previous studies demonstrated that certain non-trivial inequalities remain after the reformulation. To enhance the tractability of DDROC, the proposed method reformulates DDROC problems into one-layer smooth convex programming with only a few trivial inequalities. The proposed method is applied to a DDROC version of a patrol-agent design problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19860v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuma Shida, Yuji Ito</dc:creator>
    </item>
    <item>
      <title>Statistical Analysis of the Role of Invariant Manifolds on Robust Trajectories</title>
      <link>https://arxiv.org/abs/2409.19905</link>
      <description>arXiv:2409.19905v1 Announce Type: new 
Abstract: As low-thrust space missions increase in prevalence, it is becoming increasingly important to design robust trajectories against unforeseen thruster outages or missed thrust events. Accounting for such events is particularly important in multibody systems, such as the cislunar realm, where the dynamics are chaotic and the dynamical flow is constrained by pertinent dynamical structures. Yet the role of these dynamical structures in robust trajectory design is unclear. This paper provides the first comprehensive statistical study of robust and non-robust trajectories in relation to the invariant manifolds of resonant orbits in a circular restricted three-body problem. For both the non-robust and robust solutions analyzed in this study, the optimal subset demonstrates a closer alignment with the invariant manifolds, while the overall feasible set frequently exhibits considerable deviations. Robust optimal trajectories shadow the invariant manifolds as closely as the non-robust optimal trajectories, and in some cases, demonstrate closer alignment than the non-robust solutions. By maintaining proximity to these structures, low-thrust solutions are able to efficiently utilize the manifolds to achieve optimality even under operational uncertainties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19905v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amlan Sinha, Ryne Beeson</dc:creator>
    </item>
    <item>
      <title>Data-driven decision-making under uncertainty with entropic risk measure</title>
      <link>https://arxiv.org/abs/2409.19926</link>
      <description>arXiv:2409.19926v1 Announce Type: new 
Abstract: The entropic risk measure is widely used in high-stakes decision making to account for tail risks associated with an uncertain loss. With limited data, the empirical entropic risk estimator, i.e. replacing the expectation in the entropic risk measure with a sample average, underestimates the true risk. To debias the empirical entropic risk estimator, we propose a strongly asymptotically consistent bootstrapping procedure. The first step of the procedure involves fitting a distribution to the data, whereas the second step estimates the bias of the empirical entropic risk estimator using bootstrapping, and corrects for it. We show that naively fitting a Gaussian Mixture Model to the data using the maximum likelihood criterion typically leads to an underestimation of the risk. To mitigate this issue, we consider two alternative methods: a more computationally demanding one that fits the distribution of empirical entropic risk, and a simpler one that fits the extreme value distribution. As an application of the approach, we study a distributionally robust entropic risk minimization problem with type-$\infty$ Wasserstein ambiguity set, where debiasing the validation performance using our techniques significantly improves the calibration of the size of the ambiguity set. Furthermore, we propose a distributionally robust optimization model for a well-studied insurance contract design problem. The model considers multiple (potential) policyholders that have dependent risks and the insurer and policyholders use entropic risk measure. We show that cross validation methods can result in significantly higher out-of-sample risk for the insurer if the bias in validation performance is not corrected for. This improvement can be explained from the observation that our methods suggest a higher (and more accurate) premium to homeowners.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19926v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Utsav Sadana, Erick Delage, Angelos Georghiou</dc:creator>
    </item>
    <item>
      <title>Violina: Various-of-trajectories Identification of Linear Time-invariant Non-Markovian Dynamics</title>
      <link>https://arxiv.org/abs/2409.19978</link>
      <description>arXiv:2409.19978v1 Announce Type: new 
Abstract: We propose a new system identification method Violina (various-of-trajectories identification of linear time-invariant non-Markovian dynamics). In the Violina framework, we optimize the coefficient matrices of state-space model and memory kernel in the given space using a projected gradient descent method so that its model prediction matches the set of multiple observed data. Using Violina we can identify a linear non-Markovian dynamical system with constraints corresponding to a priori knowledge on the model parameters and memory effects. Using synthetic data, we numerically demonstrate that the Markovian and non-Markovian state-space models identified by the proposed method have considerably better generalization performances compared to the models identified by an existing dynamic decomposition-based method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19978v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ryoji Anzaki, Kazuhiro Sato</dc:creator>
    </item>
    <item>
      <title>Optimal Infinite-Horizon Mixed $\mathit{H}_2/\mathit{H}_\infty$ Control</title>
      <link>https://arxiv.org/abs/2409.20020</link>
      <description>arXiv:2409.20020v1 Announce Type: new 
Abstract: We study the problem of mixed $\mathit{H}_2/\mathit{H}_\infty$ control in the infinite-horizon setting. We identify the optimal causal controller that minimizes the $\mathit{H}_2$ cost of the closed-loop system subject to an $\mathit{H}_\infty$ constraint. Megretski proved that the optimal mixed $\mathit{H}_2/\mathit{H}_\infty$ controller is non-rational whenever the constraint is active without giving an explicit construction of the controller. In this work, we provide the first exact closed-form solution to the infinite-horizon mixed $\mathit{H}_2/\mathit{H}_\infty$ control in the frequency domain. While the optimal controller is non-rational, our formulation provides a finite-dimensional parameterization of the optimal controller. Leveraging this fact, we introduce an efficient iterative algorithm that finds the optimal causal controller in the frequency domain. We show that this algorithm is convergent when the system is scalar and present numerical evidence for exponential convergence of the proposed algorithm. Finally, we show how to find the best (in $\mathit{H}_\infty$ norm) fixed-order rational approximations of the optimal mixed $\mathit{H}_2/\mathit{H}_\infty$ controller and study its performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.20020v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vikrant Malik, Taylan Kargin, Joudi Hajar, Babak Hassibi</dc:creator>
    </item>
    <item>
      <title>A Parallel-in-Time Newton's Method for Nonlinear Model Predictive Control</title>
      <link>https://arxiv.org/abs/2409.20027</link>
      <description>arXiv:2409.20027v1 Announce Type: new 
Abstract: Model predictive control (MPC) is a powerful framework for optimal control of dynamical systems. However, MPC solvers suffer from a high computational burden that restricts their application to systems with low sampling frequency. This issue is further amplified in nonlinear and constrained systems that require nesting MPC solvers within iterative procedures. In this paper, we address these issues by developing parallel-in-time algorithms for constrained nonlinear optimization problems that take advantage of massively parallel hardware to achieve logarithmic computational time scaling over the planning horizon. We develop time-parallel second-order solvers based on interior point methods and the alternating direction method of multipliers, leveraging fast convergence and lower computational cost per iteration. The parallelization is based on a reformulation of the subproblems in terms of associative operations that can be parallelized using the associative scan algorithm. We validate our approach on numerical examples of nonlinear and constrained dynamical systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.20027v1</guid>
      <category>math.OC</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Casian Iacob, Hany Abdulsamad, Simo S\"arkk\"a</dc:creator>
    </item>
    <item>
      <title>Irreducibility of nonsmooth state-space models with an application to CMA-ES</title>
      <link>https://arxiv.org/abs/2409.20107</link>
      <description>arXiv:2409.20107v2 Announce Type: new 
Abstract: We analyze a stochastic process resulting from the normalization of states in the zeroth-order optimization method CMA-ES. On a specific class of minimization problems where the objective function is scaling-invariant, this process defines a time-homogeneous Markov chain whose convergence at a geometric rate can imply the linear convergence of CMA-ES. However, the analysis of the intricate updates for this process constitute a great mathematical challenge. We establish that this Markov chain is an irreducible and aperiodic T-chain. These contributions represent a first major step for the convergence analysis towards a stationary distribution. We rely for this analysis on conditions for the irreducibility of nonsmooth state-space models on manifolds. To obtain our results, we extend these conditions to address the irreducibility in different hyperparameter settings that define different Markov chains, and to include nonsmooth state spaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.20107v2</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Armand Gissler (CMAP), Shan-Conrad Wolf (CMAP), Anne Auger (CMAP), Nikolaus Hansen (CMAP)</dc:creator>
    </item>
    <item>
      <title>On System Operators with Variation Bounding Properties</title>
      <link>https://arxiv.org/abs/2409.20275</link>
      <description>arXiv:2409.20275v1 Announce Type: new 
Abstract: The property of linear discrete-time time-invariant system operators mapping inputs with at most $k-1$ sign changes to outputs with at $k-1$ sign changes is investigated. We show that this property is tractable via the notion of $k$-sign consistency in case of the observability/controllability operator, which as such can also be used as a sufficient condition for the Hankel operator. Our results complement the literature in several aspects: an algebraic characterization, independent of rank and dimension, is provided for variation bounding and diminishing matrices and their computational tractability is discussed. Based on these, we conduct our studies of variation bounding system operators beyond existing studies on order-preserving $k$-variation diminishment. Our results are applied to the open problem of bounding the number of sign changes in a system's impulse response.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.20275v1</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Chaim Roth, Christian Grussler</dc:creator>
    </item>
    <item>
      <title>A mean field Jacobi process for modeling sustainable tourism</title>
      <link>https://arxiv.org/abs/2409.20347</link>
      <description>arXiv:2409.20347v1 Announce Type: new 
Abstract: A mean field Jacobi process governing the dynamics of the travel demand of agents is formulated and its application to sustainable tourism is investigated both mathematically and computationally. The bounded nature of the Jacobi diffusion process enables the categorization of tourism state with sustainable tourism state corresponding to an internal solution and overtourism state to a boundary solution. A stochastic control framework is introduced to design sustainable tourism under uncertainty, incorporating model distortion conditions owing to misspecification. The control problem is reduced to solving the optimality system of a stationary mean field game whose closed-form solution is derived under certain conditions. The optimality system can be computed numerically using the finite difference method under more general conditions. We present demonstrative examples of the mean field Jacobi process for different parameter values, illustrating both sustainable tourism and overtourism cases. Our findings suggest that the sustainable tourism state cannot be realized if the fluctuation or model misspecification is large.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.20347v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hidekazu Yoshioka</dc:creator>
    </item>
    <item>
      <title>Finding quadratic underestimators for optimal value functions of nonconvex all-quadratic problems via copositive optimization</title>
      <link>https://arxiv.org/abs/2409.20355</link>
      <description>arXiv:2409.20355v1 Announce Type: new 
Abstract: Modeling parts of an optimization problem as an optimal value function that depends on a top-level decision variable is a regular occurrence in optimization and an essential ingredient for methods such as Benders Decomposition. It often allows for the disentanglement of computational complexity and exploitation of special structures in the lower-level problem that define the optimal value functions. If this problem is convex, duality theory can be used to build piecewise affine models of the optimal value function over which the top-level problem can be optimized efficiently. In this text, we are interested in the optimal value function of an all-quadratic problem (also called quadratically constrained quadratic problem, QCQP) which is not necessarily convex, so that duality theory can not be applied without introducing a generally unquantifiable relaxation error. This issue can be bypassed by employing copositive reformulations of the underlying QCQP. We investigate two ways to parametrize these by the top-level variable. The first one leads to a copositive characterization of an underestimator that is sandwiched between the convex envelope of the optimal value function and that envelope's lower-semicontinuous hull. The dual of that characterization allows us to derive affine underestimators. The second parametrization yields an alternative characterization of the optimal value function itself, which other than the original version has an exact dual counterpart. From the latter, we can derive convex and nonconvex quadratic underestimators of the optimal value function. In fact, we can show that any quadratic underestimator is associated with a dual feasible solution in a certain sense.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.20355v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Markus Gabl, Immanuel Bomze</dc:creator>
    </item>
    <item>
      <title>Well-posedness and Stability of Discrete Approximations for Controlled Sweeping Processes with Time Delay</title>
      <link>https://arxiv.org/abs/2409.20404</link>
      <description>arXiv:2409.20404v1 Announce Type: new 
Abstract: This paper addresses, for the first time in the literature, optimal control problems for dynamic systems governed by a novel class of sweeping processes with time delay. We establish well-posedness of such processes, in the sense of the existence and uniqueness of feasible trajectories corresponding to feasible controls under fairly unrestrictive assumptions. Then we construct a well-posed family of discrete approximations and find efficient conditions under the discretized time-delayed sweeping process exhibits stability with respect to strong convergence of feasible and optimal solutions. This creates a bridge between optimization of continuous-time and discrete-time sweeping control systems and justifies the effective use of discrete approximations in deriving optimality conditions and numerical techniques to solve the original time-delayed sweeping control problems via discrete approximations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.20404v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Boris Mordukhovich, Dao Nguyen, Trang Nguyen, Norma Ortiz-Robinson, Vinicio R\'ios</dc:creator>
    </item>
    <item>
      <title>Instance Configuration for Sustainable Job Shop Scheduling</title>
      <link>https://arxiv.org/abs/2409.18972</link>
      <description>arXiv:2409.18972v1 Announce Type: cross 
Abstract: The Job Shop Scheduling Problem (JSP) is a pivotal challenge in operations research and is essential for evaluating the effectiveness and performance of scheduling algorithms. Scheduling problems are a crucial domain in combinatorial optimization, where resources (machines) are allocated to job tasks to minimize the completion time (makespan) alongside other objectives like energy consumption. This research delves into the intricacies of JSP, focusing on optimizing performance metrics and minimizing energy consumption while considering various constraints such as deadlines and release dates. Recognizing the multi-dimensional nature of benchmarking in JSP, this study underscores the significance of reference libraries and datasets like JSPLIB in enriching algorithm evaluation. The research highlights the importance of problem instance characteristics, including job and machine numbers, processing times, and machine availability, emphasizing the complexities introduced by energy consumption considerations.
  An innovative instance configurator is proposed, equipped with parameters such as the number of jobs, machines, tasks, and speeds, alongside distributions for processing times and energy consumption. The generated instances encompass various configurations, reflecting real-world scenarios and operational constraints. These instances facilitate comprehensive benchmarking and evaluation of scheduling algorithms, particularly in contexts of energy efficiency. A comprehensive set of 500 test instances has been generated and made publicly available, promoting further research and benchmarking in JSP. These instances enable robust analyses and foster collaboration in developing advanced, energy-efficient scheduling solutions by providing diverse scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.18972v1</guid>
      <category>cs.DC</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Christian Perez, Carlos March, Miguel A. Salido</dc:creator>
    </item>
    <item>
      <title>Joint Optimization of Pattern, Headway, and Fleet Size of Multiple Urban Transit Lines with Perceived Headway Consideration and Passenger Flow Allocation</title>
      <link>https://arxiv.org/abs/2409.19068</link>
      <description>arXiv:2409.19068v1 Announce Type: cross 
Abstract: This study addresses the urban transit pattern design problem, optimizing stop sequences, headways, and fleet sizes across multiple routes simultaneously to minimize user costs (composed of riding, waiting, and transfer times) under operational constraints (e.g., vehicle capacity and fleet size). A destination-labeled multi-commodity network flow (MCNF) formulation is developed to solve the problem at a large scale more efficiently compared to the previous literature. The model allows for flexible pattern options without relying on pre-defined candidate sets and simultaneously considers multiple operational strategies such as express/local services, short-turning, and deadheading. It evaluates perceived headways of joint patterns for passengers, assigns passenger flows to each pattern accordingly, and allows transfers across patterns in different directions. The mixed-integer linear programming (MILP) model is demonstrated with a city-sized network of metro lines in Chicago, USA, achieving near-optimal solutions in hours. The total weighted journey times are reduced by 0.61% and 4.13% under single-route and multi-route scenarios respectively. The model provides transit agencies with an efficient tool for comprehensive service design and resource allocation, improving service quality and resource utilization without additional operational costs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19068v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Max T. M. Ng, Draco Tong, Hani S. Mahmassani, Omer Verbas, Taner Cokyasar</dc:creator>
    </item>
    <item>
      <title>Improved formulation for long-duration storage in capacity expansion models using representative periods</title>
      <link>https://arxiv.org/abs/2409.19079</link>
      <description>arXiv:2409.19079v1 Announce Type: cross 
Abstract: With the increasing complexity and size of capacity expansion models, temporal aggregation has emerged as a common method to improve computational tractability. However, this approach inherently complicates the inclusion of long-duration storage (LDS) systems, whose operation involves the entire time horizon connecting all time steps. This work presents a detailed investigation of LDS modelling with temporal aggregation. A novel compact formulation is proposed to reduce the number of constraints while effectively tracking the storage content and enforcing limits on the state of charge throughout the entire time horizon. The developed method is compared with two leading state-of-the-art formulations. All three methods are implemented in the Dolphyn capacity expansion model and tested on a case study for the continental United States, considering different configurations in terms of spatial resolutions and representative periods. The performance is assessed with both the commercial solver Gurobi and the open-source solver HiGHS. Results show that the developed compact formulation consistently outperforms the other methods in terms of both runtime (30%-70% faster than other methods) and memory usage (1%-9% lower than other methods).</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19079v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Federico Parolin, Paolo Colbertaldo, Ruaridh Macdonald</dc:creator>
    </item>
    <item>
      <title>An Accelerated Algorithm for Stochastic Bilevel Optimization under Unbounded Smoothness</title>
      <link>https://arxiv.org/abs/2409.19212</link>
      <description>arXiv:2409.19212v1 Announce Type: cross 
Abstract: This paper investigates a class of stochastic bilevel optimization problems where the upper-level function is nonconvex with potentially unbounded smoothness and the lower-level problem is strongly convex. These problems have significant applications in sequential data learning, such as text classification using recurrent neural networks. The unbounded smoothness is characterized by the smoothness constant of the upper-level function scaling linearly with the gradient norm, lacking a uniform upper bound. Existing state-of-the-art algorithms require $\widetilde{O}(1/\epsilon^4)$ oracle calls of stochastic gradient or Hessian/Jacobian-vector product to find an $\epsilon$-stationary point. However, it remains unclear if we can further improve the convergence rate when the assumptions for the function in the population level also hold for each random realization almost surely (e.g., Lipschitzness of each realization of the stochastic gradient). To address this issue, we propose a new Accelerated Bilevel Optimization algorithm named AccBO. The algorithm updates the upper-level variable by normalized stochastic gradient descent with recursive momentum and the lower-level variable by the stochastic Nesterov accelerated gradient descent algorithm with averaging. We prove that our algorithm achieves an oracle complexity of $\widetilde{O}(1/\epsilon^3)$ to find an $\epsilon$-stationary point. Our proof relies on a novel lemma characterizing the dynamics of stochastic Nesterov accelerated gradient descent algorithm under distribution drift with high probability for the lower-level variable, which is of independent interest and also plays a crucial role in analyzing the hypergradient estimation error over time. Experimental results on various tasks confirm that our proposed algorithm achieves the predicted theoretical acceleration and significantly outperforms baselines in bilevel optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19212v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaochuan Gong, Jie Hao, Mingrui Liu</dc:creator>
    </item>
    <item>
      <title>Time-Consistent Portfolio Selection for Rank-Dependent Utilities in an Incomplete Market</title>
      <link>https://arxiv.org/abs/2409.19259</link>
      <description>arXiv:2409.19259v1 Announce Type: cross 
Abstract: We investigate the portfolio selection problem for an agent with rank-dependent utility in an incomplete financial market. For a constant-coefficient market and CRRA utilities, we characterize the deterministic strict equilibrium strategies. In the case of time-invariant probability weighting function, we provide a comprehensive characterization of the deterministic strict equilibrium strategy. The unique non-zero equilibrium, if exists, can be determined by solving an autonomous ODE. In the case of time-variant probability weighting functions, we observe that there may be infinitely many non-zero deterministic strict equilibrium strategies, which are derived from the positive solutions to a nonlinear singular ODE. By specifying the maximal solution to the singular ODE, we are able to identify all the positive solutions. In addition, we address the issue of selecting an optimal strategy from the numerous equilibrium strategies available.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19259v1</guid>
      <category>q-fin.MF</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jiaqin Wei, Jianming Xia, Qian Zhao</dc:creator>
    </item>
    <item>
      <title>Strongly-Polynomial Time and Validation Analysis of Policy Gradient Methods</title>
      <link>https://arxiv.org/abs/2409.19437</link>
      <description>arXiv:2409.19437v1 Announce Type: cross 
Abstract: Reinforcement learning lacks a principled measure of optimality, causing research to rely on algorithm-to-algorithm or baselines comparisons with no certificate of optimality. Focusing on finite state and action Markov decision processes (MDP), we develop a simple, computable gap function that provides both upper and lower bounds on the optimality gap. Therefore, convergence of the gap function is a stronger mode of convergence than convergence of the optimality gap, and it is equivalent to a new notion we call distribution-free convergence, where convergence is independent of any problem-dependent distribution. We show the basic policy mirror descent exhibits fast distribution-free convergence for both the deterministic and stochastic setting. We leverage the distribution-free convergence to a uncover a couple new results. First, the deterministic policy mirror descent can solve unregularized MDPs in strongly-polynomial time. Second, accuracy estimates can be obtained with no additional samples while running stochastic policy mirror descent and can be used as a termination criteria, which can be verified in the validation step.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19437v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Caleb Ju, Guanghui Lan</dc:creator>
    </item>
    <item>
      <title>Almost Sure Convergence of Average Reward Temporal Difference Learning</title>
      <link>https://arxiv.org/abs/2409.19546</link>
      <description>arXiv:2409.19546v2 Announce Type: cross 
Abstract: Tabular average reward Temporal Difference (TD) learning is perhaps the simplest and the most fundamental policy evaluation algorithm in average reward reinforcement learning. After at least 25 years since its discovery, we are finally able to provide a long-awaited almost sure convergence analysis. Namely, we are the first to prove that, under very mild conditions, tabular average reward TD converges almost surely to a sample path dependent fixed point. Key to this success is a new general stochastic approximation result concerning nonexpansive mappings with Markovian and additive noise, built on recent advances in stochastic Krasnoselskii-Mann iterations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19546v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ethan Blaser, Shangtong Zhang</dc:creator>
    </item>
    <item>
      <title>Unifying back-propagation and forward-forward algorithms through model predictive control</title>
      <link>https://arxiv.org/abs/2409.19561</link>
      <description>arXiv:2409.19561v1 Announce Type: cross 
Abstract: We introduce a Model Predictive Control (MPC) framework for training deep neural networks, systematically unifying the Back-Propagation (BP) and Forward-Forward (FF) algorithms. At the same time, it gives rise to a range of intermediate training algorithms with varying look-forward horizons, leading to a performance-efficiency trade-off. We perform a precise analysis of this trade-off on a deep linear network, where the qualitative conclusions carry over to general networks. Based on our analysis, we propose a principled method to choose the optimization horizon based on given objectives and model specifications. Numerical results on various models and tasks demonstrate the versatility of our method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19561v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lianhai Ren, Qianxiao Li</dc:creator>
    </item>
    <item>
      <title>Long-Term Earth Magnetosphere Science Orbit via Earth-Moon Resonance Orbit</title>
      <link>https://arxiv.org/abs/2409.19570</link>
      <description>arXiv:2409.19570v1 Announce Type: cross 
Abstract: This article investigates long-term orbits within the Earth's magnetosphere, specifically focusing on orbits where the argument of periapsis is synchronized with changes induced by lunar gravity assists and the Earth's argument of latitude over a complete orbital period in Earth-Moon resonance. In the Earth-Moon rotating frame, resonance orbits appear repetitive; however, the argument of periapsis shifts due to the third-body effects from lunar flybys. The extent of this shift is influenced by the Jacobi integral associated with the resonance orbit. To identify feasible resonance orbits and the optimal Jacobi integral, we map the argument of periapsis change against the Jacobi integral for each prospective orbit. This synchronization allows the spacecraft to remain within a confined region in space when observed from the Sun-Earth rotating frame. Finally, the article discusses the applications of these long-term Earth magnetosphere science orbits, including orbit-orientation reconfiguration (station keeping) and stability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19570v1</guid>
      <category>astro-ph.EP</category>
      <category>math.OC</category>
      <category>physics.space-ph</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jinsung Lee, Jaeyoung Kwak, Jaemyung Ahn</dc:creator>
    </item>
    <item>
      <title>An Enhanced Semidefinite Relaxation Model Combined with Clique Graph Merging Strategy for Efficient AC Optimal Power Flow Solution</title>
      <link>https://arxiv.org/abs/2409.19609</link>
      <description>arXiv:2409.19609v1 Announce Type: cross 
Abstract: Semidefinite programming (SDP) is widely acknowledged as one of the most effective methods for deriving the tightest lower bounds of the optimal power flow (OPF) problems. In this paper, an enhanced semidefinite relaxation model that integrates tighter {\lambda}-based quadratic convex relaxation, valid inequalities, and optimality-based bound tightening algorithms derived in accordance with the branch thermal limit boundary surface into the SDP framework is presented to further tighten the lower bounds of the feasible region of OPF problems, effectively combining the advantages of these recent advancements. Additionally, the utilization of chordal decomposition in the complex matrix formulation of SDP can significantly accelerate the solution time. Notably, for the same SDP problem, different chordal decompositions can result in varying solution time. To address this problem, this paper proposes a clique graph merging strategy within the complex matrix SDP framework, which assesses clique sizes and the computational burden on interior-point solvers, as well as reducing the need for hyperparameter tuning and further enhancing the solution efficiency. Finally, the proposed hybrid relaxation model is evaluated using MATPOWER and PGLib-OPF test cases, demonstrating its effectiveness in reducing the optimality gap and validating its computational performance on test cases with up to 13659-node.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19609v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Zhaojun Ruan, Libao Shi</dc:creator>
    </item>
    <item>
      <title>Solving Fredholm Integral Equations of the Second Kind via Wasserstein Gradient Flows</title>
      <link>https://arxiv.org/abs/2409.19642</link>
      <description>arXiv:2409.19642v1 Announce Type: cross 
Abstract: Motivated by a recent method for approximate solution of Fredholm equations of the first kind, we develop a corresponding method for a class of Fredholm equations of the \emph{second kind}. In particular, we consider the class of equations for which the solution is a probability measure. The approach centres around specifying a functional whose gradient flow admits a minimizer corresponding to a regularized version of the solution of the underlying equation and using a mean-field particle system to approximately simulate that flow. Theoretical support for the method is presented, along with some illustrative numerical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19642v1</guid>
      <category>stat.CO</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <category>stat.ME</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Francesca R. Crucinio, Adam M. Johansen</dc:creator>
    </item>
    <item>
      <title>Differentially Private Bilevel Optimization</title>
      <link>https://arxiv.org/abs/2409.19800</link>
      <description>arXiv:2409.19800v1 Announce Type: cross 
Abstract: We present differentially private (DP) algorithms for bilevel optimization, a problem class that received significant attention lately in various machine learning applications. These are the first DP algorithms for this task that are able to provide any desired privacy, while also avoiding Hessian computations which are prohibitive in large-scale settings. Under the well-studied setting in which the upper-level is not necessarily convex and the lower-level problem is strongly-convex, our proposed gradient-based $(\epsilon,\delta)$-DP algorithm returns a point with hypergradient norm at most $\widetilde{\mathcal{O}}\left((\sqrt{d_\mathrm{up}}/\epsilon n)^{1/2}+(\sqrt{d_\mathrm{low}}/\epsilon n)^{1/3}\right)$ where $n$ is the dataset size, and $d_\mathrm{up}/d_\mathrm{low}$ are the upper/lower level dimensions. Our analysis covers constrained and unconstrained problems alike, accounts for mini-batch gradients, and applies to both empirical and population losses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19800v1</guid>
      <category>cs.LG</category>
      <category>cs.CR</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guy Kornowski</dc:creator>
    </item>
    <item>
      <title>Tannenbaum's gain-margin optimization meets Polyak's heavy-ball algorithm</title>
      <link>https://arxiv.org/abs/2409.19882</link>
      <description>arXiv:2409.19882v1 Announce Type: cross 
Abstract: The paper highlights a relatively unknown link between algorithm design in optimization and control synthesis in robust control. Specifically, quadratic optimization can be recast as a regulation problem within the framework of $\mathcal{H}_\infty$ control. From this vantage point, the optimality of Polyak's fastest heavy-ball algorithm can be ascertained as a solution to a gain margin optimization problem. The approach is independent of Polyak's original and brilliant argument, yet simpler, and relies on the foundational work by Tannenbaum that introduced and solved the gain margin optimization via Nevanlinna--Pick interpolation theory. The link between first-order optimization methods and robust control theory sheds new light into limits of algorithmic performance for such methods, and suggests a new framework where similar computational problems can be systematically studied and algorithms optimized. In particular, it raises the question as to whether periodically scheduled algorithms can achieve faster rates for quadratic optimization, in a manner analogous to periodic control that extends gain margin beyond that of time-invariant control. This turns out not to be the case, due to the analytic obstruction of a transmission zero that is inherent in causal optimization algorithms. Interestingly, this obstruction can be removed with implicit algorithms, cast in a similar manner as feedback regulation problems with causal, but not strictly causal dynamics, thereby devoid of the transmission zero at infinity and able to achieve superior convergence rates. The confluence of the fields of optimization algorithms and control provides a frame to tackle questions pertaining to speed, accuracy, distributed computation, and so forth, and to delineate respective limits to performance and tradeoffs in a systematic manner, utilizing the formalism of robust control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19882v1</guid>
      <category>eess.SY</category>
      <category>cs.NA</category>
      <category>cs.SY</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wuwei Wu, Jie Chen, Mihailo R. Jovanovi\'c, Tryphon T. Georgiou</dc:creator>
    </item>
    <item>
      <title>Acceleration Meets Inverse Maintenance: Faster $\ell_{\infty}$-Regression</title>
      <link>https://arxiv.org/abs/2409.20030</link>
      <description>arXiv:2409.20030v1 Announce Type: cross 
Abstract: We propose a randomized multiplicative weight update (MWU) algorithm for $\ell_{\infty}$ regression that runs in $\widetilde{O}\left(n^{2+1/22.5} \text{poly}(1/\epsilon)\right)$ time when $\omega = 2+o(1)$, improving upon the previous best $\widetilde{O}\left(n^{2+1/18} \text{poly} \log(1/\epsilon)\right)$ runtime in the low-accuracy regime. Our algorithm combines state-of-the-art inverse maintenance data structures with acceleration. In order to do so, we propose a novel acceleration scheme for MWU that exhibits {\it stabiliy} and {\it robustness}, which are required for the efficient implementations of the inverse maintenance data structures.
  We also design a faster {\it deterministic} MWU algorithm that runs in $\widetilde{O}\left(n^{2+1/12}\text{poly}(1/\epsilon)\right))$ time when $\omega = 2+o(1)$, improving upon the previous best $\widetilde{O}\left(n^{2+1/6} \text{poly} \log(1/\epsilon)\right)$ runtime in the low-accuracy regime. We achieve this by showing a novel stability result that goes beyond the previous known works based on interior point methods (IPMs).
  Our work is the first to use acceleration and inverse maintenance together efficiently, finally making the two most important building blocks of modern structured convex optimization compatible.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.20030v1</guid>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Deeksha Adil, Shunhua Jiang, Rasmus Kyng</dc:creator>
    </item>
    <item>
      <title>Resource Allocation for Stable LLM Training in Mobile Edge Computing</title>
      <link>https://arxiv.org/abs/2409.20247</link>
      <description>arXiv:2409.20247v1 Announce Type: cross 
Abstract: As mobile devices increasingly become focal points for advanced applications, edge computing presents a viable solution to their inherent computational limitations, particularly in deploying large language models (LLMs). However, despite the advancements in edge computing, significant challenges remain in efficient training and deploying LLMs due to the computational demands and data privacy concerns associated with these models. This paper explores a collaborative training framework that integrates mobile users with edge servers to optimize resource allocation, thereby enhancing both performance and efficiency. Our approach leverages parameter-efficient fine-tuning (PEFT) methods, allowing mobile users to adjust the initial layers of the LLM while edge servers handle the more demanding latter layers. Specifically, we formulate a multi-objective optimization problem to minimize the total energy consumption and delay during training. We also address the common issue of instability in model performance by incorporating stability enhancements into our objective function. Through novel fractional programming technique, we achieve a stationary point for the formulated problem. Simulations demonstrate that our method reduces the energy consumption as well as the latency, and increases the reliability of LLMs across various mobile settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.20247v1</guid>
      <category>cs.DC</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chang Liu, Jun Zhao</dc:creator>
    </item>
    <item>
      <title>Old Optimizer, New Norm: An Anthology</title>
      <link>https://arxiv.org/abs/2409.20325</link>
      <description>arXiv:2409.20325v1 Announce Type: cross 
Abstract: Deep learning optimizers are often motivated through a mix of convex and approximate second-order theory. We select three such methods -- Adam, Shampoo and Prodigy -- and argue that each method can instead be understood as a squarely first-order method without convexity assumptions. In fact, after switching off exponential moving averages, each method is equivalent to steepest descent under a particular norm. By generalizing this observation, we chart a new design space for training algorithms. Different operator norms should be assigned to different tensors based on the role that the tensor plays within the network. For example, while linear and embedding layers may have the same weight space of $\mathbb{R}^{m\times n}$, these layers play different roles and should be assigned different norms. We hope that this idea of carefully metrizing the neural architecture might lead to more stable, scalable and indeed faster training.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.20325v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jeremy Bernstein, Laker Newhouse</dc:creator>
    </item>
    <item>
      <title>Identification of minimal number of measurements allowing synchronization of a nodal observer for the wave equation</title>
      <link>https://arxiv.org/abs/2409.20345</link>
      <description>arXiv:2409.20345v1 Announce Type: cross 
Abstract: We study a state estimation problem for a $2\times 2$ linear hyperbolic system on networks with eigenvalues with opposite signs. The system can be seen as a simplified model for gas flow through gas networks. For this system we construct an observer system based on nodal measurements and investigate the convergence of the state of the observer system towards the original system state. We assume that measurements are available at the boundary nodes of the network and identify the minimal number of additional measurements in the network that are needed to guarantee synchronization of the observer state towards the original system state. It turns out that for tree-shaped networks boundary measurements suffice to guarantee exponential synchronization, while for networks that contain cycles synchronization can be guaranteed if and only if at least one measurement point is added in each cycle. This is shown for a system without source term and for a system with linear friction term.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.20345v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jan Giesselmann, Teresa Kunkel</dc:creator>
    </item>
    <item>
      <title>Formally Verified Physics-Informed Neural Control Lyapunov Functions</title>
      <link>https://arxiv.org/abs/2409.20528</link>
      <description>arXiv:2409.20528v1 Announce Type: cross 
Abstract: Control Lyapunov functions are a central tool in the design and analysis of stabilizing controllers for nonlinear systems. Constructing such functions, however, remains a significant challenge. In this paper, we investigate physics-informed learning and formal verification of neural network control Lyapunov functions. These neural networks solve a transformed Hamilton-Jacobi-Bellman equation, augmented by data generated using Pontryagin's maximum principle. Similar to how Zubov's equation characterizes the domain of attraction for autonomous systems, this equation characterizes the null-controllability set of a controlled system. This principled learning of neural network control Lyapunov functions outperforms alternative approaches, such as sum-of-squares and rational control Lyapunov functions, as demonstrated by numerical examples. As an intermediate step, we also present results on the formal verification of quadratic control Lyapunov functions, which, aided by satisfiability modulo theories solvers, can perform surprisingly well compared to more sophisticated approaches and efficiently produce global certificates of null-controllability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.20528v1</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jun Liu, Maxwell Fitzsimmons, Ruikun Zhou, Yiming Meng</dc:creator>
    </item>
    <item>
      <title>End-to-End Conformal Calibration for Optimization Under Uncertainty</title>
      <link>https://arxiv.org/abs/2409.20534</link>
      <description>arXiv:2409.20534v1 Announce Type: cross 
Abstract: Machine learning can significantly improve performance for decision-making under uncertainty in a wide range of domains. However, ensuring robustness guarantees requires well-calibrated uncertainty estimates, which can be difficult to achieve in high-capacity prediction models such as deep neural networks. Moreover, in high-dimensional settings, there may be many valid uncertainty estimates, each with their own performance profile - i.e., not all uncertainty is equally valuable for downstream decision-making. To address this problem, this paper develops an end-to-end framework to learn the uncertainty estimates for conditional robust optimization, with robustness and calibration guarantees provided by conformal prediction. In addition, we propose to represent arbitrary convex uncertainty sets with partially input-convex neural networks, which are learned as part of our framework. Our approach consistently improves upon two-stage estimate-then-optimize baselines on concrete applications in energy storage arbitrage and portfolio optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.20534v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christopher Yeh, Nicolas Christianson, Alan Wu, Adam Wierman, Yisong Yue</dc:creator>
    </item>
    <item>
      <title>Bundle methods with quadratic cuts for deterministic and stochastic strongly convex optimization problems</title>
      <link>https://arxiv.org/abs/1711.04650</link>
      <description>arXiv:1711.04650v5 Announce Type: replace 
Abstract: We introduce two new methods for deterministic convex optimization problems: QCC (Quadratic Cuts for Convex optimization) and QB (Quadratic Bundle method). We prove the complexity of these methods for composite optimization problems which are the sum of a convex function $\tilde h$ and of a strongly convex function $\tilde f$ with parameter $\mu$. These methods use as building blocks quadratic approximations of the strongly convex function $\tilde f$ where the quadratic terms are of form $\frac{\mu}{2}\|\cdot-x_i\|^2$ for trial points $x_i$ computed along iterations (when $\mu=0$ the building blocks are linear approximations). We extend the idea of using quadratic approximations to pieces of the objective for some multistage stochastic optimization problems which have strongly convex recourse functions that we approximate as a maximum of quadratic cuts. We call DASC (Dynamic Approximation for Strongly Convex optimzation) the corresponding optimization method. When the cuts are linear, the method boils down to the popular Stochastic Dual Dynamic Programming (SDDP) method. We provide conditions ensuring strong convexity of the recourse functions and prove the convergence of DASC. Numerical experiments illustrate the performance and correctness of DASC, with DASC being much quicker than SDDP for large values of the constants of strong convexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:1711.04650v5</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vincent Guigues, Adriana Washington</dc:creator>
    </item>
    <item>
      <title>Subgradient-based Lavrentiev regularisation of monotone ill-posed problems</title>
      <link>https://arxiv.org/abs/2005.08917</link>
      <description>arXiv:2005.08917v2 Announce Type: replace 
Abstract: We introduce subgradient-based Lavrentiev regularisation of the form \begin{equation*} \mathcal{A}(u) + \alpha \partial \mathcal{R}(u) \ni f^\delta \end{equation*} for linear and nonlinear ill-posed problems with monotone operators $\mathcal{A}$ and general regularisation functionals $\mathcal{R}$. In contrast to Tikhonov regularisation, this approach perturbs the equation itself and avoids the use of the adjoint of the derivative of $\mathcal{A}$. It is therefore especially suitable for time-causal problems that only depend on information in the past and allows for real-time computation of regularised solutions. We establish a general well-posedness theory in Banach spaces and prove convergence-rate results with variational source conditions. Furthermore, we demonstrate its application in total-variation denoising in linear Volterra integral operators of the first kind and parameter-identification problems in semilinear parabolic PDEs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2005.08917v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Markus Grasmair, Fredrik Hildrum</dc:creator>
    </item>
    <item>
      <title>Numerical method for feasible and approximately optimal solutions of multi-marginal optimal transport beyond discrete measures</title>
      <link>https://arxiv.org/abs/2203.01633</link>
      <description>arXiv:2203.01633v5 Announce Type: replace 
Abstract: We propose a numerical algorithm for the computation of multi-marginal optimal transport (MMOT) problems involving general probability measures that are not necessarily discrete. By developing a relaxation scheme in which marginal constraints are replaced by finitely many linear constraints and by proving a specifically tailored duality result for this setting, we approximate the MMOT problem by a linear semi-infinite optimization problem. Moreover, we are able to recover a feasible and approximately optimal solution of the MMOT problem, and its sub-optimality can be controlled to be arbitrarily close to 0 under mild conditions. The developed relaxation scheme leads to a numerical algorithm which can compute a feasible approximate optimizer of the MMOT problem whose theoretical sub-optimality can be chosen to be arbitrarily small. Besides the approximate optimizer, the algorithm is also able to compute both an upper bound and a lower bound for the optimal value of the MMOT problem. The difference between the computed bounds provides an explicit sub-optimality bound for the computed approximate optimizer. We demonstrate the proposed algorithm in three numerical experiments involving an MMOT problem that stems from fluid dynamics, the Wasserstein barycenter problem, and a large-scale MMOT problem with 100 marginals. We observe that our algorithm is capable of computing high-quality solutions of these MMOT problems and the computed sub-optimality bounds are much less conservative than their theoretical upper bounds in all the experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2203.01633v5</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ariel Neufeld, Qikun Xiang</dc:creator>
    </item>
    <item>
      <title>Dual Representations and $H_{\infty}$-Optimal Control of Partial Differential Equations</title>
      <link>https://arxiv.org/abs/2208.13104</link>
      <description>arXiv:2208.13104v2 Announce Type: replace 
Abstract: We consider $H_{\infty}$-optimal state-feedback control of the class of linear Partial Differential Equations (PDEs) class, which admit a Partial Integral Equation (PIE) representation. While linear matrix inequalities are commonly used for optimal control of Ordinary Differential Equations (ODEs), the absence of a universal state-space representation and suitable dual form prevents such methods from being applied to optimal control of PDEs. Specifically, for ODEs, the controller synthesis problem is defined in state-space, and duality is used to resolve the bilinearity of that synthesis problem. Recently, the PIE representation was proposed as a universal state-space representation for linear PDE systems. In this paper, we show that any PDE system represented by a PIE admits a dual PIE with identical stability and I/O properties. This result allows us to reformulate the stabilizing and optimal state-feedback control problems as convex optimization over the cone of positive Partial Integral (PI) operators. Operator inversion formulae then allow us to construct feedback gains for the original PDE system. The results are verified through application to several canonical problems in optimal control of PDEs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.13104v2</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sachin Shivakumar, Amritam Das, Matthew Peet</dc:creator>
    </item>
    <item>
      <title>A model-free first-order method for linear quadratic regulator with $\tilde{O}(1/\varepsilon)$ sampling complexity</title>
      <link>https://arxiv.org/abs/2212.00084</link>
      <description>arXiv:2212.00084v4 Announce Type: replace 
Abstract: We consider the classic stochastic linear quadratic regulator (LQR) problem under an infinite horizon average stage cost. By leveraging recent policy gradient methods from reinforcement learning, we obtain a first-order method that finds a stable feedback law whose objective function gap to the optima is at most $\varepsilon$ with high probability using $\tilde{O}(1/\varepsilon)$ samples, where $\tilde{O}$ hides polylogarithmic dependence on $\varepsilon$. Our proposed method seems to have the best dependence on $\varepsilon$ within the model-free literature without the assumption that all policies generated by the algorithm are stable almost surely, and it matches the best-known rate from the model-based literature, up to logarithmic factors. The improved dependence on $\varepsilon$ is achieved by showing the accuracy scales with the variance rather than the standard deviation of the gradient estimation error. Our developments that result in this improved sampling complexity fall in the category of actor-critic algorithms. The actor part involves a variational inequality formulation of the stochastic LQR problem, while in the critic part, we utilize a conditional stochastic primal-dual method and show that the algorithm has the optimal rate of convergence when paired with a shrinking multi-epoch scheme.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.00084v4</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Caleb Ju, Georgios Kotsalis, Guanghui Lan</dc:creator>
    </item>
    <item>
      <title>A stochastic preconditioned Douglas-Rachford splitting method for saddle-point problems</title>
      <link>https://arxiv.org/abs/2212.13001</link>
      <description>arXiv:2212.13001v3 Announce Type: replace 
Abstract: In this article, we propose and study a stochastic and relaxed preconditioned Douglas--Rachford splitting method to solve saddle-point problems that have separable dual variables. We prove the almost sure convergence of the iteration sequences in Hilbert spaces for a class of convex-concave and nonsmooth saddle-point problems. We also provide the sublinear convergence rate for the ergodic sequence concerning the expectation of the restricted primal-dual gap functions. Numerical experiments show the high efficiency of the proposed stochastic and relaxed preconditioned Douglas--Rachford splitting methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.13001v3</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yakun Dong, Kristian Bredies, Hongpeng Sun</dc:creator>
    </item>
    <item>
      <title>CEDAS: A Compressed Decentralized Stochastic Gradient Method with Improved Convergence</title>
      <link>https://arxiv.org/abs/2301.05872</link>
      <description>arXiv:2301.05872v3 Announce Type: replace 
Abstract: In this paper, we consider solving the distributed optimization problem over a multi-agent network under the communication restricted setting. We study a compressed decentralized stochastic gradient method, termed ``compressed exact diffusion with adaptive stepsizes (CEDAS)", and show the method asymptotically achieves comparable convergence rate as centralized { stochastic gradient descent (SGD)} for both smooth strongly convex objective functions and smooth nonconvex objective functions under unbiased compression operators. In particular, to our knowledge, CEDAS enjoys so far the shortest transient time (with respect to the graph specifics) for achieving the convergence rate of centralized SGD, which behaves as $\mathcal{O}(n{C^3}/(1-\lambda_2)^{2})$ under smooth strongly convex objective functions, and $\mathcal{O}(n^3{C^6}/(1-\lambda_2)^4)$ under smooth nonconvex objective functions, where $(1-\lambda_2)$ denotes the spectral gap of the mixing matrix, and $C&gt;0$ is the compression-related parameter. In particular, CEDAS exhibits the shortest transient times when $C &lt; \mathcal{O}(1/(1 - \lambda_2)^2)$, which is common in practice. Numerical experiments further demonstrate the effectiveness of the proposed algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.05872v3</guid>
      <category>math.OC</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kun Huang, Shi Pu</dc:creator>
    </item>
    <item>
      <title>On damping a control system with global aftereffect on quantum graphs. Stochastic interpretation</title>
      <link>https://arxiv.org/abs/2308.00496</link>
      <description>arXiv:2308.00496v4 Announce Type: replace 
Abstract: Quantum graphs model processes in complex systems represented as spatial networks in various fields of natural science and technology. An example is the oscillations of elastic string networks, the nodes of which, besides the continuity conditions, also obey the Kirchhoff conditions, expressing the balance of tensions. In this paper, we propose a new look at quantum graphs as {\it temporal} networks, which means that the variable parametrizing the edges of a graph is interpreted as time, while each internal vertex is a branching point giving several different scenarios for the further trajectory of a process. Then Kirchhoff-type conditions may also arise. Namely, they will be satisfied by such a trajectory of the process that is optimal with account of all the scenarios simultaneously. By employing the recent concept of global delay, we extend the problem of damping a first-order control system with aftereffect, considered earlier only on an interval, to an arbitrary tree graph. The first means that the delay, imposed starting from the initial moment of time, associated with the root of the tree, propagates through all internal vertices. Bringing the system into the equilibrium and minimizing the energy functional with account of the anticipated probability of each scenario, we come to a variational problem. Then, we establish its equivalence to a self-adjoint boundary value problem on the tree for some second-order equations involving both the global delay and the global advance. The unique solvability of both problems is proved. We also illustrate that the interval case when the coefficients of the equation are discrete stochastic processes in discrete time can be viewed as the extension to a tree.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.00496v4</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sergey Buterin</dc:creator>
    </item>
    <item>
      <title>Deep Neural Newsvendor</title>
      <link>https://arxiv.org/abs/2309.13830</link>
      <description>arXiv:2309.13830v2 Announce Type: replace 
Abstract: We consider a data-driven newsvendor problem, where one has access to past demand data and the associated feature information. We solve the problem by estimating the target quantile function using a deep neural network (DNN). The remarkable representational power of DNN allows our framework to incorporate or approximate various extant data-driven models. We provide theoretical guarantees in terms of excess risk bounds for the DNN solution characterized by the network structure and sample size in a non-asymptotic manner, which justify the applicability of DNNs in the relevant contexts. Specifically, the convergence rate of the excess risk bound with respect to the sample size increases in the smoothness of the target quantile function but decreases in the dimension of feature variables. This rate can be further accelerated when the target function possesses a composite structure. In particular, our theoretical framework can be extended to accommodate the data-dependent scenarios, where the data-generating process could be time-dependent but not necessarily identical over time. Building on our theoretical results, we provide further managerial insights and practical guidance through simulation studies. Finally, we apply the DNN method to a real-world dataset obtained from a food supermarket. Our numerical experiments demonstrate that (1) the DNN method consistently outperforms other alternatives across a wide range of cost parameters, and (2) it exhibits good performance when the sample size is either very large or relatively limited.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.13830v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jinhui Han, Ming Hu, Guohao Shen</dc:creator>
    </item>
    <item>
      <title>Bregman Proximal Linearized ADMM for Minimizing Separable Sums Coupled by a Difference of Functions</title>
      <link>https://arxiv.org/abs/2401.02635</link>
      <description>arXiv:2401.02635v3 Announce Type: replace 
Abstract: In this paper, we develop a splitting algorithm incorporating Bregman distances to solve a broad class of linearly constrained composite optimization problems, whose objective function is the separable sum of possibly nonconvex nonsmooth functions and a smooth function, coupled by a difference of functions. This structure encapsulates numerous significant nonconvex and nonsmooth optimization problems in the current literature including the linearly constrained difference-of-convex problems. Relying on the successive linearization and alternating direction method of multipliers (ADMM), the proposed algorithm exhibits the global subsequential convergence to a stationary point of the underlying problem. We also establish the convergence of the full sequence generated by our algorithm under the Kurdyka--Lojasiewicz property and some mild assumptions. The efficiency of the proposed algorithm is tested on a robust principal component analysis problem and a nonconvex optimal power flow problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.02635v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s10957-024-02539-7</arxiv:DOI>
      <arxiv:journal_reference>Journal of Optimization Theory and Applications (2024)</arxiv:journal_reference>
      <dc:creator>Tan Nhat Pham, Minh N. Dao, Andrew Eberhard, Nargiz Sultanova</dc:creator>
    </item>
    <item>
      <title>Optimized Noise Suppression for Quantum Circuits</title>
      <link>https://arxiv.org/abs/2401.06423</link>
      <description>arXiv:2401.06423v2 Announce Type: replace 
Abstract: Quantum computation promises to advance a wide range of computational tasks. However, current quantum hardware suffers from noise and is too small for error correction. Thus, accurately utilizing noisy quantum computers strongly relies on noise characterization, mitigation, and suppression. Crucially, these methods must also be efficient in terms of their classical and quantum overhead. Here, we efficiently characterize and mitigate crosstalk noise, which is a severe error source in, e.g., cross-resonance based superconducting quantum processors. For crosstalk characterization, we develop a simplified measurement experiment. Furthermore, we analyze the problem of optimal experiment scheduling and solve it for common hardware architectures. After characterization, we mitigate noise in quantum circuits by a noise-aware qubit routing algorithm. Our integer programming algorithm extends previous work on optimized qubit routing by swap insertion. We incorporate the measured crosstalk errors in addition to other, more easily accessible noise data in the objective function. Furthermore, we strengthen the underlying integer linear model by proving a convex hull result about an associated class of polytopes, which has applications beyond this work. We evaluate the proposed method by characterizing crosstalk noise for two chips with up to 127 qubits and leverage the resulting data to improve the approximation ratio of the Quantum Approximate Optimization Algorithm by up to 10 % compared to other established noise-aware routing methods. Our work clearly demonstrates the gains of including noise data when mapping abstract quantum circuits to hardware native ones.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.06423v2</guid>
      <category>math.OC</category>
      <category>quant-ph</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Friedrich Wagner, Daniel J. Egger, Frauke Liers</dc:creator>
    </item>
    <item>
      <title>An Exceptionally Difficult Binary Quadratic Optimization Problem with Symmetry: a Challenge for The Largest Unsolved QAP Instance Tai256c</title>
      <link>https://arxiv.org/abs/2401.09439</link>
      <description>arXiv:2401.09439v2 Announce Type: replace 
Abstract: Tai256c is the largest unsolved quadratic assignment problem (QAP) instance in QAPLIB. It is known that QAP tai256c can be converted into a 256 dimensional binary quadratic optimization problem (BQOP) with a single cardinality constraint which requires the sum of the binary variables to be 92. As the BQOP is much simpler than the original QAP, the conversion increases the possibility to solve the QAP. Solving exactly the BQOP, however, is still very difficult. Indeed, a 1.48\% gap remains between the best known upper bound (UB) and lower bound (LB) of the unknown optimal value. This paper shows that the BQOP admits a nontrivial symmetry, a property that makes the BQOP very hard to solve. The symmetry induces equivalent subproblems in branch and bound (BB) methods. To effectively improve the LB, we propose an efficient BB method that incorporates a doubly nonnegative relaxation, the standard orbit branching and a technique to prune equivalent subproblems. With this BB method, a new LB with 1.25\% gap is successfully obtained, and computing an LB with $1.0\%$ gap is shown to be still quite difficult.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.09439v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Koichi Fujii, Sunyoung Kim, Masakazu Kojima, Hans D. Mittelmann, Yuji Shinano</dc:creator>
    </item>
    <item>
      <title>Data-Driven Discovery of PDEs via the Adjoint Method</title>
      <link>https://arxiv.org/abs/2401.17177</link>
      <description>arXiv:2401.17177v3 Announce Type: replace 
Abstract: In this work, we present an adjoint-based method for discovering the underlying governing partial differential equations (PDEs) given data. The idea is to consider a parameterized PDE in a general form and formulate a PDE-constrained optimization problem aimed at minimizing the error of the PDE solution from data. Using variational calculus, we obtain an evolution equation for the Lagrange multipliers (adjoint equations) allowing us to compute the gradient of the objective function with respect to the parameters of PDEs given data in a straightforward manner. In particular, we consider a family of parameterized PDEs encompassing linear, nonlinear, and spatial derivative candidate terms, and elegantly derive the corresponding adjoint equations. We show the efficacy of the proposed approach in identifying the form of the PDE up to machine accuracy, enabling the accurate discovery of PDEs from data. We also compare its performance with the famous PDE Functional Identification of Nonlinear Dynamics method known as PDE-FIND (Rudy et al., 2017), on both smooth and noisy data sets. Even though the proposed adjoint method relies on forward/backward solvers, it outperforms PDE-FIND for large data sets thanks to the analytic expressions for gradients of the cost function with respect to each PDE parameter.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.17177v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohsen Sadr, Tony Tohme, Kamal Youcef-Toumi</dc:creator>
    </item>
    <item>
      <title>A clustering approach for pairwise comparison matrices</title>
      <link>https://arxiv.org/abs/2402.06061</link>
      <description>arXiv:2402.06061v5 Announce Type: replace 
Abstract: We consider clustering in group decision making where the opinions are given by pairwise comparison matrices. In particular, the k-medoids model is suggested to classify the matrices since it has a linear programming problem formulation that may contain any condition on the properties of the cluster centres. Its objective function depends on the measure of dissimilarity between the matrices but not on the weights derived from them. Our methodology provides a convenient tool for decision support, for instance, it can be used to quantify the reliability of the aggregation. The proposed theoretical framework is applied to a large-scale experimental dataset, on which it is able to automatically detect some mistakes made by the decision-makers, as well as to identify a common source of inconsistency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.06061v5</guid>
      <category>math.OC</category>
      <category>stat.AP</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kolos Csaba \'Agoston, S\'andor Boz\'oki, L\'aszl\'o Csat\'o</dc:creator>
    </item>
    <item>
      <title>Robotic Sorting Systems: Robot Management and Layout Design Optimization</title>
      <link>https://arxiv.org/abs/2404.04832</link>
      <description>arXiv:2404.04832v2 Announce Type: replace 
Abstract: In the contemporary logistics industry, automation plays a pivotal role in enhancing production efficiency and expanding industrial scale. Autonomous mobile robots, in particular, have become integral to the modernization efforts in warehouses. One noteworthy application in robotic warehousing is the robotic sorting system (RSS), distinguished by its characteristics such as cost-effectiveness, simplicity, scalability, and adaptable throughput control. While previous research has focused on analyzing the efficiency of RSS, it often assumed an ideal robot management system ignoring potential queuing delays by assuming constant travel times. This study relaxes this assumption and explores the quantitative relationship between RSS configuration parameters and system throughput. We introduce a novel robot traffic management method, named the rhythmic control for sorting scenario (RC-S), for RSS operations, equipped with an estimation formula establishing the relationship between system performance and configurations. Simulations validate that RC-S reduces average service time by 10.3\% compared to the classical cooperative A* algorithm, while also improving throughput and runtime. Based on the performance analysis of RC-S, we further develop a layout optimization model for RSS, considering RSS configuration, desired throughput, and costs, to minimize expenses and determine the best layout. Numerical studies show that at lower throughput levels, facility costs dominate, while at higher throughput levels, labor costs prevail. Additionally, due to traffic efficiency limitations, RSS is well-suited for small-scale operations like end-of-supply-chain distribution centers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.04832v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Tong Zhao, Xi Lin, Fang He, Hanwen Dai</dc:creator>
    </item>
    <item>
      <title>Optimal Interventions in Coupled-Activity Network Games: Application to Sustainable Forestry</title>
      <link>https://arxiv.org/abs/2404.13662</link>
      <description>arXiv:2404.13662v2 Announce Type: replace 
Abstract: We consider the problem of promoting sustainability in production forests wherein a given number of strategic entities are authorized to manage concession regions. These entities harvest agricultural commodities and sell them in a market. We study optimal price-shaping in a coupled activity network game model in which the concession managers (agents) engage in two activities: (a) sustainable production of commodities, which does not interfere with protected forest resources, and (b) unsustainable production, which involves infringing into protected regions to expand their agricultural footprint. Using a network game model that accounts for both intra-activity and cross-activity agent-to-agent interactions, we design pricing policies that incentivize the agents to either increase their sustainable effort or reduce their unsustainable effort by addressing the NP-hard problem of welfare maximization subject to budget constraints and tolerance constraints on the aggregate level of unsustainable effort at equilibrium. We then consider a problem variant that involves region-wise uniform pricing and another that proposes price redistribution via a combination of penalties and sustainability premiums. We obtain closed-form expressions for the optimal policies for multiple cases of practical significance, and our results show that it is possible to achieve the goals of welfare maximization and unsustainable effort reduction simultaneously without reducing any agent's individual utility, even in situations in which the planner has zero external budget for offering premium raises. Our empirical analyses, performed using real data for the case of palm oil cultivation in Indonesia, validate our theoretical results and yield novel insights for guiding the design of price-shaping policies in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13662v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rohit Parasnis, Saurabh Amin</dc:creator>
    </item>
    <item>
      <title>Tropical Gradient Descent</title>
      <link>https://arxiv.org/abs/2405.19551</link>
      <description>arXiv:2405.19551v2 Announce Type: replace 
Abstract: We propose a gradient descent method for solving optimisation problems arising in settings of tropical geometry - a variant of algebraic geometry that has become increasingly studied in applications such as computational biology, economics, and computer science. Our approach takes advantage of the polyhedral and combinatorial structures arising in tropical geometry to propose a versatile approach for approximating local minima in tropical statistical optimisation problems - a rapidly growing body of work in recent years. Theoretical results establish global solvability for 1-sample problems and a convergence rate of $O(1/\sqrt{k})$. Numerical experiments demonstrate the method's superior performance over classical descent for tropical optimisation problems which exhibit tropical convexity but not classical convexity. Notably, tropical descent seamlessly integrates into advanced optimisation methods, such as Adam, offering improved overall performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.19551v2</guid>
      <category>math.OC</category>
      <category>math.MG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Roan Talbut, Anthea Monod</dc:creator>
    </item>
    <item>
      <title>Stochastic First-Order Methods with Non-smooth and Non-Euclidean Proximal Terms for Nonconvex High-Dimensional Stochastic Optimization</title>
      <link>https://arxiv.org/abs/2406.19475</link>
      <description>arXiv:2406.19475v2 Announce Type: replace 
Abstract: When the nonconvex problem is complicated by stochasticity, the sample complexity of stochastic first-order methods may depend linearly on the problem dimension, which is undesirable for large-scale problems. In this work, we propose dimension-insensitive stochastic first-order methods (DISFOMs) to address nonconvex optimization with expected-valued objective function. Our algorithms allow for non-Euclidean and non-smooth distance functions as the proximal terms. Under mild assumptions, we show that DISFOM using minibatches to estimate the gradient enjoys sample complexity of $ \mathcal{O} ( (\log d) / \epsilon^4 ) $ to obtain an $\epsilon$-stationary point. Furthermore, we prove that DISFOM employing variance reduction can sharpen this bound to $\mathcal{O} ( (\log d)^{2/3}/\epsilon^{10/3} )$, which perhaps leads to the best-known sample complexity result in terms of $d$. We provide two choices of the non-smooth distance functions, both of which allow for closed-form solutions to the proximal step. Numerical experiments are conducted to illustrate the dimension insensitive property of the proposed frameworks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19475v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yue Xie, Jiawen Bi, Hongcheng Liu</dc:creator>
    </item>
    <item>
      <title>The Non-Substitution Theorem, Uniqueness of Solution and Convex combinations of basic optimal solutions for linear optimization</title>
      <link>https://arxiv.org/abs/2408.14150</link>
      <description>arXiv:2408.14150v2 Announce Type: replace 
Abstract: Our first result is a statement of a somewhat general form of a non-substitution theorem for linear programming problems, along with a very easy proof of the same. Subsequently, we provide an easy proof of theorem 1 in a 1979 paper by Olvi L Mangasarian, based on a lemma that may be of some significance by itself. As a result of our lemma, we are able to show that a necessary and sufficient condition for a solution for a linear programming problem to be its unique solution, is that a system of linear inequalities has a solution whose last coordinate is non-negative. We also provide a simple proof of the result that states that the set of optimal solutions of a bounded linear optimization problem is the set of all convex combinations of its basic optimal solutions and the set of basic optimal solutions are the extreme points of the set of optimal solutions. We do so by appealing to Farkas lemma and the well known result that states that if a linear optimization problem has an optimal solution, it has at least one basic optimal solution. Both results we appeal to have easy proofs. We do not appeal to any version of the Klein-Milman Theorem or any result in advanced polyhedral combinatorics to obtain our results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.14150v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Somdeb Lahiri</dc:creator>
    </item>
    <item>
      <title>Average-case optimization analysis for distributed consensus algorithms on regular graphs</title>
      <link>https://arxiv.org/abs/2409.00605</link>
      <description>arXiv:2409.00605v2 Announce Type: replace 
Abstract: The consensus problem in distributed computing involves a network of agents aiming to compute the average of their initial vectors through local communication, represented by an undirected graph. This paper focuses on the studying of this problem using an average-case analysis approach, particularly over regular graphs. Traditional algorithms for solving the consensus problem often rely on worst-case performance evaluation scenarios, which may not reflect typical performance in real-world applications. Instead, we apply average-case analysis, focusing on the expected spectral distribution of eigenvalues to obtain a more realistic view of performance. Key contributions include deriving the optimal method for consensus on regular graphs, showing its relation to the Heavy Ball method, analyzing its asymptotic convergence rate, and comparing it to various first-order methods through numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.00605v2</guid>
      <category>math.OC</category>
      <category>cs.DC</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nhat Trung Nguyen, Alexander Rogozin, Alexander Gasnikov</dc:creator>
    </item>
    <item>
      <title>Policy Optimization over General State and Action Spaces</title>
      <link>https://arxiv.org/abs/2211.16715</link>
      <description>arXiv:2211.16715v3 Announce Type: replace-cross 
Abstract: Reinforcement learning (RL) problems over general state and action spaces are notoriously challenging. In contrast to the tableau setting, one can not enumerate all the states and then iteratively update the policies for each state. This prevents the application of many well-studied RL methods especially those with provable convergence guarantees. In this paper, we first present a substantial generalization of the recently developed policy mirror descent method to deal with general state and action spaces. We introduce new approaches to incorporate function approximation into this method, so that we do not need to use explicit policy parameterization at all. Moreover, we present a novel policy dual averaging method for which possibly simpler function approximation techniques can be applied. We establish linear convergence rate to global optimality or sublinear convergence to stationarity for these methods applied to solve different classes of RL problems under exact policy evaluation. We then define proper notions of the approximation errors for policy evaluation and investigate their impact on the convergence of these methods applied to general-state RL problems with either finite-action or continuous-action spaces. To the best of our knowledge, the development of these algorithmic frameworks as well as their convergence analysis appear to be new in the literature. Preliminary numerical results demonstrate the robustness of the aforementioned methods and show they can be competitive with state-of-the-art RL algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.16715v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Caleb Ju, Guanghui Lan</dc:creator>
    </item>
    <item>
      <title>Combinatorial Causal Bandits without Graph Skeleton</title>
      <link>https://arxiv.org/abs/2301.13392</link>
      <description>arXiv:2301.13392v4 Announce Type: replace-cross 
Abstract: In combinatorial causal bandits (CCB), the learning agent chooses a subset of variables in each round to intervene and collects feedback from the observed variables to minimize expected regret or sample complexity. Previous works study this problem in both general causal models and binary generalized linear models (BGLMs). However, all of them require prior knowledge of causal graph structure or unrealistic assumptions. This paper studies the CCB problem without the graph structure on binary general causal models and BGLMs. We first provide an exponential lower bound of cumulative regrets for the CCB problem on general causal models. To overcome the exponentially large space of parameters, we then consider the CCB problem on BGLMs. We design a regret minimization algorithm for BGLMs even without the graph skeleton and show that it still achieves $O(\sqrt{T}\ln T)$ expected regret, as long as the causal graph satisfies a weight gap assumption. This asymptotic regret is the same as the state-of-art algorithms relying on the graph structure. Moreover, we propose another algorithm with $O(T^{\frac{2}{3}}\ln T)$ regret to remove the weight gap assumption.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.13392v4</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shi Feng, Nuoya Xiong, Wei Chen</dc:creator>
    </item>
    <item>
      <title>Non-degenerate Rigid Alignment in a Patch Framework</title>
      <link>https://arxiv.org/abs/2303.11620</link>
      <description>arXiv:2303.11620v3 Announce Type: replace-cross 
Abstract: Given a set of overlapping local views (patches) of a dataset, we consider the problem of finding a rigid alignment of the views that minimizes a $2$-norm based alignment error. In general, the views are noisy and a perfect alignment may not exist. In this work, we characterize the non-degeneracy of an alignment in the noisy setting based on the kernel and positivity of a certain matrix. This leads to a polynomial time algorithm for testing the non-degeneracy of a given alignment. Subsequently, we focus on Riemannian gradient descent for minimizing the alignment error, providing a sufficient condition on an alignment for the algorithm to converge (locally) linearly to it. \revadd{Additionally, we provide an exact recovery and noise stability analysis of the algorithm}. In the case of noiseless views, a perfect alignment exists, resulting in a realization of the points that respects the geometry of the views. Under a mild condition on the views, we show that a non-degenerate perfect alignment \revadd{characterizes the infinitesimally rigidity of a realization, and thus the local rigidity of a generic realization}. By specializing the non-degeneracy conditions to the noiseless case, we derive necessary and sufficient conditions on the overlapping structure of the views for \revadd{a perfect alignment to be non-degenerate and equivalently, for the resulting realization to be infinitesimally rigid}. Similar results are also derived regarding the uniqueness of a perfect alignment and global rigidity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.11620v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.DG</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dhruv Kohli, Gal Mishne, Alexander Cloninger</dc:creator>
    </item>
    <item>
      <title>Logarithmic-Regret Quantum Learning Algorithms for Zero-Sum Games</title>
      <link>https://arxiv.org/abs/2304.14197</link>
      <description>arXiv:2304.14197v2 Announce Type: replace-cross 
Abstract: We propose the first online quantum algorithm for solving zero-sum games with $\widetilde O(1)$ regret under the game setting. Moreover, our quantum algorithm computes an $\varepsilon$-approximate Nash equilibrium of an $m \times n$ matrix zero-sum game in quantum time $\widetilde O(\sqrt{m+n}/\varepsilon^{2.5})$. Our algorithm uses standard quantum inputs and generates classical outputs with succinct descriptions, facilitating end-to-end applications. Technically, our online quantum algorithm "quantizes" classical algorithms based on the optimistic multiplicative weight update method. At the heart of our algorithm is a fast quantum multi-sampling procedure for the Gibbs sampling problem, which may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.14197v2</guid>
      <category>quant-ph</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>Advances in Neural Information Processing Systems 36, pp. 31177-31203, NeurIPS 2023</arxiv:journal_reference>
      <dc:creator>Minbo Gao, Zhengfeng Ji, Tongyang Li, Qisheng Wang</dc:creator>
    </item>
    <item>
      <title>It begins with a boundary: A geometric view on probabilistically robust learning</title>
      <link>https://arxiv.org/abs/2305.18779</link>
      <description>arXiv:2305.18779v3 Announce Type: replace-cross 
Abstract: Although deep neural networks have achieved super-human performance on many classification tasks, they often exhibit a worrying lack of robustness towards adversarially generated examples. Thus, considerable effort has been invested into reformulating standard Risk Minimization (RM) into an adversarially robust framework. Recently, attention has shifted towards approaches which interpolate between the robustness offered by adversarial training and the higher clean accuracy and faster training times of RM. In this paper, we take a fresh and geometric view on one such method -- Probabilistically Robust Learning (PRL). We propose a mathematical framework for understanding PRL, which allows us to identify geometric pathologies in its original formulation and to introduce a family of probabilistic nonlocal perimeter functionals to rectify them. We prove existence of solutions to the original and modified problems using novel relaxation methods and also study properties, as well as local limits, of the introduced perimeters. We also clarify, through a suitable $\Gamma$-convergence analysis, the way in which the original and modified PRL models interpolate between risk minimization and adversarial training.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.18779v3</guid>
      <category>cs.LG</category>
      <category>math.AP</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Leon Bungert, Nicol\'as Garc\'ia Trillos, Matt Jacobs, Daniel McKenzie, {\DJ}or{\dj}e Nikoli\'c, Qingsong Wang</dc:creator>
    </item>
    <item>
      <title>Safety Control of Uncertain MIMO Systems Using Dynamic Output Feedback Barrier Pairs</title>
      <link>https://arxiv.org/abs/2308.00326</link>
      <description>arXiv:2308.00326v3 Announce Type: replace-cross 
Abstract: Safety control of dynamical systems using barrier functions relies on knowing the full state information. This paper introduces a novel approach for safety control in uncertain MIMO systems with partial state information. The proposed method combines the synthesis of a vector norm barrier function and a dynamic output feedback safety controller to ensure robust safety enforcement. The safety controller guarantees the invariance of the barrier function under uncertain dynamics and disturbances. To address the challenges associated with safety verification using partial state information, a barrier function estimator is developed. This estimator employs an identifier-based state estimator to obtain a state estimate that is affine in the uncertain model parameters of the system. By incorporating a priori knowledge of the limits of the uncertain model parameters and disturbances, the state estimate provides a robust upper bound for the barrier function. Comparative analysis with existing control barrier function based methods shows the advantage of the proposed approach in enforcing safety constraints under tight input constraints and the utilization of estimated state information.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.00326v3</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Binghan He, Takashi Tanaka</dc:creator>
    </item>
    <item>
      <title>Improving the Security of United States Elections with Robust Optimization</title>
      <link>https://arxiv.org/abs/2308.02306</link>
      <description>arXiv:2308.02306v2 Announce Type: replace-cross 
Abstract: For more than a century, election officials across the United States have inspected voting machines before elections using a procedure called Logic and Accuracy Testing (LAT). This procedure consists of election officials casting a test deck of ballots into each voting machine and confirming the machine produces the expected vote total for each candidate. We bring a scientific perspective to LAT by introducing the first formal approach to designing test decks with rigorous security guarantees. Specifically, our approach employs robust optimization to find test decks that are guaranteed to detect any voting machine misconfiguration that would cause votes to be swapped across candidates. Out of all the test decks with this security guarantee, our robust optimization problem yields the test deck with the minimum number of ballots, thereby minimizing implementation costs for election officials. To facilitate deployment at scale, we develop a practically efficient exact algorithm for solving our robust optimization problems based on the cutting plane method. In partnership with the Michigan Bureau of Elections, we retrospectively applied our approach to all 6928 ballot styles from Michigan's November 2022 general election; this retrospective study reveals that the test decks with rigorous security guarantees obtained by our approach require, on average, only 1.2% more ballots than current practice. Our approach has since been piloted in real-world elections by the Michigan Bureau of Elections as a low-cost way to improve election security and increase public trust in democratic institutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.02306v2</guid>
      <category>cs.CR</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Braden L. Crimmins, J. Alex Halderman, Bradley Sturt</dc:creator>
    </item>
    <item>
      <title>Stochastic Opinion Dynamics under Social Pressure in Arbitrary Networks</title>
      <link>https://arxiv.org/abs/2308.09275</link>
      <description>arXiv:2308.09275v3 Announce Type: replace-cross 
Abstract: Social pressure is a key factor affecting the evolution of opinions on networks in many types of settings, pushing people to conform to their neighbors' opinions. To study this, the interacting Polya urn model was introduced by Jadbabaie et al., in which each agent has two kinds of opinion: inherent beliefs, which are hidden from the other agents and fixed; and declared opinions, which are randomly sampled at each step from a distribution which depends on the agent's inherent belief and her neighbors' past declared opinions (the social pressure component), and which is then communicated to her neighbors. Each agent also has a bias parameter denoting her level of resistance to social pressure. At every step, each agent updates her declared opinion (simultaneously with all other agents) according to her neighbors' aggregate past declared opinions, her inherent belief, and her bias parameter. We study the asymptotic behavior of this opinion dynamics model and show that the agents' declaration probabilities approaches a set of equilibrium points of the expected dynamics using Lyapunov theory and stochastic approximation techniques. We also derive necessary and sufficient conditions for the agents to approach consensus on their declared opinions. Our work provides further insight into the difficulty of inferring the inherent beliefs of agents when they are under social pressure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.09275v3</guid>
      <category>eess.SY</category>
      <category>cs.SI</category>
      <category>cs.SY</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jennifer Tang, Aviv Adler, Amir Ajorlou, Ali Jadbabaie</dc:creator>
    </item>
    <item>
      <title>On the Approximation of Operator-Valued Riccati Equations in Hilbert Spaces</title>
      <link>https://arxiv.org/abs/2308.10130</link>
      <description>arXiv:2308.10130v5 Announce Type: replace-cross 
Abstract: In this work, we present an abstract theory for the approximation of operator-valued Riccati equations posed on Hilbert spaces. It is demonstrated here that the error of the approximate solution to the operator-valued Riccati equation is bounded above by the approximation error of the governing semigroup, under the assumption of boundedness on the semigroup and compactness on the coefficient operators. One significant outcome of this result is the correct prediction of optimal convergence for finite element approximations of the operator-valued Riccati equations for when the governing semigroup involves parabolic, as well as hyperbolic processes. We derive the abstract theory for the time-dependent and time-independent operator-valued Riccati equations in the first part of this work. In the second part, we derive optimal error estimates for the finite element approximation of the functional gain associated with model weakly damped wave and thermal LQR control systems. These theoretical claims are then corroborated with computational evidence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.10130v5</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>James Cheung</dc:creator>
    </item>
    <item>
      <title>Robust Multivariate Detection and Estimation with Fault Frequency Content Information</title>
      <link>https://arxiv.org/abs/2310.04922</link>
      <description>arXiv:2310.04922v4 Announce Type: replace-cross 
Abstract: This paper studies the problem of fault detection and estimation (FDE) for linear time-invariant (LTI) systems with a particular focus on frequency content information of faults, possibly as multiple disjoint continuum ranges, and under both disturbances and stochastic noise. To ensure the worst-case fault sensitivity in the considered frequency ranges and mitigate the effects of disturbances and noise, an optimization framework incorporating a mixed H_/H2 performance index is developed to compute the optimal detection filter. Moreover, a thresholding rule is proposed to guarantee both the false alarm rate (FAR) and the fault detection rate (FDR). Next, shifting attention to fault estimation in specific frequency ranges, an exact reformulation of the optimal estimation filter design using the restricted Hinf performance index is derived, which is inherently non-convex. However, focusing on finite frequency samples and fixed poles, a lower bound is established via a highly tractable quadratic programming (QP) problem. This lower bound together with an alternating optimization (AO) approach to the original estimation problem leads to a suboptimality gap for the overall estimation filter design. The effectiveness of the proposed approaches is validated through applications of a non-minimum phase hydraulic turbine system and a multi-area power system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.04922v4</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jingwei Dong, Kaikai Pan, Sergio Pequito, Peyman Mohajerin Esfahani</dc:creator>
    </item>
    <item>
      <title>Efficient Implementation of Interior-Point Methods for Quantum Relative Entropy</title>
      <link>https://arxiv.org/abs/2312.07438</link>
      <description>arXiv:2312.07438v3 Announce Type: replace-cross 
Abstract: Quantum Relative Entropy (QRE) programming is a recently popular and challenging class of convex optimization problems with significant applications in quantum computing and quantum information theory. We are interested in modern interior point (IP) methods based on optimal self-concordant barriers for the QRE cone. A range of theoretical and numerical challenges associated with such barrier functions and the QRE cones have hindered the scalability of IP methods. To address these challenges, we propose a series of numerical and linear algebraic techniques and heuristics aimed at enhancing the efficiency of gradient and Hessian computations for the self-concordant barrier function, solving linear systems, and performing matrix-vector products. We also introduce and deliberate about some interesting concepts related to QRE such as symmetric quantum relative entropy (SQRE). We also introduce a two-phase method for performing facial reduction that can significantly improve the performance of QRE programming. Our new techniques have been implemented in the latest version (DDS 2.2) of the software package DDS. In addition to handling QRE constraints, DDS accepts any combination of several other conic and non-conic convex constraints. Our comprehensive numerical experiments encompass several parts including 1) a comparison of DDS 2.2 with Hypatia for the nearest correlation matrix problem, 2) using DDS for combining QRE constraints with various other constraint types, and 3) calculating the key rate for quantum key distribution (QKD) channels and presenting results for several QKD protocols.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.07438v3</guid>
      <category>quant-ph</category>
      <category>cs.MS</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mehdi Karimi, Levent Tuncel</dc:creator>
    </item>
    <item>
      <title>A New Perspective On Denoising Based On Optimal Transport</title>
      <link>https://arxiv.org/abs/2312.08135</link>
      <description>arXiv:2312.08135v2 Announce Type: replace-cross 
Abstract: In the standard formulation of the denoising problem, one is given a probabilistic model relating a latent variable $\Theta \in \Omega \subset \mathbb{R}^m \; (m\ge 1)$ and an observation $Z \in \mathbb{R}^d$ according to: $Z \mid \Theta \sim p(\cdot\mid \Theta)$ and $\Theta \sim G^*$, and the goal is to construct a map to recover the latent variable from the observation. The posterior mean, a natural candidate for estimating $\Theta$ from $Z$, attains the minimum Bayes risk (under the squared error loss) but at the expense of over-shrinking the $Z$, and in general may fail to capture the geometric features of the prior distribution $G^*$ (e.g., low dimensionality, discreteness, sparsity, etc.). To rectify these drawbacks, we take a new perspective on this denoising problem that is inspired by optimal transport (OT) theory and use it to study a different, OT-based, denoiser at the population level setting. We rigorously prove that, under general assumptions on the model, this OT-based denoiser is mathematically well-defined and unique, and is closely connected to the solution to a Monge OT problem. We then prove that, under appropriate identifiability assumptions on the model, the OT-based denoiser can be recovered solely from information of the marginal distribution of $Z$ and the posterior mean of the model, after solving a linear relaxation problem over a suitable space of couplings that is reminiscent of standard multimarginal OT problems. In particular, thanks to Tweedie's formula, when the likelihood model $\{ p(\cdot \mid \theta) \}_{\theta \in \Omega}$ is an exponential family of distributions, the OT based-denoiser can be recovered solely from the marginal distribution of $Z$. In general, our family of OT-like relaxations is of interest in its own right and for the denoising problem suggests alternative numerical methods inspired by the rich literature on computational OT.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.08135v2</guid>
      <category>math.ST</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicolas Garcia Trillos, Bodhisattva Sen</dc:creator>
    </item>
    <item>
      <title>Safety-Critical Planning and Control for Dynamic Obstacle Avoidance Using Control Barrier Functions</title>
      <link>https://arxiv.org/abs/2403.19122</link>
      <description>arXiv:2403.19122v2 Announce Type: replace-cross 
Abstract: Dynamic obstacle avoidance is a challenging topic for optimal control and optimization-based trajectory planning problems. Many existing works use Control Barrier Functions (CBFs) to enforce safety constraints for control systems. CBFs are typically formulated based on the distance to obstacles, or integrated with path planning algorithms as a safety enhancement tool. However, these approaches usually require knowledge of the obstacle boundary equations or have very slow computational efficiency. In this paper, we propose a framework based on model predictive control (MPC) with discrete-time high-order CBFs (DHOCBFs) to generate a collision-free trajectory. The DHOCBFs are first obtained from convex polytopes generated through grid mapping, without the need to know the boundary equations of obstacles. Additionally, a path planning algorithm is incorporated into this framework to ensure the global optimality of the generated trajectory. We demonstrate through numerical examples that our framework allows a unicycle robot to safely and efficiently navigate tight, dynamically changing environments with both convex and nonconvex obstacles. By comparing our method to established CBF-based benchmarks, we demonstrate superior computing efficiency, length optimality, and feasibility in trajectory generation and obstacle avoidance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.19122v2</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuo Liu, Yihui Mao, Calin A. Belta</dc:creator>
    </item>
    <item>
      <title>Interpretable Price Bounds Estimation with Shape Constraints in Price Optimization</title>
      <link>https://arxiv.org/abs/2405.14909</link>
      <description>arXiv:2405.14909v2 Announce Type: replace-cross 
Abstract: This study addresses the interpretable estimation of price bounds in the context of price optimization. In recent years, price-optimization methods have become indispensable for maximizing revenue and profits. However, effective application of these methods to real-world pricing operations remains a significant challenge. It is crucial for operators responsible for setting prices to utilize reasonable price bounds that are not only interpretable but also acceptable. Despite this necessity, most studies assume that price bounds are given constant values, and few have explored reasonable determinations of these bounds. Therefore, we propose a comprehensive framework for determining price bounds that includes both the estimation and adjustment of these bounds. Specifically, we first estimate price bounds using three distinct approaches based on historical pricing data. Then, we adjust the estimated price bounds by solving an optimization problem that incorporates shape constraints. This method allows the implementation of price optimization under practical and reasonable price bounds suitable for real-world applications. We report the effectiveness of our proposed method through numerical experiments using historical pricing data from actual services.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14909v2</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shunnosuke Ikeda, Naoki Nishimura, Shunji Umetani</dc:creator>
    </item>
    <item>
      <title>Robust portfolio optimization for recommender systems considering uncertainty of estimated statistics</title>
      <link>https://arxiv.org/abs/2406.10250</link>
      <description>arXiv:2406.10250v2 Announce Type: replace-cross 
Abstract: This paper is concerned with portfolio optimization models for creating high-quality lists of recommended items to balance the accuracy and diversity of recommendations. However, the statistics (i.e., expectation and covariance of ratings) required for mean--variance portfolio optimization are subject to inevitable estimation errors. To remedy this situation, we focus on robust optimization techniques that derive reliable solutions to uncertain optimization problems. Specifically, we propose a robust portfolio optimization model that copes with the uncertainty of estimated statistics based on the cardinality-based uncertainty sets. This robust portfolio optimization model can be reduced to a mixed-integer linear optimization problem, which can be solved exactly using mathematical optimization solvers. Experimental results using two publicly available rating datasets demonstrate that our method can improve not only the recommendation accuracy but also the diversity of recommendations compared with conventional mean--variance portfolio optimization models. Notably, our method has the potential to improve the recommendation quality of various rating prediction algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.10250v2</guid>
      <category>cs.IR</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tomoya Yanagi, Shunnosuke Ikeda, Yuichi Takano</dc:creator>
    </item>
    <item>
      <title>Portfolio optimisation: bridging the gap between theory and practice</title>
      <link>https://arxiv.org/abs/2407.00887</link>
      <description>arXiv:2407.00887v2 Announce Type: replace-cross 
Abstract: Portfolio optimisation is essential in quantitative investing, but its implementation faces several practical difficulties. One particular challenge is converting optimal portfolio weights into real-life trades in the presence of realistic features, such as transaction costs and integral lots. This is especially important in automated trading, where the entire process happens without human intervention.
  Several works in literature have extended portfolio optimisation models to account for these features. In this paper, we highlight and illustrate difficulties faced when employing the existing literature in a practical setting, such as computational intractability, numerical imprecision and modelling trade-offs. We then propose a two-stage framework as an alternative approach to address this issue. Its goal is to optimise portfolio weights in the first stage and to generate realistic trades in the second. Through extensive computational experiments, we show that our approach not only mitigates the difficulties discussed above but also can be successfully employed in a realistic scenario.
  By splitting the problem in two, we are able to incorporate new features without adding too much complexity to any single model. With this in mind we model two novel features that are critical to many investment strategies: first, we integrate two classes of assets, futures contracts and equities, into a single framework, with an example illustrating how this can help portfolio managers in enhancing investment strategies. Second, we account for borrowing costs in short positions, which have so far been neglected in literature but which significantly impact profits in long/short strategies. Even with these new features, our two-stage approach still effectively converts optimal portfolios into actionable trades.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00887v2</guid>
      <category>q-fin.PM</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Cristiano Arbex Valle</dc:creator>
    </item>
    <item>
      <title>Infrequent Resolving Algorithm for Online Linear Programming</title>
      <link>https://arxiv.org/abs/2408.00465</link>
      <description>arXiv:2408.00465v3 Announce Type: replace-cross 
Abstract: Online linear programming (OLP) has gained significant attention from both researchers and practitioners due to its extensive applications, such as online auction, network revenue management and advertising. Existing OLP algorithms fall into two categories: LP-based algorithms and LP-free algorithms. The former one typically guarantees better performance, even offering a constant regret, but requires solving a large number of LPs, which could be computationally expensive. In contrast, LP-free algorithm only requires first-order computations but induces a worse performance, lacking a constant regret bound. In this work, we study the case where the inputs are drawn from an unknown finite-support distribution, and bridge the gap between these two extremes by proposing an algorithm that achieves a constant regret while solving LPs only $O(\log\log T)$ times over the time horizon $T$. Moreover, when we are allowed to solve LPs only $M$ times, we propose an algorithm that can guarantee an $O\left(T^{(1/2+\epsilon)^{M-1}}\right)$ regret. Furthermore, when the arrival probabilities are known at the beginning, our algorithm can guarantee a constant regret by solving LPs $O(\log\log T)$ times, and an $O\left(T^{(1/2+\epsilon)^{M}}\right)$ regret by solving LPs only $M$ times. Numerical experiments are conducted to demonstrate the efficiency of the proposed algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.00465v3</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guokai Li, Zizhuo Wang, Jingwei Zhang</dc:creator>
    </item>
  </channel>
</rss>
