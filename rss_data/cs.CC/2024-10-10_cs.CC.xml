<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CC</link>
    <description>cs.CC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 11 Oct 2024 02:24:21 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Stochastic Process Turing Machines</title>
      <link>https://arxiv.org/abs/2410.07131</link>
      <description>arXiv:2410.07131v1 Announce Type: new 
Abstract: Computer science theory provides many different measures of complexity of a system including Kolmogorov complexity, logical depth, computational depth, and Levin complexity. However, these measures are all defined only for deterministic Turing machines, i.e., deterministic dynamics of the underlying generative process whose output we are interested in. Therefore, by construction they cannot capture complexity of the output of stochastic processes - like those in the real world. Motivated by this observation, we combine probabilistic Turing machines with a prior over the inputs to the Turing machine to define a complete stochastic process of Turing machines. We call this a stochastic process Turing machine. Stochastic process Turing machines allow us to formalize a stochastic generalization of logical depth called stochastic depth, and also to apply stochastic thermodynamics to the analysis of Turing machines. Stochastic process Turing machines and stochastic depth allow us to study the complex, stochastic systems like the human brain, societies, and evolution all from within the framework of formal computation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07131v1</guid>
      <category>cs.CC</category>
      <category>cs.FL</category>
      <category>cs.LO</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>David Wolpert, Jordan Scharnhorst</dc:creator>
    </item>
    <item>
      <title>Positive bias makes tensor-network contraction tractable</title>
      <link>https://arxiv.org/abs/2410.05414</link>
      <description>arXiv:2410.05414v1 Announce Type: cross 
Abstract: Tensor network contraction is a powerful computational tool in quantum many-body physics, quantum information and quantum chemistry. The complexity of contracting a tensor network is thought to mainly depend on its entanglement properties, as reflected by the Schmidt rank across bipartite cuts. Here, we study how the complexity of tensor-network contraction depends on a different notion of quantumness, namely, the sign structure of its entries. We tackle this question rigorously by investigating the complexity of contracting tensor networks whose entries have a positive bias.
  We show that for intermediate bond dimension d&gt;~n, a small positive mean value &gt;~1/d of the tensor entries already dramatically decreases the computational complexity of approximately contracting random tensor networks, enabling a quasi-polynomial time algorithm for arbitrary 1/poly(n) multiplicative approximation. At the same time exactly contracting such tensor networks remains #P-hard, like for the zero-mean case [HHEG20]. The mean value 1/d matches the phase transition point observed in [CJHS24]. Our proof makes use of Barvinok's method for approximate counting and the technique of mapping random instances to statistical mechanical models. We further consider the worst-case complexity of approximate contraction of positive tensor networks, where all entries are non-negative. We first give a simple proof showing that a multiplicative approximation with error exponentially close to one is at least StoqMA-hard. We then show that when considering additive error in the matrix 1-norm, the contraction of positive tensor network is BPP-Complete. This result compares to Arad and Landau's [AL10] result, which shows that for general tensor networks, approximate contraction up to matrix 2-norm additive error is BQP-Complete.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05414v1</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiaqing Jiang, Jielun Chen, Norbert Schuch, Dominik Hangleiter</dc:creator>
    </item>
    <item>
      <title>Maximal Length Cellular Automata : A Survey</title>
      <link>https://arxiv.org/abs/2410.05947</link>
      <description>arXiv:2410.05947v1 Announce Type: cross 
Abstract: This article surveys some theoretical aspects of Cellular Automata (CAs) research. In particular, we discuss on maximal length CA. An n-cell CA is a maximal length CA, if all the configurations except one form a single cycle. There is a bonding between maximal length CA and primitive polynomial. So, primitive polynomials occupy a good amount of space in this survey. The main goal of this survey is to provide a tutorial on maximal length CA theory to researchers with classical and new results on maximality. We also give a compact collection of known results with references to their proofs, and to suggest some open problems. Additionally, some new theorems and corollaries are added to bridge the gaps among several known results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05947v1</guid>
      <category>cs.FL</category>
      <category>cs.CC</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sumit Adak, Sukanta Das</dc:creator>
    </item>
    <item>
      <title>Smoothed analysis for graph isomorphism</title>
      <link>https://arxiv.org/abs/2410.06095</link>
      <description>arXiv:2410.06095v2 Announce Type: cross 
Abstract: There is no known polynomial-time algorithm for graph isomorphism testing, but elementary combinatorial "refinement" algorithms seem to be very efficient in practice. Some philosophical justification is provided by a classical theorem of Babai, Erd\H{o}s and Selkow: an extremely simple polynomial-time combinatorial algorithm (variously known as "na\"ive refinement", "na\"ive vertex classification", "colour refinement" or the "1-dimensional Weisfeiler-Leman algorithm") yields a so-called canonical labelling scheme for "almost all graphs". More precisely, for a typical outcome of a random graph $G(n,1/2)$, this simple combinatorial algorithm assigns labels to vertices in a way that easily permits isomorphism-testing against any other graph.
  We improve the Babai-Erd\H{o}s-Selkow theorem in two directions. First, we consider randomly perturbed graphs, in accordance with the smoothed analysis philosophy of Spielman and Teng: for any graph $G$, na\"ive refinement becomes effective after a tiny random perturbation to $G$ (specifically, the addition and removal of $O(n\log n)$ random edges). Actually, with a twist on na\"ive refinement, we show that $O(n)$ random additions and removals suffice. These results significantly improve on previous work of Gaudio-R\'acz-Sridhar, and are in certain senses best-possible.
  Second, we complete a long line of research on canonical labelling of random graphs: for any $p$ (possibly depending on $n$), we prove that a random graph $G(n,p)$ can typically be canonically labelled in polynomial time. This is most interesting in the extremely sparse regime where $p$ has order of magnitude $c/n$; denser regimes were previously handled by Bollob\'as, Czajka-Pandurangan, and Linial-Mosheiff. Our proof also provides a description of the automorphism group of a typical outcome of $G(n,p_n)$ (slightly correcting a prediction of Linial-Mosheiff).</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06095v2</guid>
      <category>math.CO</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Anastos, Matthew Kwan, Benjamin Moore</dc:creator>
    </item>
    <item>
      <title>A Decomposition Approach to the Weighted $k$-server Problem</title>
      <link>https://arxiv.org/abs/2410.06485</link>
      <description>arXiv:2410.06485v1 Announce Type: cross 
Abstract: A natural variant of the classical online $k$-server problem is the Weighted $k$-server problem, where the cost of moving a server is its weight times the distance through which it moves. Despite its apparent simplicity, the weighted $k$-server problem is extremely poorly understood. Specifically, even on uniform metric spaces, finding the optimum competitive ratio of randomized algorithms remains an open problem -- the best upper bound known is $2^{2^{k+O(1)}}$ due to a deterministic algorithm (Bansal et al., 2018), and the best lower bound known is $\Omega(2^k)$ (Ayyadevara and Chiplunkar, 2021).
  With the aim of closing this exponential gap between the upper and lower bounds, we propose a decomposition approach for designing a randomized algorithm for weighted $k$-server on uniform metrics. Our first contribution includes two relaxed versions of the problem and a technique to obtain an algorithm for weighted $k$-server from algorithms for the two relaxed versions. Specifically, we prove that if there exists an $\alpha_1$-competitive algorithm for one version (which we call Weighted $k$-Server - Service Pattern Construction (W$k$S-SPC) and there exists an $\alpha_2$-competitive algorithm for the other version (which we call Weighted $k$-server - Revealed Service Pattern (W$k$S-RSP)), then there exists an $(\alpha_1\alpha_2)$-competitive algorithm for weighted $k$-server on uniform metric spaces. Our second contribution is a $2^{O(k^2)}$-competitive randomized algorithm for W$k$S-RSP. As a consequence, the task of designing a $2^{poly(k)}$-competitive randomized algorithm for weighted $k$-server on uniform metrics reduces to designing a $2^{poly(k)}$-competitive randomized algorithm for W$k$S-SPC. Finally, we also prove that the $\Omega(2^k)$ lower bound for weighted $k$-server, in fact, holds for W$k$S-RSP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06485v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nikhil Ayyadevara, Ashish Chiplunkar, Amatya Sharma</dc:creator>
    </item>
    <item>
      <title>A structural description of Zykov and Blanche Descartes graphs</title>
      <link>https://arxiv.org/abs/2410.06917</link>
      <description>arXiv:2410.06917v1 Announce Type: cross 
Abstract: In 1949, Zykov proposed the first explicit construction of triangle-free graphs with arbitrarily large chromatic number. We define a Zykov graph as any induced subgraph of a graph created using Zykov's construction. We give a structural characterization of Zykov graphs based on a specific type of stable set, that we call splitting stable set. It implies that recognizing this class is NP-complete, while being FPT in the treewidth of the input graph. We provide similar results for the Blanche Descartes construction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06917v1</guid>
      <category>math.CO</category>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Malory Marin, St\'ephan Thomass\'e, Nicolas Trotignon, R\'emi Watrigant</dc:creator>
    </item>
    <item>
      <title>Separations between Combinatorial Measures for Transitive Functions</title>
      <link>https://arxiv.org/abs/2103.12355</link>
      <description>arXiv:2103.12355v4 Announce Type: replace 
Abstract: The role of symmetry in Boolean functions $f:\{0,1\}^n \to \{0,1\}$ has been extensively studied in complexity theory. For example, symmetric functions, that is, functions that are invariant under the action of $S_n$, is an important class of functions in the study of Boolean functions. A function $f:\{0,1\}^n \to \{0,1\}$ is called transitive (or weakly-symmetric) if there exists a transitive group $G$ of $S_n$ such that $f$ is invariant under the action of $G$ - that is the function value remains unchanged even after the bits of the input of $f$ are moved around according to some permutation $\sigma \in G$. Understanding various complexity measures of transitive functions has been a rich area of research for the past few decades.
  In this work, we study transitive functions in light of several combinatorial measures. We look at the maximum separation between various pairs of measures for transitive functions. Such study for general Boolean functions has been going on for past many years. The best-known results for general Boolean functions have been nicely compiled by Aaronson et. al (STOC, 2021).
  The separation between a pair of combinatorial measures is shown by constructing interesting functions that demonstrate the separation. But many of the celebrated separation results are via the construction of functions (like "pointer functions" from Ambainis et al. (JACM, 2017) and "cheat-sheet functions" Aaronson et al. (STOC, 2016)) that are not transitive. Hence, we don't have such separation between the pairs of measures for transitive functions.
  In this paper we show how to modify some of these functions to construct transitive functions that demonstrate similar separations between pairs of combinatorial measures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2103.12355v4</guid>
      <category>cs.CC</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sourav Chakraborty, Chandrima Kayal, Manaswi Paraashar</dc:creator>
    </item>
    <item>
      <title>Fermionic Gaussian Testing and Non-Gaussian Measures via Convolution</title>
      <link>https://arxiv.org/abs/2409.08180</link>
      <description>arXiv:2409.08180v2 Announce Type: replace-cross 
Abstract: We define fermionic convolution and demonstrate its utility in characterizing fermionic non-Gaussian components, which are essential to the computational advantage of fermionic systems. Using fermionic convolution, we propose an efficient protocol that tests the fermionic Gaussianity of pure states using three copies of the input state. We also introduce "Non-Gaussian Entropy," an experimentally accessible resource measure that quantifies fermionic non-Gaussianity. These results provide new insights into the study of fermionic quantum computation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08180v2</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xingjian Lyu, Kaifeng Bu</dc:creator>
    </item>
    <item>
      <title>Gibbs state preparation for commuting Hamiltonian: Mapping to classical Gibbs sampling</title>
      <link>https://arxiv.org/abs/2410.04909</link>
      <description>arXiv:2410.04909v2 Announce Type: replace-cross 
Abstract: Gibbs state preparation, or Gibbs sampling, is a key computational technique extensively used in physics, statistics, and other scientific fields. Recent efforts for designing fast mixing Gibbs samplers for quantum Hamiltonians have largely focused on commuting local Hamiltonians (CLHs), a non-trivial subclass of Hamiltonians which include highly entangled systems such as the Toric code and quantum double model. Most previous Gibbs samplers relied on simulating the Davies generator, which is a Lindbladian associated with the thermalization process in nature.
  Instead of using the Davies generator, we design a different Gibbs sampler for various CLHs by giving a reduction to classical Hamiltonians, in the sense that one can efficiently prepare the Gibbs state for some CLH $H$ on a quantum computer as long as one can efficiently do classical Gibbs sampling for the corresponding classical Hamiltonian $H^{(c)}$. We demonstrate that our Gibbs sampler is able to replicate state-of-the-art results as well as prepare the Gibbs state in regimes which were previously unknown, such as the low temperature region, as long as there exists fast mixing Gibbs samplers for the corresponding classical Hamiltonians. Our reductions are as follows.
  - If $H$ is a 2-local qudit CLH, then $H^{(c)}$ is a 2-local qudit classical Hamiltonian.
  - If $H$ is a 4-local qubit CLH on 2D lattice and there are no classical qubits, then $H^{(c)}$ is a 2-local qudit classical Hamiltonian on a planar graph. As an example, our algorithm can prepare the Gibbs state for the (defected) Toric code at any non-zero temperature in $\mathcal O(n^2)$ time.
  - If $H$ is a 4-local qubit CLH on 2D lattice and there are classical qubits, assuming that quantum terms are uniformly correctable, then $H^{(c)}$ is a constant-local classical Hamiltonian.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04909v2</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yeongwoo Hwang, Jiaqing Jiang</dc:creator>
    </item>
  </channel>
</rss>
