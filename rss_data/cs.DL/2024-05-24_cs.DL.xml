<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DL updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DL</link>
    <description>cs.DL updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DL" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 24 May 2024 04:00:09 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 24 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Research information in the light of artificial intelligence: quality and data ecologies</title>
      <link>https://arxiv.org/abs/2405.12997</link>
      <description>arXiv:2405.12997v1 Announce Type: new 
Abstract: This paper presents multi- and interdisciplinary approaches for finding the appropriate AI technologies for research information. Professional research information management (RIM) is becoming increasingly important as an expressly data-driven tool for researchers. It is not only the basis of scientific knowledge processes, but also related to other data. A concept and a process model of the elementary phases from the start of the project to the ongoing operation of the AI methods in the RIM is presented, portraying the implementation of an AI project, meant to enable universities and research institutions to support their researchers in dealing with incorrect and incomplete research information, while it is being stored in their RIMs. Our aim is to show how research information harmonizes with the challenges of data literacy and data quality issues, related to AI, also wanting to underline that any project can be successful if the research institutions and various departments of universities, involved work together and appropriate support is offered to improve research information and data management.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12997v1</guid>
      <category>cs.DL</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Otmane Azeroual, Tibor Koltay</dc:creator>
    </item>
    <item>
      <title>Rethinking the production and publication of machine-reusable expressions of research findings</title>
      <link>https://arxiv.org/abs/2405.13129</link>
      <description>arXiv:2405.13129v1 Announce Type: new 
Abstract: Literature is the primary expression of scientific knowledge and an important source of research data. However, scientific knowledge expressed in narrative text documents is not inherently machine reusable. To facilitate knowledge reuse, e.g. for synthesis research, scientific knowledge must be extracted from articles and organized into databases post-publication. The high time costs and inaccuracies associated with completing these activities manually has driven the development of techniques that automate knowledge extraction. Tackling the problem with a different mindset, we propose a pre-publication approach, known as reborn, that ensures scientific knowledge is born reusable, i.e. produced in a machine-reusable format during knowledge production. We implement the approach using the Open Research Knowledge Graph infrastructure for FAIR scientific knowledge organization. We test the approach with three use cases, and discuss the role of publishers and editors in scaling the approach. Our results suggest that the proposed approach is superior compared to classical manual and semi-automated post-publication extraction techniques in terms of knowledge richness and accuracy as well as technological simplicity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.13129v1</guid>
      <category>cs.DL</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Markus Stocker, Lauren Snyder, Matthew Anfuso, Oliver Ludwig, Freya Thie{\ss}en, Kheir Eddine Farfar, Muhammad Haris, Allard Oelen, Mohamad Yaser Jaradeh</dc:creator>
    </item>
    <item>
      <title>Transfer Learning Approach for Railway Technical Map (RTM) Component Identification</title>
      <link>https://arxiv.org/abs/2405.13229</link>
      <description>arXiv:2405.13229v1 Announce Type: cross 
Abstract: The extreme popularity over the years for railway transportation urges the necessity to maintain efficient railway management systems around the globe. Even though, at present, there exist a large collection of Computer Aided Designed Railway Technical Maps (RTMs) but available only in the portable document format (PDF). Using Deep Learning and Optical Character Recognition techniques, this research work proposes a generic system to digitize the relevant map component data from a given input image and create a formatted text file per image. Out of YOLOv3, SSD and Faster-RCNN object detection models used, Faster-RCNN yields the highest mean Average Precision (mAP) and the highest F1 score values 0.68 and 0.76 respectively. Further it is proven from the results obtained that, one can improve the results with OCR when the text containing image is being sent through a sophisticated pre-processing pipeline to remove distortions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.13229v1</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>cs.DL</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1007/978-981-19-2397-5_44</arxiv:DOI>
      <arxiv:journal_reference>Lecture Notes in Networks and Systems: 465 (2022) 479-488</arxiv:journal_reference>
      <dc:creator>Obadage Rochana Rumalshan, Pramuka Weerasinghe, Mohamed Shaheer, Prabhath Gunathilake, Erunika Dayaratna</dc:creator>
    </item>
    <item>
      <title>Initial Burst of Disruptive Efforts over Individual Scientific Careers</title>
      <link>https://arxiv.org/abs/2405.14543</link>
      <description>arXiv:2405.14543v1 Announce Type: cross 
Abstract: Despite persistent efforts to understand the dynamics of creativity of scientists over careers in terms of productivity, impact, and prize, little is known about the dynamics of scientists' disruptive efforts that affect individual academic careers and drive scientific advance. Drawing on millions of data over six decades and across nineteen disciplines, associating the publication records of individual scientists with the disruption index, we systematically quantify the temporal pattern of disruptive ideas over individual scientific careers, providing a detailed understanding of the macro phenomenon of scientific stagnation from the individual perspective. We start by checking the relationship between disruption-based and citation-based publication profiles. Next, we observe the finite inequality in the disruptive productivity of scientists, diminishing gradually as the level of disruption increases. We then identify the initial burst phenomenon in disruption dynamics. It is further revealed that while early engagement in high disruption frictions away initial productivity, compared to initial advantage in productivity or impact, initial high disruption ensures more subsequent academic viability evidenced by a longer career span and relatively final higher productivity, but does not necessarily guarantee academic success throughout careers. Further analysis shows that increasing disruptive work is uncorrelated to overall productivity but negatively correlated with the overall impact. However, increasing disruptive work in the early career is associated with higher overall productivity, yet lower overall productivity in the later career. Our research underscores the urgent need for a policy shift that encourages a balance between the pursuit of disruptive efforts and the achievement of impactful outcomes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14543v1</guid>
      <category>physics.soc-ph</category>
      <category>cs.DL</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Shuang Zhang, Feifan Liu, Haoxiang Xia</dc:creator>
    </item>
    <item>
      <title>Converter: Enhancing Interoperability in Research Data Management</title>
      <link>https://arxiv.org/abs/2404.13406</link>
      <description>arXiv:2404.13406v2 Announce Type: replace 
Abstract: Research Data Management (RDM) is essential in handling and organizing data in the research field. The Berlin Open Science Platform (BOP) serves as a case study that exemplifies the significance of standardization within the Berlin University Alliance (BUA), employing different vocabularies when publishing their data, resulting in data heterogeneity. The meta portals of the NFDI4Cat and the NFDI4DataScience project serve as additional case studies in the context of the NFDI initiative. To establish consistency among the harvested repositories in the respective systems, this study focuses on developing a novel component, namely the \textit{converter}, that breaks barriers between data collection and various schemas. With the minor modification of the existing Piveau framework, the development of the converter, contributes to enhanced data accessibility, streamlined collaboration, and improved interoperability within the research community.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13406v2</guid>
      <category>cs.DL</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sefika Efeoglu, Zongxiong Chen, Sonja Schimmler, Bianca Wentzel</dc:creator>
    </item>
    <item>
      <title>Temporal Evolution of Bradford Curves in Specialized Library Contexts</title>
      <link>https://arxiv.org/abs/2404.19267</link>
      <description>arXiv:2404.19267v2 Announce Type: replace 
Abstract: Bradford's law of bibliographic scattering is a fundamental principle in bibliometrics, offering valuable guidance for academic libraries in literature search and procurement. However, Bradford curves can exhibit various shapes over time, and predicting these shapes remains a challenge due to a lack of causal explanation. This paper attributes the deviations from the theoretical J-shape to integer constraints on the number of journals and articles, extending Leimkuhler and Egghe's formulas to encompass highly productive core journals, where the theoretical journal number falls below one. Using the Simon-Yule model, key parameters of the extended formulas are identified and analyzed. The paper explains the reasons for the Groos Droop and examines the critical points for shape changes. The proposed formulas are validated with empirical data from literature, demonstrating that this method can effectively predict the evolution of Bradford curves, thereby aiding academic libraries in the procurement and utilization of scientific literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.19267v2</guid>
      <category>cs.DL</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Haobai Xue, Xian Liu</dc:creator>
    </item>
    <item>
      <title>Clustering Running Titles to Understand the Printing of Early Modern Books</title>
      <link>https://arxiv.org/abs/2405.00752</link>
      <description>arXiv:2405.00752v2 Announce Type: replace 
Abstract: We propose a novel computational approach to automatically analyze the physical process behind printing of early modern letterpress books via clustering the running titles found at the top of their pages. Specifically, we design and compare custom neural and feature-based kernels for computing pairwise visual similarity of a scanned document's running titles and cluster the titles in order to track any deviations from the expected pattern of a book's printing. Unlike body text which must be reset for every page, the running titles are one of the static type elements in a skeleton forme i.e. the frame used to print each side of a sheet of paper, and were often re-used during a book's printing. To evaluate the effectiveness of our approach, we manually annotate the running title clusters on about 1600 pages across 8 early modern books of varying size and formats. Our method can detect potential deviation from the expected patterns of such skeleton formes, which helps bibliographers understand the phenomena associated with a text's transmission, such as censorship. We also validate our results against a manual bibliographic analysis of a counterfeit early edition of Thomas Hobbes' Leviathan (1651).</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00752v2</guid>
      <category>cs.DL</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nikolai Vogler, Kartik Goyal, Samuel V. Lemley, D. J. Schuldt, Christopher N. Warren, Max G'Sell, Taylor Berg-Kirkpatrick</dc:creator>
    </item>
  </channel>
</rss>
