<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 30 Jan 2026 05:01:00 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>The augmented NLP bound for maximum-entropy remote sampling</title>
      <link>https://arxiv.org/abs/2601.20970</link>
      <description>arXiv:2601.20970v1 Announce Type: new 
Abstract: The maximum-entropy remote sampling problem (MERSP) is to select a subset of s random variables from a set of n random variables, so as to maximize the information concerning a set of target random variables that are not directly observable. We assume throughout that the set of all of these random variables follows a joint Gaussian distribution, and that we have the covariance matrix available. Finally, we measure information using Shannon's differential entropy.
  The main approach for exact solution of moderate-sized instances of MERSP has been branch-and-bound, and so previous work concentrated on upper bounds. Prior to our work, there were two upper-bounding methods for MERSP: the so-called NLP bound and the spectral bound, both introduced 25 years ago. We are able now to establish domination results between these two upper bounds. We propose an ``augmented NLP bound'' based on a subtle convex relaxation. We provide theoretical guarantees, giving sufficient conditions under which the augmented NLP bound strictly dominates the ordinary NLP bound. In addition, the augmented NLP formulation allows us to derive upper bounds for rank-deficient covariance matrices when they satisfy a technical condition. This is in contrast to the earlier work on the ordinary NLP bound that worked with only positive definite covariance matrices. Finally, we introduce a novel and very effective diagonal-scaling technique for MERSP, employing a positive vector of parameters. Numerical experiments on benchmark instances demonstrate the effectiveness of our approaches in advancing the state of the art for calculating upper bounds on MERSP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.20970v1</guid>
      <category>math.OC</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gabriel Ponte, Marcia Fampa, Jon Lee</dc:creator>
    </item>
    <item>
      <title>Thompson Sampling Algorithm for Stochastic Games</title>
      <link>https://arxiv.org/abs/2601.20973</link>
      <description>arXiv:2601.20973v1 Announce Type: new 
Abstract: We study a stochastic differential game with $N$ competitive players in a linear-quadratic framework with ergodic cost, where $d$-dimensional diffusion processes govern the state dynamics with an unknown common drift (matrix). Assuming a Gaussian prior on the drift, we use filtering techniques to update its posterior estimates. Based on these estimates, we propose a Thompson-sampling-based algorithm with dynamic episode lengths to approximate strategies. We show that the Bayesian regret for each player has an error bound of order $O(\sqrt{T\log(T)})$, where $T$ is the time-horizon, independent of the number of players. This implies that average regret per unit time goes to zero. Finally, we prove that the algorithm results in a Nash equilibrium.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.20973v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Asaf Cohen, Ruolan He, Yuqiong Wang</dc:creator>
    </item>
    <item>
      <title>The dual-path fixing strategy and its application to the set-covering problem</title>
      <link>https://arxiv.org/abs/2601.20977</link>
      <description>arXiv:2601.20977v1 Announce Type: new 
Abstract: We introduce the dual-path fixing strategy to exploit dual algorithms for solving relaxations of mixed-integer nonlinear-optimization problems. Such dual algorithms are naturally applied in the context of branch-and-bound, and eventual impact on the success of branch-and-bound is our strong motivation. Our fixing strategy aims to be more powerful than the common strategy of fixing variables based on a single dual-feasible solution (e.g., standard reduced-cost fixing for mixed-integer linear optimization), but to be much faster than ``strong fixing'', essentially requiring no more time than that of the dual algorithm that we exploit. We have successfully tested our ideas on mixed-integer linear-optimization set-covering instances from the literature, in the context of the dual-simplex method applied to the continuous relaxations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.20977v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Paulo Michel F. Yamagishi, Marcia Fampa, Jon Lee</dc:creator>
    </item>
    <item>
      <title>Noisy Pairwise-Comparison Random Search for Smooth Nonconvex Optimization</title>
      <link>https://arxiv.org/abs/2601.21166</link>
      <description>arXiv:2601.21166v1 Announce Type: new 
Abstract: We consider minimizing high-dimensional smooth nonconvex objectives using only noisy pairwise comparisons. Unlike classical zeroth-order methods limited by the ambient dimension $d$, we propose Noisy-Comparison Random Search (NCRS), a direct-search method that exploits random line search to adapt to the intrinsic dimension $k \le d$. We establish novel non-convex convergence guarantees for approximate stationarity: under a uniform-margin oracle, NCRS attains $\epsilon$-stationarity with complexity $\mathcal{O}(k/(p^{2}\epsilon^{2}))$, explicitly replacing ambient dependence with the intrinsic dimension. Furthermore, we introduce a general tie-aware noise model where comparison quality degrades near ties; for this setting, we prove that a majority-vote variant of NCRS achieves $\epsilon$-stationarity with complexity $\mathcal{O}(k^{2}/\epsilon^{4})$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21166v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Taha El Bakkali, Rayane Bouftini, Qiuyi Zhang, Omar Saadi</dc:creator>
    </item>
    <item>
      <title>Solving the Offline and Online Min-Max Problem of Non-smooth Submodular-Concave Functions: A Zeroth-Order Approach</title>
      <link>https://arxiv.org/abs/2601.21243</link>
      <description>arXiv:2601.21243v1 Announce Type: new 
Abstract: We consider max-min and min-max problems with objective functions that are possibly non-smooth, submodular with respect to the minimiser and concave with respect to the maximiser. We investigate the performance of a zeroth-order method applied to this problem. The method is based on the subgradient of the Lov\'asz extension of the objective function with respect to the minimiser and based on Gaussian smoothing to estimate the smoothed function gradient with respect to the maximiser. In expectation sense, we prove the convergence of the algorithm to an $\epsilon$-saddle point in the offline case. Moreover, we show that, in the expectation sense, in the online setting, the algorithm achieves $O(\sqrt{N\bar{P}_N})$ online duality gap, where $N$ is the number of iterations and $\bar{P}_N$ is the path length of the sequence of optimal decisions. The complexity analysis and hyperparameter selection are presented for all the cases. The theoretical results are illustrated via numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21243v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amir Ali Farzin, Yuen-Man Pun, Philipp Braun, Tyler Summers, Iman Shames</dc:creator>
    </item>
    <item>
      <title>Certifying optimality in nonconvex robust PCA</title>
      <link>https://arxiv.org/abs/2601.21333</link>
      <description>arXiv:2601.21333v1 Announce Type: new 
Abstract: Robust principal component analysis seeks to recover a low-rank matrix from fully observed data with sparse corruptions. A scalable approach fits a low-rank factorization by minimizing the sum of entrywise absolute residuals, leading to a nonsmooth and nonconvex objective. Under standard incoherence conditions and a random model for the corruption support, we study factorizations of the ground-truth rank-$r$ matrix with both factors of rank $r$. With high probability, every such factorization is a Clarke critical point. We also characterize the local geometry: when the factorization rank equals $r$, these solutions are sharp local minima; when it exceeds $r$, they are strict saddle points.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21333v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pinxi Gong, Lexiao Lai, Jianhao Ma</dc:creator>
    </item>
    <item>
      <title>Decentralized Learning with Dynamically Refined Edge Weights: A Data-Dependent Framework</title>
      <link>https://arxiv.org/abs/2601.21355</link>
      <description>arXiv:2601.21355v1 Announce Type: new 
Abstract: This paper aims to accelerate decentralized optimization by strategically designing the edge weights used in the agent-to-agent message exchanges. We propose a Dynamic Directed Decentralized Gradient (D3GD) framework and show that the proposed data-dependent framework is a practical alternative to the classical directed DGD (Di-DGD) algorithm for learning on directed graphs. To obtain a strategy for edge weights refinement, we derive a design function inspired by the cost-to-go function in a new convergence analysis for Di-DGD. This results in a data-dependent dynamical design for the edge weights. A fully decentralized version of D3GD is developed such that each agent refines its communication strategy using only neighbor's information. Numerical experiments show that D3GD accelerates convergence towards stationary solution by 30-40\% over Di-DGD, and learns edge weights that adapt to data similarity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21355v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rongxing Du, Hoi-To Wai</dc:creator>
    </item>
    <item>
      <title>Manifold constrained steepest descent</title>
      <link>https://arxiv.org/abs/2601.21487</link>
      <description>arXiv:2601.21487v1 Announce Type: new 
Abstract: Norm-constrained linear minimization oracle (LMO)-based optimizers such as spectral gradient descent and Muon are attractive in large-scale learning, but extending them to manifold-constrained problems is nontrivial and often leads to nested-loop schemes that solve tangent-space subproblems iteratively. We propose \emph{Manifold Constrained Steepest Descent} (MCSD), a single-loop framework for optimization over manifolds that selects a norm-induced steepest-descent direction via an LMO applied to the Riemannian gradient, and then returns to the manifold via projection. Under standard smoothness assumptions, we establish convergence guarantees for MCSD and a stochastic momentum variant. We further introduce \emph{SPEL}, the spectral-norm specialization of MCSD on the Stiefel manifold, which admits scalable implementations via fast matrix sign computations. Experiments on PCA, orthogonality-constrained CNNs, and manifold-constrained LLM adapter tuning demonstrate improved stability and competitive performance relative to standard Riemannian baselines and existing manifold-aware LMO methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21487v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kaiwei Yang, Lexiao Lai</dc:creator>
    </item>
    <item>
      <title>A data-based image representation for continuous-time LTI systems</title>
      <link>https://arxiv.org/abs/2601.21606</link>
      <description>arXiv:2601.21606v1 Announce Type: new 
Abstract: We derive a numerically stable method to obtain an image representation of an unknown linear system only from data, leveraging a continuous-time version of Willems et al.'s fundamental lemma. We propose a data-based representation that, unlike previous approaches, avoids solving differential-algebraic equations and uses derivatives approximated by algebraic differentiators. Our image-based formulation significantly reduces the complexity of the data-driven representation by eliminating redundant degrees of freedom and thus reducing the number of unknown quantities to be identified. Simulation results confirm the effectiveness of the proposed approach, even in the presence of severe measurement disturbances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21606v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amine Othmane, Philipp Schmitz, Karl Worthmann, Kathrin Fla{\ss}kamp</dc:creator>
    </item>
    <item>
      <title>Outrunning the Omega Clock: A Singular Control Problem for Dividend Optimisation with Ruin and Time-in-Distress Default</title>
      <link>https://arxiv.org/abs/2601.21705</link>
      <description>arXiv:2601.21705v1 Announce Type: new 
Abstract: This paper extends the classical dividend problem by incorporating a novel, path-dependent mechanism of firm default. In the traditional framework, ruin occurs when the surplus process first reaches zero. In contrast, default in our model may also arise when the surplus spends an excessive amount of time below a distress threshold, even without ever hitting zero. This occupation-time-based default criterion captures financial distress more realistically, as prolonged periods of low liquidity or capitalisation may trigger regulatory intervention or operational failure. The resulting optimisation problem is formulated as a new singular stochastic control problem with discontinuous state-dependent discounting and killing. We provide a complete analytical solution via a bespoke sequential guess-and-verify method and identify three distinct classes of optimal dividend strategies corresponding to different parameter regimes of the dual-ruin structure. Notably, for certain distress thresholds, the optimal policy features disconnected action and inaction regions. We further show that, unlike in the classical dividend problem, higher effective discounting induced by occupation time below a distress level can lead to delayed, rather than earlier, dividend payments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21705v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andi Bodnariu, Nils Engler, Neofytos Rodosthenous</dc:creator>
    </item>
    <item>
      <title>On Diagonalizable Systems with Random Structure</title>
      <link>https://arxiv.org/abs/2601.21710</link>
      <description>arXiv:2601.21710v1 Announce Type: new 
Abstract: Diagonalizability plays an important role in the analysis and design of multivariable systems. A structured matrix is called structurally diagonalizable if almost all of its numerical realizations, obtained by assigning real values to its free entries, are diagonalizable. Structural diagonalizability is useful for the verification and optimization of various structural system properties. In this paper, we study the asymptotic probability distribution of structural diagonalizability for structured systems whose system matrices are represented by directed Erd\H{o}s-R\'{e}nyi random graphs. Leveraging a recently established graph-theoretic characterization of structural diagonalizability, we analyze the distribution of structurally diagonalizable graphs under different edge-density regimes. For dense graphs, we prove that the system is almost always structurally diagonalizable. For graphs of medium density, we derive tight upper and lower bounds on the asymptotic probability of structural diagonalizability. For extremely sparse graphs, we show that this probability approaches 0. The theoretical results are validated through extensive numerical simulations with varying numbers of vertices and connection probabilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21710v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuan Zhang, Yutong Han, Yuanqing Xia, Aming Li</dc:creator>
    </item>
    <item>
      <title>Stochastic Optimal Linear Quadratic Controls with A Recursive Cost Functional</title>
      <link>https://arxiv.org/abs/2601.21748</link>
      <description>arXiv:2601.21748v1 Announce Type: new 
Abstract: This paper is concerned with a stochastic linear quadratic (LQ, for short) control problem with a recursive cost functional. It involves BSDEs in $L^1$ whose well-posedness is a subtle issue. A suitable framework has been adopted so that the corresponding LQ problem is correctly formulated. Open-loop and closed-loop solvability of such an LQ problem have been investigated and characterized by the solvability of an FBSDE and that of Riccati differential equation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21748v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lin Li, Jiongmin Yong</dc:creator>
    </item>
    <item>
      <title>ZOBA: An Efficient Single-loop Zeroth-order Bilevel Optimization Algorithm</title>
      <link>https://arxiv.org/abs/2601.21836</link>
      <description>arXiv:2601.21836v1 Announce Type: new 
Abstract: Bilevel optimization problems consist of minimizing a value function whose evaluation depends on the solution of an inner optimization problem. These problems are typically tackled using first-order methods that require computing the gradient of the value function ({\it the hypergradient}). In several practical settings, however, first-order information is unavailable ({\it zeroth-order setting}), rendering these methods inapplicable. Finite-difference methods provide an alternative by approximating hypergradients using function evaluations along a set of directions. Nevertheless, such surrogates are notoriously expensive, and existing finite-difference bilevel methods rely on two-loop algorithms that are poorly parallelizable. In this work, we propose ZOBA, the first finite-difference single-loop algorithm for bilevel optimization. Our method leverages finite-difference hypergradient approximations based on delayed information to eliminate the need for nested loops. We analyze the proposed algorithm and establish convergence rates in the non-convex setting, achieving a complexity of $\mathcal{O}(p(d + p)^2\varepsilon^{-2})$, where $p$ and $d$ denote the dimension of inner and outer spaces respectively, which is better than prior approaches based on Hessian approximation. We further introduce and analyze HF-ZOBA, a Hessian-free variant that yields additional complexity improvements. Finally, we corroborate our findings with numerical experiments on synthetic functions and a real-world black-box task in adversarial machine learning. Our results show that our methods achieve accuracy comparable to state-of-the-art techniques while requiring less computation time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21836v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marco Rando, Samuel Vaiter</dc:creator>
    </item>
    <item>
      <title>When to Match: A Cost-Balancing Principle for Dynamic Markets</title>
      <link>https://arxiv.org/abs/2601.21858</link>
      <description>arXiv:2601.21858v1 Announce Type: new 
Abstract: Matching platforms, from ridesharing to food delivery to competitive gaming, face a fundamental operational dilemma: match agents immediately to minimize waiting costs, or delay to exploit the efficiency gains of thicker markets. Yet computing optimal policies is generally intractable, sophisticated algorithms often rely on restrictive distributional assumptions, and common heuristics lack worst-case performance guarantees. We formulate a versatile framework for multi-sided matching with general state-dependent cost structures and non-stationary arrival dynamics. Central to our approach is a cost-balancing principle: match when accumulated waiting cost reaches a calibrated proportion of instantaneous matching cost. This equilibrium condition emerges from fluid-limit analysis and motivates a simple, adaptive Cost-Balancing (CB) algorithm requiring no distributional assumptions. We prove that CB achieves a competitive ratio of $(1+\sqrt{\Gamma})$ under adversarial arrivals, where $\Gamma$ quantifies economies of scale, guaranteeing cost within a constant factor of the offline optimum. In contrast, standard greedy and threshold policies can incur unbounded costs in adversarial scenarios. We further establish a universal lower bound of $(\sqrt{5}+1)/2$ (the golden ratio), quantifying the fundamental price of uncertainty in online matching. Experiments on game matchmaking and real-world food delivery data demonstrate practical effectiveness, with CB consistently outperforming industry-standard heuristics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21858v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jie Liu, Hailun Zhang, Jiheng Zhang</dc:creator>
    </item>
    <item>
      <title>Pathwise Learning of Stochastic Dynamical Systems with Partial Observations</title>
      <link>https://arxiv.org/abs/2601.21860</link>
      <description>arXiv:2601.21860v1 Announce Type: new 
Abstract: The reconstruction and inference of stochastic dynamical systems from data is a fundamental task in inverse problems and statistical learning. While surrogate modeling advances computational methods to approximate these dynamics, standard approaches typically require high-fidelity training data. In many practical settings, the data are indirectly observed through noisy and nonlinear measurement. The challenge lies not only in approximating the coefficients of the SDEs, but in simultaneously inferring the posterior updates given the observations. In this work, we present a neural path estimation approach to solve stochastic dynamical systems based on variational inference. We first derive a stochastic control problem that solve filtering posterior path measure corresponding to a pathwise Zakai equation. We then construct a generative model that maps the prior path measure to posterior measure through the controlled diffusion and the associated Randon-Nykodym derivative. Through an amortization of sample paths of the observation process, the control is learned by an embedding of the noisy observation paths. Thus, we learn the unknown prior SDE and the control can recover the conditional path measure given the observation sample paths and we learn an associated SDE which induces the same path measure. In the end, we perform experiments on nonlinear dynamical systems, demonstrating the model's ability to learn multimodal, chaotic, or high dimensional systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21860v1</guid>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicole Tianjiao Yang</dc:creator>
    </item>
    <item>
      <title>On Approximate Computation of Critical Points</title>
      <link>https://arxiv.org/abs/2601.21917</link>
      <description>arXiv:2601.21917v1 Announce Type: new 
Abstract: We show that computing even very coarse approximations of critical points is intractable for simple classes of nonconvex functions. More concretely, we prove that if there exists a polynomial-time algorithm that takes as input a polynomial in $n$ variables of constant degree (as low as three) and outputs a point whose gradient has Euclidean norm at most $2^n$ whenever the polynomial has a critical point, then P=NP. The algorithm is permitted to return an arbitrary point when no critical point exists. We also prove hardness results for approximate computation of critical points under additional structural assumptions, including settings in which existence and uniqueness of a critical point are guaranteed, the function is lower bounded, and approximation is measured in terms of distance to a critical point. Overall, our results stand in contrast to the commonly-held belief that, in nonconvex optimization, approximate computation of critical points is a tractable task.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21917v1</guid>
      <category>math.OC</category>
      <category>cs.CC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.ML</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amir Ali Ahmadi, Georgina Hall</dc:creator>
    </item>
    <item>
      <title>Batched First-Order Methods for Parallel LP Solving in MIP</title>
      <link>https://arxiv.org/abs/2601.21990</link>
      <description>arXiv:2601.21990v1 Announce Type: new 
Abstract: We present a batched first-order method for solving multiple linear programs in parallel on GPUs. Our approach extends the primal-dual hybrid gradient algorithm to efficiently solve batches of related linear programming problems that arise in mixed-integer programming techniques such as strong branching and bound tightening. By leveraging matrix-matrix operations instead of repeated matrix-vector operations, we obtain significant computational advantages on GPU architectures. We demonstrate the effectiveness of our approach on various case studies and identify the problem sizes where first-order methods outperform traditional simplex-based solvers depending on the computational environment one can use. This is a significant step for the design and development of integer programming algorithms tightly exploiting GPU capabilities where we argue that some specific operations should be allocated to GPUs and performed in full instead of using light-weight heuristic approaches on CPUs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21990v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Nicolas Blin, Stefano Gualandi, Christopher Maes, Andrea Lodi, Bartolomeo Stellato</dc:creator>
    </item>
    <item>
      <title>Anderson Mixing in Bures Wasserstein Space of Gaussian Measures</title>
      <link>https://arxiv.org/abs/2601.22038</link>
      <description>arXiv:2601.22038v1 Announce Type: new 
Abstract: Various statistical tasks, including sampling or computing Wasserstein barycenters, can be reformulated as fixed-point problems for operators on probability distributions.
  Accelerating standard fixed-point iteration schemes provides a promising novel approach to the design of efficient numerical methods for these problems.
  The Wasserstein geometry on the space of probability measures, although not precisely Riemannian, allows us to define various useful Riemannian notions, such as tangent spaces, exponential maps and parallel transport, motivating the adaptation of Riemannian numerical methods.
  We demonstrate this by developing and implementing the Riemannian Anderson Mixing (RAM) method for Gaussian distributions.
  The method reuses the history of the residuals and improves the iteration complexity, and we argue that the additional costs, compared to Picard method, are negligible.
  We show that certain open balls in the Bures-Wasserstein manifold satisfy the requirements for convergence of RAM.
  The numerical experiments show a significant acceleration compared to a Picard iteration, and performance on par with Riemannian Gradient Descent and Conjugate Gradient methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.22038v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Vitalii Aksenov, Martin Eigel, Mathias Oster</dc:creator>
    </item>
    <item>
      <title>Volt/VAR Optimization in Transmission Networks with Discrete-Control Devices</title>
      <link>https://arxiv.org/abs/2601.22080</link>
      <description>arXiv:2601.22080v1 Announce Type: new 
Abstract: Voltage (Volt) and reactive-power (VAR) control in transmission networks is critical for reliability and increasingly needs fast, implementable decisions. This paper presents a transmission Volt/VAR Optimization (VVO) framework that co-optimizes discrete control of on-load tap-changing transformers (OLTCs) and capacitor banks (CBs) with AC power flow (ACPF) physics to improve voltage stability and minimize VAR generation. The framework follows a relax-round-resolve pipeline: a continuous relaxation proposes targets, a rounding step selects feasible discrete settings, and a final solve enforces AC power flow physics. Extensive experiments on IEEE, PEGASE, and RTE systems show consistent improvements in voltage and VAR quality metrics with modest generator redispatch while preserving economic operation and achieving compatible runtimes with real-time transmission operations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.22080v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuaicheng Tong, Michael A. Boateng, Mathieu Tanneau, Pascal Van Hentenryck</dc:creator>
    </item>
    <item>
      <title>An Invitation to Higher-Order Riemannian Optimization: Optimal and Implementable Methods</title>
      <link>https://arxiv.org/abs/2601.22126</link>
      <description>arXiv:2601.22126v1 Announce Type: new 
Abstract: This paper presents the first optimal-rate $p$-th order methods with $p\geq 1$ for finding first and second-order stationary points of non-convex smooth objective functions over Riemannian manifolds. In contrast to the geodesically convex setting, we definitively establish that the optimal oracle complexity of non-convex optimization over manifolds matches that over Euclidean space. In parallel with the complexity analysis, we introduce a general framework for systematically studying higher-order regularity on Riemannian manifolds that characterizes its joint dependence on the objective function and the chosen retraction. To the best of our knowledge, this framework constitutes the first known application in optimization of pullback connections and the Sasaki metric to the study of retraction-based pullbacks of the objective function. We provide clean derivative bounds based on a new covariant Fa\`a di Bruno formula derived within our framework. For $p=3$, our methods are fully implementable via a new Krylov-based framework for minimizing quartically regularized cubic polynomials. This is the first Krylov method for this class of polynomials and may be of independent interest beyond Riemannian optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.22126v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David Huckleberry Gutman, George Lobo</dc:creator>
    </item>
    <item>
      <title>On Approximate Nash Equilibria in Mean Field Games</title>
      <link>https://arxiv.org/abs/2601.20910</link>
      <description>arXiv:2601.20910v1 Announce Type: cross 
Abstract: In the context of large population symmetric games, approximate Nash equilibria are introduced through equilibrium solutions of the corresponding mean field game in the sense that the individual gain from optimal unilateral deviation under such strategies converges to zero in the large population size asymptotic. We show that these strategies satisfy an $\L^\infty$ notion of approximate Nash equilibrium which guarantees that the individual gain from optimal unilateral deviation is small uniformly among players and uniformly on their initial characteristics. We establish these results in the context of static models and in the dynamic continuous time setting, and we cover situations where the agents' criteria depend on the conditional law of the controlled state process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.20910v1</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mao Fabrice Djete, Nizar Touzi</dc:creator>
    </item>
    <item>
      <title>Monotone Optimisation with Learned Projections</title>
      <link>https://arxiv.org/abs/2601.20983</link>
      <description>arXiv:2601.20983v1 Announce Type: cross 
Abstract: Monotone optimisation problems admit specialised global solvers such as the Polyblock Outer Approximation (POA) algorithm, but these methods typically require explicit objective and constraint functions. In many applications, these functions are only available through data, making POA difficult to apply directly. We introduce an algorithm-aware learning approach that integrates learned models into POA by directly predicting its projection primitive via the radial inverse, avoiding the costly bisection procedure used in standard POA. We propose Homogeneous-Monotone Radial Inverse (HM-RI) networks, structured neural architectures that enforce key monotonicity and homogeneity properties, enabling fast projection estimation. We provide a theoretical characterisation of radial inverse functions and show that, under mild structural conditions, a HM-RI predictor corresponds to the radial inverse of a valid set of monotone constraints. To reduce training overhead, we further develop relaxed monotonicity conditions that remain compatible with POA. Across multiple monotone optimisation benchmarks (indefinite quadratic programming, multiplicative programming, and transmit power optimisation), our approach yields substantial speed-ups in comparison to direct function estimation while maintaining strong solution quality, outperforming baselines that do not exploit monotonic structure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.20983v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ahmed Rashwan, Keith Briggs, Chris Budd, Lisa Kreusser</dc:creator>
    </item>
    <item>
      <title>Solver-in-the-Loop: MDP-Based Benchmarks for Self-Correction and Behavioral Rationality in Operations Research</title>
      <link>https://arxiv.org/abs/2601.21008</link>
      <description>arXiv:2601.21008v1 Announce Type: cross 
Abstract: Operations Research practitioners routinely debug infeasible models through an iterative process: analyzing Irreducible Infeasible Subsystems (\IIS{}), identifying constraint conflicts, and systematically repairing formulations until feasibility is achieved. Yet existing LLM benchmarks evaluate OR as one-shot translation -- given a problem description, generate solver code -- ignoring this diagnostic loop entirely. We introduce two benchmarks that place the \textbf{solver in the evaluation loop}. \textbf{\ORDebug{}} evaluates iterative self-correction through 5,000+ problems spanning 9 error types; each repair action triggers solver re-execution and \IIS{} recomputation, providing deterministic, verifiable feedback. \textbf{\ORBias{}} evaluates behavioral rationality through 2,000 newsvendor instances (1,000 ID + 1,000 OOD), measuring systematic deviations from closed-form optimal policies. Across 26 models and 12,000+ samples, we find that domain-specific RLVR training enables an 8B model to surpass frontier APIs: 95.3\% vs 86.2\% recovery rate (+9.1\%), 62.4\% vs 47.8\% diagnostic accuracy (+14.6\%), and 2.25 vs 3.78 steps to resolution (1.7$\times$ faster). On \ORBias{}, curriculum training achieves the only negative ID$\rightarrow$OOD bias drift among models evaluated (-9.6\%), reducing systematic bias by 48\% (from 20.0\% to 10.4\%). These results demonstrate that process-level evaluation with verifiable oracles enables targeted training that outperforms scale.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21008v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ruicheng Ao, David Simchi-Levi, Xinshang Wang</dc:creator>
    </item>
    <item>
      <title>High-dimensional learning dynamics of multi-pass Stochastic Gradient Descent in multi-index models</title>
      <link>https://arxiv.org/abs/2601.21093</link>
      <description>arXiv:2601.21093v1 Announce Type: cross 
Abstract: We study the learning dynamics of a multi-pass, mini-batch Stochastic Gradient Descent (SGD) procedure for empirical risk minimization in high-dimensional multi-index models with isotropic random data. In an asymptotic regime where the sample size $n$ and data dimension $d$ increase proportionally, for any sub-linear batch size $\kappa \asymp n^\alpha$ where $\alpha \in [0,1)$, and for a commensurate ``critical'' scaling of the learning rate, we provide an asymptotically exact characterization of the coordinate-wise dynamics of SGD. This characterization takes the form of a system of dynamical mean-field equations, driven by a scalar Poisson jump process that represents the asymptotic limit of SGD sampling noise. We develop an analogous characterization of the Stochastic Modified Equation (SME) which provides a Gaussian diffusion approximation to SGD.
  Our analyses imply that the limiting dynamics for SGD are the same for any batch size scaling $\alpha \in [0,1)$, and that under a commensurate scaling of the learning rate, dynamics of SGD, SME, and gradient flow are mutually distinct, with those of SGD and SME coinciding in the special case of a linear model. We recover a known dynamical mean-field characterization of gradient flow in a limit of small learning rate, and of one-pass/online SGD in a limit of increasing sample size $n/d \to \infty$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21093v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhou Fan, Leda Wang</dc:creator>
    </item>
    <item>
      <title>Deep Koopman Iterative Learning and Stability-Guaranteed Control for Unknown Nonlinear Time-Varying Systems</title>
      <link>https://arxiv.org/abs/2601.21230</link>
      <description>arXiv:2601.21230v1 Announce Type: cross 
Abstract: This paper proposes a Koopman-based framework for modeling, prediction, and control of unknown nonlinear time-varying systems. We present a novel Koopman-based learning method for predicting the state of unknown nonlinear time-varying systems, upon which a robust controller is designed to ensure that the resulting closed-loop system is input-to-state stable with respect to the Koopman approximation error. The error of the lifted system model learned through the Koopman-based method increases over time due to the time-varying nature of the nonlinear time-varying system. To address this issue, an online iterative update scheme is incorporated into the learning process to update the lifted system model, aligning it more precisely with the time-varying nonlinear system by integrating the updated data and discarding the outdated data. A necessary condition for the feasibility of the proposed iterative learning method is derived. In order to reduce unnecessary system updates while ensuring the prediction accuracy of the lifted system, the update mechanism is enhanced to determine whether to update the lifted system and meanwhile to reduce updates that deteriorate the fitting performance. Furthermore, based on the online-updated lifted system, a controller is designed to ensure the closed-loop controlled system be input-to-state stable with respect to the Koopman approximation error. Numerical simulations on the Duffing oscillator, the serial manipulator, and the synthetic biological network system are presented to demonstrate the effectiveness of the proposed method for the approximation and control of unknown nonlinear time-varying systems. The results show that the proposed approach outperforms existing methods in terms of approximation accuracy and computational efficiency, even under significant system variations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21230v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Hengde Zhang, Yunxiao Ren, Zhisheng Duan, Zhiyong Sun, Guanrong Chen</dc:creator>
    </item>
    <item>
      <title>Perceptrons and localization of attention's mean-field landscape</title>
      <link>https://arxiv.org/abs/2601.21366</link>
      <description>arXiv:2601.21366v1 Announce Type: cross 
Abstract: The forward pass of a Transformer can be seen as an interacting particle system on the unit sphere: time plays the role of layers, particles that of token embeddings, and the unit sphere idealizes layer normalization. In some weight settings the system can even be seen as a gradient flow for an explicit energy, and one can make sense of the infinite context length (mean-field) limit thanks to Wasserstein gradient flows. In this paper we study the effect of the perceptron block in this setting, and show that critical points are generically atomic and localized on subsets of the sphere.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21366v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Antonio \'Alvarez-L\'opez, Borjan Geshkovski, Dom\`enec Ruiz-Balet</dc:creator>
    </item>
    <item>
      <title>A block-coordinate descent framework for non-convex composite optimization. Application to sparse precision matrix estimation</title>
      <link>https://arxiv.org/abs/2601.21467</link>
      <description>arXiv:2601.21467v1 Announce Type: cross 
Abstract: Block-coordinate descent (BCD) is the method of choice to solve numerous large scale optimization problems, however their theoretical study for non-convex optimization, has received less attention. In this paper, we present a new block-coordinate descent (BCD) framework to tackle non-convex composite optimization problems, ensuring decrease of the objective function and convergence to a solution. This framework is general enough to include variable metric proximal gradient updates, proximal Newton updates, and alternated minimization updates. This generality allows to encompass three versions of the most used solvers in the sparse precision matrix estimation problem, deemed Graphical Lasso: graphical ISTA, Primal GLasso, and QUIC. We demonstrate the value of this new framework on non-convex sparse precision matrix estimation problems, providing convergence guarantees and up to a $100$-fold reduction in the number of iterations required to reach state-of-the-art estimation quality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21467v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guillaume Lauga (LJAD)</dc:creator>
    </item>
    <item>
      <title>PPI-SVRG: Unifying Prediction-Powered Inference and Variance Reduction for Semi-Supervised Optimization</title>
      <link>https://arxiv.org/abs/2601.21470</link>
      <description>arXiv:2601.21470v1 Announce Type: cross 
Abstract: We study semi-supervised stochastic optimization when labeled data is scarce but predictions from pre-trained models are available. PPI and SVRG both reduce variance through control variates -- PPI uses predictions, SVRG uses reference gradients. We show they are mathematically equivalent and develop PPI-SVRG, which combines both. Our convergence bound decomposes into the standard SVRG rate plus an error floor from prediction uncertainty. The rate depends only on loss geometry; predictions affect only the neighborhood size. When predictions are perfect, we recover SVRG exactly. When predictions degrade, convergence remains stable but reaches a larger neighborhood. Experiments confirm the theory: PPI-SVRG reduces MSE by 43--52\% under label scarcity on mean estimation benchmarks and improves test accuracy by 2.7--2.9 percentage points on MNIST with only 10\% labeled data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21470v1</guid>
      <category>cs.LG</category>
      <category>econ.EM</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ruicheng Ao, Hongyu Chen, Haoyang Liu, David Simchi-Levi, Will Wei Sun</dc:creator>
    </item>
    <item>
      <title>Best Arm Identification with LLM Judges and Limited Human</title>
      <link>https://arxiv.org/abs/2601.21471</link>
      <description>arXiv:2601.21471v1 Announce Type: cross 
Abstract: We study fixed-confidence best-arm identification (BAI) where a cheap but potentially biased proxy (e.g., LLM judge) is available for every sample, while an expensive ground-truth label can only be acquired selectively when using a human for auditing. Unlike classical multi-fidelity BAI, the proxy is biased (arm- and context-dependent) and ground truth is selectively observed. Consequently, standard multi-fidelity methods can mis-select the best arm, and uniform auditing, though accurate, wastes scarce resources and is inefficient. We prove that without bias correction and propensity adjustment, mis-selection probability may not vanish (even with unlimited proxy data). We then develop an estimator for the mean of each arm that combines proxy scores with inverse-propensity-weighted residuals and form anytime-valid confidence sequences for that estimator. Based on the estimator and confidence sequence, we propose an algorithm that adaptively selects and audits arms. The algorithm concentrates audits on unreliable contexts and close arms and we prove that a plug-in Neyman rule achieves near-oracle audit efficiency. Numerical experiments confirm the theoretical guarantees and demonstrate the superior empirical performance of the proposed algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21471v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ruicheng Ao, Hongyu Chen, Siyang Gao, Hanwei Li, David Simchi-Levi</dc:creator>
    </item>
    <item>
      <title>Mean-Field Control on Sparse Graphs: From Local Limits to GNNs via Neighborhood Distributions</title>
      <link>https://arxiv.org/abs/2601.21477</link>
      <description>arXiv:2601.21477v1 Announce Type: cross 
Abstract: Mean-field control (MFC) offers a scalable solution to the curse of dimensionality in multi-agent systems but traditionally hinges on the restrictive assumption of exchangeability via dense, all-to-all interactions. In this work, we bridge the gap to real-world network structures by proposing a rigorous framework for MFC on large sparse graphs. We redefine the system state as a probability measure over decorated rooted neighborhoods, effectively capturing local heterogeneity. Our central contribution is a theoretical foundation for scalable reinforcement learning in this setting. We prove horizon-dependent locality: for finite-horizon problems, an agent's optimal policy at time t depends strictly on its (T-t)-hop neighborhood. This result renders the infinite-dimensional control problem tractable and underpins a novel Dynamic Programming Principle (DPP) on the lifted space of neighborhood distributions. Furthermore, we formally and experimentally justify the use of Graph Neural Networks (GNNs) for actor-critic algorithms in this context. Our framework naturally recovers classical MFC as a degenerate case while enabling efficient, theoretically grounded control on complex sparse topologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21477v1</guid>
      <category>cs.MA</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tobias Schmidt, Kai Cui</dc:creator>
    </item>
    <item>
      <title>Strassen's support functionals coincide with the quantum functionals</title>
      <link>https://arxiv.org/abs/2601.21553</link>
      <description>arXiv:2601.21553v1 Announce Type: cross 
Abstract: Strassen's asymptotic spectrum offers a framework for analyzing the complexity of tensors. It has found applications in diverse areas, from computer science to additive combinatorics and quantum information. A long-standing open problem, dating back to 1991, asks whether Strassen's support functionals are universal spectral points, that is, points in the asymptotic spectrum of tensors.
  In this paper, we answer this question in the affirmative by proving that the support functionals coincide with the quantum functionals - universal spectral points that are defined via entropy optimization on entanglement polytopes. We obtain this result as a special case of a general minimax formula for convex optimization on entanglement polytopes (and other moment polytopes) that has further applications to other tensor parameters, including the asymptotic slice rank. Our proof is based on a recent Fenchel-type duality theorem on Hadamard manifolds due to Hirai.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21553v1</guid>
      <category>cs.CC</category>
      <category>math.OC</category>
      <category>quant-ph</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Keiya Sakabe, Mahmut Levent Do\u{g}an, Michael Walter</dc:creator>
    </item>
    <item>
      <title>On the minimum doubly resolving set problem in line graphs</title>
      <link>https://arxiv.org/abs/2601.21580</link>
      <description>arXiv:2601.21580v1 Announce Type: cross 
Abstract: Given a connected graph $G$ with at least three vertices, let $d_G(u,v)$ denote the distance between vertices $u,v\in V(G)$. A subset $S\subseteq V$ is called a doubly resolving set (DRS) of $G$ if for any two distinct vertices $u, v \in V(G)$, there exists a pair $\{x,y\}\subseteq S$ such that $d_G(u,x)-d_G(u,y)\neq d_G(v,x)-d_G(v,y)$. This paper studies the minimum cardinality of a DRS in the line graph of $G$, denoted by $\Psi(L(G))$. First, we prove that computing $\Psi(L(G))$ is NP-hard, even when $G$ is a bipartite graph. Second, we establish that $\lceil \log_2 (1+\Delta(G))\rceil \le \Psi(L(G)) \le |V(G)| - 1$ holds for all $G$ with maximum degree $\Delta(G)$, and show that both inequalities are tight. Finally, we determine the exact value of $\Psi(L(G))$ provided $G$ is a tree.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21580v1</guid>
      <category>math.CO</category>
      <category>math.OC</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qingjie Ye</dc:creator>
    </item>
    <item>
      <title>Solving Hamilton-Jacobi equations by minimizing residuals of monotone discretizations</title>
      <link>https://arxiv.org/abs/2601.21764</link>
      <description>arXiv:2601.21764v1 Announce Type: cross 
Abstract: We derive sufficient conditions under which residual minimization yields well-posed discrete solutions for nonlinear equations defined by monotone finite--difference discretizations. Our analysis is motivated by the challenge of solving fully nonlinear Hamilton--Jacobi (HJ) equations in high dimensions by means of a Neural Network, which is trained by minimizing residuals arising from monotone discretizations of the Hamiltonian. While classical theory ensures that consistency and monotonicity imply convergence to the viscosity solution, treating these discrete systems as optimization problems introduces new analytical hurdles: solvability and the uniqueness of local minima do not follow from monotonicity alone.
  By establishing the well--posedness of these optimization--based solvers, our framework enables the adaptation of Level Set Methods to high--dimensional settings, unlocking new capabilities in applications such as high--dimensional segmentation and interface tracking. Finally, we observe that these arguments extend almost directly to degenerate elliptic or parabolic PDEs on graphs equipped with monotone graph Laplacians.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21764v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Olivier Bokanowski, Carlos Esteve-Yag\"ue, Richard Tsai</dc:creator>
    </item>
    <item>
      <title>Escaping the unit ball</title>
      <link>https://arxiv.org/abs/2601.21867</link>
      <description>arXiv:2601.21867v1 Announce Type: cross 
Abstract: We prove that among all unit-speed paths, a straight line minimises the expected escape time from a ball in $\mathbf{R}^n$, solving the min-mean variant of Bellman's Lost in a Forest problem for ball-shaped forests. The proof uses the Kneser--Poulsen conjecture in the plane, together with results on polygonal chain straightening in higher dimensions. Moreover, we calculate this minimal escape time by deriving the expected linear distance to the boundary of a ball in $n$ dimensions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21867v1</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David Treeby, Edward Wang</dc:creator>
    </item>
    <item>
      <title>Quotient geometry of tensor ring decomposition</title>
      <link>https://arxiv.org/abs/2601.21874</link>
      <description>arXiv:2601.21874v1 Announce Type: cross 
Abstract: Differential geometries derived from tensor decompositions have been extensively studied and provided the foundations for a variety of efficient numerical methods. Despite the practical success of the tensor ring (TR) decomposition, its intrinsic geometry remains less understood, primarily due to the underlying ring structure and the resulting nontrivial gauge invariance. We establish the quotient geometry of TR decomposition by imposing full-rank conditions on all unfolding matrices of the core tensors and capturing the gauge invariance. Additionally, the results can be extended to the uniform TR decomposition, where all core tensors are identical. Numerical experiments validate the developed geometries via tensor ring completion tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21874v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <category>quant-ph</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bin Gao, Renfeng Peng, Ya-xiang Yuan</dc:creator>
    </item>
    <item>
      <title>PRISM: Distribution-free Adaptive Computation of Matrix Functions for Accelerating Neural Network Training</title>
      <link>https://arxiv.org/abs/2601.22137</link>
      <description>arXiv:2601.22137v1 Announce Type: cross 
Abstract: Matrix functions such as square root, inverse roots, and orthogonalization play a central role in preconditioned gradient methods for neural network training. This has motivated the development of iterative algorithms that avoid explicit eigendecompositions and rely primarily on matrix multiplications, making them well suited for modern GPU accelerators. We present PRISM (Polynomial-fitting and Randomized Iterative Sketching for Matrix functions computation), a general framework for accelerating iterative algorithms for computing matrix functions. PRISM combines adaptive polynomial approximation with randomized sketching: at each iteration, it fits a polynomial surrogate to the current spectrum via a sketched least-squares problem, adapting to the instance at hand with minimal overhead. We apply PRISM to accelerate Newton-Schulz-like iterations for matrix square roots and orthogonalization, which are core primitives in machine learning. Unlike prior methods, PRISM requires no explicit spectral bounds or singular value estimates; and it adapts automatically to the evolving spectrum. Empirically, PRISM accelerates training when integrated into Shampoo and Muon optimizers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.22137v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shenghao Yang, Zhichao Wang, Oleg Balabanov, N. Benjamin Erichson, Michael W. Mahoney</dc:creator>
    </item>
    <item>
      <title>Performance bound analysis of linear consensus algorithm on strongly connected graphs using effective resistance and reversiblization</title>
      <link>https://arxiv.org/abs/2502.19720</link>
      <description>arXiv:2502.19720v3 Announce Type: replace 
Abstract: We study the performance of the linear consensus algorithm on strongly connected directed graphs using the linear quadratic (LQ) cost as a performance measure. In particular, we derive bounds on the LQ cost by leveraging effective resistance and reversiblization. Our results extend previous analyses-which were limited to reversible cases-to the nonreversible setting. To facilitate this generalization, we introduce novel concepts, termed the back-and-forth path and the pivot node, which serve as effective alternatives to traditional techniques that require reversibility. Moreover, we apply our approach to Cayley graphs and random geometric graphs to estimate the LQ cost without the reversibility assumption. The proposed approach provides a framework that can be adapted to other contexts where reversibility is typically assumed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.19720v3</guid>
      <category>math.OC</category>
      <category>cs.MA</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Takumi Yonaiyama, Kazuhiro Sato</dc:creator>
    </item>
    <item>
      <title>Bounds for Distributionally Robust Optimization Problems</title>
      <link>https://arxiv.org/abs/2504.06381</link>
      <description>arXiv:2504.06381v3 Announce Type: replace 
Abstract: We study distributionally robust optimization (DRO) problems with uncertainty sets consisting of high-dimensional random vectors that are close in the multivariate Wasserstein distance to a reference random vector. We give conditions when the images of these sets under scalar-valued aggregation functions are contained in and contain uncertainty sets of univariate random variables defined via a univariate Wasserstein distance. This provides lower and upper bounds for the solution to general multivariate DRO problems that are computationally tractable. Furthermore, we generalize the results to uncertainty sets characterized by Bregman-Wasserstein divergences, which allows for asymmetric deviations from the reference random vector. Moreover, for DRO problems with risk measure criterion in the class of signed Choquet integrals, we derive semi-analytic formulae for the upper and lower bounds and the distribution that attains these bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.06381v3</guid>
      <category>math.OC</category>
      <category>q-fin.RM</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Brandon Tam, Silvana M. Pesenti</dc:creator>
    </item>
    <item>
      <title>Nagumo-Type Characterization of Forward Invariance for Constrained Systems</title>
      <link>https://arxiv.org/abs/2508.20045</link>
      <description>arXiv:2508.20045v3 Announce Type: replace 
Abstract: This paper proposes a Nagumo-type invariance condition for differential inclusions defined on closed constraint sets. More specifically, given a closed set to render forward invariant, the proposed condition restricts the system's dynamics, assumed to be locally Lipschitz, on the boundary of the set restricted to the interior of the constraint set. In particular, when the boundary of the set is entirely within the interior of the constraint set, the proposed condition reduces to the well-known Nagumo condition, known to be necessary and sufficient for forward invariance in this case. This being said, the proposed condition is only necessary in the general setting. As a result, we provide a set of additional assumptions relating the constrained system to the set to render forward invariant, and restricting to the geometry at the intersection between the two sets, so that the equivalence holds. The importance of the proposed assumptions is illustrated via examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.20045v3</guid>
      <category>math.OC</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Olayo Reynaud, Mohamed Maghenem, Adnane Saoud, Sadek Belamfedel Alaoui, Ahmad Hably</dc:creator>
    </item>
    <item>
      <title>Bregman Stochastic Proximal Point Algorithm with Variance Reduction</title>
      <link>https://arxiv.org/abs/2510.16655</link>
      <description>arXiv:2510.16655v2 Announce Type: replace 
Abstract: Stochastic algorithms, especially stochastic gradient descent (SGD), have proven to be the go-to methods in data science and machine learning. In recent years, the stochastic proximal point algorithm (SPPA) emerged, and it was shown to be more robust than SGD with respect to stepsize settings. However, SPPA still suffers from a decreased convergence rate due to the need for vanishing stepsizes, which is resolved by using variance reduction methods. In the deterministic setting, there are many problems that can be solved more efficiently when viewing them in a non-Euclidean geometry using Bregman distances. This paper combines these two worlds and proposes variance reduction techniques for the Bregman stochastic proximal point algorithm (BSPPA). As special cases, we obtain SAGA- and SVRG-like variance reduction techniques for BSPPA. Our theoretical and numerical results demonstrate improved stability and convergence rates compared to the vanilla BSPPA with constant and vanishing stepsizes, respectively. Our analysis, also, allow to recover the same variance reduction techniques for Bregman SGD in a unified way.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.16655v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Cheik Traor\'e, Peter Ochs</dc:creator>
    </item>
    <item>
      <title>Neural Policy Composition from Free Energy Minimization</title>
      <link>https://arxiv.org/abs/2512.04745</link>
      <description>arXiv:2512.04745v2 Announce Type: replace 
Abstract: The ability to compose acquired skills to plan and execute behaviors is a hallmark of natural intelligence. Yet, despite remarkable cross-disciplinary efforts, a principled account of how task structure shapes gating and how such computations could be delivered in neural circuits, remains elusive. Here we introduce GateMod, an interpretable theoretically grounded computational model linking the emergence of gating to the underlying decision-making task, and to a neural circuit architecture. We first develop GateFrame, a normative framework casting policy gating into the minimization of the free energy. This framework, relating gating rules to task, applies broadly across neuroscience, cognitive and computational sciences. We then derive GateFlow, a continuous-time energy based dynamics that provably converges to GateFrame optimal solution. Convergence, exponential and global, follows from a contractivity property that also yields robustness and other desirable properties. Finally, we derive a neural circuit from GateFlow, GateNet. This is a soft-competitive recurrent circuit whose components perform local and contextual computations consistent with known dendritic and neural processing motifs. We evaluate GateMod across two different settings: collective behaviors in multi-agent systems and human decision-making in multi-armed bandits. In all settings, GateMod provides interpretable mechanistic explanations of gating and quantitatively matches or outperforms established models. GateMod offers a unifying framework for neural policy gating, linking task objectives, dynamical computation, and circuit-level mechanisms. It provides a framework to understand gating in natural agents beyond current explanations and to equip machines with this ability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.04745v2</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>nlin.AO</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Francesca Rossi, Veronica Centorrino, Francesco Bullo, Giovanni Russo</dc:creator>
    </item>
    <item>
      <title>Differentiable Integer Linear Programming is not Differentiable &amp; it's not a mere technical problem</title>
      <link>https://arxiv.org/abs/2601.17800</link>
      <description>arXiv:2601.17800v2 Announce Type: replace 
Abstract: We show how the differentiability method employed in the paper ``Differentiable Integer Linear Programming'', Geng, et al., 2025 as shown in its theorem 5 is incorrect. Moreover, there already exists some downstream work that inherits the same error. The underlying reason comes from that, though being continuous in expectation, the surrogate loss is discontinuous in almost every realization of the randomness, for the stochastic gradient descent.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.17800v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Thanawat Sornwanee</dc:creator>
    </item>
    <item>
      <title>Improved Convergence Rates of Muon Optimizer for Nonconvex Optimization</title>
      <link>https://arxiv.org/abs/2601.19400</link>
      <description>arXiv:2601.19400v2 Announce Type: replace 
Abstract: The Muon optimizer has recently attracted attention due to its orthogonalized first-order updates, and a deeper theoretical understanding of its convergence behavior is essential for guiding practical applications; however, existing convergence guarantees are either coarse or obtained under restrictive analytical settings. In this work, we establish sharper convergence guarantees for the Muon optimizer through a direct and simplified analysis that does not rely on restrictive assumptions on the update rule. Our results improve upon existing bounds by achieving faster convergence rates while covering a broader class of problem settings. These findings provide a more accurate theoretical characterization of Muon and offer insights applicable to a broader class of orthogonalized first-order methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.19400v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuntaro Nagashima, Hideaki Iiduka</dc:creator>
    </item>
    <item>
      <title>Convergence Analysis of Randomized Subspace Normalized SGD under Heavy-Tailed Noise</title>
      <link>https://arxiv.org/abs/2601.20399</link>
      <description>arXiv:2601.20399v2 Announce Type: replace 
Abstract: Randomized subspace methods reduce per-iteration cost; however, in nonconvex optimization, most analyses are expectation-based, and high-probability bounds remain scarce even under sub-Gaussian noise. We first prove that randomized subspace SGD (RS-SGD) admits a high-probability convergence bound under sub-Gaussian noise, achieving the same order of oracle complexity as prior in-expectation results. Motivated by the prevalence of heavy-tailed gradients in modern machine learning, we then propose randomized subspace normalized SGD (RS-NSGD), which integrates direction normalization into subspace updates. Assuming the noise has bounded $p$-th moments, we establish both in-expectation and high-probability convergence guarantees, and show that RS-NSGD can achieve better oracle complexity than full-dimensional normalized SGD.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.20399v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gaku Omiya, Pierre-Louis Poirion, Akiko Takeda</dc:creator>
    </item>
    <item>
      <title>Divergence Results and Convergence of a Variance Reduced Version of ADAM</title>
      <link>https://arxiv.org/abs/2210.05607</link>
      <description>arXiv:2210.05607v2 Announce Type: replace-cross 
Abstract: Stochastic optimization algorithms using exponential moving averages of the past gradients, such as ADAM, RMSProp and AdaGrad, have been having great successes in many applications, especially in training deep neural networks. ADAM in particular stands out as efficient and robust. Despite of its outstanding performance, ADAM has been proved to be divergent for some specific problems. We revisit the divergent question and provide divergent examples under stronger conditions such as in expectation or high probability. Under a variance reduction assumption, we show that an ADAM-type algorithm converges, which means that it is the variance of gradients that causes the divergence of original ADAM. To this end, we propose a variance reduced version of ADAM and provide a convergent analysis of the algorithm. Numerical experiments show that the proposed algorithm has as good performance as ADAM. Our work suggests a new direction for fixing the convergence issues.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.05607v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ruiqi Wang, Diego Klabjan</dc:creator>
    </item>
    <item>
      <title>Harmonizing Safety and Speed: A Human-Algorithm Approach to Enhance the FDA's Medical Device Clearance Policy</title>
      <link>https://arxiv.org/abs/2407.11823</link>
      <description>arXiv:2407.11823v3 Announce Type: replace-cross 
Abstract: The United States Food and Drug Administration's (FDA's) 510(k) pathway allows manufacturers to gain medical device approval by demonstrating substantial equivalence to a legally marketed device. However, the inherent ambiguity of this regulatory procedure has been associated with high recall among many devices cleared through this pathway, raising significant safety concerns. In this paper, we develop a combined human-algorithm approach to assist the FDA in improving its 510(k) medical device clearance process by reducing recall risk and regulatory workload. We first develop machine learning methods to estimate the risk of recall of 510(k) medical devices based on the information available at the time of submission. We then propose a data-driven clearance policy that recommends acceptance, rejection, or deferral to FDA's committees for in-depth evaluation. We conduct an empirical study using a unique dataset of over 31,000 submissions that we assembled based on data sources from the FDA and Centers for Medicare and Medicaid Service (CMS). Compared to the FDA's current practice, which has a recall rate of 10.3% and a normalized workload measure of 100%, a conservative evaluation of our policy shows a 32.9% improvement in the recall rate and a 40.5% reduction in the workload. Our analyses further suggest annual cost savings of approximately $1.7 billion for the healthcare system driven by avoided replacement costs, which is equivalent to 1.1% of the entire United States annual medical device expenditure. Our findings highlight the value of a holistic and data-driven approach to improve the FDA's current 510(k) pathway.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.11823v3</guid>
      <category>cs.LG</category>
      <category>cs.HC</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohammad Zhalechian, Soroush Saghafian, Omar Robles</dc:creator>
    </item>
    <item>
      <title>Representative Action Selection for Large Action Space Bandit Families</title>
      <link>https://arxiv.org/abs/2505.18269</link>
      <description>arXiv:2505.18269v4 Announce Type: replace-cross 
Abstract: We study the problem of selecting a subset from a large action space shared by a family of bandits, with the goal of achieving performance nearly matching that of using the full action space. Indeed, in many natural situations, while the nominal set of actions may be large, there also exist significant correlations between the rewards of different actions. In this paper we propose an algorithm that can significantly reduce the action space when such correlations are present, without the need to a-priori know the correlation structure. We provide theoretical guarantees on the performance of the algorithm and demonstrate its practical effectiveness through empirical comparisons with Thompson Sampling and Upper Confidence Bound methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18269v4</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Quan Zhou, Mark Kozdoba, Shie Mannor</dc:creator>
    </item>
    <item>
      <title>Delayed Momentum Aggregation: Communication-efficient Byzantine-robust Federated Learning with Partial Participation</title>
      <link>https://arxiv.org/abs/2509.02970</link>
      <description>arXiv:2509.02970v2 Announce Type: replace-cross 
Abstract: Partial participation is essential for communication-efficient federated learning at scale, yet existing Byzantine-robust methods typically assume full client participation. In the partial participation setting, a majority of the sampled clients may be Byzantine, once Byzantine clients dominate, existing methods break down immediately. We introduce delayed momentum aggregation, a principle where the central server aggregates cached momentum from non-sampled clients along with fresh momentum from sampled clients. This principle ensures Byzantine clients remain a minority from the server's perspective even when they dominate the sampled set. We instantiate this principle in our optimizer DeMoA. We analyze the convergence rate of DeMoA, showing that DeMoA is Byzantine-robust under partial participation. Experiments show that, with 20% Byzantine ratio and only 10% partial participation rate, DeMoA achieves the best accuracy even when existing methods fail empirically.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.02970v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kaoru Otsuka, Yuki Takezawa, Makoto Yamada</dc:creator>
    </item>
    <item>
      <title>Resolvent Compositions for Positive Linear Operators</title>
      <link>https://arxiv.org/abs/2509.07251</link>
      <description>arXiv:2509.07251v4 Announce Type: replace-cross 
Abstract: Resolvent compositions were recently introduced as monotonicity-preserving operations that combine a set-valued monotone operator and a bounded linear operator. They generalize in particular the notion of a resolvent average. We analyze the resolvent compositions when the monotone operator is a positive linear operator. We establish several new properties, including L\"owner partial order relations, concavity, and asymptotic behavior. In addition, we show that the resolvent composition operations are nonexpansive with respect to the Thompson metric. We also introduce a new form of geometric interpolation and explore its connections to resolvent compositions. Finally, we study two nonlinear equations based on resolvent compositions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.07251v4</guid>
      <category>math.FA</category>
      <category>math.OC</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Diego J. Cornejo</dc:creator>
    </item>
    <item>
      <title>Convergence of Stochastic Gradient Langevin Dynamics in the Lazy Training Regime</title>
      <link>https://arxiv.org/abs/2510.21245</link>
      <description>arXiv:2510.21245v3 Announce Type: replace-cross 
Abstract: Continuous-time models provide important insights into the training dynamics of optimization algorithms in deep learning. In this work, we establish a non-asymptotic convergence analysis of stochastic gradient Langevin dynamics (SGLD), which is an It\^o stochastic differential equation (SDE) approximation of stochastic gradient descent in continuous time, in the lazy training regime. We show that, under regularity conditions on the Hessian of the loss function, SGLD with multiplicative and state-dependent noise (i) yields a non-degenerate kernel throughout the training process with high probability, and (ii) achieves exponential convergence to the empirical risk minimizer in expectation, and we establish finite-time and finite-width bounds on the optimality gap. We corroborate our theoretical findings with numerical examples in the regression setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21245v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Noah Oberweis, Semih Cayci</dc:creator>
    </item>
    <item>
      <title>What the flock knows that the birds do not: exploring the emergence of joint agency in multi-agent active inference</title>
      <link>https://arxiv.org/abs/2511.10835</link>
      <description>arXiv:2511.10835v2 Announce Type: replace-cross 
Abstract: Collective behavior pervades biological systems, from flocks of birds to neural assemblies and human societies. Yet, how such collectives acquire functional properties -- such as joint agency or knowledge -- that transcend those of their individual components remains an open question. Here, we combine active inference and information-theoretic analyses to explore how a minimal system of interacting agents can give rise to joint agency and collective knowledge. We model flocking dynamics using multiple active inference agents, each minimizing its own free energy while coupling reciprocally with its neighbors. We show that as agents self-organize, their interactions define higher-order statistical boundaries (Markov blankets) enclosing a ``flock'' that can be treated as an emergent agent with its own sensory, active, and internal states. When exposed to external perturbations (a ``predator''), the flock exhibits faster, coordinated responses than individual agents, reflecting collective sensitivity to environmental change. Crucially, analyses of synergistic information reveal that the flock encodes information about the predator's location that is not accessible to every individual bird, demonstrating implicit collective knowledge. Together, these results show how informational coupling among active inference agents can generate new levels of autonomy and inference, providing a framework for understanding the emergence of (implicit) collective knowledge and joint agency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.10835v2</guid>
      <category>nlin.AO</category>
      <category>cs.MA</category>
      <category>math.OC</category>
      <category>q-bio.NC</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Domenico Maisto, Davide Nuzzi, Giovanni Pezzulo</dc:creator>
    </item>
    <item>
      <title>On the Provable Suboptimality of Momentum SGD in Nonstationary Stochastic Optimization</title>
      <link>https://arxiv.org/abs/2601.12238</link>
      <description>arXiv:2601.12238v3 Announce Type: replace-cross 
Abstract: In this paper, we provide a comprehensive theoretical analysis of Stochastic Gradient Descent (SGD) and its momentum variants (Polyak Heavy-Ball and Nesterov) for tracking time-varying optima under strong convexity and smoothness. Our finite-time bounds reveal a sharp decomposition of tracking error into transient, noise-induced, and drift-induced components. This decomposition exposes a fundamental trade-off: while momentum is often used as a gradient-smoothing heuristic, under distribution shift it incurs an explicit drift-amplification penalty that diverges as the momentum parameter $\beta$ approaches 1, yielding systematic tracking lag. We complement these upper bounds with minimax lower bounds under gradient-variation constraints, proving this momentum-induced tracking penalty is not an analytical artifact but an information-theoretic barrier: in drift-dominated regimes, momentum is unavoidably worse because stale-gradient averaging forces systematic lag. Our results provide theoretical grounding for the empirical instability of momentum in dynamic settings and precisely delineate regime boundaries where vanilla SGD provably outperforms its accelerated counterparts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.12238v3</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sharan Sahu, Cameron J. Hogan, Martin T. Wells</dc:creator>
    </item>
    <item>
      <title>Model-Free Output Feedback Stabilization via Policy Gradient Methods</title>
      <link>https://arxiv.org/abs/2601.19284</link>
      <description>arXiv:2601.19284v2 Announce Type: replace-cross 
Abstract: Stabilizing a dynamical system is a fundamental problem that serves as a cornerstone for many complex tasks in the field of control systems. The problem becomes challenging when the system model is unknown. Among the Reinforcement Learning (RL) algorithms that have been successfully applied to solve problems pertaining to unknown linear dynamical systems, the policy gradient (PG) method stands out due to its ease of implementation and can solve the problem in a model-free manner. However, most of the existing works on PG methods for unknown linear dynamical systems assume full-state feedback. In this paper, we take a step towards model-free learning for partially observable linear dynamical systems with output feedback and focus on the fundamental stabilization problem of the system. We propose an algorithmic framework that stretches the boundary of PG methods to the problem without global convergence guarantees. We show that by leveraging zeroth-order PG update based on system trajectories and its convergence to stationary points, the proposed algorithms return a stabilizing output feedback policy for discrete-time linear dynamical systems. We also explicitly characterize the sample complexity of our algorithm and verify the effectiveness of the algorithm using numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.19284v2</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ankang Zhang, Ming Chi, Xiaoling Wang, Lintao Ye</dc:creator>
    </item>
  </channel>
</rss>
