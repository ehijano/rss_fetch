<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 05 Jun 2024 01:54:58 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 04 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>$\epsilon$-Optimally Solving Zero-Sum POSGs</title>
      <link>https://arxiv.org/abs/2406.00054</link>
      <description>arXiv:2406.00054v1 Announce Type: new 
Abstract: A recent method for solving zero-sum partially observable stochastic games (zs-POSGs) embeds the original game into a new one called the occupancy Markov game. This reformulation allows applying Bellman's principle of optimality to solve zs-POSGs. However, improving a current solution requires solving a linear program with exponentially many potential constraints, which significantly restricts the scalability of this approach. This paper exploits the optimal value function's novel uniform continuity properties to overcome this limitation. We first construct a new operator that is computationally more efficient than the state-of-the-art update rules without compromising optimality. In particular, improving a current solution now involves a linear program with an exponential drop in constraints. We then also show that point-based value iteration algorithms utilizing our findings improve the scalability of existing methods while maintaining guarantees in various domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00054v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Erwan Escudie, Matthia Sabatelli, Jilles Dibangoye</dc:creator>
    </item>
    <item>
      <title>Fair Allocation in Dynamic Mechanism Design</title>
      <link>https://arxiv.org/abs/2406.00147</link>
      <description>arXiv:2406.00147v1 Announce Type: new 
Abstract: We consider a dynamic mechanism design problem where an auctioneer sells an indivisible good to two groups of buyers in every round, for a total of $T$ rounds. The auctioneer aims to maximize their discounted overall revenue while adhering to a fairness constraint that guarantees a minimum average allocation for each group. We begin by studying the static case ($T=1$) and establish that the optimal mechanism involves two types of subsidization: one that increases the overall probability of allocation to all buyers, and another that favors the group which otherwise has a lower probability of winning the item. We then extend our results to the dynamic case by characterizing a set of recursive functions that determine the optimal allocation and payments in each round. Notably, our results establish that in the dynamic case, the seller, on the one hand, commits to a participation reward to incentivize truth-telling, and on the other hand, charges an entry fee for every round. Moreover, the optimal allocation once more involves subsidization in favor of one group, where the extent of subsidization depends on the difference in future utilities for both the seller and buyers when allocating the item to one group versus the other. Finally, we present an approximation scheme to solve the recursive equations and determine an approximately optimal and fair allocation efficiently.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00147v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>econ.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alireza Fallah, Michael I. Jordan, Annie Ulichney</dc:creator>
    </item>
    <item>
      <title>Robustness of Online Proportional Response in Stochastic Online Fisher Markets: a Decentralized Approach</title>
      <link>https://arxiv.org/abs/2406.00160</link>
      <description>arXiv:2406.00160v1 Announce Type: new 
Abstract: This study is focused on periodic Fisher markets where items with time-dependent and stochastic values are regularly replenished and buyers aim to maximize their utilities by spending budgets on these items. Traditional approaches of finding a market equilibrium in the single-period Fisher market rely on complete information about buyers' utility functions and budgets. However, it is impractical to consistently enforce buyers to disclose this private information in a periodic setting. We introduce a distributed auction algorithm, online proportional response, wherein buyers update bids solely based on the randomly fluctuating values of items in each period. The market then allocates items based on the bids provided by the buyers. Utilizing the known Shmyrev convex program that characterizes market equilibrium of a Fisher market, two performance metrics are proposed: the fairness regret is the cumulative difference in the objective value of a stochastic Shmyrev convex program between an online algorithm and an offline optimum, and the individual buyer's regret gauges the deviation in terms of utility for each buyer between the online algorithm and the offline optimum. Our algorithm attains a problem-dependent upper bound contingent on the number of items and buyers under stationary inputs in fairness regret. Additionally, we conduct analysis of regret under various non-stationary stochastic input models to demonstrate the algorithm's efficiency across diverse scenarios. The online proportional response algorithm addresses privacy concerns by allowing buyers to update bids without revealing sensitive information and ensures decentralized decision-making, fostering autonomy and potential improvements in buyer satisfaction. Furthermore, our algorithm is universally applicable to many worlds and shows the robust performance guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00160v1</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yongge Yang, Yu-Ching Lee, Po-An Chen, Chuang-Chieh Lin</dc:creator>
    </item>
    <item>
      <title>Matroid Bayesian Online Selection</title>
      <link>https://arxiv.org/abs/2406.00224</link>
      <description>arXiv:2406.00224v1 Announce Type: new 
Abstract: We study a class of Bayesian online selection problems with matroid constraints. Consider a vendor who has several items to sell, with the set of sold items being subject to some structural constraints, e.g., the set of sold items should be independent with respect to some matroid. Each item has an offer value drawn independently from a known distribution. Given distribution information for each item, the vendor wishes to maximize their expected revenue by carefully choosing which offers to accept as they arrive.
  Such problems have been studied extensively when the vendor's revenue is compared with the offline optimum, referred to as the "prophet". In this setting, a tight 2-competitive algorithm is known when the vendor is limited to selling independent sets from a matroid [Kleinberg and Weinberg, 2012]. We turn our attention to the online optimum, or "philosopher", and ask how well the vendor can do with polynomial-time computation, compared to a vendor with unlimited computation but with the same limited distribution information about offers.
  We show that when the underlying constraints are laminar and the arrival of buyers follows a natural "left-to-right" order, there is a Polynomial-Time Approximation Scheme for maximizing the vendor's revenue. We also show that such a result is impossible for the related case when the underlying constraints correspond to a graphic matroid. In particular, it is $\texttt{PSPACE}$-hard to approximate the philosopher's expected revenue to some fixed constant $\alpha &lt; 1$; moreover, this cannot be alleviated by requirements on the arrival order in the case of graphic matroids.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00224v1</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ian DeHaan, Kanstantsin Pashkovich</dc:creator>
    </item>
    <item>
      <title>On Network Congestion Reduction Using Public Signals Under Boundedly Rational User Equilibria (Full Version)</title>
      <link>https://arxiv.org/abs/2406.00295</link>
      <description>arXiv:2406.00295v1 Announce Type: new 
Abstract: Boundedly Rational User Equilibria (BRUE) capture situations where all agents on a transportation network are electing the fastest option up to some time indifference, and serve as a relaxation of User Equilibria (UE), where each agent exactly minimizes their travel time. We study how the social cost under BRUE departs from that of UE in the context of static demand and stochastic costs, along with the implications of BRUE on the optimal signaling scheme of a benevolent central planner. We show that the average excess time is sublinear in the maximum time indifference of the agents, though such aggregate may hide disparity between populations and the sublinearity constant depends on the topology of the network. Regarding the design of public signals, even though in the limit where agents are totally indifferent, it is optimal to not reveal any information, there is in general no trend in how much information is optimally disclosed to agents. What is more, an increase in information disclosed may either harm or benefit agents as a whole.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00295v1</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Olivier Massicot, C\'edric Langbort</dc:creator>
    </item>
    <item>
      <title>A memory-based spatial evolutionary game with the dynamic interaction between learners and profiteers</title>
      <link>https://arxiv.org/abs/2406.00662</link>
      <description>arXiv:2406.00662v1 Announce Type: new 
Abstract: Spatial evolutionary games provide a valuable framework for elucidating the emergence and maintenance of cooperative behavior. However, most previous studies assume that individuals are profiteers and neglect to consider the effects of memory. To bridge this gap, in this paper, we propose a memory-based spatial evolutionary game with dynamic interaction between learners and profiteers. Specifically, there are two different categories of individuals in the network, including profiteers and learners with different strategy updating rules. Notably, there is a dynamic interaction between profiteers and learners, i.e., each individual has the transition probability between profiteers and learners, which is portrayed by a Markov process. Besides, the payoff of each individual is not only determined by a single round of the game but also depends on the memory mechanism of the individual. Extensive numerical simulations validate the theoretical analysis and uncover that dynamic interactions between profiteers and learners foster cooperation, memory mechanisms facilitate the emergence of cooperative behaviors among profiteers, and increasing the learning rate of learners promotes a rise in the number of cooperators. In addition, the robustness of the model is verified through simulations across various network sizes. Overall, this work contributes to a deeper understanding of the mechanisms driving the formation and evolution of cooperation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00662v1</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1063/5.0215761</arxiv:DOI>
      <dc:creator>Bin Pi, Minyu Feng, Liang-Jian Deng</dc:creator>
    </item>
    <item>
      <title>Sample Complexity of Posted Pricing for a Single Item</title>
      <link>https://arxiv.org/abs/2406.00819</link>
      <description>arXiv:2406.00819v1 Announce Type: new 
Abstract: Selling a single item to $n$ self-interested buyers is a fundamental problem in economics, where the two objectives typically considered are welfare maximization and revenue maximization. Since the optimal mechanisms are often impractical and do not work for sequential buyers, posted pricing mechanisms, where fixed prices are set for the item for different buyers, have emerged as a practical and effective alternative. This paper investigates how many samples are needed from buyers' value distributions to find near-optimal posted prices, considering both independent and correlated buyer distributions, and welfare versus revenue maximization. We obtain matching upper and lower bounds (up to logarithmic factors) on the sample complexity for all these settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00819v1</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Billy Jin, Thomas Kesselheim, Will Ma, Sahil Singla</dc:creator>
    </item>
    <item>
      <title>Computing Optimal Equilibria in Repeated Games with Restarts</title>
      <link>https://arxiv.org/abs/2406.00851</link>
      <description>arXiv:2406.00851v1 Announce Type: new 
Abstract: Infinitely repeated games can support cooperative outcomes that are not equilibria in the one-shot game. The idea is to make sure that any gains from deviating will be offset by retaliation in future rounds. However, this model of cooperation fails in anonymous settings with many strategic agents that interact in pairs. Here, a player can defect and then avoid penalization by immediately switching partners. In this paper, we focus on a specific set of equilibria that avoids this pitfall. In them, agents follow a designated sequence of actions, and restart if their opponent ever deviates. We show that the socially-optimal sequence of actions consists of an infinitely repeating goal value, preceded by a hazing period. We introduce an equivalence relation on sequences and prove that the computational problem of finding a representative from the optimal equivalence class is (weakly) NP-hard. Nevertheless, we present a pseudo-polynomial time dynamic program for this problem, as well as an integer linear program, and show they are efficient in practice. Lastly, we introduce a fully polynomial-time approximation scheme that outputs a hazing sequence with arbitrarily small approximation ratio.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00851v1</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ratip Emin Berker, Vincent Conitzer</dc:creator>
    </item>
    <item>
      <title>The Surprising Effectiveness of SP Voting with Partial Preferences</title>
      <link>https://arxiv.org/abs/2406.00870</link>
      <description>arXiv:2406.00870v1 Announce Type: new 
Abstract: We consider the problem of recovering the ground truth ordering (ranking, top-$k$, or others) over a large number of alternatives. The wisdom of crowd is a heuristic approach based on Condorcet's Jury theorem to address this problem through collective opinions. This approach fails to recover the ground truth when the majority of the crowd is misinformed. The surprisingly popular (SP) algorithm cite{prelec2017solution} is an alternative approach that is able to recover the ground truth even when experts are in minority. The SP algorithm requires the voters to predict other voters' report in the form of a full probability distribution over all rankings of alternatives. However, when the number of alternatives, $m$, is large, eliciting the prediction report or even the vote over $m$ alternatives might be too costly. In this paper, we design a scalable alternative of the SP algorithm which only requires eliciting partial preferences from the voters, and propose new variants of the SP algorithm. In particular, we propose two versions -- Aggregated-SP and Partial-SP -- that ask voters to report vote and prediction on a subset of size $k$ ($\ll m$) in terms of top alternative, partial rank, or an approval set. Through a large-scale crowdsourcing experiment on MTurk, we show that both of our approaches outperform conventional preference aggregation algorithms for the recovery of ground truth rankings, when measured in terms of Kendall-Tau distance and Spearman's $\rho$. We further analyze the collected data and demonstrate that voters' behavior in the experiment, including the minority of the experts, and the SP phenomenon, can be correctly simulated by a concentric mixtures of Mallows model. Finally, we provide theoretical bounds on the sample complexity of SP algorithms with partial rankings to demonstrate the theoretical guarantees of the proposed methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00870v1</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hadi Hosseini, Debmalya Mandal, Amrit Puhan</dc:creator>
    </item>
    <item>
      <title>Boosting Sortition via Proportional Representation</title>
      <link>https://arxiv.org/abs/2406.00913</link>
      <description>arXiv:2406.00913v1 Announce Type: new 
Abstract: Sortition is based on the idea of choosing randomly selected representatives for decision making. The main properties that make sortition particularly appealing are fairness -- all the citizens can be selected with the same probability -- and proportional representation -- a randomly selected panel probably reflects the composition of the whole population. When a population lies on a representation metric, we formally define proportional representation by using a notion called the core. A panel is in the core if no group of individuals is underrepresented proportional to its size. While uniform selection is fair, it does not always return panels that are in the core. Thus, we ask if we can design a selection algorithm that satisfies fairness and ex post core simultaneously. We answer this question affirmatively and present an efficient selection algorithm that is fair and provides a constant-factor approximation to the optimal ex post core. Moreover, we show that uniformly random selection satisfies a constant-factor approximation to the optimal ex ante core. We complement our theoretical results by conducting experiments with real data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00913v1</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Soroush Ebadian, Evi Micha</dc:creator>
    </item>
    <item>
      <title>Stability in Random Hedonic Games</title>
      <link>https://arxiv.org/abs/2406.01373</link>
      <description>arXiv:2406.01373v1 Announce Type: new 
Abstract: Partitioning a large group of employees into teams can prove difficult because unsatisfied employees may want to transfer to other teams. In this case, the team (coalition) formation is unstable and incentivizes deviation from the proposed structure. Such a coalition formation scenario can be modeled in the framework of hedonic games and a significant amount of research has been devoted to the study of stability in such games. Unfortunately, stable coalition structures are not guaranteed to exist in general and their practicality is further hindered by computational hardness barriers. We offer a new perspective on this matter by studying a random model of hedonic games. For three prominent stability concepts based on single-agent deviations, we provide a high probability analysis of stability in the large agent limit.
  Our first main result is an efficient algorithm that outputs an individually and contractually Nash-stable partition with high probability. Our second main result is that the probability that a random game admits a Nash-stable partition tends to zero. Our approach resolves the two major downsides associated with individual stability and contractual Nash stability and reveals agents acting single-handedly are usually to blame for instabilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01373v1</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Martin Bullinger, Sonja Kraiczy</dc:creator>
    </item>
    <item>
      <title>Structural and algorithmic results for stable cycles and partitions in the Roommates problem</title>
      <link>https://arxiv.org/abs/2406.00437</link>
      <description>arXiv:2406.00437v1 Announce Type: cross 
Abstract: An instance of the Stable Roommates problem involves a set of agents, each with ordinal preferences over the others. We seek a stable matching, in which no two agents have an incentive to deviate from their assignment. It is well known that a stable matching is unlikely to exist for instances with a large number of agents. However, stable partitions always exist and provide a succinct certificate for the unsolvability of an instance, although their significance extends beyond this. They are also a useful structural tool to study the problem and correspond to half-matchings in which the agents are in a stable equilibrium.
  In this paper, we investigate the stable partition structure further and show how to efficiently enumerate all stable partitions and the cycles included in such structures. Furthermore, we adapt known fairness and optimality criteria from stable matchings to stable partitions. As there can be an exponential number of stable partitions, we investigate the complexity of computing different "fair" and "optimal" stable partitions directly. While a minimum-regret stable partition always exists and can be computed in linear time, we prove the NP-hardness of finding five other kinds of stable partitions that are "optimal" regarding their profile (measuring the number of first, second, third, etc., choices assigned). Furthermore, we give 2-approximation algorithms for two of the optimal stable partition problems and show the inapproximability within any constant factor for another.
  Through this research, we contribute to a deeper understanding of stable partitions from a combinatorial and complexity point of view, closing the gap between integral and fractional stable matchings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00437v1</guid>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Frederik Glitzner, David Manlove</dc:creator>
    </item>
    <item>
      <title>Strategic Linear Contextual Bandits</title>
      <link>https://arxiv.org/abs/2406.00551</link>
      <description>arXiv:2406.00551v1 Announce Type: cross 
Abstract: Motivated by the phenomenon of strategic agents gaming a recommender system to maximize the number of times they are recommended to users, we study a strategic variant of the linear contextual bandit problem, where the arms can strategically misreport their privately observed contexts to the learner. We treat the algorithm design problem as one of mechanism design under uncertainty and propose the Optimistic Grim Trigger Mechanism (OptGTM) that incentivizes the agents (i.e., arms) to report their contexts truthfully while simultaneously minimizing regret. We also show that failing to account for the strategic nature of the agents results in linear regret. However, a trade-off between mechanism design and regret minimization appears to be unavoidable. More broadly, this work aims to provide insight into the intersection of online learning and mechanism design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00551v1</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas Kleine Buening, Aadirupa Saha, Christos Dimitrakakis, Haifeng Xu</dc:creator>
    </item>
    <item>
      <title>Evaluating and Managing Tokenomics for Non-Fungible Tokens in Game-Based Blockchain Networks</title>
      <link>https://arxiv.org/abs/2306.13672</link>
      <description>arXiv:2306.13672v3 Announce Type: replace 
Abstract: Non-fungible tokens (NFTs) are becoming increasingly popular in Play-to-Earn (P2E) Web3 applications as a means of incentivizing user engagement. In Web3, users with NFTs ownership are entitled to monetize them. However, due to lack of objective NFT valuation, which makes NFT value determination challenging, P2E applications ecosystems have experienced inflation. In this paper, we propose a method that enables NFT inflation value management in P2E applications. Our method leverages the contribution-rewards model proposed by Curve Finance and the automated market maker (AMM) of decentralized exchanges. In decentralized systems, P2E Web3 applications inclusive, not all participants contribute in good faith. Therefore, rewards are provided to incentivize contribution. Our mechanism proves that burning NFTs, indicating the permanent removal of NFTs, contributes to managing inflation by reducing the number of NFTs in circulation. As a reward for this contribution, our method mints a compensation (CP) token as an ERC-20 token, which can be exchanged for NFTs once enough tokens have been accumulated. To further increase the value of the CP token, we suggest using governance tokens and CP tokens to create liquidity pools for AMM. The value of the governance token is determined by the market, and the CP token derives its value from the governance token in AMM. The CP token can determine its worth based on the market value of the governance token. Additionally, since CP tokens are used for exchanging NFTs, the value of the NFT is ultimately determined by the value of the CP token. To further illustrate our concept, we show how to adjust burning rewards based on factors such as the probability of upgrading NFTs' rarity or the current swap ratio of governance and CP tokens in AMM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.13672v3</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Hyoungsung Kim, Hyun-Sik Kim, Yong-Suk Park</dc:creator>
    </item>
    <item>
      <title>Learning Optimal Contracts: How to Exploit Small Action Spaces</title>
      <link>https://arxiv.org/abs/2309.09801</link>
      <description>arXiv:2309.09801v3 Announce Type: replace 
Abstract: We study principal-agent problems in which a principal commits to an outcome-dependent payment scheme -- called contract -- in order to induce an agent to take a costly, unobservable action leading to favorable outcomes. We consider a generalization of the classical (single-round) version of the problem in which the principal interacts with the agent by committing to contracts over multiple rounds. The principal has no information about the agent, and they have to learn an optimal contract by only observing the outcome realized at each round. We focus on settings in which the size of the agent's action space is small. We design an algorithm that learns an approximately-optimal contract with high probability in a number of rounds polynomial in the size of the outcome space, when the number of actions is constant. Our algorithm solves an open problem by Zhu et al.[2022]. Moreover, it can also be employed to provide a $\tilde{\mathcal{O}}(T^{4/5})$ regret bound in the related online learning setting in which the principal aims at maximizing their cumulative utility, thus considerably improving previously-known regret bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.09801v3</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Francesco Bacchiocchi, Matteo Castiglioni, Alberto Marchesi, Nicola Gatti</dc:creator>
    </item>
    <item>
      <title>Polynomial-time Approximation Scheme for Equilibriums of Games</title>
      <link>https://arxiv.org/abs/2401.00747</link>
      <description>arXiv:2401.00747v3 Announce Type: replace 
Abstract: Whether a PTAS (polynomial-time approximation scheme) exists for equilibriums of games has been an open question, which relates to questions in three fields, the practicality of methods in algorithmic game theory, the equation PPAD=FP about the two complexity classes in computational complexity theory, and non-stationarity and curse of multiagency in MARL (multi-agent reinforcement learning). This paper introduces our discovery of the sufficient and necessary conditions for iterations based on dynamic programming and line search to approximate perfect equilibriums of dynamic games, out of which we construct a method proved to be a FPTAS (fully PTAS) for non-singular perfect equilibriums of dynamic games, where for almost any given dynamic game, all its perfect equilibriums are non-singular, indicating that FP$\subseteq$PPAD$\subseteq$Almost-FP. Our discovery consists of cone interior dynamic programming and primal-dual unbiased regret minimization, which fit into existing theories by degeneration in a structure-preserving manner. The former enables a dynamic programming operator to iteratively converge to a perfect equilibrium based on a concept called policy cone. The latter enables an interior-point line search to approximate a Nash equilibrium based on two concepts called primal-dual bias and unbiased central variety, solving a subproblem of the former. Validity of our discovery is cross-corroborated by a combination of theorem proofs, graphs of the three main concepts, and experimental results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.00747v3</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongbo Sun, Chongkun Xia, Junbo Tan, Bo Yuan, Xueqian Wang, Bin Liang</dc:creator>
    </item>
    <item>
      <title>Understanding Model Selection For Learning In Strategic Environments</title>
      <link>https://arxiv.org/abs/2402.07588</link>
      <description>arXiv:2402.07588v3 Announce Type: replace 
Abstract: The deployment of ever-larger machine learning models reflects a growing consensus that the more expressive the model class one optimizes over$\unicode{x2013}$and the more data one has access to$\unicode{x2013}$the more one can improve performance. As models get deployed in a variety of real-world scenarios, they inevitably face strategic environments. In this work, we consider the natural question of how the interplay of models and strategic interactions affects the relationship between performance at equilibrium and the expressivity of model classes. We find that strategic interactions can break the conventional view$\unicode{x2013}$meaning that performance does not necessarily monotonically improve as model classes get larger or more expressive (even with infinite data). We show the implications of this result in several contexts including strategic regression, strategic classification, and multi-agent reinforcement learning. In particular, we show that each of these settings admits a Braess' paradox-like phenomenon in which optimizing over less expressive model classes allows one to achieve strictly better equilibrium outcomes. Motivated by these examples, we then propose a new paradigm for model selection in games wherein an agent seeks to choose amongst different model classes to use as their action set in a game.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.07588v3</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tinashe Handina, Eric Mazumdar</dc:creator>
    </item>
    <item>
      <title>Fusion-PSRO: Nash Policy Fusion for Policy Space Response Oracles</title>
      <link>https://arxiv.org/abs/2405.21027</link>
      <description>arXiv:2405.21027v2 Announce Type: replace 
Abstract: A popular approach for solving zero-sum games is to maintain populations of policies to approximate the Nash Equilibrium (NE). Previous studies have shown that Policy Space Response Oracle (PSRO) algorithm is an effective multi-agent reinforcement learning framework for solving such games. However, repeatedly training new policies from scratch to approximate Best Response (BR) to opponents' mixed policies at each iteration is both inefficient and costly. While some PSRO variants initialize a new policy by inheriting from past BR policies, this approach limits the exploration of new policies, especially against challenging opponents. To address this issue, we propose Fusion-PSRO, which employs policy fusion to initialize policies for better approximation to BR. By selecting high-quality base policies from meta-NE, policy fusion fuses the base policies into a new policy through model averaging. This approach allows the initialized policies to incorporate multiple expert policies, making it easier to handle difficult opponents compared to inheriting from past BR policies or initializing from scratch. Moreover, our method only modifies the policy initialization phase, allowing its application to nearly all PSRO variants without additional training overhead. Our experiments on non-transitive matrix games, Leduc Poker, and the more complex Liars Dice demonstrate that Fusion-PSRO enhances the performance of nearly all PSRO variants, achieving lower exploitability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.21027v2</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiesong Lian, Yucong Huang, Mingzhi Wang, Chengdong Ma, Yixue Hao, Ying Wen, Yaodong Yang</dc:creator>
    </item>
    <item>
      <title>Online Learning with Bounded Recall</title>
      <link>https://arxiv.org/abs/2205.14519</link>
      <description>arXiv:2205.14519v2 Announce Type: replace-cross 
Abstract: We study the problem of full-information online learning in the "bounded recall" setting popular in the study of repeated games. An online learning algorithm $\mathcal{A}$ is $M$-$\textit{bounded-recall}$ if its output at time $t$ can be written as a function of the $M$ previous rewards (and not e.g. any other internal state of $\mathcal{A}$). We first demonstrate that a natural approach to constructing bounded-recall algorithms from mean-based no-regret learning algorithms (e.g., running Hedge over the last $M$ rounds) fails, and that any such algorithm incurs constant regret per round. We then construct a stationary bounded-recall algorithm that achieves a per-round regret of $\Theta(1/\sqrt{M})$, which we complement with a tight lower bound. Finally, we show that unlike the perfect recall setting, any low regret bound bounded-recall algorithm must be aware of the ordering of the past $M$ losses -- any bounded-recall algorithm which plays a symmetric function of the past $M$ losses must incur constant regret per round.</description>
      <guid isPermaLink="false">oai:arXiv.org:2205.14519v2</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jon Schneider, Kiran Vodrahalli</dc:creator>
    </item>
    <item>
      <title>A survey on multi-player bandits</title>
      <link>https://arxiv.org/abs/2211.16275</link>
      <description>arXiv:2211.16275v2 Announce Type: replace-cross 
Abstract: Due mostly to its application to cognitive radio networks, multiplayer bandits gained a lot of interest in the last decade. A considerable progress has been made on its theoretical aspect. However, the current algorithms are far from applicable and many obstacles remain between these theoretical results and a possible implementation of multiplayer bandits algorithms in real cognitive radio networks. This survey contextualizes and organizes the rich multiplayer bandits literature. In light of the existing works, some clear directions for future research appear. We believe that a further study of these different directions might lead to theoretical algorithms adapted to real-world situations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.16275v2</guid>
      <category>stat.ML</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Etienne Boursier, Vianney Perchet</dc:creator>
    </item>
    <item>
      <title>Pontryagin Neural Operator for Solving Parametric General-Sum Differential Games</title>
      <link>https://arxiv.org/abs/2401.01502</link>
      <description>arXiv:2401.01502v2 Announce Type: replace-cross 
Abstract: The values of two-player general-sum differential games are viscosity solutions to Hamilton-Jacobi-Isaacs (HJI) equations. Value and policy approximations for such games suffer from the curse of dimensionality (CoD). Alleviating CoD through physics-informed neural networks (PINN) encounters convergence issues when differentiable values with large Lipschitz constants are present due to state constraints. On top of these challenges, it is often necessary to learn generalizable values and policies across a parametric space of games, e.g., for game parameter inference when information is incomplete. To address these challenges, we propose in this paper a Pontryagin-mode neural operator that outperforms the current state-of-the-art hybrid PINN model on safety performance across games with parametric state constraints. Our key contribution is the introduction of a costate loss defined on the discrepancy between forward and backward costate rollouts, which are computationally cheap. We show that the costate dynamics, which can reflect state constraint violation, effectively enables the learning of differentiable values with large Lipschitz constants, without requiring manually supervised data as suggested by the hybrid PINN model. More importantly, we show that the close relationship between costates and policies makes the former critical in learning feedback control policies with generalizable safety performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.01502v2</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <category>cs.RO</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lei Zhang, Mukesh Ghimire, Zhe Xu, Wenlong Zhang, Yi Ren</dc:creator>
    </item>
    <item>
      <title>Improved Bandits in Many-to-one Matching Markets with Incentive Compatibility</title>
      <link>https://arxiv.org/abs/2401.01528</link>
      <description>arXiv:2401.01528v2 Announce Type: replace-cross 
Abstract: Two-sided matching markets have been widely studied in the literature due to their rich applications. Since participants are usually uncertain about their preferences, online algorithms have recently been adopted to learn them through iterative interactions. An existing work initiates the study of this problem in a many-to-one setting with responsiveness. However, their results are far from optimal and lack guarantees of incentive compatibility. We first extend an existing algorithm for the one-to-one setting to this more general setting and show it achieves a near-optimal bound for player-optimal regret. Nevertheless, due to the substantial requirement for collaboration, a single player's deviation could lead to a huge increase in its own cumulative rewards and a linear regret for others. In this paper, we aim to enhance the regret bound in many-to-one markets while ensuring incentive compatibility. We first propose the adaptively explore-then-deferred-acceptance (AETDA) algorithm for responsiveness setting and derive an upper bound for player-optimal stable regret while demonstrating its guarantee of incentive compatibility. To the best of our knowledge, it constitutes the first polynomial player-optimal guarantee in matching markets that offers such robust assurances without known $\Delta$, where $\Delta$ is some preference gap among players and arms. We also consider broader substitutable preferences, one of the most general conditions to ensure the existence of a stable matching and cover responsiveness. We devise an online DA (ODA) algorithm and establish an upper bound for the player-pessimal stable regret for this setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.01528v2</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fang Kong, Shuai Li</dc:creator>
    </item>
    <item>
      <title>Model-Based RL for Mean-Field Games is not Statistically Harder than Single-Agent RL</title>
      <link>https://arxiv.org/abs/2402.05724</link>
      <description>arXiv:2402.05724v2 Announce Type: replace-cross 
Abstract: We study the sample complexity of reinforcement learning (RL) in Mean-Field Games (MFGs) with model-based function approximation that requires strategic exploration to find a Nash Equilibrium policy. We introduce the Partial Model-Based Eluder Dimension (P-MBED), a more effective notion to characterize the model class complexity. Notably, P-MBED measures the complexity of the single-agent model class converted from the given mean-field model class, and potentially, can be exponentially lower than the MBED proposed by \citet{huang2023statistical}. We contribute a model elimination algorithm featuring a novel exploration strategy and establish sample complexity results polynomial w.r.t.~P-MBED. Crucially, our results reveal that, under the basic realizability and Lipschitz continuity assumptions, \emph{learning Nash Equilibrium in MFGs is no more statistically challenging than solving a logarithmic number of single-agent RL problems}. We further extend our results to Multi-Type MFGs, generalizing from conventional MFGs and involving multiple types of agents. This extension implies statistical tractability of a broader class of Markov Games through the efficacy of mean-field approximation. Finally, inspired by our theoretical algorithm, we present a heuristic approach with improved computational efficiency and empirically demonstrate its effectiveness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.05724v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiawei Huang, Niao He, Andreas Krause</dc:creator>
    </item>
    <item>
      <title>Learning to Defer in Content Moderation: The Human-AI Interplay</title>
      <link>https://arxiv.org/abs/2402.12237</link>
      <description>arXiv:2402.12237v3 Announce Type: replace-cross 
Abstract: Successful content moderation in online platforms relies on a human-AI collaboration approach. A typical heuristic estimates the expected harmfulness of a post and uses fixed thresholds to decide whether to remove it and whether to send it for human review. This disregards the prediction uncertainty, the time-varying element of human review capacity and post arrivals, and the selective sampling in the dataset (humans only review posts filtered by the admission algorithm).
  In this paper, we introduce a model to capture the human-AI interplay in content moderation. The algorithm observes contextual information for incoming posts, makes classification and admission decisions, and schedules posts for human review. Only admitted posts receive human reviews on their harmfulness. These reviews help educate the machine-learning algorithms but are delayed due to congestion in the human review system. The classical learning-theoretic way to capture this human-AI interplay is via the framework of learning to defer, where the algorithm has the option to defer a classification task to humans for a fixed cost and immediately receive feedback. Our model contributes to this literature by introducing congestion in the human review system. Moreover, unlike work on online learning with delayed feedback where the delay in the feedback is exogenous to the algorithm's decisions, the delay in our model is endogenous to both the admission and the scheduling decisions.
  We propose a near-optimal learning algorithm that carefully balances the classification loss from a selectively sampled dataset, the idiosyncratic loss of non-reviewed posts, and the delay loss of having congestion in the human review system. To the best of our knowledge, this is the first result for online learning in contextual queueing systems and hence our analytical framework may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.12237v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>cs.HC</category>
      <category>cs.PF</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thodoris Lykouris, Wentao Weng</dc:creator>
    </item>
    <item>
      <title>Proof-of-Learning with Incentive Security</title>
      <link>https://arxiv.org/abs/2404.09005</link>
      <description>arXiv:2404.09005v4 Announce Type: replace-cross 
Abstract: Most concurrent blockchain systems rely heavily on the Proof-of-Work (PoW) or Proof-of-Stake (PoS) mechanisms for decentralized consensus and security assurance. However, the substantial energy expenditure stemming from computationally intensive yet meaningless tasks has raised considerable concerns surrounding traditional PoW approaches, The PoS mechanism, while free of energy consumption, is subject to security and economic issues. Addressing these issues, the paradigm of Proof-of-Useful-Work (PoUW) seeks to employ challenges of practical significance as PoW, thereby imbuing energy consumption with tangible value. While previous efforts in Proof of Learning (PoL) explored the utilization of deep learning model training SGD tasks as PoUW challenges, recent research has revealed its vulnerabilities to adversarial attacks and the theoretical hardness in crafting a byzantine-secure PoL mechanism. In this paper, we introduce the concept of incentive-security that incentivizes rational provers to behave honestly for their best interest, bypassing the existing hardness to design a PoL mechanism with computational efficiency, a provable incentive-security guarantee and controllable difficulty. Particularly, our work is secure against two attacks to the recent work of Jia et al. [2021], and also improves the computational overhead from $\Theta(1)$ to $O(\frac{\log E}{E})$. Furthermore, while most recent research assumes trusted problem providers and verifiers, our design also guarantees frontend incentive-security even when problem providers are untrusted, and verifier incentive-security that bypasses the Verifier's Dilemma. By incorporating ML training into blockchain consensus mechanisms with provable guarantees, our research not only proposes an eco-friendly solution to blockchain systems, but also provides a proposal for a completely decentralized computing power market in the new AI age.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.09005v4</guid>
      <category>cs.CR</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zishuo Zhao, Zhixuan Fang, Xuechao Wang, Xi Chen, Yuan Zhou</dc:creator>
    </item>
    <item>
      <title>Optimal single threshold stopping rules and sharp prophet inequalities</title>
      <link>https://arxiv.org/abs/2404.12949</link>
      <description>arXiv:2404.12949v2 Announce Type: replace-cross 
Abstract: This paper considers a finite horizon optimal stopping problem for a sequence of independent and identically distributed random variables. The objective is to design stopping rules that attempt to select the random variable with the highest value in the sequence. The performance of any stopping rule may be benchmarked relative to the selection of a ``prophet" that has perfect foreknowledge of the largest value. Such comparisons are typically stated in the form of "prophet inequalities." In this paper we characterize sharp prophet inequalities for single threshold stopping rules as solutions to infinite two person zero sum games on the unit square with special payoff kernels. The proposed game theoretic characterization allows one to derive sharp non-asymptotic prophet inequalities for different classes of distributions. This, in turn, gives rise to a simple and computationally tractable algorithmic paradigm for deriving optimal single threshold stopping rules.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.12949v2</guid>
      <category>math.PR</category>
      <category>cs.GT</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Goldenshluger, Yaakov Malinovsky, Assaf Zeevi</dc:creator>
    </item>
    <item>
      <title>Optimal Pricing for Linear-Quadratic Games with Nonlinear Interaction Between Agents</title>
      <link>https://arxiv.org/abs/2405.01047</link>
      <description>arXiv:2405.01047v2 Announce Type: replace-cross 
Abstract: This paper studies a class of network games with linear-quadratic payoffs and externalities exerted through a strictly concave interaction function. This class of game is motivated by the diminishing marginal effects with peer influences. We analyze the optimal pricing strategy for this class of network game. First, we prove the existence of a unique Nash Equilibrium (NE). Second, we study the optimal pricing strategy of a monopolist selling a divisible good to agents. We show that the optimal pricing strategy, found by solving a bilevel optimization problem, is strictly better when the monopolist knows the network structure as opposed to the best strategy agnostic to network structure. Numerical experiments demonstrate that in most cases, the maximum revenue is achieved with an asymmetric network. These results contrast with the previously studied case of linear interaction function, where a network-independent price is proven optimal with symmetric networks. Lastly, we describe an efficient algorithm to find the optimal pricing strategy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.01047v2</guid>
      <category>math.OC</category>
      <category>cs.GT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiamin Cai, Chenyue Zhang, Hoi-To Wai</dc:creator>
    </item>
  </channel>
</rss>
