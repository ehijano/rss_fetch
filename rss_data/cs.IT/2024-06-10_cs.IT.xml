<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.IT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.IT</link>
    <description>cs.IT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.IT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 11 Jun 2024 02:39:40 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 10 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>The Gaussian Multiple Access Wiretap Channel with Selfish Transmitters: A Coalitional Game Theory Perspective</title>
      <link>https://arxiv.org/abs/2406.04521</link>
      <description>arXiv:2406.04521v1 Announce Type: new 
Abstract: This paper considers the Gaussian multiple access wiretap channel (GMAC-WT) with selfish transmitters, i.e., who are each solely interested in maximizing their individual secrecy rate. The question then arises as to whether selfish transmitters can increase their individual secrecy rate by participating in a collective, i.e., multiple access, protocol instead of operating on their own. If yes, the question arises whether there is a protocol that satisfies all the participating transmitters simultaneously, in the sense that no transmitter has an incentive to deviate from the protocol. Utilizing coalitional game theory, these questions are addressed for the degraded GMAC-WT with an arbitrary number of transmitters and for the non-degraded GMAC-WT with two transmitters. In particular, for the degraded GMAC-WT, cooperation is shown to be in the best interest of all transmitters, and the existence of protocols that incentivize all transmitters to participate is established. Furthermore, a unique, fair, stable, and achievable secrecy rate allocation is determined. For the non-degraded GMAC-WT, depending on the channel parameters, there are cases where cooperation is not in the best interest of all transmitters, and cases where it is. In the latter cases, a unique, fair, stable, and achievable secrecy rate allocation is determined.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04521v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Remi A. Chou, Aylin Yener</dc:creator>
    </item>
    <item>
      <title>A Unified View of Group Fairness Tradeoffs Using Partial Information Decomposition</title>
      <link>https://arxiv.org/abs/2406.04562</link>
      <description>arXiv:2406.04562v1 Announce Type: new 
Abstract: This paper introduces a novel information-theoretic perspective on the relationship between prominent group fairness notions in machine learning, namely statistical parity, equalized odds, and predictive parity. It is well known that simultaneous satisfiability of these three fairness notions is usually impossible, motivating practitioners to resort to approximate fairness solutions rather than stringent satisfiability of these definitions. However, a comprehensive analysis of their interrelations, particularly when they are not exactly satisfied, remains largely unexplored. Our main contribution lies in elucidating an exact relationship between these three measures of (un)fairness by leveraging a body of work in information theory called partial information decomposition (PID). In this work, we leverage PID to identify the granular regions where these three measures of (un)fairness overlap and where they disagree with each other leading to potential tradeoffs. We also include numerical simulations to complement our results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04562v1</guid>
      <category>cs.IT</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Faisal Hamman, Sanghamitra Dutta</dc:creator>
    </item>
    <item>
      <title>End-to-End Design of Polar Coded Integrated Data and Energy Networking</title>
      <link>https://arxiv.org/abs/2406.04721</link>
      <description>arXiv:2406.04721v1 Announce Type: new 
Abstract: In order to transmit data and transfer energy to the low-power Internet of Things (IoT) devices, integrated data and energy networking (IDEN) system may be harnessed. In this context, we propose a bitwise end-to-end design for polar coded IDEN systems, where the conventional encoding/decoding, modulation/demodulation, and energy harvesting (EH) modules are replaced by the neural networks (NNs). In this way, the entire system can be treated as an AutoEncoder (AE) and trained in an end-to-end manner. Hence achieving global optimization. Additionally, we improve the common NN-based belief propagation (BP) decoder by adding an extra hypernetwork, which generates the corresponding NN weights for the main network under different number of iterations, thus the adaptability of the receiver architecture can be further enhanced. Our numerical results demonstrate that our BP-based end-to-end design is superior to conventional BP-based counterparts in terms of both the BER and power transfer, but it is inferior to the successive cancellation list (SCL)-based conventional IDEN system, which may be due to the inherent performance gap between the BP and SCL decoders.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04721v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jie Hu, Jingwen Cui, Luping Xiang, Kun Yang</dc:creator>
    </item>
    <item>
      <title>Throughput and Fairness Trade-off Balancing for UAV-Enabled Wireless Communication Systems</title>
      <link>https://arxiv.org/abs/2406.04750</link>
      <description>arXiv:2406.04750v1 Announce Type: new 
Abstract: Given the imperative of 6G networks' ubiquitous connectivity, along with the inherent mobility and cost-effectiveness of unmanned aerial vehicles (UAVs), UAVs play a critical role within 6G wireless networks. Despite advancements in enhancing the UAV-enabled communication systems' throughput in existing studies, there remains a notable gap in addressing issues concerning user fairness and quality-of-service (QoS) provisioning and lacks an effective scheme to depict the trade-off between system throughput and user fairness. To solve the above challenges, in this paper we introduce a novel fairness control scheme for UAV-enabled wireless communication systems based on a new weighted function. First, we propose a throughput combining model based on a new weighted function with fairness considering. Second, we formulate the optimization problem to maximize the weighted sum of all users' throughput. Third, we decompose the optimization problem and propose an efficient iterative algorithm to solve it. Finally, simulation results are provided to demonstrate the considerable potential of our proposed scheme in fairness and QoS provisioning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04750v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kejie Ni, Jingqing Wang, Wenchi Cheng, Wei Zhang</dc:creator>
    </item>
    <item>
      <title>Hulls of Projective Reed-Muller Codes</title>
      <link>https://arxiv.org/abs/2406.04757</link>
      <description>arXiv:2406.04757v1 Announce Type: new 
Abstract: Projective Reed-Muller codes are constructed from the family of projective hypersurfaces of a fixed degree over a finite field $\F_q$. We consider the relationship between projective Reed-Muller codes and their duals. We determine when these codes are self-dual, when they are self-orthogonal, and when they are LCD. We then show that when $q$ is sufficiently large, the dimension of the hull of a projective Reed-Muller code is 1 less than the dimension of the code. We determine the dimension of the hull for a wider range of parameters and describe how this leads to a new proof of a recent result of Ruano and San Jos\'e (2024).</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04757v1</guid>
      <category>cs.IT</category>
      <category>cs.DM</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nathan Kaplan, Jon-Lark Kim</dc:creator>
    </item>
    <item>
      <title>Time-Series JEPA for Predictive Remote Control under Capacity-Limited Networks</title>
      <link>https://arxiv.org/abs/2406.04853</link>
      <description>arXiv:2406.04853v1 Announce Type: new 
Abstract: In remote control systems, transmitting large data volumes (e.g. video feeds) from wireless sensors to faraway controllers is challenging when the uplink channel capacity is limited (e.g. RedCap devices or massive wireless sensor networks). Furthermore, the controllers often only need the information-rich components of the original data. To address this, we propose a Time-Series Joint Embedding Predictive Architecture (TS-JEPA) and a semantic actor trained through self-supervised learning. This approach harnesses TS-JEPA's semantic representation power and predictive capabilities by capturing spatio-temporal correlations in the source data. We leverage this to optimize uplink channel utilization, while the semantic actor calculates control commands directly from the encoded representations, rather than from the original data. We test our model through multiple parallel instances of the well-known inverted cart-pole scenario, where the approach is validated through the maximization of stability under constrained uplink channel capacity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04853v1</guid>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>cs.RO</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Abanoub M. Girgis, Alvaro Valcarce, Mehdi Bennis</dc:creator>
    </item>
    <item>
      <title>MIMO Capacity Analysis and Channel Estimation for Electromagnetic Information Theory</title>
      <link>https://arxiv.org/abs/2406.04881</link>
      <description>arXiv:2406.04881v1 Announce Type: new 
Abstract: Electromagnetic information theory (EIT) is an interdisciplinary subject that serves to integrate deterministic electromagnetic theory with stochastic Shannon's information theory. Existing EIT analysis operates in the continuous space domain, which is not aligned with the practical algorithms working in the discrete space domain. This mismatch leads to a significant difficulty in application of EIT methodologies to practical discrete space systems, which is called as the discrete-continuous gap in this paper. To bridge this gap, we establish the discrete-continuous correspondence with a prolate spheroidal wave function (PSWF)-based ergodic capacity analysis framework. Specifically, we state and prove some discrete-continuous correspondence lemmas to establish a firm theoretical connection between discrete information-theoretic quantities to their continuous counterparts. With these lemmas, we apply the PSWF ergodic capacity bound to advanced MIMO architectures such as continuous-aperture MIMO (CAP-MIMO) and extremely large-scale MIMO (XL-MIMO). From this PSWF capacity bound, we discover the capacity saturation phenomenon both theoretically and empirically. Although the growth of MIMO performance is fundamentally limited in this EIT-based analysis framework, we reveal new opportunities in MIMO channel estimation by exploiting the EIT knowledge about the channel. Inspired by the PSWF capacity bound, we utilize continuous PSWFs to improve the pilot design of discrete MIMO channel estimators, which is called as the PSWF channel estimator (PSWF-CE). Simulation results demonstrate improved performances of the proposed PSWF-CE, compared to traditional minimum mean squared error (MMSE) and compressed sensing-based estimators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04881v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Jieao Zhu, Vincent Y. F. Tan, Linglong Dai</dc:creator>
    </item>
    <item>
      <title>Enhancing LEO Mega-Constellations with Inter-Satellite Links: Vision and Challenges</title>
      <link>https://arxiv.org/abs/2406.05078</link>
      <description>arXiv:2406.05078v1 Announce Type: new 
Abstract: Low Earth orbit (LEO) satellites have been envisioned as a significant component of the sixth generation (6G) network architecture for achieving ubiquitous coverage and seamless access. However, the implementation of LEO satellites is largely restricted by the deployment of ground stations. Inter-satellite links (ISLs) have been regarded as a promising technique to fully exploit the potentials of LEO mega constellations by concatenating multiple satellites to constitute an autonomous space network. In this article, we present the merits of implementing ISLs in LEO mega constellations and the representative applications empowered/inspired by ISLs. Moreover, we outline several key technical challenges as well as potential solutions related to LEO satellite networks with ISLs, including performance analysis for system design, routing and load balancing, and resource allocation. Particularly, the potential of using ISLs in enhancing in-flight connectivity is showcased with a preliminary performance evaluation. Finally, some open issues are discussed to inspire future research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05078v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chenyu Wu, Shuai Han, Qian Chen, Yu Wang, Weixiao Meng, Abderrahim Benslimane</dc:creator>
    </item>
    <item>
      <title>Revisiting Attention Weights as Interpretations of Message-Passing Neural Networks</title>
      <link>https://arxiv.org/abs/2406.04612</link>
      <description>arXiv:2406.04612v1 Announce Type: cross 
Abstract: The self-attention mechanism has been adopted in several widely-used message-passing neural networks (MPNNs) (e.g., GATs), which adaptively controls the amount of information that flows along the edges of the underlying graph. This usage of attention has made such models a baseline for studies on explainable AI (XAI) since interpretations via attention have been popularized in various domains (e.g., natural language processing and computer vision). However, existing studies often use naive calculations to derive attribution scores from attention, and do not take the precise and careful calculation of edge attribution into consideration. In our study, we aim to fill the gap between the widespread usage of attention-enabled MPNNs and their potential in largely under-explored explainability, a topic that has been actively investigated in other areas. To this end, as the first attempt, we formalize the problem of edge attribution from attention weights in GNNs. Then, we propose GATT, an edge attribution calculation method built upon the computation tree. Through comprehensive experiments, we demonstrate the effectiveness of our proposed method when evaluating attributions from GATs. Conversely, we empirically validate that simply averaging attention weights over graph attention layers is insufficient to interpret the GAT model's behavior. Code is publicly available at https://github.com/jordan7186/GAtt/tree/main.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04612v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>cs.NE</category>
      <category>cs.SI</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yong-Min Shin, Siqing Li, Xin Cao, Won-Yong Shin</dc:creator>
    </item>
    <item>
      <title>MIMO with 1-bit Pre/Post-Coding Resolution: A Quantum Annealing Approach</title>
      <link>https://arxiv.org/abs/2406.04708</link>
      <description>arXiv:2406.04708v1 Announce Type: cross 
Abstract: In this paper, we study the problem of digital pre/post-coding design in multiple-input multiple-output (MIMO) systems with 1-bit resolution per complex dimension. The optimal solution that maximizes the received signal-to-noise ratio relies on an NP-hard combinatorial problem that requires exhaustive searching with exponential complexity. By using the principles of alternating optimization and quantum annealing (QA), an iterative QA-based algorithm is proposed that achieves near-optimal performance with polynomial complexity. The algorithm is associated with a rigorous mathematical framework that casts the pre/post-coding vector design to appropriate real-valued quadratic unconstrained binary optimization (QUBO) problems. Experimental results in a state-of-the-art D-WAVE QA device validate the efficiency of the proposed algorithm. To further improve the efficiency of the D-WAVE quantum device, a new pre-processing technique which preserves the quadratic QUBO matrix from the detrimental effects of the Hamiltonian noise through non-linear companding, is proposed. The proposed pre-processing technique significantly improves the quality of the D-WAVE solutions as well as the occurrence probability of the optimal solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04708v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ioannis Krikidis</dc:creator>
    </item>
    <item>
      <title>ComplexityMeasures.jl: scalable software to unify and accelerate entropy and complexity timeseries analysis</title>
      <link>https://arxiv.org/abs/2406.05011</link>
      <description>arXiv:2406.05011v1 Announce Type: cross 
Abstract: In the nonlinear timeseries analysis literature, countless quantities have been presented as new "entropy" or "complexity" measures, often with similar roles. The ever-increasing pool of such measures makes creating a sustainable and all-encompassing software for them difficult both conceptually and pragmatically. Such a software however would be an important tool that can aid researchers make an informed decision of which measure to use and for which application, as well as accelerate novel research. Here we present ComplexityMeasures.jl, an easily extendable and highly performant open-source software that implements a vast selection of complexity measures. The software provides 1530 measures with 3,834 lines of source code, averaging only 2.5 lines of code per exported quantity (version 3.5). This is made possible by its mathematically rigorous composable design. In this paper we discuss the software design and demonstrate how it can accelerate complexity-related research in the future. We carefully compare it with alternative software and conclude that ComplexityMeasures.jl outclasses the alternatives in several objective aspects of comparison, such as computational performance, overall amount of measures, reliability, and extendability. ComplexityMeasures.jl is also a component of the DynamicalSystems.jl library for nonlinear dynamics and nonlinear timeseries analysis and follows open source development practices for creating a sustainable community of developers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05011v1</guid>
      <category>cs.SE</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>nlin.CD</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>George Datseris, Kristian Agas{\o}ster Haaga</dc:creator>
    </item>
    <item>
      <title>A Bregman Proximal Perspective on Classical and Quantum Blahut-Arimoto Algorithms</title>
      <link>https://arxiv.org/abs/2306.04492</link>
      <description>arXiv:2306.04492v3 Announce Type: replace 
Abstract: The Blahut-Arimoto algorithm is a well-known method to compute classical channel capacities and rate-distortion functions. Recent works have extended this algorithm to compute various quantum analogs of these quantities. In this paper, we show how these Blahut-Arimoto algorithms are special instances of mirror descent, which is a type of Bregman proximal method, and a well-studied generalization of gradient descent for constrained convex optimization. Using recently developed convex analysis tools, we show how analysis based on relative smoothness and strong convexity recovers known sublinear and linear convergence rates for Blahut-Arimoto algorithms. This Bregman proximal viewpoint allows us to derive related algorithms with similar convergence guarantees to solve problems in information theory for which Blahut-Arimoto-type algorithms are not directly applicable. We apply this framework to compute energy-constrained classical and quantum channel capacities, classical and quantum rate-distortion functions, and approximations of the relative entropy of entanglement, all with provable convergence guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.04492v3</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <category>quant-ph</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kerry He, James Saunderson, Hamza Fawzi</dc:creator>
    </item>
    <item>
      <title>A Survey of Recent Advances in Optimization Methods for Wireless Communications</title>
      <link>https://arxiv.org/abs/2401.12025</link>
      <description>arXiv:2401.12025v3 Announce Type: replace 
Abstract: Mathematical optimization is now widely regarded as an indispensable modeling and solution tool for the design of wireless communications systems. While optimization has played a significant role in the revolutionary progress in wireless communication and networking technologies from 1G to 5G and onto the future 6G, the innovations in wireless technologies have also substantially transformed the nature of the underlying mathematical optimization problems upon which the system designs are based and have sparked significant innovations in the development of methodologies to understand, to analyze, and to solve those problems. In this paper, we provide a comprehensive survey of recent advances in mathematical optimization theory and algorithms for wireless communication system design. We begin by illustrating common features of mathematical optimization problems arising in wireless communication system design. We discuss various scenarios and use cases and their associated mathematical structures from an optimization perspective. We then provide an overview of recently developed optimization techniques in areas ranging from nonconvex optimization, global optimization, and integer programming, to distributed optimization and learning-based optimization. The key to successful solution of mathematical optimization problems is in carefully choosing or developing suitable algorithms (or neural network architectures) that can exploit the underlying problem structure. We conclude the paper by identifying several open research challenges and outlining future research directions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.12025v3</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ya-Feng Liu, Tsung-Hui Chang, Mingyi Hong, Zheyu Wu, Anthony Man-Cho So, Eduard A. Jorswieck, Wei Yu</dc:creator>
    </item>
    <item>
      <title>Design and Performance of Enhanced Spread Spectrum Aloha for Unsourced Multiple Access</title>
      <link>https://arxiv.org/abs/2402.12101</link>
      <description>arXiv:2402.12101v2 Announce Type: replace 
Abstract: We analyze the performance of enhanced spread spectrum Aloha (E-SSA) in the framework of unsourced multiple access (UMAC). The asynchronous, unframed transmission of E-SSA is modified to enable a direct comparison with framed UMAC schemes and with Polyanskiy's achievability bound. The design of E-SSA is tailored to the UMAC setting, resorting to short polar codes and the use of a timing channel to improve the energy efficiency of the protocol. We assess the impact of the preamble length and of the spreading factor on the system efficiency. The resulting scheme exhibits simplicity at the transmitter and linear complexity with respect to the number of active users at the receiver, approaching the UMAC achievability bound in close competition with the best known UMAC schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.12101v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Riccardo Schiavone, Gianluigi Liva, Roberto Garello</dc:creator>
    </item>
    <item>
      <title>Active Sensing for Reciprocal MIMO Channels</title>
      <link>https://arxiv.org/abs/2403.00134</link>
      <description>arXiv:2403.00134v2 Announce Type: replace 
Abstract: This paper addresses the design of transmit precoder and receive combiner matrices to support $N_{\rm s}$ independent data streams over a time-division duplex (TDD) point-to-point massive multiple-input multiple-output (MIMO) channel with either a fully digital or a hybrid structure. The optimal precoder and combiner design amounts to finding the top-$N_{\rm s}$ singular vectors of the channel matrix, but the explicit estimation of the entire high-dimensional channel would require significant pilot overhead. Alternatively, prior works suggest to find the precoding and combining matrices directly by exploiting channel reciprocity and by using the power iteration method, but its performance degrades in the low SNR regime. To tackle this challenging problem, this paper proposes a learning-based active sensing framework, where the transmitter and the receiver send pilots alternately using sensing beamformers that are actively designed as functions of previously received pilots. This is accomplished by using recurrent neural networks to summarize information from the historical observations into hidden state vectors, then using fully connected neural networks to learn the appropriate sensing beamformers in the next pilot stage and finally the transmit precoding and receive combiner matrices for data communications. Simulations demonstrate that the learning-based method outperforms existing approaches significantly and maintains superior performance even in the low SNR regime for both the fully digital and hybrid MIMO scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.00134v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tao Jiang, Wei Yu</dc:creator>
    </item>
    <item>
      <title>Scalability and Implementation Aspects of Cell-Free Massive MIMO for ISAC</title>
      <link>https://arxiv.org/abs/2404.14874</link>
      <description>arXiv:2404.14874v2 Announce Type: replace 
Abstract: This paper addresses the problem of scalability for a cell-free massive MIMO (CF-mMIMO) system that performs integrated sensing and communications (ISAC). Specifically, the case where a large number of access points (APs) are deployed to perform simultaneous communication with mobile users and monitoring of the surrounding environment in the same time-frequency slot is considered, and a target-centric approach on top of the user-centric architecture used for communication services is introduced. In the paper, other practical aspects such as the fronthaul load and scanning protocol are also considered. The proposed scalable ISAC-enabled CF-mMIMO network has lower levels of system complexity, permits managing the scenario in which multiple targets are to be tracked/sensed by the APs, and achieves performance levels superior or, in some cases, close to those of the non-scalable solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.14874v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stefano Buzzi, Carmen D'Andrea, Sergi Liesegang</dc:creator>
    </item>
    <item>
      <title>S$\Omega$I: Score-based O-INFORMATION Estimation</title>
      <link>https://arxiv.org/abs/2402.05667</link>
      <description>arXiv:2402.05667v3 Announce Type: replace-cross 
Abstract: The analysis of scientific data and complex multivariate systems requires information quantities that capture relationships among multiple random variables. Recently, new information-theoretic measures have been developed to overcome the shortcomings of classical ones, such as mutual information, that are restricted to considering pairwise interactions. Among them, the concept of information synergy and redundancy is crucial for understanding the high-order dependencies between variables. One of the most prominent and versatile measures based on this concept is O-information, which provides a clear and scalable way to quantify the synergy-redundancy balance in multivariate systems. However, its practical application is limited to simplified cases. In this work, we introduce S$\Omega$I, which allows for the first time to compute O-information without restrictive assumptions about the system. Our experiments validate our approach on synthetic data, and demonstrate the effectiveness of S$\Omega$I in the context of a real-world use case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.05667v3</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mustapha Bounoua, Giulio Franzese, Pietro Michiardi</dc:creator>
    </item>
    <item>
      <title>Partial Information Decomposition for Data Interpretability and Feature Selection</title>
      <link>https://arxiv.org/abs/2405.19212</link>
      <description>arXiv:2405.19212v2 Announce Type: replace-cross 
Abstract: In this paper, we introduce Partial Information Decomposition of Features (PIDF), a new paradigm for simultaneous data interpretability and feature selection. Contrary to traditional methods that assign a single importance value, our approach is based on three metrics per feature: the mutual information shared with the target variable, the feature's contribution to synergistic information, and the amount of this information that is redundant. In particular, we develop a novel procedure based on these three metrics, which reveals not only how features are correlated with the target but also the additional and overlapping information provided by considering them in combination with other features. We extensively evaluate PIDF using both synthetic and real-world data, demonstrating its potential applications and effectiveness, by considering case studies from genetics and neuroscience.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.19212v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Charles Westphal, Stephen Hailes, Mirco Musolesi</dc:creator>
    </item>
  </channel>
</rss>
