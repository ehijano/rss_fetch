<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.data-an updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.data-an</link>
    <description>physics.data-an updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.data-an" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 12 Aug 2025 04:04:02 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Error Breakdown and Sensitivity Analysis of Dynamical Quantities in Markov State Models</title>
      <link>https://arxiv.org/abs/2508.06735</link>
      <description>arXiv:2508.06735v1 Announce Type: new 
Abstract: Markov state models (MSMs) are widely employed to analyze the kinetics of complex systems. But despite their effectiveness in many applications, MSMs are prone to systematic or statistical errors, often exacerbated by suboptimal hyperparameter choice. In this paper, we attempt to understand how these choices affect the error of estimates of mean first-passage times and committors, key quantities in chemical rate theory. We first evaluate the performance of the recently introduced "stopped-process estimator" that attempts to reduce error caused by choosing a too-large lag time. We then study the effect of statistical errors on Markov state model construction using the condition number, which measures an MSM's sensitivity to perturbation. This analysis helps give an intuition into which factors cause an MSM to be more or less sensitive to statistical error. Our work highlights the importance of choosing a good sampling measure, the measure from which the initial points are drawn, and has implications for recent work applying a variational principle for evaluating the committor.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.06735v1</guid>
      <category>physics.data-an</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yehor Tuchkov, Luke Evans, Sonya M. Hanson, Erik H. Thiede</dc:creator>
    </item>
    <item>
      <title>Taking the Garbage Out of Data-Driven Prediction Across Climate Timescales</title>
      <link>https://arxiv.org/abs/2508.07062</link>
      <description>arXiv:2508.07062v1 Announce Type: new 
Abstract: Artificial intelligence (AI) -- and specifically machine learning (ML) -- applications for climate prediction across timescales are proliferating quickly. The emergence of these methods prompts a revisit to the impact of data preprocessing, a topic familiar to the climate community, as more traditional statistical models work with relatively small sample sizes. Indeed, the skill and confidence in the forecasts produced by data-driven models are directly influenced by the quality of the datasets and how they are treated during model development, thus yielding the colloquialism "garbage in, garbage out." As such, this article establishes protocols for the proper preprocessing of input data for AI/ML models designed for climate prediction (i.e., subseasonal to decadal and longer). The three aims are to: (1) educate researchers, developers, and end users on the effects that preprocessing has on climate predictions; (2) provide recommended practices for data preprocessing for such applications; and (3) empower end users to decipher whether the models they are using are properly designed for their objectives. Specific topics covered in this article include the creation of (standardized) anomalies, dealing with non-stationarity and the spatiotemporally correlated nature of climate data, and handling of extreme values and variables with potentially complex distributions. Case studies will illustrate how using different preprocessing techniques can produce different predictions from the same model, which can create confusion and decrease confidence in the overall process. Ultimately, implementing the recommended practices set forth in this article will enhance the robustness and transparency of AI/ML in climate prediction studies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.07062v1</guid>
      <category>physics.data-an</category>
      <category>cs.LG</category>
      <category>physics.ao-ph</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jason C. Furtado, Maria J. Molina, Marybeth C. Arcodia, Weston Anderson, Tom Beucler, John A. Callahan, Laura M. Ciasto, Vittorio A. Gensini, Michelle L'Heureux, Kathleen Pegion, Jhayron S. P\'erez-Carrasquilla, Maike Sonnewald, Ken Takahashi, Baoqiang Xiang, Brian G. Zimmerman</dc:creator>
    </item>
    <item>
      <title>Benchmarking Self-Driving Labs</title>
      <link>https://arxiv.org/abs/2508.06642</link>
      <description>arXiv:2508.06642v1 Announce Type: cross 
Abstract: A key goal of modern materials science is accelerating the pace of materials discovery. Self-driving labs, or systems that select experiments using machine learning and then execute them using automation, are designed to fulfil this promise by performing experiments faster, more intelligently, more reliably, and with richer metadata than conventional means. This review summarizes progress in understanding the degree to which SDLs accelerate learning by quantifying how much they reduce the number of experiments required for a given goal. The review begins by summarizing the theory underlying two key metrics, namely acceleration factor AF and enhancement factor EF, which quantify how much faster and better an algorithm is relative to a reference strategy. Next, we provide a comprehensive review of the literature, which reveals a wide range of AFs with a median of 6, and that tends to increase with the dimensionality of the space, reflecting an interesting blessing of dimensionality. In contrast, reported EF values vary by over two orders of magnitude, although they consistently peak at 10-20 experiments per dimension. To understand these results, we perform a series of simulated Bayesian optimization campaigns that reveal how EF depends upon the statistical properties of the parameter space while AF depends on its complexity. Collectively, these results reinforce the motivation for using SDLs by revealing their value across a wide range of material parameter spaces and provide a common language for quantifying and understanding this acceleration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.06642v1</guid>
      <category>cond-mat.mtrl-sci</category>
      <category>cs.LG</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Adedire D. Adesiji, Jiashuo Wang, Cheng-Shu Kuo, Keith A. Brown</dc:creator>
    </item>
    <item>
      <title>Conditional splitting probabilities for hidden-state inference in drift-diffusive processes</title>
      <link>https://arxiv.org/abs/2508.07386</link>
      <description>arXiv:2508.07386v1 Announce Type: cross 
Abstract: Splitting probabilities quantify the likelihood of particular outcomes out of a set of mutually-exclusive possibilities for stochastic processes and play a central role in first-passage problems. For two-dimensional Markov processes $\{X(t),Y(t)\}_{t\in T}$, a joint analogue of the splitting probabilities can be defined, which captures the likelihood that the variable $X(t)$, having been initialised at $x_0 \in \mathbb{L}$, exits $\mathbb{L}$ for the first time via either of the interval boundaries \emph{and} that the variable $Y(t)$, initialised at $y_0$, is given by $y_{\rm exit}$ at the time of exit. We compute such joint splitting probabilities for two classes of processes: processes where $X(t)$ is Brownian motion and $Y(t)$ is a decoupled internal state, and unidirectionally coupled processes where $X(t)$ is drift-diffusive and depends on $Y(t)$, while $Y(t)$ evolves independently. For the first class we obtain generic expressions in terms of the eigensystem of the Fokker-Planck operator for the $Y$ dynamics, while for the second we carry out explicit derivations for three paradigmatic cases (run-and-tumble motion, diffusion in an intermittent piecewise-linear potential and diffusion with stochastic resetting). Drawing on Bayes' theorem, we subsequently introduce the related notion of conditional splitting probabilities, defined as the posterior likelihoods of the internal state $Y$ \emph{given} that the observable degree of freedom $X$ has undergone a specific exit event. After computing these conditional splitting probabilities, we propose a simple scheme that leverages them to partially infer the assumedly hidden state $Y(t)$ from point-wise detection events.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.07386v1</guid>
      <category>math-ph</category>
      <category>cond-mat.stat-mech</category>
      <category>math.MP</category>
      <category>math.PR</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Emir Sezik, Jacob Knight, Henry Alston, Connor Roberts, Thibault Bertrand, Gunnar Pruessner, Luca Cocconi</dc:creator>
    </item>
    <item>
      <title>Real-Time Analysis of Unstructured Data with Machine Learning on Heterogeneous Architectures</title>
      <link>https://arxiv.org/abs/2508.07423</link>
      <description>arXiv:2508.07423v1 Announce Type: cross 
Abstract: As the particle physics community needs higher and higher precisions in order to test our current model of the subatomic world, larger and larger datasets are necessary. With upgrades scheduled for the detectors of colliding-beam experiments around the world, and specifically at the Large Hadron Collider at CERN, more collisions and more complex interactions are expected. This directly implies an increase in data produced and consequently in the computational resources needed to process them. At CERN, the amount of data produced is gargantuan. This is why the data have to be heavily filtered and selected in real time before being permanently stored. This data can then be used to perform physics analyses, in order to expand our current understanding of the universe and improve the Standard Model of physics. This real-time filtering, known as triggering, involves complex processing happening often at frequencies as high as 40 MHz. This thesis contributes to understanding how machine learning models can be efficiently deployed in such environments, in order to maximize throughput and minimize energy consumption. Inevitably, modern hardware designed for such tasks and contemporary algorithms are needed in order to meet the challenges posed by the stringent, high-frequency data rates. In this work, I present our graph neural network-based pipeline, developed for charged particle track reconstruction at the LHCb experiment at CERN. The pipeline was implemented end-to-end inside LHCb's first-level trigger, entirely on GPUs. Its performance was compared against the classical tracking algorithms currently in production at LHCb. The pipeline was also accelerated on the FPGA architecture, and its performance in terms of power consumption and processing speed was compared against the GPU implementation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.07423v1</guid>
      <category>hep-ex</category>
      <category>cs.AI</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fotis I. Giasemis</dc:creator>
    </item>
    <item>
      <title>High-background X-ray single particle imaging enabled by holographic enhancement with 2D crystals</title>
      <link>https://arxiv.org/abs/2508.07953</link>
      <description>arXiv:2508.07953v1 Announce Type: cross 
Abstract: X-ray single particle imaging (SPI) has offered the potential to visualize structures of biomolecules at near-atomic resolution. However, state-of-the-art structures at X-ray free electron lasers (XFELs) are limited to moderate resolution, primarily due to background scattering. We computationally explore a modified SPI technique based on holographic enhancement from a strongly scattering 2D crystal lattice placed near the object. The Bragg peaks from the crystal enable structure retrieval even for background levels up to 10$^{5}$ times higher than the object signal. This method could enable SPI at more widely accessible synchrotron sources, where even detection of objects before radiation damage is nearly impossible currently, supports practical fixed-target sample delivery, and enables high-resolution imaging under near-native conditions. Numerical simulations with a custom reconstruction algorithm to recover the latent parameters show the potential to improve the achievable resolution while also expanding the accessibility to the technique.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.07953v1</guid>
      <category>physics.optics</category>
      <category>eess.IV</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Abhishek Mall, Zhou Shen, Kartik Ayyer</dc:creator>
    </item>
    <item>
      <title>Effect of filter kernel on scale-energetics of near-wall turbulent structures</title>
      <link>https://arxiv.org/abs/2008.03535</link>
      <description>arXiv:2008.03535v2 Announce Type: replace-cross 
Abstract: Inter-scale energy fluxes, $\Pi^\lambda$, are widely used as a diagnostic tool to analyse energy transfer across length scales, $\lambda$, in turbulence data. Here, we investigate how the choice of filter kernel (sharp spectral, Gaussian, box) affects the computed energy fluxes at constant filter width. We apply spatial filtering to a turbulent pipe flow simulation dataset and assess the effect on the local structure of $\Pi$. While the mean energy flux profile at each wall-normal distance is qualitatively robust across kernels, we observe significant differences in the intensity and spatial distribution of localised $\Pi$ events. Correlations between typical flow structures in the buffer layer (streaks, vortices, and Q-events) and regions of forward/backward transfer in the instantaneous $\Pi$ field differ markedly between kernel types. Cross-correlations appear strongly upstream--downstream symmetric when using the sharp spectral kernel, but asymmetric for the Gaussian and box kernels. For the Gaussian and box kernels $\Pi$ events tend to localise along the inclined meander of streaks, while they are centred on top of the streaks for the sharp spectral kernel. Moreover, using the sharp spectral kernel, we observe a coincidence of backward scatter and fluid transport away from the wall ($Q_1$), which does not appear with the Gaussian and box kernels. All kernels, however, predict backward scatter directly downstream of $Q_1$ events. The results suggest that interpretations of inter-scale energy flux based on sharp spectral scale separation should be treated with caution, since such kernels act non-local in physical space, whereas $\Pi$ events are inherently localised. Our python post-processing tool eFlux for scale separation and energy flux analysis in pipe flows is freely available and readily adaptable to other flow configurations and filter widths.</description>
      <guid isPermaLink="false">oai:arXiv.org:2008.03535v2</guid>
      <category>physics.flu-dyn</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniel Feldmann, Mohammad Umair, Marc Avila, Alexandra von Kameke</dc:creator>
    </item>
    <item>
      <title>An information-matching approach to optimal experimental design and active learning</title>
      <link>https://arxiv.org/abs/2411.02740</link>
      <description>arXiv:2411.02740v3 Announce Type: replace-cross 
Abstract: The efficacy of mathematical models heavily depends on the quality of the training data, yet collecting sufficient data is often expensive and challenging. Many modeling applications require inferring parameters only as a means to predict other quantities of interest (QoI). Because models often contain many unidentifiable (sloppy) parameters, QoIs often depend on a relatively small number of parameter combinations. Therefore, we introduce an information-matching criterion based on the Fisher Information Matrix to select the most informative training data from a candidate pool. This method ensures that the selected data contain sufficient information to learn only those parameters that are needed to constrain downstream QoIs. It is formulated as a convex optimization problem, making it scalable to large models and datasets. We demonstrate the effectiveness of this approach across various modeling problems in diverse scientific fields, including power systems and underwater acoustics. Finally, we use information-matching as a query function within an Active Learning loop for material science applications. In all these applications, we find that a relatively small set of optimal training data can provide the necessary information for achieving precise predictions. These results are encouraging for diverse future applications, particularly active learning in large machine learning models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.02740v3</guid>
      <category>cs.LG</category>
      <category>cond-mat.mtrl-sci</category>
      <category>physics.app-ph</category>
      <category>physics.comp-ph</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yonatan Kurniawan (Brigham Young University, Provo, UT, USA), Tracianne B. Neilsen (Brigham Young University, Provo, UT, USA), Benjamin L. Francis (Achilles Heel Technologies, Orem, UT, USA), Alex M. Stankovic (SLAC National Accelerator Laboratory, Menlo Park, CA, USA), Mingjian Wen (University of Electronic Science and Technology of China, Chengdu, China), Ilia Nikiforov (University of Minnesota, Minneapolis, MN, USA), Ellad B. Tadmor (University of Minnesota, Minneapolis, MN, USA), Vasily V. Bulatov (Lawrence Livermore National Laboratory), Vincenzo Lordi (Lawrence Livermore National Laboratory), Mark K. Transtrum (Brigham Young University, Provo, UT, USA, SLAC National Accelerator Laboratory, Menlo Park, CA, USA)</dc:creator>
    </item>
    <item>
      <title>Reconstruction of boosted and resolved multi-Higgs-boson events with symmetry-preserving attention networks</title>
      <link>https://arxiv.org/abs/2412.03819</link>
      <description>arXiv:2412.03819v3 Announce Type: replace-cross 
Abstract: The production of multiple Higgs bosons at the CERN LHC provides a direct way to measure the trilinear and quartic Higgs self-interaction strengths as well as potential access to beyond the standard model effects that can enhance production at large transverse momentum $p_{\mathrm{T}}$. The largest event fraction arises from the fully hadronic final state in which every Higgs boson decays to a bottom quark-antiquark pair ($b\bar{b}$). This introduces a combinatorial challenge known as the \emph{jet assignment problem}: assigning jets to sets representing Higgs boson candidates. Symmetry-preserving attention networks (SPA-Nets) have been been developed to address this challenge. However, the complexity of jet assignment increases when simultaneously considering both $H\rightarrow b\bar{b}$ reconstruction possibilities, i.e., two "resolved" small-radius jets each containing a shower initiated by a $b$-quark or one "boosted" large-radius jet containing a merged shower initiated by a $b\bar{b}$ pair. The latter improves the reconstruction efficiency at high $p_{\mathrm{T}}$. In this work, we introduce a generalization to the SPA-Net approach to simultaneously consider both boosted and resolved reconstruction possibilities and unambiguously interpret an event as "fully resolved'', "fully boosted", or in between. We report the performance of baseline methods, the original SPA-Net approach, and our generalized version on nonresonant $HH$ and $HHH$ production at the LHC. Considering both boosted and resolved topologies, our SPA-Net approach increases the Higgs boson reconstruction purity by 57--62\% and the efficiency by 23--38\% compared to the baseline method depending on the final state.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.03819v3</guid>
      <category>hep-ph</category>
      <category>cs.LG</category>
      <category>hep-ex</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haoyang Li, Marko Stamenkovic, Alexander Shmakov, Michael Fenton, Darius Shih-Chieh Chao, Kaitlyn Maiya White, Caden Mikkelsen, Jovan Mitic, Cristina Mantilla Suarez, Melissa Quinnan, Greg Landsberg, Harvey Newman, Pierre Baldi, Daniel Whiteson, Javier Duarte</dc:creator>
    </item>
    <item>
      <title>Quantitative approaches for multi-scale structural analysis with atomic resolution electron microscopy</title>
      <link>https://arxiv.org/abs/2504.01159</link>
      <description>arXiv:2504.01159v2 Announce Type: replace-cross 
Abstract: Atomic-resolution imaging with scanning transmission electron microscopy is a powerful tool for characterizing the nanoscale structure of materials, in particular features such as defects, local strains, and symmetry-breaking distortions. In addition to advanced instrumentation, the effectiveness of the technique depends on computational image analysis to extract meaningful features from complex datasets recorded in experiments, which can be complicated by the presence of noise and artifacts, small or overlapping features, and the need to scale analysis over large representative areas. Here, we present image analysis approaches which synergize real and reciprocal space information to efficiently and reliably obtain meaningful structural information with picometer scale precision across hundreds of nanometers of material from atomic-resolution electron microscope images. Damping superstructure peaks in reciprocal space allows symmetry-breaking structural distortions to be disentangled from other sources of inhomogeneity and measured with high precision. Real space fitting of the wave-like signals resulting from Fourier filtering enables absolute quantification of lattice parameter variations and strain, as well as the uncertainty associated with these measurements. Implementations of these algorithms are made available as an open source Python package.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.01159v2</guid>
      <category>cond-mat.mtrl-sci</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Noah Schnitzer, Lopa Bhatt, Ismail El Baggari, Robert Hovden, Benjamin H. Savitzky, Michelle A. Smeaton, Berit H. Goodge</dc:creator>
    </item>
    <item>
      <title>UniFoil: A Universal Dataset of Airfoils in Transitional and Turbulent Regimes for Subsonic and Transonic Flows</title>
      <link>https://arxiv.org/abs/2505.21124</link>
      <description>arXiv:2505.21124v3 Announce Type: replace-cross 
Abstract: We present UniFoil, a large publicly available universal airfoil dataset based on Reynolds-averaged Navier-Stokes (RANS) simulations. It contains over 500,000 samples spanning a wide range of Reynolds and Mach numbers, capturing both transitional and fully turbulent flows across incompressible to compressible regimes. UniFoil is designed to support machine learning research in fluid dynamics, particularly for modeling complex aerodynamic phenomena. Most existing datasets are limited to incompressible, fully turbulent flows with smooth field characteristics, overlooking the critical physics of laminar\-turbulent transition and shock\-wave interactions\-features that exhibit strong nonlinearity and sharp gradients. UniFoil addresses this limitation by offering a broad spectrum of realistic flow conditions. Turbulent simulations utilize the Spalart\-Allmaras (SA) model, while transitional flows are modeled using an e^N\-based transition prediction method coupled with the SA model. The dataset includes a comprehensive geometry set comprising over 4,800 natural laminar flow (NLF) airfoils and 30,000 fully turbulent (FT) airfoils, covering a diverse range of airfoil designs relevant to aerospace, wind energy, and marine applications. This dataset is also valuable for scientific machine learning, enabling the development of data-driven models that more accurately capture the transport processes associated with laminar-turbulent transition. UniFoil is freely available under a permissive CC\-BY\-SA license.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21124v3</guid>
      <category>physics.flu-dyn</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Rohit Sunil Kanchi, Benjamin Melanson, Nithin Somasekharan, Shaowu Pan, Sicheng He</dc:creator>
    </item>
  </channel>
</rss>
