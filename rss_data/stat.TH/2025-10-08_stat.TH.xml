<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.TH updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.TH</link>
    <description>stat.TH updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.TH" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 08 Oct 2025 04:05:57 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Weak convergence of Bayes estimators under general loss functions</title>
      <link>https://arxiv.org/abs/2510.05645</link>
      <description>arXiv:2510.05645v1 Announce Type: new 
Abstract: We investigate the asymptotic behavior of parametric Bayes estimators under a broad class of loss functions that extend beyond the classical translation-invariant setting. To this end, we develop a unified theoretical framework for loss functions exhibiting locally polynomial structure. This general theory encompasses important examples such as the squared Wasserstein distance, the Sinkhorn divergence and Stein discrepancies, which have gained prominence in modern statistical inference and machine learning. Building on the classical Bernstein--von Mises theorem, we establish sufficient conditions under which Bayes estimators inherit the posterior's asymptotic normality. As a by-product, we also derive conditions for the differentiability of Wasserstein-induced loss functions and provide new consistency results for Bayes estimators. Several examples and numerical experiments demonstrate the relevance and accuracy of the proposed methodology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05645v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Robin Requadt, Housen Li, Axel Munk</dc:creator>
    </item>
    <item>
      <title>Sample complexity for entropic optimal transport with radial cost</title>
      <link>https://arxiv.org/abs/2510.05685</link>
      <description>arXiv:2510.05685v1 Announce Type: new 
Abstract: We prove a new sample complexity result for entropy regularized optimal transport. Our bound holds for probability measures on $\mathbb R^d$ with exponential tail decay and for radial cost functions that satisfy a local Lipschitz condition. It is sharp up to logarithmic factors, and captures the intrinsic dimension of the marginal distributions through a generalized covering number of their supports. Examples that fit into our framework include subexponential and subgaussian distributions and radial cost functions $c(x,y)=|x-y|^p$ for $p\ge 2.$</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05685v1</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ruiyu Han. Johannes Wiesel</dc:creator>
    </item>
    <item>
      <title>Measures of Dependence based on Wasserstein distances</title>
      <link>https://arxiv.org/abs/2510.06034</link>
      <description>arXiv:2510.06034v1 Announce Type: new 
Abstract: Measuring dependence between random variables is a fundamental problem in Statistics, with applications across diverse fields. While classical measures such as Pearson's correlation have been widely used for over a century, they have notable limitations, particularly in capturing nonlinear relationships and extending to general metric spaces. In recent years, the theory of Optimal Transport and Wasserstein distances has provided new tools to define measures of dependence that generalize beyond Euclidean settings. This survey explores recent proposals, outlining two main approaches: one based on the distance between the joint distribution and the product of marginals, and another leveraging conditional distributions. We discuss key properties, including characterization of independence, normalization, invariances, robustness, sample, and computational complexity. Additionally, we propose an alternative perspective that measures deviation from maximal dependence rather than independence, leading to new insights and potential extensions. Our work highlights recent advances in the field and suggests directions for further research in the measurement of dependence using Optimal Transport.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.06034v1</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marta Catalano, Hugo Lavenant</dc:creator>
    </item>
    <item>
      <title>Construction of optimal tests for symmetry on the torus and their quantitative error bounds</title>
      <link>https://arxiv.org/abs/2510.06055</link>
      <description>arXiv:2510.06055v1 Announce Type: new 
Abstract: In this paper, we develop optimal tests for symmetry on the hyper-dimensional torus, leveraging Le Cam's methodology. We address both scenarios where the center of symmetry is known and where it is unknown. These tests are not only valid under a given parametric hypothesis but also under a very broad class of symmetric distributions. The asymptotic behavior of the proposed tests is studied both under the null hypothesis and local alternatives, and we derive quantitative bounds on the distributional distance between the exact (unknown) distribution of the test statistic and its asymptotic counterpart using Stein's method. The finite-sample performance of the tests is evaluated through simulation studies, and their practical utility is demonstrated via an application to protein folding data. Additionally, we establish a broadly applicable result on the quadratic mean differentiability of functions, a key property underpinning the use of Le Cam's approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.06055v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andreas Anastasiou, Christophe Ley, Sophia Loizidou</dc:creator>
    </item>
    <item>
      <title>Optimal sub-Gaussian variance proxy for 3-mass distributions</title>
      <link>https://arxiv.org/abs/2510.06132</link>
      <description>arXiv:2510.06132v1 Announce Type: new 
Abstract: We investigate the problem of characterizing the optimal variance proxy for sub-Gaussian random variables,whose moment-generating function exhibits bounded growth at infinity. We apply a general characterization method to discrete random variables with equally spaced atoms. We thoroughly study 3-mass distributions, thereby generalizing the well-studied Bernoulli case. We also prove that the discrete uniform distribution over $N$ points is strictly sub-Gaussian. Finally, we provide an open-source Python package that combines analytical and numerical approaches to compute optimal sub-Gaussian variance proxies across a wide range of distributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.06132v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Soufiane Atouani, Olivier Marchal, Julyan Arbel</dc:creator>
    </item>
    <item>
      <title>Hadamard ranks of algebraic varieties</title>
      <link>https://arxiv.org/abs/2510.05231</link>
      <description>arXiv:2510.05231v1 Announce Type: cross 
Abstract: Motivated by the study of decompositions of tensors as Hadamard products (i.e., coefficient-wise products) of low-rank tensors, we introduce the notion of Hadamard rank of a given point with respect to a projective variety: if it exists, it is the smallest number of points in the variety such that the given point is equal to their Hadamard product. We prove that if the variety $X$ is not contained in a coordinate hyperplane or a binomial hypersurface, then the generic point has a finite $X$-Hadamard-rank. Although the Hadamard rank might not be well defined for special points, we prove that the general Hadamard rank with respect to secant varieties of toric varieties is finite and the maximum Hadamard rank for points with no coordinates equal to zero is at most twice the generic rank. In particular, we focus on Hadamard ranks with respect to secant varieties of toric varieties since they provide a geometric framework in which Hadamard decompositions of tensors can be interpreted. Finally, we give a lower bound to the dimension of Hadamard products of secant varieties of toric varieties: this allows us to deduce the general Hadamard rank with respect to secant varieties of several Segre-Veronese varieties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05231v1</guid>
      <category>math.AG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dario Antolini, Guido Mont\'ufar, Alessandro Oneto</dc:creator>
    </item>
    <item>
      <title>Transfer Learning on Edge Connecting Probability Estimation under Graphon Model</title>
      <link>https://arxiv.org/abs/2510.05527</link>
      <description>arXiv:2510.05527v1 Announce Type: cross 
Abstract: Graphon models provide a flexible nonparametric framework for estimating latent connectivity probabilities in networks, enabling a range of downstream applications such as link prediction and data augmentation. However, accurate graphon estimation typically requires a large graph, whereas in practice, one often only observes a small-sized network. One approach to addressing this issue is to adopt a transfer learning framework, which aims to improve estimation in a small target graph by leveraging structural information from a larger, related source graph. In this paper, we propose a novel method, namely GTRANS, a transfer learning framework that integrates neighborhood smoothing and Gromov-Wasserstein optimal transport to align and transfer structural patterns between graphs. To prevent negative transfer, GTRANS includes an adaptive debiasing mechanism that identifies and corrects for target-specific deviations via residual smoothing. We provide theoretical guarantees on the stability of the estimated alignment matrix and demonstrate the effectiveness of GTRANS in improving the accuracy of target graph estimation through extensive synthetic and real data experiments. These improvements translate directly to enhanced performance in downstream applications, such as the graph classification task and the link prediction task.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05527v1</guid>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuyao Wang, Yu-Hung Cheng, Debarghya Mukherjee, Huimin Cheng</dc:creator>
    </item>
    <item>
      <title>A Note on "Quasi-Maximum-Likelihood Estimation in Conditionally Heteroscedastic Time Series: A Stochastic Recurrence Equations Approach"</title>
      <link>https://arxiv.org/abs/2510.05716</link>
      <description>arXiv:2510.05716v1 Announce Type: cross 
Abstract: Bougerol (1993) and Straumann and Mikosch (2006) gave conditions under which there exists a unique stationary and ergodic solution to the stochastic difference equation $Y_t \overset{a.s.}{=} \Phi_t (Y_{t-1}), t \in \mathbb{Z}$ where $(\Phi_t)_{t \in \mathbb{Z}}$ is a sequence of stationary and ergodic random Lipschitz continuous functions from $(Y,|| \cdot ||)$ to $(Y,|| \cdot ||)$ where $(Y,|| \cdot ||)$ is a complete subspace of a real or complex separable Banach space. In the case where $(Y,|| \cdot ||)$ is a real or complex separable Banach space, Straumann and Mikosch (2006) also gave conditions under which any solution to the stochastic difference equation $\hat{Y}_t \overset{a.s.}{=} \hat{\Phi}_t (\hat{Y}_{t-1}), t \in \mathbb{N}$ with $\hat{Y}_0$ given where $(\hat{\Phi}_t)_{t \in \mathbb{N}}$ is only a sequence of random Lipschitz continuous functions from $(Y,|| \cdot ||)$ to $(Y,|| \cdot ||)$ satisfies $\gamma^t || \hat{Y}_t - Y_t || \overset{a.s.}{\rightarrow} 0$ as $t \rightarrow \infty$ for some $\gamma &gt; 1$. In this note, we give slightly different conditions under which this continues to hold in the case where $(Y,|| \cdot ||)$ is only a complete subspace of a real or complex separable Banach space by using close to identical arguments as Straumann and Mikosch (2006).</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05716v1</guid>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Frederik Krabbe</dc:creator>
    </item>
    <item>
      <title>A Universal Moments-Only Bound for Cumulants</title>
      <link>https://arxiv.org/abs/2510.05739</link>
      <description>arXiv:2510.05739v1 Announce Type: cross 
Abstract: We establish a simple, universal inequality that bounds the $n$-th cumulant of a real-valued random variable using only its $n$-th (absolute or central) moment. Specifically, for any integer $n \ge 1$, the $n$-th cumulant $\kappa_n(X)$ satisfies \[ \lvert \kappa_n(X) \rvert \;\le\; C_n\, \mathbb{E}\lvert X-\mathbb{E}X\rvert^{\,n}, \] with an alternative bound in terms of $\mathbb{E}\lvert X\rvert^{\,n}$ in the uncentered form. The coefficient $C_n$ is derived from the combinatorial structure of the moment--cumulant formula and exhibits the asymptotic behavior $C_n \sim (n-1)!/\rho^{\,n}$, giving an exponential improvement over classical bounds that grow on the order of $n^n$.
  In full generality, the bound involves the ordered Bell numbers, corresponding to a rate parameter $\rho=\ln 2\approx 0.693$. For $n\ge 2$, shift-invariance of cumulants yields a universal centered refinement with parameter $\rho_0\approx 1.146$, determined by $e^{\rho_0}=2+\rho_0$. For symmetric random variables, the bound sharpens further to $\rho_{\mathrm{sym}}=\operatorname{arcosh}2\approx 1.317$. These results extend naturally to the multivariate setting, providing uniform control of joint cumulants under the same minimal moment assumptions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05739v1</guid>
      <category>math.PR</category>
      <category>math.CO</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiechen Zhang</dc:creator>
    </item>
    <item>
      <title>Coherent estimation of risk measures</title>
      <link>https://arxiv.org/abs/2510.05809</link>
      <description>arXiv:2510.05809v1 Announce Type: cross 
Abstract: We develop a statistical framework for risk estimation, inspired by the axiomatic theory of risk measures. Coherent risk estimators -- functionals of P&amp;L samples inheriting the economic properties of risk measures -- are defined and characterized through robust representations linked to $L$-estimators. The framework provides a canonical methodology for constructing estimators with sound financial and statistical properties, unifying risk measure theory, principles for capital adequacy, and practical statistical challenges in market risk. A numerical study illustrates the approach, focusing on expected shortfall estimation under both i.i.d. and overlapping samples relevant for regulatory FRTB model applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05809v1</guid>
      <category>q-fin.RM</category>
      <category>math.ST</category>
      <category>q-fin.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Martin Aichele, Igor Cialenco, Damian Jelito, Marcin Pitera</dc:creator>
    </item>
    <item>
      <title>A subsampling approach for large data sets when the Generalised Linear Model is potentially misspecified</title>
      <link>https://arxiv.org/abs/2510.05902</link>
      <description>arXiv:2510.05902v1 Announce Type: cross 
Abstract: Subsampling is a computationally efficient and scalable method to draw inference in large data settings based on a subset of the data rather than needing to consider the whole dataset. When employing subsampling techniques, a crucial consideration is how to select an informative subset based on the queries posed by the data analyst. A recently proposed method for this purpose involves randomly selecting samples from the large dataset based on subsampling probabilities. However, a major drawback of this approach is that the derived subsampling probabilities are typically based on an assumed statistical model which may be difficult to correctly specify in practice. To address this limitation, we propose to determine subsampling probabilities based on a statistical model that we acknowledge may be misspecified. To do so, we propose to evaluate the subsampling probabilities based on the Mean Squared Error (MSE) of the predictions from a model that is not assumed to completely describe the large dataset. We apply our subsampling approach in a simulation study and for the analysis of two real-world large datasets, where its performance is benchmarked against existing subsampling techniques. The findings suggest that there is value in adopting our approach over current practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05902v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amalan Mahendran, Helen Thompson, James M. McGree</dc:creator>
    </item>
    <item>
      <title>Minimal Unimodal Decomposition is NP-Hard on Graphs</title>
      <link>https://arxiv.org/abs/2510.05944</link>
      <description>arXiv:2510.05944v1 Announce Type: cross 
Abstract: A function on a topological space is called unimodal if all of its super-level sets are contractible. A minimal unimodal decomposition of a function $f$ is the smallest number of unimodal functions that sum up to $f$. The problem of decomposing a given density function into its minimal unimodal components is fundamental in topological statistics. We show that finding a minimal unimodal decomposition of an edge-linear function on a graph is NP-hard. Given any $k \geq 2$, we establish the NP-hardness of finding a unimodal decomposition consisting of $k$ unimodal functions. We also extend the NP-hardness result to related variants of the problem, including restriction to planar graphs, inapproximability results, and generalizations to higher dimensions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05944v1</guid>
      <category>math.AT</category>
      <category>cs.CG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mishal Assif P K, Yuliy Baryshnikov</dc:creator>
    </item>
    <item>
      <title>Robust Inference for Convex Pairwise Difference Estimators</title>
      <link>https://arxiv.org/abs/2510.05991</link>
      <description>arXiv:2510.05991v1 Announce Type: cross 
Abstract: This paper develops distribution theory and bootstrap-based inference methods for a broad class of convex pairwise difference estimators. These estimators minimize a kernel-weighted convex-in-parameter function over observation pairs that are similar in terms of certain covariates, where the similarity is governed by a localization (bandwidth) parameter. While classical results establish asymptotic normality under restrictive bandwidth conditions, we show that valid Gaussian and bootstrap-based inference remains possible under substantially weaker assumptions. First, we extend the theory of small bandwidth asymptotics to convex pairwise estimation settings, deriving robust Gaussian approximations even when a smaller than standard bandwidth is used. Second, we employ a debiasing procedure based on generalized jackknifing to enable inference with larger bandwidths, while preserving convexity of the objective function. Third, we construct a novel bootstrap method that adjusts for bandwidth-induced variance distortions, yielding valid inference across a wide range of bandwidth choices. Our proposed inference method enjoys demonstrable more robustness, while retaining the practical appeal of convex pairwise difference estimators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05991v1</guid>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matias D. Cattaneo, Michael Jansson, Kenichi Nagasawa</dc:creator>
    </item>
    <item>
      <title>Higher-Order Feature Attribution: Bridging Statistics, Explainable AI, and Topological Signal Processing</title>
      <link>https://arxiv.org/abs/2510.06165</link>
      <description>arXiv:2510.06165v1 Announce Type: cross 
Abstract: Feature attributions are post-training analysis methods that assess how various input features of a machine learning model contribute to an output prediction. Their interpretation is straightforward when features act independently, but becomes less direct when the predictive model involves interactions such as multiplicative relationships or joint feature contributions. In this work, we propose a general theory of higher-order feature attribution, which we develop on the foundation of Integrated Gradients (IG). This work extends existing frameworks in the literature on explainable AI. When using IG as the method of feature attribution, we discover natural connections to statistics and topological signal processing. We provide several theoretical results that establish the theory, and we validate our theory on a few examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.06165v1</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kurt Butler, Guanchao Feng, Petar Djuric</dc:creator>
    </item>
    <item>
      <title>Power-divergence copulas: A new class of Archimedean copulas, with an insurance application</title>
      <link>https://arxiv.org/abs/2510.06177</link>
      <description>arXiv:2510.06177v1 Announce Type: cross 
Abstract: This paper demonstrates that, under a particular convention, the convex functions that characterise the phi divergences also generate Archimedean copulas in at least two dimensions. As a special case, we develop the family of Archimedean copulas associated with the important family of power divergences, which we call the power-divergence copulas. The properties of the family are extensively studied, including the subfamilies that are absolutely continuous or have a singular component, the ordering of the family, limiting cases (i.e., the Frechet-Hoeffding lower bound and Frechet-Hoeffding upper bound), the Kendall's tau and tail-dependence coefficients, and cases that extend to three or more dimensions. In an illustrative application, the power-divergence copulas are used to model a Danish fire insurance dataset. It is shown that the power-divergence copulas provide an adequate fit to the bivariate distribution of two kinds of fire-related losses claimed by businesses, while several benchmarks (a suite of well known Archimedean, extreme-value, and elliptical copulas) do not.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.06177v1</guid>
      <category>stat.ME</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alan R. Pearse, Howard Bondell</dc:creator>
    </item>
    <item>
      <title>Maximum Ideal Likelihood Estimation: A Unified Inference Framework for Latent Variable Models</title>
      <link>https://arxiv.org/abs/2410.01194</link>
      <description>arXiv:2410.01194v2 Announce Type: replace 
Abstract: This paper develops a unified estimation framework, the Maximum Ideal Likelihood Estimation (MILE), for general parametric models with latent variables. Unlike traditional approaches relying on the marginal likelihood of the observed data, MILE directly exploits the joint distribution of the complete data by treating the latent variables as parameters (the ideal likelihood). Borrowing strength from optimisation techniques and algorithms, MILE is a broadly applicable framework in case that traditional methods fail, such as when the marginal likelihood has non-finite expectations. MILE offers a flexible and robust alternative to established techniques, including the Expectation-Maximisation algorithm and Markov chain Monte Carlo. We facilitate statistical inference of MILE on consistency, asymptotic distribution, and equivalence to the Maximum Likelihood Estimation, under some mild conditions. Extensive simulations illustrative real-data applications illustrate the empirical advantages of MILE, outperforming existing methods on computational feasibility and scalability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.01194v2</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yizhou Cai, Ting Fung Ma</dc:creator>
    </item>
    <item>
      <title>Offline changepoint localization using a matrix of conformal p-values</title>
      <link>https://arxiv.org/abs/2505.00292</link>
      <description>arXiv:2505.00292v4 Announce Type: replace 
Abstract: Changepoint localization is the problem of estimating the index at which a change occurred in the data generating distribution of an ordered list of data, or declaring that no change occurred. We present the broadly applicable MCP algorithm, which uses a matrix of conformal p-values to produce a confidence interval for a (single) changepoint under the mild assumption that the pre-change and post-change distributions are each exchangeable. We prove a novel conformal Neyman-Pearson lemma, motivating practical classifier-based choices for our conformal score function. Finally, we exemplify the MCP algorithm on a variety of synthetic and real-world datasets, including using black-box pre-trained classifiers to detect changes in sequences of images, text, and accelerometer data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00292v4</guid>
      <category>math.ST</category>
      <category>eess.SP</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sanjit Dandapanthula, Aaditya Ramdas</dc:creator>
    </item>
    <item>
      <title>Towards multi-purpose locally differentially-private synthetic data release via spline wavelet plug-in estimation</title>
      <link>https://arxiv.org/abs/2508.13969</link>
      <description>arXiv:2508.13969v2 Announce Type: replace 
Abstract: We develop plug-in estimators for locally differentially private semi-parametric estimation via spline wavelets. The approach leads to optimal rates of convergence for a large class of estimation problems that are characterized by (differentiable) functionals $\Lambda(f)$ of the true data generating density $f$. The crucial feature of the locally private data $Z_1,\dots, Z_n$ we generate is that it does not depend on the particular functional $\Lambda$ (or the unknown density $f$) the analyst wants to estimate. Hence, the synthetic data can be generated and stored a priori and can subsequently be used by any number of analysts to estimate many vastly different functionals of interest at the provably optimal rate. In principle, this removes a long standing practical limitation in statistics of differential privacy, namely, that optimal privacy mechanisms need to be tailored towards the specific estimation problem at hand.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.13969v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thibault Randrianarisoa, Lukas Steinberger, Botond Szab\'o</dc:creator>
    </item>
    <item>
      <title>Identification in source apportionment using geometry</title>
      <link>https://arxiv.org/abs/2510.03616</link>
      <description>arXiv:2510.03616v2 Announce Type: replace 
Abstract: Source apportionment analysis, which aims to quantify the attribution of observed concentrations of multiple air pollutants to specific sources, can be formulated as a non-negative matrix factorization (NMF) problem. However, NMF is non-unique and typically relies on unverifiable assumptions such as sparsity and uninterpretable scalings. In this manuscript, we establish identifiability of the source attribution percentage matrix under much weaker and more realistic conditions. We introduce the population-level estimand for this matrix, and show that it is scale-invariant and identifiable even when the NMF factors are not. Viewing the data as a point cloud in a conical hull, we show that a geometric estimator of the source attribution percentage matrix is consistent without any sparsity or parametric distributional assumptions, and while accommodating spatio-temporal dependence. Numerical experiments corroborate the theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.03616v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bora Jin, Abhirup Datta</dc:creator>
    </item>
    <item>
      <title>Shrinkage Methods for Treatment Choice</title>
      <link>https://arxiv.org/abs/2210.17063</link>
      <description>arXiv:2210.17063v4 Announce Type: replace-cross 
Abstract: This study examines the problem of determining whether to treat individuals based on observed covariates. The most common decision rule is the conditional empirical success (CES) rule proposed by Manski (2004), which assigns individuals to treatments that yield the best experimental outcomes conditional on the observed covariates. Conversely, using shrinkage estimators, which shrink unbiased but noisy preliminary estimates toward the average of these estimates, is a common approach in statistical estimation problems because it is well-known that shrinkage estimators may have smaller mean squared errors than unshrunk estimators. Inspired by this idea, we propose a computationally tractable shrinkage rule that selects the shrinkage factor by minimizing an upper bound of the maximum regret. Then, we compare the maximum regret of the proposed shrinkage rule with those of the CES and pooling rules when the space of conditional average treatment effects (CATEs) is correctly specified or misspecified. Our theoretical results demonstrate that the shrinkage rule performs well in many cases and these findings are further supported by numerical experiments. Specifically, we show that the maximum regret of the shrinkage rule can be strictly smaller than those of the CES and pooling rules in certain cases when the space of CATEs is correctly specified. In addition, we find that the shrinkage rule is robust against misspecification of the space of CATEs. Finally, we apply our method to experimental data from the National Job Training Partnership Act Study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.17063v4</guid>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Takuya Ishihara, Daisuke Kurisu</dc:creator>
    </item>
    <item>
      <title>Information-Theoretic Thresholds for the Alignments of Partially Correlated Graphs</title>
      <link>https://arxiv.org/abs/2406.05428</link>
      <description>arXiv:2406.05428v3 Announce Type: replace-cross 
Abstract: This paper studies the problem of recovering the hidden vertex correspondence between two correlated random graphs. We propose the partially correlated Erd\H{o}s-R\'enyi graphs model, wherein a pair of induced subgraphs with a certain number are correlated. We investigate the information-theoretic thresholds for recovering the latent correlated subgraphs and the hidden vertex correspondence. We prove that there exists an optimal rate for partial recovery for the number of correlated nodes, above which one can correctly match a fraction of vertices and below which correctly matching any positive fraction is impossible, and we also derive an optimal rate for exact recovery. In the proof of possibility results, we propose correlated functional digraphs, which partition the edges of the intersection graph into two types of components, and bound the error probability by lower-order cumulant generating functions. The proof of impossibility results build upon the generalized Fano's inequality and the recovery thresholds settled in correlated Erd\H{o}s-R\'enyi graphs model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05428v3</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dong Huang, Xianwen Song, Pengkun Yang</dc:creator>
    </item>
    <item>
      <title>Conjugate gradient methods for high-dimensional GLMMs</title>
      <link>https://arxiv.org/abs/2411.04729</link>
      <description>arXiv:2411.04729v2 Announce Type: replace-cross 
Abstract: Generalized linear mixed models (GLMMs) are a widely used tool in statistical analysis. The main bottleneck of many computational approaches lies in the inversion of the high dimensional precision matrices associated with the random effects. Such matrices are typically sparse; however, the sparsity pattern resembles a multi partite random graph, which does not lend itself well to default sparse linear algebra techniques. Notably, we show that, for typical GLMMs, the Cholesky factor is dense even when the original precision is sparse. We thus turn to approximate iterative techniques, in particular to the conjugate gradient (CG) method. We combine a detailed analysis of the spectrum of said precision matrices with results from random graph theory to show that CG-based methods applied to high-dimensional GLMMs typically achieve a fixed approximation error with a total cost that scales linearly with the number of parameters and observations. Numerical illustrations with both real and simulated data confirm the theoretical findings, while at the same time illustrating situations, such as nested structures, where CG-based methods struggle.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04729v2</guid>
      <category>stat.CO</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrea Pandolfi, Omiros Papaspiliopoulos, Giacomo Zanella</dc:creator>
    </item>
    <item>
      <title>Quickest Change Detection with Cost-Constrained Experiment Design</title>
      <link>https://arxiv.org/abs/2509.14186</link>
      <description>arXiv:2509.14186v2 Announce Type: replace-cross 
Abstract: In the classical quickest change detection problem, an observer performs a single experiment to monitor a stochastic process. The goal in the classical problem is to detect a change in the statistical properties of the process, with the minimum possible delay, subject to a constraint on the rate of false alarms. This paper considers the case where, at each observation time, the decision-maker must choose between multiple experiments with varying information qualities and costs. The change can be detected using any of the experiments. The goal here is to detect the change with the minimum delay, subject to constraints on the rate of false alarms and the fraction of time each experiment is performed before the time of change. The constraint on the fraction of time can be used to control the overall cost of using the system of experiments. An algorithm called the two-experiment cumulative sum (2E-CUSUM) algorithm is first proposed to solve the problem when there are only two experiments. The algorithm for the case of multiple experiments, starting with three experiments, is then designed iteratively using the 2E-CUSUM algorithm. Two key ideas used in the design are the scaling of undershoots and the truncation of tests. The multiple-experiment algorithm can be designed to satisfy the constraints and can achieve the delay performance of the experiment with the highest quality within a constant. The important concept of data efficiency, where the observer has the choice of not performing any experiment, is explored as well.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14186v2</guid>
      <category>eess.SP</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Patrick Vincent N. Lubenia, Taposh Banerjee</dc:creator>
    </item>
  </channel>
</rss>
