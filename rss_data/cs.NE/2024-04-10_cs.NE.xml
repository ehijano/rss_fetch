<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NE</link>
    <description>cs.NE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 11 Apr 2024 04:00:01 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 11 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>An Enhanced Grey Wolf Optimizer with Elite Inheritance and Balance Search Mechanisms</title>
      <link>https://arxiv.org/abs/2404.06524</link>
      <description>arXiv:2404.06524v1 Announce Type: new 
Abstract: The Grey Wolf Optimizer (GWO) is recognized as a novel meta-heuristic algorithm inspired by the social leadership hierarchy and hunting mechanism of grey wolves. It is well-known for its simple parameter setting, fast convergence speed, and strong optimization capability. In the original GWO, there are two significant design flaws in its fundamental optimization mechanisms. Problem (1): the algorithm fails to inherit from elite positions from the last iteration when generating the next positions of the wolf population, potentially leading to suboptimal solutions. Problem (2): the positions of the population are updated based on the central position of the three leading wolves (alpha, beta, delta), without a balanced mechanism between local and global search. To tackle these problems, an enhanced Grey Wolf Optimizer with Elite Inheritance Mechanism and Balance Search Mechanism, named as EBGWO, is proposed to improve the effectiveness of the position updating and the quality of the convergence solutions. The IEEE CEC 2014 benchmark functions suite and a series of simulation tests are employed to evaluate the performance of the proposed algorithm. The simulation tests involve a comparative study between EBGWO, three GWO variants, GWO and two well-known meta-heuristic algorithms. The experimental results demonstrate that the proposed EBGWO algorithm outperforms other meta-heuristic algorithms in both accuracy and convergence speed. Three engineering optimization problems are adopted to prove its capability in processing real-world problems. The results indicate that the proposed EBGWO outperforms several popular algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06524v1</guid>
      <category>cs.NE</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Jianhua Jiang, Ziying Zhao, Weihua Li, Keqin Li</dc:creator>
    </item>
    <item>
      <title>Emergent Braitenberg-style Behaviours for Navigating the ViZDoom `My Way Home' Labyrinth</title>
      <link>https://arxiv.org/abs/2404.06529</link>
      <description>arXiv:2404.06529v1 Announce Type: new 
Abstract: The navigation of complex labyrinths with tens of rooms under visual partially observable state is typically addressed using recurrent deep reinforcement learning architectures. In this work, we show that navigation can be achieved through the emergent evolution of a simple Braitentberg-style heuristic that structures the interaction between agent and labyrinth, i.e. complex behaviour from simple heuristics. To do so, the approach of tangled program graphs is assumed in which programs cooperatively coevolve to develop a modular indexing scheme that only employs 0.8\% of the state space. We attribute this simplicity to several biases implicit in the representation, such as the use of pixel indexing as opposed to deploying a convolutional kernel or image processing operators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06529v1</guid>
      <category>cs.NE</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Caleidgh Bayer, Robert J. Smith, Malcolm I. Heywood</dc:creator>
    </item>
    <item>
      <title>Temporal True and Surrogate Fitness Landscape Analysis for Expensive Bi-Objective Optimisation</title>
      <link>https://arxiv.org/abs/2404.06557</link>
      <description>arXiv:2404.06557v1 Announce Type: new 
Abstract: Many real-world problems have expensive-to-compute fitness functions and are multi-objective in nature. Surrogate-assisted evolutionary algorithms are often used to tackle such problems. Despite this, literature about analysing the fitness landscapes induced by surrogate models is limited, and even non-existent for multi-objective problems. This study addresses this critical gap by comparing landscapes of the true fitness function with those of surrogate models for multi-objective functions. Moreover, it does so temporally by examining landscape features at different points in time during optimisation, in the vicinity of the population at that point in time. We consider the BBOB bi-objective benchmark functions in our experiments. The results of the fitness landscape analysis reveals significant differences between true and surrogate features at different time points during optimisation. Despite these differences, the true and surrogate landscape features still show high correlations between each other. Furthermore, this study identifies which landscape features are related to search and demonstrates that both surrogate and true landscape features are capable of predicting algorithm performance. These findings indicate that temporal analysis of the landscape features may help to facilitate the design of surrogate switching approaches to improve performance in multi-objective optimisation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06557v1</guid>
      <category>cs.NE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3638529.3654125</arxiv:DOI>
      <dc:creator>C. J. Rodriguez, S. L. Thomson, T. Alderliesten, P. A. N. Bosman</dc:creator>
    </item>
    <item>
      <title>Phylogeny-Informed Interaction Estimation Accelerates Co-Evolutionary Learning</title>
      <link>https://arxiv.org/abs/2404.06588</link>
      <description>arXiv:2404.06588v1 Announce Type: new 
Abstract: Co-evolution is a powerful problem-solving approach. However, fitness evaluation in co-evolutionary algorithms can be computationally expensive, as the quality of an individual in one population is defined by its interactions with many (or all) members of one or more other populations. To accelerate co-evolutionary systems, we introduce phylogeny-informed interaction estimation, which uses runtime phylogenetic analysis to estimate interaction outcomes between individuals based on how their relatives performed against each other. We test our interaction estimation method with three distinct co-evolutionary systems: two systems focused on measuring problem-solving success and one focused on measuring evolutionary open-endedness. We find that phylogeny-informed estimation can substantially reduce the computation required to solve problems, particularly at the beginning of long-term evolutionary runs. Additionally, we find that our estimation method initially jump-starts the evolution of neural complexity in our open-ended domain, but estimation-free systems eventually "catch-up" if given enough time. More broadly, continued refinements to these phylogeny-informed interaction estimation methods offers a promising path to reducing the computational cost of running co-evolutionary systems while maintaining their open-endedness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06588v1</guid>
      <category>cs.NE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jack Garbus, Thomas Willkens, Alexander Lalejini, Jordan Pollack</dc:creator>
    </item>
    <item>
      <title>Evolving Loss Functions for Specific Image Augmentation Techniques</title>
      <link>https://arxiv.org/abs/2404.06633</link>
      <description>arXiv:2404.06633v1 Announce Type: new 
Abstract: Previous work in Neural Loss Function Search (NLFS) has shown a lack of correlation between smaller surrogate functions and large convolutional neural networks with massive regularization. We expand upon this research by revealing another disparity that exists, correlation between different types of image augmentation techniques. We show that different loss functions can perform well on certain image augmentation techniques, while performing poorly on others. We exploit this disparity by performing an evolutionary search on five types of image augmentation techniques in the hopes of finding image augmentation specific loss functions. The best loss functions from each evolution were then taken and transferred to WideResNet-28-10 on CIFAR-10 and CIFAR-100 across each of the five image augmentation techniques. The best from that were then taken and evaluated by fine-tuning EfficientNetV2Small on the CARS, Oxford-Flowers, and Caltech datasets across each of the five image augmentation techniques. Multiple loss functions were found that outperformed cross-entropy across multiple experiments. In the end, we found a single loss function, which we called the inverse bessel logarithm loss, that was able to outperform cross-entropy across the majority of experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06633v1</guid>
      <category>cs.NE</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Brandon Morgan, Dean Hougen</dc:creator>
    </item>
    <item>
      <title>Neural Optimizer Equation, Decay Function, and Learning Rate Schedule Joint Evolution</title>
      <link>https://arxiv.org/abs/2404.06679</link>
      <description>arXiv:2404.06679v1 Announce Type: new 
Abstract: A major contributor to the quality of a deep learning model is the selection of the optimizer. We propose a new dual-joint search space in the realm of neural optimizer search (NOS), along with an integrity check, to automate the process of finding deep learning optimizers. Our dual-joint search space simultaneously allows for the optimization of not only the update equation, but also internal decay functions and learning rate schedules for optimizers. We search the space using our proposed mutation-only, particle-based genetic algorithm able to be massively parallelized for our domain-specific problem. We evaluate our candidate optimizers on the CIFAR-10 dataset using a small ConvNet. To assess generalization, the final optimizers were then transferred to large-scale image classification on CIFAR- 100 and TinyImageNet, while also being fine-tuned on Flowers102, Cars196, and Caltech101 using EfficientNetV2Small. We found multiple optimizers, learning rate schedules, and Adam variants that outperformed Adam, as well as other standard deep learning optimizers, across the image classification tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06679v1</guid>
      <category>cs.NE</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Brandon Morgan, Dean Hougen</dc:creator>
    </item>
    <item>
      <title>Solving the Food-Energy-Water Nexus Problem via Intelligent Optimization Algorithms</title>
      <link>https://arxiv.org/abs/2404.06769</link>
      <description>arXiv:2404.06769v1 Announce Type: new 
Abstract: The application of evolutionary algorithms (EAs) to multi-objective optimization problems has been widespread. However, the EA research community has not paid much attention to large-scale multi-objective optimization problems arising from real-world applications. Especially, Food-Energy-Water systems are intricately linked among food, energy and water that impact each other. They usually involve a huge number of decision variables and many conflicting objectives to be optimized. Solving their related optimization problems is essentially important to sustain the high-quality life of human beings. Their solution space size expands exponentially with the number of decision variables. Searching in such a vast space is challenging because of such large numbers of decision variables and objective functions. In recent years, a number of large-scale many-objectives optimization evolutionary algorithms have been proposed. In this paper, we solve a Food-Energy-Water optimization problem by using the state-of-art intelligent optimization methods and compare their performance. Our results conclude that the algorithm based on an inverse model outperforms the others. This work should be highly useful for practitioners to select the most suitable method for their particular large-scale engineering optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06769v1</guid>
      <category>cs.NE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qi Deng, Zheng Fan, Zhi Li, Xinna Pan, Qi Kang, MengChu Zhou</dc:creator>
    </item>
    <item>
      <title>Proposed modified computational model for the amoeba-inspired combinatorial optimization machine</title>
      <link>https://arxiv.org/abs/2404.06828</link>
      <description>arXiv:2404.06828v1 Announce Type: new 
Abstract: A single-celled amoeba can solve the traveling salesman problem through its shape-changing dynamics. In this paper, we examine roles of several elements in a previously proposed computational model of the solution-search process of amoeba and three modifications towards enhancing the solution-search preformance. We find that appropriate modifications can indeed significantly improve the quality of solutions. It is also found that a condition associated with the volume conservation can also be modified in contrast to the naive belief that it is indispensable for the solution-search ability of amoeba. A proposed modified model shows much better performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06828v1</guid>
      <category>cs.NE</category>
      <category>cond-mat.dis-nn</category>
      <category>cs.AI</category>
      <category>nlin.CD</category>
      <category>stat.CO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yusuke Miyajima, Masahito Mochizuki</dc:creator>
    </item>
    <item>
      <title>A Tight $O(4^k/p_c)$ Runtime Bound for a ($\mu$+1) GA on Jump$_k$ for Realistic Crossover Probabilities</title>
      <link>https://arxiv.org/abs/2404.07061</link>
      <description>arXiv:2404.07061v1 Announce Type: new 
Abstract: The Jump$_k$ benchmark was the first problem for which crossover was proven to give a speedup over mutation-only evolutionary algorithms. Jansen and Wegener (2002) proved an upper bound of $O({\rm poly}(n) + 4^k/p_c)$ for the ($\mu$+1)~Genetic Algorithm ($(\mu+1)$ GA), but only for unrealistically small crossover probabilities $p_c$. To this date, it remains an open problem to prove similar upper bounds for realistic~$p_c$; the best known runtime bound for $p_c = \Omega(1)$ is $O((n/\chi)^{k-1})$, $\chi$ a positive constant. Using recently developed techniques, we analyse the evolution of the population diversity, measured as sum of pairwise Hamming distances, for a variant of the \muga on Jump$_k$. We show that population diversity converges to an equilibrium of near-perfect diversity. This yields an improved and tight time bound of $O(\mu n \log(k) + 4^k/p_c)$ for a range of~$k$ under the mild assumptions $p_c = O(1/k)$ and $\mu \in \Omega(kn)$. For all constant~$k$ the restriction is satisfied for some $p_c = \Omega(1)$. Our work partially solves a problem that has been open for more than 20 years.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07061v1</guid>
      <category>cs.NE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Andre Opris, Johannes Lengler, Dirk Sudholt</dc:creator>
    </item>
    <item>
      <title>Semantically-correlated memories in a dense associative model</title>
      <link>https://arxiv.org/abs/2404.07123</link>
      <description>arXiv:2404.07123v1 Announce Type: new 
Abstract: I introduce a novel associative memory model named Correlated Dense Associative Memory (CDAM), which integrates both auto- and hetero-association in a unified framework for continuous-valued memory patterns. Employing an arbitrary graph structure to semantically link memory patterns, CDAM is theoretically and numerically analysed, revealing four distinct dynamical modes: auto-association, narrow hetero-association, wide hetero-association, and neutral quiescence. Drawing inspiration from inhibitory modulation studies, I employ anti-Hebbian learning rules to control the range of hetero-association, extract multi-scale representations of community structures in graphs, and stabilise the recall of temporal sequences. Experimental demonstrations showcase CDAM's efficacy in handling real-world data, replicating a classical neuroscience experiment, performing image retrieval, and simulating arbitrary finite automata.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07123v1</guid>
      <category>cs.NE</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thomas F Burns</dc:creator>
    </item>
    <item>
      <title>Latent Chemical Space Searching for Plug-in Multi-objective Molecule Generation</title>
      <link>https://arxiv.org/abs/2404.06691</link>
      <description>arXiv:2404.06691v1 Announce Type: cross 
Abstract: Molecular generation, an essential method for identifying new drug structures, has been supported by advancements in machine learning and computational technology. However, challenges remain in multi-objective generation, model adaptability, and practical application in drug discovery. In this study, we developed a versatile 'plug-in' molecular generation model that incorporates multiple objectives related to target affinity, drug-likeness, and synthesizability, facilitating its application in various drug development contexts. We improved the Particle Swarm Optimization (PSO) in the context of drug discoveries, and identified PSO-ENP as the optimal variant for multi-objective molecular generation and optimization through comparative experiments. The model also incorporates a novel target-ligand affinity predictor, enhancing the model's utility by supporting three-dimensional information and improving synthetic feasibility. Case studies focused on generating and optimizing drug-like big marine natural products were performed, underscoring PSO-ENP's effectiveness and demonstrating its considerable potential for practical drug discovery applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06691v1</guid>
      <category>q-bio.BM</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ningfeng Liu (State Key Laboratory of Natural and Biomimetic Drugs, School of Pharmaceutical Sciences, Peking University, Peking-Tsinghua Center for Life Science), Jie Yu (State Key Laboratory of Natural and Biomimetic Drugs, School of Pharmaceutical Sciences, Peking University), Siyu Xiu (State Key Laboratory of Natural and Biomimetic Drugs, School of Pharmaceutical Sciences, Peking University), Xinfang Zhao (State Key Laboratory of Natural and Biomimetic Drugs, School of Pharmaceutical Sciences, Peking University), Siyu Lin (State Key Laboratory of Natural and Biomimetic Drugs, School of Pharmaceutical Sciences, Peking University), Bo Qiang (State Key Laboratory of Natural and Biomimetic Drugs, School of Pharmaceutical Sciences, Peking University), Ruqiu Zheng (State Key Laboratory of Natural and Biomimetic Drugs, School of Pharmaceutical Sciences, Peking University), Hongwei Jin (State Key Laboratory of Natural and Biomimetic Drugs, School of Pharmaceutical Sciences, Peking University), Liangren Zhang (State Key Laboratory of Natural and Biomimetic Drugs, School of Pharmaceutical Sciences, Peking University), Zhenming Liu (State Key Laboratory of Natural and Biomimetic Drugs, School of Pharmaceutical Sciences, Peking University, State Key Laboratory of Pharmaceutical Biotechnology, Nanjing University)</dc:creator>
    </item>
    <item>
      <title>Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention</title>
      <link>https://arxiv.org/abs/2404.07143</link>
      <description>arXiv:2404.07143v1 Announce Type: cross 
Abstract: This work introduces an efficient method to scale Transformer-based Large Language Models (LLMs) to infinitely long inputs with bounded memory and computation. A key component in our proposed approach is a new attention technique dubbed Infini-attention. The Infini-attention incorporates a compressive memory into the vanilla attention mechanism and builds in both masked local attention and long-term linear attention mechanisms in a single Transformer block. We demonstrate the effectiveness of our approach on long-context language modeling benchmarks, 1M sequence length passkey context block retrieval and 500K length book summarization tasks with 1B and 8B LLMs. Our approach introduces minimal bounded memory parameters and enables fast streaming inference for LLMs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07143v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tsendsuren Munkhdalai, Manaal Faruqui, Siddharth Gopal</dc:creator>
    </item>
    <item>
      <title>Is Learning in Biological Neural Networks based on Stochastic Gradient Descent? An analysis using stochastic processes</title>
      <link>https://arxiv.org/abs/2309.05102</link>
      <description>arXiv:2309.05102v3 Announce Type: replace-cross 
Abstract: In recent years, there has been an intense debate about how learning in biological neural networks (BNNs) differs from learning in artificial neural networks. It is often argued that the updating of connections in the brain relies only on local information, and therefore a stochastic gradient-descent type optimization method cannot be used. In this paper, we study a stochastic model for supervised learning in BNNs. We show that a (continuous) gradient step occurs approximately when each learning opportunity is processed by many local updates. This result suggests that stochastic gradient descent may indeed play a role in optimizing BNNs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.05102v3</guid>
      <category>q-bio.NC</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <category>math.PR</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>S\"oren Christensen, Jan Kallsen</dc:creator>
    </item>
  </channel>
</rss>
