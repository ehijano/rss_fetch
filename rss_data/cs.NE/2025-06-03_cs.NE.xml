<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NE</link>
    <description>cs.NE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 04 Jun 2025 01:54:22 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Regionalized Metric Framework: A Novel Approach for Evaluating Multimodal Multi-Objective Optimization Algorithms</title>
      <link>https://arxiv.org/abs/2506.00468</link>
      <description>arXiv:2506.00468v1 Announce Type: new 
Abstract: This study aims to optimize the evaluation metric of multimodal multi-objective optimization problems using a Regionalized Metric Framework, which provides a certain boost to research in this field. Existing evaluation metrics usually use the reference set as the evaluation basis, which inevitably leads to reference set dependence. To optimize this problem, this study proposes an evaluation metric based on a Regionalized Metric Framework. The algorithm divides the set of solutions to be evaluated into three regions, and evaluates each solution according to a unique scoring function for each region, which is combined to form the evaluation value of the solution set. To verify the feasibility of this method, a comparative experiment was conducted in this study. The results of the experiment are roughly the same as the trend of existing indicators, and at the same time, it can accurately judge the advantages and disadvantages of points equidistant from the reference set. Our method provides a new perspective for further research on evaluation metrics for multimodal multi-objective optimization algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00468v1</guid>
      <category>cs.NE</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jintai Chen, Fangqing Liu, Xueming Yan, Han Huang</dc:creator>
    </item>
    <item>
      <title>LLM-Driven Instance-Specific Heuristic Generation and Selection</title>
      <link>https://arxiv.org/abs/2506.00490</link>
      <description>arXiv:2506.00490v2 Announce Type: new 
Abstract: Combinatorial optimization problems are widely encountered in real-world applications. Designing high-quality heuristic algorithms that efficiently approximate optimal solutions within reasonable time is a critical research challenge. In recent years, many works have explored integrating Large Language Models (LLMs) with Evolutionary Algorithms to automate heuristic algorithm design through prompt engineering. However, these approaches generally adopt a problem-specific paradigm, applying a single algorithm across all problem instances, failing to account for the heterogeneity across instances. In this paper, we propose InstSpecHH, a novel framework that introduces the concept of instance-specific heuristic generation. InstSpecHH partitions the overall problem class into sub-classes based on instance features and performs differentiated, automated heuristic design for each problem subclass. By tailoring heuristics to the unique features of different sub-classes, InstSpecHH achieves better performance at the problem class level while avoiding redundant heuristic generation for similar instances, thus reducing computational overhead. This approach effectively balances the trade-off between the cost of automatic heuristic design and the quality of the obtained solutions. To evaluate the performance of InstSpecHH, we conduct experiments on 4,500 subclasses of the Online Bin Packing Problem (OBPP) and 365 subclasses of the Capacitated Vehicle Routing Problem (CVRP). Experimental results show that InstSpecHH demonstrates strong intra-subclass and inter-subclass generalization capabilities. Compared to previous problem-specific methods, InstSpecHH reduces the average optimality gap by more than 5.6\% for OBPP and 0.9\% for CVRP. These results highlight the potential of instance-aware automatic heuristic design to further enhance solution quality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00490v2</guid>
      <category>cs.NE</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shaofeng Zhang, Shengcai Liu, Ning Lu, Jiahao Wu, Ji Liu, Yew-Soon Ong, Ke Tang</dc:creator>
    </item>
    <item>
      <title>Improving population size adapting CMA-ES algorithm on step-size blow-up in weakly-structured multimodal functions</title>
      <link>https://arxiv.org/abs/2506.00825</link>
      <description>arXiv:2506.00825v1 Announce Type: new 
Abstract: Multimodal optimization requires both exploration and exploitation. Exploration identifies promising attraction basins, while exploitation finds the best solutions within these basins. The balance between exploration and exploitation can be maintained by adjusting parameter settings. The population size adaptation covariance matrix adaption evolutionary strategy algorithm (PSA-CMA-ES) achieves this balance by dynamically adjusting population size. PSA-CMA-ES performs well on well-structured multimodal benchmark problems. In weakly structured multimodal problems, however, the algorithm struggles to effectively manage step-size increases, resulting in uncontrolled step-size blow-ups that impede convergence near the global optimum. In this study, we reformulated the step-size correction strategy to overcome this limitation. We analytically identified the cause of the step-size blow-up and demonstrate the existence of a significance level for population size change guiding a safe passage to step-size correction. These insights were incorporated to form the reformulation. Through computer experiments on two weakly structured multimodal benchmark problems, we evaluated the performance of the new approach and compared the results with the state-of-the-art algorithm. The improved algorithm successfully mitigates step-size blow-up, enabling a better balance between exploration and exploitation near the global optimum enhancing convergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00825v1</guid>
      <category>cs.NE</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chandula Fernando, Kushani De Silva</dc:creator>
    </item>
    <item>
      <title>Trilevel Memetic Algorithm for the Electric Vehicle Routing Problem</title>
      <link>https://arxiv.org/abs/2506.01065</link>
      <description>arXiv:2506.01065v1 Announce Type: new 
Abstract: The Electric Vehicle Routing Problem (EVRP) extends the capacitated vehicle routing problem by incorporating battery constraints and charging stations, posing significant optimization challenges. This paper introduces a Trilevel Memetic Algorithm (TMA) that hierarchically optimizes customer sequences, route assignments, and charging station insertions. The method combines genetic algorithms with dynamic programming, ensuring efficient and high-quality solutions. Benchmark tests on WCCI2020 instances show competitive performance, matching best-known results for small-scale cases. While computational demands limit scalability, TMA demonstrates strong potential for sustainable logistics planning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01065v1</guid>
      <category>cs.NE</category>
      <category>cs.AI</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ivan Milinovi\'c, Leon Stjepan Uroi\'c, Marko {\DJ}urasevi\'c</dc:creator>
    </item>
    <item>
      <title>Speeding Up Hyper-Heuristics With Markov-Chain Operator Selection and the Only-Worsening Acceptance Operator</title>
      <link>https://arxiv.org/abs/2506.01107</link>
      <description>arXiv:2506.01107v1 Announce Type: new 
Abstract: The move-acceptance hyper-heuristic was recently shown to be able to leave local optima with astonishing efficiency (Lissovoi et al., Artificial Intelligence (2023)). In this work, we propose two modifications to this algorithm that demonstrate impressive performances on a large class of benchmarks including the classic Cliff$_d$ and Jump$_m$ function classes. (i) Instead of randomly choosing between the only-improving and any-move acceptance operator, we take this choice via a simple two-state Markov chain. This modification alone reduces the runtime on Jump$_m$ functions with gap parameter $m$ from $\Omega(n^{2m-1})$ to $O(n^{m+1})$. (ii) We then replace the all-moves acceptance operator with the operator that only accepts worsenings. Such a, counter-intuitive, operator has not been used before in the literature. However, our proofs show that our only-worsening operator can greatly help in leaving local optima, reducing, e.g., the runtime on Jump functions to $O(n^3 \log n)$ independent of the gap size. In general, we prove a remarkably good runtime of $O(n^{k+1} \log n)$ for our Markov move-acceptance hyper-heuristic on all members of a new benchmark class SEQOPT$_k$, which contains a large number of functions having $k$ successive local optima, and which contains the commonly studied Jump$_m$ and Cliff$_d$ functions for $k=2$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01107v1</guid>
      <category>cs.NE</category>
      <category>cs.AI</category>
      <category>cs.DS</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>International Joint Conference on Artificial Intelligence (IJCAI), 2025</arxiv:journal_reference>
      <dc:creator>Abderrahim Bendahi, Benjamin Doerr, Adrien Fradin, Johannes F. Lutzeyer</dc:creator>
    </item>
    <item>
      <title>Spatio-Temporal Decoupled Learning for Spiking Neural Networks</title>
      <link>https://arxiv.org/abs/2506.01117</link>
      <description>arXiv:2506.01117v1 Announce Type: new 
Abstract: Spiking neural networks (SNNs) have gained significant attention for their potential to enable energy-efficient artificial intelligence. However, effective and efficient training of SNNs remains an unresolved challenge. While backpropagation through time (BPTT) achieves high accuracy, it incurs substantial memory overhead. In contrast, biologically plausible local learning methods are more memory-efficient but struggle to match the accuracy of BPTT. To bridge this gap, we propose spatio-temporal decouple learning (STDL), a novel training framework that decouples the spatial and temporal dependencies to achieve both high accuracy and training efficiency for SNNs. Specifically, to achieve spatial decoupling, STDL partitions the network into smaller subnetworks, each of which is trained independently using an auxiliary network. To address the decreased synergy among subnetworks resulting from spatial decoupling, STDL constructs each subnetwork's auxiliary network by selecting the largest subset of layers from its subsequent network layers under a memory constraint. Furthermore, STDL decouples dependencies across time steps to enable efficient online learning. Extensive evaluations on seven static and event-based vision datasets demonstrate that STDL consistently outperforms local learning methods and achieves comparable accuracy to the BPTT method with considerably reduced GPU memory cost. Notably, STDL achieves 4x reduced GPU memory than BPTT on the ImageNet dataset. Therefore, this work opens up a promising avenue for memory-efficient SNN training. Code is available at https://github.com/ChenxiangMA/STDL.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01117v1</guid>
      <category>cs.NE</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chenxiang Ma, Xinyi Chen, Kay Chen Tan, Jibin Wu</dc:creator>
    </item>
    <item>
      <title>SpiceMixer -- Netlist-Level Circuit Evolution</title>
      <link>https://arxiv.org/abs/2506.01497</link>
      <description>arXiv:2506.01497v1 Announce Type: new 
Abstract: This paper introduces SpiceMixer, a genetic algorithm developed to synthesize novel analog circuits by evolving SPICE netlists. Unlike conventional methods, SpiceMixer operates directly on netlist lines, enabling compatibility with any component or subcircuit type and supporting general-purpose genetic operations. By using a normalized netlist format, the algorithm enhances the effectiveness of its genetic operators: crossover, mutation, and pruning. We show that SpiceMixer achieves superior performance in synthesizing standard cells (inverter, two-input NAND, and latch) and in designing an analog classifier circuit for the Iris dataset, reaching an accuracy of 89% on the test set. Across all evaluated tasks, SpiceMixer consistently outperforms existing synthesis methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01497v1</guid>
      <category>cs.NE</category>
      <category>cs.AR</category>
      <category>cs.LG</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stefan Uhlich, Andrea Bonetti, Arun Venkitaraman, Chia-Yu Hsieh, Mustafa Emre G\"ursoy, Ryoga Matsuo, Lorenzo Servadei</dc:creator>
    </item>
    <item>
      <title>Engram Memory Encoding and Retrieval: A Neurocomputational Perspective</title>
      <link>https://arxiv.org/abs/2506.01659</link>
      <description>arXiv:2506.01659v1 Announce Type: new 
Abstract: Despite substantial research into the biological basis of memory, the precise mechanisms by which experiences are encoded, stored, and retrieved in the brain remain incompletely understood. A growing body of evidence supports the engram theory, which posits that sparse populations of neurons undergo lasting physical and biochemical changes to support long-term memory. Yet, a comprehensive computational framework that integrates biological findings with mechanistic models remains elusive. This work synthesizes insights from cellular neuroscience and computational modeling to address key challenges in engram research: how engram neurons are identified and manipulated; how synaptic plasticity mechanisms contribute to stable memory traces; and how sparsity promotes efficient, interference-resistant representations. Relevant computational approaches -- such as sparse regularization, engram gating, and biologically inspired architectures like Sparse Distributed Memory and spiking neural networks -- are also examined. Together, these findings suggest that memory efficiency, capacity, and stability emerge from the interaction of plasticity and sparsity constraints. By integrating neurobiological and computational perspectives, this paper provides a comprehensive theoretical foundation for engram research and proposes a roadmap for future inquiry into the mechanisms underlying memory, with implications for the diagnosis and treatment of memory-related disorders.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01659v1</guid>
      <category>cs.NE</category>
      <category>cs.AI</category>
      <category>cs.IR</category>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel Szelogowski</dc:creator>
    </item>
    <item>
      <title>The Promise of Spiking Neural Networks for Ubiquitous Computing: A Survey and New Perspectives</title>
      <link>https://arxiv.org/abs/2506.01737</link>
      <description>arXiv:2506.01737v1 Announce Type: new 
Abstract: Spiking neural networks (SNNs) have emerged as a class of bio -inspired networks that leverage sparse, event-driven signaling to achieve low-power computation while inherently modeling temporal dynamics. Such characteristics align closely with the demands of ubiquitous computing systems, which often operate on resource-constrained devices while continuously monitoring and processing time-series sensor data. Despite their unique and promising features, SNNs have received limited attention and remain underexplored (or at least, under-adopted) within the ubiquitous computing community. To address this gap, this paper first introduces the core components of SNNs, both in terms of models and training mechanisms. It then presents a systematic survey of 76 SNN-based studies focused on time-series data analysis, categorizing them into six key application domains. For each domain, we summarize relevant works and subsequent advancements, distill core insights, and highlight key takeaways for researchers and practitioners. To facilitate hands-on experimentation, we also provide a comprehensive review of current software frameworks and neuromorphic hardware platforms, detailing their capabilities and specifications, and then offering tailored recommendations for selecting development tools based on specific application needs. Finally, we identify prevailing challenges within each application domain and propose future research directions that need be explored in ubiquitous community. Our survey highlights the transformative potential of SNNs in enabling energy-efficient ubiquitous sensing across diverse application domains, while also serving as an essential introduction for researchers looking to enter this emerging field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01737v1</guid>
      <category>cs.NE</category>
      <category>eess.SP</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hemanth Sabbella, Archit Mukherjee, Thivya Kandappu, Sounak Dey, Arpan Pal, Archan Misra, Dong Ma</dc:creator>
    </item>
    <item>
      <title>Tournament of Prompts: Evolving LLM Instructions Through Structured Debates and Elo Ratings</title>
      <link>https://arxiv.org/abs/2506.00178</link>
      <description>arXiv:2506.00178v1 Announce Type: cross 
Abstract: Prompt engineering represents a critical bottleneck to harness the full potential of Large Language Models (LLMs) for solving complex tasks, as it requires specialized expertise, significant trial-and-error, and manual intervention. This challenge is particularly pronounced for tasks involving subjective quality assessment, where defining explicit optimization objectives becomes fundamentally problematic. Existing automated prompt optimization methods falter in these scenarios, as they typically require well-defined task-specific numerical fitness functions or rely on generic templates that cannot capture the nuanced requirements of complex use cases. We introduce DEEVO (DEbate-driven EVOlutionary prompt optimization), a novel framework that guides prompt evolution through a debate-driven evaluation with an Elo-based selection. Contrary to prior work, DEEVOs approach enables exploration of the discrete prompt space while preserving semantic coherence through intelligent crossover and strategic mutation operations that incorporate debate-based feedback, combining elements from both successful and unsuccessful prompts based on identified strengths rather than arbitrary splicing. Using Elo ratings as a fitness proxy, DEEVO simultaneously drives improvement and preserves valuable diversity in the prompt population. Experimental results demonstrate that DEEVO significantly outperforms both manual prompt engineering and alternative state-of-the-art optimization approaches on open-ended tasks and close-ended tasks despite using no ground truth feedback. By connecting LLMs reasoning capabilities with adaptive optimization, DEEVO represents a significant advancement in prompt optimization research by eliminating the need of predetermined metrics to continuously improve AI systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00178v1</guid>
      <category>cs.AI</category>
      <category>cs.NE</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anirudh Nair, Adi Banerjee, Laurent Mombaerts, Matthew Hagen, Tarik Borogovac</dc:creator>
    </item>
    <item>
      <title>A Systematic Review of Metaheuristics-Based and Machine Learning-Driven Intrusion Detection Systems in IoT</title>
      <link>https://arxiv.org/abs/2506.00377</link>
      <description>arXiv:2506.00377v2 Announce Type: cross 
Abstract: The widespread adoption of the Internet of Things (IoT) has raised a new challenge for developers since it is prone to known and unknown cyberattacks due to its heterogeneity, flexibility, and close connectivity. To defend against such security breaches, researchers have focused on building sophisticated intrusion detection systems (IDSs) using machine learning (ML) techniques. Although these algorithms notably improve detection performance, they require excessive computing power and resources, which are crucial issues in IoT networks considering the recent trends of decentralized data processing and computing systems. Consequently, many optimization techniques have been incorporated with these ML models. Specifically, a special category of optimizer adopted from the behavior of living creatures and different aspects of natural phenomena, known as metaheuristic algorithms, has been a central focus in recent years and brought about remarkable results. Considering this vital significance, we present a comprehensive and systematic review of various applications of metaheuristics algorithms in developing a machine learning-based IDS, especially for IoT. A significant contribution of this study is the discovery of hidden correlations between these optimization techniques and machine learning models integrated with state-of-the-art IoT-IDSs. In addition, the effectiveness of these metaheuristic algorithms in different applications, such as feature selection, parameter or hyperparameter tuning, and hybrid usages are separately analyzed. Moreover, a taxonomy of existing IoT-IDSs is proposed. Furthermore, we investigate several critical issues related to such integration. Our extensive exploration ends with a discussion of promising optimization algorithms and technologies that can enhance the efficiency of IoT-IDSs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00377v2</guid>
      <category>cs.CR</category>
      <category>cs.NE</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.swevo.2025.101984</arxiv:DOI>
      <dc:creator>Mohammad Shamim Ahsan, Salekul Islam, Swakkhar Shatabda</dc:creator>
    </item>
    <item>
      <title>RsGCN: Rescaling Enhances Generalization of GCNs for Solving Scalable Traveling Salesman Problems</title>
      <link>https://arxiv.org/abs/2506.00533</link>
      <description>arXiv:2506.00533v1 Announce Type: cross 
Abstract: Neural traveling salesman problem (TSP) solvers face two critical challenges: poor generalization for scalable TSPs and high training costs. To address these challenges, we propose a new Rescaling Graph Convolutional Network (RsGCN). Focusing on the scale-dependent features (i.e., features varied with problem scales) related to nodes and edges that influence the sensitivity of GCNs to the problem scales, a Rescaling Mechanism in RsGCN enhances the generalization capability by (1) rescaling adjacent nodes to construct a subgraph with a uniform number of adjacent nodes for each node across various scales of TSPs, which stabilizes the graph message aggregation; (2) rescaling subgraph edges to adjust the lengths of subgraph edges to the same magnitude, which maintains numerical consistency. In addition, an efficient training strategy with a mixed-scale dataset and bidirectional loss is used in RsGCN. To fully exploit the heatmaps generated by RsGCN, we design an efficient post-search algorithm termed Re2Opt, in which a reconstruction process based on adaptive weight is incorporated to help avoid local optima. Based on a combined architecture of RsGCN and Re2Opt, our solver achieves remarkable generalization and low training cost: with only 3 epochs of training on the mixed-scale dataset containing instances with up to 100 nodes, it can be generalized successfully to 10K-node instances without any fine-tuning. Extensive experiments demonstrate our state-of-the-art performance across uniform distribution instances of 9 different scales from 20 to 10K nodes and 78 real-world instances from TSPLIB, while requiring the fewest learnable parameters and training epochs among neural competitors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00533v1</guid>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junquan Huang, Zong-Gan Chen, Yuncheng Jiang, Zhi-Hui Zhan</dc:creator>
    </item>
    <item>
      <title>Position as Probability: Self-Supervised Transformers that Think Past Their Training for Length Extrapolation</title>
      <link>https://arxiv.org/abs/2506.00920</link>
      <description>arXiv:2506.00920v1 Announce Type: cross 
Abstract: Deep sequence models typically degrade in accuracy when test sequences significantly exceed their training lengths, yet many critical tasks--such as algorithmic reasoning, multi-step arithmetic, and compositional generalization--require robust length extrapolation. We introduce PRISM, a Probabilistic Relative-position Implicit Superposition Model, a novel positional encoding mechanism that enables Transformers to extrapolate accurately up to 10x beyond their training length. PRISM learns continuous relative positions through a differentiable histogram-filter update, preserving position uncertainty via a probabilistic superposition rather than conventional deterministic embeddings. Empirically, PRISM achieves state-of-the-art length extrapolation, successfully generalizing to previously intractable sequence lengths across algorithmic benchmarks--including arithmetic (addition, multiplication), SCAN compositionality tasks, and complex copy variants derived from DeepMind's recent datasets. Our analysis demonstrates that PRISM's stochastic positional encoding maintains sharp and interpretable internal states, providing a theoretical basis for reliable length generalization. These results advance the goal of neural sequence models that remain algorithmically robust at lengths far exceeding their training horizon.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00920v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.NE</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Philip Heejun Lee</dc:creator>
    </item>
    <item>
      <title>Generating Diverse Challenging Terrains for Legged Robots Using Quality-Diversity Algorithm</title>
      <link>https://arxiv.org/abs/2506.01362</link>
      <description>arXiv:2506.01362v1 Announce Type: cross 
Abstract: While legged robots have achieved significant advancements in recent years, ensuring the robustness of their controllers on unstructured terrains remains challenging. It requires generating diverse and challenging unstructured terrains to test the robot and discover its vulnerabilities. This topic remains underexplored in the literature. This paper presents a Quality-Diversity framework to generate diverse and challenging terrains that uncover weaknesses in legged robot controllers. Our method, applied to both simulated bipedal and quadruped robots, produces an archive of terrains optimized to challenge the controller in different ways. Quantitative and qualitative analyses show that the generated archive effectively contains terrains that the robots struggled to traverse, presenting different failure modes. Interesting results were observed, including failure cases that were not necessarily expected. Experiments show that the generated terrains can also be used to improve RL-based controllers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01362v1</guid>
      <category>cs.RO</category>
      <category>cs.NE</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arthur Esquerre-Pourt\`ere, Minsoo Kim, Jaeheung Park</dc:creator>
    </item>
    <item>
      <title>Multi Part Deployment of Neural Network</title>
      <link>https://arxiv.org/abs/2506.01387</link>
      <description>arXiv:2506.01387v1 Announce Type: cross 
Abstract: The increasing scale of modern neural networks, exemplified by architectures from IBM (530 billion neurons) and Google (500 billion parameters), presents significant challenges in terms of computational cost and infrastructure requirements. As deep neural networks continue to grow, traditional training paradigms relying on monolithic GPU clusters become increasingly unsustainable. This paper proposes a distributed system architecture that partitions a neural network across multiple servers, each responsible for a subset of neurons. Neurons are classified as local or remote, with inter-server connections managed via a metadata-driven lookup mechanism. A Multi-Part Neural Network Execution Engine facilitates seamless execution and training across distributed partitions by dynamically resolving and invoking remote neurons using stored metadata. All servers share a unified model through a network file system (NFS), ensuring consistency during parallel updates. A Neuron Distributor module enables flexible partitioning strategies based on neuron count, percentage, identifiers, or network layers. This architecture enables cost-effective, scalable deployment of deep learning models on cloud infrastructure, reducing dependency on high-performance centralized compute resources.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01387v1</guid>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Paritosh Ranjan, Surajit Majumder, Prodip Roy</dc:creator>
    </item>
    <item>
      <title>Optimization Strategies for Variational Quantum Algorithms in Noisy Landscapes</title>
      <link>https://arxiv.org/abs/2506.01715</link>
      <description>arXiv:2506.01715v1 Announce Type: cross 
Abstract: Variational Quantum Algorithms (VQAs) are a promising tool in the NISQ era, leveraging quantum computing across diverse fields. However, their performance is hindered by optimization challenges like local minima, barren plateaus, and noise from current quantum hardware. Variational Quantum Eigensolver (VQE), a key subset of VQAs, approximates molecular ground-state energies by minimizing a Hamiltonian, enabling quantum chemistry applications. Beyond this, VQE contributes to condensed matter physics by exploring quantum phase transitions and exotic states, and to quantum machine learning by optimizing parameterized circuits for classifiers and generative models. This study systematically evaluates over 50 meta-heuristic optimization algorithms including evolution-based, swarm-based, and music-inspired methods-on their ability to navigate VQE's multimodal and noisy landscapes. Using a multi-phase sieve-like approach, we identify the most capable optimizers and compare their performance on a 1D Ising model (3-9 qubits). Further testing on the Hubbard model (up to 192 parameters) reveals insights into convergence rates, effectiveness, and resilience under noise, offering valuable guidance for advancing optimization in noisy quantum environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01715v1</guid>
      <category>quant-ph</category>
      <category>cs.NE</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vojt\v{e}ch Nov\'ak, Ivan Zelinka, V\'aclav Sn\'a\v{s}el</dc:creator>
    </item>
    <item>
      <title>A Neuromorphic Electronic Nose Design</title>
      <link>https://arxiv.org/abs/2410.16677</link>
      <description>arXiv:2410.16677v3 Announce Type: replace 
Abstract: Rapid detection of gas concentration is important in different domains like gas leakage monitoring, pollution control, and so on, for the prevention of health hazards. Out of different types of gas sensors, Metal oxide (MOx) sensors are extensively used in such applications because of their portability, low cost, and high sensitivity for specific gases. However, how to effectively sample the MOx data for the real-time detection of gas and its concentration level remains an open question. Here, we introduce a simple analog front-end for one MOx sensor that encodes the gas concentration in the time difference between pulses of two separate pathways. This front-end design is inspired by the spiking output of a mammalian olfactory bulb. We show that for a gas pulse injected in a constant airflow, the time difference between pulses decreases with increasing gas concentration, similar to the spike time difference between the two principal output neurons in the olfactory bulb. The circuit design is further extended to a MOx sensor array, and this sensor array front-end was tested in the same environment for gas identification and concentration estimation. Encoding of gas stimulus features in analog spikes at the sensor level itself may result in data and power-efficient real-time gas sensing systems in the future that can ultimately be used in uncontrolled and turbulent environments for longer periods without data explosion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.16677v3</guid>
      <category>cs.NE</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shavika Rastogi, Nik Dennler, Michael Schmuker, Andr\'e van Schaik</dc:creator>
    </item>
    <item>
      <title>CatCMA with Margin: Stochastic Optimization for Continuous, Integer, and Categorical Variables</title>
      <link>https://arxiv.org/abs/2504.07884</link>
      <description>arXiv:2504.07884v4 Announce Type: replace 
Abstract: This study focuses on mixed-variable black-box optimization (MV-BBO), addressing continuous, integer, and categorical variables. Many real-world MV-BBO problems involve dependencies among these different types of variables, requiring efficient methods to optimize them simultaneously. Recently, stochastic optimization methods leveraging the mechanism of the covariance matrix adaptation evolution strategy have shown promising results in mixed-integer or mixed-category optimization. However, such methods cannot handle the three types of variables simultaneously. In this study, we propose CatCMA with Margin (CatCMAwM), a stochastic optimization method for MV-BBO that jointly optimizes continuous, integer, and categorical variables. CatCMAwM is developed by incorporating a novel integer handling into CatCMA, a mixed-category black-box optimization method employing a joint distribution of multivariate Gaussian and categorical distributions. The proposed integer handling is carefully designed by reviewing existing integer handlings and following the design principles of CatCMA. Even when applied to mixed-integer problems, it stabilizes the marginal probability and improves the convergence performance of continuous variables. Numerical experiments show that CatCMAwM effectively handles the three types of variables, outperforming state-of-the-art Bayesian optimization methods and baselines that simply incorporate existing integer handlings into CatCMA.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.07884v4</guid>
      <category>cs.NE</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3712256.3726471</arxiv:DOI>
      <dc:creator>Ryoki Hamano, Masahiro Nomura, Shota Saito, Kento Uchida, Shinichi Shirakawa</dc:creator>
    </item>
    <item>
      <title>Learning Successor Features with Distributed Hebbian Temporal Memory</title>
      <link>https://arxiv.org/abs/2310.13391</link>
      <description>arXiv:2310.13391v4 Announce Type: replace-cross 
Abstract: This paper presents a novel approach to address the challenge of online sequence learning for decision making under uncertainty in non-stationary, partially observable environments. The proposed algorithm, Distributed Hebbian Temporal Memory (DHTM), is based on the factor graph formalism and a multi-component neuron model. DHTM aims to capture sequential data relationships and make cumulative predictions about future observations, forming Successor Features (SFs). Inspired by neurophysiological models of the neocortex, the algorithm uses distributed representations, sparse transition matrices, and local Hebbian-like learning rules to overcome the instability and slow learning of traditional temporal memory algorithms such as RNN and HMM. Experimental results show that DHTM outperforms LSTM, RWKV and a biologically inspired HMM-like algorithm, CSCG, on non-stationary data sets. Our results suggest that DHTM is a promising approach to address the challenges of online sequence learning and planning in dynamic environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.13391v4</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NE</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Evgenii Dzhivelikian, Petr Kuderov, Aleksandr I. Panov</dc:creator>
    </item>
    <item>
      <title>Application based Evaluation of an Efficient Spike-Encoder, "Spiketrum"</title>
      <link>https://arxiv.org/abs/2405.15927</link>
      <description>arXiv:2405.15927v4 Announce Type: replace-cross 
Abstract: Spike-based encoders represent information as sequences of spikes or pulses, which are transmitted between neurons. A prevailing consensus suggests that spike-based approaches demonstrate exceptional capabilities in capturing the temporal dynamics of neural activity and have the potential to provide energy-efficient solutions for low-power applications. The Spiketrum encoder efficiently compresses input data using spike trains or code sets (for non-spiking applications) and is adaptable to both hardware and software implementations, with lossless signal reconstruction capability. The paper proposes and assesses Spiketrum's hardware, evaluating its output under varying spike rates and its classification performance with popular spiking and non-spiking classifiers, and also assessing the quality of information compression and hardware resource utilization. The paper extensively benchmarks both Spiketrum hardware and its software counterpart against state-of-the-art, biologically-plausible encoders. The evaluations encompass benchmarking criteria, including classification accuracy, training speed, and sparsity when using encoder outputs in pattern recognition and classification with both spiking and non-spiking classifiers. Additionally, they consider encoded output entropy and hardware resource utilization and power consumption of the hardware version of the encoders. Results demonstrate Spiketrum's superiority in most benchmarking criteria, making it a promising choice for various applications. It efficiently utilizes hardware resources with low power consumption, achieving high classification accuracy. This work also emphasizes the potential of encoders in spike-based processing to improve the efficiency and performance of neural computing systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15927v4</guid>
      <category>eess.SP</category>
      <category>cs.NE</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>MHD Anas Alsakkal, Runze Wang, Jayawan Wijekoon, Huajin Tang</dc:creator>
    </item>
    <item>
      <title>SageAttention2: Efficient Attention with Thorough Outlier Smoothing and Per-thread INT4 Quantization</title>
      <link>https://arxiv.org/abs/2411.10958</link>
      <description>arXiv:2411.10958v5 Announce Type: replace-cross 
Abstract: Although quantization for linear layers has been widely used, its application to accelerate the attention process remains limited. To further enhance the efficiency of attention computation compared to SageAttention while maintaining precision, we propose SageAttention2, which utilizes significantly faster 4-bit matrix multiplication (Matmul) alongside additional precision-enhancing techniques. First, we propose to quantize matrices $(Q, K)$ to INT4 in a hardware-friendly thread-level granularity and quantize matrices $(\widetilde P, V)$ to FP8. Second, we propose a method to smooth $Q$, enhancing the accuracy of INT4 $QK^\top$. Third, we propose a two-level accumulation strategy for $\widetilde PV$ to enhance the accuracy of FP8 $\widetilde PV$. The operations per second (OPS) of SageAttention2 surpass FlashAttention2 and xformers by about 3x and 4.5x on RTX4090, respectively. Moreover, SageAttention2 matches the speed of FlashAttention3(fp8) on the Hopper GPUs, while delivering much higher accuracy. Comprehensive experiments confirm that our approach incurs negligible end-to-end metrics loss across diverse models, including those for language, image, and video generation. The code is available at https://github.com/thu-ml/SageAttention.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10958v5</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.NE</category>
      <category>cs.PF</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Proceedings of the 42nd International Conference on Machine Learning, PMLR 267, 2025 (ICML 2025)</arxiv:journal_reference>
      <dc:creator>Jintao Zhang, Haofeng Huang, Pengle Zhang, Jia Wei, Jun Zhu, Jianfei Chen</dc:creator>
    </item>
    <item>
      <title>Multihead self-attention in cortico-thalamic circuits</title>
      <link>https://arxiv.org/abs/2504.06354</link>
      <description>arXiv:2504.06354v2 Announce Type: replace-cross 
Abstract: Both biological cortico-thalamic networks and artificial transformer networks use canonical computations to perform a wide range of cognitive tasks. In this work, we propose that the structure of cortico-thalamic circuits is well suited to realize a computation analogous to multihead self-attention, the main algorithmic innovation of transformers. We start with the concept of a cortical unit module or microcolumn, and propose that superficial and deep pyramidal cells carry distinct computational roles. Specifically, superficial pyramidal cells encode an attention mask applied onto deep pyramidal cells to compute attention-modulated values. We show how to wire such microcolumns into a circuit equivalent to a single head of self-attention. We then suggest the parallel between one head of attention and a cortical area. On this basis, we show how to wire cortico-thalamic circuits to perform multihead self-attention. Along these constructions, we refer back to existing experimental data, and find noticeable correspondence. Finally, as a first step towards a mechanistic theory of synaptic learning in this framework, we formally derive gradient-based updates for the parameters of a multihead linear self-attention block and propose steps towards their implementation by local synaptic plasticity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.06354v2</guid>
      <category>q-bio.NC</category>
      <category>cs.NE</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arno Granier, Walter Senn</dc:creator>
    </item>
  </channel>
</rss>
