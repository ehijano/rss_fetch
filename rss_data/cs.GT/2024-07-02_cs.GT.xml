<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 03 Jul 2024 01:48:01 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 02 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>TierDrop: Harnessing Airdrop Farmers for User Growth</title>
      <link>https://arxiv.org/abs/2407.01176</link>
      <description>arXiv:2407.01176v1 Announce Type: new 
Abstract: Blockchain platforms attempt to expand their user base by awarding tokens to users, a practice known as issuing airdrops. Empirical data and related work implies that previous airdrops fall short of their stated aim of attracting long-term users, partially due to adversarial farmers who game airdrop mechanisms and receive an outsize share of rewards. In this work, we argue that given the futility of fighting farmers, the airdrop business model should be reconsidered: farmers should be harnessed to generate activity that attracts real users, i.e., strengthens network effects. To understand the impact of farmers on airdrops, we analyze their performance in a market inhabited by two competing platforms and two tiers of users: real users and farmers. We show that counterintuitively, farmers sometimes represent a necessary evil-it can be revenue-optimal for airdrop issuers to give some tokens to farmers, even in the hypothetical case where platforms could costlessly detect and banish all farmers. Although we focus on airdrops, our results generally apply to activity-based incentive schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.01176v1</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aviv Yaish, Benjamin Livshits</dc:creator>
    </item>
    <item>
      <title>A Coopetition Index for Coalitions in Simple Games</title>
      <link>https://arxiv.org/abs/2407.01383</link>
      <description>arXiv:2407.01383v1 Announce Type: new 
Abstract: In monotone simple games, larger coalitions typically wield more power, but do all players align their efforts effectively? Consider a voting scenario where a coalition forms, but needs more voters to pass a bill. The cohesion of the new group of voters hinges on whether all the new members can proficiently collaborate with the existing players to ensure the bill's passage or if subgroups form that pursue an independent alternative, thus generating antagonism among the new voters.
  This research introduces the coopetition index, ranging from -1 to 1, to measure agents' preferences for cooperation (near 1) or competition (near -1) with the remaining players. We also introduce the Banzhaf and Shapley-Owen coopetition indices, addressing limitations of previous indices.
  By applying our index to the apex game and symmetric majority games, we observe that cooperation and competition frequently balance each other out, leading to null values for the Shapley-Owen and Banzhaf coopetition indices. To distinguish balanced scenarios from those involving powerless coalitions, we define a decisiveness index that measures the extent of coalition involvement in negotiations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.01383v1</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michele Aleandri, Marco Dall'Aglio</dc:creator>
    </item>
    <item>
      <title>Visual Reasoning and Multi-Agent Approach in Multimodal Large Language Models (MLLMs): Solving TSP and mTSP Combinatorial Challenges</title>
      <link>https://arxiv.org/abs/2407.00092</link>
      <description>arXiv:2407.00092v1 Announce Type: cross 
Abstract: Multimodal Large Language Models (MLLMs) harness comprehensive knowledge spanning text, images, and audio to adeptly tackle complex problems, including zero-shot in-context learning scenarios. This study explores the ability of MLLMs in visually solving the Traveling Salesman Problem (TSP) and Multiple Traveling Salesman Problem (mTSP) using images that portray point distributions on a two-dimensional plane. We introduce a novel approach employing multiple specialized agents within the MLLM framework, each dedicated to optimizing solutions for these combinatorial challenges. Our experimental investigation includes rigorous evaluations across zero-shot settings and introduces innovative multi-agent zero-shot in-context scenarios. The results demonstrated that both multi-agent models. Multi-Agent 1, which includes the Initializer, Critic, and Scorer agents, and Multi-Agent 2, which comprises only the Initializer and Critic agents; significantly improved solution quality for TSP and mTSP problems. Multi-Agent 1 excelled in environments requiring detailed route refinement and evaluation, providing a robust framework for sophisticated optimizations. In contrast, Multi-Agent 2, focusing on iterative refinements by the Initializer and Critic, proved effective for rapid decision-making scenarios. These experiments yield promising outcomes, showcasing the robust visual reasoning capabilities of MLLMs in addressing diverse combinatorial problems. The findings underscore the potential of MLLMs as powerful tools in computational optimization, offering insights that could inspire further advancements in this promising field. Project link: https://github.com/ahmed-abdulhuy/Solving-TSP-and-mTSP-Combinatorial-Challenges-using-Visual-Reasoning-and-Multi-Agent-Approach-MLLMs-.git</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00092v1</guid>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammed Elhenawy, Ahmad Abutahoun, Taqwa I. Alhadidi, Ahmed Jaber, Huthaifa I. Ashqar, Shadi Jaradat, Ahmed Abdelhay, Sebastien Glaser, Andry Rakotonirainy</dc:creator>
    </item>
    <item>
      <title>ShapG: new feature importance method based on the Shapley value</title>
      <link>https://arxiv.org/abs/2407.00506</link>
      <description>arXiv:2407.00506v1 Announce Type: cross 
Abstract: With wide application of Artificial Intelligence (AI), it has become particularly important to make decisions of AI systems explainable and transparent. In this paper, we proposed a new Explainable Artificial Intelligence (XAI) method called ShapG (Explanations based on Shapley value for Graphs) for measuring feature importance. ShapG is a model-agnostic global explanation method. At the first stage, it defines an undirected graph based on the dataset, where nodes represent features and edges are added based on calculation of correlation coefficients between features. At the second stage, it calculates an approximated Shapley value by sampling the data taking into account this graph structure. The sampling approach of ShapG allows to calculate the importance of features efficiently, i.e. to reduce computational complexity. Comparison of ShapG with other existing XAI methods shows that it provides more accurate explanations for two examined datasets. We also compared other XAI methods developed based on cooperative game theory with ShapG in running time, and the results show that ShapG exhibits obvious advantages in its running time, which further proves efficiency of ShapG. In addition, extensive experiments demonstrate a wide range of applicability of the ShapG method for explaining complex models. We find ShapG an important tool in improving explainability and transparency of AI systems and believe it can be widely used in various fields.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00506v1</guid>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chi Zhao, Jing Liu, Elena Parilina</dc:creator>
    </item>
    <item>
      <title>Iterative Nash Policy Optimization: Aligning LLMs with General Preferences via No-Regret Learning</title>
      <link>https://arxiv.org/abs/2407.00617</link>
      <description>arXiv:2407.00617v1 Announce Type: cross 
Abstract: Reinforcement Learning with Human Feedback (RLHF) has achieved great success in aligning large language models (LLMs) with human preferences. Prevalent RLHF approaches are reward-based, following the Bradley-Terry (BT) model assumption, which may not fully capture the complexity of human preferences. In this paper, we explore RLHF under a general preference framework and approach it from a game-theoretic perspective. Specifically, we formulate the problem as a two-player game and propose a novel algorithm, iterative Nash policy optimization (INPO). The key idea is to let the policy play against itself via no-regret learning, thereby approximating the Nash policy. Unlike previous methods, INPO bypasses the need for estimating the expected win rate for individual responses, which typically incurs high computational or annotation costs. Instead, we introduce a new loss objective that is directly minimized over a preference dataset. We provide theoretical analysis for our approach and demonstrate its effectiveness through experiments on various representative benchmarks. With an LLaMA-3-8B-based SFT model, INPO achieves a 41.5% length-controlled win rate on AlpacaEval 2.0 and a 38.3% win rate on Arena-Hard, showing substantial improvement over the state-of-the-art iterative algorithm [Dong et al., 2024] under the BT model assumption. Additionally, our ablation study highlights the benefits of incorporating KL regularization for response length control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00617v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.GT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuheng Zhang, Dian Yu, Baolin Peng, Linfeng Song, Ye Tian, Mingyue Huo, Nan Jiang, Haitao Mi, Dong Yu</dc:creator>
    </item>
    <item>
      <title>Contractual Reinforcement Learning: Pulling Arms with Invisible Hands</title>
      <link>https://arxiv.org/abs/2407.01458</link>
      <description>arXiv:2407.01458v1 Announce Type: cross 
Abstract: The agency problem emerges in today's large scale machine learning tasks, where the learners are unable to direct content creation or enforce data collection. In this work, we propose a theoretical framework for aligning economic interests of different stakeholders in the online learning problems through contract design. The problem, termed \emph{contractual reinforcement learning}, naturally arises from the classic model of Markov decision processes, where a learning principal seeks to optimally influence the agent's action policy for their common interests through a set of payment rules contingent on the realization of next state. For the planning problem, we design an efficient dynamic programming algorithm to determine the optimal contracts against the far-sighted agent. For the learning problem, we introduce a generic design of no-regret learning algorithms to untangle the challenges from robust design of contracts to the balance of exploration and exploitation, reducing the complexity analysis to the construction of efficient search algorithms. For several natural classes of problems, we design tailored search algorithms that provably achieve $\tilde{O}(\sqrt{T})$ regret. We also present an algorithm with $\tilde{O}(T^{2/3})$ for the general problem that improves the existing analysis in online contract design with mild technical assumptions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.01458v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jibang Wu, Siyu Chen, Mengdi Wang, Huazheng Wang, Haifeng Xu</dc:creator>
    </item>
    <item>
      <title>Weighted Fairness Notions for Indivisible Items Revisited</title>
      <link>https://arxiv.org/abs/2112.04166</link>
      <description>arXiv:2112.04166v2 Announce Type: replace 
Abstract: We revisit the setting of fairly allocating indivisible items when agents have different weights representing their entitlements. First, we propose a parameterized family of relaxations for weighted envy-freeness and the same for weighted proportionality; the parameters indicate whether smaller-weight or larger-weight agents should be given a higher priority. We show that each notion in these families can always be satisfied, but any two cannot necessarily be fulfilled simultaneously. We then introduce an intuitive weighted generalization of maximin share fairness and establish the optimal approximation of it that can be guaranteed. Furthermore, we characterize the implication relations between the various weighted fairness notions introduced in this and prior work, and relate them to the lower and upper quota axioms from apportionment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2112.04166v2</guid>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3665799</arxiv:DOI>
      <dc:creator>Mithun Chakraborty, Erel Segal-Halevi, Warut Suksompong</dc:creator>
    </item>
    <item>
      <title>The Machine Psychology of Cooperation: Can GPT models operationalise prompts for altruism, cooperation, competitiveness and selfishness in economic games?</title>
      <link>https://arxiv.org/abs/2305.07970</link>
      <description>arXiv:2305.07970v2 Announce Type: replace 
Abstract: We investigated the capability of the GPT-3.5 large language model (LLM) to operationalize natural language descriptions of cooperative, competitive, altruistic, and self-interested behavior in two social dilemmas: the repeated Prisoners Dilemma and the one-shot Dictator Game. Using a within-subject experimental design, we used a prompt to describe the task environment using a similar protocol to that used in experimental psychology studies with human subjects. We tested our research question by manipulating the part of our prompt which was used to create a simulated persona with different cooperative and competitive stances. We then assessed the resulting simulacras' level of cooperation in each social dilemma, taking into account the effect of different partner conditions for the repeated game. Our results provide evidence that LLMs can, to some extent, translate natural language descriptions of different cooperative stances into corresponding descriptions of appropriate task behaviour, particularly in the one-shot game. There is some evidence of behaviour resembling conditional reciprocity for the cooperative simulacra in the repeated game, and for the later version of the model there is evidence of altruistic behaviour. Our study has potential implications for using LLM chatbots in task environments that involve cooperation, e.g. using chatbots as mediators and facilitators in public-goods negotiations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.07970v2</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Steve Phelps, Yvan I. Russell</dc:creator>
    </item>
    <item>
      <title>Partially Observable Stochastic Games with Neural Perception Mechanisms</title>
      <link>https://arxiv.org/abs/2310.11566</link>
      <description>arXiv:2310.11566v3 Announce Type: replace 
Abstract: Stochastic games are a well established model for multi-agent sequential decision making under uncertainty. In practical applications, though, agents often have only partial observability of their environment. Furthermore, agents increasingly perceive their environment using data-driven approaches such as neural networks trained on continuous data. We propose the model of neuro-symbolic partially-observable stochastic games (NS-POSGs), a variant of continuous-space concurrent stochastic games that explicitly incorporates neural perception mechanisms. We focus on a one-sided setting with a partially-informed agent using discrete, data-driven observations and another, fully-informed agent. We present a new method, called one-sided NS-HSVI, for approximate solution of one-sided NS-POSGs, which exploits the piecewise constant structure of the model. Using neural network pre-image analysis to construct finite polyhedral representations and particle-based representations for beliefs, we implement our approach and illustrate its practical applicability to the analysis of pedestrian-vehicle and pursuit-evasion scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.11566v3</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rui Yan, Gabriel Santos, Gethin Norman, David Parker, Marta Kwiatkowska</dc:creator>
    </item>
    <item>
      <title>As Soon as Possible but Rationally</title>
      <link>https://arxiv.org/abs/2403.00399</link>
      <description>arXiv:2403.00399v3 Announce Type: replace 
Abstract: This paper addresses complexity problems in rational verification and synthesis for multi-player games played on weighted graphs, where the objective of each player is to minimize the cost of reaching a specific set of target vertices. In these games, one player, referred to as the system, declares his strategy upfront. The other players, composing the environment, then rationally make their moves according to their objectives. The rational behavior of these responding players is captured through two models: they opt for strategies that either represent a Nash equilibrium or lead to a play with a Pareto-optimal cost tuple.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.00399v3</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>V\'eronique Bruy\`ere, Christophe Grandmont, Jean-Fran\c{c}ois Raskin</dc:creator>
    </item>
    <item>
      <title>Synthesis of Robust Optimal Strategies in Weighted Timed Games</title>
      <link>https://arxiv.org/abs/2403.06921</link>
      <description>arXiv:2403.06921v2 Announce Type: replace 
Abstract: Weighted Timed Games (WTG for short) are the most widely used model to describe controller synthesis problems involving real-time issues. The synthesized strategies rely on a perfect measure of time elapse, which is not realistic in practice. In order to produce strategies tolerant to timing imprecisions, we rely on a notion of robustness first introduced for timed automata. More precisely, WTGs are two-player zero-sum games played in a timed automaton equipped with integer weights in which one of the players, that we call Min, wants to reach a target location while minimising the cumulated weight. In this work, we equip the underlying timed automaton with a semantics depending on some parameter (representing the maximal possible perturbation) in which the opponent of Min can in addition perturb delays chosen by Min.
  The robust value problem can then be stated as follows: given some threshold, determine whether there exists a positive perturbation and a strategy for Min ensuring to reach the target, with an accumulated weight below the threshold, whatever the opponent does.
  We provide the first decidability result for this robust value problem by computing the robust value function, in a parametric way, for the class of divergent WTGs (introduced to obtain decidability of the (classical) value problem in WTGs without bounding the number of clocks). To this end, we show that the robust value is the fixpoint of some operators, as is classically done for value iteration algorithms. We then combine in a very careful way two representations: piecewise affine functions introduced in [1] to analyse WTGs, and shrunk Difference Bound Matrices considered in [29] to analyse robustness in timed automata. Last, we also study qualitative decision problems and close an open problem on robust reachability, showing it is EXPTIME-complete for general WTGs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06921v2</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Benjamin Monmege, Julie Parreaux, Pierre-Alain Reynier</dc:creator>
    </item>
    <item>
      <title>An Axiomatic Characterization of Split Cycle</title>
      <link>https://arxiv.org/abs/2210.12503</link>
      <description>arXiv:2210.12503v3 Announce Type: replace-cross 
Abstract: A number of rules for resolving majority cycles in elections have been proposed in the literature. Recently, Holliday and Pacuit (Journal of Theoretical Politics 33 (2021) 475-524) axiomatically characterized the class of rules refined by one such cycle-resolving rule, dubbed Split Cycle: in each majority cycle, discard the majority preferences with the smallest majority margin. They showed that any rule satisfying five standard axioms plus a weakening of Arrow's Independence of Irrelevant Alternatives (IIA), called Coherent IIA, is refined by Split Cycle. In this paper, we go further and show that Split Cycle is the only rule satisfying the axioms of Holliday and Pacuit together with two additional axioms, which characterize the class of rules that refine Split Cycle: Coherent Defeat and Positive Involvement in Defeat. Coherent Defeat states that any majority preference not occurring in a cycle is retained, while Positive Involvement in Defeat is closely related to the well-known axiom of Positive Involvement (as in J. Perez, Social Choice and Welfare 18 (2001) 601-616). We characterize Split Cycle not only as a collective choice rule but also as a social choice correspondence, over both profiles of linear ballots and profiles of ballots allowing ties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.12503v3</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yifeng Ding, Wesley H. Holliday, Eric Pacuit</dc:creator>
    </item>
    <item>
      <title>A Robust Characterization of Nash Equilibrium</title>
      <link>https://arxiv.org/abs/2307.03079</link>
      <description>arXiv:2307.03079v2 Announce Type: replace-cross 
Abstract: We characterize Nash equilibrium by postulating coherent behavior across varying games. Nash equilibrium is the only solution concept that satisfies the following axioms: (i) strictly dominant actions are played with positive probability, (ii) if a strategy profile is played in two games, it is also played in every convex combination of these games, and (iii) players can shift probability arbitrarily between two indistinguishable actions, and deleting one of these actions has no effect. Our theorem implies that every equilibrium refinement violates at least one of these axioms. Moreover, every solution concept that approximately satisfies these axioms returns approximate Nash equilibria, even in natural subclasses of games, such as two-player zero-sum games, potential games, and graphical games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.03079v2</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Florian Brandl, Felix Brandt</dc:creator>
    </item>
    <item>
      <title>The Value of Context: Human versus Black Box Evaluators</title>
      <link>https://arxiv.org/abs/2402.11157</link>
      <description>arXiv:2402.11157v2 Announce Type: replace-cross 
Abstract: Machine learning algorithms are now capable of performing evaluations previously conducted by human experts (e.g., medical diagnoses). How should we conceptualize the difference between evaluation by humans and by algorithms, and when should an individual prefer one over the other? We propose a framework to examine one key distinction between the two forms of evaluation: Machine learning algorithms are standardized, fixing a common set of covariates by which to assess all individuals, while human evaluators customize which covariates are acquired to each individual. Our framework defines and analyzes the advantage of this customization -- the value of context -- in environments with high-dimensional data. We show that unless the agent has precise knowledge about the joint distribution of covariates, the benefit of additional covariates generally outweighs the value of context.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.11157v2</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrei Iakovlev, Annie Liang</dc:creator>
    </item>
  </channel>
</rss>
