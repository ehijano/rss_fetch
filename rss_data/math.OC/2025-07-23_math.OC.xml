<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 24 Jul 2025 04:01:17 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>The Generalized Matrix Separation Problem: Algorithms</title>
      <link>https://arxiv.org/abs/2507.17069</link>
      <description>arXiv:2507.17069v1 Announce Type: new 
Abstract: When given a generalized matrix separation problem, which aims to recover a low rank matrix $L_0$ and a sparse matrix $S_0$ from $M_0=L_0+HS_0$, the work \cite{CW25} proposes a novel convex optimization problem whose objective function is the sum of the $\ell_1$-norm and nuclear norm. In this paper we detail the iterative algorithms and its associated computations for solving this convex optimization problem. We present various efficient implementation strategies, with attention to practical cases where $H$ is circulant, separable, or block structured. Notably, we propose a preconditioning technique that drastically improved the performance of our algorithms in terms of efficiency, accuracy, and robustness. While this paper serves as an illustrative algorithm implementation manual, we also provide theoretical guarantee for our preconditioning strategy. Numerical results illustrate the effectiveness of the proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.17069v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xuemei Chen, Owen Deen</dc:creator>
    </item>
    <item>
      <title>Stochastically Structured Reservoir Computers for Financial and Economic System Identification</title>
      <link>https://arxiv.org/abs/2507.17115</link>
      <description>arXiv:2507.17115v1 Announce Type: new 
Abstract: This paper introduces a methodology for identifying and simulating financial and economic systems using stochastically structured reservoir computers (SSRCs). The proposed framework leverages structure-preserving embeddings and graph-informed coupling matrices to model inter-agent dynamics with enhanced interpretability. A constrained optimization scheme ensures that the learned models satisfy both stochastic and structural constraints. Two empirical case studies, a dynamic behavioral model of resource competition among agents, and regional inflation network dynamics, illustrate the effectiveness of the approach in capturing and anticipating complex nonlinear patterns and enabling interpretable predictive analysis under uncertainty.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.17115v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>econ.TH</category>
      <category>eess.SY</category>
      <pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lendy Banegas, Fredy Vides</dc:creator>
    </item>
    <item>
      <title>Frank-Wolfe algorithm for star-convex functions</title>
      <link>https://arxiv.org/abs/2507.17272</link>
      <description>arXiv:2507.17272v1 Announce Type: new 
Abstract: We study the Frank-Wolfe algorithm for minimizing a differentiable function with Lipschitz continuous gradient over a compact convex set. To extend classical complexity bounds to certain non-convex functions, we focus on the class of \emph{star-convex functions}, which retain essential geometric properties despite the lack of convexity. We establish iteration-complexity bounds of $\mathcal{O}(1/k)$ for both the objective values and the duality gap under star-convexity, using diminishing, Armijo-type, and Lipschitz-based stepsize rules. Notably, the diminishing and Armijo strategies do not require prior knowledge of Lipschitz or curvature constants. These results demonstrate that the Frank-Wolfe method preserves optimal complexity guarantees beyond the convex setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.17272v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>R. Diaz Millan, Orizon Pereira Ferreira, Julien Ugon</dc:creator>
    </item>
    <item>
      <title>Investigating State-of-the-Art Planning Strategies for Electric Vehicle Charging Infrastructures in Coupled Transport and Power Networks: A Comprehensive Review</title>
      <link>https://arxiv.org/abs/2507.17277</link>
      <description>arXiv:2507.17277v1 Announce Type: new 
Abstract: Electric vehicles (EVs) have emerged as a pivotal solution to reduce greenhouse gas emissions paving a pathway to net zero. As the adoption of EVs continues to grow, countries are proactively formulating systematic plans for nationwide electric vehicle charging infrastructure (EVCI) to keep pace with the accelerating shift towards EVs. This comprehensive review aims to thoroughly examine current global practices in EVCI planning and explore state-of-the-art methodologies for designing EVCI planning strategies. Despite remarkable efforts by influential players in the global EV market, such as China, the United States, and the European Union, the progress in EVCI rollout has been notably slower than anticipated in the rest of the world. This delay can be attributable to three major impediments: inadequate EVCI charging services, low utilization rates of public EVCI facilities, and the non-trivial integration of EVCI into the electric grid. This review dissects the interests of these stakeholders, clarifying their respective roles and expectations in the context of EVCI planning. This review also provides insights into level 1, 2, and 3 chargers with explorations of their applications in different geographical locations for diverse EV charging patterns. Finally, a thorough review of node-based and flow-based approaches to EV planning is presented. The modeling of placing charging stations is broadly categorized into set coverage, maximum coverage, flow-capturing, and flow-refueling location models. In conclusion, this review identifies several research gaps, including the dynamic modeling of EV charging demand and the coordination of vehicle electrification with grid decarbonization. This paper calls for further contributions to bridge these gaps and drive the advancement of EVCI planning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.17277v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1088/2516-1083/ad6be1</arxiv:DOI>
      <arxiv:journal_reference>Progress in Energy, 2024</arxiv:journal_reference>
      <dc:creator>Jinhao Li, Arlena Chew, Hao Wang</dc:creator>
    </item>
    <item>
      <title>Scalable DC Optimization via Adaptive Frank-Wolfe Algorithms</title>
      <link>https://arxiv.org/abs/2507.17545</link>
      <description>arXiv:2507.17545v1 Announce Type: new 
Abstract: We consider the problem of minimizing a difference of (smooth) convex functions over a compact convex feasible region $P$, i.e., $\min_{x \in P} f(x) - g(x)$, with smooth $f$ and Lipschitz continuous $g$. This computational study builds upon and complements the framework of Maskan et al. [2025] by integrating advanced Frank-Wolfe variants to reduce computational overhead. We empirically show that constrained DC problems can be efficiently solved using a combination of the Blended Pairwise Conditional Gradients (BPCG) algorithm [Tsuji et al., 2022] with warm-starting and the adaptive error bound from Maskan et al. [2025]. The result is a highly efficient and scalable projection-free algorithm for constrained DC optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.17545v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sebastian Pokutta</dc:creator>
    </item>
    <item>
      <title>Sub-sampled Trust-Region Methods with Deterministic Worst-Case Complexity Guarantees</title>
      <link>https://arxiv.org/abs/2507.17556</link>
      <description>arXiv:2507.17556v1 Announce Type: new 
Abstract: In this paper, we develop and analyze sub-sampled trust-region methods for solving finite-sum optimization problems. These methods employ subsampling strategies to approximate the gradient and Hessian of the objective function, significantly reducing the overall computational cost. We propose a novel adaptive procedure for deterministically adjusting the sample size used for gradient (or gradient and Hessian) approximations. Furthermore, we establish worst-case iteration complexity bounds for obtaining approximate stationary points. More specifically, for a given $\varepsilon_g, \varepsilon_H\in (0,1)$, it is shown that an $\varepsilon_g$-approximate first-order stationary point is reached in at most $\mathcal{O}({\varepsilon_g}^{-2} )$ iterations, whereas an $(\varepsilon_g,\varepsilon_H)$-approximate second-order stationary point is reached in at most $\mathcal{O}(\max\{\varepsilon_{g}^{-2}\varepsilon_{H}^{-1},\varepsilon_{H}^{-3}\})$ iterations. Finally, numerical experiments illustrate the effectiveness of our new subsampling technique.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.17556v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Max L. N. Goncalves, Geovani N. Grapiglia</dc:creator>
    </item>
    <item>
      <title>A Compact Cycle Formulation for the Multiperiodic Event Scheduling Problem</title>
      <link>https://arxiv.org/abs/2507.17566</link>
      <description>arXiv:2507.17566v1 Announce Type: new 
Abstract: The Periodic Event Scheduling Problem (PESP) is a fundamental model in periodic timetabling for public transport systems, assuming a common period across all events. However, real-world networks often feature heterogeneous service frequencies. This paper studies the Multiperiodic Event Scheduling Problem (MPESP), a generalization of PESP that allows each event to recur at its own individual period. While more expressive, MPESP presents new modeling challenges due to the loss of a global period. We present a cycle-based formulation for MPESP that extends the strongest known formulation for PESP and, in contrast to existing approaches, is valid for any MPESP instance. Crucially, the formulation requires a cycle basis derived from a spanning tree satisfying specific structural properties, which we formalize and algorithmically construct, extending the concept of sharp spanning trees to rooted instances. We further prove a multiperiodic analogue of the cycle periodicity property. Our new formulation solves nearly all tested instances, including several large-scale real-world public transport networks, to optimality or with small optimality gaps, dramatically outperforming existing arc-based models. The results demonstrate the practical potential of MPESP in capturing heterogeneous frequencies without resorting to artificial event duplication.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.17566v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rolf Nelson van Lieshout, Niels Lindner</dc:creator>
    </item>
    <item>
      <title>Neural networks for bifurcation and linear stability analysis of steady states in partial differential equations</title>
      <link>https://arxiv.org/abs/2407.19707</link>
      <description>arXiv:2407.19707v4 Announce Type: cross 
Abstract: This research introduces an extended application of neural networks for solving nonlinear partial differential equations (PDEs). A neural network, combined with a pseudo-arclength continuation, is proposed to construct bifurcation diagrams from parameterized nonlinear PDEs. Additionally, a neural network approach is also presented for solving eigenvalue problems to analyze solution linear stability, focusing on identifying the largest eigenvalue. The effectiveness of the proposed neural network is examined through experiments on the Bratu equation and the Burgers equation. Results from a finite difference method are also presented as comparison. Varying numbers of grid points are employed in each case to assess the behavior and accuracy of both the neural network and the finite difference method. The experimental results demonstrate that the proposed neural network produces better solutions, generates more accurate bifurcation diagrams, has reasonable computational times, and proves effective for linear stability analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.19707v4</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>cs.NE</category>
      <category>math.OC</category>
      <category>nlin.PS</category>
      <pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Muhammad Luthfi Shahab, Hadi Susanto</dc:creator>
    </item>
    <item>
      <title>Quantitative convergence for displacement monotone Mean Field Games of control</title>
      <link>https://arxiv.org/abs/2507.17014</link>
      <description>arXiv:2507.17014v1 Announce Type: cross 
Abstract: In this paper we establish quantitative convergence results for both open and closed-loop Nash equilibria of N-player stochastic differential games in the setting of Mean Field Games of Controls (MFGC), a class of models where interactions among agents occur through both states and controls. Our analysis covers a general class of non-separable Hamiltonians satisfying a displacement monotonicity condition, along with mild regularity and growth conditions at infinity. A major novelty of our work is the rigorous treatment of a nontrivial fixed-point problem on a space of measures, which arises naturally in the MFGC formulation. Unlike prior works that either restrict to separable Hamiltonians - rendering the fixed-point map trivial - or assume convergence or regularity properties of the fixed point map, we develop a detailed structural analysis of this equation and its N-player analogue. This leads to new regularity results for the fixed-point maps and, in turn, to quantitative convergence of open-loop equilibria. We further derive sharp a priori estimates for the N-player Nash system, enabling us to control the discrepancy between open and closed-loop strategies, and thus to conclude the convergence of closed-loop equilibria. Our framework also accommodates common noise in a natural way.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.17014v1</guid>
      <category>math.PR</category>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Joe Jackson, Alp\'ar R. M\'esz\'aros</dc:creator>
    </item>
    <item>
      <title>ZORMS-LfD: Learning from Demonstrations with Zeroth-Order Random Matrix Search</title>
      <link>https://arxiv.org/abs/2507.17096</link>
      <description>arXiv:2507.17096v1 Announce Type: cross 
Abstract: We propose Zeroth-Order Random Matrix Search for Learning from Demonstrations (ZORMS-LfD). ZORMS-LfD enables the costs, constraints, and dynamics of constrained optimal control problems, in both continuous and discrete time, to be learned from expert demonstrations without requiring smoothness of the learning-loss landscape. In contrast, existing state-of-the-art first-order methods require the existence and computation of gradients of the costs, constraints, dynamics, and learning loss with respect to states, controls and/or parameters. Most existing methods are also tailored to discrete time, with constrained problems in continuous time receiving only cursory attention. We demonstrate that ZORMS-LfD matches or surpasses the performance of state-of-the-art methods in terms of both learning loss and compute time across a variety of benchmark problems. On unconstrained continuous-time benchmark problems, ZORMS-LfD achieves similar loss performance to state-of-the-art first-order methods with an over $80$\% reduction in compute time. On constrained continuous-time benchmark problems where there is no specialized state-of-the-art method, ZORMS-LfD is shown to outperform the commonly used gradient-free Nelder-Mead optimization method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.17096v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Olivia Dry, Timothy L. Molloy, Wanxin Jin, Iman Shames</dc:creator>
    </item>
    <item>
      <title>A Unified Toolbox for Multipartite Entanglement Certification</title>
      <link>https://arxiv.org/abs/2507.17435</link>
      <description>arXiv:2507.17435v1 Announce Type: cross 
Abstract: We present a unified framework for multipartite entanglement characterization based on the conditional gradient (CG) method, incorporating both fast heuristic detection and rigorous witness construction with numerical error control. Our method enables entanglement certification in quantum systems of up to ten qubits and applies to arbitrary entanglement structures. We demonstrate its power by closing the gap between entanglement and separability bounds in white noise robustness benchmarks for a class of bound entangled states. Furthermore, the framework extends to entanglement robustness under general quantum noise channels, providing accurate thresholds in cases beyond the reach of previous algorithmic methods. These results position CG methods as a powerful tool for practical and scalable entanglement analysis in realistic experimental settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.17435v1</guid>
      <category>quant-ph</category>
      <category>math.OC</category>
      <pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ye-Chao Liu, Jannis Halbey, Sebastian Pokutta, S\'ebastien Designolle</dc:creator>
    </item>
    <item>
      <title>Output Feedback Design for Parameter Varying Systems subject to Persistent Disturbances and Control Rate Constraints</title>
      <link>https://arxiv.org/abs/2507.17475</link>
      <description>arXiv:2507.17475v1 Announce Type: cross 
Abstract: This paper presents a technique for designing output feedback controllers for constrained linear parameter-varying systems that are subject to persistent disturbances. Specifically, we develop an incremental parameter-varying output feedback control law to address control rate constraints, as well as state and control amplitude constraints. The proposal is based on the concept of robust positively invariant sets and applies the extended Farkas' lemma to derive a set of algebraic conditions that define both the control gains and a robust positively invariant polyhedron that satisfies the control and state constraints. These algebraic conditions are formulated into a bilinear optimization problem aimed at determining the output feedback gains and the associated polyedral robust positively invariant region. The obtained controller ensures that any closed-loop trajectory originating from the polyhedron converges to another smaller inner polyhedral set around the origin in finite time, where the trajectory remains ultimately bounded regardless of the persistent disturbances and variations in system parameters. Furthermore, by including the sizes of the two polyhedral sets inside the objective function, the proposed optimization can also jointly enlarge the outer set while minimizing the inner one. Numerical examples are presented to demonstrate the effectiveness of our proposal in managing the specified constraints, disturbances, and parameter variations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.17475v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jackson G. Ernesto, Eugenio B. Castelan, Walter Lucia</dc:creator>
    </item>
    <item>
      <title>Federated Majorize-Minimization: Beyond Parameter Aggregation</title>
      <link>https://arxiv.org/abs/2507.17534</link>
      <description>arXiv:2507.17534v1 Announce Type: cross 
Abstract: This paper proposes a unified approach for designing stochastic optimization algorithms that robustly scale to the federated learning setting. Our work studies a class of Majorize-Minimization (MM) problems, which possesses a linearly parameterized family of majorizing surrogate functions. This framework encompasses (proximal) gradient-based algorithms for (regularized) smooth objectives, the Expectation Maximization algorithm, and many problems seen as variational surrogate MM. We show that our framework motivates a unifying algorithm called Stochastic Approximation Stochastic Surrogate MM (\SSMM), which includes previous stochastic MM procedures as special instances. We then extend \SSMM\ to the federated setting, while taking into consideration common bottlenecks such as data heterogeneity, partial participation, and communication constraints; this yields \QSMM. The originality of \QSMM\ is to learn locally and then aggregate information characterizing the \textit{surrogate majorizing function}, contrary to classical algorithms which learn and aggregate the \textit{original parameter}. Finally, to showcase the flexibility of this methodology beyond our theoretical setting, we use it to design an algorithm for computing optimal transport maps in the federated setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.17534v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aymeric Dieuleveut, Gersende Fort, Mahmoud Hegazy, Hoi-To Wai</dc:creator>
    </item>
    <item>
      <title>Unified Convergence Theory of Stochastic and Variance-Reduced Cubic Newton Methods</title>
      <link>https://arxiv.org/abs/2302.11962</link>
      <description>arXiv:2302.11962v5 Announce Type: replace 
Abstract: We study stochastic Cubic Newton methods for solving general possibly non-convex minimization problems. We propose a new framework, which we call the helper framework, that provides a unified view of the stochastic and variance-reduced second-order algorithms equipped with global complexity guarantees. It can also be applied to learning with auxiliary information. Our helper framework offers the algorithm designer high flexibility for constructing and analyzing the stochastic Cubic Newton methods, allowing arbitrary size batches, and the use of noisy and possibly biased estimates of the gradients and Hessians, incorporating both the variance reduction and the lazy Hessian updates. We recover the best-known complexities for the stochastic and variance-reduced Cubic Newton, under weak assumptions on the noise. A direct consequence of our theory is the new lazy stochastic second-order method, which significantly improves the arithmetic complexity for large dimension problems. We also establish complexity bounds for the classes of gradient-dominated objectives, that include convex and strongly convex problems. For Auxiliary Learning, we show that using a helper (auxiliary function) can outperform training alone if a given similarity measure is small.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.11962v5</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>El Mahdi Chayti, Nikita Doikov, Martin Jaggi</dc:creator>
    </item>
    <item>
      <title>Constrained Control Allocation With Continuous-Time Rate Constraints: Three-Dimensional Case</title>
      <link>https://arxiv.org/abs/2507.15489</link>
      <description>arXiv:2507.15489v2 Announce Type: replace 
Abstract: This paper presents a novel quadratic programming (QP) approach for constrained control allocation that directly incorporates continuous-time actuator rate constraints without requiring slack variables. Over-actuated aircraft configurations, particularly prevalent in eVTOL and military applications, require control allocation algorithms to distribute commanded control moments among available actuators while respecting position and rate constraints. Existing methods such as direct allocation, pseudo-inverse, cascaded generalized inverse, and exact redistributed pseudo-inverse either cannot handle rate constraints in continuous time or require discretization approaches that compromise performance. Current QP methods that incorporate rate constraints rely on slack variables to ensure feasibility, which prevents full utilization of the attainable moment set and degrades allocation performance. The proposed methodology addresses this limitation by calculating the attainable moment set from both position and rate constraints through convex hull operations, then ensuring feasibility by scaling unattainable commanded moments to the boundary of the attainable moment set while preserving their direction. This approach guarantees the feasibility of the optimization problem without slack variables. The method is validated through simulation on an F-18 fighter aircraft control allocation problem, demonstrating equivalent performance to the established exact redistributed pseudo-inverse method while providing smoother actuator behavior and enhanced constraint satisfaction. Results show that incorporating continuous-time rate constraints leads to improved actuator tracking, reduced overshoot, and more precise adherence to position limits, which is essential for aircraft safety, ride comfort, and actuator longevity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.15489v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>S\"uleyman \"Ozkurt, Adrian Grimm, Walter Fichter</dc:creator>
    </item>
    <item>
      <title>Automated Market Making and Arbitrage Profits in the Presence of Fees</title>
      <link>https://arxiv.org/abs/2305.14604</link>
      <description>arXiv:2305.14604v2 Announce Type: replace-cross 
Abstract: We consider the impact of trading fees on the profits of arbitrageurs trading against an automated market maker (AMM) or, equivalently, on the adverse selection incurred by liquidity providers (LPs) due to arbitrage. We extend the model of Milionis et al. [2022] for a general class of two asset AMMs to introduce both fees and discrete Poisson block generation times. In our setting, we are able to compute the expected instantaneous rate of arbitrage profit in closed form. When the fees are low, in the fast block asymptotic regime, the impact of fees takes a particularly simple form: fees simply scale down arbitrage profits by the fraction of blocks which present profitable trading opportunities to arbitrageurs. This fraction decreases with an increasing block rate, hence our model yields an important practical insight: faster blockchains will result in reduced LP losses. Further introducing gas fees (fixed costs) in our model, we show that, in the fast block asymptotic regime, lower gas fees lead to smaller losses for LPs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.14604v2</guid>
      <category>q-fin.MF</category>
      <category>math.OC</category>
      <category>q-fin.PM</category>
      <category>q-fin.PR</category>
      <category>q-fin.TR</category>
      <pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jason Milionis, Ciamac C. Moallemi, Tim Roughgarden</dc:creator>
    </item>
    <item>
      <title>Gathering and Exploiting Higher-Order Information when Training Large Structured Models</title>
      <link>https://arxiv.org/abs/2312.03885</link>
      <description>arXiv:2312.03885v4 Announce Type: replace-cross 
Abstract: When training large models, such as neural networks, the full derivatives of order 2 and beyond are usually inaccessible, due to their computational cost. Therefore, among the second-order optimization methods, it is common to bypass the computation of the Hessian by using first-order information, such as the gradient of the parameters (e.g., quasi-Newton methods) or the activations (e.g., K-FAC). In this paper, we focus on the exact and explicit computation of projections of the Hessian and higher-order derivatives on well-chosen subspaces relevant for optimization. Namely, for a given partition of the set of parameters, we compute tensors that can be seen as "higher-order derivatives according to the partition", at a reasonable cost as long as the number of subsets of the partition remains small. Then, we give some examples of how these tensors can be used. First, we show how to compute a learning rate per subset of parameters, which can be used for hyperparameter tuning. Second, we show how to use these tensors at order 2 to construct an optimization method that uses information contained in the Hessian. Third, we show how to use these tensors at order 3 (information contained in the third derivative of the loss) to regularize this optimization method. The resulting training step has several interesting properties, including: it takes into account long-range interactions between the layers of the trained neural network, which is usually not the case in similar methods (e.g., K-FAC); the trajectory of the optimization is invariant under affine layer-wise reparameterization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.03885v4</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pierre Wolinski</dc:creator>
    </item>
    <item>
      <title>Enhancing supply chain security with automated machine learning</title>
      <link>https://arxiv.org/abs/2406.13166</link>
      <description>arXiv:2406.13166v3 Announce Type: replace-cross 
Abstract: The increasing scale and complexity of global supply chains have led to new challenges spanning various fields, such as supply chain disruptions due to long waiting lines at the ports, material shortages, and inflation. Coupled with the size of supply chains and the availability of vast amounts of data, efforts towards tackling such challenges have led to an increasing interest in applying machine learning methods in many aspects of supply chains. Unlike other solutions, ML techniques, including Random Forest, XGBoost, LightGBM, and Neural Networks, make predictions and approximate optimal solutions faster. This paper presents an automated ML framework to enhance supply chain security by detecting fraudulent activities, predicting maintenance needs, and forecasting material backorders. Using datasets of varying sizes, results show that fraud detection achieves an 88% accuracy rate using sampling methods, machine failure prediction reaches 93.4% accuracy, and material backorder prediction achieves 89.3% accuracy. Hyperparameter tuning significantly improved the performance of these models, with certain supervised techniques like XGBoost and LightGBM reaching up to 100% precision. This research contributes to supply chain security by streamlining data preprocessing, feature selection, model optimization, and inference deployment, addressing critical challenges and boosting operational efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.13166v3</guid>
      <category>cs.LG</category>
      <category>econ.GN</category>
      <category>math.OC</category>
      <category>q-fin.EC</category>
      <pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haibo Wang, Lutfu S. Sua, Bahram Alidaee</dc:creator>
    </item>
    <item>
      <title>Balans: Multi-Armed Bandits-based Adaptive Large Neighborhood Search for Mixed-Integer Programming Problem</title>
      <link>https://arxiv.org/abs/2412.14382</link>
      <description>arXiv:2412.14382v3 Announce Type: replace-cross 
Abstract: Mixed-integer programming (MIP) is a powerful paradigm for modeling and solving various important combinatorial optimization problems. Recently, learning-based approaches have shown a potential to speed up MIP solving via offline training that then guides important design decisions during the search. However, a significant drawback of these methods is their heavy reliance on offline training, which requires collecting training datasets and computationally costly training epochs yet offering only limited generalization to unseen (larger) instances. In this paper, we propose Balans, an adaptive meta-solver for MIPs with online learning capability that does not require any supervision or apriori training. At its core, Balans is based on adaptive large-neighborhood search, operating on top of an MIP solver by successive applications of destroy and repair neighborhood operators. During the search, the selection among different neighborhood definitions is guided on the fly for the instance at hand via multi-armed bandit algorithms. Our extensive experiments on hard optimization instances show that Balans offers significant performance gains over the default MIP solver, is better than committing to any single best neighborhood, and improves over the state-of-the-art large-neighborhood search for MIPs. Finally, we release Balans as a highly configurable, MIP solver agnostic, open-source software.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.14382v3</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junyang Cai, Serdar Kadioglu, Bistra Dilkina</dc:creator>
    </item>
    <item>
      <title>A Coalition Game for On-demand Multi-modal 3D Automated Delivery System</title>
      <link>https://arxiv.org/abs/2412.17252</link>
      <description>arXiv:2412.17252v2 Announce Type: replace-cross 
Abstract: We introduce a multi-modal autonomous delivery optimization framework as a coalition game for a fleet of UAVs and ADRs operating in two overlaying networks to address last-mile delivery in urban environments, including high-density areas and time-critical applications. The problem is defined as multiple depot pickup and delivery with time windows constrained over operational restrictions, such as vehicle battery limitation, precedence time window, and building obstruction. Utilizing the coalition game theory, we investigate cooperation structures among the modes to capture how strategic collaboration can improve overall routing efficiency. To do so, a generalized reinforcement learning model is designed to evaluate the cost-sharing and allocation to different modes to learn the cooperative behaviour with respect to various realistic scenarios. Our methodology leverages an end-to-end deep multi-agent policy gradient method augmented by a novel spatio-temporal adjacency neighbourhood graph attention network using a heterogeneous edge-enhanced attention model and transformer architecture. Several numerical experiments on last-mile delivery applications have been conducted, showing the results from the case study in the city of Mississauga, which shows that despite the incorporation of an extensive network in the graph for two modes and a complex training structure, the model addresses realistic operational constraints and achieves high-quality solutions compared with the existing transformer-based and classical methods. It can perform well on non-homogeneous data distribution, generalizes well on different scales and configurations, and demonstrates a robust cooperative performance under stochastic scenarios across various tasks, which is effectively reflected by coalition analysis and cost allocation to signify the advantage of cooperation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17252v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Farzan Moosavi, Bilal Farooq</dc:creator>
    </item>
    <item>
      <title>The Surprising Agreement Between Convex Optimization Theory and Learning-Rate Scheduling for Large Model Training</title>
      <link>https://arxiv.org/abs/2501.18965</link>
      <description>arXiv:2501.18965v2 Announce Type: replace-cross 
Abstract: We show that learning-rate schedules for large model training behave surprisingly similar to a performance bound from non-smooth convex optimization theory. We provide a bound for the constant schedule with linear cooldown; in particular, the practical benefit of cooldown is reflected in the bound due to the absence of logarithmic terms. Further, we show that this surprisingly close match between optimization theory and practice can be exploited for learning-rate tuning: we achieve noticeable improvements for training 124M and 210M Llama-type models by (i) extending the schedule for continued training with optimal learning-rate, and (ii) transferring the optimal learning-rate across schedules.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18965v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fabian Schaipp, Alexander H\"agele, Adrien Taylor, Umut Simsekli, Francis Bach</dc:creator>
    </item>
    <item>
      <title>The Learning Approach to Games</title>
      <link>https://arxiv.org/abs/2503.00227</link>
      <description>arXiv:2503.00227v2 Announce Type: replace-cross 
Abstract: This work introduces a unified framework for a more detailed exploration of games. In existing literature, strategies of players are typically assigned scalar values, and the concept of Nash equilibrium is used to identify compatible strategies. However, this approach lacks the internal structure of a player, thereby failing to accurately model observed behaviors.
  To address this limitation, we propose an abstract definition of a player. This allows for a more nuanced understanding of players and brings the focus to the challenge of learning that players face. Unlike Markov decision processes, which formalize control problems but not agent design, our framework subsumes standard reinforcement learning structures. It thus offers a language that enables a deeper connection between games and learning. To illustrate the need for such generality, we study a simple two-player game and show that even in the most basic settings, a sophisticated player may adopt dynamic strategies that cannot be captured by simpler designs or compatibility analysis alone.
  In the discrete setting, we consider a player whose structure incorporates standard estimates from the literature. We explore connections to correlated equilibrium and highlight that dynamic programming naturally applies to all estimates. In the mean-field setting, we exploit symmetry to construct explicit examples of equilibria. Finally, we examine connections to reinforcement learning and bandit problems, demonstrating the broad applicability of the framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00227v2</guid>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <category>math.OC</category>
      <pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Melih \.I\c{s}eri, Erhan Bayraktar</dc:creator>
    </item>
    <item>
      <title>Data-Driven Exploration for a Class of Continuous-Time Indefinite Linear--Quadratic Reinforcement Learning Problems</title>
      <link>https://arxiv.org/abs/2507.00358</link>
      <description>arXiv:2507.00358v2 Announce Type: replace-cross 
Abstract: We study reinforcement learning (RL) for the same class of continuous-time stochastic linear--quadratic (LQ) control problems as in \cite{huang2024sublinear}, where volatilities depend on both states and controls while states are scalar-valued and running control rewards are absent. We propose a model-free, data-driven exploration mechanism that adaptively adjusts entropy regularization by the critic and policy variance by the actor. Unlike the constant or deterministic exploration schedules employed in \cite{huang2024sublinear}, which require extensive tuning for implementations and ignore learning progresses during iterations, our adaptive exploratory approach boosts learning efficiency with minimal tuning. Despite its flexibility, our method achieves a sublinear regret bound that matches the best-known model-free results for this class of LQ problems, which were previously derived only with fixed exploration schedules. Numerical experiments demonstrate that adaptive explorations accelerate convergence and improve regret performance compared to the non-adaptive model-free and model-based counterparts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.00358v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yilie Huang, Xun Yu Zhou</dc:creator>
    </item>
    <item>
      <title>On the non-convexity issue in the radial Calder\'on problem</title>
      <link>https://arxiv.org/abs/2507.03379</link>
      <description>arXiv:2507.03379v2 Announce Type: replace-cross 
Abstract: A classical approach to the Calder\'on problem is to estimate the unknown conductivity by solving a nonlinear least-squares problem. It is generally believed that it leads to a nonconvex optimization problem which is riddled with bad local minimums. This has motivated the development of reconstruction methods based on convex optimization, one recent contribution being the nonlinear convex semidefinite programming approach of Harrach (2023). In this work, we investigate the computational viability of this convex approach in a simple setting where the conductivities are piecewise constant and radial. We implement this convex reconstruction method and compare it extensively to the least squares approach. Our experiments suggest that this convex programming approach only allows to accurately estimate the unknown for problems with a very small size. Moreover, surprisingly, it is consistently outperformed by Newton-type least squares solvers, which are also faster and require less measurements. We revisit the issue of nonconvexity in this piecewise constant radial setting and prove that, contrary to previous claims, there are no local minimums in the case of two scalar unknowns with no measurement noise. We also provide a partial proof of this result in the general setting which holds under a numerically verifiable assumption.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.03379v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Giovanni S. Alberti, Romain Petit, Clarice Poon</dc:creator>
    </item>
  </channel>
</rss>
