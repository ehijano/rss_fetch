<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-fin.RM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-fin.RM</link>
    <description>q-fin.RM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-fin.RM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 18 Sep 2025 04:04:56 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 18 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Valuation of Exotic Options and Counterparty Games Based on Conditional Diffusion</title>
      <link>https://arxiv.org/abs/2509.13374</link>
      <description>arXiv:2509.13374v1 Announce Type: cross 
Abstract: This paper addresses the challenges of pricing exotic options and structured products, which traditional models often fail to handle due to their inability to capture real-world market phenomena like fat-tailed distributions and volatility clustering. We introduce a Diffusion-Conditional Probability Model (DDPM) to generate more realistic price paths. Our method incorporates a composite loss function with financial-specific features, and we propose a P-Q dynamic game framework for evaluating the model's economic value through adversarial backtesting. Static validation shows our P-model effectively matches market mean and volatility. In dynamic games, it demonstrates significantly higher profitability than a traditional Monte Carlo-based model for European and Asian options. However, the model shows limitations in pricing products highly sensitive to extreme events, such as snowballs and accumulators, because it tends to underestimate tail risks. The study concludes that diffusion models hold significant potential for enhancing pricing accuracy, though further research is needed to improve their ability to model extreme market risks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.13374v1</guid>
      <category>q-fin.PR</category>
      <category>cs.LG</category>
      <category>q-fin.RM</category>
      <pubDate>Thu, 18 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Helin Zhao, Junchi Shen</dc:creator>
    </item>
    <item>
      <title>Holdout cross-validation for large non-Gaussian covariance matrix estimation using Weingarten calculus</title>
      <link>https://arxiv.org/abs/2509.13923</link>
      <description>arXiv:2509.13923v1 Announce Type: cross 
Abstract: Cross-validation is one of the most widely used methods for model selection and evaluation; its efficiency for large covariance matrix estimation appears robust in practice, but little is known about the theoretical behavior of its error. In this paper, we derive the expected Frobenius error of the holdout method, a particular cross-validation procedure that involves a single train and test split, for a generic rotationally invariant multiplicative noise model, therefore extending previous results to non-Gaussian data distributions. Our approach involves using the Weingarten calculus and the Ledoit-P\'ech\'e formula to derive the oracle eigenvalues in the high-dimensional limit. When the population covariance matrix follows an inverse Wishart distribution, we approximate the expected holdout error, first with a linear shrinkage, then with a quadratic shrinkage to approximate the oracle eigenvalues. Under the linear approximation, we find that the optimal train-test split ratio is proportional to the square root of the matrix dimension. Then we compute Monte Carlo simulations of the holdout error for different distributions of the norm of the noise, such as the Gaussian, Student, and Laplace distributions and observe that the quadratic approximation yields a substantial improvement, especially around the optimal train-test split ratio. We also observe that a higher fourth-order moment of the Euclidean norm of the noise vector sharpens the holdout error curve near the optimal split and lowers the ideal train-test ratio, making the choice of the train-test ratio more important when performing the holdout method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.13923v1</guid>
      <category>q-fin.ST</category>
      <category>math.ST</category>
      <category>q-fin.RM</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Thu, 18 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lamia Lamrani, Beno\^it Collins, Jean-Philippe Bouchaud</dc:creator>
    </item>
    <item>
      <title>Statistical Consequences of Fat Tails: Real World Preasymptotics, Epistemology, and Applications</title>
      <link>https://arxiv.org/abs/2001.10488</link>
      <description>arXiv:2001.10488v4 Announce Type: replace-cross 
Abstract: (The third edition corrects minor typos and adds 3 chapters synthesized from published papers plus an appendix on maximum entropy distributions.) The monograph investigates the misapplication of conventional statistical techniques to fat tailed distributions and looks for remedies, when possible.
  Switching from thin tailed to fat tailed distributions requires more than "changing the color of the dress". Traditional asymptotics deal mainly with either n=1 or $n=\infty$, and the real world is in between, under of the "laws of the medium numbers" --which vary widely across specific distributions. Both the law of large numbers and the generalized central limit mechanisms operate in highly idiosyncratic ways outside the standard Gaussian or Levy-Stable basins of convergence.
  A few examples:
  + The sample mean is rarely in line with the population mean, with effect on "naive empiricism", but can be sometimes be estimated via parametric methods.
  + The "empirical distribution" is rarely empirical.
  + Parameter uncertainty has compounding effects on statistical metrics.
  + Dimension reduction (principal components) fails.
  + Inequality estimators (GINI or quantile contributions) are not additive and produce wrong results.
  + Many "biases" found in psychology become entirely rational under more sophisticated probability distributions
  + Most of the failures of financial economics, econometrics, and behavioral economics can be attributed to using the wrong distributions.
  This book, the first volume of the Technical Incerto, weaves a narrative around published journal articles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2001.10488v4</guid>
      <category>stat.OT</category>
      <category>q-fin.RM</category>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <pubDate>Thu, 18 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nassim Nicholas Taleb</dc:creator>
    </item>
    <item>
      <title>Optimal Data Splitting for Holdout Cross-Validation in Large Covariance Matrix Estimation</title>
      <link>https://arxiv.org/abs/2503.15186</link>
      <description>arXiv:2503.15186v2 Announce Type: replace-cross 
Abstract: Cross-validation is a statistical tool that can be used to improve large covariance matrix estimation. Although its efficiency is observed in practical applications and a convergence result towards the error of the non linear shrinkage is available in the high-dimensional regime, formal proofs that take into account the finite sample size effects are currently lacking. To carry on analytical analysis, we focus on the holdout method, a single iteration of cross-validation, rather than the traditional $k$-fold approach. We derive a closed-form expression for the expected estimation error when the population matrix follows a white inverse Wishart distribution, and we observe the optimal train-test split scales as the square root of the matrix dimension. For general population matrices, we connected the error to the variance of eigenvalues distribution, but approximations are necessary. In this framework and in the high-dimensional asymptotic regime, both the holdout and $k$-fold cross-validation methods converge to the optimal estimator when the train-test ratio scales with the square root of the matrix dimension which is coherent with the existing theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.15186v2</guid>
      <category>math.ST</category>
      <category>q-fin.PM</category>
      <category>q-fin.RM</category>
      <category>stat.AP</category>
      <category>stat.TH</category>
      <pubDate>Thu, 18 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lamia Lamrani, Christian Bongiorno, Marc Potters</dc:creator>
    </item>
  </channel>
</rss>
