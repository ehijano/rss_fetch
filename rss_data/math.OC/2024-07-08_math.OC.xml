<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 08 Jul 2024 04:00:16 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 08 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>AI Driven Laser Parameter Search: Inverse Design of Photonic Surfaces using Greedy Surrogate-based Optimization</title>
      <link>https://arxiv.org/abs/2407.03356</link>
      <description>arXiv:2407.03356v1 Announce Type: new 
Abstract: Photonic surfaces designed with specific optical characteristics are becoming increasingly important for use in in various energy harvesting and storage systems. , In this study, we develop a surrogate-based optimization approach for designing such surfaces. The surrogate-based optimization framework employs the Random Forest algorithm and uses a greedy, prediction-based exploration strategy to identify the laser fabrication parameters that minimize the discrepancy relative to a user-defined target optical characteristics. We demonstrate the approach on two synthetic benchmarks and two specific cases of photonic surface inverse design targets. It exhibits superior performance when compared to other optimization algorithms across all benchmarks. Additionally, we demonstrate a technique of inverse design warm starting for changed target optical characteristics which enhances the performance of the introduced approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03356v1</guid>
      <category>math.OC</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>physics.app-ph</category>
      <category>physics.optics</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luka Grbcic, Minok Park, Juliane M\"uller, Vassilia Zorba, Wibe Albert de Jong</dc:creator>
    </item>
    <item>
      <title>Fault-Ride-Through (FRT) Control of a grid-connected Fixed-Speed Wind Energy Conversion System using STATCOM</title>
      <link>https://arxiv.org/abs/2407.03429</link>
      <description>arXiv:2407.03429v1 Announce Type: new 
Abstract: Wind energy conversion system (WECS) is stochastic in nature and has low inertia to grid voltage instability, poor reactive power compensation and most importantly fault susceptibility. Variable speed WECS such as a doubly-fed induction generators (DFIG) are well known to reach steady state quickly after fault occurrence without the need for an external reactive power source because of the presence of a back-to-back converter that provides independent control of the active and reactive power unlike in the fixed-speed squirrel cage induction generator (SCIG) counterpart that cant be stabilized unless ab external source of reactive power support is present. However, controlling DFIG is complicated and costly due to complete tripping unlike the fixed-speed generators which doesnt trip completely when fault occurs. Hence, in this work, a 48-pulse, 3-phase static synchronous compensator (STATCOM) is used to ensure reactive power compensation and fault-ride through (FRT) control of the SCIG against over-voltage emanating from fault occurrence in a grid-connected power system. The goal here is to guarantee voltage stability and fault-ride through control against injected faults within certain time ranges at the point of common coupling (PCC) between the AC sources, the load, and the fixed-speed WECS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03429v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ayobami Olajube, Satish Vedula, Koto Omiloli, Olugbenga Anubi</dc:creator>
    </item>
    <item>
      <title>Fault-Tolerant Decentralized Control for Large-scale Inverter-based Resources for Active Power Tracking</title>
      <link>https://arxiv.org/abs/2407.03444</link>
      <description>arXiv:2407.03444v1 Announce Type: new 
Abstract: Integration of Inverter Based Resources (IBRs) which lack the intrinsic characteristics such as the inertial response of the traditional synchronous-generator (SG) based sources presents a new challenge in the form of analyzing the grid stability under their presence. While the dynamic composition of IBRs differs from that of the SGs, the control objective remains similar in terms of tracking the desired active power. This letter presents a decentralized primal-dual-based fault-tolerant control framework for the power allocation in IBRs. Overall, a hierarchical control algorithm is developed with a lower level addressing the current control and the parameter estimation for the IBRs and the higher level acting as the reference power generator to the low level based on the desired active power profile. The decentralized network-based algorithm adaptively splits the desired power between the IBRs taking into consideration the health of the IBRs transmission lines. The proposed framework is tested through a simulation on the network of IBRs and the high-level controller performance is compared against the existing framework in the literature. The proposed algorithm shows significant performance improvement in the magnitude of power deviation and settling time to the nominal value under faulty conditions as compared to the algorithm in the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03444v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Satish Vedula, Ayobami Olajube, Olugbenga Anubi</dc:creator>
    </item>
    <item>
      <title>A strongly convergent inertial inexact proximal-point algorithm for monotone inclusions with applications to variational inequalities</title>
      <link>https://arxiv.org/abs/2407.03485</link>
      <description>arXiv:2407.03485v1 Announce Type: new 
Abstract: We propose an inertial variant of the strongly convergent inexact proximal-point (PP) method of Solodov and Svaiter (2000) for monotone inclusions. We prove strong convergence of our main algorithm under less restrictive assumptions on the inertial parameters when compared to previous analysis of inertial PP-type algorithms, which makes our method of interest even in finite-dimensional settings. We also performed an iteration-complexity analysis and applied our main algorithm to variational inequalities for monotone operators, obtaining strongly convergent (inertial) variants of Korpolevich's extragradient, forward-backward and Tseng's modified forward-backward methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03485v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>M. Marques Alves, J. E. Navarro Caballero, R. T. Marcavillaca</dc:creator>
    </item>
    <item>
      <title>Improved Iteration Complexity in Black-Box Optimization Problems under Higher Order Smoothness Function Condition</title>
      <link>https://arxiv.org/abs/2407.03507</link>
      <description>arXiv:2407.03507v1 Announce Type: new 
Abstract: This paper is devoted to the study (common in many applications) of the black-box optimization problem, where the black-box represents a gradient-free oracle $\tilde{f} = f(x) + \xi$ providing the objective function value with some stochastic noise. Assuming that the objective function is $\mu$-strongly convex, and also not just $L$-smooth, but has a higher order of smoothness ($\beta \geq 2$) we provide a novel optimization method: Zero-Order Accelerated Batched Stochastic Gradient Descent, whose theoretical analysis closes the question regarding the iteration complexity, achieving optimal estimates. Moreover, we provide a thorough analysis of the maximum noise level, and show under which condition the maximum noise level will take into account information about batch size $B$ as well as information about the smoothness order of the function $\beta$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03507v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aleksandr Lobanov</dc:creator>
    </item>
    <item>
      <title>A Fully Parameter-Free Second-Order Algorithm for Convex-Concave Minimax Problems with Optimal Iteration Complexity</title>
      <link>https://arxiv.org/abs/2407.03571</link>
      <description>arXiv:2407.03571v1 Announce Type: new 
Abstract: In this paper, we study second-order algorithms for the convex-concave minimax problem, which has attracted much attention in many fields such as machine learning in recent years. We propose a Lipschitz-free cubic regularization (LF-CR) algorithm for solving the convex-concave minimax optimization problem without knowing the Lipschitz constant. It can be shown that the iteration complexity of the LF-CR algorithm to obtain an $\epsilon$-optimal solution with respect to the restricted primal-dual gap is upper bounded by $\mathcal{O}(\frac{\rho\|z^0-z^*\|^3}{\epsilon})^{\frac{2}{3}}$, where $z^0=(x^0,y^0)$ is a pair of initial points, $z^*=(x^*,y^*)$ is a pair of optimal solutions, and $\rho$ is the Lipschitz constant. We further propose a fully parameter-free cubic regularization (FF-CR) algorithm that does not require any parameters of the problem, including the Lipschitz constant and the upper bound of the distance from the initial point to the optimal solution. We also prove that the iteration complexity of the FF-CR algorithm to obtain an $\epsilon$-optimal solution with respect to the gradient norm is upper bounded by $\mathcal{O}(\frac{\rho\|z^0-z^*\|^2}{\epsilon})^{\frac{2}{3}}$. Numerical experiments show the efficiency of both algorithms. To the best of our knowledge, the proposed FF-CR algorithm is the first completely parameter-free second-order algorithm for solving convex-concave minimax optimization problems, and its iteration complexity is consistent with the optimal iteration complexity lower bound of existing second-order algorithms with parameters for solving convex-concave minimax problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03571v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junlin Wang, Junnan Yang, Zi Xu</dc:creator>
    </item>
    <item>
      <title>Distributed online generalized Nash Equilibrium learning in multi-cluster games: A delay-tolerant algorithm</title>
      <link>https://arxiv.org/abs/2407.03578</link>
      <description>arXiv:2407.03578v1 Announce Type: new 
Abstract: This paper addresses the problem of distributed online generalized Nash equilibrium (GNE) learning for multi-cluster games with delayed feedback information. Specifically, each agent in the game is assumed to be informed a sequence of local cost functions and constraint functions, which are known to the agent with time-varying delays subsequent to decision-making at each round. The objective of each agent within a cluster is to collaboratively optimize the cluster's cost function, subject to time-varying coupled inequality constraints and local feasible set constraints over time. Additionally, it is assumed that each agent is required to estimate the decisions of all other agents through interactions with its neighbors, rather than directly accessing the decisions of all agents, i.e., each agent needs to make decision under partial-decision information. To solve such a challenging problem, a novel distributed online delay-tolerant GNE learning algorithm is developed based upon the primal-dual algorithm with an aggregation gradient mechanism. The system-wise regret and the constraint violation are formulated to measure the performance of the algorithm, demonstrating sublinear growth with respect to time under certain conditions. Finally, numerical results are presented to verify the effectiveness of the proposed algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03578v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bingqian Liu, Guanghui Wen, Xiao Fang, Tingwen Huang, Guanrong Chen</dc:creator>
    </item>
    <item>
      <title>Online Non-Stationary Stochastic Quasar-Convex Optimization</title>
      <link>https://arxiv.org/abs/2407.03601</link>
      <description>arXiv:2407.03601v1 Announce Type: new 
Abstract: Recent research has shown that quasar-convexity can be found in applications such as identification of linear dynamical systems and generalized linear models. Such observations have in turn spurred exciting developments in design and analysis algorithms that exploit quasar-convexity. In this work, we study the online stochastic quasar-convex optimization problems in a dynamic environment. We establish regret bounds of online gradient descent in terms of cumulative path variation and cumulative gradient variance for losses satisfying quasar-convexity and strong quasar-convexity. We then apply the results to generalized linear models (GLM) when the underlying parameter is time-varying. We establish regret bounds of online gradient descent when applying to GLMs with leaky ReLU activation function, logistic activation function, and ReLU activation function. Numerical results are presented to corroborate our findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03601v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yuen-Man Pun, Iman Shames</dc:creator>
    </item>
    <item>
      <title>Orthogonal Constrained Minimization with Tensor $\ell_{2,p}$ Regularization for HSI Denoising and Destriping</title>
      <link>https://arxiv.org/abs/2407.03605</link>
      <description>arXiv:2407.03605v1 Announce Type: new 
Abstract: Hyperspectral images (HSIs) are often contaminated by a mixture of noises such as Gaussian noise, dead lines, stripes, and so on. In this paper, we propose a novel approach for HSI denoising and destriping, called NLTL2p, which consists of an orthogonal constrained minimization model and an iterative algorithm with convergence guarantees. The model of the proposed NLTL2p approach is built based on a new sparsity-enhanced Nonlocal Low-rank Tensor regularization and a tensor $\ell_{2,p}$ norm with $p\in(0,1)$. The low-rank constraints for HSI denoising utilize the spatial nonlocal self-similarity and spectral correlation of HSIs and are formulated based on independent higher-order singular value decomposition with sparsity enhancement on its core tensor to prompt more low-rankness. The tensor $\ell_{2,p}$ norm for HSI destriping is extended from the matrix $\ell_{2,p}$ norm. A proximal block coordinate descent algorithm is proposed in the NLTL2p approach to solve the resulting nonconvex nonsmooth minimization with orthogonal constraints. We show any accumulation point of the sequence generated by the proposed algorithm converges to a first-order stationary point, which is defined using three equalities of substationarity, symmetry, and feasibility for orthogonal constraints. In the numerical experiments, we compare the proposed method with state-of-the-art methods including a deep learning based method, and test the methods on both simulated and real HSI datasets. Our proposed NLTL2p method demonstrates outperformance in terms of metrics such as mean peak signal-to-noise ratio as well as visual quality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03605v1</guid>
      <category>math.OC</category>
      <category>cs.CV</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaoxia Liu, Shijie Yu, Jian Lu, Xiaojun Chen</dc:creator>
    </item>
    <item>
      <title>A Probabilistic Approach to Discounted Infinite Horizon and Invariant Mean Field Games</title>
      <link>https://arxiv.org/abs/2407.03642</link>
      <description>arXiv:2407.03642v1 Announce Type: new 
Abstract: This paper considers discounted infinite horizon mean field games by extending the probabilistic weak formulation of the game as introduced by Carmona and Lacker (2015). Under similar assumptions as in the finite horizon game, we prove existence and uniqueness of solutions for the extended infinite horizon game. The key idea is to construct local versions of the previously considered stable topologies. Further, we analyze how sequences of finite horizon games approximate the infinite horizon one. Under a weakened Lasry-Lions monotonicity condition, we can quantify the convergence rate of solutions for the finite horizon games to the one for the infinite horizon game using a novel stability result for mean field games. Lastly, applying our results allows to solve the invariant mean field game as well.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03642v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ren\'e Carmona, Ludovic Tangpi, Kaiwen Zhang</dc:creator>
    </item>
    <item>
      <title>WANCO: Weak Adversarial Networks for Constrained Optimization problems</title>
      <link>https://arxiv.org/abs/2407.03647</link>
      <description>arXiv:2407.03647v1 Announce Type: new 
Abstract: This paper focuses on integrating the networks and adversarial training into constrained optimization problems to develop a framework algorithm for constrained optimization problems. For such problems, we first transform them into minimax problems using the augmented Lagrangian method and then use two (or several) deep neural networks(DNNs) to represent the primal and dual variables respectively. The parameters in the neural networks are then trained by an adversarial process. The proposed architecture is relatively insensitive to the scale of values of different constraints when compared to penalty based deep learning methods. Through this type of training, the constraints are imposed better based on the augmented Lagrangian multipliers. Extensive examples for optimization problems with scalar constraints, nonlinear constraints, partial differential equation constraints, and inequality constraints are considered to show the capability and robustness of the proposed method, with applications ranging from Ginzburg--Landau energy minimization problems, partition problems, fluid-solid topology optimization, to obstacle problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03647v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gang Bao, Dong Wang, Boyi Zou</dc:creator>
    </item>
    <item>
      <title>Internal Controls for Stochastic Lattice Dynamics</title>
      <link>https://arxiv.org/abs/2407.03710</link>
      <description>arXiv:2407.03710v1 Announce Type: new 
Abstract: In [6], we have designed impulsive and feed-back controls for harmonic chains with a point thermostat. In this work, a new type of control is proposed: internal control. We study the internal control for for stochastic lattice dynamics, with the goal of controlling the transition kernel of the kinetic equation in the limit.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03710v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Amirali Hannani, Minh-Nhat Phung, Minh-Binh Tran, Emmanuel Tr\'elat</dc:creator>
    </item>
    <item>
      <title>Continuous-time q-Learning for Jump-Diffusion Models under Tsallis Entropy</title>
      <link>https://arxiv.org/abs/2407.03888</link>
      <description>arXiv:2407.03888v1 Announce Type: new 
Abstract: This paper studies continuous-time reinforcement learning for controlled jump-diffusion models by featuring the q-function (the continuous-time counterpart of Q-function) and the q-learning algorithms under the Tsallis entropy regularization. Contrary to the conventional Shannon entropy, the general form of Tsallis entropy renders the optimal policy not necessary a Gibbs measure, where some Lagrange multiplier and KKT multiplier naturally arise from certain constraints to ensure the learnt policy to be a probability distribution. As a consequence,the relationship between the optimal policy and the q-function also involves the Lagrange multiplier. In response, we establish the martingale characterization of the q-function under Tsallis entropy and devise two q-learning algorithms depending on whether the Lagrange multiplier can be derived explicitly or not. In the latter case, we need to consider different parameterizations of the q-function and the policy and update them alternatively. Finally, we examine two financial applications, namely an optimal portfolio liquidation problem and a non-LQ control problem. It is interesting to see therein that the optimal policies under the Tsallis entropy regularization can be characterized explicitly, which are distributions concentrate on some compact support. The satisfactory performance of our q-learning algorithm is illustrated in both examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03888v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lijun Bo, Yijie Huang, Xiang Yu, Tingting Zhang</dc:creator>
    </item>
    <item>
      <title>A Generalized Spiking Locally Competitive Algorithm for Multiple Optimization Problems</title>
      <link>https://arxiv.org/abs/2407.03930</link>
      <description>arXiv:2407.03930v1 Announce Type: new 
Abstract: We introduce a generalized Spiking Locally Competitive Algorithm (LCA) that is biologically plausible and exhibits adaptability to a large variety of neuron models and network connectivity structures. In addition, we provide theoretical evidence demonstrating the algorithm's convergence in optimization problems of signal recovery. Furthermore, our algorithm demonstrates superior performance over traditional optimization methods, such as FISTA, particularly by achieving faster early convergence in practical scenarios including signal denoising, seismic wave detection, and computed tomography reconstruction. Notably, our algorithm is compatible with neuromorphic chips, such as Loihi, facilitating efficient multitasking within the same chip architecture - a capability not present in existing algorithms. These advancements make our generalized Spiking LCA a promising solution for real-world applications, offering significant improvements in execution speed and flexibility for neuromorphic computing systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03930v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xuexing Du, Zhong-qi K. Tian, Songting Li, Douglas Zhou</dc:creator>
    </item>
    <item>
      <title>Factorized binary polynomial optimization</title>
      <link>https://arxiv.org/abs/2407.03936</link>
      <description>arXiv:2407.03936v1 Announce Type: new 
Abstract: In binary polynomial optimization, the goal is to find a binary point maximizing a given polynomial function. In this paper, we propose a novel way of formulating this general optimization problem, which we call factorized binary polynomial optimization. In this formulation, we assume that the variables are partitioned into a fixed number of sets, and that the objective function is written as a sum of r products of linear functions, each one involving only variables in one set of the partition. Our main result is an algorithm that solves factorized binary polynomial optimization in strongly polynomial time, when r is fixed. This result provides a vast new class of tractable instances of binary polynomial optimization, and it even improves on the state-of-the-art for quadratic objective functions, both in terms of generality and running time. We demonstrate the applicability of our result through the binary tensor factorization problem, which arises in mining discrete patterns in data, and that contains as a special case the rank-1 Boolean tensor factorization problem. Our main result implies that these problems can be solved in strongly polynomial time, if the input tensor has fixed rank, and a rank factorization is given. For the rank-1 Boolean matrix factorization problem, we only require that the input matrix has fixed rank.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03936v1</guid>
      <category>math.OC</category>
      <category>cs.DM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alberto Del Pia</dc:creator>
    </item>
    <item>
      <title>Coincident Peak Prediction for Capacity and Transmission Charge Reduction</title>
      <link>https://arxiv.org/abs/2407.04081</link>
      <description>arXiv:2407.04081v1 Announce Type: new 
Abstract: Meeting the ever-growing needs of the power grid requires constant infrastructure enhancement. There are two important aspects for a grid ability to ensure continuous and reliable electricity delivery to consumers: capacity, the maximum amount the system can handle, and transmission, the infrastructure necessary to deliver electricity across the network. These capacity and transmission costs are then allocated to the end-users according to the cost causation principle. These charges are computed based on the customer demand on coincident peak (CP) events, time intervals when the system-wide electric load is highest. We tackle the problem of predicting CP events based on actual load and forecast data on the load of different jurisdictions. In particular, we identify two main use cases depending on the availability of a forecast. Our approach generates scenarios and formulates Monte-Carlo estimators for predicting CP-day and exact CP-hour events. Finally, we backtest the prediction performance of strategies with adaptive threshold for the prediction task. This analysis enables us to derive practical implications for load curtailment through Battery Energy Storage System (BESS) solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04081v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Rene Carmona, Xinshuo Yang, Claire Zeng</dc:creator>
    </item>
    <item>
      <title>A General Maximum Principle for Progressive Optimal Control of Fully Coupled Forward-Backward Stochastic Systems with Jumps</title>
      <link>https://arxiv.org/abs/2407.04201</link>
      <description>arXiv:2407.04201v1 Announce Type: new 
Abstract: This paper is concerned with a general maximum principle for the fully coupled forward-backward stochastic optimal control problem with jumps, where the control domain is not necessarily convex, within the progressively measurable framework. It is worth noting that not only the control variable enters into all the coefficients, but also the jump size "$e$" . We first proposed that the solution $Z$ of BSDEP also contains the variable "$e$", which is different from previous articles and we provide an explanation in Remark 2.1.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04201v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Bin Wang, Yu Si, Jingtao Shi</dc:creator>
    </item>
    <item>
      <title>Novel Optimization Techniques for Parameter Estimation</title>
      <link>https://arxiv.org/abs/2407.04235</link>
      <description>arXiv:2407.04235v1 Announce Type: new 
Abstract: In this paper, we introduce a new optimization algorithm that is well suited for solving parameter estimation problems. We call our new method cubic regularized Newton with affine scaling (CRNAS). In contrast to so-called first-order methods which rely solely on the gradient of the objective function, our method utilizes the Hessian of the objective. As a result it is able to focus on points satisfying the second-order optimality conditions, as opposed to first-order methods that simply converge to critical points. This is an important feature in parameter estimation problems where the objective function is often non-convex and as a result there can be many critical points making it is near impossible to identify the global minimum. An important feature of parameter estimation in mathematical models of biological systems is that the parameters are constrained by either physical constraints or prior knowledge. We use an affine scaling approach to handle a wide class of constraints. We establish that CRNAS identifies a point satisfying $\epsilon$-approximate second-order optimality conditions within $O(\epsilon^{-3/2})$ iterations. Finally, we compare CRNAS with MATLAB's optimization solver fmincon on three different test problems. These test problems all feature mixtures of heterogeneous populations, a problem setting that CRNAS is particularly well-suited for. Our numerical simulations show CRNAS has favorable performance, performing comparable if not better than fmincon in accuracy and computational cost for most of our examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04235v1</guid>
      <category>math.OC</category>
      <category>q-bio.QM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chenyu Wu, Nuozhou Wang, Casey Garner, Kevin Leder, Shuzhong Zhang</dc:creator>
    </item>
    <item>
      <title>Robust Q-Learning for finite ambiguity sets</title>
      <link>https://arxiv.org/abs/2407.04259</link>
      <description>arXiv:2407.04259v1 Announce Type: new 
Abstract: In this paper we propose a novel $Q$-learning algorithm allowing to solve distributionally robust Markov decision problems for which the ambiguity set of probability measures can be chosen arbitrarily as long as it comprises only a finite amount of measures. Therefore, our approach goes beyond the well-studied cases involving ambiguity sets of balls around some reference measure with the distance to reference measure being measured with respect to the Wasserstein distance or the Kullback--Leibler divergence. Hence, our approach allows the applicant to create ambiguity sets better tailored to her needs and to solve the associated robust Markov decision problem via a $Q$-learning algorithm whose convergence is guaranteed by our main result. Moreover, we showcase in several numerical experiments the tractability of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04259v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>C\'ecile Decker, Julian Sester</dc:creator>
    </item>
    <item>
      <title>Flat sub-Lorentzian structures on Martinet distribution</title>
      <link>https://arxiv.org/abs/2407.04341</link>
      <description>arXiv:2407.04341v1 Announce Type: new 
Abstract: Two flat sub-Lorentzian problems on the Martinet distribution are studied. For the first one, the attainable set has a nontrivial intersection with the Martinet plane, but for the second one it does not. Attainable sets, optimal trajectories, sub-Lorentzian distances and spheres are described.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04341v1</guid>
      <category>math.OC</category>
      <category>math.DG</category>
      <category>math.MG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yu. L. Sachkov</dc:creator>
    </item>
    <item>
      <title>An Adaptive Stochastic Gradient Method with Non-negative Gauss-Newton Stepsizes</title>
      <link>https://arxiv.org/abs/2407.04358</link>
      <description>arXiv:2407.04358v1 Announce Type: new 
Abstract: We consider the problem of minimizing the average of a large number of smooth but possibly non-convex functions. In the context of most machine learning applications, each loss function is non-negative and thus can be expressed as the composition of a square and its real-valued square root. This reformulation allows us to apply the Gauss-Newton method, or the Levenberg-Marquardt method when adding a quadratic regularization. The resulting algorithm, while being computationally as efficient as the vanilla stochastic gradient method, is highly adaptive and can automatically warmup and decay the effective stepsize while tracking the non-negative loss landscape. We provide a tight convergence analysis, leveraging new techniques, in the stochastic convex and non-convex settings. In particular, in the convex case, the method does not require access to the gradient Lipshitz constant for convergence, and is guaranteed to never diverge. The convergence rates and empirical evaluations compare favorably to the classical (stochastic) gradient method as well as to several other adaptive methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04358v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Antonio Orvieto, Lin Xiao</dc:creator>
    </item>
    <item>
      <title>A Tunneling Method for Nonlinear Multi-objective Optimization Problems</title>
      <link>https://arxiv.org/abs/2407.04436</link>
      <description>arXiv:2407.04436v1 Announce Type: new 
Abstract: In this paper, a tunneling method is developed for nonlinear multi-objective optimization problems. The proposed method is free from any kind of priori chosen parameter or ordering information of objective functions. Using this method, global Pareto front can be generated for non-convex problems with more than one local front. An algorithm is developed using some ideas of single objective tunneling method. Convergence of this algorithm is justified under some mild assumptions. In addition to this, some numerical examples are included to justify the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04436v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bikram Adhikary, Md Abu Talhamainuddin Ansary</dc:creator>
    </item>
    <item>
      <title>Unified continuous-time q-learning for mean-field game and mean-field control problems</title>
      <link>https://arxiv.org/abs/2407.04521</link>
      <description>arXiv:2407.04521v1 Announce Type: new 
Abstract: This paper studies the continuous-time q-learning in the mean-field jump-diffusion models from the representative agent's perspective. To overcome the challenge when the population distribution may not be directly observable, we introduce the integrated q-function in decoupled form (decoupled Iq-function) and establish its martingale characterization together with the value function, which provides a unified policy evaluation rule for both mean-field game (MFG) and mean-field control (MFC) problems. Moreover, depending on the task to solve the MFG or MFC problem, we can employ the decoupled Iq-function by different means to learn the mean-field equilibrium policy or the mean-field optimal policy respectively. As a result, we devise a unified q-learning algorithm for both MFG and MFC problems by utilizing all test policies stemming from the mean-field interactions. For several examples in the jump-diffusion setting, within and beyond the LQ framework, we can obtain the exact parameterization of the decoupled Iq-functions and the value functions, and illustrate our algorithm from the representative agent's perspective with satisfactory performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04521v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>q-fin.CP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaoli Wei, Xiang Yu, Fengyi Yuan</dc:creator>
    </item>
    <item>
      <title>An SDE Perspective on Stochastic Inertial Gradient Dynamics with Time-Dependent Viscosity and Geometric Damping</title>
      <link>https://arxiv.org/abs/2407.04562</link>
      <description>arXiv:2407.04562v1 Announce Type: new 
Abstract: Our approach is part of the close link between continuous dissipative dynamical systems and optimization algorithms. We aim to solve convex minimization problems by means of stochastic inertial differential equations which are driven by the gradient of the objective function. This will provide a general mathematical framework for analyzing fast optimization algorithms with stochastic gradient input. Our study is a natural extension of our previous work devoted to the first-order in time stochastic steepest descent. Our goal is to develop these results further by considering second-order stochastic differential equations in time, incorporating a viscous time-dependent damping and a Hessian-driven damping. To develop this program, we rely on stochastic Lyapunov analysis. Assuming a square-integrability condition on the diffusion term times a function dependant on the viscous damping, and that the Hessian-driven damping is a positive constant, our first main result shows that almost surely, there is convergence of the values, and states fast convergence of the values in expectation. Besides, in the case where the Hessian-driven damping is zero, we conclude with the fast convergence of the values in expectation and in almost sure sense, we also managed to prove almost sure weak convergence of the trajectory. We provide a comprehensive complexity analysis by establishing several new pointwise and ergodic convergence rates in expectation for the convex and strongly convex case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04562v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rodrigo Maulen-Soto, Jalal Fadili, Hedy Attouch, Peter Ochs</dc:creator>
    </item>
    <item>
      <title>Multiple stage stochastic linear programming with multiple objectives: flexible decision making</title>
      <link>https://arxiv.org/abs/2407.04602</link>
      <description>arXiv:2407.04602v1 Announce Type: new 
Abstract: Optimization problems with random data have a wide range of applications. A typical feature of many such problems is that some variables have to be optimized before certain random coefficients have been realized and for other variables it is sufficient to decide on them afterwards. This leads to a multiple stage decision process. To optimize the variables in the first of two subsequent stages the stochastic problem is transformed into a deterministic program, called the (deterministic equivalent of the) recourse problem. In case of stochastic linear programs with finitely distributed random data this non-stochastic substitute is just a linear program. In the same way a multiple objective linear program is obtained if the original problem has multiple objective functions. In the first of the two stages, a decision maker usually would chose a feasible point out of the set of all Pareto-optimal points. This choice however has consequences to later stage decisions. We claim that the decision process in the earlier of the two stages is not fully transparent if a classical multi-objective decision process is applied: in addition to the original objectives of the problem a decision maker may have a preference for largest possible flexibility in later stage decisions. This additional objective is taken into account if the recourse problem in case of multiple objectives is taken to be a polyhedral convex set optimization problem instead of a multi-objective linear program only. We also discuss several surrogate problems to the recourse problem such as the wait-and-see problem and the expected valued problem for the multi-objective case. The new approach based on set optimization is illustrated by an example, the multi-objective newsvendor problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04602v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andreas H. Hamel, Andreas L\"ohne</dc:creator>
    </item>
    <item>
      <title>A Multi-Player Potential Game Approach for Sensor Network Localization with Noisy Measurements</title>
      <link>https://arxiv.org/abs/2407.04608</link>
      <description>arXiv:2407.04608v1 Announce Type: new 
Abstract: Sensor network localization (SNL) is a challenging problem due to its inherent non-convexity and the effects of noise in inter-node ranging measurements and anchor node position. We formulate a non-convex SNL problem as a multi-player non-convex potential game and investigate the existence and uniqueness of a Nash equilibrium (NE) in both the ideal setting without measurement noise and the practical setting with measurement noise. We first show that the NE exists and is unique in the noiseless case, and corresponds to the precise network localization. Then, we study the SNL for the case with errors affecting the anchor node position and the inter-node distance measurements. Specifically, we establish that in case these errors are sufficiently small, the NE exists and is unique. It is shown that the NE is an approximate solution to the SNL problem, and that the position errors can be quantified accordingly. Based on these findings, we apply the results to case studies involving only inter-node distance measurement errors and only anchor position information inaccuracies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04608v1</guid>
      <category>math.OC</category>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gehui Xu, Guanpu Chen, Baris Fidan, Yiguang Hong, Hongsheng Qi, Thomas Parisini, Karl H. Johansson</dc:creator>
    </item>
    <item>
      <title>(Two-scale) $W^{1}L^{\Phi}$-gradient Young measures and homogenization of integral functionals in Orlicz-Sobolev spaces</title>
      <link>https://arxiv.org/abs/2407.03359</link>
      <description>arXiv:2407.03359v1 Announce Type: cross 
Abstract: (Two-scale) gradient Young measures in Orlicz-Sobolev setting are introduced and characterized providing also an integral representation formula for non convex energies arising in homogenization problems with nonstandard growth.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03359v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Joel Fotso Tachago, Hubert Nnang, Franck Tchinda, Elvira Zappale</dc:creator>
    </item>
    <item>
      <title>Decomposition of Difficulties in Complex Optimization Problems Using a Bilevel Approach</title>
      <link>https://arxiv.org/abs/2407.03454</link>
      <description>arXiv:2407.03454v1 Announce Type: cross 
Abstract: Practical optimization problems may contain different kinds of difficulties that are often not tractable if one relies on a particular optimization method. Different optimization approaches offer different strengths that are good at tackling one or more difficulty in an optimization problem. For instance, evolutionary algorithms have a niche in handling complexities like discontinuity, non-differentiability, discreteness and non-convexity. However, evolutionary algorithms may get computationally expensive for mathematically well behaved problems with large number of variables for which classical mathematical programming approaches are better suited. In this paper, we demonstrate a decomposition strategy that allows us to synergistically apply two complementary approaches at the same time on a complex optimization problem. Evolutionary algorithms are useful in this context as their flexibility makes pairing with other solution approaches easy. The decomposition idea is a special case of bilevel optimization that separates the difficulties into two levels and assigns different approaches at each level that is better equipped at handling them. We demonstrate the benefits of the proposed decomposition idea on a wide range of test problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03454v1</guid>
      <category>cs.NE</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ankur Sinha, Dhaval Pujara, Hemant Kumar Singh</dc:creator>
    </item>
    <item>
      <title>A Bistatic Sensing System in Space-Air-Ground Integrated Networks</title>
      <link>https://arxiv.org/abs/2407.03628</link>
      <description>arXiv:2407.03628v1 Announce Type: cross 
Abstract: Sensing is anticipated to have wider extensions in communication systems with the boom of non-terrestrial networks (NTNs) during the past years. In this paper, we study a bistatic sensing system by maximizing the signal-to-interference-plus-noise ration (SINR) from the target aircraft in the space-air-ground integrated network (SAGIN). We formulate a joint optimization problem for the transmit beamforming of low-earth orbit (LEO) satellite and the receive filtering of ground base station. To tackle this problem, we decompose the original problem into two sub-problems and use the alternating optimization to solve them iteratively. Using techniques of fractional programming and generalized Rayleigh quotient, the closed-form solution for each sub-problem is returned. Simulation results show that the proposed algorithm has good convergence performance.Moreover, the optimization of receive filtering dominates the optimality, especially when the satellite altitude becomes higher, which provides valuable network design insights.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03628v1</guid>
      <category>eess.SP</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiangyu Li, Bodong Shang, Qingqing Wu</dc:creator>
    </item>
    <item>
      <title>Forward Reachability for Discrete-Time Nonlinear Stochastic Systems via Mixed-Monotonicity and Stochastic Order</title>
      <link>https://arxiv.org/abs/2407.03984</link>
      <description>arXiv:2407.03984v1 Announce Type: cross 
Abstract: We present a method to overapproximate forward stochastic reach sets of discrete-time, stochastic nonlinear systems with interval geometry. This is made possible by extending the theory of mixed-monotone systems to incorporate stochastic orders, and a concentration inequality result that lower-bounds the probability the state resides within an interval through a monotone mapping. Then, we present an algorithm to compute the overapproximations of forward reachable set and the probability the state resides within it. We present our approach on two aerospace examples to show its efficacy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03984v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vignesh Sivaramakrishnan, Rosalyn A. Devonport, Murat Arcak, Meeko M. K. Oishi</dc:creator>
    </item>
    <item>
      <title>Subinvariant metric functionals for nonexpansive mappings</title>
      <link>https://arxiv.org/abs/2407.04234</link>
      <description>arXiv:2407.04234v1 Announce Type: cross 
Abstract: We investigate the existence of subinvariant metric functionals for commuting families of nonexpansive mappings in noncompact subsets of Banach spaces. Our findings underscore the practicality of metric functionals when searching for fixed points of nonexpansive mappings. To demonstrate this, we additionally investigate subsets of Banach spaces that have only nontrivial metric functionals. We particularly show that in certain cases every metric functional has a unique minimizer; thus, subinvariance implies the existence of a fixed point.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04234v1</guid>
      <category>math.FA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Armando W. Guti\'errez, Olavi Nevanlinna</dc:creator>
    </item>
    <item>
      <title>Langevin Dynamics: A Unified Perspective on Optimization via Lyapunov Potentials</title>
      <link>https://arxiv.org/abs/2407.04264</link>
      <description>arXiv:2407.04264v1 Announce Type: cross 
Abstract: We study the problem of non-convex optimization using Stochastic Gradient Langevin Dynamics (SGLD). SGLD is a natural and popular variation of stochastic gradient descent where at each step, appropriately scaled Gaussian noise is added. To our knowledge, the only strategy for showing global convergence of SGLD on the loss function is to show that SGLD can sample from a stationary distribution which assigns larger mass when the function is small (the Gibbs measure), and then to convert these guarantees to optimization results.
  We employ a new strategy to analyze the convergence of SGLD to global minima, based on Lyapunov potentials and optimization. We convert the same mild conditions from previous works on SGLD into geometric properties based on Lyapunov potentials. This adapts well to the case with a stochastic gradient oracle, which is natural for machine learning applications where one wants to minimize population loss but only has access to stochastic gradients via minibatch training samples. Here we provide 1) improved rates in the setting of previous works studying SGLD for optimization, 2) the first finite gradient complexity guarantee for SGLD where the function is Lipschitz and the Gibbs measure defined by the function satisfies a Poincar\'e Inequality, and 3) prove if continuous-time Langevin Dynamics succeeds for optimization, then discrete-time SGLD succeeds under mild regularity assumptions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04264v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>August Y. Chen, Ayush Sekhari, Karthik Sridharan</dc:creator>
    </item>
    <item>
      <title>Indirect stabilization of semilinear coupled wave systems</title>
      <link>https://arxiv.org/abs/2407.04309</link>
      <description>arXiv:2407.04309v1 Announce Type: cross 
Abstract: In this paper, we study the indirect stabilization problem for a system of two coupled semilinear wave equations with internal damping in a bounded domain in $\mathbb{R}^3$. The nonlinearity is assumed to be subcritical, defocusing and analytic. Under geometric control condition on both coupling and damping regions, we establish the exponential energy decay rate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04309v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Radhia Ayechi (LJLL, CNRS), Moez Khenissi (LJLL, CNRS), Camille Laurent (LJLL, CNRS)</dc:creator>
    </item>
    <item>
      <title>Nash epidemics</title>
      <link>https://arxiv.org/abs/2407.04366</link>
      <description>arXiv:2407.04366v1 Announce Type: cross 
Abstract: Faced with a dangerous epidemic humans will spontaneously social distance to reduce their risk of infection at a socio-economic cost. Compartmentalised epidemic models have been extended to include this endogenous decision making: Individuals choose their behaviour to optimise a utility function, self-consistently giving rise to population behaviour. Here we study the properties of the resulting Nash equilibria, in which no member of the population can gain an advantage by unilaterally adopting different behaviour. We leverage a new analytic solution to obtain, (1) a simple relationship between rational social distancing behaviour and the current number of infections; (2) new scaling results for how the infection peak and number of total cases depend on the cost of contracting the disease; (3) characteristic infection costs that divide regimes of strong and weak behavioural response and depend only on the basic reproduction number of the disease; (4) a closed form expression for the value of the utility. We discuss how these analytic results provide a deep and intuitive understanding into the disease dynamics, useful for both individuals and policymakers. In particular the relationship between social distancing and infections represents a heuristic that could be communicated to the population to encourage, or "bootstrap", rational behaviour.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04366v1</guid>
      <category>econ.TH</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <category>physics.soc-ph</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Simon K. Schnyder, John J. Molina, Ryoichi Yamamoto, Matthew S. Turner</dc:creator>
    </item>
    <item>
      <title>LoCo: Low-Bit Communication Adaptor for Large-scale Model Training</title>
      <link>https://arxiv.org/abs/2407.04480</link>
      <description>arXiv:2407.04480v1 Announce Type: cross 
Abstract: To efficiently train large-scale models, low-bit gradient communication compresses full-precision gradients on local GPU nodes into low-precision ones for higher gradient synchronization efficiency among GPU nodes. However, it often degrades training quality due to compression information loss. To address this, we propose the Low-bit Communication Adaptor (LoCo), which compensates gradients on local GPU nodes before compression, ensuring efficient synchronization without compromising training quality. Specifically, LoCo designs a moving average of historical compensation errors to stably estimate concurrent compression error and then adopts it to compensate for the concurrent gradient compression, yielding a less lossless compression. This mechanism allows it to be compatible with general optimizers like Adam and sharding strategies like FSDP. Theoretical analysis shows that integrating LoCo into full-precision optimizers like Adam and SGD does not impair their convergence speed on nonconvex problems. Experimental results show that across large-scale model training frameworks like Megatron-LM and PyTorch's FSDP, LoCo significantly improves communication efficiency, e.g., improving Adam's training speed by 14% to 40% without performance degradation on large language models like LLAMAs and MoE.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04480v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xingyu Xie, Zhijie Lin, Kim-Chuan Toh, Pan Zhou</dc:creator>
    </item>
    <item>
      <title>Proximal Point Method for Online Saddle Point Problem</title>
      <link>https://arxiv.org/abs/2407.04591</link>
      <description>arXiv:2407.04591v1 Announce Type: cross 
Abstract: This paper focuses on the online saddle point problem, which involves a sequence of two-player time-varying convex-concave games. Considering the nonstationarity of the environment, we adopt the duality gap and the dynamic Nash equilibrium regret as performance metrics for algorithm design. We present three variants of the proximal point method: the Online Proximal Point Method~(OPPM), the Optimistic OPPM~(OptOPPM), and the OptOPPM with multiple predictors. Each algorithm guarantees upper bounds for both the duality gap and dynamic Nash equilibrium regret, achieving near-optimality when measured against the duality gap. Specifically, in certain benign environments, such as sequences of stationary payoff functions, these algorithms maintain a nearly constant metric bound. Experimental results further validate the effectiveness of these algorithms. Lastly, this paper discusses potential reliability concerns associated with using dynamic Nash equilibrium regret as a performance metric.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04591v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qing-xin Meng, Jian-wei Liu</dc:creator>
    </item>
    <item>
      <title>Asymptotic flocking for the Cucker-Smale model with time variable time delays</title>
      <link>https://arxiv.org/abs/2206.11770</link>
      <description>arXiv:2206.11770v2 Announce Type: replace 
Abstract: In this paper, we investigate a Cucker-Smale flocking model with varying time delay. We establish exponential asymptotic flocking without requiring smallness assumptions on the time delay size and the monotonicity of the influence function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2206.11770v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/s10440-023-00625-y</arxiv:DOI>
      <dc:creator>Elisa Continelli</dc:creator>
    </item>
    <item>
      <title>Learning Decentralized Linear Quadratic Regulators with $\sqrt{T}$ Regret</title>
      <link>https://arxiv.org/abs/2210.08886</link>
      <description>arXiv:2210.08886v4 Announce Type: replace 
Abstract: We propose an online learning algorithm that adaptively designs a decentralized linear quadratic regulator when the system model is unknown a priori and new data samples from a single system trajectory become progressively available. The algorithm uses a disturbance-feedback representation of state-feedback controllers coupled with online convex optimization with memory and delayed feedback. Under the assumption that the system is stable or given a known stabilizing controller, we show that our controller enjoys an expected regret that scales as $\sqrt{T}$ with the time horizon $T$ for the case of partially nested information pattern. For more general information patterns, the optimal controller is unknown even if the system model is known. In this case, the regret of our controller is shown with respect to a linear sub-optimal controller. We validate our theoretical findings using numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.08886v4</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lintao Ye, Ming Chi, Ruiquan Liao, Vijay Gupta</dc:creator>
    </item>
    <item>
      <title>Smoothed Moreau-Yosida Tensor Train Approximation of State-constrained Optimization Problems under Uncertainty</title>
      <link>https://arxiv.org/abs/2301.08684</link>
      <description>arXiv:2301.08684v2 Announce Type: replace 
Abstract: We propose an algorithm to solve optimization problems constrained by partial (ordinary) differential equations under uncertainty, with almost sure constraints on the state variable. To alleviate the computational burden of high-dimensional random variables, we approximate all random fields by the tensor-train decomposition. To enable efficient tensor-train approximation of the state constraints, the latter are handled using the Moreau-Yosida penalty, with an additional smoothing of the positive part (plus/ReLU) function by a softplus function. In a special case of a quadratic cost minimization constrained by linear elliptic partial differential equations, and some additional constraint qualification, we prove strong convergence of the regularized solution to the optimal control. This result also proposes a practical recipe for selecting the smoothing parameter as a function of the penalty parameter. We develop a second order Newton type method with a fast matrix-free action of the approximate Hessian to solve the smoothed Moreau-Yosida problem. This algorithm is tested on benchmark elliptic problems with random coefficients, optimization problems constrained by random elliptic variational inequalities, and a real-world epidemiological model with 20 random variables. These examples demonstrate mild (at most polynomial) scaling with respect to the dimension and regularization parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.08684v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Harbir Antil, Sergey Dolgov, Akwum Onwunta</dc:creator>
    </item>
    <item>
      <title>Proximity Operators of Perspective Functions with Nonlinear Scaling</title>
      <link>https://arxiv.org/abs/2303.05337</link>
      <description>arXiv:2303.05337v3 Announce Type: replace 
Abstract: A perspective function is a construction which combines a base function defined on a given space with a nonlinear scaling function defined on another space and which yields a lower semicontinuous convex function on the product space. Since perspective functions are typically nonsmooth, their use in first-order algorithms necessitates the computation of their proximity operator. This paper establishes closed-form expressions for the proximity operator of a perspective function defined on a Hilbert space in terms of a proximity operator involving its base function and one involving its scaling function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.05337v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luis M. Brice\~no-Arias, Patrick L. Combettes, Francisco J. Silva</dc:creator>
    </item>
    <item>
      <title>Solving decision problems with endogenous uncertainty and conditional information revelation using influence diagrams</title>
      <link>https://arxiv.org/abs/2304.02338</link>
      <description>arXiv:2304.02338v3 Announce Type: replace 
Abstract: Despite methodological advances for modeling decision problems under uncertainty, representing endogenous uncertainty still proves challenging both in terms of modeling capabilities and computational requirements. A novel reformulation based on rooted junction trees (RJTs) provides an approach for solving such decision problems using off-the-shelf mathematical optimization solvers. This is made possible by using an influence diagram to represent a given decision problem and reformulating it as an RJT, which is then represented as a mixed-integer linear programming model. In this paper, we focus on the type of endogenous uncertainty that received less attention in the rooted junction tree approach: conditionally observed information. Multi-stage stochastic programming models use conditional non-anticipativity constraints to represent such uncertainties, and we show how such constraints can be incorporated into RJT formulations. This allows us to consider the two main types of endogenous uncertainty simultaneously, namely decision-dependent information structure and decision-dependent probability distribution. Finally, the extended framework is illustrated with a large-scale cost-benefit problem regarding climate change mitigation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.02338v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Olli Herrala, Tommi Ekholm, Fabricio Oliveira</dc:creator>
    </item>
    <item>
      <title>An extended Merton problem with relaxed benchmark tracking</title>
      <link>https://arxiv.org/abs/2304.10802</link>
      <description>arXiv:2304.10802v3 Announce Type: replace 
Abstract: This paper studies a Merton's optimal consumption problem in an extended formulation incorporating the tracking of a benchmark process described by a geometric Brownian motion. We consider a relaxed tracking formulation such that the wealth process compensated by a fictitious capital injection outperforms the benchmark at all times. The fund manager aims to maximize the expected utility of consumption deducted by the cost of the capital injection, where the latter term can also be regarded as the expected largest shortfall of the wealth with reference to the benchmark. By introducing an auxiliary state process with reflection, we formulate and tackle an equivalent stochastic control problem by means of the dual transform and probabilistic representation, where the dual PDE can be solved explicitly. On the strength of the closed-form results, we can derive and verify the optimal feedback control for the primal control problem, allowing us to discuss some new and interesting financial implications induced by the additional risk-taking from the capital injection and the goal of tracking.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.10802v3</guid>
      <category>math.OC</category>
      <category>q-fin.PM</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lijun Bo, Yijie Huang, Xiang Yu</dc:creator>
    </item>
    <item>
      <title>On the Viability and Invariance of Proper Sets under Continuity Inclusions in Wasserstein Spaces</title>
      <link>https://arxiv.org/abs/2304.11945</link>
      <description>arXiv:2304.11945v3 Announce Type: replace 
Abstract: In this article, we derive conditions for the existence of solutions to state-constrained continuity inclusions in Wasserstein spaces whose right-hand sides may be discontinuous in time. These latter are based on a fine investigation of the infinitesimal behaviour of the underlying reachable sets, through which we show that up to a negligible set of times, every admissible velocity of a continuity inclusion can be approximately realised as the metric derivative of a solution of the dynamics, and vice versa. Building on these results, we are able to establish necessary and sufficient geometric conditions for the viability and invariance of stationary and time-dependent constraint sets which involve a suitable notion of contingent cones in Wasserstein spaces, and presented in ascending order of generality. We then close the article by exhibiting two prototypical examples of constraints sets appearing in applications for which one can compute relevant subfamilies of contingent directions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.11945v3</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>SIAM Journal on Mathematical Analysis 56 (3), 2863-2914 (2024)</arxiv:journal_reference>
      <dc:creator>Beno\^it Bonnet-Weill, H\'el\`ene Frankowska</dc:creator>
    </item>
    <item>
      <title>A Theory of the NEPv Approach for Optimization On the Stiefel Manifold</title>
      <link>https://arxiv.org/abs/2305.00091</link>
      <description>arXiv:2305.00091v3 Announce Type: replace 
Abstract: The NEPv approach has been increasingly used lately for optimization on the Stiefel manifold arising from machine learning. General speaking, the approach first turns the first order optimality condition, also known as the KKT condition, into a nonlinear eigenvalue problem with eigenvector dependency (NEPv) or a nonlinear polar decomposition with orthogonal factor dependency (NPDo) and then solve the nonlinear problem via some variations of the self-consistent-field (SCF) iteration. The difficulty, however, lies in designing a proper SCF iteration so that a maximizer is found at the end. Currently, each use of the approach is very much individualized, especially in its convergence analysis to show that the approach does work or otherwise. In this paper, a unifying framework is established. The framework is built upon some basic assumptions. If the basic assumptions are satisfied, globally convergence is guaranteed to a stationary point and during the SCF iterative process that leads to the stationary point, the objective function increases monotonically. Also a notion of atomic functions is proposed, which include commonly used matrix traces of linear and quadratic forms as special ones. It is shown that the basic assumptions are satisfied by atomic functions and by convex compositions of atomic functions. Together they provide a large collection of objectives for which the NEPv/NPDo approach is guaranteed to work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.00091v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ren-Cang Li</dc:creator>
    </item>
    <item>
      <title>Learning Decision-Focused Uncertainty Sets in Robust Optimization</title>
      <link>https://arxiv.org/abs/2305.19225</link>
      <description>arXiv:2305.19225v4 Announce Type: replace 
Abstract: We propose a data-driven technique to automatically learn the uncertainty sets in robust optimization. Our method reshapes the uncertainty sets by minimizing the expected performance across a family of problems subject to guaranteeing constraint satisfaction. Our approach is very flexible and can learn a wide variety of uncertainty sets while preserving tractability. We solve the constrained learning problem using a stochastic augmented Lagrangian method that relies on differentiating the solutions of the robust optimization problems with respect to the parameters of the uncertainty set. Due to the nonsmooth and nonconvex nature of the augmented Lagrangian function, we apply the nonsmooth conservative implicit function theorem to establish convergence to a critical point, which is a feasible solution of the constrained problem under mild assumptions. Using empirical process theory, we show finite-sample probabilistic guarantees of constraint satisfaction for the resulting solutions. Numerical experiments show that our method outperforms traditional approaches in robust and distributionally robust optimization in terms of out-of-sample performance and constraint satisfaction guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.19225v4</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Irina Wang, Cole Becker, Bart Van Parys, Bartolomeo Stellato</dc:creator>
    </item>
    <item>
      <title>Revisiting $L_q(0\leq q&lt;1)$ Norm Regularized Optimization</title>
      <link>https://arxiv.org/abs/2306.14394</link>
      <description>arXiv:2306.14394v5 Announce Type: replace 
Abstract: Sparse optimization has seen its advances in recent decades. For scenarios where the true sparsity is unknown, regularization turns out to be a promising solution. Two popular non-convex regularizations are the so-called $L_0$ norm and $L_q$ norm with $q\in(0,1)$, giving rise to extensive research on their induced optimization. However, the majority of these work centered around the main function that is twice continuously differentiable and the best convergence rate for an algorithm solving the optimization with $q\in(0,1)$ is superlinear. This paper explores the $L_q$ norm regularized optimization in a unified way for any $q\in[0,1)$, where the main function has a semismooth gradient. In particular, we establish the first-order and the second-order optimality conditions under mild assumptions and then integrate the proximal operator and semismooth Newton method to develop a proximal semismooth Newton pursuit algorithm. Under the second sufficient condition, the whole sequence generated by the algorithm converges to a unique local minimizer. Moreover, the convergence is superlinear and quadratic if the gradient of the main function is semismooth and strongly semismooth at the local minimizer, respectively. Hence, this paper accomplishes the quadratic rate for an algorithm designed to solve the $L_q$ norm regularization problem for any $q\in(0,1)$. Finally, some numerical experiments have showcased its nice performance when compared with several existing solvers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.14394v5</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shenglong Zhou, Xianchao Xiu, Yingnan Wang, Dingtao Peng</dc:creator>
    </item>
    <item>
      <title>The Error in Multivariate Linear Extrapolation with Applications to Derivative-Free Optimization</title>
      <link>https://arxiv.org/abs/2307.00358</link>
      <description>arXiv:2307.00358v2 Announce Type: replace 
Abstract: We study in this paper the function approximation error of multivariate linear extrapolation. While the sharp error bound of linear interpolation already exists in the literature, linear extrapolation is used far more often in applications such as derivative-free optimization, and its error is not well-studied. A method to numerically compute the sharp error bound is introduced, and several analytical bounds are presented along with the conditions under which they are sharp. The approximation error achievable by quadratic functions and the error bound for the bivariate case are analyzed in depth. Additionally, we provide the convergence theories regarding the simplex derivative-free optimization method as a demonstration of the utility of the derived bounds. All results are under the assumptions that the function being interpolated has Lipschitz continuous gradient and is interpolated on an affinely independent sample set.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.00358v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Liyuan Cao, Zaiwen Wen, Ya-xiang Yuan</dc:creator>
    </item>
    <item>
      <title>Logistics Hub Location Optimization: A K-Means and P-Median Model Hybrid Approach Using Road Network Distances</title>
      <link>https://arxiv.org/abs/2308.11038</link>
      <description>arXiv:2308.11038v3 Announce Type: replace 
Abstract: Logistic hubs play a pivotal role in the last-mile delivery distance; even a slight increment in distance negatively impacts the business of the e-commerce industry while also increasing its carbon footprint. The growth of this industry, particularly after Covid-19, has further intensified the need for optimized allocation of resources in an urban environment. In this study, we use a hybrid approach to optimize the placement of logistic hubs. The approach sequentially employs different techniques. Initially, delivery points are clustered using K-Means in relation to their spatial locations. The clustering method utilizes road network distances as opposed to Euclidean distances. Non-road network-based approaches have been avoided since they lead to erroneous and misleading results. Finally, hubs are located using the P-Median method. The P-Median method also incorporates the number of deliveries and population as weights. Real-world delivery data from Muller and Phipps (M&amp;P) is used to demonstrate the effectiveness of the approach. Serving deliveries from the optimal hub locations results in the saving of 815 (10%) meters per delivery.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.11038v3</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Muhammad Abdul Rahman, Muhammad Aamir Basheer, Zubair Khalid, Muhammad Tahir, Momin Uppal</dc:creator>
    </item>
    <item>
      <title>Finite convergence of Moment-SOS relaxations with non-real radical ideals</title>
      <link>https://arxiv.org/abs/2309.15398</link>
      <description>arXiv:2309.15398v2 Announce Type: replace 
Abstract: We consider the linear conic optimization problem with the cone of nonnegative polynomials. Its dual optimization problem is the generalized moment problem. Moment-SOS relaxations are powerful for solving them. This paper studies finite convergence of the Moment-SOS hierarchy when the constraining set is defined by equations whose ideal may not be real radical. Under the archimedeanness, we show that the Moment-SOS hierarchy has finite convergence if some classical optimality conditions hold at every minimizer of the optimal nonnegative polynomial for the linear conic optimization problem. When the archimedeanness fails (this is the case for unbounded sets), we propose a homogenized Moment-SOS hierarchy and prove its finite convergence under similar assumptions. Furthermore, we also prove the finite convergence of the Moment-SOS hierarchy with denominators. In particular, this paper resolves a conjecture posed in the earlier work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.15398v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lei Huang, Jiawang Nie, Ya-Xiang Yuan</dc:creator>
    </item>
    <item>
      <title>A Projection-Free Method for Solving Convex Bilevel Optimization Problems</title>
      <link>https://arxiv.org/abs/2311.09738</link>
      <description>arXiv:2311.09738v3 Announce Type: replace 
Abstract: When faced with multiple minima of an "inner-level" convex optimization problem, the convex bilevel optimization problem selects an optimal solution which also minimizes an auxiliary "outer-level" convex objective of interest. Bilevel optimization requires a different approach compared to single-level optimization problems since the set of minimizers for the inner-level objective is not given explicitly. In this paper, we propose a new projection-free method for convex bilevel optimization which require only a linear optimization oracle over the base domain. We establish $O(t^{-1/2})$ convergence rate guarantees for our method in terms of both inner- and outer-level objectives, and demonstrate how additional assumptions such as quadratic growth and strong convexity result in accelerated rates of up to $O(t^{-1})$ and $O(t^{-2/3})$ for inner- and outer-levels respectively. Lastly, we conduct a numerical study to demonstrate the performance of our method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.09738v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Khanh-Hung Giang-Tran, Nam Ho-Nguyen, Dabeen Lee</dc:creator>
    </item>
    <item>
      <title>Online estimation of the inverse of the Hessian for stochastic optimization with application to universal stochastic Newton algorithms</title>
      <link>https://arxiv.org/abs/2401.10923</link>
      <description>arXiv:2401.10923v2 Announce Type: replace 
Abstract: This paper addresses second-order stochastic optimization for estimating the minimizer of a convex function written as an expectation. A direct recursive estimation technique for the inverse Hessian matrix using a Robbins-Monro procedure is introduced. This approach enables to drastically reduces computational complexity. Above all, it allows to develop universal stochastic Newton methods and investigate the asymptotic efficiency of the proposed approach. This work so expands the application scope of secondorder algorithms in stochastic optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.10923v2</guid>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Antoine Godichon-Baggioni (LPSM), Wei Lu (LMI), Bruno Portier (LMI)</dc:creator>
    </item>
    <item>
      <title>Adaptive proximal gradient methods are universal without approximation</title>
      <link>https://arxiv.org/abs/2402.06271</link>
      <description>arXiv:2402.06271v2 Announce Type: replace 
Abstract: We show that adaptive proximal gradient methods for convex problems are not restricted to traditional Lipschitzian assumptions. Our analysis reveals that a class of linesearch-free methods is still convergent under mere local H\"older gradient continuity, covering in particular continuously differentiable semi-algebraic functions. To mitigate the lack of local Lipschitz continuity, popular approaches revolve around $\varepsilon$-oracles and/or linesearch procedures. In contrast, we exploit plain H\"older inequalities not entailing any approximation, all while retaining the linesearch-free nature of adaptive schemes. Furthermore, we prove full sequence convergence without prior knowledge of local H\"older constants nor of the order of H\"older continuity. Numerical experiments make comparisons with baseline methods on diverse tasks from machine learning covering both the locally and the globally H\"older setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.06271v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Konstantinos A. Oikonomidis, Emanuel Laude, Puya Latafat, Andreas Themelis, Panagiotis Patrinos</dc:creator>
    </item>
    <item>
      <title>Advanced-Step Real-time Iterations with Four Levels -- New Error Bounds and Fast Implementation in acados</title>
      <link>https://arxiv.org/abs/2403.07101</link>
      <description>arXiv:2403.07101v2 Announce Type: replace 
Abstract: The Real-Time Iteration (RTI) is an online nonlinear model predictive control algorithm that performs a single Sequential Quadratic Programming (SQP) per sampling time. The algorithm is split into a preparation and a feedback phase, where the latter one performs as little computations as possible solving a single prepared quadratic program. To further improve the accuracy of this method, the Advanced-Step RTI (AS-RTI) performs additional Multi-Level Iterations (MLI) in the preparation phase, such as inexact or zero-order SQP iterations on a problem with a predicted state estimate. This paper extends and streamlines the existing local convergence analysis of AS-RTI, such as analyzing MLI of level A and B for the first time, and significantly simplifying the proofs for levels C and D. Moreover, this paper provides an efficient open-source implementation in acados, making it widely accessible to practitioners.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07101v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/LCSYS.2024.3412007</arxiv:DOI>
      <dc:creator>Jonathan Frey, Armin Nurkanovic, Moritz Diehl</dc:creator>
    </item>
    <item>
      <title>Fast Generation of Feasible Trajectories in Direct Optimal Control</title>
      <link>https://arxiv.org/abs/2403.10115</link>
      <description>arXiv:2403.10115v2 Announce Type: replace 
Abstract: This paper examines the question of finding feasible points to discrete-time optimal control problems. The optimization problem of finding a feasible trajectory is transcribed to an unconstrained optimal control problem. An efficient algorithm, called FP-DDP, is proposed that solves the resulting problem using Differential Dynamic Programming preserving feasibility with respect to the system dynamics in every iteration. Notably, FP-DDP admits global and rapid local convergence properties induced by a combination of a Levenberg-Marquardt method and an Armijo-type line search. The efficiency of FP-DDP is demonstrated against established methods such as Direct Multiple Shooting, Direct Single Shooting, and state-of-the-art solvers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.10115v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/LCSYS.2024.3409109</arxiv:DOI>
      <dc:creator>David Kiessling, Katrin Baumg\"artner, Jonathan Frey, Wilm Decr\'e, Jan Swevers, Moritz Diehl</dc:creator>
    </item>
    <item>
      <title>Pole Placement and Feedback Stabilization for Discrete Linear Ensemble Systems</title>
      <link>https://arxiv.org/abs/2403.19017</link>
      <description>arXiv:2403.19017v3 Announce Type: replace 
Abstract: We consider discrete ensembles of linear, scalar control systems with single-inputs. Assuming that all the individual systems are unstable, we investigate whether there exist linear feedback control laws that can asymptotically stabilize the ensemble system. We provide necessary/sufficient conditions for feasibility of pole placement in the left half plane and for feedback stabilizability of the ensemble systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.19017v3</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xudong Chen</dc:creator>
    </item>
    <item>
      <title>A New Optimization Model for Multiple-Control Toffoli Quantum Circuit Design</title>
      <link>https://arxiv.org/abs/2404.14384</link>
      <description>arXiv:2404.14384v2 Announce Type: replace 
Abstract: As quantum technology is advancing, the efficient design of quantum circuits has become an important area of research. This paper provides an introduction to the MCT quantum circuit design problem for reversible Boolean functions without assuming a prior background in quantum computing. While this is a well-studied problem, optimization models that minimize the true objective have only been explored recently. This paper introduces a new optimization model and symmetry-breaking constraints that improve solving time by up to two orders of magnitude compared to earlier work when a Constraint Programming solver is used. Experiments with up to seven qubits and using up to 15 quantum gates result in several new best-known circuits, obtained by any method, for well-known benchmarks. Finally, an extensive comparison with other approaches shows that optimization models may require more time but can provide superior circuits with optimality guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.14384v2</guid>
      <category>math.OC</category>
      <category>cs.ET</category>
      <category>quant-ph</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jihye Jung, Kevin Dalmeijer, Pascal Van Hentenryck</dc:creator>
    </item>
    <item>
      <title>Minimax problems for ensembles of affine-control systems</title>
      <link>https://arxiv.org/abs/2405.05782</link>
      <description>arXiv:2405.05782v3 Announce Type: replace 
Abstract: In this paper, we consider ensembles of affine-control systems in $\mathbb{R}^d$, and we study simultaneous optimal control problems related to the worst-case minimization. After proving that such problems admit solutions, denoting with $(\Theta^N)_N$ a sequence of compact sets that parametrize the ensembles of systems, we first show that the corresponding minimax optimal control problems are $\Gamma$-convergent whenever $(\Theta^N)_N$ has a limit with respect to the Hausdorff distance. Besides its independent interest, the previous result is crucial role for establishing the Pontryagin Maximum Principle (PMP) when the ensemble is parametrized by a set $\Theta$ consisting of infinitely many points. Namely, we first approximate $\Theta$ by finite and increasing-in-size sets $(\Theta^N)_N$ for which the PMP is known, and then we derive the PMP for the $\Gamma$-limiting problem. The same strategy can be pursued in applications, where we can reduce infinite ensembles to finite ones to compute the minimizers numerically. We bring as a numerical example the Schr\"odinger equation for a qubit with uncertain resonance frequency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.05782v3</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alessandro Scagliotti</dc:creator>
    </item>
    <item>
      <title>Approximate Controllability of Linear Fractional Impulsive Evolution Equations in Hilbert Spaces</title>
      <link>https://arxiv.org/abs/2406.15114</link>
      <description>arXiv:2406.15114v2 Announce Type: replace 
Abstract: In this paper, we investigate the approximate controllability of linear fractional impulsive evolution equations in Hilbert spaces. We provide a representation of solutions utilizing impulsive operators. Necessary and sufficient conditions for the approximate controllability of linear fractional impulsive evolution equations are established in terms of the impulsive resolvent operator. An example is presented to demonstrate the application of the obtained theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15114v2</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Javad A. Asadzade, Nazim I. Mahmudov</dc:creator>
    </item>
    <item>
      <title>Non-Myopic Multifidelity Bayesian Optimization</title>
      <link>https://arxiv.org/abs/2207.06325</link>
      <description>arXiv:2207.06325v3 Announce Type: replace-cross 
Abstract: Bayesian optimization is a popular framework for the optimization of black box functions. Multifidelity methods allows to accelerate Bayesian optimization by exploiting low-fidelity representations of expensive objective functions. Popular multifidelity Bayesian strategies rely on sampling policies that account for the immediate reward obtained evaluating the objective function at a specific input, precluding greater informative gains that might be obtained looking ahead more steps. This paper proposes a non-myopic multifidelity Bayesian framework to grasp the long-term reward from future steps of the optimization. Our computational strategy comes with a two-step lookahead multifidelity acquisition function that maximizes the cumulative reward obtained measuring the improvement in the solution over two steps ahead. We demonstrate that the proposed algorithm outperforms a standard multifidelity Bayesian framework on popular benchmark optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2207.06325v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.knosys.2024.111959</arxiv:DOI>
      <arxiv:journal_reference>Knowledge-Based Systems 299 (2024): 111959</arxiv:journal_reference>
      <dc:creator>Francesco Di Fiore, Laura Mainini</dc:creator>
    </item>
    <item>
      <title>Optimal transport and Wasserstein distances for causal models</title>
      <link>https://arxiv.org/abs/2303.14085</link>
      <description>arXiv:2303.14085v2 Announce Type: replace-cross 
Abstract: In this paper, we introduce a variant of optimal transport adapted to the causal structure given by an underlying directed graph $G$. Different graph structures lead to different specifications of the optimal transport problem. For instance, a fully connected graph yields standard optimal transport, a linear graph structure corresponds to causal optimal transport between the distributions of two discrete-time stochastic processes, and an empty graph leads to a notion of optimal transport related to CO-OT, Gromov-Wasserstein distances and factored OT. We derive different characterizations of $G$-causal transport plans and introduce Wasserstein distances between causal models that respect the underlying graph structure. We show that average treatment effects are continuous with respect to $G$-causal Wasserstein distances and small perturbations of structural causal models lead to small deviations in $G$-causal Wasserstein distance. We also introduce an interpolation between causal models based on $G$-causal Wasserstein distance and compare it to standard Wasserstein interpolation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.14085v2</guid>
      <category>math.ST</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Patrick Cheridito, Stephan Eckstein</dc:creator>
    </item>
    <item>
      <title>On a sharper bound on the stability of non-autonomous Schr\"odinger equations and applications to quantum control</title>
      <link>https://arxiv.org/abs/2306.10203</link>
      <description>arXiv:2306.10203v2 Announce Type: replace-cross 
Abstract: We study the stability of the Schr\"odinger equation generated by time-dependent Hamiltonians with constant form domain. That is, we bound the difference between solutions of the Schr\"odinger equation by the difference of their Hamiltonians. The stability theorem obtained in this article provides a sharper bound than those previously obtained in the literature. This makes it a potentially useful tool for time-dependent problems in Quantum Physics, in particular for Quantum Control. We apply this result to prove two theorems about global approximate controllability of infinite-dimensional quantum systems. These results improve and generalise existing results on infinite-dimensional quantum control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.10203v2</guid>
      <category>math-ph</category>
      <category>math.FA</category>
      <category>math.MP</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aitor Balmaseda, Davide Lonigro, Juan Manuel P\'erez-Pardo</dc:creator>
    </item>
    <item>
      <title>Optimal ratcheting of dividend payout under Brownian motion surplus</title>
      <link>https://arxiv.org/abs/2308.15048</link>
      <description>arXiv:2308.15048v2 Announce Type: replace-cross 
Abstract: This paper is concerned with a long standing optimal dividend payout problem subject to the so-called ratcheting constraint, that is, the dividend payout rate shall be non-decreasing over time and is thus self-path-dependent. The surplus process is modeled by a drifted Brownian motion process and the aim is to find the optimal dividend ratcheting strategy to maximize the expectation of the total discounted dividend payouts until the ruin time. Due to the self-path-dependent control constraint, the standard control theory cannot be directly applied to tackle the problem. The related Hamilton-Jacobi-Bellman (HJB) equation is a new type of variational inequality. In the literature, it is only shown to have a viscosity solution, which is not strong enough to guarantee the existence of an optimal dividend ratcheting strategy. This paper proposes a novel partial differential equation method to study the HJB equation. We not only prove the the existence and uniqueness of the solution in some stronger functional space, but also prove the strict monotonicity, boundedness, and $C^\infty$-smoothness of the dividend ratcheting free boundary. Based on these results, we eventually derive an optimal dividend ratcheting strategy, and thus solve the open problem completely. Economically speaking, we find that if the surplus volatility is above an explicit threshold, then one should pay dividends at the maximum rate, regardless the surplus level. Otherwise, by contrast, the optimal dividend ratcheting strategy relays on the surplus level and one should only ratchet up the dividend payout rate when the surplus level touches the dividend ratcheting free boundary. Moreover, our numerical results suggest that one should invest into those companies with stable dividend payout strategies since their income rates should be higher and volatility rates smaller.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.15048v2</guid>
      <category>q-fin.MF</category>
      <category>math.OC</category>
      <category>q-fin.GN</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chonghu Guan, Zuo Quan Xu</dc:creator>
    </item>
    <item>
      <title>Convergence of flow-based generative models via proximal gradient descent in Wasserstein space</title>
      <link>https://arxiv.org/abs/2310.17582</link>
      <description>arXiv:2310.17582v3 Announce Type: replace-cross 
Abstract: Flow-based generative models enjoy certain advantages in computing the data generation and the likelihood, and have recently shown competitive empirical performance. Compared to the accumulating theoretical studies on related score-based diffusion models, analysis of flow-based models, which are deterministic in both forward (data-to-noise) and reverse (noise-to-data) directions, remain sparse. In this paper, we provide a theoretical guarantee of generating data distribution by a progressive flow model, the so-called JKO flow model, which implements the Jordan-Kinderleherer-Otto (JKO) scheme in a normalizing flow network. Leveraging the exponential convergence of the proximal gradient descent (GD) in Wasserstein space, we prove the Kullback-Leibler (KL) guarantee of data generation by a JKO flow model to be $O(\varepsilon^2)$ when using $N \lesssim \log (1/\varepsilon)$ many JKO steps ($N$ Residual Blocks in the flow) where $\varepsilon $ is the error in the per-step first-order condition. The assumption on data density is merely a finite second moment, and the theory extends to data distributions without density and when there are inversion errors in the reverse process where we obtain KL-$W_2$ mixed error guarantees. The non-asymptotic convergence rate of the JKO-type $W_2$-proximal GD is proved for a general class of convex objective functionals that includes the KL divergence as a special case, which can be of independent interest. The analysis framework can extend to other first-order Wasserstein optimization schemes applied to flow-based generative models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.17582v3</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiuyuan Cheng, Jianfeng Lu, Yixin Tan, Yao Xie</dc:creator>
    </item>
    <item>
      <title>Physics-Aware Multifidelity Bayesian Optimization: a Generalized Formulation</title>
      <link>https://arxiv.org/abs/2312.05831</link>
      <description>arXiv:2312.05831v2 Announce Type: replace-cross 
Abstract: The adoption of high-fidelity models for many-query optimization problems is majorly limited by the significant computational cost required for their evaluation at every query. Multifidelity Bayesian methods (MFBO) allow to include costly high-fidelity responses for a sub-selection of queries only, and use fast lower-fidelity models to accelerate the optimization process. State-of-the-art methods rely on a purely data-driven search and do not include explicit information about the physical context. This paper acknowledges that prior knowledge about the physical domains of engineering problems can be leveraged to accelerate these data-driven searches, and proposes a generalized formulation for MFBO to embed a form of domain awareness during the optimization procedure. In particular, we formalize a bias as a multifidelity acquisition function that captures the physical structure of the domain. This permits to partially alleviate the data-driven search from learning the domain properties on-the-fly, and sensitively enhances the management of multiple sources of information. The method allows to efficiently include high-fidelity simulations to guide the optimization search while containing the overall computational expense. Our physics-aware multifidelity Bayesian optimization is presented and illustrated for two classes of optimization problems frequently met in science and engineering, namely design optimization and health monitoring problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.05831v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.compstruc.2024.107302</arxiv:DOI>
      <arxiv:journal_reference>Computers &amp; Structures 296 (2024): 107302</arxiv:journal_reference>
      <dc:creator>Francesco Di Fiore, Laura Mainini</dc:creator>
    </item>
    <item>
      <title>The Two Lives of the Grassmannian</title>
      <link>https://arxiv.org/abs/2401.03684</link>
      <description>arXiv:2401.03684v3 Announce Type: replace-cross 
Abstract: The real Grassmannian is both a projective variety (via Pl\"ucker coordinates) and an affine variety (via orthogonal projections). We connect these two representations, and we develop the commutative algebra of the latter variety. We introduce the squared Grassmannian, and we study applications to determinantal point processes in statistics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.03684v3</guid>
      <category>math.AG</category>
      <category>math.CO</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Karel Devriendt, Hannah Friedman, Bernhard Reinke, Bernd Sturmfels</dc:creator>
    </item>
    <item>
      <title>Graphical Quadratic Algebra</title>
      <link>https://arxiv.org/abs/2403.02284</link>
      <description>arXiv:2403.02284v2 Announce Type: replace-cross 
Abstract: We introduce Graphical Quadratic Algebra (GQA), a string diagrammatic calculus extending the language of Graphical Affine Algebra with a new generator characterised by invariance under rotation matrices. We show that GQA is a sound and complete axiomatisation for three different models: quadratic relations, which are a compositional formalism for least-squares problems, Gaussian stochastic processes, and Gaussian stochastic processes extended with non-determinisms. The equational theory of GQA sheds light on the connections between these perspectives, giving an algebraic interpretation to the interplay of stochastic behaviour, relational behaviour, non-determinism, and conditioning. As applications, we discuss various case studies, including linear regression, probabilistic programming, and electrical circuits with realistic (noisy) components.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02284v2</guid>
      <category>cs.LO</category>
      <category>math.CT</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dario Stein, Fabio Zanasi, Robin Piedeleu, Richard Samuelson</dc:creator>
    </item>
    <item>
      <title>Accelerated Parameter-Free Stochastic Optimization</title>
      <link>https://arxiv.org/abs/2404.00666</link>
      <description>arXiv:2404.00666v2 Announce Type: replace-cross 
Abstract: We propose a method that achieves near-optimal rates for smooth stochastic convex optimization and requires essentially no prior knowledge of problem parameters. This improves on prior work which requires knowing at least the initial distance to optimality d0. Our method, U-DoG, combines UniXGrad (Kavis et al., 2019) and DoG (Ivgi et al., 2023) with novel iterate stabilization techniques. It requires only loose bounds on d0 and the noise magnitude, provides high probability guarantees under sub-Gaussian noise, and is also near-optimal in the non-smooth case. Our experiments show consistent, strong performance on convex problems and mixed results on neural network training.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00666v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Itai Kreisler, Maor Ivgi, Oliver Hinder, Yair Carmon</dc:creator>
    </item>
    <item>
      <title>A quantum approach for optimal control</title>
      <link>https://arxiv.org/abs/2407.02864</link>
      <description>arXiv:2407.02864v2 Announce Type: replace-cross 
Abstract: In this work, we propose a novel variational quantum approach for solving a class of nonlinear optimal control problems. Our approach integrates Dirac's canonical quantization of dynamical systems with the solution of the ground state of the resulting non-Hermitian Hamiltonian via a variational quantum eigensolver (VQE). We introduce a new perspective on the Dirac bracket formulation for generalized Hamiltonian dynamics in the presence of constraints, providing a clear motivation and illustrative examples. Additionally, we explore the structural properties of Dirac brackets within the context of multidimensional constrained optimization problems.
  Our approach for solving a class of nonlinear optimal control problems employs a VQE-based approach to determine the eigenstate and corresponding eigenvalue associated with the ground state energy of a non-Hermitian Hamiltonian. Assuming access to an ideal VQE, our formulation demonstrates excellent results, as evidenced by selected computational examples. Furthermore, our method performs well when combined with a VQE-based approach for non-Hermitian Hamiltonian systems. Our VQE-based formulation effectively addresses challenges associated with a wide range of optimal control problems, particularly in high-dimensional scenarios. Compared to standard classical approaches, our quantum-based method shows significant promise and offers a compelling alternative for tackling complex, high-dimensional optimization challenges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.02864v2</guid>
      <category>quant-ph</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hirmay Sandesara, Alok Shukla, Prakash Vedula</dc:creator>
    </item>
  </channel>
</rss>
