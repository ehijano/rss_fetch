<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.QM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.QM</link>
    <description>q-bio.QM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.QM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 03 Dec 2025 05:02:01 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Compact, Data-Logging Breath-Gas Analyzer</title>
      <link>https://arxiv.org/abs/2512.02089</link>
      <description>arXiv:2512.02089v1 Announce Type: new 
Abstract: Respiratory ailments are increasing globally at an alarming rate and are currently one of the leading factors of death and infirmity worldwide. Among respiratory diseases, those linked to poor air quality and pollutants are increasing at a proportionally higher rate than those linked to viral or other factors. Diagnosing disorders of the respiratory system is often performed initially by routine physical examinations and questionnaires. Once most patients have symptoms that are severe enough to warrant clinical testing, the ailment could have already caused pulmonary damage. Clinical diagnosis involves the use of cumbersome, expensive equipment that measures different parameters separately, e.g., Capnography (CO2) and spirometry (bidirectional tidal mass flow). These disparate sets of data must then be interpreted collectively by a qualified medical practitioner. This paper details the design of a portable, inexpensive, mixed-signal data-logging system that measures a chosen set of parameters in exhaled breath from humans or animals. The data is a comprehensive set of pertinent gases and mass flow that when looked at simultaneously, gives a synergistic view of these interrelated breathing biomarkers and thus the state of the respiratory system as a whole. A mask-mounted, tabletop, and handheld version was developed for different applications. The system, when fully developed, would enable a new set of clinical vitals that only require a patient to breathe through a single, small device for a few moments. This new set of clinical vitals could enable the early diagnosis of many respiratory ailments, something that could have a large positive impact on disease prognosis and quality of life.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02089v1</guid>
      <category>q-bio.QM</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shelby Lacouture, Mitchell Kelley, Noah Plues, Laszlo Hunyadi, Emily Sundman, Annette Sobel, Robert V. Duncan</dc:creator>
    </item>
    <item>
      <title>EcoCast: A Spatio-Temporal Model for Continual Biodiversity and Climate Risk Forecasting</title>
      <link>https://arxiv.org/abs/2512.02260</link>
      <description>arXiv:2512.02260v1 Announce Type: new 
Abstract: Increasing climate change and habitat loss are driving unprecedented shifts in species distributions. Conservation professionals urgently need timely, high-resolution predictions of biodiversity risks, especially in ecologically diverse regions like Africa. We propose EcoCast, a spatio-temporal model designed for continual biodiversity and climate risk forecasting. Utilizing multisource satellite imagery, climate data, and citizen science occurrence records, EcoCast predicts near-term (monthly to seasonal) shifts in species distributions through sequence-based transformers that model spatio-temporal environmental dependencies. The architecture is designed with support for continual learning to enable future operational deployment with new data streams. Our pilot study in Africa shows promising improvements in forecasting distributions of selected bird species compared to a Random Forest baseline, highlighting EcoCast's potential to inform targeted conservation policies. By demonstrating an end-to-end pipeline from multi-modal data ingestion to operational forecasting, EcoCast bridges the gap between cutting-edge machine learning and biodiversity management, ultimately guiding data-driven strategies for climate resilience and ecosystem conservation throughout Africa.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02260v1</guid>
      <category>q-bio.QM</category>
      <category>stat.ML</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hammed A. Akande, Abdulrauf A. Gidado</dc:creator>
    </item>
    <item>
      <title>Fast and Accurate Node-Age Estimation Under Fossil Calibration Uncertainty Using the Adjusted Pairwise Likelihood</title>
      <link>https://arxiv.org/abs/2512.02312</link>
      <description>arXiv:2512.02312v1 Announce Type: new 
Abstract: Estimating divergence times from molecular sequence data is central to reconstructing the evolutionary history of lineages. Although Bayesian relaxed-clock methods provide a principled framework for incorporating fossil information, their dependence on repeated evaluations of the full phylogenetic likelihood makes them computationally demanding for large genomic datasets. Furthermore, because disagreements in divergence-time estimates often arise from uncertainty or error in fossil placement and prior specification, there is a need for methods that are both computationally efficient and robust to fossil-calibration uncertainty. In this study, we introduce fast and accurate alternatives based on the phylogenetic pairwise composite likelihood, presenting two adjusted pairwise likelihood (APW) formulations that employ asymptotic moment-matching weights to better approximate the behavior of the full likelihood within a Bayesian MCMC framework. Extensive simulations across diverse fossil-calibration scenarios show that APW methods produce node-age estimates comparable to those obtained from the full likelihood while offering greater robustness to fossil misplacement and prior misspecification, due to the reduced sensitivity of composite likelihoods to local calibration errors. Applied to a genome-scale dataset of modern birds, APW methods recover divergence time patterns consistent with recent studies, while reducing computational cost by more than an order of magnitude. Overall, our results demonstrate that adjusted pairwise likelihoods provide a calibration-robust and computationally efficient framework for Bayesian node dating, especially suited for large phylogenomic datasets and analyses in which fossil priors may be uncertain or imperfectly placed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02312v1</guid>
      <category>q-bio.QM</category>
      <category>q-bio.PE</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gregory M Ellison, Liang Liu</dc:creator>
    </item>
    <item>
      <title>Molecular Embedding-Based Algorithm Selection in Protein-Ligand Docking</title>
      <link>https://arxiv.org/abs/2512.02328</link>
      <description>arXiv:2512.02328v1 Announce Type: new 
Abstract: Selecting an effective docking algorithm is highly context-dependent, and no single method performs reliably across structural, chemical, or protocol regimes. We introduce MolAS, a lightweight algorithm selection system that predicts per-algorithm performance from pretrained protein-ligand embeddings using attentional pooling and a shallow residual decoder. With only hundreds to a few thousand labelled complexes, MolAS achieves up to 15% absolute improvement over the single-best solver (SBS) and closes 17-66% of the Virtual Best Solver (VBS)-SBS gap across five diverse docking benchmarks. Analyses of reliability, embedding geometry, and solver-selection patterns show that MolAS succeeds when the oracle landscape exhibits low entropy and separable solver behaviour, but collapses under protocol-induced hierarchy shifts. These findings indicate that the main barrier to robust docking AS is not representational capacity but instability in solver rankings across pose-generation regimes, positioning MolAS as both a practical in-domain selector and a diagnostic tool for assessing when AS is feasible.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02328v1</guid>
      <category>q-bio.QM</category>
      <category>cs.LG</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiabao Brad Wang, Siyuan Cao, Hongxuan Wu, Yiliang Yuan, Mustafa Misir</dc:creator>
    </item>
    <item>
      <title>Assessment of Simulation-based Inference Methods for Stochastic Compartmental Models</title>
      <link>https://arxiv.org/abs/2512.02528</link>
      <description>arXiv:2512.02528v1 Announce Type: new 
Abstract: Global pandemics, such as the recent COVID-19 crisis, highlight the need for stochastic epidemic models that can capture the randomness inherent in the spread of disease. Such models must be accompanied by methods for estimating parameters in order to generate fast nowcasts and short-term forecasts that can inform public health decisions. This paper presents a comparison of two advanced Bayesian inference methods: 1) pseudo-marginal particle Markov chain Monte Carlo, short Particle Filters (PF), and 2) Conditional Normalizing Flows (CNF). We investigate their performance on two commonly used compartmental models: a classical Susceptible-Infected-Recovered (SIR) model and a two-variant Susceptible-Exposed-Infected-Recovered (SEIR) model, complemented by an observation model that maps latent trajectories to empirical data. Addressing the challenges of intractable likelihoods for parameter inference in stochastic settings, our analysis highlights how these likelihood-free methods provide accurate and robust inference capabilities. The results of our simulation study further underscore the effectiveness of these approaches in capturing the stochastic dynamics of epidemics, providing prediction capabilities for the control of epidemic outbreaks. Results on an Ethiopian cohort study demonstrate operational robustness under real-world noise and irregular data sampling. To facilitate reuse and to enable building pipelines that ultimately contribute to better informed decision making in public health, we make code and synthetic datasets publicly available.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02528v1</guid>
      <category>q-bio.QM</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vincent Wieland, Nils Wassmuth, Lorenzo Contento, Martin K\"uhn, Jan Hasenauer</dc:creator>
    </item>
    <item>
      <title>Vessel Network Topology in Molecular Communication: Insights from Experiments and Theory</title>
      <link>https://arxiv.org/abs/2512.02811</link>
      <description>arXiv:2512.02811v1 Announce Type: new 
Abstract: The notion of synthetic molecular communication (MC) refers to the transmission of information via signaling molecules and is foreseen to enable innovative medical applications in the human cardiovascular system (CVS). Crucially, the design of such applications requires accurate and experimentally validated channel models that characterize the propagation of signaling molecules, not just in individual blood vessels, but in complex vessel networks (VNs), as prevalent in the CVS. However, experimentally validated models for MC in VNs remain scarce. To address this gap, we propose a novel channel model for MC in complex VN topologies, which captures molecular transport via advection, molecular and turbulent diffusion, as well as adsorption and desorption at the vessel walls. We specialize this model for superparamagnetic iron-oxide nanoparticles (SPIONs) as signaling molecules by introducing a new receiver (RX) model for planar coil inductive sensors, enabling end-to-end experimental validation with a dedicated SPION testbed. Validation covers a range of channel topologies, from single-vessel topologies to branched VNs with multiple paths between transmitter (TX) and RX. Additionally, to quantify how the VN topology impacts signal quality, and inspired by multi-path propagation models in conventional wireless communications, we introduce two metrics, namely molecule delay and multi-path spread. We show that these metrics link the VN structure to molecule dispersion induced by the VN and mediately to the resulting signal-to-noise ratio (SNR) at the RX. The proposed VN structure-SNR link is validated experimentally, demonstrating that the proposed framework can support tasks such as optimal sensor placement in the CVS or the identification of suitable testbed topologies for specific SNR requirements. All experimental data are openly available on Zenodo.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02811v1</guid>
      <category>q-bio.QM</category>
      <category>cs.ET</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Timo Jakumeit, Lukas Brand, Jens Kirchner, Robert Schober, Sebastian Lotter</dc:creator>
    </item>
    <item>
      <title>Mapping of Lesion Images to Somatic Mutations</title>
      <link>https://arxiv.org/abs/2512.02162</link>
      <description>arXiv:2512.02162v1 Announce Type: cross 
Abstract: Medical imaging is a critical initial tool used by clinicians to determine a patient's cancer diagnosis, allowing for faster intervention and more reliable patient prognosis. At subsequent stages of patient diagnosis, genetic information is extracted to help select specific patient treatment options. As the efficacy of cancer treatment often relies on early diagnosis and treatment, we build a deep latent variable model to determine patients' somatic mutation profiles based on their corresponding medical images. We first introduce a point cloud representation of lesions images to allow for invariance to the imaging modality. We then propose, LLOST, a model with dual variational autoencoders coupled together by a separate shared latent space that unifies features from the lesion point clouds and counts of distinct somatic mutations. Therefore our model consists of three latent space, each of which is learned with a conditional normalizing flow prior to account for the diverse distributions of each domain. We conduct qualitative and quantitative experiments on de-identified medical images from The Cancer Imaging Archive and the corresponding somatic mutations from the Pan Cancer dataset of The Cancer Genomic Archive. We show the model's predictive performance on the counts of specific mutations as well as it's ability to accurately predict the occurrence of mutations. In particular, shared patterns between the imaging and somatic mutation domain that reflect cancer type. We conclude with a remark on how to improve the model and possible future avenues of research to include other genetic domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02162v1</guid>
      <category>cs.CV</category>
      <category>q-bio.QM</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rahul Mehta</dc:creator>
    </item>
    <item>
      <title>Imperfect molecular detection renormalizes apparent kinetic rates in stochastic gene regulatory networks</title>
      <link>https://arxiv.org/abs/2512.02908</link>
      <description>arXiv:2512.02908v1 Announce Type: cross 
Abstract: Imperfect molecular detection in single-cell experiments introduces technical noise that obscures the true stochastic dynamics of gene regulatory networks. While binomial models of molecular capture provide a principled description of imperfect detection, they have so far been analyzed only for simple gene-expression models that do not explicitly account for regulation. Here, we extend binomial models of capture to general gene regulatory networks to understand how imperfect capture reshapes the observed time-dependent statistics of molecular counts. Our results reveal when capture effects correspond to a renormalization of a subset of the kinetic rates and when they cannot be absorbed into effective rates, providing a systematic basis for interpreting noisy single-cell measurements. In particular, we show that rate renormalization emerges either under significant transcription factor abundance or when promoter-state transitions occur on a distinct (much slower or faster) timescale than other reactions. In these cases, technical noise causes the apparent mean burst size of synthesized gene products to appear reduced while transcription factor binding reactions appear faster. These effects hold for gene regulatory networks of arbitrary connectivity and remain valid under time-dependent kinetic rates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02908v1</guid>
      <category>q-bio.MN</category>
      <category>q-bio.QM</category>
      <category>q-bio.SC</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Iryna Zabaikina, Ramon Grima</dc:creator>
    </item>
    <item>
      <title>A reduced model for the long-term effects of physical activity on type 2 diabetes</title>
      <link>https://arxiv.org/abs/2412.16261</link>
      <description>arXiv:2412.16261v2 Announce Type: replace 
Abstract: Type 2 diabetes progresses slowly and may be reversed through lifestyle changes, but quantifying the long-term impact of regular physical activity remains challenging due to sparse longitudinal data. Mechanistic models offer a powerful tool by simulating metabolic processes over extended timescales. However, multi-scale formulations that capture both the short-term effects of exercise sessions and the slow evolution of disease tend to be computationally demanding, limiting their practical use in personalized decision support. To address this limitation, we derived a reduced version of a two-scale model that captures the short- and long-term effects of physical activity on blood glucose regulation. By analytically averaging the short-term effects induced by exercise, we developed a homogenized formulation that transmits the average contribution of physical activity to the slower glucose-insulin dynamics. This reduction preserves the key model dynamics while decreasing computational complexity by almost a factor 2000. We prove that the approximation error remains bounded and confirm the model's accuracy through a parameter-based simulation study. The resulting model provides a mathematically grounded reduction that retains key physiological mechanisms while enabling fast long-term simulations. This substantial computational gain makes it suitable for integration into medical decision support systems, where it can be used to design and evaluate personalized physical activity plans aimed at reducing the risk of type 2 diabetes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16261v2</guid>
      <category>q-bio.QM</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lea Multerer, Pierluigi Francesco De Paola, Marta Lenatti, Alessia Paglialonga, Laura Azzimonti</dc:creator>
    </item>
    <item>
      <title>Forest tree species classification and entropy-derived uncertainty mapping using extreme gradient boosting and Sentinel-1/2 satellite data</title>
      <link>https://arxiv.org/abs/2509.18228</link>
      <description>arXiv:2509.18228v2 Announce Type: replace 
Abstract: We present a new 10-meter map of dominant tree species in Swedish forests accompanied by pixel-level uncertainty estimates. The tree species classification is based on spatiotemporal metrics derived from Sentinel-1 and Sentinel-2 satellite data, combined with field observations from the Swedish National Forest Inventory. We apply an extreme gradient boosting model with Bayesian optimization to relate field observations to satellite-derived features and generate the final species map. Classification uncertainty is quantified using Shannon's entropy of the predicted class probabilities, which provide a spatially explicit measure of model confidence. The final model achieved an overall accuracy of 85% (F1 score = 0.82, Matthews correlation coefficient = 0.81), and mapped species distributions showed strong agreement with official forest statistics (Spearman's rho = 0.94).</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.18228v2</guid>
      <category>q-bio.QM</category>
      <category>stat.ML</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Abdulhakim M. Abdi, Fan Wang</dc:creator>
    </item>
    <item>
      <title>Model-based calibration of gear-specific fish abundance survey data as a change-of-support problem</title>
      <link>https://arxiv.org/abs/2505.05767</link>
      <description>arXiv:2505.05767v2 Announce Type: replace-cross 
Abstract: For commercial and recreational fisheries of a wide-ranging species to be sustainable, abundance studies from neighboring regions should be unified. For the first time in the USA, a single research project to estimate the abundance of the Greater Amberjack {Seriola dumerili) is being undertaken at the continental scale. A major methodological challenge lies in 1) the difference in fish detection gears deployed by regional survey teams that produce gear-specific relative abundance indices, and 2) the unknown relationship between actual abundance and these indices. In this paper, we develop a conversion tool that is operationalized from a Bayesian hierarchical model in an inferential context akin to the change-of-support problem often encountered in large-scale spatial studies; though, the context here is to reconcile abundance data observed at various gear-specific scales. To this end, we consider a small calibration experiment in which 2 to 4 different underwater video camera types were simultaneously deployed on each of 21 boat trips. Alongside the suite of deployed cameras was also an acoustic echosounder that recorded fish signals along surrounding transects. Our modeling framework is used to derive calibration formulae for translating camera-specific relative indices to the actual abundance scale in surveys that deploy a single camera. Cross-validation is conducted using mark-recapture abundance estimates (only available for 10 trips, all observed at a single habitat type) and through a separate simulation study. We also briefly discuss the case when surveys pair one camera with the echosounder.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.05767v2</guid>
      <category>stat.ME</category>
      <category>q-bio.QM</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Grace S. Chiu, Anton H. Westveld, Mark A. Albins, Kevin M. Boswell, John M. Hoenig, Sean P. Powers, S. Lynne Stokes, Allison L. White</dc:creator>
    </item>
    <item>
      <title>SimpleFold: Folding Proteins is Simpler than You Think</title>
      <link>https://arxiv.org/abs/2509.18480</link>
      <description>arXiv:2509.18480v3 Announce Type: replace-cross 
Abstract: Protein folding models have achieved groundbreaking results typically via a combination of integrating domain knowledge into the architectural blocks and training pipelines. Nonetheless, given the success of generative models across different but related problems, it is natural to question whether these architectural designs are a necessary condition to build performant models. In this paper, we introduce SimpleFold, the first flow-matching based protein folding model that solely uses general purpose transformer blocks. Protein folding models typically employ computationally expensive modules involving triangular updates, explicit pair representations or multiple training objectives curated for this specific domain. Instead, SimpleFold employs standard transformer blocks with adaptive layers and is trained via a generative flow-matching objective with an additional structural term. We scale SimpleFold to 3B parameters and train it on approximately 9M distilled protein structures together with experimental PDB data. On standard folding benchmarks, SimpleFold-3B achieves competitive performance compared to state-of-the-art baselines, in addition SimpleFold demonstrates strong performance in ensemble prediction which is typically difficult for models trained via deterministic reconstruction objectives. Due to its general-purpose architecture, SimpleFold shows efficiency in deployment and inference on consumer-level hardware. SimpleFold challenges the reliance on complex domain-specific architectures designs in protein folding, opening up an alternative design space for future progress.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.18480v3</guid>
      <category>cs.LG</category>
      <category>q-bio.QM</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuyang Wang, Jiarui Lu, Navdeep Jaitly, Josh Susskind, Miguel Angel Bautista</dc:creator>
    </item>
    <item>
      <title>Geometric Modeling of Hippocampal Tau Deposition: A Surface-Based Framework for Covariate Analysis and Off-Target Contamination Detection</title>
      <link>https://arxiv.org/abs/2511.01732</link>
      <description>arXiv:2511.01732v2 Announce Type: replace-cross 
Abstract: We introduce a framework combining geometric modeling with disease progression analysis to investigate tau deposition in Alzheimer's disease (AD) using positron emission tomography (PET) data. Focusing on the hippocampus, we construct a principal surface that captures the spatial distribution and morphological changes of tau pathology. By projecting voxels onto this surface, we quantify tau coverage, intensity, and thickness through bidirectional projection distances and interpolated standardized uptake value ratios (SUVR). This low-dimensional embedding preserves spatial specificity while mitigating multiple comparison issues. Covariate effects are analyzed using a two-stage regression model with inverse probability weighting to adjust for signal sparsity and selection bias. Using the SuStaIn model, we identify subtypes and stages of AD, revealing distinct tau dynamics: the limbic-predominant subtype shows age-related nonlinear accumulation in coverage and thickness, whereas the posterior subtype exhibits uniform SUVR increases across disease progression. Model-based predictions show that hippocampal tau deposition follows a structured spatial trajectory expanding bidirectionally with increasing thickness, while subtype differences highlight posterior hippocampal involvement consistent with whole-brain patterns. Finally, directional signal patterns on the principal surface reveal contamination from the choroid plexus, demonstrating the broader applicability of the proposed framework across modalities including amyloid PET.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01732v2</guid>
      <category>stat.AP</category>
      <category>q-bio.QM</category>
      <category>stat.OT</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liangkang Wang, Akhil Ambekar, Ani Eloyan</dc:creator>
    </item>
    <item>
      <title>BioArc: Discovering Optimal Neural Architectures for Biological Foundation Models</title>
      <link>https://arxiv.org/abs/2512.00283</link>
      <description>arXiv:2512.00283v2 Announce Type: replace-cross 
Abstract: Foundation models have revolutionized various fields such as natural language processing (NLP) and computer vision (CV). While efforts have been made to transfer the success of the foundation models in general AI domains to biology, existing works focus on directly adopting the existing foundation model architectures from general machine learning domains without a systematic design considering the unique physicochemical and structural properties of each biological data modality. This leads to suboptimal performance, as these repurposed architectures struggle to capture the long-range dependencies, sparse information, and complex underlying ``grammars'' inherent to biological data. To address this gap, we introduce BioArc, a novel framework designed to move beyond intuition-driven architecture design towards principled, automated architecture discovery for biological foundation models. Leveraging Neural Architecture Search (NAS), BioArc systematically explores a vast architecture design space, evaluating architectures across multiple biological modalities while rigorously analyzing the interplay between architecture, tokenization, and training strategies. This large-scale analysis identifies novel, high-performance architectures, allowing us to distill a set of empirical design principles to guide future model development. Furthermore, to make the best of this set of discovered principled architectures, we propose and compare several architecture prediction methods that effectively and efficiently predict optimal architectures for new biological tasks. Overall, our work provides a foundational resource and a principled methodology to guide the creation of the next generation of task-specific and foundation models for biology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.00283v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>q-bio.QM</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yi Fang, Haoran Xu, Jiaxin Han, Sirui Ding, Yizhi Wang, Yue Wang, Xuan Wang</dc:creator>
    </item>
  </channel>
</rss>
