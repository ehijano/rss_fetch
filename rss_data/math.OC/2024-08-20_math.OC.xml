<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 21 Aug 2024 01:48:25 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 20 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Determining internal topological structures and running cost of mean field games with partial boundary measurement</title>
      <link>https://arxiv.org/abs/2408.08911</link>
      <description>arXiv:2408.08911v1 Announce Type: new 
Abstract: This paper investigates the simultaneous reconstruction of the running cost function and the internal topological structure within the mean-field games (MFG) system utilizing partial boundary data. The inverse problem is notably challenging due to factors such as nonlinear coupling, the necessity for multi-parameter reconstruction, constraints on probability measures, and the limited availability of measurement information. To address these challenges, we propose an innovative approach grounded in a higher-order linearization method. This method is tailored for inverse problems in MFG systems that involve Dirichlet and Neumann boundary conditions. Initially, we present unique reconstruction results for the cost function and internal topological structure of the MFG system under various homogeneous boundary conditions. Subsequently, we extend these results to accommodate inhomogeneous boundary conditions. These findings greatly enhance our understanding of simultaneous reconstruction in complex MFG systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.08911v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ming-Hui Ding, Hongyu Liu, Guang-Hui Zheng</dc:creator>
    </item>
    <item>
      <title>Variable Neighborhood Search for the Multi-Depot Multiple Set Orienteering Problem</title>
      <link>https://arxiv.org/abs/2408.08922</link>
      <description>arXiv:2408.08922v1 Announce Type: new 
Abstract: This paper introduces a variant of the Set Orienteering Problem (SOP), the multi-Depot multiple Set Orienteering Problem (mDmSOP). It generalizes the SOP by grouping nodes into mutually exclusive sets (clusters) with associated profits. Profit can be earned if any node within the set is visited. Multiple travelers, denoted by $t$ $(&gt; 1)$, are employed, with each traveler linked to a specific depot. The primary objective of the problem is to maximize profit collection from the sets within a predefined budget. A novel formulation is introduced for the mDmSOP. The paper utilizes the Variable Neighborhood Search (VNS) meta-heuristic to solve the mDmSOP on small, medium, and large instances from the Generalized Traveling Salesman Problem (GTSP) benchmark. The results demonstrate the VNS's superiority in robustness and solution quality, as it requires less computational time than solving the mathematical formulation with GAMS 37.1.0 and CPLEX. Additionally, increasing the number of travelers leads to significant improvements in profits.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.08922v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ravi Kant, Salmaan Shahid, Anuvind Bhat, Abhishek Mishra</dc:creator>
    </item>
    <item>
      <title>Scalable Computation of $\mathcal{H}_\infty$ Energy Functions for Polynomial Control-Affine Systems</title>
      <link>https://arxiv.org/abs/2408.08970</link>
      <description>arXiv:2408.08970v1 Announce Type: new 
Abstract: We present a scalable approach to computing nonlinear balancing energy functions for control-affine systems with polynomial nonlinearities. Al'brekht's power-series method is used to solve the Hamilton-Jacobi-Bellman equations for polynomial approximations to the energy functions. The contribution of this article lies in the numerical implementation of the method based on the Kronecker product, enabling scalability to over 1000 state dimensions. The tensor structure and symmetries arising from the Kronecker product representation are key to the development of efficient and scalable algorithms. We derive the explicit algebraic structure for the equations, present rigorous theory for the solvability and algorithmic complexity of those equations, and provide general purpose open-source software implementations for the proposed algorithms. The method is illustrated on two simple academic models, followed by a high-dimensional semidiscretized PDE model of dimension as large as $n=1080$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.08970v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicholas A. Corbin, Boris Kramer</dc:creator>
    </item>
    <item>
      <title>Set Values of Dynamic Nonzero Sum Games and Set Valued Hamiltonians</title>
      <link>https://arxiv.org/abs/2408.09047</link>
      <description>arXiv:2408.09047v1 Announce Type: new 
Abstract: It is well known that the (unique) value of a stochastic control problem or a two person zero sum game under Isaacs condition can be characterized through a PDE driven by the Hamiltonian. Our goal of this paper is to extend this classical result to nonzero sum games, which typically have multiple Nash equilibria and multiple values. Our object is the set value of the game, which roughly speaking is the set of values over all equilibria and thus is by nature unique. We shall introduce set valued Hamiltonians and characterize the set value of the game through backward SDEs driven by appropriate selectors of the set valued Hamiltonians, where the selectors are typically path dependent. When the set valued Hamiltonian is a singleton, our result covers the standard control problem and two person zero sum game problem under Isaacs condition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09047v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bixing Qiao, Jianfeng Zhang</dc:creator>
    </item>
    <item>
      <title>A Rapid Algorithm for Beam Illumination Patterns and Hopping Time Plan</title>
      <link>https://arxiv.org/abs/2408.09068</link>
      <description>arXiv:2408.09068v1 Announce Type: new 
Abstract: Beam hopping (BH) is a satellite communications technique in which sets of beams are sequentially illuminated over a defined time interval. Geographically varying the duty cycle of satellite transmission allows for reduced resource wastage as satellite capacity is matched to non-uniform user demands. Total feasible active beam combinations is given by $2^n$ for $n$ beams. With in service satellite systems operating in excess of 100 beams, complete enumeration of optimum illumination patterns is not tractable. Developing efficient optimization methods which minimize resource wastage is essential to realising the benefits of modern BH systems. We present a computationally efficient pattern generation method which uses the binary logarithm to decompose beam demands into common powers of two. This method is shown to produce feasible patterns within 0.047 and 0.31 seconds for systems using 49 and 132 beams respectively and within 19.109 seconds for a 1085 beam system. When averaged across all testing configurations, this method reduced capacity error by 94% compared to a conventional even data distribution. To facilitate algorithm comparison, two integer linear programming formulations are developed. Even though they can only solve problems of modest sizes to proven optimality, they provide valuable insights in the optimality gap for our proposed heuristic approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09068v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Angus Gaudry, Vicky Mak-Hau</dc:creator>
    </item>
    <item>
      <title>Planning of Off-Grid Renewable Power to Ammonia Systems with Heterogeneous Flexibility: A Multistakeholder Equilibrium Perspective</title>
      <link>https://arxiv.org/abs/2408.09113</link>
      <description>arXiv:2408.09113v1 Announce Type: new 
Abstract: Off-grid renewable power to ammonia (ReP2A) systems present a promising pathway toward carbon neutrality in both the energy and chemical industries. However, due to chemical safety requirements, the limited flexibility of ammonia synthesis poses a challenge when attempting to align with the variable hydrogen flow produced from renewable power. This necessitates the optimal sizing of equipment capacity for effective and coordinated production across the system. Additionally, an ReP2A system may involve multiple stakeholders with varying degrees of operational flexibility, complicating the planning problem. This paper first examines the multistakeholder sizing equilibrium (MSSE) of the ReP2A system. First, we propose an MSSE model that accounts for individual planning decisions and the competing economic interests of the stakeholders of power generation, hydrogen production, and ammonia synthesis. We then construct an equivalent optimization problem based on Karush--Kuhn--Tucker (KKT) conditions to determine the equilibrium. Following this, we decompose the problem in the temporal dimension and solve it via multicut generalized Benders decomposition (GBD) to address long-term balancing issues. Case studies based on a realistic project reveal that the equilibrium does not naturally balance the interests of all stakeholders due to their heterogeneous characteristics. Our findings suggest that benefit transfer agreements ensure mutual benefits and the successful implementation of ReP2A projects.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09113v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yangjun Zeng (College of Electrical Engineering, Sichuan University), Yiwei Qiu (College of Electrical Engineering, Sichuan University), Jie Zhu (College of Electrical Engineering, Sichuan University), Shi Chen (College of Electrical Engineering, Sichuan University), Tianlei Zang (College of Electrical Engineering, Sichuan University), Buxiang Zhou (College of Electrical Engineering, Sichuan University), Ge He (School of Chemical Engineering, Sichuan University), Xu Ji (School of Chemical Engineering, Sichuan University)</dc:creator>
    </item>
    <item>
      <title>Refining asymptotic complexity bounds for nonconvex optimization methods, including why steepest descent is $o(\epsilon^{-2})$ rather than $\mathcal{O}(\epsilon^{-2})$</title>
      <link>https://arxiv.org/abs/2408.09124</link>
      <description>arXiv:2408.09124v1 Announce Type: new 
Abstract: We revisit the standard ``telescoping sum'' argument ubiquitous in the final steps of analyzing evaluation complexity of algorithms for smooth nonconvex optimization, and obtain a refined formulation of the resulting bound as a function of the requested accuracy $\epsilon$. While bounds obtained using the standard argument typically are of the form $\mathcal{O}(\epsilon^{-\alpha})$ for some positive $\alpha$, the refined results are of the form $o(\epsilon^{-\alpha})$. We then explore to which known algorithms our refined bounds are applicable and finally describe an example showing how close the standard and refined bounds can be.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09124v1</guid>
      <category>math.OC</category>
      <category>cs.CC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Serge Gratton, Chee-Khian Sim, Philippe L. Toint</dc:creator>
    </item>
    <item>
      <title>Explicit Convergence Rate of The Proximal Point Algorithm under R-Continuity</title>
      <link>https://arxiv.org/abs/2408.09139</link>
      <description>arXiv:2408.09139v1 Announce Type: new 
Abstract: The paper provides a thorough comparison between R-continuity and other fundamental tools in optimization such as metric regularity, metric subregularity and calmness. We show that R-continuity has some advantages in the convergence rate analysis of algorithms solving optimization problems. We also present some properties of R-continuity and study the explicit convergence rate of the Proximal Point Algorithm (PPA) under the R-continuity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09139v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ba Khiet Le, Michel Th\'era</dc:creator>
    </item>
    <item>
      <title>Learning to Optimally Stop a Diffusion Process</title>
      <link>https://arxiv.org/abs/2408.09242</link>
      <description>arXiv:2408.09242v1 Announce Type: new 
Abstract: We study optimal stopping for a diffusion process with unknown model primitives within the continuous-time reinforcement learning (RL) framework developed by Wang et al. (2020). By penalizing its variational inequality, we transform the stopping problem into a stochastic optimal control problem with two actions. We then randomize control into Bernoulli distributions and add an entropy regularizer to encourage exploration. We derive a semi-analytical optimal Bernoulli distribution, based on which we devise RL algorithms using the martingale approach established in Jia and Zhou (2022a) and prove a policy improvement theorem. Finally, we demonstrate the effectiveness of the algorithms in examples of pricing finite-horizon American put options and solving Merton's problem with transaction costs, and show that both the offline and online algorithms achieve high accuracy in learning the value functions and characterizing the associated free boundaries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09242v1</guid>
      <category>math.OC</category>
      <category>q-fin.MF</category>
      <category>q-fin.PR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Min Dai, Yu Sun, Zuo Quan Xu, Xun Yu Zhou</dc:creator>
    </item>
    <item>
      <title>Optimal Strip Attitude Command of Earth Observation Satellite using Differential Dynamic Programming</title>
      <link>https://arxiv.org/abs/2408.09244</link>
      <description>arXiv:2408.09244v1 Announce Type: new 
Abstract: This paper addresses the optimal scan profile problem for strip imaging in an Earth observation satellite (EOS) equipped with a time-delay integration (TDI) camera. Modern TDI cameras can control image integration frequency during imaging operation, adding an additional degree of freedom (DOF) to the imaging operation. On the other hand, modern agile EOS is capable of imaging non-parallel ground targets, which require a substantial amount of angular velocity and angular acceleration during operation. We leverage this DOF to minimize various factors impacting image quality, such as angular velocity. Initially, we derive analytic expressions for angular velocity based on kinematic equations. These expressions are then used to formulate a constrained optimal control problem (OCP), which we solve using differential dynamic programming (DDP). We validate our approach through testing and comparison with reference methods across various practical scenarios. Simulation results demonstrate that our proposed method efficiently achieves near-optimal solutions without encountering non-convergence issues.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09244v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Seungyeop Han, Byeong-Un Jo, Koki Ho</dc:creator>
    </item>
    <item>
      <title>Time Efficient Rate Feedback Tracking Controller with Slew Rate and Control Constraint</title>
      <link>https://arxiv.org/abs/2408.09246</link>
      <description>arXiv:2408.09246v1 Announce Type: new 
Abstract: This paper proposes a time-efficient attitude-tracking controller considering the slew rate constraint and control constraint. The algorithm defines the sliding surface, which is the linear combination of command, body, and regulating angular velocity, and utilizes the sliding surface to derive the control command that guarantees finite time stability. The regulating rate, which is an angular velocity regulating the attitude error between the command and body frame, is defined along the instantaneous eigen-axis between the two frames to minimize the rotation angle. In addition, the regulating rate is shaped such that the slew rate constraint is satisfied while the time to regulation is minimized with consideration of the control constraint. Practical scenarios involving Earth observation satellites are used to validate the algorithm's performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09246v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Seungyeop Han, Byeong-Un Jo, Koki Ho</dc:creator>
    </item>
    <item>
      <title>Analysis and Design of Satellite Constellation Spare Strategy Using Markov Chain</title>
      <link>https://arxiv.org/abs/2408.09250</link>
      <description>arXiv:2408.09250v1 Announce Type: new 
Abstract: This paper introduces the analysis and design method of an optimal spare management policy using Markov chain for a large-scale satellite constellation. We propose an analysis methodology of spare strategy using a multi-echelon $(r,q)$ inventory control model with Markov chain, and review two different spare strategies: direct resupply, which inserts spares directly into the constellation orbit using launch vehicles; and indirect resupply, which places spares into parking orbits before transferring them to the constellation orbit. Furthermore, we propose an optimization formulation utilizing the results of the proposed analysis method, and an optimal solution is found using a genetic algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09250v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Seungyeop Han, Takumi Noro, Koki Ho</dc:creator>
    </item>
    <item>
      <title>Exploratory Optimal Stopping: A Singular Control Formulation</title>
      <link>https://arxiv.org/abs/2408.09335</link>
      <description>arXiv:2408.09335v1 Announce Type: new 
Abstract: This paper explores continuous-time and state-space optimal stopping problems from a reinforcement learning perspective. We begin by formulating the stopping problem using randomized stopping times, where the decision maker's control is represented by the probability of stopping within a given time--specifically, a bounded, non-decreasing, c\`adl\`ag control process. To encourage exploration and facilitate learning, we introduce a regularized version of the problem by penalizing it with the cumulative residual entropy of the randomized stopping time. The regularized problem takes the form of an (n+1)-dimensional degenerate singular stochastic control with finite-fuel. We address this through the dynamic programming principle, which enables us to identify the unique optimal exploratory strategy. For the specific case of a real option problem, we derive a semi-explicit solution to the regularized problem, allowing us to assess the impact of entropy regularization and analyze the vanishing entropy limit. Finally, we propose a reinforcement learning algorithm based on policy iteration. We show both policy improvement and policy convergence results for our proposed algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09335v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>q-fin.MF</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jodi Dianetti, Giorgio Ferrari, Renyuan Xu</dc:creator>
    </item>
    <item>
      <title>Entropic Semi-Martingale Optimal Transport</title>
      <link>https://arxiv.org/abs/2408.09361</link>
      <description>arXiv:2408.09361v2 Announce Type: new 
Abstract: Entropic Optimal Transport (EOT), also referred to as the Schr\"odinger problem, seeks to find a random processes with prescribed initial/final marginals and with minimal relative entropy with respect to a reference measure. The relative entropy forces the two measures to share the same support and only the drift of the controlled process can be adjusted, the diffusion being imposed by the reference measure. Therefore, at first sight, Semi-Martingale Optimal Transport (SMOT) problems (see [1]) seem out of the scope of applications of Entropic regularization techniques, which are otherwise very attractive from a computational point of view. However, when the process is observed only at discrete times, and become therefore a Markov chain, its relative entropy can remain finite even with variable diffusion coefficients, and discrete semi-martingales can be obtained as solutions of (multi-marginal) EOT problems.Given a (smooth) semi-martingale, the limit of the relative entropy of its time discretizations, scaled by the time step converges to the so-called ``specific relative entropy'', a convex functional of its variance process, similar to those used in SMOT.In this paper we use this observation to build an entropic time discretization of continuous SMOT problems. This allows to compute discrete approximations of solutions to continuous SMOT problems by a multi-marginal Sinkhorn algorithm, without the need of solving the non-linear Hamilton-Jacobi-Bellman pde's associated to the dual problem, as done for example in [1, 2]. We prove a convergence result of the time discrete entropic problem to the continuous time problem, we propose an implementation and provide numerical experiments supporting the theoretical convergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09361v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jean-David Benamou, Guillaume Chazareix, Marc Hoffmann, Gr\'egoire Loeper, Fran\c{c}ois-Xavier Vialard</dc:creator>
    </item>
    <item>
      <title>Internalizing sensing externality via matching and pricing for drive-by sensing taxi fleets</title>
      <link>https://arxiv.org/abs/2408.09376</link>
      <description>arXiv:2408.09376v1 Announce Type: new 
Abstract: Drive-by sensing is a promising data collection paradigm that leverages the mobilities of vehicles to survey urban environments at low costs, contributing to the positive externality of urban transport activities. Focusing on e-hailing services, this paper explores the sensing potential of taxi fleets, by designing a joint matching and pricing scheme based on a double auction process. The matching module maximizes the sensing utility by prioritizing trips with high sensing potentials, and the pricing module allocates the corresponding social welfare according to the participants' contributions to the sensing utility. We show that the proposed scheme is allocative efficient, individually rational, budget balancing, envy-free, and group incentive compatible. The last notion guarantees that the participants, as a cohort, will end up with the same total utility regardless of mis-reporting on part of its members. Extensive numerical tests based on a real-world scenario reveal that the sensing externality can be well aligned with the level of service and budget balance. Various managerial insights regarding the applicability and efficacy of the proposed scheme are generated through scenario-based sensitivity analyses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09376v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Binzhou Yang, Ke Han, Shenglin Liu, Ruijie Li</dc:creator>
    </item>
    <item>
      <title>A Framework for Approximating Perturbed Optimal Control Problems</title>
      <link>https://arxiv.org/abs/2408.09546</link>
      <description>arXiv:2408.09546v1 Announce Type: new 
Abstract: We consider trajectory optimal control problems in which parameter uncertainty limits the applicability of control trajectories computed prior to travel. Hence, efficient trajectory adjustment is needed to ensure successful travel. However, it is often prohibitive or impossible to recalculate the optimal control in-transit due to strict time constraints or limited onboard computing resources. Thus, we propose a framework for quick and accurate trajectory approximations by using post-optimality sensitivity information. This allows the reduction of uncertain parameter space and an instantaneous approximation of the new optimal controller while using sensitivity data computed and stored pretransit.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09546v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Riley Link, Ethan Ebbighausen</dc:creator>
    </item>
    <item>
      <title>Existence of Solutions for Fractional Optimal Control Problems with Superlinear-subcritical Controls</title>
      <link>https://arxiv.org/abs/2408.09586</link>
      <description>arXiv:2408.09586v1 Announce Type: new 
Abstract: This paper gives an existence result for solutions to an elliptic optimal control problem based on a general fractional kernel, where the admissible controls come from a class satisfying both a growth bound and a superlinear-subcritical condition. Each admissible control is known to produce a nontrivial corresponding state by applying the Mountain Pass Theorem to fractional equations. The main theoretical contribution is the construction of a suitable set of admissible controls on which the the standard existence theory for control problems with linear and semi-linear state constraints can be adapted. Extra care is taken to explain what new difficulties arise for these types of control problems, to justify the limitations of this theory. For completeness, the corresponding local elliptic control problem is also studied.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09586v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joshua M. Siktar</dc:creator>
    </item>
    <item>
      <title>Linear-Quadratic Mean-Field Game for Stochastic Systems with Partial Observation</title>
      <link>https://arxiv.org/abs/2408.09652</link>
      <description>arXiv:2408.09652v1 Announce Type: new 
Abstract: This paper is concerned with a class of linear-quadratic stochastic large-population problems with partial information, where the individual agent only has access to a noisy observation process related to the state. The dynamics of each agent follows a linear stochastic differential equation driven by individual noise, and all agents are coupled together via the control average term. Using the mean-field game approach and the backward separation principle with a state decomposition technique, the decentralized optimal control can be obtained in the open-loop form through a forward-backward stochastic differential equation with the conditional expectation. The optimal filtering equation is also provided. By the decoupling method, the decentralized optimal control can also be further presented as the feedback of state filtering via the Riccati equation. The explicit solution of the control average limit is given, and the consistency condition system is discussed. Moreover, the related $\varepsilon$-Nash equilibrium property is verified. To illustrate the good performance of theoretical results, an example in finance is studied.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09652v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Min Li, Na Li, Zhen Wu</dc:creator>
    </item>
    <item>
      <title>Enhanced Barrier-Smoothing Technique for Bilevel Optimization with Nonsmooth Mappings</title>
      <link>https://arxiv.org/abs/2408.09661</link>
      <description>arXiv:2408.09661v2 Announce Type: new 
Abstract: Bilevel optimization problems, encountered in fields such as economics, engineering, and machine learning, pose significant computational challenges due to their hierarchical structure and constraints at both upper and lower levels. Traditional gradient-based methods are effective for unconstrained bilevel programs with unique lower level solutions, but struggle with constrained bilevel problems due to the nonsmoothness of lower level solution mappings. To overcome these challenges, this paper introduces the Enhanced Barrier-Smoothing Algorithm (EBSA), a novel approach that integrates gradient-based techniques with an augmented Lagrangian framework. EBSA utilizes innovative smoothing functions to approximate the primal-dual solution mapping of the lower level problem, and then transforms the bilevel problem into a sequence of smooth single-level problems. This approach not only addresses the nonsmoothness but also enhances convergence properties. Theoretical analysis demonstrates its superiority in achieving Clarke and, under certain conditions, Bouligand stationary points for bilevel problems. Both theoretical analysis and preliminary numerical experiments confirm the robustness and efficiency of EBSA.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09661v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mengwei Xu, Yu-Hong Dai, Xin-Wei Liu, Bo Wang</dc:creator>
    </item>
    <item>
      <title>Continuous-Time Dynamic Decision Making with Costly Information</title>
      <link>https://arxiv.org/abs/2408.09693</link>
      <description>arXiv:2408.09693v1 Announce Type: new 
Abstract: We consider a continuous-time linear-quadratic Gaussian control problem with partial observations and costly information acquisition. More precisely, we assume the drift of the state process to be governed by an unobservable Ornstein--Uhlenbeck process. The decision maker can additionally acquire information on the hidden state by conducting costly tests, thereby augmenting the available information.
  Combining the Kalman--Bucy filter with a dynamic programming approach, we show that the problem can be reduced to a deterministic control problem for the conditional variance of the unobservable state. Optimal controls and value functions are derived in a semi-explicit form, and we present an extensive study of the qualitative properties of the model.
  We demonstrate that both the optimal cost and the marginal cost increase with model uncertainty. We identify a critical threshold: below this level, it is optimal not to acquire additional information, whereas above this threshold, continuous information acquisition is optimal, with the rate increasing as uncertainty grows. For quadratic information costs, we derive the precise asymptotic behavior of the acquisition rate as uncertainty approaches zero and infinity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09693v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christoph Knochenhauer, Alexander Merkel, Yufei Zhang</dc:creator>
    </item>
    <item>
      <title>Optimal Replenishment Strategy for Satellite Constellation with Dual Supply Modes</title>
      <link>https://arxiv.org/abs/2408.09696</link>
      <description>arXiv:2408.09696v1 Announce Type: new 
Abstract: This paper proposes a novel inventory management model for the spare strategy of a satellite mega-constellation incorporating dual supply modes: normal and emergency. The proposed framework employs an indirect channel for normal supply, wherein spare satellites are initially injected into a parking orbit before transferring to the target orbital plane via propulsion systems and orbital perturbations. Conversely, the emergency supply mode utilizes a direct channel, injecting spare satellites immediately into their designated orbital planes. The inventory management model is constructed using parametric replenishment policies: (s,Q) and (R1,R2,Q1,Q2) with a time window. Following this model, two optimization problems are formulated to address decision-making contexts from the perspectives of constellation operators and launch service providers. The case study showcases the practical applicability of the proposed model and optimization problems, yielding valuable insights for stakeholders in the spaceborne industry.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09696v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Taehyun Sung, Jaewoo Kim, Jaemyung Ahn</dc:creator>
    </item>
    <item>
      <title>A new formulation for the collection and delivery problem of biomedical specimen</title>
      <link>https://arxiv.org/abs/2408.09998</link>
      <description>arXiv:2408.09998v1 Announce Type: new 
Abstract: We study the collection and delivery problem of biomedical specimens (CDSP) with multiple trips, time windows, a homogeneous fleet, and the objective of minimizing total completion time of delivery requests. This is a prominent problem in healthcare logistics, where specimens (blood, plasma, urin etc.) collected from patients in doctor's offices and hospitals are transported to a central laboratory for advanced analysis. To the best of our knowledge, available exact solution approaches for CDSP have been able to solve only small instances with up to 9 delivery requests. In this paper, we propose a two-index mixed-integer programming formulation that, when used with an off-the-shelf solver, results in a fast exact solution approach. Computational experiments on a benchmark data set confirm that the proposed formulation outperforms both the state-of-the-art model and the state-of-the-art metaheuristic from the literature, solving 80 out of 168 benchmark instances to optimality, including a significant number of instances with 100 delivery requests.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09998v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luis Aurelio Rocha, Alena Otto, Marc Goerigk</dc:creator>
    </item>
    <item>
      <title>Control semiflows, chain controllability, and the Selgrade decomposition for linear delay systems</title>
      <link>https://arxiv.org/abs/2408.10048</link>
      <description>arXiv:2408.10048v1 Announce Type: new 
Abstract: A continuous semiflow is introduced for linear control systems with delays in the states and controls and bounded control range. The state includes the control functions. It is proved that there exists a unique chain control set which corresponds to the chain recurrent set of the semiflow. The semiflow can be lifted to a linear semiflow on an infinite dimensional vector bundle with chain transitive base flow. A decomposition into exponentially separated subbundles is provided by a recent generalization of Selgrade's theorem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.10048v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fritz Colonius</dc:creator>
    </item>
    <item>
      <title>A discrete Consensus-Based Global Optimization Method with Noisy Objective Function</title>
      <link>https://arxiv.org/abs/2408.10078</link>
      <description>arXiv:2408.10078v1 Announce Type: new 
Abstract: Consensus based optimization is a derivative-free particles-based method for the solution of global optimization problems. Several versions of the method have been proposed in the literature, and different convergence results have been proved. However, all existing results assume the objective function to be evaluated exactly at each iteration of the method. In this work, we extend the convergence analysis of a discrete-time CBO method to the case where only a noisy stochastic estimator of the objective function can be computed at a given point. In particular we prove that under suitable assumptions on the oracle's noise, the expected value of the mean squared distance of the particles from the solution can be made arbitrarily small in a finite number of iterations. Numerical experiments showing the impact of noise are also given.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.10078v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stefania Bellavia, Greta Malaspina</dc:creator>
    </item>
    <item>
      <title>Gradient-Variation Online Learning under Generalized Smoothness</title>
      <link>https://arxiv.org/abs/2408.09074</link>
      <description>arXiv:2408.09074v1 Announce Type: cross 
Abstract: Gradient-variation online learning aims to achieve regret guarantees that scale with the variations in the gradients of online functions, which has been shown to be crucial for attaining fast convergence in games and robustness in stochastic optimization, hence receiving increased attention. Existing results often require the smoothness condition by imposing a fixed bound on the gradient Lipschitzness, but this may not hold in practice. Recent efforts in neural network optimization suggest a generalized smoothness condition, allowing smoothness to correlate with gradient norms. In this paper, we systematically study gradient-variation online learning under generalized smoothness. To this end, we extend the classic optimistic mirror descent algorithm to derive gradient-variation bounds by conducting stability analysis over the optimization trajectory and exploiting smoothness locally. Furthermore, we explore universal online learning, designing a single algorithm enjoying optimal gradient-variation regrets for convex and strongly convex functions simultaneously without knowing curvature information. The algorithm adopts a two-layer structure with a meta-algorithm running over a group of base-learners. To ensure favorable guarantees, we have designed a new meta-algorithm that is Lipschitz-adaptive to handle potentially unbounded gradients and meanwhile ensures second-order regret to cooperate with base-learners. Finally, we provide implications of our findings and obtain new results in fast-rate games and stochastic extended adversarial optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09074v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yan-Feng Xie, Peng Zhao, Zhi-Hua Zhou</dc:creator>
    </item>
    <item>
      <title>Secrecy Energy Efficiency Maximization in RIS-Aided Wireless Networks with Statistical CSI</title>
      <link>https://arxiv.org/abs/2408.09180</link>
      <description>arXiv:2408.09180v1 Announce Type: cross 
Abstract: This work studies the problem of secrecy energy efficiency maximization in multi-user wireless networks aided by reconfigurable intelligent surfaces, in which an eavesdropper overhears the uplink communication. A provably convergent optimization algorithm is proposed which optimizes the user's transmit power, metasurface reflection coefficients, and base station receive filters. The complexity of the proposed method is analyzed and numerical results are provided to show the performance of the proposed optimization method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09180v1</guid>
      <category>eess.SP</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Robert Kuku Fotock, Agbotiname Lucky Imoize, Alessio Zappone, Marco Di Renzo, Roberto Garello</dc:creator>
    </item>
    <item>
      <title>Branch and Bound to Assess Stability of Regression Coefficients in Uncertain Models</title>
      <link>https://arxiv.org/abs/2408.09634</link>
      <description>arXiv:2408.09634v1 Announce Type: cross 
Abstract: It can be difficult to interpret a coefficient of an uncertain model. A slope coefficient of a regression model may change as covariates are added or removed from the model. In the context of high-dimensional data, there are too many model extensions to check. However, as we show here, it is possible to efficiently search, with a branch and bound algorithm, for maximum and minimum values of that adjusted slope coefficient over a discrete space of regularized regression models. Here we introduce our algorithm, along with supporting mathematical results, an example application, and a link to our computer code, to help researchers summarize high-dimensional data and assess the stability of regression coefficients in uncertain models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09634v1</guid>
      <category>stat.ME</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Brian Knaeble, R. Mitchell Hughes, George Rudolph, Mark A. Abramson, Daniel Razo</dc:creator>
    </item>
    <item>
      <title>Solving stochastic climate-economy models: A deep least-squares Monte Carlo approach</title>
      <link>https://arxiv.org/abs/2408.09642</link>
      <description>arXiv:2408.09642v1 Announce Type: cross 
Abstract: Stochastic versions of recursive integrated climate-economy assessment models are essential for studying and quantifying policy decisions under uncertainty. However, as the number of stochastic shocks increases, solving these models as dynamic programming problems using deterministic grid methods becomes computationally infeasible, and simulation-based methods are needed. The least-squares Monte Carlo (LSMC) method has become popular for solving optimal stochastic control problems in quantitative finance. In this paper, we extend the application of the LSMC method to stochastic climate-economy models. We exemplify this approach using a stochastic version of the DICE model with all five main uncertainties discussed in the literature. To address the complexity and high dimensionality of these models, we incorporate deep neural network approximations in place of standard regression techniques within the LSMC framework. Our results demonstrate that the deep LSMC method can be used to efficiently derive optimal policies for climate-economy models in the presence of uncertainty.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09642v1</guid>
      <category>econ.GN</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <category>q-fin.EC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aleksandar Arandjelovi\'c, Pavel V. Shevchenko, Tomoko Matsui, Daisuke Murakami, Tor A. Myrvoll</dc:creator>
    </item>
    <item>
      <title>Regularization for Adversarial Robust Learning</title>
      <link>https://arxiv.org/abs/2408.09672</link>
      <description>arXiv:2408.09672v1 Announce Type: cross 
Abstract: Despite the growing prevalence of artificial neural networks in real-world applications, their vulnerability to adversarial attacks remains to be a significant concern, which motivates us to investigate the robustness of machine learning models. While various heuristics aim to optimize the distributionally robust risk using the $\infty$-Wasserstein metric, such a notion of robustness frequently encounters computation intractability. To tackle the computational challenge, we develop a novel approach to adversarial training that integrates $\phi$-divergence regularization into the distributionally robust risk function. This regularization brings a notable improvement in computation compared with the original formulation. We develop stochastic gradient methods with biased oracles to solve this problem efficiently, achieving the near-optimal sample complexity. Moreover, we establish its regularization effects and demonstrate it is asymptotic equivalence to a regularized empirical risk minimization (ERM) framework, by considering various scaling regimes of the regularization parameter $\eta$ and robustness level $\rho$. These regimes yield gradient norm regularization, variance regularization, or a smoothed gradient norm regularization that interpolates between these extremes. We numerically validate our proposed method in supervised learning, reinforcement learning, and contextual learning and showcase its state-of-the-art performance against various adversarial attacks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09672v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jie Wang, Rui Gao, Yao Xie</dc:creator>
    </item>
    <item>
      <title>Faster Adaptive Decentralized Learning Algorithms</title>
      <link>https://arxiv.org/abs/2408.09775</link>
      <description>arXiv:2408.09775v1 Announce Type: cross 
Abstract: Decentralized learning recently has received increasing attention in machine learning due to its advantages in implementation simplicity and system robustness, data privacy. Meanwhile, the adaptive gradient methods show superior performances in many machine learning tasks such as training neural networks. Although some works focus on studying decentralized optimization algorithms with adaptive learning rates, these adaptive decentralized algorithms still suffer from high sample complexity. To fill these gaps, we propose a class of faster adaptive decentralized algorithms (i.e., AdaMDOS and AdaMDOF) for distributed nonconvex stochastic and finite-sum optimization, respectively. Moreover, we provide a solid convergence analysis framework for our methods. In particular, we prove that our AdaMDOS obtains a near-optimal sample complexity of $\tilde{O}(\epsilon^{-3})$ for finding an $\epsilon$-stationary solution of nonconvex stochastic optimization. Meanwhile, our AdaMDOF obtains a near-optimal sample complexity of $O(\sqrt{n}\epsilon^{-2})$ for finding an $\epsilon$-stationary solution of nonconvex finite-sum optimization, where $n$ denotes the sample size. To the best of our knowledge, our AdaMDOF algorithm is the first adaptive decentralized algorithm for nonconvex finite-sum optimization. Some experimental results demonstrate efficiency of our algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09775v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Feihu Huang, Jianyu Zhao</dc:creator>
    </item>
    <item>
      <title>Unsupervised Machine Learning Hybrid Approach Integrating Linear Programming in Loss Function: A Robust Optimization Technique</title>
      <link>https://arxiv.org/abs/2408.09967</link>
      <description>arXiv:2408.09967v1 Announce Type: cross 
Abstract: This paper presents a novel hybrid approach that integrates linear programming (LP) within the loss function of an unsupervised machine learning model. By leveraging the strengths of both optimization techniques and machine learning, this method introduces a robust framework for solving complex optimization problems where traditional methods may fall short. The proposed approach encapsulates the constraints and objectives of a linear programming problem directly into the loss function, guiding the learning process to adhere to these constraints while optimizing the desired outcomes. This technique not only preserves the interpretability of linear programming but also benefits from the flexibility and adaptability of machine learning, making it particularly well-suited for unsupervised or semi-supervised learning scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09967v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrew Kiruluta, Andreas Lemos</dc:creator>
    </item>
    <item>
      <title>Preference-Optimized Pareto Set Learning for Blackbox Optimization</title>
      <link>https://arxiv.org/abs/2408.09976</link>
      <description>arXiv:2408.09976v1 Announce Type: cross 
Abstract: Multi-Objective Optimization (MOO) is an important problem in real-world applications. However, for a non-trivial problem, no single solution exists that can optimize all the objectives simultaneously. In a typical MOO problem, the goal is to find a set of optimum solutions (Pareto set) that trades off the preferences among objectives. Scalarization in MOO is a well-established method for finding a finite set approximation of the whole Pareto set (PS). However, in real-world experimental design scenarios, it's beneficial to obtain the whole PS for flexible exploration of the design space. Recently Pareto set learning (PSL) has been introduced to approximate the whole PS. PSL involves creating a manifold representing the Pareto front of a multi-objective optimization problem. A naive approach includes finding discrete points on the Pareto front through randomly generated preference vectors and connecting them by regression. However, this approach is computationally expensive and leads to a poor PS approximation. We propose to optimize the preference points to be distributed evenly on the Pareto front. Our formulation leads to a bilevel optimization problem that can be solved by e.g. differentiable cross-entropy methods. We demonstrated the efficacy of our method for complex and difficult black-box MOO problems using both synthetic and real-world benchmark data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09976v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhang Haishan, Diptesh Das, Koji Tsuda</dc:creator>
    </item>
    <item>
      <title>Deterministic Policy Gradient Primal-Dual Methods for Continuous-Space Constrained MDPs</title>
      <link>https://arxiv.org/abs/2408.10015</link>
      <description>arXiv:2408.10015v1 Announce Type: cross 
Abstract: We study the problem of computing deterministic optimal policies for constrained Markov decision processes (MDPs) with continuous state and action spaces, which are widely encountered in constrained dynamical systems. Designing deterministic policy gradient methods in continuous state and action spaces is particularly challenging due to the lack of enumerable state-action pairs and the adoption of deterministic policies, hindering the application of existing policy gradient methods for constrained MDPs. To this end, we develop a deterministic policy gradient primal-dual method to find an optimal deterministic policy with non-asymptotic convergence. Specifically, we leverage regularization of the Lagrangian of the constrained MDP to propose a deterministic policy gradient primal-dual (D-PGPD) algorithm that updates the deterministic policy via a quadratic-regularized gradient ascent step and the dual variable via a quadratic-regularized gradient descent step. We prove that the primal-dual iterates of D-PGPD converge at a sub-linear rate to an optimal regularized primal-dual pair. We instantiate D-PGPD with function approximation and prove that the primal-dual iterates of D-PGPD converge at a sub-linear rate to an optimal regularized primal-dual pair, up to a function approximation error. Furthermore, we demonstrate the effectiveness of our method in two continuous control problems: robot navigation and fluid control. To the best of our knowledge, this appears to be the first work that proposes a deterministic policy search method for continuous-space constrained MDPs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.10015v1</guid>
      <category>cs.AI</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sergio Rozada, Dongsheng Ding, Antonio G. Marques, Alejandro Ribeiro</dc:creator>
    </item>
    <item>
      <title>Near-Optimal Mechanisms for Resource Allocation Without Monetary Transfers</title>
      <link>https://arxiv.org/abs/2408.10066</link>
      <description>arXiv:2408.10066v1 Announce Type: cross 
Abstract: We study the problem in which a central planner sequentially allocates a single resource to multiple strategic agents using their utility reports at each round, but without using any monetary transfers. We consider general agent utility distributions and two standard settings: a finite horizon $T$ and an infinite horizon with $\gamma$ discounts. We provide general tools to characterize the convergence rate between the optimal mechanism for the central planner and the first-best allocation if true agent utilities were available. This heavily depends on the utility distributions, yielding rates anywhere between $1/\sqrt T$ and $1/T$ for the finite-horizon setting, and rates faster than $\sqrt{1-\gamma}$, including exponential rates for the infinite-horizon setting as agents are more patient $\gamma\to 1$. On the algorithmic side, we design mechanisms based on the promised-utility framework to achieve these rates and leverage structure on the utility distributions. Intuitively, the more flexibility the central planner has to reward or penalize any agent while incurring little social welfare cost, the faster the convergence rate. In particular, discrete utility distributions typically yield the slower rates $1/\sqrt T$ and $\sqrt{1-\gamma}$, while smooth distributions with density typically yield faster rates $1/T$ (up to logarithmic factors) and $1-\gamma$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.10066v1</guid>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Moise Blanchard, Patrick Jaillet</dc:creator>
    </item>
    <item>
      <title>Quantized Distributed Nonconvex Optimization Algorithms with Linear Convergence under the Polyak--${\L}$ojasiewicz Condition</title>
      <link>https://arxiv.org/abs/2207.08106</link>
      <description>arXiv:2207.08106v3 Announce Type: replace 
Abstract: This paper considers distributed optimization for minimizing the average of local nonconvex cost functions, by using local information exchange over undirected communication networks. To reduce the required communication capacity, we introduce an encoder--decoder scheme. By integrating them with distributed gradient tracking and proportional integral algorithms, respectively, we then propose two quantized distributed nonconvex optimization algorithms. Assuming the global cost function satisfies the Polyak--{\L}ojasiewicz condition, which does not require the global cost function to be convex and the global minimizer is not necessarily unique, we show that our proposed algorithms linearly converge to a global optimal point and that larger quantization level leads to faster convergence speed. Moreover, we show that a low data rate is sufficient to guarantee linear convergence when the algorithm parameters are properly chosen. The theoretical results are illustrated by numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2207.08106v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lei Xu, Xinlei Yi, Jiayue Sun, Yang Shi, Karl H. Johansson, Tao Yang</dc:creator>
    </item>
    <item>
      <title>On Distributionally Robust Multistage Convex Optimization: Data-driven Models and Performance</title>
      <link>https://arxiv.org/abs/2210.08433</link>
      <description>arXiv:2210.08433v2 Announce Type: replace 
Abstract: This paper presents a novel algorithmic study with extensive numerical experiments of distributionally robust multistage convex optimization (DR-MCO). Following the previous work on dual dynamic programming (DDP) algorithmic framework for DR-MCO, we focus on data-driven DR-MCO models with Wasserstein ambiguity sets that allow probability measures with infinite supports. These data-driven Wasserstein DR-MCO models have out-of-sample performance guarantees and adjustable in-sample conservatism. Then by exploiting additional concavity or convexity in the uncertain cost functions, we design exact single stage subproblem oracle (SSSO) implementations that ensure the convergence of DDP algorithms. We test the data-driven Wasserstein DR-MCO models against multistage robust convex optimization (MRCO), risk-neutral and risk-averse multistage stochastic convex optimization (MSCO) models on multi-commodity inventory problems and hydro-thermal power planning problems. The results show that our DR-MCO models could outperform MRCO and MSCO models when the data size is small.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.08433v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shixuan Zhang, Xu Andy Sun</dc:creator>
    </item>
    <item>
      <title>Generalized Hukuhara directional differentiability of interval-valued functions on Riemannian manifolds</title>
      <link>https://arxiv.org/abs/2212.04541</link>
      <description>arXiv:2212.04541v4 Announce Type: replace 
Abstract: In this paper, we show that generalized Hukuhara directional differentiability of an interval-valued function (IVF) defined on Riemannian manifolds is not equivalent to the directional differentiability of its center and half-width functions and hence not to its end point functions. This contrasts with S.-L. Chen's \cite{chen} assertion which says the equivalence holds in terms of endpoint functions of an IVF which is defined on a Hadamard manifold. Additionally, the paper addresses some other inaccuracies which arise when assuming the convexity of a function at a single point in its domain. In light of these arguments, the paper presents some basic results that relate to both the convexity and directional differentiability of an IVF.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.04541v4</guid>
      <category>math.OC</category>
      <category>math.DG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hilal Ahmad Bhat, Akhlad Iqbal</dc:creator>
    </item>
    <item>
      <title>A simple uniformly optimal method without line search for convex optimization</title>
      <link>https://arxiv.org/abs/2310.10082</link>
      <description>arXiv:2310.10082v3 Announce Type: replace 
Abstract: Line search (or backtracking) procedures have been widely employed into first-order methods for solving convex optimization problems, especially those with unknown problem parameters (e.g., Lipschitz constant). In this paper, we show that line search is superfluous in attaining the optimal rate of convergence for solving a convex optimization problem whose parameters are not given a priori. In particular, we present a novel accelerated gradient descent type algorithm called auto-conditioned fast gradient method (AC-FGM) that can achieve an optimal $\mathcal{O}(1/k^2)$ rate of convergence for smooth convex optimization without requiring the estimate of a global Lipschitz constant or the employment of line search procedures. We then extend AC-FGM to solve convex optimization problems with H\"{o}lder continuous gradients and show that it automatically achieves the optimal rates of convergence uniformly for all problem classes with the desired accuracy of the solution as the only input. Finally, we report some encouraging numerical results that demonstrate the advantages of AC-FGM over the previously developed parameter-free methods for convex optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.10082v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tianjiao Li, Guanghui Lan</dc:creator>
    </item>
    <item>
      <title>Variational Properties of Decomposable Functions. Part I: Strict Epi-Calculus and Applications</title>
      <link>https://arxiv.org/abs/2311.07267</link>
      <description>arXiv:2311.07267v2 Announce Type: replace 
Abstract: This work provides a systematic study of the variational properties of decomposable functions which are compositions of an outer support function and an inner smooth mapping under certain constraint qualifications. A particular focus is put on the strict twice epi-differentiability and the associated strict second subderivative of such functions. A lower bound for the strict second subderivative of decomposable functions is derived which allows linking the strict second subderivative of decomposable mappings to the simpler outer support function. Leveraging the variational properties of the support function, we establish the equivalence between the strict twice epi-differentiability of decomposable functions, continuous differentiability of the proximity operator, and the strict complementarity condition. As an application, this allows us to fully characterize the strict saddle point property of decomposable functions. In addition, an explicit formula for the strict second subderivative of decomposable functions is derived if the outer support set is sufficiently regular. This yields an alternative characterization of the strong metric regularity of the subdifferential of decomposable functions at a local minimizer. Finally, we verify that the introduced regularity conditions are satisfied by many practical functions and applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.07267v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenqing Ouyang, Andre Milzarek</dc:creator>
    </item>
    <item>
      <title>Variational Properties of Decomposable Functions. Part II: Strong Second-Order Theory</title>
      <link>https://arxiv.org/abs/2311.07276</link>
      <description>arXiv:2311.07276v2 Announce Type: replace 
Abstract: Local superlinear convergence of the semismooth Newton method usually necessitates assumptions on the uniform invertibility of the utilized, generalized Jacobian matrices, such as, e.g., BD- or CD-regularity. For certain composite-type problems and nonlinear programs (for which explicit representations of the generalized Jacobians of the associated stationarity equations are available), such regularity assumptions are closely connected to strong second-order sufficient conditions. However, general characterizations are not well understood. In this paper, we investigate a strong second-order sufficient condition ($\mathrm{SSOSC}$) for composite problems whose nonsmooth part has a generalized conic-quadratic second subderivative. We discuss the relationship between the $\mathrm{SSOSC}$ and other second order-type conditions that involve the generalized Jacobians of the normal map. In particular, these two conditions are equivalent under certain structural assumptions on the generalized Jacobian matrix of the proximity operator. Leveraging second-order variational techniques and properties, we then verify that the introduced structural conditions hold for a broad class of $C^2$-strictly decomposable functions. Finally, it is shown that the $\mathrm{SSOSC}$ is further equivalent to the strong metric regularity of the subdifferential, the normal map, and the natural residual.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.07276v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenqing Ouyang, Andre Milzarek</dc:creator>
    </item>
    <item>
      <title>Risk-Aware Control of Discrete-Time Stochastic Systems: Integrating Kalman Filter and Worst-case CVaR in Control Barrier Functions</title>
      <link>https://arxiv.org/abs/2312.15638</link>
      <description>arXiv:2312.15638v2 Announce Type: replace 
Abstract: This paper proposes control approaches for discrete-time linear systems subject to stochastic disturbances. It employs Kalman filter to estimate the mean and covariance of the state propagation, and the worst-case conditional value-at-risk (CVaR) to quantify the tail risk using the estimated mean and covariance. The quantified risk is then integrated into a control barrier function (CBF) to derive constraints for controller synthesis, addressing tail risks near safe set boundaries. Two optimization-based control methods are presented using the obtained constraints for half-space and ellipsoidal safe sets, respectively. The effectiveness of the obtained results is demonstrated using numerical simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.15638v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Masako Kishida</dc:creator>
    </item>
    <item>
      <title>An Augmented Lagrangian Method for Training Recurrent Neural Networks</title>
      <link>https://arxiv.org/abs/2402.13687</link>
      <description>arXiv:2402.13687v2 Announce Type: replace 
Abstract: Recurrent Neural Networks (RNNs) are widely used to model sequential data in a wide range of areas, such as natural language processing, speech recognition, machine translation, and time series analysis. In this paper, we model the training process of RNNs with the ReLU activation function as a constrained optimization problem with a smooth nonconvex objective function and piecewise smooth nonconvex constraints. We prove that any feasible point of the optimization problem satisfies the no nonzero abnormal multiplier constraint qualification (NNAMCQ), and any local minimizer is a Karush-Kuhn-Tucker (KKT) point of the problem. Moreover, we propose an augmented Lagrangian method (ALM) and design an efficient block coordinate descent (BCD) method to solve the subproblems of the ALM. The update of each block of the BCD method has a closed-form solution. The stop criterion for the inner loop is easy to check and can be stopped in finite steps. Moreover, we show that the BCD method can generate a directional stationary point of the subproblem. Furthermore, we establish the global convergence of the ALM to a KKT point of the constrained optimization problem. Compared with the state-of-the-art algorithms, numerical results demonstrate the efficiency and effectiveness of the ALM for training RNNs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.13687v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yue Wang, Chao Zhang, Xiaojun Chen</dc:creator>
    </item>
    <item>
      <title>PhiBE: A PDE-based Bellman Equation for Continuous Time Policy Evaluation</title>
      <link>https://arxiv.org/abs/2405.12535</link>
      <description>arXiv:2405.12535v2 Announce Type: replace 
Abstract: In this paper, we address the problem of continuous-time reinforcement learning in scenarios where the dynamics follow a stochastic differential equation. When the underlying dynamics remain unknown and we have access only to discrete-time information, how can we effectively conduct policy evaluation? We first highlight that the commonly used Bellman equation (BE) is not always a reliable approximation to the true value function. We then introduce a new bellman equation, PhiBE, which integrates the discrete-time information into a PDE formulation. The new bellman equation offers a more accurate approximation to the true value function, especially in scenarios where the underlying dynamics change slowly. Moreover, we extend PhiBE to higher orders, providing increasingly accurate approximations. We conduct the error analysis for both BE and PhiBE with explicit dependence on the discounted coefficient, the reward and the dynamics. Additionally, we present a model-free algorithm to solve PhiBE when only discrete-time trajectory data is available. Numerical experiments are provided to validate the theoretical guarantees we propose.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12535v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuhua Zhu</dc:creator>
    </item>
    <item>
      <title>A structured L-BFGS method with diagonal scaling and its application to image registration</title>
      <link>https://arxiv.org/abs/2405.19834</link>
      <description>arXiv:2405.19834v2 Announce Type: replace 
Abstract: We devise an L-BFGS method for optimization problems in which the objective is the sum of two functions, where the Hessian of the first function is computationally unavailable while the Hessian of the second function has a computationally available approximation that allows for cheap matrix-vector products. This is a prototypical setting for many inverse problems. The proposed L-BFGS method exploits the structure of the objective to construct a more accurate Hessian approximation than in standard L-BFGS. In contrast to existing works on structured L-BFGS, we choose the first part of the seed matrix, which approximates the Hessian of the first function, as a diagonal matrix rather than a multiple of the identity. We derive two suitable formulas for the coefficients of the diagonal matrix and show that this boosts performance on real-life image registration problems, which are highly non-convex inverse problems. The new method converges globally and linearly on non-convex problems under mild assumptions in a general Hilbert space setting, making it applicable to a broad class of inverse problems. An implementation of the method is freely available.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.19834v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Florian Mannel, Hari Om Aggrawal</dc:creator>
    </item>
    <item>
      <title>Reduced-Space Iteratively Reweighted Second-Order Methods for Nonconvex Sparse Regularization</title>
      <link>https://arxiv.org/abs/2407.17216</link>
      <description>arXiv:2407.17216v3 Announce Type: replace 
Abstract: This paper explores a specific type of nonconvex sparsity-promoting regularization problems, namely those involving $\ell_p$-norm regularization, in conjunction with a twice continuously differentiable loss function. We propose a novel second-order algorithm designed to effectively address this class of challenging nonconvex and nonsmooth problems, showcasing several innovative features: (i) The use of an alternating strategy to solve a reweighted $\ell_1$ regularized subproblem and the subspace approximate Newton step. (ii) The reweighted $\ell_1$ regularized subproblem relies on a convex approximation to the nonconvex regularization term, enabling a closed-form solution characterized by the soft-thresholding operator. This feature allows our method to be applied to various nonconvex regularization problems. (iii) Our algorithm ensures that the iterates maintain their sign values and that nonzero components are kept away from 0 for a sufficient number of iterations, eventually transitioning to a perturbed Newton method. (iv) We provide theoretical guarantees of global convergence, local superlinear convergence in the presence of the Kurdyka-\L ojasiewicz (KL) property, and local quadratic convergence when employing the exact Newton step in our algorithm. We also showcase the effectiveness of our approach through experiments on a diverse set of model prediction problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.17216v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hao Wang, Xiangyu Yang, Yichen Zhu</dc:creator>
    </item>
    <item>
      <title>A Formal Perspective on Byte-Pair Encoding</title>
      <link>https://arxiv.org/abs/2306.16837</link>
      <description>arXiv:2306.16837v2 Announce Type: replace-cross 
Abstract: Byte-Pair Encoding (BPE) is a popular algorithm used for tokenizing data in NLP, despite being devised initially as a compression method. BPE appears to be a greedy algorithm at face value, but the underlying optimization problem that BPE seeks to solve has not yet been laid down. We formalize BPE as a combinatorial optimization problem. Via submodular functions, we prove that the iterative greedy version is a $\frac{1}{{\sigma(\boldsymbol{\mu}^\star)}}(1-e^{-{\sigma(\boldsymbol{\mu}^\star)}})$-approximation of an optimal merge sequence, where ${\sigma(\boldsymbol{\mu}^\star)}$ is the total backward curvature with respect to the optimal merge sequence $\boldsymbol{\mu}^\star$. Empirically the lower bound of the approximation is $\approx 0.37$.
  We provide a faster implementation of BPE which improves the runtime complexity from $\mathcal{O}\left(N M\right)$ to $\mathcal{O}\left(N \log M\right)$, where $N$ is the sequence length and $M$ is the merge count. Finally, we optimize the brute-force algorithm for optimal BPE using memoization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.16837v2</guid>
      <category>cs.CL</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vil\'em Zouhar, Clara Meister, Juan Luis Gastaldi, Li Du, Tim Vieira, Mrinmaya Sachan, Ryan Cotterell</dc:creator>
    </item>
    <item>
      <title>Accurate, scalable, and efficient Bayesian optimal experimental design with derivative-informed neural operators</title>
      <link>https://arxiv.org/abs/2312.14810</link>
      <description>arXiv:2312.14810v3 Announce Type: replace-cross 
Abstract: We consider optimal experimental design (OED) problems in selecting the most informative observation sensors to estimate model parameters in a Bayesian framework. Such problems are computationally prohibitive when the parameter-to-observable (PtO) map is expensive to evaluate, the parameters are high-dimensional, and the optimization for sensor selection is combinatorial and high-dimensional. To address these challenges, we develop an accurate, scalable, and efficient computational framework based on derivative-informed neural operators (DINO). We propose to use derivative-informed dimension reduction to reduce the parameter dimensions, based on which we train DINO with derivative information as an accurate and efficient surrogate for the PtO map and its derivative. Moreover, we derive DINO-enabled efficient formulations in computing the maximum a posteriori (MAP) point, the eigenvalues of approximate posterior covariance, and three commonly used optimality criteria for the OED problems. Furthermore, we provide detailed error analysis for the approximations of the MAP point, the eigenvalues, and the optimality criteria. We also propose a modified swapping greedy algorithm for the sensor selection optimization and demonstrate that the proposed computational framework is scalable to preserve the accuracy for increasing parameter dimensions and achieves high computational efficiency, with an over 1000$\times$ speedup accounting for both offline construction and online evaluation costs, compared to high-fidelity Bayesian OED solutions for a three-dimensional nonlinear convection-diffusion-reaction example with tens of thousands of parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.14810v3</guid>
      <category>cs.CE</category>
      <category>math.OC</category>
      <category>stat.ME</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jinwoo Go, Peng Chen</dc:creator>
    </item>
    <item>
      <title>Tractable Optimal Experimental Design using Transport Maps</title>
      <link>https://arxiv.org/abs/2401.07971</link>
      <description>arXiv:2401.07971v3 Announce Type: replace-cross 
Abstract: We present a flexible method for computing Bayesian optimal experimental designs (BOEDs) for inverse problems with intractable posteriors. The approach is applicable to a wide range of BOED problems and can accommodate various optimality criteria, prior distributions and noise models. The key to our approach is the construction of a transport-map-based surrogate to the joint probability law of the design, observational and inference random variables. This order-preserving transport map is constructed using tensor trains and can be used to efficiently sample from (and evaluate approximate densities of) conditional distributions that are required in the evaluation of many commonly-used optimality criteria. The algorithm is also extended to sequential data acquisition problems, where experiments can be performed in sequence to update the state of knowledge about the unknown parameters. The sequential BOED problem is made computationally feasible by preconditioning the approximation of the joint density at the current stage using transport maps constructed at previous stages. The flexibility of our approach in finding optimal designs is illustrated with some numerical examples inspired by disease modeling and the reconstruction of subsurface structures in aquifers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.07971v3</guid>
      <category>stat.CO</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Karina Koval, Roland Herzog, Robert Scheichl</dc:creator>
    </item>
    <item>
      <title>Integrated Optimal Fast Charging and Active Thermal Management of Lithium-Ion Batteries in Extreme Ambient Temperatures</title>
      <link>https://arxiv.org/abs/2404.04358</link>
      <description>arXiv:2404.04358v2 Announce Type: replace-cross 
Abstract: This paper presents an integrated control strategy for optimal fast charging and active thermal management of Lithium-ion batteries in extreme ambient temperatures, striking a balance between charging speed and battery health. A control-oriented thermal-NDC (nonlinear double-capacitor) battery model is proposed to describe the electrical and thermal dynamics, incorporating the effects of both an active thermal source and ambient temperature. A state-feedback model predictive control algorithm is then developed for optimal fast charging and active thermal management. Numerical experiments validate the algorithm under extreme temperatures, showing that the proposed algorithm can energy-efficiently adjust the battery temperature, thereby balancing charging speed and battery health. Additionally, an output-feedback model predictive control algorithm with an extended Kalman filter is proposed for battery charging when states are partially measurable. Numerical experiments validate the effectiveness under extreme temperatures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.04358v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Zehui Lu, Hao Tu, Huazhen Fang, Yebin Wang, Shaoshuai Mou</dc:creator>
    </item>
    <item>
      <title>Existence, Stability and Optimal Drug Dosage for a Reaction-Diffusion System Arising in a Cancer Treatment</title>
      <link>https://arxiv.org/abs/2408.02227</link>
      <description>arXiv:2408.02227v2 Announce Type: replace-cross 
Abstract: In this paper, a reaction-diffusion system modeling injection of a chemotherapeutic drug on the surface of a living tissue during a treatment for cancer patients is studied. The system describes the interaction of the chemotherapeutic drug and the normal, tumor and immune cells. We first establish well-posedness for the nonlinear reaction-diffusion system, then investigate the long-time behavior of solutions. Particularly, it is shown that the cancer cells will be eliminated assuming that its reproduction rate is sufficiently small in a short time period in each treatment interval. The analysis is then essentially exploited to study an optimal drug injection rate problem during a chemotherapeutic drug treatment for tumor cells, which is formulated as an optimal boundary control problem with constraints. For this, we show that the existence of an optimal drug injection rate through the boundary, and derive the first-order optimality condition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02227v2</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Jeff Morgan, Bao Quoc Tang, Hong-Ming Yin</dc:creator>
    </item>
  </channel>
</rss>
