<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 21 Feb 2025 05:00:18 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Latent computing by biological neural networks: A dynamical systems framework</title>
      <link>https://arxiv.org/abs/2502.14337</link>
      <description>arXiv:2502.14337v1 Announce Type: new 
Abstract: Although individual neurons and neural populations exhibit the phenomenon of representational drift, perceptual and behavioral outputs of many neural circuits can remain stable across time scales over which representational drift is substantial. These observations motivate a dynamical systems framework for neural network activity that focuses on the concept of \emph{latent processing units,} core elements for robust coding and computation embedded in collective neural dynamics. Our theoretical treatment of these latent processing units yields five key attributes of computing through neural network dynamics. First, neural computations that are low-dimensional can nevertheless generate high-dimensional neural dynamics. Second, the manifolds defined by neural dynamical trajectories exhibit an inherent coding redundancy as a direct consequence of the universal computing capabilities of the underlying dynamical system. Third, linear readouts or decoders of neural population activity can suffice to optimally subserve downstream circuits controlling behavioral outputs. Fourth, whereas recordings from thousands of neurons may suffice for near optimal decoding from instantaneous neural activity patterns, experimental access to millions of neurons may be necessary to predict neural ensemble dynamical trajectories across timescales of seconds. Fifth, despite the variable activity of single cells, neural networks can maintain stable representations of the variables computed by the latent processing units, thereby making computations robust to representational drift. Overall, our framework for latent computation provides an analytic description and empirically testable predictions regarding how large systems of neurons perform robust computations via their collective dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.14337v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fatih Dinc, Marta Blanco-Pozo, David Klindt, Francisco Acosta, Yiqi Jiang, Sadegh Ebrahimi, Adam Shai, Hidenori Tanaka, Peng Yuan, Mark J. Schnitzer, Nina Miolane</dc:creator>
    </item>
    <item>
      <title>Beyond Performance Scores: Directed Functional Connectivity as a Brain-Based Biomarker for Motor Skill Learning and Retention</title>
      <link>https://arxiv.org/abs/2502.14731</link>
      <description>arXiv:2502.14731v1 Announce Type: new 
Abstract: Motor skill acquisition in fields like surgery, robotics, and sports involves learning complex task sequences through extensive training. Traditional performance metrics, like execution time and error rates, offer limited insight as they fail to capture the neural mechanisms underlying skill learning and retention. This study introduces directed functional connectivity (dFC), derived from electroencephalography (EEG), as a novel brain-based biomarker for assessing motor skill learning and retention. For the first time, dFC is applied as a biomarker to map the stages of the Fitts and Posner motor learning model, offering new insights into the neural mechanisms underlying skill acquisition and retention. Unlike traditional measures, it captures both the strength and direction of neural information flow, providing a comprehensive understanding of neural adaptations across different learning stages. The analysis demonstrates that dFC can effectively identify and track the progression through various stages of the Fitts and Posner model. Furthermore, its stability over a six-week washout period highlights its utility in monitoring long-term retention. No significant changes in dFC were observed in a control group, confirming that the observed neural adaptations were specific to training and not due to external factors. By offering a granular view of the learning process at the group and individual levels, dFC facilitates the development of personalized, targeted training protocols aimed at enhancing outcomes in fields where precision and long-term retention are critical, such as surgical education. These findings underscore the value of dFC as a robust biomarker that complements traditional performance metrics, providing a deeper understanding of motor skill learning and retention.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.14731v1</guid>
      <category>q-bio.NC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anil Kamat, Rahul Rahul, Lora Cavuoto, Harry Burke, Matthew Hackett, Jack Norfleet, Steven Schwaitzberg, Suvranu De</dc:creator>
    </item>
    <item>
      <title>Explanations of Deep Language Models Explain Language Representations in the Brain</title>
      <link>https://arxiv.org/abs/2502.14671</link>
      <description>arXiv:2502.14671v1 Announce Type: cross 
Abstract: Recent advances in artificial intelligence have given rise to large language models (LLMs) that not only achieve human-like performance but also share computational principles with the brain's language processing mechanisms. While previous research has primarily focused on aligning LLMs' internal representations with neural activity, we introduce a novel approach that leverages explainable AI (XAI) methods to forge deeper connections between the two domains. Using attribution methods, we quantified how preceding words contribute to an LLM's next-word predictions and employed these explanations to predict fMRI recordings from participants listening to the same narratives. Our findings demonstrate that attribution methods robustly predict brain activity across the language network, surpassing traditional internal representations in early language areas. This alignment is hierarchical: early-layer explanations correspond to the initial stages of language processing in the brain, while later layers align with more advanced stages. Moreover, the layers more influential on LLM next-word prediction$\unicode{x2014}$those with higher attribution scores$\unicode{x2014}$exhibited stronger alignment with neural activity. This work establishes a bidirectional bridge between AI and neuroscience. First, we demonstrate that attribution methods offer a powerful lens for investigating the neural mechanisms of language comprehension, revealing how meaning emerges from preceding context. Second, we propose using brain alignment as a metric to evaluate the validity of attribution methods, providing a framework for assessing their biological plausibility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.14671v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>q-bio.NC</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Maryam Rahimi (Biomedical Engineering Department, School of Electrical Engineering, Iran University of Science and Technology, Tehran, Iran), Yadollah Yaghoobzadeh (Electrical and Computer Engineering Department, University of Tehran, Tehran, Iran, Tehran Institute for Advanced Studies, Khatam University, Tehran, Iran), Mohammad Reza Daliri (Biomedical Engineering Department, School of Electrical Engineering, Iran University of Science and Technology, Tehran, Iran, School of Cognitive Sciences, Institute for Research in Fundamental Sciences, Tehran, Iran)</dc:creator>
    </item>
    <item>
      <title>A Relativistic Theory of Consciousness (shortened version)</title>
      <link>https://arxiv.org/abs/2502.07247</link>
      <description>arXiv:2502.07247v3 Announce Type: replace 
Abstract: This paper is a shortened version of the full paper that was published in the journal Frontiers of Psychology in May 2022. In recent decades, the scientific study of consciousness has significantly increased our understanding of this elusive phenomenon. Yet, despite critical development in our understanding of the functional side of consciousness, we still lack a fundamental theory regarding its phenomenal aspect. The phenomenal aspect of consciousness is the first-person answer to what it is like question, and it has thus far proved recalcitrant to direct scientific investigation. The question of how the brain, or any cognitive system, can create conscious experience out of neural representations poses a great conundrum to science. Naturalistic dualists argue that it is composed of a primitive, private, nonreductive element of reality. Illusionists, on the other hand, argue that it is merely a cognitive illusion. We contend that both the dualist and illusionist positions are flawed because they tacitly assume consciousness to be an absolute property that does not depend on the observer. We developed a conceptual and a mathematical argument for a relativistic theory of consciousness in which a system either has or does not have phenomenal consciousness with respect to some observer. According to the theory, Phenomenal consciousness is neither private nor delusional, just relativistic. In the frame of reference of the cognitive system, it will be observable (first-person perspective) and in other frame of reference it will not (third-person perspective). These two cognitive frames of reference are both correct, just as in the case of an observer that claims to be at rest while another will claim that the observer has constant velocity. Neither observer position can be privileged, as they both describe the same underlying reality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.07247v3</guid>
      <category>q-bio.NC</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.3389/fpsyg.2021.704270</arxiv:DOI>
      <arxiv:journal_reference>A Relativistic theory of consciousness." Frontiers in Psychology 12 (2022): 704270</arxiv:journal_reference>
      <dc:creator>Nir Lahav, Zachariah A. Neemeh</dc:creator>
    </item>
    <item>
      <title>Emergence of the Primacy Effect in Structured State-Space Models</title>
      <link>https://arxiv.org/abs/2502.13729</link>
      <description>arXiv:2502.13729v2 Announce Type: replace-cross 
Abstract: Human and animal memory for sequentially presented items is well-documented to be more accurate for those at the beginning and end of the sequence, phenomena known as the primacy and recency effects, respectively. By contrast, artificial neural network (ANN) models are typically designed with a memory that decays monotonically over time. Accordingly, ANNs are expected to show the recency effect but not the primacy effect. Contrary to this theoretical expectation, however, the present study reveals a counterintuitive finding: a recently developed ANN architecture, called structured state-space models, exhibits the primacy effect when trained and evaluated on a synthetic task that mirrors psychological memory experiments. Given that this model was originally designed for recovering neuronal activity patterns observed in biological brains, this result provides a novel perspective on the psychological primacy effect while also posing a non-trivial puzzle for the current theories in machine learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13729v2</guid>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <category>q-bio.NC</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Takashi Morita</dc:creator>
    </item>
  </channel>
</rss>
