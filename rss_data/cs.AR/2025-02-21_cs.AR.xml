<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.AR updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.AR</link>
    <description>cs.AR updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.AR" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 21 Feb 2025 05:00:00 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>NDPage: Efficient Address Translation for Near-Data Processing Architectures via Tailored Page Table</title>
      <link>https://arxiv.org/abs/2502.14220</link>
      <description>arXiv:2502.14220v1 Announce Type: new 
Abstract: Near-Data Processing (NDP) has been a promising architectural paradigm to address the memory wall problem for data-intensive applications. Practical implementation of NDP architectures calls for system support for better programmability, where having virtual memory (VM) is critical. Modern computing systems incorporate a 4-level page table design to support address translation in VM. However, simply adopting an existing 4-level page table in NDP systems causes significant address translation overhead because (1) NDP applications generate a lot of address translations, and (2) the limited L1 cache in NDP systems cannot cover the accesses to page table entries (PTEs). We extensively analyze the 4-level page table design in the NDP scenario and observe that (1) the memory access to page table entries is highly irregular, thus cannot benefit from the L1 cache, and (2) the last two levels of page tables are nearly fully occupied. Based on our observations, we propose NDPage, an efficient page table design tailored for NDP systems. The key mechanisms of NDPage are (1) an L1 cache bypass mechanism for PTEs that not only accelerates the memory accesses of PTEs but also prevents the pollution of PTEs in the cache system, and (2) a flattened page table design that merges the last two levels of page tables, allowing the page table to enjoy the flexibility of a 4KB page while reducing the number of PTE accesses. We evaluate NDPage using a variety of data-intensive workloads. Our evaluation shows that in a single-core NDP system, NDPage improves the end-to-end performance over the state-of-the-art address translation mechanism of 14.3\%; in 4-core and 8-core NDP systems, NDPage enhances the performance of 9.8\% and 30.5\%, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.14220v1</guid>
      <category>cs.AR</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Qingcai Jiang, Buxin Tu, Hong An</dc:creator>
    </item>
    <item>
      <title>Micro Blossom: Accelerated Minimum-Weight Perfect Matching Decoding for Quantum Error Correction</title>
      <link>https://arxiv.org/abs/2502.14787</link>
      <description>arXiv:2502.14787v1 Announce Type: new 
Abstract: Minimum-Weight Perfect Matching (MWPM) decoding is important to quantum error correction decoding because of its accuracy. However, many believe that it is difficult, if possible at all, to achieve the microsecond latency requirement posed by superconducting qubits. This work presents the first publicly known MWPM decoder, called Micro Blossom, that achieves sub-microsecond decoding latency. Micro Blossom employs a heterogeneous architecture that carefully partitions a state-of-the-art MWPM decoder between software and a programmable accelerator with parallel processing units, one of each vertex/edge of the decoding graph. On a surface code with code distance $d$ and a circuit-level noise model with physical error rate $p$, Micro Blossom's accelerator employs $O(d^3)$ parallel processing units to reduce the worst-case latency from $O(d^{12})$ to $O(d^9)$ and reduce the average latency from $O(p d^3+1)$ to $O(p^2 d^2+1)$ when $p \ll 1$.
  We report a prototype implementation of Micro Blossom using FPGA. Measured at $d=13$ and $p=0.1\%$, the prototype achieves an average decoding latency of $0.8 \mu s$ at a moderate clock frequency of $62 MHz$. Micro Blossom is the first publicly known hardware-accelerated exact MWPM decoder, and the decoding latency of $0.8 \mu s$ is 8 times shorter than the best latency of MWPM decoder implementations reported in the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.14787v1</guid>
      <category>cs.AR</category>
      <category>quant-ph</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3676641.3716005</arxiv:DOI>
      <arxiv:journal_reference>Proceedings of the 30th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2 (ASPLOS '25), March 30-April 3, 2025, Rotterdam, Netherlands</arxiv:journal_reference>
      <dc:creator>Yue Wu, Namitha Liyanage, Lin Zhong</dc:creator>
    </item>
    <item>
      <title>{\mu}RL: Discovering Transient Execution Vulnerabilities Using Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2502.14307</link>
      <description>arXiv:2502.14307v1 Announce Type: cross 
Abstract: We propose using reinforcement learning to address the challenges of discovering microarchitectural vulnerabilities, such as Spectre and Meltdown, which exploit subtle interactions in modern processors. Traditional methods like random fuzzing fail to efficiently explore the vast instruction space and often miss vulnerabilities that manifest under specific conditions. To overcome this, we introduce an intelligent, feedback-driven approach using RL. Our RL agents interact with the processor, learning from real-time feedback to prioritize instruction sequences more likely to reveal vulnerabilities, significantly improving the efficiency of the discovery process.
  We also demonstrate that RL systems adapt effectively to various microarchitectures, providing a scalable solution across processor generations. By automating the exploration process, we reduce the need for human intervention, enabling continuous learning that uncovers hidden vulnerabilities. Additionally, our approach detects subtle signals, such as timing anomalies or unusual cache behavior, that may indicate microarchitectural weaknesses. This proposal advances hardware security testing by introducing a more efficient, adaptive, and systematic framework for protecting modern processors.
  When unleashed on Intel Skylake-X and Raptor Lake microarchitectures, our RL agent was indeed able to generate instruction sequences that cause significant observable byte leakages through transient execution without generating any $\mu$code assists, faults or interrupts. The newly identified leaky sequences stem from a variety of Intel instructions, e.g. including SERIALIZE, VERR/VERW, CLMUL, MMX-x87 transitions, LSL+RDSCP and LAR. These initial results give credence to the proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.14307v1</guid>
      <category>cs.CR</category>
      <category>cs.AR</category>
      <category>cs.LG</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>M. Caner Tol, Kemal Derya, Berk Sunar</dc:creator>
    </item>
    <item>
      <title>Parallelizing a modern GPU simulator</title>
      <link>https://arxiv.org/abs/2502.14691</link>
      <description>arXiv:2502.14691v1 Announce Type: cross 
Abstract: Simulators are a primary tool in computer architecture research but are extremely computationally intensive. Simulating modern architectures with increased core counts and recent workloads can be challenging, even on modern hardware. This paper demonstrates that simulating some GPGPU workloads in a single-threaded state-of-the-art simulator such as Accel-sim can take more than five days. In this paper we present a simple approach to parallelize this simulator with minimal code changes by using OpenMP. Moreover, our parallelization technique is deterministic, so the simulator provides the same results for single-threaded and multi-threaded simulations. Compared to previous works, we achieve a higher speed-up, and, more importantly, the parallel simulation does not incur any inaccuracies. When we run the simulator with 16 threads, we achieve an average speed-up of 5.8x and reach 14x in some workloads. This allows researchers to simulate applications that take five days in less than 12 hours. By speeding up simulations, researchers can model larger systems, simulate bigger workloads, add more detail to the model, increase the efficiency of the hardware platform where the simulator is run, and obtain results sooner.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.14691v1</guid>
      <category>cs.DC</category>
      <category>cs.AR</category>
      <category>cs.PF</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <arxiv:journal_reference>CAMS 2024</arxiv:journal_reference>
      <dc:creator>Rodrigo Huerta, Antonio Gonz\'alez</dc:creator>
    </item>
    <item>
      <title>Leveraging Error Resilience of Iterative Algorithms for Energy Efficiency: from Concept to Implementation</title>
      <link>https://arxiv.org/abs/2502.14729</link>
      <description>arXiv:2502.14729v1 Announce Type: cross 
Abstract: Iterative algorithms are widely used in digital signal processing applications. With the case study of radio astronomy calibration processing, this work contributes towards revealing and exploiting the intrinsic error resilience of iterative algorithms for energy efficiency benefits. We consider iterative methods that use a convergence criterion as a quality metric to terminate the iterative computations. We propose an adaptive statistical approximation model for high-level resilience analysis that provides an opportunity to divide an iterative algorithm into exact and approximate iterations. We realize an energy-efficient accelerator based on a heterogeneous architecture, where the heterogeneity is introduced using accurate and approximate processing cores. Our proposed methodology exploits the error-resilience of the algorithm, where initial iterations are processed on approximate modules while the later ones on accurate modules. The proposed accelerator design does not increase the number of iterations as compared to that of an accurate counterpart and provides sufficient precision to converge to an acceptable solution. Our implementation using TSMC 40nm Low Power (TCBN40LP) technology shows 23% savings in electrical energy consumption.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.14729v1</guid>
      <category>eess.SP</category>
      <category>cs.AR</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>G. A. Gillani, A. Krapukhin, A. B. J. Kokkeler</dc:creator>
    </item>
  </channel>
</rss>
