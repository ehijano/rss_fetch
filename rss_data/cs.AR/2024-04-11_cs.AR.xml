<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.AR updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.AR</link>
    <description>cs.AR updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.AR" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 12 Apr 2024 04:00:09 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 12 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Block-SSD: A New Block-Based Blocking SSD Architecture</title>
      <link>https://arxiv.org/abs/2404.07228</link>
      <description>arXiv:2404.07228v1 Announce Type: new 
Abstract: Computer science and related fields (e.g., computer engineering, computer hardware engineering, electrical engineering, electrical and computer engineering, computer systems engineering) often draw inspiration from other fields, areas, and the real world in order to describe topics in their area. One cross-domain example is the idea of a block. The idea of blocks comes in many flavors, including software (e.g., process control blocks, file system blocks, data blocks, basic blocks, blocking statements, blocking processes, blocker bugs) and hardware (e.g., NAND flash blocks, cache blocks, logic blocks); however, this makes it difficult to precisely discern what a "block" is. In this work, we make little (negative) effort to disambiguate these terms and propose our own set of overloaded terms to increase the complexity of this paper. To inspire new students to join their research groups, professors often hang posters or other publications along the walls adjacent to their offices. Regrettably, Saugata does not have any posters directly covering his door, leaving prime real estate. Therefore, this underutilized space in the Siebel Center for Computer Science offers substantial opportunities for renovations. To alleviate this concern, we propose Block-SSD. Block-SSD takes a basic block, formed out of a page, and physically combines these blocks into larger blocks. Those blocks are then formed into a larger door block, which cover most of the professor's door. To our knowledge, we are the first to design a block-based blocking Sabotaging Saugata's Door (SSD) architecture.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07228v1</guid>
      <category>cs.AR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ryan Wong, Arjun Tyagi, Sungjun Cho, Pratik Sampat, Yiqiu Sun</dc:creator>
    </item>
    <item>
      <title>Explaining EDA synthesis errors with LLMs</title>
      <link>https://arxiv.org/abs/2404.07235</link>
      <description>arXiv:2404.07235v1 Announce Type: new 
Abstract: Training new engineers in digital design is a challenge, particularly when it comes to teaching the complex electronic design automation (EDA) tooling used in this domain. Learners will typically deploy designs in the Verilog and VHDL hardware description languages to Field Programmable Gate Arrays (FPGAs) from Altera (Intel) and Xilinx (AMD) via proprietary closed-source toolchains (Quartus Prime and Vivado, respectively). These tools are complex and difficult to use -- yet, as they are the tools used in industry, they are an essential first step in this space. In this work, we examine how recent advances in artificial intelligence may be leveraged to address aspects of this challenge. Specifically, we investigate if Large Language Models (LLMs), which have demonstrated text comprehension and question-answering capabilities, can be used to generate novice-friendly explanations of compile-time synthesis error messages from Quartus Prime and Vivado. To perform this study we generate 936 error message explanations using three OpenAI LLMs over 21 different buggy code samples. These are then graded for relevance and correctness, and we find that in approximately 71% of cases the LLMs give correct &amp; complete explanations suitable for novice learners.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07235v1</guid>
      <category>cs.AR</category>
      <category>cs.AI</category>
      <category>cs.PL</category>
      <category>cs.SE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Siyu Qiu, Benjamin Tan, Hammond Pearce</dc:creator>
    </item>
    <item>
      <title>On Reducing the Execution Latency of Superconducting Quantum Processors via Quantum Program Scheduling</title>
      <link>https://arxiv.org/abs/2404.07882</link>
      <description>arXiv:2404.07882v1 Announce Type: new 
Abstract: Quantum computing has gained considerable attention, especially after the arrival of the Noisy Intermediate-Scale Quantum (NISQ) era. Quantum processors and cloud services have been made world-wide increasingly available. Unfortunately, programs on existing quantum processors are often executed in series, and the workload could be heavy to the processor. Typically, one has to wait for hours or even longer to obtain the result of a single quantum program on public quantum cloud due to long queue time. In fact, as the scale grows, the qubit utilization rate of the serial execution mode will further diminish, causing the waste of quantum resources. In this paper, to our best knowledge for the first time, the Quantum Program Scheduling Problem (QPSP) is formulated and introduced to improve the utility efficiency of quantum resources. Specifically, a quantum program scheduling method concerning the circuit width, number of measurement shots, and submission time of quantum programs is proposed to reduce the execution latency. We conduct extensive experiments on a simulated Qiskit noise model, as well as on the Xiaohong (from QuantumCTek) superconducting quantum processor. Numerical results show the effectiveness in both QPU time and turnaround time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07882v1</guid>
      <category>cs.AR</category>
      <category>quant-ph</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenjie Wu, Yiquan Wang, Ge Yan, Yuming Zhao, Junchi Yan</dc:creator>
    </item>
    <item>
      <title>LeapFrog: The Rowhammer Instruction Skip Attack</title>
      <link>https://arxiv.org/abs/2404.07878</link>
      <description>arXiv:2404.07878v1 Announce Type: cross 
Abstract: Since its inception, Rowhammer exploits have rapidly evolved into increasingly sophisticated threats not only compromising data integrity but also the control flow integrity of victim processes. Nevertheless, it remains a challenge for an attacker to identify vulnerable targets (i.e., Rowhammer gadgets), understand the outcome of the attempted fault, and formulate an attack that yields useful results.
  In this paper, we present a new type of Rowhammer gadget, called a LeapFrog gadget, which, when present in the victim code, allows an adversary to subvert code execution to bypass a critical piece of code (e.g., authentication check logic, encryption rounds, padding in security protocols). The Leapfrog gadget manifests when the victim code stores the Program Counter (PC) value in the user or kernel stack (e.g., a return address during a function call) which, when tampered with, re-positions the return address to a location that bypasses a security-critical code pattern.
  This research also presents a systematic process to identify Leapfrog gadgets. This methodology enables the automated detection of susceptible targets and the determination of optimal attack parameters. We first showcase this new attack vector through a practical demonstration on a TLS handshake client/server scenario, successfully inducing an instruction skip in a client application. We then demonstrate the attack on real-world code found in the wild, implementing an attack on OpenSSL.
  Our findings extend the impact of Rowhammer attacks on control flow and contribute to the development of more robust defenses against these increasingly sophisticated threats.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07878v1</guid>
      <category>cs.CR</category>
      <category>cs.AR</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Andrew Adiletta, Caner Tol, Berk Sunar</dc:creator>
    </item>
    <item>
      <title>Beehive: A Flexible Network Stack for Direct-Attached Accelerators</title>
      <link>https://arxiv.org/abs/2403.14770</link>
      <description>arXiv:2403.14770v2 Announce Type: replace 
Abstract: Accelerators have become increasingly popular in datacenters due to their cost, performance, and energy benefits. Direct-attached accelerators, where the network stack is implemented in hardware and network traffic bypasses the main CPU, can further enhance these benefits. However, modern datacenter software network stacks are complex, with interleaved protocol layers, network management functions, as well as virtualization support. They also need to flexibly interpose new layers to support new use cases. By contrast, most hardware network stacks only support basic protocol compatibility and are often difficult to extend due to using fixed processing pipelines.
  This paper proposes Beehive, a new, open-source hardware network stack for direct-attached FPGA accelerators designed to enable flexible and adaptive construction of complex protocol functionality. Our approach is based on a network-on-chip (NoC) substrate, automated tooling for the independent scale-up of protocol elements, compiletime deadlock analysis, and a flexible diagnostics and control plane. Our implementation interoperates with standard Linux TCP and UDP clients, allowing existing RPC clients to interface with the accelerator. We use three applications to illustrate the advantages of our approach: a throughputoriented erasure coding application, an accelerator for distributed consensus operations that reduces the latency and energy cost of linearizability, and TCP live migration support for dynamic server consolidation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.14770v2</guid>
      <category>cs.AR</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Katie Lim, Matthew Giordano, Theano Stavrinos, Baris Kasikci, Tom Anderson</dc:creator>
    </item>
    <item>
      <title>Less is More: Hop-Wise Graph Attention for Scalable and Generalizable Learning on Circuits</title>
      <link>https://arxiv.org/abs/2403.01317</link>
      <description>arXiv:2403.01317v4 Announce Type: replace-cross 
Abstract: While graph neural networks (GNNs) have gained popularity for learning circuit representations in various electronic design automation (EDA) tasks, they face challenges in scalability when applied to large graphs and exhibit limited generalizability to new designs. These limitations make them less practical for addressing large-scale, complex circuit problems. In this work we propose HOGA, a novel attention-based model for learning circuit representations in a scalable and generalizable manner. HOGA first computes hop-wise features per node prior to model training. Subsequently, the hop-wise features are solely used to produce node representations through a gated self-attention module, which adaptively learns important features among different hops without involving the graph topology. As a result, HOGA is adaptive to various structures across different circuits and can be efficiently trained in a distributed manner. To demonstrate the efficacy of HOGA, we consider two representative EDA tasks: quality of results (QoR) prediction and functional reasoning. Our experimental results indicate that (1) HOGA reduces estimation error over conventional GNNs by 46.76% for predicting QoR after logic synthesis; (2) HOGA improves 10.0% reasoning accuracy over GNNs for identifying functional blocks on unseen gate-level netlists after complex technology mapping; (3) The training time for HOGA almost linearly decreases with an increase in computing resources.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.01317v4</guid>
      <category>cs.LG</category>
      <category>cs.AR</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chenhui Deng, Zichao Yue, Cunxi Yu, Gokce Sarar, Ryan Carey, Rajeev Jain, Zhiru Zhang</dc:creator>
    </item>
  </channel>
</rss>
