<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.NA</link>
    <description>math.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 22 May 2024 04:01:50 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 22 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Tensor-Train WENO Scheme for Compressible Flows</title>
      <link>https://arxiv.org/abs/2405.12301</link>
      <description>arXiv:2405.12301v1 Announce Type: new 
Abstract: In this study, we introduce a tensor-train (TT) finite difference WENO method for solving compressible Euler equations. In a step-by-step manner, the tensorization of the governing equations is demonstrated. We also introduce \emph{LF-cross} and \emph{WENO-cross} methods to compute numerical fluxes and the WENO reconstruction using the cross interpolation technique. A tensor-train approach is developed for boundary condition types commonly encountered in Computational Fluid Dynamics (CFD). The performance of the proposed WENO-TT solver is investigated in a rich set of numerical experiments. We demonstrate that the WENO-TT method achieves the theoretical $\text{5}^{\text{th}}$-order accuracy of the classical WENO scheme in smooth problems while successfully capturing complicated shock structures. In an effort to avoid the growth of TT ranks, we propose a dynamic method to estimate the TT approximation error that governs the ranks and overall truncation error of the WENO-TT scheme. Finally, we show that the traditional WENO scheme can be accelerated up to 1000 times in the TT format, and the memory requirements can be significantly decreased for low-rank problems, demonstrating the potential of tensor-train approach for future CFD application. This paper is the first study that develops a finite difference WENO scheme using the tensor-train approach for compressible flows. It is also the first comprehensive work that provides a detailed perspective into the relationship between rank, truncation error, and the TT approximation error for compressible WENO solvers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12301v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mustafa Engin Danis, Duc Truong, Ismael Boureima, Oleg Korobkin, Kim Rasmussen, Boian Alexandrov</dc:creator>
    </item>
    <item>
      <title>Half-closed Discontinuous Galerkin discretisations</title>
      <link>https://arxiv.org/abs/2405.12383</link>
      <description>arXiv:2405.12383v1 Announce Type: new 
Abstract: We introduce the concept of half-closed nodes for nodal Discontinuous Galerkin (DG) discretisations. This is in contrast to more commonly used closed nodes in DG where in each element nodes are placed on every boundary. Half-closed nodes relax this constraint by only requiring nodes on a subset of the boundaries in each element, with this extra freedom in node placement allowing for increased efficiency in the assembly of DG operators. To determine which element boundaries half-closed nodes are placed on we outline a simple procedure based on switch functions. We examine the effect on operator sparsity from using the different types of nodes and show that in particular for the Laplace operator there is no difference in the sparsity from using half-closed or closed nodes. We also discuss in this work some linear solver techniques commonly used for Finite Element or Discontinuous Galerkin methods such as static condensation and block-based methods, and how they can be applied to half-closed DG discretisations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12383v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yulong Pan, Per-Olof Persson</dc:creator>
    </item>
    <item>
      <title>APTT: An accuracy-preserved tensor-train method for the Boltzmann-BGK equation</title>
      <link>https://arxiv.org/abs/2405.12524</link>
      <description>arXiv:2405.12524v1 Announce Type: new 
Abstract: Solving the Boltzmann-BGK equation with traditional numerical methods suffers from high computational and memory costs due to the curse of dimensionality. In this paper, we propose a novel accuracy-preserved tensor-train (APTT) method to efficiently solve the Boltzmann-BGK equation. A second-order finite difference scheme is applied to discretize the Boltzmann-BGK equation, resulting in a tensor algebraic system at each time step. Based on the low-rank TT representation, the tensor algebraic system is then approximated as a TT-based low-rank system, which is efficiently solved using the TT-modified alternating least-squares (TT-MALS) solver. Thanks to the low-rank TT representation, the APTT method can significantly reduce the computational and memory costs compared to traditional numerical methods. Theoretical analysis demonstrates that the APTT method maintains the same convergence rate as that of the finite difference scheme. The convergence rate and efficiency of the APTT method are validated by several benchmark test cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12524v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhitao Zhu, Chuanfu Xiao, Kejun Tang, Jizu Huang, Chao Yang</dc:creator>
    </item>
    <item>
      <title>Implicit-explicit Crank-Nicolson scheme for Oseen's equation at high Reynolds number</title>
      <link>https://arxiv.org/abs/2405.12562</link>
      <description>arXiv:2405.12562v1 Announce Type: new 
Abstract: In this paper we continue the work on implicit-explicit (IMEX) time discretizations for the incompressible Oseen equations that we started in \cite{BGG23} (E. Burman, D. Garg, J. Guzm\`an, {\emph{Implicit-explicit time discretization for Oseen's equation at high Reynolds number with application to fractional step methods}}, SIAM J. Numer. Anal., 61, 2859--2886, 2023). The pressure velocity coupling and the viscous terms are treated implicitly, while the convection term is treated explicitly using extrapolation. Herein we focus on the implicit-explicit Crank-Nicolson method for time discretization. For the discretization in space we consider finite element methods with stabilization on the gradient jumps. The stabilizing terms ensures inf-sup stability for equal order interpolation and robustness at high Reynolds number. Under suitable Courant conditions we prove stability of the implicit-explicit Crank-Nicolson scheme in this regime. The stabilization allows us to prove error estimates of order $O(h^{k+\frac12} + \tau^2)$. Here $h$ is the mesh parameter, $k$ the polynomial order and $\tau$ the time step. Finally we discuss some fractional step methods that are implied by the IMEX scheme. Numerical examples are reported comparing the different methods when applied to the Navier-Stokes' equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12562v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Erik Burman, Deepika Garg, Johnny Guzman</dc:creator>
    </item>
    <item>
      <title>Deep ReLU Neural Network Emulation in High-Frequency Acoustic Scattering</title>
      <link>https://arxiv.org/abs/2405.12624</link>
      <description>arXiv:2405.12624v1 Announce Type: new 
Abstract: We obtain wavenumber-robust error bounds for the deep neural network (DNN) emulation of the solution to the time-harmonic, sound-soft acoustic scattering problem in the exterior of a smooth, convex obstacle in two physical dimensions. The error bounds are based on a boundary reduction of the scattering problem in the unbounded exterior region to its smooth, curved boundary $\Gamma$ using the so-called combined field integral equation (CFIE), a well-posed, second-kind boundary integral equation (BIE) for the field's Neumann datum on $\Gamma$. In this setting, the continuity and stability constants of this formulation are explicit in terms of the (non-dimensional) wavenumber $\kappa$. Using wavenumber-explicit asymptotics of the problem's Neumann datum, we analyze the DNN approximation rate for this problem. We use fully connected NNs of the feed-forward type with Rectified Linear Unit (ReLU) activation. Through a constructive argument we prove the existence of DNNs with an $\epsilon$-error bound in the $L^\infty(\Gamma)$-norm having a small, fixed width and a depth that increases $\textit{spectrally}$ with the target accuracy $\epsilon&gt;0$. We show that for fixed $\epsilon&gt;0$, the depth of these NNs should increase $\textit{poly-logarithmically}$ with respect to the wavenumber $\kappa$ whereas the width of the NN remains fixed. Unlike current computational approaches, such as wavenumber-adapted versions of the Galerkin Boundary Element Method (BEM) with shape- and wavenumber-tailored solution $\textit{ansatz}$ spaces, our DNN approximations do not require any prior analytic information about the scatterer's shape.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12624v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fernando Henr\'iquez, Christoph Schwab</dc:creator>
    </item>
    <item>
      <title>Conditions for tractability of the weighted $L_p$-discrepancy and integration in non-homogeneous tensor product spaces</title>
      <link>https://arxiv.org/abs/2405.12729</link>
      <description>arXiv:2405.12729v1 Announce Type: new 
Abstract: We study tractability properties of the weighted $L_p$-discrepancy. The concept of {\it weighted} discrepancy was introduced by Sloan and Wo\'{z}\-nia\-kowski in 1998 in order to prove a weighted version of the Koksma-Hlawka inequality for the error of quasi-Monte Carlo integration rules. The weights have the aim to model the influence of different coordinates of integrands on the error. A discrepancy is said to be tractable if the information complexity, i.e., the minimal number $N$ of points such that the discrepancy is less than the initial discrepancy times an error threshold $\varepsilon$, does not grow exponentially fast with the dimension. In this case there are various notions of tractabilities used in order to classify the exact rate.
  For even integer parameters $p$ there are sufficient conditions on the weights available in literature, which guarantee the one or other notion of tractability. In the present paper we prove matching sufficient conditions (upper bounds) and neccessary conditions (lower bounds) for polynomial and weak tractability for all $p \in (1, \infty)$.
  The proofs of the lower bounds are based on a general result for the information complexity of integration with positive quadrature formulas for tensor product spaces. In order to demonstrate this lower bound we consider as a second application the integration of tensor products of polynomials of degree at most 2.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12729v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.NT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Erich Novak, Friedrich Pillichshammer</dc:creator>
    </item>
    <item>
      <title>A stable poro-mechanical formulation for Material Point Methods leveraging overlapping meshes and multi-field ghost penalisation</title>
      <link>https://arxiv.org/abs/2405.12814</link>
      <description>arXiv:2405.12814v1 Announce Type: new 
Abstract: The Material Point Method (MPM) is widely used to analyse coupled (solid-water) problems under large deformations/displacements. However, if not addressed carefully, MPM u-p formulations for poro-mechanics can be affected by two major sources of instability. Firstly, inf-sup condition violation can arise when the spaces for the displacement and pressure fields are not chosen correctly, resulting in an unstable pressure field. Secondly, the intrinsic nature of particle-based discretisation makes the MPM an unfitted mesh-based method, which can affect the system's condition number and solvability, particularly when background mesh elements are poorly populated. This work proposes a solution to both problems. The inf-sup condition is avoided using two overlapping meshes, a coarser one for the pressure and a finer one for the displacement. This approach does not require stabilisation of the primary equations since it is stable by design and is particularly valuable for low-order shape functions. As for the system's poor condition number, a face ghost penalisation method is added to both the primary equations, which constitutes a novelty in the context of MPM mixed formulations. This study frequently makes use of the theories of functional analysis or the unfitted Finite Element Method (FEM). Although these theories may not directly apply to the MPM, they provide a robust and logical basis for the research. These rationales are further supported by three numerical examples, which encompass both elastic and elasto-plastic cases and drained and undrained conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12814v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Giuliano Pretti, Robert E. Bird, Nathan D. Gavin, William M. Coombs, Charles E. Augarde</dc:creator>
    </item>
    <item>
      <title>A conservative relaxation Crank-Nicolson finite element method for the Schr\"{o}dinger-Poisson equation</title>
      <link>https://arxiv.org/abs/2405.12848</link>
      <description>arXiv:2405.12848v1 Announce Type: new 
Abstract: In this paper, we propose a novel mass and energy conservative relaxation Crank-Nicolson finite element method for the Schr\"{o}dinger-Poisson equation. Utilizing only a single auxiliary variable, we simultaneously reformulate the distinct nonlinear terms present in both the Schr\"{o}dinger equation and the Poisson equation into their equivalent expressions, constructing an equivalent system to the original Schr\"{o}dinger-Poisson equation. Our proposed scheme, derived from this new system, operates linearly and bypasses the need to solve the nonlinear coupled equation, thus eliminating the requirement for iterative techniques. We in turn rigorously derive error estimates for the proposed scheme, demonstrating second-order accuracy in time and $(k+1)$th order accuracy in space when employing polynomials of degree up to $k$. Numerical experiments validate the accuracy and effectiveness of our method and emphasize its conservation properties over long-time simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12848v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Huini Liu, Nianyu Yi, Peimeng Yin</dc:creator>
    </item>
    <item>
      <title>Computer assisted proofs for transverse heteroclinics by the parameterization method</title>
      <link>https://arxiv.org/abs/2405.12446</link>
      <description>arXiv:2405.12446v1 Announce Type: cross 
Abstract: This work develops a functional analytic framework for making computer assisted arguments involving transverse heteroclinic connecting orbits between hyperbolic periodic solutions of ordinary differential equations. We exploit a Fourier-Taylor approximation of the local stable/unstable manifold of the periodic orbit, combined with a numerical method for solving two point boundary value problems via Chebyshev series approximations. The a-posteriori analysis developed provides mathematically rigorous bounds on all approximation errors, providing both abstract existence results and quantitative information about the true heteroclinic solution. Example calculations are given for both the dissipative Lorenz system and the Hamiltonian Hill Restricted Four Body Problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12446v1</guid>
      <category>math.DS</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maxime Murray, J. D. Mireles James</dc:creator>
    </item>
    <item>
      <title>Lipschitz minimization and the Goldstein modulus</title>
      <link>https://arxiv.org/abs/2405.12655</link>
      <description>arXiv:2405.12655v1 Announce Type: cross 
Abstract: Goldstein's 1977 idealized iteration for minimizing a Lipschitz objective fixes a distance - the step size - and relies on a certain approximate subgradient. That "Goldstein subgradient" is the shortest convex combination of objective gradients at points within that distance of the current iterate. A recent implementable Goldstein-style algorithm allows a remarkable complexity analysis (Zhang et al. 2020), and a more sophisticated variant (Davis and Jiang, 2022) leverages typical objective geometry to force near-linear convergence. To explore such methods, we introduce a new modulus, based on Goldstein subgradients, that robustly measures the slope of a Lipschitz function. We relate near-linear convergence of Goldstein-style methods to linear growth of this modulus at minimizers. We illustrate the idea computationally with a simple heuristic for Lipschitz minimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12655v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Siyu Kong, Adrian S. Lewis</dc:creator>
    </item>
    <item>
      <title>Experimental investigation of trans-scale displacement responses of wrinkle defects in fiber reinforced composite laminates</title>
      <link>https://arxiv.org/abs/2405.12676</link>
      <description>arXiv:2405.12676v1 Announce Type: cross 
Abstract: Wrinkle defects were found widely exist in the field of industrial products, i.e. wind turbine blades and filament-wound composite pressure vessels. The magnitude of wrinkle wavelength varies from several millimeters to over one hundred millimeters. Locating the wrinkle defects and measuring their responses are very important to the assessment of the structures that containing wrinkle defects. A meso-mechanical modeling is presented based on the homogenization method to obtain the effective stiffness of a graded wrinkle. The finite element simulation predicts the trans-scale response of out-of-plane displacement of wrinkled laminates, where the maximum displacement ranges from nanoscale to millimeter scale. Such trans-scale effect requires different measurement approaches to observe the displacement responses. Here we employed Shearography (Speckle Pattern Shearing Interferometry) and fringe projection profilometry (FPP) method respectively according to the different magnitude of displacement. In FPP method, a displacement extraction algorithm was presented to obtain the out-of-plane displacement. The measurement sensitivity and accuracy of Shearography and FPP are compared, which provides a quantitative reference for industrial non-destructive test.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12676v1</guid>
      <category>cs.CV</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Li Ma, Shoulong Wang, Changchen Liu, Ange Wen, Kaidi Ying, Jing Guo</dc:creator>
    </item>
    <item>
      <title>Chordal-NMF with Riemannian Multiplicative Update</title>
      <link>https://arxiv.org/abs/2405.12823</link>
      <description>arXiv:2405.12823v1 Announce Type: cross 
Abstract: Nonnegative Matrix Factorization (NMF) is the problem of approximating a given nonnegative matrix M through the conic combination of two nonnegative low-rank matrices W and H. Traditionally NMF is tackled by optimizing a specific objective function evaluating the quality of the approximation. This assessment is often done based on the Frobenius norm. In this study, we argue that the Frobenius norm as the "point-to-point" distance may not always be appropriate. Due to the nonnegative combination resulting in a polyhedral cone, this conic perspective of NMF may not naturally align with conventional point-to-point distance measures. Hence, a ray-to-ray chordal distance is proposed as an alternative way of measuring the discrepancy between M and WH. This measure is related to the Euclidean distance on the unit sphere, motivating us to employ nonsmooth manifold optimization approaches.
  We apply Riemannian optimization technique to solve chordal-NMF by casting it on a manifold. Unlike existing works on Riemannian optimization that require the manifold to be smooth, the nonnegativity in chordal-NMF is a non-differentiable manifold. We propose a Riemannian Multiplicative Update (RMU) that preserves the convergence properties of Riemannian gradient descent without breaking the smoothness condition on the manifold.
  We showcase the effectiveness of the Chordal-NMF on synthetic datasets as well as real-world multispectral images.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12823v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Flavia Esposito, Andersen Ang</dc:creator>
    </item>
    <item>
      <title>Time-dependent Hamiltonian Simulation via Magnus Expansion: Algorithm and Superconvergence</title>
      <link>https://arxiv.org/abs/2405.12925</link>
      <description>arXiv:2405.12925v1 Announce Type: cross 
Abstract: Hamiltonian simulation becomes more challenging as the underlying unitary becomes more oscillatory. In such cases, an algorithm with commutator scaling and a weak dependence, such as logarithmic, on the derivatives of the Hamiltonian is desired. We introduce a new time-dependent Hamiltonian simulation algorithm based on the Magnus series expansion that exhibits both features. Importantly, when applied to unbounded Hamiltonian simulation in the interaction picture, we prove that the commutator in the second-order algorithm leads to a surprising fourth-order superconvergence, with an error preconstant independent of the number of spatial grids. This extends the qHOP algorithm [An, Fang, Lin, Quantum 2022] based on first-order Magnus expansion, and the proof of superconvergence is based on semiclassical analysis that is of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12925v1</guid>
      <category>quant-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Di Fang, Diyi Liu, Rahul Sarkar</dc:creator>
    </item>
    <item>
      <title>Moving Mesh with Streamline Upwind Petrov-Galerkin (MM-SUPG) Method for Time-dependent Convection-Dominated Convection-Diffusion Problems</title>
      <link>https://arxiv.org/abs/2105.08765</link>
      <description>arXiv:2105.08765v3 Announce Type: replace 
Abstract: Time-dependent convection-diffusion problems is considered, particularly when the diffusivity is very small and sharp layers exist in the solutions. Nonphysical oscillations may occur in the numerical solutions when using regular mesh with standard computational methods. In this work, we develop a moving mesh SUPG (MM-SUPG) method, which integrates the streamline upwind Petrov-Galerkin (SUPG) method with the moving mesh partial differential equation (MMPDE) approach. The proposed method is designed to handle both isotropic and anisotropic diffusivity tensors. For the isotropic case, we focus on improving the stability of the numerical solution by utilizing both artificial diffusion from SUPG and mesh adaptation from MMPDE. And for the anisotropic case, we focus on the positivity of the numerical solution. We introduce a weighted diffusion tensor and develop a new metric tensor to control the mesh movement. We also develop conditions for time step size so that the numerical solution satisfies the discrete maximum principle (DMP). Numerical results demonstrate that the proposed MM-SUPG method provides results better than SUPG with fixed mesh or moving mesh without SUPG.</description>
      <guid isPermaLink="false">oai:arXiv.org:2105.08765v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xianping Li, Matthew McCoy</dc:creator>
    </item>
    <item>
      <title>Hyb Error: A Hybrid Metric Combining Absolute and Relative Errors</title>
      <link>https://arxiv.org/abs/2403.07492</link>
      <description>arXiv:2403.07492v2 Announce Type: replace 
Abstract: Suppose $x$ is an approximation of $y$. This paper proposes using $\frac{|x-y|}{1+|y|}$, named Hyb Error, to measure the error. This metric equals half the harmonic mean of absolute error and relative error, effectively combining their advantages while mitigating their limitations. For example, Hyb Error approaches absolute error as $|y|$ approaches 0, thereby avoiding the exaggeration of relative error, and approaches relative error as $|y|$ approaches infinity, thereby avoiding the exaggeration of absolute error. The Hyb Error of $\epsilon$ is equivalent to $|x-y|=\epsilon+\epsilon |y|$, which implies $\mathrm{isclose}(x,y,\epsilon,\epsilon)=\mathrm{True}$, where ``isclose'' is a common floating-point equality check function in numerical libraries. For sequences, this property makes the Maximum Element-wise Hyb Error (MEHE) a pragmatic error metric that reflects the most significant error and equals the decision boundary of the ``isclose'' function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07492v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Peichen Xie</dc:creator>
    </item>
    <item>
      <title>Monte Carlo Neural PDE Solver for Learning PDEs via Probabilistic Representation</title>
      <link>https://arxiv.org/abs/2302.05104</link>
      <description>arXiv:2302.05104v4 Announce Type: replace-cross 
Abstract: In scenarios with limited available data, training the function-to-function neural PDE solver in an unsupervised manner is essential. However, the efficiency and accuracy of existing methods are constrained by the properties of numerical algorithms, such as finite difference and pseudo-spectral methods, integrated during the training stage. These methods necessitate careful spatiotemporal discretization to achieve reasonable accuracy, leading to significant computational challenges and inaccurate simulations, particularly in cases with substantial spatiotemporal variations. To address these limitations, we propose the Monte Carlo Neural PDE Solver (MCNP Solver) for training unsupervised neural solvers via the PDEs' probabilistic representation, which regards macroscopic phenomena as ensembles of random particles. Compared to other unsupervised methods, MCNP Solver naturally inherits the advantages of the Monte Carlo method, which is robust against spatiotemporal variations and can tolerate coarse step size. In simulating the trajectories of particles, we employ Heun's method for the convection process and calculate the expectation via the probability density function of neighbouring grid points during the diffusion process. These techniques enhance accuracy and circumvent the computational issues associated with Monte Carlo sampling. Our numerical experiments on convection-diffusion, Allen-Cahn, and Navier-Stokes equations demonstrate significant improvements in accuracy and efficiency compared to other unsupervised baselines. The source code will be publicly available at: https://github.com/optray/MCNP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.05104v4</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rui Zhang, Qi Meng, Rongchan Zhu, Yue Wang, Wenlei Shi, Shihua Zhang, Zhi-Ming Ma, Tie-Yan Liu</dc:creator>
    </item>
    <item>
      <title>High-Resolution Cranial Defect Reconstruction by Iterative, Low-Resolution, Point Cloud Completion Transformers</title>
      <link>https://arxiv.org/abs/2308.03813</link>
      <description>arXiv:2308.03813v2 Announce Type: replace-cross 
Abstract: Each year thousands of people suffer from various types of cranial injuries and require personalized implants whose manual design is expensive and time-consuming. Therefore, an automatic, dedicated system to increase the availability of personalized cranial reconstruction is highly desirable. The problem of the automatic cranial defect reconstruction can be formulated as the shape completion task and solved using dedicated deep networks. Currently, the most common approach is to use the volumetric representation and apply deep networks dedicated to image segmentation. However, this approach has several limitations and does not scale well into high-resolution volumes, nor takes into account the data sparsity. In our work, we reformulate the problem into a point cloud completion task. We propose an iterative, transformer-based method to reconstruct the cranial defect at any resolution while also being fast and resource-efficient during training and inference. We compare the proposed methods to the state-of-the-art volumetric approaches and show superior performance in terms of GPU memory consumption while maintaining high-quality of the reconstructed defects.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.03813v2</guid>
      <category>eess.IV</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1007/978-3-031-43996-4_32</arxiv:DOI>
      <arxiv:journal_reference>MICCAI 2023 (LNCS, Vol. 14228)</arxiv:journal_reference>
      <dc:creator>Marek Wodzinski, Mateusz Daniol, Daria Hemmerling, Miroslaw Socha</dc:creator>
    </item>
  </channel>
</rss>
