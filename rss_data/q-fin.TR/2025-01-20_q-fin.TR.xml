<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-fin.TR updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-fin.TR</link>
    <description>q-fin.TR updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-fin.TR" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 20 Jan 2025 05:04:47 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 20 Jan 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>What Drives Liquidity on Decentralized Exchanges? Evidence from the Uniswap Protocol</title>
      <link>https://arxiv.org/abs/2410.19107</link>
      <description>arXiv:2410.19107v2 Announce Type: replace 
Abstract: We study liquidity on decentralized exchanges (DEXs), identifying factors at the platform, blockchain, token pair, and liquidity pool levels with predictive power for market depth metrics. We introduce the v2 counterfactual spread metric, a novel criterion which assesses the degree of liquidity concentration in pools using the ``concentrated liquidity'' mechanism, allowing us to decompose the effect of a factor on market depth into two channels: total value locked (TVL) and concentration. We further explore how external liquidity from competing DEXs and private inventory on DEX aggregators influence market depth. We find that (i) gas prices, returns, and a DEX's share of trading volume affect liquidity through concentration, (ii) internalization of order flow by private market makers affects TVL but not the overall market depth, and (iii) volatility, fee revenue, and markout affect liquidity through both channels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.19107v2</guid>
      <category>q-fin.TR</category>
      <pubDate>Mon, 20 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Brian Z. Zhu, Dingyue Liu, Xin Wan, Gordon Liao, Ciamac C. Moallemi, Brad Bachu</dc:creator>
    </item>
    <item>
      <title>LLM-Based Routing in Mixture of Experts: A Novel Framework for Trading</title>
      <link>https://arxiv.org/abs/2501.09636</link>
      <description>arXiv:2501.09636v2 Announce Type: replace-cross 
Abstract: Recent advances in deep learning and large language models (LLMs) have facilitated the deployment of the mixture-of-experts (MoE) mechanism in the stock investment domain. While these models have demonstrated promising trading performance, they are often unimodal, neglecting the wealth of information available in other modalities, such as textual data. Moreover, the traditional neural network-based router selection mechanism fails to consider contextual and real-world nuances, resulting in suboptimal expert selection. To address these limitations, we propose LLMoE, a novel framework that employs LLMs as the router within the MoE architecture. Specifically, we replace the conventional neural network-based router with LLMs, leveraging their extensive world knowledge and reasoning capabilities to select experts based on historical price data and stock news. This approach provides a more effective and interpretable selection mechanism. Our experiments on multimodal real-world stock datasets demonstrate that LLMoE outperforms state-of-the-art MoE models and other deep neural network approaches. Additionally, the flexible architecture of LLMoE allows for easy adaptation to various downstream tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.09636v2</guid>
      <category>cs.LG</category>
      <category>q-fin.TR</category>
      <pubDate>Mon, 20 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kuan-Ming Liu, Ming-Chih Lo</dc:creator>
    </item>
  </channel>
</rss>
