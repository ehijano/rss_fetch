<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.LO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.LO</link>
    <description>cs.LO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.LO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 02 Feb 2026 05:00:35 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Partial Rewriting and Value Interpretation of Logically Constrained Terms (Full Version)</title>
      <link>https://arxiv.org/abs/2601.22191</link>
      <description>arXiv:2601.22191v1 Announce Type: new 
Abstract: Logically constrained term rewrite systems (LCTRSs) are a rewriting formalism that naturally supports built-in data structures, including integers and bit-vectors. The recent framework of existentially constrained terms and most general constrained rewriting on them (Takahata et al., 2025) has many advantages over the original approach of rewriting constrained terms. In this paper, we introduce partial constrained rewriting, a variant of rewriting existentially constrained terms whose underlying idea has already appeared implicitly in previous analyses and applications of LCTRSs. We examine the differences between these two notions of constrained rewriting. First, we establish a direct correspondence between them, leveraging subsumption and equivalence of constrained terms where appropriate. Then we give characterizations of each of them, using the interpretation of existentially constrained terms by instantiation. We further introduce the novel notion of value interpretation, that highlights subtle differences between partial and most general rewriting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.22191v1</guid>
      <category>cs.LO</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Takahito Aoto, Naoki Nishida, Jonas Sch\"opf</dc:creator>
    </item>
    <item>
      <title>Proof Complexity of Linear Logics</title>
      <link>https://arxiv.org/abs/2601.22393</link>
      <description>arXiv:2601.22393v1 Announce Type: new 
Abstract: Proving proof-size lower bounds for $\mathbf{LK}$, the sequent calculus for classical propositional logic, remains a major open problem in proof complexity. We shed new light on this challenge by isolating the power of structural rules, showing that their combination is extremely stronger than any single rule alone. We establish exponential (resp. sub-exponential) proof-size lower bounds for $\mathbf{LK}$ without contraction (resp. weakening) for formulas with short $\mathbf{LK}$-proofs. Concretely, we work with the Full Lambek calculus with exchange, $\mathbf{FL_e}$, and its contraction-extended variant, $\mathbf{FL_{ec}}$, substructural systems underlying linear logic. We construct families of $\mathbf{FL_e}$-provable (resp. $\mathbf{FL_{ec}}$-provable) formulas that require exponential-size (resp. sub-exponential-size) proofs in affine linear logic $\mathbf{ALL}$ (resp. relevant linear logic $\mathbf{RLL}$), but admit polynomial-size proofs once contraction (resp. weakening) is restored. This yields exponential lower bounds on proof-size of $\mathbf{FL_e}$-provable formulas in $\mathbf{ALL}$ and hence for $\mathbf{MALL}$, $\mathbf{AMALL}$, and full classical linear logic $\mathbf{CLL}$. Finally, we exhibit formulas with polynomial-size $\mathbf{FL_e}$-proofs that nevertheless require exponential-size proofs in cut-free $\mathbf{LK}$, establishing exponential speed-ups between various linear calculi and their cut-free counterparts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.22393v1</guid>
      <category>cs.LO</category>
      <category>cs.CC</category>
      <category>math.LO</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amirhossein Akbar Tabatabai, Raheleh Jalali</dc:creator>
    </item>
    <item>
      <title>LeanArchitect: Automating Blueprint Generation for Humans and AI</title>
      <link>https://arxiv.org/abs/2601.22554</link>
      <description>arXiv:2601.22554v1 Announce Type: new 
Abstract: Large-scale formalization projects in Lean rely on blueprints: structured dependency graphs linking informal mathematical exposition to formal declarations. While blueprints are central to human collaboration, existing tooling treats the informal ($\LaTeX$) and formal (Lean) components as largely decoupled artifacts, leading to maintenance overhead and limiting integration with AI automation. We present LeanArchitect, a Lean package for extracting, managing, and exporting blueprint data directly from Lean code. LeanArchitect introduces a declarative annotation mechanism that associates formal declarations with blueprint metadata, automatically infers dependency information, and generates $\LaTeX$ blueprint content synchronized with the Lean development. This design eliminates duplication between formal and informal representations and eases fine-grained progress tracking for both human contributors and AI-based theorem provers. We demonstrate the practicality of LeanArchitect through the automated conversion of several large existing blueprint-driven projects, and through a human--AI collaboration case study formalizing a multivariate Taylor theorem. Our results show that LeanArchitect improves maintainability, exposes latent inconsistencies in existing blueprints, and provides an effective interface for integrating AI tools into real-world formalization workflows.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.22554v1</guid>
      <category>cs.LO</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas Zhu, Pietro Monticone, Jeremy Avigad, Sean Welleck</dc:creator>
    </item>
    <item>
      <title>A Complete Finitary Refinement Type System for Scott-Open Properties</title>
      <link>https://arxiv.org/abs/2601.23082</link>
      <description>arXiv:2601.23082v1 Announce Type: new 
Abstract: We are interested in proving input-output properties of functions that handle infinite data such as streams or non-wellfounded trees. We provide a finitary refinement type system which is sound and complete for Scott-open properties defined in a fixpoint-like logic. Working on top of Abramsky's Domain Theory in Logical Form, we build from the well-known fact that the Scott domains interpreting recursive types are spectral spaces. The usual symmetry between Scott-open and compact-saturated sets is reflected in logical polarities: positive formulae allow for least fixpoints and define Scott-open properties, while negative formulae allow for greatest fixpoints and define compact-saturated properties. A realizability implication with the usual (contra)variance on polarities allows for non-trivial input-output properties to be formulated as positive formulae on function types.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.23082v1</guid>
      <category>cs.LO</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Colin Riba, Adam Donadille</dc:creator>
    </item>
    <item>
      <title>Formalization of non-Archimedean functional analysis 1: spherically complete spaces</title>
      <link>https://arxiv.org/abs/2601.21734</link>
      <description>arXiv:2601.21734v1 Announce Type: cross 
Abstract: In this article, we present a formalization of spherically complete spaces, which is a fundamental notion in non-archimedean functional analysis. This work includes the equivalent definitions of spherically complete spaces, their basic properties, examples and non-examples such as the field $\mathbf{C}_p$ of $p$-adic complex numbers. As applications, we formalize the Birkhoff-James orthogonality, Hahn-Banach extension theorem and the spherical completion for non-archimedean Banach spaces.
  Code available at https://github.com/YijunYuan/SphericalCompleteness</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21734v1</guid>
      <category>math.NT</category>
      <category>cs.LO</category>
      <category>math.FA</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yijun Yuan</dc:creator>
    </item>
    <item>
      <title>On the computability of cofinal Fra\"iss\'e limits</title>
      <link>https://arxiv.org/abs/2601.22435</link>
      <description>arXiv:2601.22435v1 Announce Type: cross 
Abstract: For any collection of finite structures closed under isomorphism (i.e., an age) which has the Hereditary Property (HP), the Joint Embedding Property (JEP), and the Cofinal Amalgamation Property (CAP), there is a unique (up to isomorphism) countable structure which is cofinally ultrahomogeneous with the given age. Such a structure is called the cofinal Fra\"iss\'e limit of the age.
  In this paper, we consider the computational strength needed to construct the cofinal Fra\"iss\'e limit of a computable age. We show that this construction can always be done using the oracle 0''', and that there are ages that require 0''.
  In contrast, we show that if one assumes the strengthening of (CAP) known as the Amalgamation Property (AP), then the resulting limit, called the Fra\"iss\'e limit, can be constructed from the age using 0'. Our results therefore show that the more general case of cofinal Fra\"iss\'e limits requires greater computational strength than Fra\"iss\'e limits.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.22435v1</guid>
      <category>math.LO</category>
      <category>cs.LO</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nathanael Ackerman, Cameron Freer, Mostafa Mirabi</dc:creator>
    </item>
    <item>
      <title>Recursive Mutexes in Separation Logic</title>
      <link>https://arxiv.org/abs/2601.22557</link>
      <description>arXiv:2601.22557v1 Announce Type: cross 
Abstract: Mutexes (i.e., locks) are well understood in separation logic, and can be specified in terms of either protecting an invariant or atomically changing the state of the lock. In this abstract, we develop the same styles of specifications for \emph{recursive} mutexes, a common variant of mutexes in object-oriented languages such as C++ and Java. A recursive mutex can be acquired any number of times by the same thread, and our specifications treat all acquires/releases uniformly, with clients only needing to determine whether they hold the mutex when accessing the lock invariant.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.22557v1</guid>
      <category>cs.PL</category>
      <category>cs.LO</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>RocqPL 2026-Rocq for Programming Languages</arxiv:journal_reference>
      <dc:creator>Ke Du, William Mansky, Paolo G. Giarrusso, Gregory Malecha</dc:creator>
    </item>
    <item>
      <title>Constraint Satisfaction Problems over Finitely Bounded Homogeneous Structures: a Dichotomy between FO and L-hard</title>
      <link>https://arxiv.org/abs/2601.22691</link>
      <description>arXiv:2601.22691v1 Announce Type: cross 
Abstract: Feder-Vardi conjecture, which proposed that every finite-domain Constraint Satisfaction Problem (CSP) is either in P or it is NP-complete, has been solved independently by Bulatov and Zhuk almost ten years ago. Bodirsky-Pinsker conjecture which states a similar dichotomy for countably infinite first-order reducts of finitely bounded homogeneous structures is wide open.
  In this paper, we prove that CSPs over first-order expansions of finitely bounded homogeneous model-complete cores are either first-order definable (and hence in non-uniform AC$^0$) or L-hard under first-order reduction. It is arguably the most general complexity dichotomy when it comes to the scope of structures within Bodirsky-Pinsker conjecture. Our strategy is that we first give a new proof of Larose-Tesson theorem, which provides a similar dichotomy over finite structures, and then generalize that new proof to infinite structures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.22691v1</guid>
      <category>cs.CC</category>
      <category>cs.LO</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Leonid Dorochko, Micha{\l} Wrona</dc:creator>
    </item>
    <item>
      <title>Profunctorial algebras</title>
      <link>https://arxiv.org/abs/2601.22721</link>
      <description>arXiv:2601.22721v1 Announce Type: cross 
Abstract: We provide a bicategorical generalization of Barr's landmark 1970 paper, in which he describes how to extend Set-monads to relations and uses this to characterize topological spaces as the relational algebras of the ultrafilter monad. With two-sided discrete fibrations playing the role of relations in a bicategory, we first characterize, in terms of exact squares, when pseudomonads on a bicategory extend to its bicategory of two-sided discrete fibrations. As a wide class of examples, we show that every Set-monad induces a pseudomonad on the 2-category of categories satisfying our criterion and thus extending to profunctors. Among these, we then focus on the ultracompletion pseudomonad, whose pseudoalgebras are ultracategories: we characterize the normalized lax algebras of its profunctorial extension as ultraconvergence spaces, a recently-introduced categorification of topological spaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.22721v1</guid>
      <category>math.CT</category>
      <category>cs.LO</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Quentin Aristote, Umberto Tarantino</dc:creator>
    </item>
    <item>
      <title>Names Don't Matter: Symbol-Invariant Transformer for Open-Vocabulary Learning</title>
      <link>https://arxiv.org/abs/2601.23169</link>
      <description>arXiv:2601.23169v1 Announce Type: cross 
Abstract: Current neural architectures lack a principled way to handle interchangeable tokens, i.e., symbols that are semantically equivalent yet distinguishable, such as bound variables. As a result, models trained on fixed vocabularies often struggle to generalize to unseen symbols, even when the underlying semantics remain unchanged. We propose a novel Transformer-based mechanism that is provably invariant to the renaming of interchangeable tokens. Our approach employs parallel embedding streams to isolate the contribution of each interchangeable token in the input, combined with an aggregated attention mechanism that enables structured information sharing across streams. Experimental results confirm the theoretical guarantees of our method and demonstrate substantial performance gains on open-vocabulary tasks that require generalization to novel symbols.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.23169v1</guid>
      <category>cs.LG</category>
      <category>cs.LO</category>
      <category>cs.SC</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>\.Ilker I\c{s}{\i}k, Wenchao Li</dc:creator>
    </item>
    <item>
      <title>Implications of computer science theory for the simulation hypothesis</title>
      <link>https://arxiv.org/abs/2404.16050</link>
      <description>arXiv:2404.16050v4 Announce Type: replace 
Abstract: The simulation hypothesis has recently excited renewed interest in the physics and philosophy communities. However, the hypothesis specifically concerns {\textit{computers}} that simulate physical universes. So to formally investigate the hypothesis, we need to understand it in terms of computer science (CS) theory. In addition we need a formal way to couple CS theory with physics. Here I couple those fields by using the physical Church-Turing thesis. This allow me to exploit Kleene's second recursion, to prove that not only is it possible for {us} to be a simulation being run on a computer, but that we might be in a simulation being run a computer \emph{by us}. In such a ``self-simulation'', there would be two identical instances of us, both equally ``real''. I then use Rice's theorem to derive impossibility results concerning simulation and self-simulation; derive implications for (self-)simulation if we are being simulated in a program using fully homomorphic encryption; and briefly investigate the graphical structure of universes simulating other universes which contain computers running their own simulations. I end by describing some of the possible avenues for future research. While motivated in terms of the simulation hypothesis, the results in this paper are direct consequences of the Church-Turing thesis. So they apply far more broadly than the simulation hypothesis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.16050v4</guid>
      <category>cs.LO</category>
      <category>physics.hist-ph</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>David H. Wolpert</dc:creator>
    </item>
    <item>
      <title>Policies for Fair Exchanges of Resources</title>
      <link>https://arxiv.org/abs/2410.21214</link>
      <description>arXiv:2410.21214v2 Announce Type: replace 
Abstract: People increasingly use digital platforms to exchange resources in accordance with some policies stating what resources users offer and what they require in return. In this paper, we propose a formal model of these environments, focussing on how users' policies are defined and enforced, so ensuring that malicious users cannot take advantage of honest ones. To that end, we introduce the declarative policy language MuAC and equip it with a formal semantics. To determine if a resource exchange is fair, i.e., if it respects the MuAC policies in force, we introduce the non-standard logic MuACL that combines non-linear, linear and contractual aspects, and prove it decidable. Notably, the operator for contractual implication of MuACL is not expressible in linear logic. We define a semantics preserving compilation of MuAC policies into MuACL, thus establishing that exchange fairness is reduced to finding a proof in MuACL. Finally, we show how this approach can be put to work on a blockchain to exchange non-fungible tokens.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.21214v2</guid>
      <category>cs.LO</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lorenzo Ceragioli, Pierpaolo Degano, Letterio Galletta, Luca Vigan\`o</dc:creator>
    </item>
    <item>
      <title>Rewriting Systems on Arbitrary Monoids</title>
      <link>https://arxiv.org/abs/2601.10564</link>
      <description>arXiv:2601.10564v5 Announce Type: replace-cross 
Abstract: In this paper, we introduce monoidal rewriting systems (MRS), an abstraction of string rewriting in which reductions are defined over an arbitrary ambient monoid rather than a free monoid of words. This shift is partly motivated by logic: the class of free monoids is not first-order axiomatizable, so "working in the free setting" cannot be treated internally when applying first-order methods to rewriting presentations.
  To analyze these systems categorically, we define $\mathbf{NCRS_2}$ as the 2-category of Noetherian Confluent MRS. We then prove the existence of a canonical biadjunction between $\mathbf{NCRS_2}$ and $\mathbf{Mon}$.
  Finally, we classify all Noetherian Confluent MRS that present a given fixed monoid. For this, we introduce Generalized Elementary Tietze Transformations (GETTs) and prove that any two presentations of a monoid are connected by a (possibly infinite) sequence of these transformations, yielding a complete characterization of generating systems up to GETT-equivalence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10564v5</guid>
      <category>cs.FL</category>
      <category>cs.LO</category>
      <category>math.CT</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eduardo Magalh\~aes</dc:creator>
    </item>
  </channel>
</rss>
