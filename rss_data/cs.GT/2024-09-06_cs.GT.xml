<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 06 Sep 2024 04:00:18 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 06 Sep 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Subsidy design for better social outcomes</title>
      <link>https://arxiv.org/abs/2409.03129</link>
      <description>arXiv:2409.03129v1 Announce Type: new 
Abstract: Overcoming the impact of selfish behavior of rational players in multiagent systems is a fundamental problem in game theory. Without any intervention from a central agent, strategic users take actions in order to maximize their personal utility, which can lead to extremely inefficient overall system performance, often indicated by a high Price of Anarchy. Recent work (Lin et al. 2021) investigated and formalized yet another undesirable behavior of rational agents, that of avoiding freely available information about the game for selfish reasons, leading to worse social outcomes. A central planner can significantly mitigate these issues by injecting a subsidy to reduce certain costs associated with the system and obtain net gains in the system performance. Crucially, the planner needs to determine how to allocate this subsidy effectively.
  We formally show that designing subsidies that perfectly optimize the social good, in terms of minimizing the Price of Anarchy or preventing the information avoidance behavior, is computationally hard under standard complexity theoretic assumptions. On the positive side, we show that we can learn provably good values of subsidy in repeated games coming from the same domain. This data-driven subsidy design approach avoids solving computationally hard problems for unseen games by learning over polynomially many games. We also show that optimal subsidy can be learned with no-regret given an online sequence of games, under mild assumptions on the cost matrix. Our study focuses on two distinct games: a Bayesian extension of the well-studied fair cost-sharing game, and a component maintenance game with engineering applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.03129v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Fri, 06 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maria-Florina Balcan, Matteo Pozzi, Dravyansh Sharma</dc:creator>
    </item>
    <item>
      <title>A Complete Landscape of EFX Allocations of Mixed Manna on Graphs</title>
      <link>https://arxiv.org/abs/2409.03594</link>
      <description>arXiv:2409.03594v1 Announce Type: new 
Abstract: We study envy-free up to any item (EFX) allocations on graphs where vertices and edges represent agents and items respectively. An agent is only interested in items that are incident to her and all other items have zero marginal values to her. Christodoulou et al. [EC, 2023] first proposed this setting and studied the case of goods. We extend this setting to the case of mixed manna where an item may be liked or disliked by its endpoint agents. In our problem, an agent has an arbitrary valuation over her incident items such that the items she likes have non-negative marginal values to her and those she dislikes have non-positive marginal values. We provide a complete study of the four notions of EFX for mixed manna in the literature, which differ by whether the removed item can have zero marginal value. We prove that an allocation that satisfies the notion of EFX where the virtually-removed item could always have zero marginal value may not exist and determining its existence is NP-complete, while one that satisfies any of the other three notions always exists and can be computed in polynomial time. We also prove that an orientation (i.e., a special allocation where each edge must be allocated to one of its endpoint agents) that satisfies any of the four notions may not exist, and determining its existence is NP-complete.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.03594v1</guid>
      <category>cs.GT</category>
      <pubDate>Fri, 06 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yu Zhou, Tianze Wei, Minming Li, Bo Li</dc:creator>
    </item>
    <item>
      <title>Managing multiple agents by automatically adjusting incentives</title>
      <link>https://arxiv.org/abs/2409.02960</link>
      <description>arXiv:2409.02960v1 Announce Type: cross 
Abstract: In the coming years, AI agents will be used for making more complex decisions, including in situations involving many different groups of people. One big challenge is that AI agent tends to act in its own interest, unlike humans who often think about what will be the best for everyone in the long run. In this paper, we explore a method to get self-interested agents to work towards goals that benefit society as a whole. We propose a method to add a manager agent to mediate agent interactions by assigning incentives to certain actions. We tested our method with a supply-chain management problem and showed that this framework (1) increases the raw reward by 22.2%, (2) increases the agents' reward by 23.8%, and (3) increases the manager's reward by 20.1%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02960v1</guid>
      <category>cs.MA</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <pubDate>Fri, 06 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shunichi Akatsuka, Yaemi Teramoto, Aaron Courville</dc:creator>
    </item>
    <item>
      <title>Variance reduction in Texas hold'em and in video poker</title>
      <link>https://arxiv.org/abs/2409.03607</link>
      <description>arXiv:2409.03607v1 Announce Type: cross 
Abstract: In Texas hold'em, after an all-in bet is made and called before the flop, the turn, or the river, the two players sometimes agree to run it $n$ times, meaning that the remaining five, two, or one cards are dealt out $n$ times successively, with $1/n$ of the pot attached to each run. In $n$-play video poker, five cards are dealt exactly as in the conventional single-play game. After the player chooses which cards to hold, new cards are drawn to replace the discards, not just once but $n$ times independently, with $1/n$ of the bet attached to each draw. In both scenarios the players are attempting to reduce the variance of the return without changing the mean. We quantify the extent to which the variance is reduced.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.03607v1</guid>
      <category>math.PR</category>
      <category>cs.GT</category>
      <pubDate>Fri, 06 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Stewart N. Ethier</dc:creator>
    </item>
    <item>
      <title>Randomized Lower Bounds for Tarski Fixed Points in High Dimensions</title>
      <link>https://arxiv.org/abs/2409.03751</link>
      <description>arXiv:2409.03751v1 Announce Type: cross 
Abstract: The Knaster-Tarski theorem, also known as Tarski's theorem, guarantees that every monotone function defined on a complete lattice has a fixed point. We analyze the query complexity of finding such a fixed point on the $k$-dimensional grid of side length $n$ under the $\leq$ relation. Specifically, there is an unknown monotone function $f: \{0,1,\ldots, n-1\}^k \to \{0,1,\ldots, n-1\}^k$ and an algorithm must query a vertex $v$ to learn $f(v)$.
  Our main result is a randomized lower bound of $\Omega\left( k + \frac{k \cdot \log{n}}{\log{k}} \right)$ for the $k$-dimensional grid of side length $n$, which is nearly optimal in high dimensions when $k$ is large relative to $n$. As a corollary, we characterize the randomized and deterministic query complexity on the Boolean hypercube $\{0,1\}^k$ as $\Theta(k)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.03751v1</guid>
      <category>cs.CC</category>
      <category>cs.GT</category>
      <pubDate>Fri, 06 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Simina Br\^anzei, Reed Phillips, Nicholas Recker</dc:creator>
    </item>
    <item>
      <title>Information Design in the Principal-Agent Problem</title>
      <link>https://arxiv.org/abs/2209.13688</link>
      <description>arXiv:2209.13688v2 Announce Type: replace 
Abstract: We study a variant of the principal-agent problem in which the principal does not directly observe the agent's effort outcome; rather, she gets a signal about the agent's action according to a variable information structure designed by a regulator. We consider both the case of a risk-neutral and of a risk-averse agent, focusing mainly on a setting with a limited liability assumption. We provide a clean characterization for implementability of actions and utility profiles by any information structure, which turns out to be simple thresholds on the utilities. We further study naturally constrained information structures in which the signal emitted from any action is either the action itself or some actions nearby. We show that the worst implementable welfare deteriorates gracefully as the information structure becomes noisier. Finally, we show that our clean characterization does not generalize to a larger class of signaling constraints. In fact, even deciding whether a certain action is implementable by some constrained information structure from this class is NP-complete in the general setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.13688v2</guid>
      <category>cs.GT</category>
      <pubDate>Fri, 06 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yakov Babichenko, Inbal Talgam-Cohen, Haifeng Xu, Konstantin Zabarnyi</dc:creator>
    </item>
    <item>
      <title>From First-Order to Second-Order Rationality: Advancing Game Convergence with Dynamic Weighted Fictitious Play</title>
      <link>https://arxiv.org/abs/2402.12164</link>
      <description>arXiv:2402.12164v2 Announce Type: replace 
Abstract: Constructing effective algorithms to converge to Nash Equilibrium (NE) is an important problem in algorithmic game theory. Prior research generally posits that the upper bound on the convergence rate for games is $O\left(T^{-1/2}\right)$. This paper introduces a novel perspective, positing that the key to accelerating convergence in game theory is rationality. Based on this concept, we propose a Dynamic Weighted Fictitious Play (DW-FP) algorithm. We demonstrate that this algorithm can converge to a NE and exhibits a convergence rate of $O(T^{-1})$ in experimental evaluations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.12164v2</guid>
      <category>cs.GT</category>
      <pubDate>Fri, 06 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qi Ju, Falin Hei, Yuxuan Liu, Zhemei Fang, Yunfeng Luo</dc:creator>
    </item>
    <item>
      <title>Last-Iterate Convergence of Payoff-Based Independent Learning in Zero-Sum Stochastic Games</title>
      <link>https://arxiv.org/abs/2409.01447</link>
      <description>arXiv:2409.01447v2 Announce Type: replace-cross 
Abstract: In this paper, we consider two-player zero-sum matrix and stochastic games and develop learning dynamics that are payoff-based, convergent, rational, and symmetric between the two players. Specifically, the learning dynamics for matrix games are based on the smoothed best-response dynamics, while the learning dynamics for stochastic games build upon those for matrix games, with additional incorporation of the minimax value iteration. To our knowledge, our theoretical results present the first finite-sample analysis of such learning dynamics with last-iterate guarantees. In the matrix game setting, the results imply a sample complexity of $O(\epsilon^{-1})$ to find the Nash distribution and a sample complexity of $O(\epsilon^{-8})$ to find a Nash equilibrium. In the stochastic game setting, the results also imply a sample complexity of $O(\epsilon^{-8})$ to find a Nash equilibrium. To establish these results, the main challenge is to handle stochastic approximation algorithms with multiple sets of coupled and stochastic iterates that evolve on (possibly) different time scales. To overcome this challenge, we developed a coupled Lyapunov-based approach, which may be of independent interest to the broader community studying the convergence behavior of stochastic approximation algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.01447v2</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <pubDate>Fri, 06 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zaiwei Chen, Kaiqing Zhang, Eric Mazumdar, Asuman Ozdaglar, Adam Wierman</dc:creator>
    </item>
  </channel>
</rss>
