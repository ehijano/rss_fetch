<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.TH updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.TH</link>
    <description>stat.TH updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.TH" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 25 Sep 2024 04:00:25 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 25 Sep 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Detecting Change Points of Covariance Matrices in High Dimensions</title>
      <link>https://arxiv.org/abs/2409.15588</link>
      <description>arXiv:2409.15588v1 Announce Type: new 
Abstract: Testing for change points in sequences of high-dimensional covariance matrices is an important and equally challenging problem in statistical methodology with applications in various fields. Motivated by the observation that even in cases where the ratio between dimension and sample size is as small as $0.05$, tests based on a fixed-dimension asymptotics do not keep their preassigned level, we propose to derive critical values of test statistics using an asymptotic regime where the dimension diverges at the same rate as the sample size.
  This paper introduces a novel and well-founded statistical methodology for detecting change points in a sequence of high-dimensional covariance matrices. Our approach utilizes a min-type statistic based on a sequential process of likelihood ratio statistics. This is used to construct a test for the hypothesis of the existence of a change point with a corresponding estimator for its location. We provide theoretical guarantees for these inference tools by thoroughly analyzing the asymptotic properties of the sequential process of likelihood ratio statistics in the case where the dimension and sample size converge with the same rate to infinity. In particular, we prove weak convergence towards a Gaussian process under the null hypothesis of no change. To identify the challenging dependency structure between consecutive test statistics, we employ tools from random matrix theory and stochastic processes. Moreover, we show that the new test attains power under a class of alternatives reflecting changes in the bulk of the spectrum, and we prove consistency of the estimator for the change-point location.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.15588v1</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Wed, 25 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nina D\"ornemann, Holger Dette</dc:creator>
    </item>
    <item>
      <title>Two-Sample Testing with a Graph-Based Total Variation Integral Probability Metric</title>
      <link>https://arxiv.org/abs/2409.15628</link>
      <description>arXiv:2409.15628v1 Announce Type: new 
Abstract: We consider a novel multivariate nonparametric two-sample testing problem where, under the alternative, distributions $P$ and $Q$ are separated in an integral probability metric over functions of bounded total variation (TV IPM). We propose a new test, the graph TV test, which uses a graph-based approximation to the TV IPM as its test statistic. We show that this test, computed with an $\varepsilon$-neighborhood graph and calibrated by permutation, is minimax rate-optimal for detecting alternatives separated in the TV IPM. As an important special case, we show that this implies the graph TV test is optimal for detecting spatially localized alternatives, whereas the $\chi^2$ test is provably suboptimal. Our theory is supported with numerical experiments on simulated and real data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.15628v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 25 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alden Green, Sivaraman Balakrishnan, Ryan J. Tibshirani</dc:creator>
    </item>
    <item>
      <title>Smoothing the Conditional Value-at-Risk based Pickands Estimators</title>
      <link>https://arxiv.org/abs/2409.15677</link>
      <description>arXiv:2409.15677v1 Announce Type: new 
Abstract: We incorporate the conditional value-at-risk (CVaR) quantity into a generalized class of Pickands estimators. By introducing CVaR, the newly developed estimators not only retain the desirable properties of consistency, location, and scale invariance inherent to Pickands estimators, but also achieve a reduction in mean squared error (MSE). To address the issue of sensitivity to the choice of the number of top order statistics used for the estimation, and ensure robust estimation, which are crucial in practice, we first propose a beta measure, which is a modified beta density function, to smooth the estimator. Then, we develop an algorithm to approximate the asymptotic mean squared error (AMSE) and determine the optimal beta measure that minimizes AMSE. A simulation study involving a wide range of distributions shows that our estimators have good and highly stable finite-sample performance and compare favorably with the other estimators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.15677v1</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Wed, 25 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yizhou Li, Pawel Polak</dc:creator>
    </item>
    <item>
      <title>A sparsified Christoffel function for high-dimensional inference</title>
      <link>https://arxiv.org/abs/2409.15965</link>
      <description>arXiv:2409.15965v1 Announce Type: new 
Abstract: Christoffel polynomials are classical tools from approximation theory. They can be used to estimate the (compact) support of a measure $\mu$ on $\mathbb{R}^d$ based on its low-degree moments. Recently, they have been applied to problems in data science, including outlier detection and support inference. A major downside of Christoffel polynomials in such applications is the fact that, in order to compute their coefficients, one must invert a matrix whose size grows rapidly with the dimension $d$. In this paper, we propose a modification of the Christoffel polynomial which is significantly cheaper to compute, but retains many of its desirable properties. Our approach relies on sparsity of the underlying measure $\mu$, described by a graphical model. The complexity of our modification depends on the treewidth of this model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.15965v1</guid>
      <category>math.ST</category>
      <category>math.OC</category>
      <category>stat.TH</category>
      <pubDate>Wed, 25 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jean-Bernard Lasserre, Lucas Slot</dc:creator>
    </item>
    <item>
      <title>Model robust hybrid likelihood</title>
      <link>https://arxiv.org/abs/2409.15975</link>
      <description>arXiv:2409.15975v1 Announce Type: new 
Abstract: The article concerns hybrid combinations of empirical and parametric likelihood functions. Combining the two allows classical parametric likelihood to be crucially modified via the nonparametric counterpart, making possible model misspecification less problematic. Limit theory for the maximum hybrid likelihood estimator is sorted out, also outside the parametric model conditions. Results include consistency of the estimated parameter in the parametric model towards a well-defined limit, as well as asymptotic normality after proper scaling and centring of the same quantity. Our results allow for the presence of plug-in parameters in the hybrid and empirical likelihood framework. Furthermore, the variance and mean squared error of these estimators are studied, with recipes for their estimation. The latter is used to define a focused information criterion, which can be used to choose how the parametric and empirical part of the hybrid combination should be balanced. This allows for hybrid models to be fitted in a context driven way, minimizing the estimated mean squared error for estimating any pre-specified quantity of interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.15975v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 25 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ingrid D{\ae}hlen, Nils Lid Hjort</dc:creator>
    </item>
    <item>
      <title>Asymptotic considerations in a Bayesian linear model with nonparametrically modelled time series innovations</title>
      <link>https://arxiv.org/abs/2409.16207</link>
      <description>arXiv:2409.16207v1 Announce Type: new 
Abstract: This paper considers a semiparametric approach within the general Bayesian linear model where the innovations consist of a stationary, mean zero Gaussian time series. While a parametric prior is specified for the linear model coefficients, the autocovariance structure of the time series is modeled nonparametrically using a Bernstein-Gamma process prior for the spectral density function, the Fourier transform of the autocovariance function. When updating this joint prior with Whittle's likelihood, a Bernstein-von-Mises result is established for the linear model coefficients showing the asymptotic equivalence of the corresponding estimators to those obtained from frequentist pseudo-maximum-likelihood estimation under the Whittle likelihood. Local asymptotic normality of the likelihood is shown, demonstrating that the marginal posterior distribution of the linear model coefficients shrinks at parametric rate towards the true value, and that the conditional posterior distribution of the spectral density contracts in the sup-norm, even in the case of a partially misspecified linear model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.16207v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 25 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Claudia Kirch, Alexander Meier, Renate Meyer, Yifu Tang</dc:creator>
    </item>
    <item>
      <title>Axiomatic characterisation of generalized $\psi$-estimators</title>
      <link>https://arxiv.org/abs/2409.16240</link>
      <description>arXiv:2409.16240v1 Announce Type: new 
Abstract: We give axiomatic characterisations of generalized $\psi$-estimators and (usual) $\psi$-estimators (also called $Z$-estimators), respectively. The key properties of estimators that come into play in the characterisation theorems are the symmetry, the (strong) internality and the asymptotic idempotency. In the proofs, a separation theorem for Abelian subsemigroups plays a crucial role.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.16240v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 25 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matyas Barczy, Zsolt P\'ales</dc:creator>
    </item>
    <item>
      <title>Sticky coupling as a control variate for sensitivity analysis</title>
      <link>https://arxiv.org/abs/2409.15500</link>
      <description>arXiv:2409.15500v1 Announce Type: cross 
Abstract: We present and analyze a control variate strategy based on couplings to reduce the variance of finite difference estimators of sensitivity coefficients, called transport coefficients in the physics literature. We study the bias and variance of a sticky-coupling and a synchronous-coupling based estimator as the finite difference parameter $\eta$ goes to zero. For diffusions with elliptic additive noise, we show that when the drift is contractive outside a compact the bias of a sticky-coupling based estimator is bounded as $\eta \to 0$ and its variance behaves like $\eta^{-1}$, compared to the standard estimator whose bias and variance behave like $\eta^{-1}$ and $\eta^{-2}$, respectively. Under the stronger assumption that the drift is contractive everywhere, we additionally show that the bias and variance of the synchronous-coupling based estimator are both bounded as $\eta \to 0$. Our hypotheses include overdamped Langevin dynamics with many physically relevant non-convex potentials. We illustrate our theoretical results with numerical examples, including overdamped Langevin dynamics with a highly non-convex Lennard-Jones potential to demonstrate both failure of synchronous coupling and the effectiveness of sticky coupling in the not globally contractive setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.15500v1</guid>
      <category>math.PR</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.TH</category>
      <pubDate>Wed, 25 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shiva Darshan, Andreas Eberle, Gabriel Stoltz</dc:creator>
    </item>
    <item>
      <title>Higher-criticism for sparse multi-sensor change-point detection</title>
      <link>https://arxiv.org/abs/2409.15597</link>
      <description>arXiv:2409.15597v1 Announce Type: cross 
Abstract: We present a procedure based on higher criticism (Dohono \&amp; Jin 2004) to address the sparse multi-sensor quickest change-point detection problem. Namely, we aim to detect a change in the distribution of the multi-sensor that might affect a few sensors out of potentially many, while those affected sensors, if they exist, are unknown to us in advance. Our procedure involves testing for a change point in individual sensors and combining multiple tests using higher criticism. As a by-product, our procedure also indicates a set of sensors suspected to be affected by the change. We demonstrate the effectiveness of our method compared to other procedures using extensive numerical evaluations. We analyze our procedure under a theoretical framework involving normal data sensors that might experience a change in both mean and variance. We consider individual tests based on the likelihood ratio or the generalized likelihood ratio statistics and show that our procedure attains the information-theoretic limits of detection. These limits coincide with existing litereature when the change is only in the mean.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.15597v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 25 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tingnan Gong, Alon Kipnis, Yao Xie</dc:creator>
    </item>
    <item>
      <title>TUNE: Algorithm-Agnostic Inference after Changepoint Detection</title>
      <link>https://arxiv.org/abs/2409.15676</link>
      <description>arXiv:2409.15676v1 Announce Type: cross 
Abstract: In multiple changepoint analysis, assessing the uncertainty of detected changepoints is crucial for enhancing detection reliability -- a topic that has garnered significant attention. Despite advancements through selective p-values, current methodologies often rely on stringent assumptions tied to specific changepoint models and detection algorithms, potentially compromising the accuracy of post-detection statistical inference. We introduce TUNE (Thresholding Universally and Nullifying change Effect), a novel algorithm-agnostic approach that uniformly controls error probabilities across detected changepoints. TUNE sets a universal threshold for multiple test statistics, applicable across a wide range of algorithms, and directly controls the family-wise error rate without the need for selective p-values. Through extensive theoretical and numerical analyses, TUNE demonstrates versatility, robustness, and competitive power, offering a viable and reliable alternative for model-agnostic post-detection inference.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.15676v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 25 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yinxu Jia, Jixuan Liu, Guanghui Wang, Zhaojun Wang, Changliang Zou</dc:creator>
    </item>
    <item>
      <title>Low-degree Security of the Planted Random Subgraph Problem</title>
      <link>https://arxiv.org/abs/2409.16227</link>
      <description>arXiv:2409.16227v1 Announce Type: cross 
Abstract: The planted random subgraph detection conjecture of Abram et al. (TCC 2023) asserts the pseudorandomness of a pair of graphs $(H, G)$, where $G$ is an Erdos-Renyi random graph on $n$ vertices, and $H$ is a random induced subgraph of $G$ on $k$ vertices. Assuming the hardness of distinguishing these two distributions (with two leaked vertices), Abram et al. construct communication-efficient, computationally secure (1) 2-party private simultaneous messages (PSM) and (2) secret sharing for forbidden graph structures.
  We prove the low-degree hardness of detecting planted random subgraphs all the way up to $k\leq n^{1 - \Omega(1)}$. This improves over Abram et al.'s analysis for $k \leq n^{1/2 - \Omega(1)}$. The hardness extends to $r$-uniform hypergraphs for constant $r$.
  Our analysis is tight in the distinguisher's degree, its advantage, and in the number of leaked vertices. Extending the constructions of Abram et al, we apply the conjecture towards (1) communication-optimal multiparty PSM protocols for random functions and (2) bit secret sharing with share size $(1 + \epsilon)\log n$ for any $\epsilon &gt; 0$ in which arbitrary minimal coalitions of up to $r$ parties can reconstruct and secrecy holds against all unqualified subsets of up to $\ell = o(\epsilon \log n)^{1/(r-1)}$ parties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.16227v1</guid>
      <category>cs.CR</category>
      <category>cs.DS</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 25 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrej Bogdanov, Chris Jones, Alon Rosen, Ilias Zadik</dc:creator>
    </item>
    <item>
      <title>High Dimensional Logistic Regression Under Network Dependence</title>
      <link>https://arxiv.org/abs/2110.03200</link>
      <description>arXiv:2110.03200v3 Announce Type: replace 
Abstract: Logistic regression is key method for modeling the probability of a binary outcome based on a collection of covariates. However, the classical formulation of logistic regression relies on the independent sampling assumption, which is often violated when the outcomes interact through an underlying network structure, such as over a temporal/spatial domain or on a social network. This necessitates the development of models that can simultaneously handle both the network `peer-effect' and the effect of high-dimensional covariates. In this paper, we develop a framework for incorporating such dependencies in a high-dimensional logistic regression model by introducing a quadratic interaction term, as in the Ising model, designed to capture the pairwise interactions from the underlying network. The resulting model can also be viewed as an Ising model, where the node-dependent external fields linearly encode the high-dimensional covariates. We propose a penalized maximum pseudo-likelihood method for estimating the network peer-effect and the effect of the covariates (the regression coefficients), which, in addition to handling the high-dimensionality of the parameters, conveniently avoids the computational intractability of the maximum likelihood approach. Under various standard regularity conditions, we show that the corresponding estimate attains the classical high-dimensional rate of consistency. Our results imply that even under network dependence it is possible to consistently estimate the model parameters at the same rate as in classical (independent) logistic regression, when the true parameter is sparse and the underlying network is not too dense. We also develop an efficient algorithm for computing the estimates and validate our theoretical results in numerical experiments. An application to selecting genes in clustering spatial transcriptomics data is also discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2110.03200v3</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Wed, 25 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Somabha Mukherjee, Ziang Niu, Sagnik Halder, Bhaswar B. Bhattacharya, George Michailidis</dc:creator>
    </item>
    <item>
      <title>Bayesian Mixtures Models with Repulsive and Attractive Atoms</title>
      <link>https://arxiv.org/abs/2302.09034</link>
      <description>arXiv:2302.09034v3 Announce Type: replace 
Abstract: The study of almost surely discrete random probability measures is an active line of research in Bayesian nonparametrics. The idea of assuming interaction across the atoms of the random probability measure has recently spurred significant interest in the context of Bayesian mixture models. This allows the definition of priors that encourage well-separated and interpretable clusters. In this work, we provide a unified framework for the construction and the Bayesian analysis of random probability measures with interacting atoms, encompassing both repulsive and attractive behaviours. Specifically, we derive closed-form expressions for the posterior distribution, the marginal and predictive distributions, which were not previously available except for the case of measures with i.i.d. atoms. We show how these quantities are fundamental both for prior elicitation and to develop new posterior simulation algorithms for hierarchical mixture models. Our results are obtained without any assumption on the finite point process that governs the atoms of the random measure. Their proofs rely on analytical tools borrowed from the Palm calculus theory, which might be of independent interest. We specialise our treatment to the classes of Poisson, Gibbs, and determinantal point processes, as well as in the case of shot-noise Cox processes. Finally, we illustrate the performance of different modelling strategies on simulated and real datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.09034v3</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Wed, 25 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mario Beraha, Raffaele Argiento, Federico Camerlenghi, Alessandra Guglielmi</dc:creator>
    </item>
    <item>
      <title>On Sparsity and Sub-Gaussianity in the Johnson-Lindenstrauss Lemma</title>
      <link>https://arxiv.org/abs/2409.06275</link>
      <description>arXiv:2409.06275v2 Announce Type: replace 
Abstract: We provide a simple proof of the Johnson-Lindenstrauss lemma for sub-Gaussian variables. We extend the analysis to identify how sparse projections can be, and what the cost of sparsity is on the target dimension.The Johnson-Lindenstrauss lemma is the theoretical core of the dimensionality reduction methods based on random projections. While its original formulation involves matrices with Gaussian entries, the computational cost of random projections can be drastically reduced by the use of simpler variables, especially if they vanish with a high probability. In this paper, we propose a simple and elementary analysis of random projections under classical assumptions that emphasizes the key role of sub-Gaussianity. Furthermore, we show how to extend it to sparse projections, emphasizing the limits induced by the sparsity of the data itself.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06275v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 25 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aur\'elien Garivier (UMPA-ENSL, MC2), Emmanuel Pilliat (UMPA-ENSL)</dc:creator>
    </item>
    <item>
      <title>Robust inference for intermittently-monitored step-stress tests under Weibull lifetime distributions</title>
      <link>https://arxiv.org/abs/2208.02674</link>
      <description>arXiv:2208.02674v2 Announce Type: replace-cross 
Abstract: Many modern products exhibit high reliability under normal operating conditions. Conducting life tests under these conditions may result in very few observed failures, insufficient for accurate inferences. Instead, accelerated life tests (ALTs) must be performed. One of the most popular ALT designs is the step-stress test, which shortens the product's lifetime by progressively increasing the stress level at which units are subjected to at some pre-specified times. Classical estimation methods based on the maximum likelihood estimator (MLE) enjoy suitable asymptotic properties but they lack robustness. That is, data contaminationcan significantly impact the statistical analysis. In this paper, we develop robust inferential methods for highly reliable devices based on the density power divergence (DPD) for estimating and testing under the step-stress model with intermittent monitoring and Weibull lifetime distributions. We theoretically and empirically examine asymptotic and robustness properties of the minimum DPD estimators and associated Wald-type test statistics. Moreover, we develop robust estimators and confidence intervals for some important lifetime characteristics. The effect of temperature in solar lights, medium power silicon bipolar transistors and LED lights using real data arising from an step-stress ALT is analyzed applying the robust methods proposed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.02674v2</guid>
      <category>stat.AP</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 25 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Narayanaswamy Balakrishnan, Mar\'ia Jaenada, Leandro Pardo</dc:creator>
    </item>
    <item>
      <title>Robust Estimation under the Wasserstein Distance</title>
      <link>https://arxiv.org/abs/2302.01237</link>
      <description>arXiv:2302.01237v2 Announce Type: replace-cross 
Abstract: We study the problem of robust distribution estimation under the Wasserstein distance, a popular discrepancy measure between probability distributions rooted in optimal transport (OT) theory. Given $n$ samples from an unknown distribution $\mu$, of which $\varepsilon n$ are adversarially corrupted, we seek an estimate for $\mu$ with minimal Wasserstein error. To address this task, we draw upon two frameworks from OT and robust statistics: partial OT (POT) and minimum distance estimation (MDE). We prove new structural properties for POT and use them to show that MDE under a partial Wasserstein distance achieves the minimax-optimal robust estimation risk in many settings. Along the way, we derive a novel dual form for POT that adds a sup-norm penalty to the classic Kantorovich dual for standard OT. Since the popular Wasserstein generative adversarial network (WGAN) framework implements Wasserstein MDE via Kantorovich duality, our penalized dual enables large-scale generative modeling with contaminated datasets via an elementary modification to WGAN. Numerical experiments demonstrating the efficacy of our approach in mitigating the impact of adversarial corruptions are provided.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.01237v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 25 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sloan Nietert, Rachel Cummings, Ziv Goldfeld</dc:creator>
    </item>
  </channel>
</rss>
