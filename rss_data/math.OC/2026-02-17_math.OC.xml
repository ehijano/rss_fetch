<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 17 Feb 2026 05:00:11 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Dynamic Analysis and Optimal Prevention Strategies for Monkeypox Spread Modeled via the Mittag--Leffler Kernel</title>
      <link>https://arxiv.org/abs/2602.13208</link>
      <description>arXiv:2602.13208v1 Announce Type: new 
Abstract: Monkeypox is a viral disease belonging to the smallpox family. Although it has milder symptoms than smallpox in humans, it has become a global threat in recent years, especially in African countries. Initially, incidental immunity against monkeypox was provided by smallpox vaccines. However, the eradication of smallpox over time and thus the lack of vaccination has led to the widespread and clinical importance of monkeypox. Although mathematical epidemiology research on the disease is complementary to clinical studies, it has attracted attention in the last few years. The present study aims to discuss the indispensable effects of three control strategies such as vaccination, treatment, and quarantine to prevent the monkeypox epidemic modeled via the Atangana--Baleanu operator. The main purpose is to determine optimal control measures planned to reduce the rates of exposed and infected individuals at the minimum costs. For the controlled model, the existence-uniqueness of the solutions, stability, and sensitivity analysis, and numerical optimal solutions are exhibited. The optimal system is numerically solved using the Adams-type predictor--corrector method. In the numerical simulations, the efficacy of the vaccination, treatment, and quarantine controls is evaluated in separate analyzes as single-, double-, and triple-control strategies. The results demonstrate that the most effective strategy for achieving the aimed outcome is the simultaneous application of vaccination, treatment, and quarantine controls.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.13208v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.3390/fractalfract10010044</arxiv:DOI>
      <arxiv:journal_reference>Fractal Fract. 2026, 10(1), Art. 44, 25 pp</arxiv:journal_reference>
      <dc:creator>Mine Yurto\u{g}lu, Dilara Yap{\i}\c{s}kan, Ebenezer Bonyah, Beyza Billur \.Iskender Ero\u{g}lu, Derya Avc{\i}, Delfim F. M. Torres</dc:creator>
    </item>
    <item>
      <title>Stochastic variance reduced extragradient methods for solving hierarchical variational inequalities</title>
      <link>https://arxiv.org/abs/2602.13510</link>
      <description>arXiv:2602.13510v1 Announce Type: new 
Abstract: We are concerned with optimization in a broad sense through the lens of solving variational inequalities (VIs) -- a class of problems that are so general that they cover as particular cases minimization of functions, saddle-point (minimax) problems, Nash equilibrium problems, and many others. The key challenges in our problem formulation are the two-level hierarchical structure and finite-sum representation of the smooth operators in each level. For this setting, we are the first to prove convergence rates and complexity statements for variance-reduced stochastic algorithms approaching the solution of hierarchical VIs in Euclidean and Bregman setups.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.13510v1</guid>
      <category>math.OC</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pavel Dvurechensky, Andrea Ebner, Johannes Carl Schnebel, Shimrit Shtern, Mathias Staudigl</dc:creator>
    </item>
    <item>
      <title>Learning Gradient Flow: Using Equation Discovery to Accelerate Engineering Optimization</title>
      <link>https://arxiv.org/abs/2602.13513</link>
      <description>arXiv:2602.13513v1 Announce Type: new 
Abstract: In this work, we investigate the use of data-driven equation discovery for dynamical systems to model and forecast continuous-time dynamics of unconstrained optimization problems. To avoid expensive evaluations of the objective function and its gradient, we leverage trajectory data on the optimization variables to learn the continuous-time dynamics associated with gradient descent, Newton's method, and ADAM optimization. The discovered gradient flows are then solved as a surrogate for the original optimization problem. To this end, we introduce the Learned Gradient Flow (LGF) optimizer, which is equipped to build surrogate models of variable polynomial order in full- or reduced-dimensional spaces at user-defined intervals in the optimization process. We demonstrate the efficacy of this approach on several standard problems from engineering mechanics and scientific machine learning, including two inverse problems, structural topology optimization, and two forward solves with different discretizations. Our results suggest that the learned gradient flows can significantly expedite convergence by capturing critical features of the optimization trajectory while avoiding expensive evaluations of the objective and its gradient.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.13513v1</guid>
      <category>math.OC</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.DS</category>
      <category>math.NA</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Grant Norman, Conor Rowan, Kurt Maute, Alireza Doostan</dc:creator>
    </item>
    <item>
      <title>Distributed Edge Computing Task Allocation with Network Effects</title>
      <link>https://arxiv.org/abs/2602.13514</link>
      <description>arXiv:2602.13514v1 Announce Type: new 
Abstract: Field-deployable edge computing nodes form a network and are used to complete scientific tasks for remote sensing and monitoring. The networked nodes collectively decide which scientific applications to run while they are constrained by various factors, such as differing hardware constraints from heterogeneous nodes and time-varying quality of service (QoS) requirements. We model the problem of task allocation as an optimization problem that maximizes the QoS, subject to the constraints. We solve the optimization problem using a dual-descent method, which can be easily implemented in a distributed way subject to the communication constraints of the network. Using a simulation that uses real-world data collected from Sage, a distributed sensor network, we analyze our policy's performance in dynamic situations where the required QoS and the nodes' capabilities change, and verify that it can adapt and return a feasible solution while accounting for those changes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.13514v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Henry Abrahamson, Yongho Kim, Seongha Park, Ermin Wei</dc:creator>
    </item>
    <item>
      <title>On the Existence of Periodic Solutions with Applications to Extremum-Seeking</title>
      <link>https://arxiv.org/abs/2602.13615</link>
      <description>arXiv:2602.13615v1 Announce Type: new 
Abstract: This paper provides two results that are useful in the study of the existence and the stability properties of a periodic solution for a given dynamical system. The first result deals with scalar time-periodic systems and establishes the equivalence of the existence of a periodic solution and the existence of a bounded solution. The second result provides sufficient conditions for the existence and the stability of a periodic solution for a time-periodic dynamical system. Both results are applied to extremum seeking problems for a static output map with no plant dynamics and novel non-local results are provided without the use of averaging theorems and singular perturbation arguments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.13615v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.DS</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Iasson Karafyllis, Miroslav Krstic</dc:creator>
    </item>
    <item>
      <title>An adaptive framework for first-order gradient methods</title>
      <link>https://arxiv.org/abs/2602.13620</link>
      <description>arXiv:2602.13620v1 Announce Type: new 
Abstract: Gradient methods are widely used in optimization problems. In practice, while the smoothness parameter can be estimated utilizing techniques such as backtracking, estimating the strong convexity parameter remains a challenge; moreover, even with the optimal parameter choice, convergence can be slow. In this work, we propose a framework for dynamically adapting the step size and momentum parameters in first-order gradient methods for the optimization problem, without prior knowledge of the strong convexity parameter. The main idea is to use the geometric average of the ratios of successive residual norms as an empirical estimate of the upper bound on the convergence rate, which in turn allows us to adaptively update the algorithm parameters. The resulting algorithms are simple to implement, yet efficient in practice, requiring only a few additional computations on existing information. The proposed adaptive gradient methods are shown to converge at least as fast as gradient descent for quadratic optimization problems. Numerical experiments on both quadratic and nonlinear problems validate the effectiveness of the proposed adaptive algorithms. The results show that the adaptive algorithms are comparable to their counterparts using optimal parameters, and in some cases, they capture local information and exhibit improved performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.13620v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaozhe Hu, Sara Pollock, Zhongqin Xue, Yunrong Zhu</dc:creator>
    </item>
    <item>
      <title>Riemannian Momentum Tracking: Distributed Optimization with Momentum on Compact Submanifolds</title>
      <link>https://arxiv.org/abs/2602.13646</link>
      <description>arXiv:2602.13646v1 Announce Type: new 
Abstract: Gradient descent with momentum has been widely applied in various signal processing and machine learning tasks, demonstrating a notable empirical advantage over standard gradient descent. However, momentum-based distributed Riemannian algorithms have been only scarcely explored. In this paper, we propose Riemannian Momentum Tracking (RMTracking), a decentralized optimization algorithm with momentum over a compact submanifold. Given the non-convex nature of compact submanifolds, the objective function, composed of a finite sum of smooth (possibly non-convex) local functions, is minimized across agents in an undirected and connected network graph. With a constant step-size, we establish an $\mathcal{O}(\frac{1-\beta}{K})$ convergence rate of the Riemannian gradient average for any momentum weight $\beta \in [0,1)$. Especially, RMTracking can achieve a convergence rate of $\mathcal{O}(\frac{1-\beta}{K})$ to a stationary point when the step-size is sufficiently small. To best of our knowledge, RMTracking is the first decentralized algorithm to achieve exact convergence that is $\frac{1}{1-\beta}$ times faster than other related algorithms. Finally, we verify these theoretical claims through numerical experiments on eigenvalue problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.13646v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jun Chen, Tianyi Zhu, Haishan Ye, Lina Liu, Guang Dai, Yong Liu, Yunliang Jiang, Ivor W. Tsang</dc:creator>
    </item>
    <item>
      <title>From time series to dissipativity of linear systems with dynamic supply rates</title>
      <link>https://arxiv.org/abs/2602.13654</link>
      <description>arXiv:2602.13654v1 Announce Type: new 
Abstract: This paper studies the problem of verifying dissipativity of linear time-invariant (LTI) systems using input-output data. We leverage behavioral systems theory to express dissipativity in terms of quadratic difference forms (QDFs), allowing the study of general dynamic quadratic supply rates. We work under the assumptions that the data-generating system is controllable, and an upper bound is given on its lag. As our main results, we provide sufficient conditions for the data to be informative for dissipativity. We also show that for a specific class of static supply rates, these conditions are both necessary and sufficient. For the latter supply rates, it turns out that certification of dissipativity is only possible from data that enable unique system identification. As auxiliary results, we highlight some properties of QDFs, such as upper bounds on the degree of storage functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.13654v1</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Henk J. van Waarde, Jeremy Coulson, Alberto Padoan</dc:creator>
    </item>
    <item>
      <title>Persistent homology-based explicit topological control for 2D topology optimization with MMA</title>
      <link>https://arxiv.org/abs/2602.13856</link>
      <description>arXiv:2602.13856v1 Announce Type: new 
Abstract: Controlling structural complexity, particularly the number of holes, remains a fundamental challenge in topology optimization, with significant implications for both theoretical analysis and manufacturability. Most existing approaches rely on indirect strategies, such as filtering techniques, minimum length-scale control, or specific level-set initializations, which influence topology only implicitly and do not allow precise regulation of topological features. In this work, we propose an explicit and differentiable topology-control framework by integrating persistent homology into the classical minimum-compliance topology optimization problem. The design domain and density field are represented using non-uniform rational B-splines (NURBS), while persistence diagrams are employed to rigorously and quantitatively characterize topological features. Given a prescribed number of holes, a differentiable topology-aware objective is constructed from the persistence pairs and incorporated into the compliance objective, leading to a unified optimization formulation. The resulting problem is efficiently solved using the method of moving asymptotes (MMA).Numerical experiments demonstrate that the proposed approach enables explicit control over structural connectivity and the number of holes, thereby providing a systematic and mathematically grounded strategy for topology regulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.13856v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gengchen Li, Depeng Gao, Wenliang Yin, Hongwei Lin</dc:creator>
    </item>
    <item>
      <title>The local minimality of differentiable functions</title>
      <link>https://arxiv.org/abs/2602.13965</link>
      <description>arXiv:2602.13965v1 Announce Type: new 
Abstract: In this paper we present necessary and sufficient conditions (in terms of {\L}ojasiewicz inequalities) for the stability of local minimum points in smooth unconstrained optimization. In particular, we derive a sufficient condition for which the local minimum property of a given function is determined by its Taylor polynomial of a certain degree.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.13965v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tien-Son Pham</dc:creator>
    </item>
    <item>
      <title>A Homogeneous Second-Order Descent Ascent Algorithm for Nonconvex-Strongly Concave Minimax Problems</title>
      <link>https://arxiv.org/abs/2602.14058</link>
      <description>arXiv:2602.14058v1 Announce Type: new 
Abstract: This paper introduces a novel Homogeneous Second-order Descent Ascent (HSDA) algorithm for nonconvex-strongly concave minimax optimization problems. At each iteration, HSDA uniquely computes a search direction by solving a homogenized eigenvalue subproblem built from the gradient and Hessian of the objective function. This formulation guarantees a descent direction with sufficient negative curvature even in near-positive-semidefinite Hessian regimes--a key feature that enhances escape from saddle points. We prove that HSDA finds an $\mathcal{O}(\varepsilon,\sqrt{\varepsilon})$-second-order stationary point within $\tilde{\mathcal{O}}(\varepsilon^{-3/2})$ iterations, matching the optimal $\varepsilon$-order iteration complexity among second-order methods for this problem class. To address large-scale applications, we further design an inexact variant (IHSDA) that preserves the single-loop structure while solving the subproblem approximately via a Lanczos procedure. With high probability, IHSDA achieves the same $\tilde{\mathcal{O}}(\varepsilon^{-3/2})$ iteration complexity and attains an $\mathcal{O}(\varepsilon, \sqrt{\varepsilon})$-second-order stationary point, with the total Hessian-vector product cost bounded by $\tilde{\mathcal{O}}(\varepsilon^{-7/4})$. Experiments on synthetic minimax problems and adversarial training tasks confirm the practical effectiveness and robustness of the proposed algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14058v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jia-Hao Chen, Zi Xu, Hui-Ling Zhang</dc:creator>
    </item>
    <item>
      <title>Comparative Evaluation of SDP, SOCP, and QC Convex Relaxations for Large-Scale Market-Based AC Optimal Power Flow</title>
      <link>https://arxiv.org/abs/2602.14136</link>
      <description>arXiv:2602.14136v1 Announce Type: new 
Abstract: The alternating current optimal power flow (ACOPF) problem is central to modern power system operations, determining how electricity is generated and transmitted to maximize social welfare while respecting physical and operational constraints. However, the nonlinear and non-convex nature of AC power flow equations makes finding globally optimal solutions computationally intractable for large networks. Convex relaxations - including semidefinite programming (SDP), second-order cone programming (SOCP), and quadratic convex (QC) formulations - provide tractable alternatives that can yield provably optimal or near-optimal solutions under appropriate conditions. This paper presents a comprehensive comparative study of multiple ACOPF relaxations applied to market-based welfare maximization. We implement DCOPF, Shor's SDP relaxation (complex and real-valued forms), chordal SDP, Jabr's SOCP relaxation, and QC relaxations in a unified, solver-native framework using the MOSEK Fusion API, eliminating modeling overhead present in high-level frameworks such as CVXPY. To address the practical challenge of missing or overly conservative angle difference bounds required by QC relaxations, we employ quasi-Monte Carlo sampling with Sobol sequences to empirically estimate tighter bounds. We evaluate these relaxations on subnetworks of varying sizes derived from the ARPA-E dataset, systematically comparing solution quality, runtime, and memory consumption. Our results demonstrate the trade-offs between relaxation tightness and computational efficiency, providing practical guidance for selecting appropriate formulations based on network scale and solution requirements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14136v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ata Keskin</dc:creator>
    </item>
    <item>
      <title>Subgradient Gliding Method for Nonsmooth Convex Optimization</title>
      <link>https://arxiv.org/abs/2602.14139</link>
      <description>arXiv:2602.14139v1 Announce Type: new 
Abstract: We identify and analyze a fundamental limitation of the classical projected subgradient method in nonsmooth convex optimization: the inevitable failure caused by the absence of valid subgradients at boundary points. We show that, under standard step sizes for both convex and strongly convex objectives, the method can fail after a single iteration with probability arbitrarily close to one, even on simple problem instances. To overcome this limitation, we propose a novel alternative termed the \textit{subgradient gliding method}, which remains well defined without boundary subgradients and avoids premature termination. Beyond resolving this foundational issue, the proposed framework encompasses the classical projected subgradient method as a special case and substantially enlarges its admissible step-size design space, providing greater flexibility for algorithmic design. We establish optimal ergodic convergence rates, $\mathcal{O}(1/\sqrt{t})$ for convex problems and $\mathcal{O}(1/t)$ for strongly convex problems, and further extend the framework to stochastic settings. Notably, our analysis does not rely on global Lipschitz continuity of the objective function, requiring only mild control on subgradient growth. Numerical experiments demonstrate that, in scenarios where the classical projected subgradient method fails completely, the proposed method converges reliably with a $100\%$ success rate and achieves orders-of-magnitude improvements in accuracy and convergence speed. These results substantially expand the scope of subgradient-based optimization methods to non-Lipschitz nonsmooth convex problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14139v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhihan Zhu, Yanhao Zhang, Yong Xia</dc:creator>
    </item>
    <item>
      <title>Stable representations of Hamilton-Jacobi-Bellman equations with infinite horizon</title>
      <link>https://arxiv.org/abs/2602.14156</link>
      <description>arXiv:2602.14156v1 Announce Type: new 
Abstract: In this paper, for the Hamilton-Jacobi-Bellman equation with an infinite horizon and state constraints, we construct a suitably regular representation. This allows us to reduce the problem of existence and uniqueness of solutions to the Frankowska and Basco theorem from (2019). Furthermore, we demonstrate that our representations are stable. The obtained results are illustrated with examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14156v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s00245-025-10362-3</arxiv:DOI>
      <arxiv:journal_reference>Appl. Math. Optim., 93 (2026) 17</arxiv:journal_reference>
      <dc:creator>Arkadiusz Misztela, S{\l}awomir Plaskacz</dc:creator>
    </item>
    <item>
      <title>Smoothing Meets Perturbation: Unified and Tight Analysis for Nonconvex-Concave Minimax Optimization</title>
      <link>https://arxiv.org/abs/2602.14185</link>
      <description>arXiv:2602.14185v1 Announce Type: new 
Abstract: In this paper, we investigate smooth nonconvex-concave minimax optimization problems and analyze two widely used acceleration mechanisms -- perturbation and smoothing. Perturbation augments the dual objective with a small quadratic regularization term, whereas smoothing employs an auxiliary primal sequence to approximate a proximal-point update of the value function. While both techniques are known to improve convergence guarantees, their respective roles and relative strengths remain unclear. We develop a unified analytical framework that disentangles and quantifies the respective roles of smoothing and perturbation. With this analytical framework, we design new first-order methods that improve the state-of-the-art iteration complexity bounds for both single-loop and double-loop schemes, for achieving both approximate game stationary (GS) and optimization stationary (OS) points. We also establish matching lower bounds based on carefully constructed hard instances, showing that the resulting complexity bounds are tight. Taken together, these results reveal a fundamental difference between approximate GS and OS in terms of their intrinsic complexity behavior and the following understanding: smoothing and perturbation play fundamentally different yet complementary roles in achieving approximate GS. Their combination creates a synergistic effect that yields strictly faster convergence speed than either mechanism alone, whereas perturbation by itself is insufficient for OS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14185v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiajin Li, Mahesh Nagarajan, Siyu Pan, Nanxi Zhang</dc:creator>
    </item>
    <item>
      <title>Graph-Guided Fused Regularization for Single- and Multi-Task Regression on Spatiotemporal Data</title>
      <link>https://arxiv.org/abs/2602.14480</link>
      <description>arXiv:2602.14480v1 Announce Type: new 
Abstract: Spatiotemporal matrix-valued data arise frequently in modern applications, yet performing effective regression analysis remains challenging due to complex, dimension-specific dependencies. In this work, we propose a regularized framework for spatiotemporal matrix regression that characterizes temporal and spatial dependencies through tailored penalties. Specifically, the model incorporates a fused penalty to capture smooth temporal evolution and a graph-guided penalty to promote spatial similarity. The framework also extends to the multi-task setting, enabling joint estimation across related tasks. We provide a comprehensive analysis of the framework from both theoretical and computational perspectives. Theoretically, we establish the statistical consistency of the proposed estimators. Computationally, we develop an efficient solver based on the Halpern Peaceman-Rachford method for the resulting composite convex optimization problem. The proposed algorithm achieves a fast global non-ergodic $\mathcal{O}(1/k)$ convergence rate with low per-iteration complexity. Extensive numerical experiments demonstrate that our method significantly outperforms state-of-the-art approaches in terms of predictive accuracy and estimation error, while also exhibiting superior computational efficiency and scalability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14480v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Meixia Lin, Ziyang Zeng, Yangjing Zhang</dc:creator>
    </item>
    <item>
      <title>On the Existence of Koopman Linear Embeddings for Controlled Nonlinear Systems</title>
      <link>https://arxiv.org/abs/2602.14537</link>
      <description>arXiv:2602.14537v1 Announce Type: new 
Abstract: Koopman linear representations have become a popular tool for control design of nonlinear systems, yet it remains unclear when such representations are exact. In this paper, we establish sufficient and necessary conditions under which a controlled nonlinear system admits an exact finite-dimensional Koopman linear representation, which we term Koopman linear embedding. We show that such a system must be transformable into a special control-affine preserved (CAP) structure, which enforces affine dependence of the state on the control input and isolates all nonlinearities into an autonomous subsystem. We further prove that this autonomous subsystem must itself admit a finite-dimensional Koopman linear model with a sufficiently-rich Koopman invariant subspace. Finally, we introduce a symbolic procedure to determine whether a given controlled nonlinear system admits the CAP structure, thereby elucidating whether Koopman approximation errors arise from intrinsic system dynamics or from the choice of lifting functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14537v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xu Shang, Masih Haseli, Jorge Cort\'es, Yang Zheng</dc:creator>
    </item>
    <item>
      <title>Extragradient methods for mean field games of controls and mean field type FBSDEs</title>
      <link>https://arxiv.org/abs/2602.14621</link>
      <description>arXiv:2602.14621v1 Announce Type: new 
Abstract: In this paper we present a numerical scheme to solve coupled mean field forward-backward stochastic differential equations driven by monotone vector fields. This is based on an adaptation of so called extragradient methods by characterizing solutions as zeros of monotone variational inequalities in a Hilbert space. We first introduce the procedure in the context of mean field games of controls and highlight its connection to the fictitious play. Under sufficiently strong monotonicity assumptions, we demonstrate that the sequence of approximate solutions converges exponentially fast. Then we extend the method and main results to general forward backward systems of stochastic differential equations that do not necessarily stem from optimal control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14621v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Charles Meynard (LJAD)</dc:creator>
    </item>
    <item>
      <title>Interwoven SDP in Primal-Dual Proximal Splitting Methods for Adjustable Robust Convex Optimisation with SOS-Convex Polynomial Constraints</title>
      <link>https://arxiv.org/abs/2602.14624</link>
      <description>arXiv:2602.14624v1 Announce Type: new 
Abstract: We propose a novel methodology for solving a two-stage adjustable robust convex optimisation problem with a general (proximable) convex objective function and constraints defined by sum-of-squares (SOS) convex polynomials. These problems appear in many decision-making applications. However, they are challenging to solve and typically cannot be reformulated as numerically tractable convex optimisation models, such as conic linear programs, that can be solved directly using existing software. We show that the robust problem admits an equivalent representation as a convex composite unconstrained optimisation model that preserves the same objective values, under quadratic decision rules on the adjustable decision variables. Building on this reformulation, we develop a tailored first-order primal-dual proximal splitting method. By leveraging semidefinite programming (SDP) techniques as well as tools from convex analysis and real algebraic geometry, we establish its theoretical properties, including computable SDP-based formulas for projections onto closed convex sets, specified by SOS-convex polynomial inequalities. Numerical experiments on a two-stage lot-sizing model with both linear as well as SOS-convex polynomial storage costs under demand uncertainty demonstrate the effectiveness and applicability of the proposed approach. Our approach enables the incorporation of SDP techniques into a primal-dual proximal splitting framework, thereby broadening the class of problems to which these methods can be effectively applied.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14624v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Neil D. Dizon, Bethany I. Caldwell, Vaithilingam Jeyakumar, Guoyin Li</dc:creator>
    </item>
    <item>
      <title>Second-order conditions for bang-bang control of elliptic equations in arbitrary dimensions</title>
      <link>https://arxiv.org/abs/2602.14632</link>
      <description>arXiv:2602.14632v1 Announce Type: new 
Abstract: We consider an optimal control problem governed by a semilinear PDE in cases where the optimal control is of bang-bang type. By utilizing the theory of Bessel potential space, we characterize quadratic growth of the objective via a second-order optimality condition. In contrast to previous contributions, our method of proof works in arbitrary spatial dimensions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14632v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Gerd Wachsmuth</dc:creator>
    </item>
    <item>
      <title>Temporally Flexible Transport Scheduling on Networks with Departure-Arrival Constriction and Nodal Capacity Limits</title>
      <link>https://arxiv.org/abs/2602.14652</link>
      <description>arXiv:2602.14652v1 Announce Type: new 
Abstract: We investigate the optimal transport (OT) problem over networks, wherein supply and demand are conceptualized as temporal marginals governing departure rates of particles from source nodes and arrival rates at sink nodes. This setting extends the classical OT framework, where all mass is conventionally assumed to depart at $t = 0$ and arrive at $t = t_f$. Our generalization accommodates departures and arrivals at specified times, referred as departure--arrival(DA) constraints. In particular, we impose nodal-temporal flux constraints at source and sink nodes, characterizing two distinct scenarios: (i) Independent DA constraints, where departure and arrival rates are prescribed independently, and (ii) Coupled DA constraints, where each particle's transportation time span is explicitly specified. We establish that OT with independent DA constraints admits a multi-marginal optimal transport formulation, while the coupled DA case aligns with the unequal-dimensional OT framework. For line graphs, we analyze the existence and uniqueness of the solution path. For general graphs, we use a constructive path-based reduction and optimize over a prescribed set of paths. From a computational perspective, we consider entropic regularization of the original problem to efficiently provide solutions based on multi-marginal Sinkhorn method, making use of the graphical structure of the cost to further improve scalability. Our numerical simulation further illustrates the linear convergence rate in terms of marginal violation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14652v1</guid>
      <category>math.OC</category>
      <category>cs.SI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anqi Dong, Karl H. Johansson, Johan Karlsson</dc:creator>
    </item>
    <item>
      <title>Joint Majorization-Minimization for Nonnegative CP and Tucker Decompositions under $\beta$-Divergences: Unfolding-Free Updates</title>
      <link>https://arxiv.org/abs/2602.14683</link>
      <description>arXiv:2602.14683v1 Announce Type: new 
Abstract: We study majorization-minimization methods for nonnegative tensor decompositions under the $\beta$-divergence family, focusing on nonnegative CP and Tucker models. Our aim is to avoid explicit mode unfoldings and large auxiliary matrices by deriving separable surrogates whose multiplicative updates can be implemented using only tensor contractions (einsum-style operations). We present both classical block-MM updates in contraction-only form and a joint majorization strategy, inspired by joint MM for matrix $\beta$-NMF, that reuses cached reference quantities across inexpensive inner updates. We prove tightness of the proposed majorizers, establish monotonic decrease of the objective, and show convergence of the sequence of objective values; we also discuss how BSUM theory applies to the block-MM scheme for analyzing limit points. Finally, experiments on synthetic tensors and the Uber spatiotemporal count tensor demonstrate substantial speedups over unfolding-based baselines and a recent einsum-factorization framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14683v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Valentin Leplat</dc:creator>
    </item>
    <item>
      <title>Distributed Multi-Step Model Predictive Control for Consensus</title>
      <link>https://arxiv.org/abs/2602.14714</link>
      <description>arXiv:2602.14714v1 Announce Type: new 
Abstract: This paper studies consensus of discrete-time multi-agent systems under time-varying directed communication, state and input constraints using a distributed multi-step model predictive control (MPC) framework. Consensus is recast as stabilization of the agreement set, and a geometric viewpoint based on convex-hull invariance and strict interiority is adopted. Building on an existing geometric necessary and sufficient condition for agreement, we show that enforcing terminal inclusion in local neighbor convex hulls guarantees hull invariance but does not, in general, imply the strict relative-interior property required for convergence. An explicit counterexample demonstrates that strictness cannot be deduced from feasibility and contraction constraints alone.
  To resolve this issue without shrinking feasible sets or altering primary performance objectives, a lexicographic tie-breaking mechanism is introduced. Among optimal (or near-optimal) MPC solutions, the proposed secondary criterion selects trajectories maximizing an interiority measure with respect to the neighbor hull. It is shown that whenever an interior feasible terminal state exists, this selection rule enforces the strictness condition required for asymptotic consensus. Explicit horizon conditions are derived for single- and double-integrator agents with bounded inputs, ensuring feasibility and automatic existence of interior feasible terminal points. The resulting scheme provides a distributed and implementable route to consensus via finite-step set-Lyapunov contraction. Numerical simulations with distributed inter-process communication illustrate monotone diameter decay and report per-agent computational complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14714v1</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Navid Noroozi</dc:creator>
    </item>
    <item>
      <title>An Age-Structured Vaccination Strategy for Epidemic Containment: A Model Predictive Control Approach</title>
      <link>https://arxiv.org/abs/2602.14758</link>
      <description>arXiv:2602.14758v1 Announce Type: new 
Abstract: This work presents a novel Model Predictive Control (MPC) approach to develop an optimal age-structured vaccination strategy for the containment of COVID-19 in Wallonia, Belgium. The proposed MPC framework is designed to minimize deaths, achieve early disease eradication, and adhere to operational constraints. By incorporating an age-structured Susceptible-Infected-Recovered-Deceased (SIRD) model with an additional term for vaccination, the MPC strategy dynamically adapts to the evolving epidemic state. A detailed proof of the asymptotic stability and recursive feasibility of the proposed MPC algorithm is provided. This ensures that the optimal cost at each step provides an upper bound on the minimal number obtainable of deaths at the end of the pandemic. Moreover, simulations demonstrate that the proposed MPC approach outperforms the decreasing age vaccination strategy adopted by the Belgian government during the first wave of vaccinations. The results highlight the potential of MPC-based vaccination strategies to reduce the total number of deaths, accelerate disease eradication, and optimize vaccine administration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14758v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Candy Sonveaux, Morgane Dumont, Mirko Fiacchini, Mohamad Ajami</dc:creator>
    </item>
    <item>
      <title>Reciprocal Specific Relative Entropy between Continuous Martingales</title>
      <link>https://arxiv.org/abs/2602.14776</link>
      <description>arXiv:2602.14776v1 Announce Type: new 
Abstract: We introduce a novel notion of divergence between continuous martingales; the reciprocal specific relative entropy. First, we motivate this definition from multiple perspectives. Thereafter, we solve the reciprocal specific relative entropy minimization problem over the set of win-martingales (used as models for prediction markets Aldous (2013)). Surprisingly, we show that the optimizer is the renowned neutral Wright-Fisher diffusion. We also justify that this diffusion is in a sense the most salient win-martingale, since it is uniquely selected when we suitably perturb the degenerate martingale optimal transport problem of variance minimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14776v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Julio Backhoff, Xin Zhang</dc:creator>
    </item>
    <item>
      <title>Effective approximations of solutions to highly oscillatory diffusion equations from coarse measurements</title>
      <link>https://arxiv.org/abs/2602.14820</link>
      <description>arXiv:2602.14820v1 Announce Type: new 
Abstract: We approximate a diffusion equation with highly oscillatory coefficients with a diffusion equation with constant coefficients. The approach is put in action in contexts where only partial information (namely the global energy stored in the physical system) is available. While the reconstruction of the microstructure is known to be an ill-posed problem, we show that the reconstruction of effective coefficients is possible and this even with only some coarse information. The strategy we present takes the form of a non-convex optimization problem. Homogenization theory provides elements for a rigorous foundation of the approach. Some algorithmic aspects are discussed in details. We provide a comprehensive set of numerical illustrations that demonstrate the practical interest of our strategy. The present work improves on the earlier works [C. Le Bris, F. Legoll and S. Lemaire, COCV 2018; C. Le Bris, F. Legoll and K. Li, CRAS 2013].</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14820v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Claude Le Bris, Fr\'ed\'eric Legoll, Simon Ruget</dc:creator>
    </item>
    <item>
      <title>On Convergence Analysis of Network-GIANT: An approximate Hessian-based fully distributed optimization algorithm</title>
      <link>https://arxiv.org/abs/2602.14830</link>
      <description>arXiv:2602.14830v1 Announce Type: new 
Abstract: In this paper, we present a detailed convergence analysis of a recently developed approximate Newton-type fully distributed optimization method for smooth, strongly convex local loss functions, called Network-GIANT, which has been empirically illustrated to show faster linear convergence properties while having the same communication complexity (per iteration) as its first order distributed counterparts. By using consensus based parameter updates, and a local Hessian based descent direction at the individual nodes with gradient tracking, we first explicitly characterize a global linear convergence rate for Network-GIANT, which can be computed as the spectral radius of a $3 \times 3$ matrix dependent on the Lipschitz continuity ($L$) and strong convexity ($\mu$) parameters of the objective functions, and the spectral norm ($\sigma$) of the underlying undirected graph represented by a doubly stochastic consensus matrix. We provide an explicit bound on the step size parameter $\eta$, below which this spectral radius is guaranteed to be less than $1$. Furthermore, we derive a mixed linear-quadratic inequality based upper bound for the optimality gap norm, which allows us to conclude that, under small step size values, asymptotically, as the algorithm approaches the global optimum, it achieves a locally linear convergence rate of $1-\eta(1 -\frac{\gamma}{\mu})$ for Network-GIANT, provided the Hessian approximation error $\gamma$ (between the harmonic mean of the local Hessians and the global hessian (the arithmetic mean of the local Hessians) is smaller than $\mu$. This asymptotically linear convergence rate of $\approx 1-\eta$ explains the faster convergence rate of Network-GIANT for the first time. Numerical experiments are carried out with a reduced CovType dataset for binary logistic regression over a variety of graphs to illustrate the above theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14830v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>eess.SY</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Souvik Das, Luca Schenato, Subhrakanti Dey</dc:creator>
    </item>
    <item>
      <title>Numerical exploration of the range of shape functionals using neural networks</title>
      <link>https://arxiv.org/abs/2602.14881</link>
      <description>arXiv:2602.14881v1 Announce Type: new 
Abstract: We introduce a novel numerical framework for the exploration of Blaschke--Santal\'o diagrams, which are efficient tools characterizing the possible inequalities relating some given shape functionals. We introduce a parametrization of convex bodies in arbitrary dimensions using a specific invertible neural network architecture based on gauge functions, allowing an intrinsic conservation of the convexity of the sets during the shape optimization process. To achieve a uniform sampling inside the diagram, and thus a satisfying description of it, we introduce an interacting particle system that minimizes a Riesz energy functional via automatic differentiation in PyTorch. The effectiveness of the method is demonstrated on several diagrams involving both geometric and PDE-type functionals for convex bodies of $\mathbb{R}^2$ and $\mathbb{R}^3$, namely, the volume, the perimeter, the moment of inertia, the torsional rigidity, the Willmore energy, and the first two Neumann eigenvalues of the Laplacian.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14881v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eloi Martinet, Ilias Ftouhi</dc:creator>
    </item>
    <item>
      <title>Pattern preservation in finite to infinite-horizon optimal control problems for dissipative systems</title>
      <link>https://arxiv.org/abs/2602.14944</link>
      <description>arXiv:2602.14944v1 Announce Type: new 
Abstract: This paper focuses on infinite-horizon optimal control problems for dissipative systems and the relations to their finite-horizon formulations. We show that, for a large class of problems, dissipativity of the state equation, when a coercive storage function exists, implies that infinite-horizon optimal controls can be obtained as limits of the corresponding finite-horizon ones. This property is referred to as pattern preservation, or pattern-preserving property.
  Our analysis establishes a formal link between dissipativity theory and the variational convergence framework in optimal control, thus providing a concrete and numerically tractable condition for verifying pattern preservation. Numerical examples illustrate the effectiveness and limitations of the proposed sufficient conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14944v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matteo Della Rossa, Thiago Alves Lima, Lorenzo Freddi</dc:creator>
    </item>
    <item>
      <title>Max-Min Bilinear Completely Positive Programs: A Semidefinite Relaxation with Tightness Guarantees</title>
      <link>https://arxiv.org/abs/2602.14949</link>
      <description>arXiv:2602.14949v1 Announce Type: new 
Abstract: Max-min bilinear optimization models, where one agent maximizes and an adversary minimizes a common bilinear objective, serve as canonical saddle-point formulations in optimization theory. They capture, among others, two-player zero-sum games, robust and distributionally robust optimization, and adversarial machine learning. This study focuses on the subclass whose variables lie in the completely positive (CP) cone, capturing a broad family of mixed-binary quadratic max-min problems through the modelling power of completely positive programming. We show that such problems admit an equivalent single-stage linear reformulation over the COP-CP cone, defined as the Cartesian product of the copositive (COP) and CP cones. Because testing membership in COP cones is co-NP-complete, the resulting COP-CP program inherits NP-hardness. To address this challenge, we develop a hierarchy of semidefinite relaxations based on moment and sum-of-squares representations of the COP and CP cones, and flat truncation conditions are applied to certify the tightness. We show that the tightness of the hierarchy is guaranteed under mild conditions. The framework extends existing CP/COP approaches for distributionally robust optimization and polynomial games. We apply the framework to the cyclic Colonel Blotto game, an extension of Borel's classic allocation contest. Across multiple instances, the semidefinite relaxation meets the flat-truncation conditions and solves the exact mixed-strategy equilibrium.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14949v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sarah Yini Gao, Xindong Tang, Yancheng Yuan</dc:creator>
    </item>
    <item>
      <title>ALiA: Adaptive Linearized ADMM</title>
      <link>https://arxiv.org/abs/2602.15000</link>
      <description>arXiv:2602.15000v1 Announce Type: new 
Abstract: We propose ALiA, a novel adaptive variant of the alternating direction method of multipliers (ADMM). Specifically, ALiA is a variant of function-linearized proximal ADMM (FLiP ADMM), which generalizes the classical ADMM by leveraging the differentiable structure of the objective function, making it highly versatile. Notably, ALiA features an adaptive stepsize selection scheme that eliminates the need for backtracking linesearch. Motivated by recent advances in adaptive gradient and proximal methods, we establish point convergence of ALiA for convex and differentiable objectives. Furthermore, by introducing negligible computational overhead, we develop an alternative stepsize selection scheme for ALiA that improves the convergence speed both theoretically and empirically. Extensive numerical experiments on practical datasets confirm the accelerated performance of ALiA compared to standard FLiP ADMM. Additionally, we demonstrate that ALiA either outperforms or matches the practical performance of existing adaptive methods across problem classes where it is applicable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15000v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Uijeong Jang, Kaizhao Sun, Wotao Yin, Ernest K Ryu</dc:creator>
    </item>
    <item>
      <title>Why is Normalization Preferred? A Worst-Case Complexity Theory for Stochastically Preconditioned SGD under Heavy-Tailed Noise</title>
      <link>https://arxiv.org/abs/2602.13413</link>
      <description>arXiv:2602.13413v1 Announce Type: cross 
Abstract: We develop a worst-case complexity theory for stochastically preconditioned stochastic gradient descent (SPSGD) and its accelerated variants under heavy-tailed noise, a setting that encompasses widely used adaptive methods such as Adam, RMSProp, and Shampoo. We assume the stochastic gradient noise has a finite $p$-th moment for some $p \in (1,2]$, and measure convergence after $T$ iterations. While clipping and normalization are parallel tools for stabilizing training of SGD under heavy-tailed noise, there is a fundamental separation in their worst-case properties in stochastically preconditioned settings. We demonstrate that normalization guarantees convergence to a first-order stationary point at rate $\mathcal{O}(T^{-\frac{p-1}{3p-2}})$ when problem parameters are known, and $\mathcal{O}(T^{-\frac{p-1}{2p}})$ when problem parameters are unknown, matching the optimal rates for normalized SGD, respectively. In contrast, we prove that clipping may fail to converge in the worst case due to the statistical dependence between the stochastic preconditioner and the gradient estimates. To enable the analysis, we develop a novel vector-valued Burkholder-type inequality that may be of independent interest. These results provide a theoretical explanation for the empirical preference for normalization over clipping in large-scale model training.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.13413v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuchen Fang, James Demmel, Javad Lavaei</dc:creator>
    </item>
    <item>
      <title>Quantum Speedups for Group Relaxations of Integer Linear Programs</title>
      <link>https://arxiv.org/abs/2602.13494</link>
      <description>arXiv:2602.13494v1 Announce Type: cross 
Abstract: Integer Linear Programs (ILPs) are a flexible and ubiquitous model for discrete optimization problems. Solving ILPs is \textsf{NP-Hard} yet of great practical importance. Super-quadratic quantum speedups for ILPs have been difficult to obtain because classical algorithms for many-constraint ILPs are global and exhaustive, whereas quantum frameworks that offer super-quadratic speedup exploit local structure of the objective and feasible set. We address this via quantum algorithms for Gomory's group relaxation. The group relaxation of an ILP is obtained by dropping nonnegativity on variables that are positive in the optimal solution of the linear programming (LP) relaxation, while retaining integrality of the decision variables. We present a competitive feasibility-preserving classical local-search algorithm for the group relaxation, and a corresponding quantum algorithm that, under reasonable technical conditions, achieves a super-quadratic speedup. When the group relaxation satisfies a nondegeneracy condition analogous to, but stronger than, LP non-degeneracy, our approach yields the optimal solution to the original ILP. Otherwise, the group relaxation tightens bounds on the optimal objective value of the ILP, and can improve downstream branch-and-cut by reducing the integrality gap; we numerically observe this on several practically relevant ILPs. To achieve these results, we derive efficiently constructible constraint-preserving mixers for the group relaxation with favorable spectral properties, which are of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.13494v1</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Brandon Augustino, Dylan Herman, Guneykan Ozgul, Jacob Watkins, Atithi Acharya, Enrico Fontana, Junhyung Lyle Kim, Shouvanik Chakrabarti</dc:creator>
    </item>
    <item>
      <title>$\gamma$-weakly $\theta$-up-concavity: Linearizable Non-Convex Optimization with Applications to DR-Submodular and OSS Functions</title>
      <link>https://arxiv.org/abs/2602.13506</link>
      <description>arXiv:2602.13506v1 Announce Type: cross 
Abstract: Optimizing monotone non-convex functions is a fundamental challenge across machine learning and combinatorial optimization. We introduce and study $\gamma$-weakly $\theta$-up-concavity, a novel first-order condition that characterizes a broad class of such functions. This condition provides a powerful unifying framework, strictly generalizing both DR-submodular functions and One-Sided Smooth (OSS) functions. Our central theoretical contribution demonstrates that $\gamma$-weakly $\theta$-up-concave functions are upper-linearizable: for any feasible point, we can construct a linear surrogate whose gains provably approximate the original non-linear objective. This approximation holds up to a constant factor, namely the approximation coefficient, dependent solely on $\gamma$, $\theta$, and the geometry of the feasible set. This linearizability yields immediate and unified approximation guarantees for a wide range of problems. Specifically, we obtain unified approximation guarantees for offline optimization as well as static and dynamic regret bounds in online settings via standard reductions to linear optimization. Moreover, our framework recovers the optimal approximation coefficient for DR-submodular maximization and significantly improves existing approximation coefficients for OSS optimization, particularly over matroid constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.13506v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohammad Pedramfar, Vaneet Aggarwal</dc:creator>
    </item>
    <item>
      <title>Zero-Order Optimization for LLM Fine-Tuning via Learnable Direction Sampling</title>
      <link>https://arxiv.org/abs/2602.13659</link>
      <description>arXiv:2602.13659v1 Announce Type: cross 
Abstract: Fine-tuning large pretrained language models (LLMs) is a cornerstone of modern NLP, yet its growing memory demands (driven by backpropagation and large optimizer States) limit deployment in resource-constrained settings. Zero-order (ZO) methods bypass backpropagation by estimating directional derivatives from forward evaluations, offering substantial memory savings. However, classical ZO estimators suffer from high variance and an adverse dependence on the parameter dimensionality $d$, which has constrained their use to low-dimensional problems. In this work, we propose a policy-driven ZO framework that treats the sampling distribution over perturbation directions as a learnable policy and updates it to reduce the variance of directional estimates. We develop a practical algorithm implementing this idea and provide a theoretical analysis, showing that learned sampling distributions improve the quality of gradient information and relax the explicit dependence on $d$ in convergence bounds. Empirically, we validate the approach on challenging LLM fine-tuning benchmarks, demonstrating substantially improved performance compared to standard ZO baselines. Our results suggest that adaptive direction sampling is a promising route to make ZO fine-tuning viable at scale. The source code is available at https://github.com/brain-lab-research/zo_ldsd</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.13659v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Valery Parfenov, Grigoriy Evseev, Andrey Veprikov, Nikolay Bushkov, Stanislav Moiseev, Aleksandr Beznosikov</dc:creator>
    </item>
    <item>
      <title>Discrete Double-Bracket Flows for Isotropic-Noise Invariant Eigendecomposition</title>
      <link>https://arxiv.org/abs/2602.13759</link>
      <description>arXiv:2602.13759v1 Announce Type: cross 
Abstract: We study matrix-free eigendecomposition under a matrix-vector product (MVP) oracle, where each step observes a covariance operator $C_k = C_{sig} + \sigma_k^2 I + E_k$. Standard stochastic approximation methods either use fixed steps that couple stability to $\|C_k\|_2$, or adapt steps in ways that slow down due to vanishing updates. We introduce a discrete double-bracket flow whose generator is invariant to isotropic shifts, yielding pathwise invariance to $\sigma_k^2 I$ at the discrete-time level. The resulting trajectory and a maximal stable step size $\eta_{max} \propto 1/\|C_e\|_2^2$ depend only on the trace-free covariance $C_e$. We establish global convergence via strict-saddle geometry for the diagonalization objective and an input-to-state stability analysis, with sample complexity scaling as $O(\|C_e\|_2^2 / (\Delta^2 \epsilon))$ under trace-free perturbations. An explicit characterization of degenerate blocks yields an accelerated $O(\log(1/\zeta))$ saddle-escape rate and a high-probability finite-time convergence guarantee.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.13759v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>ZhiMing Li, JiaHe Feng</dc:creator>
    </item>
    <item>
      <title>Min-Max Connected Multiway Cut</title>
      <link>https://arxiv.org/abs/2602.13861</link>
      <description>arXiv:2602.13861v1 Announce Type: cross 
Abstract: We introduce a variant of the multiway cut that we call the min-max connected multiway cut. Given a graph $G=(V,E)$ and a set $\Gamma\subseteq V$ of $t$ terminals, partition $V$ into $t$ parts such that each part is connected and contains exactly one terminal; the objective is to minimize the maximum weight of the edges leaving any part of the partition. This problem is a natural modification of the standard multiway cut problem and it differs from it in two ways: first, the cost of a partition is defined to be the maximum size of the boundary of any part, as opposed to the sum of all boundaries, and second, the subgraph induced by each part is required to be connected. Although the modified objective function has been considered before in the literature under the name min-max multiway cut, the requirement on each component to be connected has not been studied as far as we know.
  We show various hardness results for this problem, including a proof of weak NP-hardness of the weighted version of the problem on graphs with tree-width two, and provide a pseudopolynomial time algorithm as well as an FPTAS for the weighted problem on trees. As a consequence of our investigation we also show that the (unconstrained) min-max multiway cut problem is NP-hard even for three terminals, strengthening the known results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.13861v1</guid>
      <category>cs.DS</category>
      <category>math.CO</category>
      <category>math.OC</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hans Raj Tiwary, Petr Kolman</dc:creator>
    </item>
    <item>
      <title>Ensemble-Conditional Gaussian Processes (Ens-CGP): Representation, Geometry, and Inference</title>
      <link>https://arxiv.org/abs/2602.13871</link>
      <description>arXiv:2602.13871v1 Announce Type: cross 
Abstract: We formulate Ensemble-Conditional Gaussian Processes (Ens-CGP), a finite-dimensional synthesis that centers ensemble-based inference on the conditional Gaussian law. Conditional Gaussian processes (CGP) arise directly from Gaussian processes under conditioning and, in linear-Gaussian settings, define the full posterior distribution for a Gaussian prior and linear observations. Classical Kalman filtering is a recursive algorithm that computes this same conditional law under dynamical assumptions; the conditional Gaussian law itself is therefore the underlying representational object, while the filter is one computational realization. In this sense, CGP provides the probabilistic foundation for Kalman-type methods as well as equivalent formulations as a strictly convex quadratic program (MAP estimation), RKHS-regularized regression, and classical regularization. Ens-CGP is the ensemble instantiation of this object, obtained by treating empirical ensemble moments as a (possibly low-rank) Gaussian prior and performing exact conditioning. By separating representation (GP -&gt; CGP -&gt; Ens-CGP) from computation (Kalman filters, EnKF variants, and iterative ensemble schemes), the framework links an earlier-established representational foundation for inference to ensemble-derived priors and clarifies the relationships among probabilistic, variational, and ensemble perspectives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.13871v1</guid>
      <category>math.ST</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <category>stat.AP</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sai Ravela, Jae Deok Kim, Kenneth Gee, Xingjian Yan, Samson Mercier, Lubna Albarghouty, Anamitra Saha</dc:creator>
    </item>
    <item>
      <title>A Penalty Approach for Differentiation Through Black-Box Quadratic Programming Solvers</title>
      <link>https://arxiv.org/abs/2602.14154</link>
      <description>arXiv:2602.14154v1 Announce Type: cross 
Abstract: Differentiating through the solution of a quadratic program (QP) is a central problem in differentiable optimization. Most existing approaches differentiate through the Karush--Kuhn--Tucker (KKT) system, but their computational cost and numerical robustness can degrade at scale. To address these limitations, we propose dXPP, a penalty-based differentiation framework that decouples QP solving from differentiation. In the solving step (forward pass), dXPP is solver-agnostic and can leverage any black-box QP solver. In the differentiation step (backward pass), we map the solution to a smooth approximate penalty problem and implicitly differentiate through it, requiring only the solution of a much smaller linear system in the primal variables. This approach bypasses the difficulties inherent in explicit KKT differentiation and significantly improves computational efficiency and robustness. We evaluate dXPP on various tasks, including randomly generated QPs, large-scale sparse projection problems, and a real-world multi-period portfolio optimization task. Empirical results demonstrate that dXPP is competitive with KKT-based differentiation methods and achieves substantial speedups on large-scale problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14154v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuxuan Linghu, Zhiyuan Liu, Qi Deng</dc:creator>
    </item>
    <item>
      <title>Fast Catch-Up, Late Switching: Optimal Batch Size Scheduling via Functional Scaling Laws</title>
      <link>https://arxiv.org/abs/2602.14208</link>
      <description>arXiv:2602.14208v1 Announce Type: cross 
Abstract: Batch size scheduling (BSS) plays a critical role in large-scale deep learning training, influencing both optimization dynamics and computational efficiency. Yet, its theoretical foundations remain poorly understood. In this work, we show that the functional scaling law (FSL) framework introduced in Li et al. (2025a) provides a principled lens for analyzing BSS. Specifically, we characterize the optimal BSS under a fixed data budget and show that its structure depends sharply on task difficulty. For easy tasks, optimal schedules keep increasing batch size throughout. In contrast, for hard tasks, the optimal schedule maintains small batch sizes for most of training and switches to large batches only in a late stage. To explain the emergence of late switching, we uncover a dynamical mechanism -- the fast catch-up effect -- which also manifests in large language model (LLM) pretraining. After switching from small to large batches, the loss rapidly aligns with the constant large-batch trajectory. Using FSL, we show that this effect stems from rapid forgetting of accumulated gradient noise, with the catch-up speed determined by task difficulty. Crucially, this effect implies that large batches can be safely deferred to late training without sacrificing performance, while substantially reducing data consumption. Finally, extensive LLM pretraining experiments -- covering both Dense and MoE architectures with up to 1.1B parameters and 1T tokens -- validate our theoretical predictions. Across all settings, late-switch schedules consistently outperform constant-batch and early-switch baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14208v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jinbo Wang, Binghui Li, Zhanpeng Zhou, Mingze Wang, Yuxuan Sun, Jiaqi Zhang, Xunliang Cai, Lei Wu</dc:creator>
    </item>
    <item>
      <title>Muscle Coactivation in the Sky: Geometry and Pareto Optimality of Energy vs. Promptness in Multirotors</title>
      <link>https://arxiv.org/abs/2602.14222</link>
      <description>arXiv:2602.14222v1 Announce Type: cross 
Abstract: In robotics and human biomechanics, the tension between energy economy and kinematic readiness is well recognized; this work brings that fundamental principle to aerial multirotors. We show that the limited torque of the motors and the nonlinear aerodynamic map from rotor speed to thrust naturally give rise to the novel concept of promptness-a metric akin to dynamic aerodynamic manipulability. By treating energy consumption as a competing objective and introducing a geometric fiber-bundle formulation, we turn redundancy resolution into a principled multi-objective program on affine fibers. The use of the diffeomorphic transformation linearizing the signed-quadratic propulsion model allows us to lay the foundations for a rigorous study of the interplay between these costs. Through an illustrative case study on 4-DoF allocation on the hexarotor, we reveal that this interplay is fiber-dependent and physically shaped by hardware inequalities. For unidirectional thrusters, the feasible fibers are compact, yielding interior allocations and a short Pareto arc, while torque demands break symmetry and separate the optima. Conversely, with reversible propellers, the null space enables antagonistic rotor co-contraction that drives promptness to hardware limits, making optimal endurance and agility fundamentally incompatible in those regimes. Ultimately, rather than relying on heuristic tuning or black box algorithms to empirically improve task execution, this framework provides a foundational understanding of why and how to achieve agility through geometry-aware control allocation, offering possible guidance for vehicle design, certification metrics, and threat-aware flight operation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14222v1</guid>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Antonio Franchi</dc:creator>
    </item>
    <item>
      <title>Subdifferential theory and the Fenchel conjugate via Busemann functions on Hadamard manifolds</title>
      <link>https://arxiv.org/abs/2602.14258</link>
      <description>arXiv:2602.14258v1 Announce Type: cross 
Abstract: In this paper, we propose a notion of subdifferential defined via Busemann functions and use it to identify a condition under which the Fenchel-Young inequality of Bento, Cruz Neto and Melo (Appl. Math. Optim. 88:83, 2023) holds with equality. This equality condition is particularly significant, as it captures a fundamental duality principle in convex analysis, linking a primal convex function to its conjugate and clarifying the sharpness of the associated inequality on Riemannian manifolds. We also investigate the existence of non-trivial affine functions under Ricci curvature information. In particular, we extend the result of Bento, Cruz Neto and Melo, originally formulated for the case of negative Ricci curvature on an open set, to manifolds whose Ricci curvature may be non-zero. As a consequence, we prove new non-existence criteria for non-trivial affine functions and show that the assumption of non-zero Ricci curvature is, in general, necessary to ensure such a rigidity conclusion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14258v1</guid>
      <category>math.DG</category>
      <category>math.OC</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>G. C. Bento, J. X. Cruz Neto, I. D. L. Melo</dc:creator>
    </item>
    <item>
      <title>Topology optimization of type-II superconductors with superconductor-dielectric/vacuum interfaces based on Ginzburg-Landau theory under Weyl gauge</title>
      <link>https://arxiv.org/abs/2602.14261</link>
      <description>arXiv:2602.14261v1 Announce Type: cross 
Abstract: Geometry design is a crucial and challenging strategy for improving the performance of type-II superconductors. Topology optimization is one of the most powerful approaches used to determine structural geometries. Therefore, a topology optimization approach is presented to inversely design structural geometries of both low- and high-temperature type-II superconductors with superconductor-dielectric/vacuum interfaces. In the presented approach, the magnetic response of type-II superconductors is modeled using the Ginzburg-Landau theory, where the temporal evolution of the order parameter and vector potential is described by the time-dependent Ginzburg-Landau equations under the Weyl gauge.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14261v1</guid>
      <category>cond-mat.supr-con</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.OC</category>
      <category>physics.comp-ph</category>
      <category>quant-ph</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Yongbo Deng, Jan G. Korvink</dc:creator>
    </item>
    <item>
      <title>Frequentist Regret Analysis of Gaussian Process Thompson Sampling via Fractional Posteriors</title>
      <link>https://arxiv.org/abs/2602.14472</link>
      <description>arXiv:2602.14472v1 Announce Type: cross 
Abstract: We study Gaussian Process Thompson Sampling (GP-TS) for sequential decision-making over compact, continuous action spaces and provide a frequentist regret analysis based on fractional Gaussian process posteriors, without relying on domain discretization as in prior work. We show that the variance inflation commonly assumed in existing analyses of GP-TS can be interpreted as Thompson Sampling with respect to a fractional posterior with tempering parameter $\alpha \in (0,1)$. We derive a kernel-agnostic regret bound expressed in terms of the information gain parameter $\gamma_t$ and the posterior contraction rate $\epsilon_t$, and identify conditions on the Gaussian process prior under which $\epsilon_t$ can be controlled. As special cases of our general bound, we recover regret of order $\tilde{\mathcal{O}}(T^{\frac{1}{2}})$ for the squared exponential kernel, $\tilde{\mathcal{O}}(T^{\frac{2\nu+3d}{2(2\nu+d)}} )$ for the Mat\'ern-$\nu$ kernel, and a bound of order $\tilde{\mathcal{O}}(T^{\frac{2\nu+3d}{2(2\nu+d)}})$ for the rational quadratic kernel. Overall, our analysis provides a unified and discretization-free regret framework for GP-TS that applies broadly across kernel classes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14472v1</guid>
      <category>math.ST</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Somjit Roy, Prateek Jaiswal, Anirban Bhattacharya, Debdeep Pati, Bani K. Mallick</dc:creator>
    </item>
    <item>
      <title>Constrained and Composite Sampling via Proximal Sampler</title>
      <link>https://arxiv.org/abs/2602.14478</link>
      <description>arXiv:2602.14478v1 Announce Type: cross 
Abstract: We study two log-concave sampling problems: constrained sampling and composite sampling. First, we consider sampling from a target distribution with density proportional to $\exp(-f(x))$ supported on a convex set $K \subset \mathbb{R}^d$, where $f$ is convex. The main challenge is enforcing feasibility without degrading mixing. Using an epigraph transformation, we reduce this task to sampling from a nearly uniform distribution over a lifted convex set in $\mathbb{R}^{d+1}$. We then solve the lifted problem using a proximal sampler. Assuming only a separation oracle for $K$ and a subgradient oracle for $f$, we develop an implementation of the proximal sampler based on the cutting-plane method and rejection sampling. Unlike existing constrained samplers that rely on projection, reflection, barrier functions, or mirror maps, our approach enforces feasibility using only minimal oracle access, resulting in a practical and unbiased sampler without knowing the geometry of the constraint set.
  Second, we study composite sampling, where the target is proportional to $\exp(-f(x)-h(x))$ with closed and convex $f$ and $h$. This composite structure is standard in Bayesian inference with $f$ modeling data fidelity and $h$ encoding prior information. We reduce composite sampling via an epigraph lifting of $h$ to constrained sampling in $\mathbb{R}^{d+1}$, which allows direct application of the constrained sampling algorithm developed in the first part. This reduction results in a double epigraph lifting formulation in $\mathbb{R}^{d+2}$, on which we apply a proximal sampler. By keeping $f$ and $h$ separate, we further demonstrate how different combinations of oracle access (such as subgradient and proximal) can be leveraged to construct separation oracles for the lifted problem. For both sampling problems, we establish mixing time bounds measured in R\'enyi and $\chi^2$ divergences.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14478v1</guid>
      <category>stat.ML</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thanh Dang, Jiaming Liang</dc:creator>
    </item>
    <item>
      <title>Decoupled Continuous-Time Reinforcement Learning via Hamiltonian Flow</title>
      <link>https://arxiv.org/abs/2602.14587</link>
      <description>arXiv:2602.14587v1 Announce Type: cross 
Abstract: Many real-world control problems, ranging from finance to robotics, evolve in continuous time with non-uniform, event-driven decisions. Standard discrete-time reinforcement learning (RL), based on fixed-step Bellman updates, struggles in this setting: as time gaps shrink, the $Q$-function collapses to the value function $V$, eliminating action ranking. Existing continuous-time methods reintroduce action information via an advantage-rate function $q$. However, they enforce optimality through complicated martingale losses or orthogonality constraints, which are sensitive to the choice of test processes. These approaches entangle $V$ and $q$ into a large, complex optimization problem that is difficult to train reliably. To address these limitations, we propose a novel decoupled continuous-time actor-critic algorithm with alternating updates: $q$ is learned from diffusion generators on $V$, and $V$ is updated via a Hamiltonian-based value flow that remains informative under infinitesimal time steps, where standard max/softmax backups fail. Theoretically, we prove rigorous convergence via new probabilistic arguments, sidestepping the challenge that generator-based Hamiltonians lack Bellman-style contraction under the sup-norm. Empirically, our method outperforms prior continuous-time and leading discrete-time baselines across challenging continuous-control benchmarks and a real-world trading task, achieving 21% profit over a single quarter$-$nearly doubling the second-best method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14587v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Minh Nguyen</dc:creator>
    </item>
    <item>
      <title>An Embarrassingly Simple Way to Optimize Orthogonal Matrices at Scale</title>
      <link>https://arxiv.org/abs/2602.14656</link>
      <description>arXiv:2602.14656v1 Announce Type: cross 
Abstract: Orthogonality constraints are ubiquitous in robust and probabilistic machine learning. Unfortunately, current optimizers are computationally expensive and do not scale to problems with hundreds or thousands of constraints. One notable exception is the Landing algorithm (Ablin et al., 2024) which, however comes at the expense of temporarily relaxing orthogonality. In this work, we revisit and improve on the ideas behind Landing, enabling the inclusion of modern adaptive optimizers while ensuring that orthogonal constraints are effectively met. Remarkably, these improvements come at little to no cost, and reduce the number of required hyperparemeters. Our algorithm POGO is fast and GPU-friendly, consisting of only 5 matrix products, and in practice maintains orthogonality at all times. On several challenging benchmarks, POGO greatly outperforms recent optimizers and shows it can optimize problems with thousands of orthogonal matrices in minutes while alternatives would take hours. As such, POGO sets a milestone to finally exploit orthogonality constraints in ML at scale. A PyTorch implementation of POGO is publicly available at https://github.com/adrianjav/pogo.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14656v1</guid>
      <category>cs.LG</category>
      <category>math.DG</category>
      <category>math.OC</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Adri\'an Javaloy, Antonio Vergari</dc:creator>
    </item>
    <item>
      <title>Morrey estimates for the gradient in non-linear variational transmission problems</title>
      <link>https://arxiv.org/abs/2602.14658</link>
      <description>arXiv:2602.14658v1 Announce Type: cross 
Abstract: We study a class of variational transmission problems driven by nonlinear energies with discontinuous coefficients across a prescribed interface. The model setting consists of integral functionals of the form \[ \mathcal{F}(u;E)=\int_{\Omega}\sigma_E(x)\,F(\nabla u)\,dx, \] where the coefficient $\sigma_E$ takes two constant values on complementary regions separated by a $C^1$ hypersurface, and the integrand $F$ satisfies standard $p$-growth and monotonicity conditions with $p&gt;2$.
  In this nonlinear variational framework, we establish local Morrey-space regularity for the gradient of local minimizers, proving that $\nabla u\in L^{2,\lambda}_{\mathrm{loc}}(\Omega)$ for every $0\leq\lambda&lt;n$, provided $2&lt;p&lt;\frac{2n}{n-2}$. The proof is based on quantitative decay estimates for the energy near the interface, first obtained in a flat configuration and then extended to the general case by a suitable approximation argument.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14658v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Luca Esposito, Lorenzo Lamberti</dc:creator>
    </item>
    <item>
      <title>Exposing Diversity Bias in Deep Generative Models: Statistical Origins and Correction of Diversity Error</title>
      <link>https://arxiv.org/abs/2602.14682</link>
      <description>arXiv:2602.14682v1 Announce Type: cross 
Abstract: Deep generative models have achieved great success in producing high-quality samples, making them a central tool across machine learning applications. Beyond sample quality, an important yet less systematically studied question is whether trained generative models faithfully capture the diversity of the underlying data distribution. In this work, we address this question by directly comparing the diversity of samples generated by state-of-the-art models with that of test samples drawn from the target data distribution, using recently proposed reference-free entropy-based diversity scores, Vendi and RKE. Across multiple benchmark datasets, we find that test data consistently attains substantially higher Vendi and RKE diversity scores than the generated samples, suggesting a systematic downward diversity bias in modern generative models. To understand the origin of this bias, we analyze the finite-sample behavior of entropy-based diversity scores and show that their expected values increase with sample size, implying that diversity estimated from finite training sets could inherently underestimate the diversity of the true distribution. As a result, optimizing the generators to minimize divergence to empirical data distributions would induce a loss of diversity. Finally, we discuss potential diversity-aware regularization and guidance strategies based on Vendi and RKE as principled directions for mitigating this bias, and provide empirical evidence suggesting their potential to improve the results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14682v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>math.OC</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Farzan Farnia, Mohammad Jalali, Azim Ospanov</dc:creator>
    </item>
    <item>
      <title>Hierarchical parameter estimation for distributed networked systems: a dynamic consensus approach</title>
      <link>https://arxiv.org/abs/2602.14765</link>
      <description>arXiv:2602.14765v1 Announce Type: cross 
Abstract: This work introduces a novel two-stage distributed framework to globally estimate constant parameters in a networked system, separating shared information from local estimation. The first stage uses dynamic average consensus to aggregate agents' measurements into surrogates of centralized data. Using these surrogates, the second stage implements a local estimator to determine the parameters. By designing an appropriate consensus gain, the persistence of excitation of the regressor matrix is achieved, and thus, exponential convergence of a local Gradient Estimator (GE) is guaranteed. The framework facilitates its extension to switched network topologies, quantization, and the heterogeneous substitution of the GE with a Dynamic Regressor Extension and Mixing (DREM) estimator, which supports relaxed excitation requirements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14765v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ariana R. Mendez-Castillo, Rodrigo Aldana-Lopez, Antonio Ramirez-Trevino, Rosario Aragues, David Gomez-Gutierrez</dc:creator>
    </item>
    <item>
      <title>Identifying Bergman space functions from intervals</title>
      <link>https://arxiv.org/abs/2602.14801</link>
      <description>arXiv:2602.14801v1 Announce Type: cross 
Abstract: We characterize functions of a Bergman space on a square by their values and derivatives on the diagonals. This problem is connected with the reachable space of the one-dimensional heat equation on a finite interval with boundary $L^2$-controls.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14801v1</guid>
      <category>math.CV</category>
      <category>math.AP</category>
      <category>math.FA</category>
      <category>math.OC</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andreas Hartmann, Marcu-Antone Orsoni</dc:creator>
    </item>
    <item>
      <title>Convergence for linear quadratic potential mean field games</title>
      <link>https://arxiv.org/abs/2602.14842</link>
      <description>arXiv:2602.14842v1 Announce Type: cross 
Abstract: This paper studies the limits of empirical means of open-loop Nash equilibria of linear-quadratic stochastic differential games as the number of players goes to infinity, when the corresponding mean field game is of potential type and may have multiple equilibria. Via weak compactness arguments, the limit points are characterized as optimal trajectories of the related deterministic control problem, thus ruling out some of the mean field equilibria. Our result is obtained by first connecting the finite player game to a suitable control problem, whose optimal trajectories are the empirical means of Nash equilibria of the game, and in which the number of players $N$ becomes a parameter. True convergence to the unique minimizer of the limit control problem then holds for almost every initial mean. In cases of multiple optimizers, we focus on examples to show that some symmetry of the data ensures that the sequence admits a random limit which is distributes uniformly among the minimizers of the potential. Multidimensional examples of the convergence result appear here for the first time, which show the flexibility of our method. We also establish a similar convergence results for the corresponding linear-quadratic potential mean field games with common noise, as the noise vanishes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14842v1</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cecchin Alekos, Dianetti Jodi</dc:creator>
    </item>
    <item>
      <title>On the Learning Dynamics of RLVR at the Edge of Competence</title>
      <link>https://arxiv.org/abs/2602.14872</link>
      <description>arXiv:2602.14872v1 Announce Type: cross 
Abstract: Reinforcement learning with verifiable rewards (RLVR) has been a main driver of recent breakthroughs in large reasoning models. Yet it remains a mystery how rewards based solely on final outcomes can help overcome the long-horizon barrier to extended reasoning. To understand this, we develop a theory of the training dynamics of RL for transformers on compositional reasoning tasks. Our theory characterizes how the effectiveness of RLVR is governed by the smoothness of the difficulty spectrum. When data contains abrupt discontinuities in difficulty, learning undergoes grokking-type phase transitions, producing prolonged plateaus before progress recurs. In contrast, a smooth difficulty spectrum leads to a relay effect: persistent gradient signals on easier problems elevate the model's capabilities to the point where harder ones become tractable, resulting in steady and continuous improvement. Our theory explains how RLVR can improve performance at the edge of competence, and suggests that appropriately designed data mixtures can yield scalable gains. As a technical contribution, our analysis develops and adapts tools from Fourier analysis on finite groups to our setting. We validate the predicted mechanisms empirically via synthetic experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14872v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yu Huang, Zixin Wen, Yuejie Chi, Yuting Wei, Aarti Singh, Yingbin Liang, Yuxin Chen</dc:creator>
    </item>
    <item>
      <title>Variance-Reduced $(\varepsilon,\delta)-$Unlearning using Forget Set Gradients</title>
      <link>https://arxiv.org/abs/2602.14938</link>
      <description>arXiv:2602.14938v1 Announce Type: cross 
Abstract: In machine unlearning, $(\varepsilon,\delta)-$unlearning is a popular framework that provides formal guarantees on the effectiveness of the removal of a subset of training data, the forget set, from a trained model. For strongly convex objectives, existing first-order methods achieve $(\varepsilon,\delta)-$unlearning, but they only use the forget set to calibrate injected noise, never as a direct optimization signal. In contrast, efficient empirical heuristics often exploit the forget samples (e.g., via gradient ascent) but come with no formal unlearning guarantees. We bridge this gap by presenting the Variance-Reduced Unlearning (VRU) algorithm. To the best of our knowledge, VRU is the first first-order algorithm that directly includes forget set gradients in its update rule, while provably satisfying ($(\varepsilon,\delta)-$unlearning. We establish the convergence of VRU and show that incorporating the forget set yields strictly improved rates, i.e. a better dependence on the achieved error compared to existing first-order $(\varepsilon,\delta)-$unlearning methods. Moreover, we prove that, in a low-error regime, VRU asymptotically outperforms any first-order method that ignores the forget set.Experiments corroborate our theory, showing consistent gains over both state-of-the-art certified unlearning methods and over empirical baselines that explicitly leverage the forget set.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14938v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Martin Van Waerebeke, Marco Lorenzi, Kevin Scaman, El Mahdi El Mhamdi, Giovanni Neglia</dc:creator>
    </item>
    <item>
      <title>Locally Adaptive Multi-Objective Learning</title>
      <link>https://arxiv.org/abs/2602.14952</link>
      <description>arXiv:2602.14952v1 Announce Type: cross 
Abstract: We consider the general problem of learning a predictor that satisfies multiple objectives of interest simultaneously, a broad framework that captures a range of specific learning goals including calibration, regret, and multiaccuracy. We work in an online setting where the data distribution can change arbitrarily over time. Existing approaches to this problem aim to minimize the set of objectives over the entire time horizon in a worst-case sense, and in practice they do not necessarily adapt to distribution shifts. Earlier work has aimed to alleviate this problem by incorporating additional objectives that target local guarantees over contiguous subintervals. Empirical evaluation of these proposals is, however, scarce. In this article, we consider an alternative procedure that achieves local adaptivity by replacing one part of the multi-objective learning method with an adaptive online algorithm. Empirical evaluations on datasets from energy forecasting and algorithmic fairness show that our proposed method improves upon existing approaches and achieves unbiased predictions over subgroups, while remaining robust under distribution shift.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14952v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jivat Neet Kaur, Isaac Gibbs, Michael I. Jordan</dc:creator>
    </item>
    <item>
      <title>The gradient's limit of a definable family of functions admits a variational stratification</title>
      <link>https://arxiv.org/abs/2402.08272</link>
      <description>arXiv:2402.08272v4 Announce Type: replace 
Abstract: It is well-known that the convergence of a family of smooth functions does not imply the convergence of its gradients. In this work, we show that if the family is definable in an o-minimal structure (for instance semialgebraic, subanalytic, or any composition of the previous with exp, log), then the gradient's limit admits a variational stratification and, under mild assumptions, is a conservative set-valued field in the sense introduced by Bolte and Pauwels. Immediate implications of this result on convergence guarantees of smoothing methods are discussed. The result is established in a general form, where the functions in the original family might be non Lipschitz continuous, be vector-valued and the gradients are replaced by their Clarke Jacobians or an arbitrary mapping satisfying a definable variational stratification. In passing, we investigate various stability properties of definable variational stratifications which might be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.08272v4</guid>
      <category>math.OC</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sholom Schechtman (SAMOVAR)</dc:creator>
    </item>
    <item>
      <title>An Optimal Solution to Infinite Horizon Nonholonomic and Discounted Nonlinear Control Problems</title>
      <link>https://arxiv.org/abs/2403.16979</link>
      <description>arXiv:2403.16979v2 Announce Type: replace 
Abstract: This paper considers the infinite horizon optimal control problem for nonlinear systems. Under the condition of nonlinear controllability of the system to any terminal set containing the origin and forward invariance of the terminal set, we establish a regularized solution approach consisting of a ``finite free final time" optimal transfer problem to the terminal set, which renders the set globally asymptotically stable. Further, we show that the approximations converge to the optimal infinite horizon cost as the size of the terminal set decreases to zero. We also perform the analysis for the discounted problem and show that the terminal set is asymptotically stable only for a subset of the state space and not globally. The theory is empirically evaluated on various nonholonomic robotic systems to show that the cost of our approximate problem converges and the transfer time into the terminal set is dependent on the initial state of the system, necessitating the free final time formulation. We also do comparisons of our free-final time approach with nonlinear MPC.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16979v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.23919/ACC63710.2025.11107879</arxiv:DOI>
      <arxiv:journal_reference>2025 American Control Conference (ACC), 2025, pp. 692-697</arxiv:journal_reference>
      <dc:creator>Mohamed Naveed Gul Mohamed,  Abhijeet, Aayushman Sharma, Raman Goyal, Suman Chakravorty</dc:creator>
    </item>
    <item>
      <title>Learning nonnegative matrix factorizations from compressed data</title>
      <link>https://arxiv.org/abs/2409.04994</link>
      <description>arXiv:2409.04994v2 Announce Type: replace 
Abstract: We propose a flexible and theoretically supported framework for scalable nonnegative matrix factorization. The goal is to find nonnegative low-rank components directly from compressed measurements, accessing the original data only once or twice. We consider compression through randomized sketching methods that can be adapted to the data, or can be oblivious. We formulate optimization problems that only depend on the compressed data, but which can recover a nonnegative factorization which closely approximates the original matrix. The defined problems can be approached with a variety of algorithms, and in particular, we discuss variations of the popular multiplicative updates method for these compressed problems. We demonstrate the success of our approaches empirically and validate their performance in real-world applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.04994v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Abraar Chaudhry, Elizaveta Rebrova</dc:creator>
    </item>
    <item>
      <title>Accelerated Gradient Descent by Concatenation of Stepsize Schedules</title>
      <link>https://arxiv.org/abs/2410.12395</link>
      <description>arXiv:2410.12395v2 Announce Type: replace 
Abstract: This work considers stepsize schedules for gradient descent on smooth convex objectives. We extend the existing literature and propose a unified technique for constructing stepsizes with analytic bounds for an arbitrary number of iterations. This technique constructs new stepsize schedules by concatenating two stepsize schedules with fewer steps. Using this approach, we introduce two new families of stepsize schedules, achieving a convergence rate of $O(n^{-\log_2(\sqrt 2+1)})$ with state-of-the-art constants for the objective value and gradient norm of the last iterate, respectively. Furthermore, our analytically derived stepsize schedules either match or surpass the existing best numerically computed stepsize schedules.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12395v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zehao Zhang, Rujun Jiang</dc:creator>
    </item>
    <item>
      <title>Inpatient Overflow Management with Proximal Policy Optimization</title>
      <link>https://arxiv.org/abs/2410.13767</link>
      <description>arXiv:2410.13767v4 Announce Type: replace 
Abstract: Problem Definition: Managing inpatient flow in large hospital systems is challenging due to the complexity of assigning randomly arriving patients -- either waiting for primary units or being overflowed to alternative units. Current practices rely on ad-hoc rules, while prior analytical approaches struggle with the intractably large state and action spaces inherent in patient-unit matching. Scalable decision support is needed to optimize overflow management while accounting for time-periodic fluctuations in patient flow.
  Methodology/Results: We develop a scalable decision-making framework using Proximal Policy Optimization (PPO) to optimize overflow decisions in a time-periodic, long-run average cost setting. To address the combinatorial complexity, we introduce atomic actions, which decompose multi-patient routing into sequential assignments. We further enhance computational efficiency through a partially-shared policy network designed to balance parameter sharing with time-specific policy adaptations, and a queueing-informed value function approximation to improve policy evaluation. Our method significantly reduces the need for extensive simulation data, a common limitation in reinforcement learning applications. Case studies on hospital systems with up to twenty patient classes and twenty wards demonstrate that our approach matches or outperforms existing benchmarks, including approximate dynamic programming, which is computationally infeasible beyond five wards.
  Managerial Implications: Our framework offers a scalable, efficient, and explainable solution for managing patient flow in complex hospital systems. More broadly, our results highlight that domain-aware adaptation is more critical to improving algorithm performance than fine-tuning neural network parameters when applying general-purpose algorithms to specific applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.13767v4</guid>
      <category>math.OC</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jingjing Sun, Jim Dai, Pengyi Shi</dc:creator>
    </item>
    <item>
      <title>Heuristic Search for Linear Positive Systems</title>
      <link>https://arxiv.org/abs/2410.17220</link>
      <description>arXiv:2410.17220v2 Announce Type: replace 
Abstract: This work considers infinite-horizon optimal control of positive linear systems applied to the case of network routing problems. We demonstrate the equivalence between Stochastic Shortest Path (SSP) problems and optimal control of a certain class of linear systems. This is used to construct a heuristic search framework for linear {positive} systems inspired by existing methods for SSP. {We propose a heuristics-based algorithm for {efficiently} finding local solutions to the analyzed class of optimal control problems with {a given initial} state and {positive} linear dynamics.} {By leveraging the bound on optimality in each state provided by the heuristics, we also derive a novel distributed algorithm for calculating local controllers within a specified performance bound, with a distributed condition for termination.} More fundamentally, the results allow for analysis of the conditions for explicit solutions to the Bellman equation utilized by heuristic search methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.17220v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>David Ohlin, Anders Rantzer, Emma Tegling</dc:creator>
    </item>
    <item>
      <title>On uniqueness in structured model learning</title>
      <link>https://arxiv.org/abs/2410.22009</link>
      <description>arXiv:2410.22009v4 Announce Type: replace 
Abstract: This paper addresses the problem of uniqueness in learning physical laws for systems of partial differential equations (PDEs). Contrary to most existing approaches, it considers a framework of structured model learning, where existing, approximately correct physical models are augmented with components that are learned from data. The main results of the paper are a uniqueness and a convergence result that cover a large class of PDEs and a suitable class of neural networks used for approximating the unknown model components. The uniqueness result shows that, in the limit of full, noiseless measurements, a unique identification of the unknown model components as functions is possible as classical regularization-minimizing solutions of the PDE system. This result is complemented by a convergence result showing that model components learned as parameterized neural networks from incomplete, noisy measurements approximate the regularization-minimizing solutions of the PDE system in the limit. These results are possible under specific properties of the approximating neural networks and due to a dedicated choice of regularization. With this, a practical contribution of this analytic paper is to provide a class of model learning frameworks different to standard settings where uniqueness can be expected in the limit of full measurements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.22009v4</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>math.AP</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Martin Holler, Erion Morina</dc:creator>
    </item>
    <item>
      <title>Minimax Linear Regulator Problems for Positive Systems</title>
      <link>https://arxiv.org/abs/2411.04809</link>
      <description>arXiv:2411.04809v2 Announce Type: replace 
Abstract: Explicit solutions to optimal control problems are rarely obtainable. Of particular interest are the explicit solutions derived for minimax problems, providing a framework to address adversarial conditions and uncertainty. This work considers a multi-disturbance minimax Linear Regulator (LR) framework for positive linear time-invariant systems in continuous time, which, analogous to the Linear-Quadratic Regulator (LQR) problem, can be utilized for the stabilization of positive systems. The problem is studied for nonnegative and state-bounded disturbances. Dynamic programming theory is leveraged to derive explicit solutions to the minimax LR problem for both finite and infinite time horizons. In addition, a fixed-point method is proposed that computes the solution for the infinite horizon case, and the minimum L1-induced gain of the system is studied. We motivate the prospective scalability properties of our framework with a large-scale water management network.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04809v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Alba Gurpegui, Mark Jeeninga, Emma Tegling, Anders Rantzer</dc:creator>
    </item>
    <item>
      <title>Solving Monge problem by Hilbert space embeddings of probability measures</title>
      <link>https://arxiv.org/abs/2412.03478</link>
      <description>arXiv:2412.03478v5 Announce Type: replace 
Abstract: We propose deep learning methods for classical Monge's optimal mass transportation problems, where where the distribution constraint is treated as penalty terms defined by the maximum mean discrepancy in the theory of Hilbert space embeddings of probability measures. We prove that the transport maps given by the proposed methods converge to optimal transport maps in the problem with $L^2$ cost. Several numerical experiments validate our methods. In particular, we show that our methods are applicable to large-scale Monge problems. This is a corrected version of the ICORES 2025 proceedings paper.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.03478v5</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Takafumi Saito, Yumiharu Nakano</dc:creator>
    </item>
    <item>
      <title>High-Probability Polynomial-Time Complexity of Restarted PDHG for Linear Programming</title>
      <link>https://arxiv.org/abs/2501.00728</link>
      <description>arXiv:2501.00728v2 Announce Type: replace 
Abstract: The restarted primal-dual hybrid gradient method (rPDHG) is a first-order method that has recently received significant attention for its computational effectiveness in solving linear program (LP) problems. Despite its impressive practical performance, the theoretical iteration bounds for rPDHG can be exponentially poor. To shrink this gap between theory and practice, we show that rPDHG achieves polynomial-time complexity in a high-probability sense, under assumptions on the probability distribution from which the data instance is generated. We consider not only Gaussian distribution models but also sub-Gaussian distribution models as well. For standard-form LP instances with $m$ linear constraints and $n$ decision variables, we prove that rPDHG iterates settle on the optimal basis in $\widetilde{O}\left(\tfrac{n^{2.5}m^{0.5}}{\delta}\right)$ iterations, followed by $O\left(\frac{n^{0.5}m^{0.5}}{\delta}\ln\big(\tfrac{1}{\varepsilon}\big)\right)$ iterations to compute an $\varepsilon$-optimal solution. These bounds hold with probability at least $1-\delta$ for $\delta$ that is not exponentially small. The first-stage bound further improves to $\widetilde{O}\left(\frac{n^{2.5}}{\delta}\right)$ in the Gaussian distribution model. Experimental results confirm the tail behavior and the polynomial-time dependence on problem dimensions of the iteration counts. As an application of our probabilistic analysis, we explore how the disparity among the components of the optimal solution bears on the performance of rPDHG, and we provide guidelines for generating challenging LP test instance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.00728v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zikai Xiong</dc:creator>
    </item>
    <item>
      <title>Lagrange Multipliers and Duality with Applications to Constrained Support Vector Machine</title>
      <link>https://arxiv.org/abs/2501.01082</link>
      <description>arXiv:2501.01082v2 Announce Type: replace 
Abstract: In this paper, we employ the concept of quasi-relative interior to analyze the method of Lagrange multipliers and establish strong Lagrangian duality for nonsmooth convex optimization problems in Hilbert spaces. Then, we generalize the classical support vector machine (SVM) model by incorporating a new geometric constraint or a regularizer on the separating hyperplane, serving as a regularization mechanism for the SVM model. This new SVM model is examined using Lagrangian duality and other convex optimization techniques in both theoretical and numerical aspects via a new subgradient algorithm as well as a primal-dual method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.01082v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nguyen Mau Nam, Gary Sandine, Quoc Tran-Dinh</dc:creator>
    </item>
    <item>
      <title>Variable aggregation for nonlinear optimization problems</title>
      <link>https://arxiv.org/abs/2502.13869</link>
      <description>arXiv:2502.13869v3 Announce Type: replace 
Abstract: Variable aggregation has been largely studied as an important pre-solve algorithm for optimization of linear and mixed-integer programs. Although some nonlinear solvers and algebraic modeling languages implement variable aggregation as a pre-solve, the impact it can have on constrained nonlinear programs is unexplored. In this work, we formalize variable aggregation as a pre-solve algorithm to develop reduced-space formulations of nonlinear programs. A novel approximate maximum variable aggregation strategy is developed to aggregate as many variables as possible. Furthermore, aggregation strategies that preserve the problem structure are compared against approximate maximum aggregation. Our results show that variable aggregation can generally help to improve the convergence reliability of nonlinear programs. It can also help in reducing total solve time. However, Hessian evaluation can become a bottleneck if aggregation significantly increases the number of variables appearing nonlinearly in many constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13869v3</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sakshi Naik, Lorenz Biegler, Russell Bent, Robert Parker</dc:creator>
    </item>
    <item>
      <title>A Geometric Framework for Stochastic Iterations</title>
      <link>https://arxiv.org/abs/2504.02761</link>
      <description>arXiv:2504.02761v3 Announce Type: replace 
Abstract: This paper concerns models and convergence principles for dealing with stochasticity in a wide range of algorithms arising in nonlinear analysis and optimization in Hilbert spaces. It proposes a flexible geometric framework within which existing solution methods can be recast and improved, and new ones can be designed. Almost sure weak, strong, and linear convergence results are established in particular for stochastic fixed point iterations, the stochastic gradient descent method, and stochastic extrapolated parallel algorithms for feasibility problems. In these areas, the proposed algorithms exceed the features and convergence guarantees of the state of the art. Numerical applications to signal and image recovery are provided.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.02761v3</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Patrick L. Combettes, Javier I. Madariaga</dc:creator>
    </item>
    <item>
      <title>On the Convergence of Decentralized Stochastic Gradient-Tracking with Finite-Time Consensus</title>
      <link>https://arxiv.org/abs/2505.23577</link>
      <description>arXiv:2505.23577v3 Announce Type: replace 
Abstract: Algorithms for decentralized optimization and learning rely on local optimization steps coupled with combination steps over a graph. Recent works have demonstrated that using a time-varying sequence of matrices that achieves finite-time consensus can improve the communication and iteration complexity of decentralized optimization algorithms based on gradient tracking. In practice, a sequence of matrices satisfying the exact finite-time consensus property may not be available due to imperfect knowledge of the network topology, a limit on the length of the sequence, or numerical instabilities. In this work, we quantify the impact of approximate finite-time consensus sequences on the convergence of a gradient-tracking based decentralized optimization algorithm. Our results hold for any periodic sequence of combination matrices. We clarify the interplay between approximation error of the finite-time consensus sequence and the length of the sequence as well as typical problem parameters such as smoothness and gradient noise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.23577v3</guid>
      <category>math.OC</category>
      <category>eess.SP</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aaron Fainman, Stefan Vlaski</dc:creator>
    </item>
    <item>
      <title>An Integrated Optimization Framework for Smart Charging of Electric Bus Fleets under Dynamic Electricity Prices with On-Site Solar Generation, Energy Storage, and V2G operations</title>
      <link>https://arxiv.org/abs/2509.05940</link>
      <description>arXiv:2509.05940v2 Announce Type: replace 
Abstract: The rapid electrification of city bus fleets presents public transportation operators (PTOs) with the complex challenge of managing charging operations to minimize energy costs. Most existing studies on electric bus (EB) charging management rely on a discrete-time-based discretization approach, which is operationally unrealistic and limits their scalability for realistic applications. This study proposes a discrete-event optimization (DEO) approach for daily EB fleet charging management that considers peak power charges, photovoltaic (PV) generation with an energy storage system (ESS), vehicle-to-grid (V2G) operations, and battery degradation costs. We apply the DEO approach to a real-world case in Brussels involving 28 articulated EBs and 232 trips. A set of parametric instances is used to assess computational scalability. The results demonstrate that the DEO formulation can solve instances of realistic size within practical computation times with tight optimality gaps. A thorough cost analysis was conducted to evaluate the added value of V2G benefits and on-site PV generation. Key findings indicate that incorporating demand charges into the optimization reduces daily costs by 5% and decreases the share of peak power costs by 9%, underscoring the importance of load management. Integrating PV and ESS results in a total net cost reduction of up to 56%, with ESS primarily used for energy arbitrage rather than direct bus charging. V2G participation is highly sensitive to battery degradation costs and policy incentives. Combining all extensions results in a 58% reduction in total operational expenses compared to the baseline, demonstrating the significant value of smart (dis)charging tools for PTOs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.05940v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Louise Caustur, Penelope Hertoghe, Tai-Yu Ma, Martina Vandebroek</dc:creator>
    </item>
    <item>
      <title>Complexity Bounds for Smooth Multiobjective Optimization</title>
      <link>https://arxiv.org/abs/2509.13550</link>
      <description>arXiv:2509.13550v2 Announce Type: replace 
Abstract: We study the oracle complexity of finding $\varepsilon$-Pareto stationary points in smooth multiobjective optimization with $m$ objectives. Progress is measured by the Pareto stationarity gap $\mathcal{G}(x)$, the norm of the best convex combination of objective gradients. Our analysis relies on a non-degenerate lifting that embeds hard single-objective instances into MOO instances with distinct objectives and non-singleton Pareto fronts while preserving lower bounds on $\mathcal{G}$. We establish: (i) in the $\mu$-strongly convex case, any span first-order method has worst-case linear convergence no faster than $\exp(-\Theta(T/\sqrt{\kappa}))$ after $T$ oracle calls, yielding $\Theta(\sqrt{\kappa}\log(1/\varepsilon))$ iterations and matching accelerated upper bounds; (ii) in the convex case, an $\Omega(1/T)$ min-iterate lower bound for oblivious one-step methods and a universal last-iterate lower bound $\Omega(1/T^2)$ for oblivious span methods via polynomial-degree arguments, and we further show this latter bound is loose (for general adaptive methods) by importing geometric lower bounds to obtain an $\Omega(1/T)$ min-iterate lower bound for general adaptive first-order methods; (iii) in the nonconvex case with $L$-Lipschitz gradients, an $\Omega(\sqrt{L}/(T+1))$-type lower bound on $\mathcal{G}$ (tight in order), implying $\Omega(1/\varepsilon^2)$ iterations to reach $\mathcal{G}(x)\le\varepsilon$ up to natural scaling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.13550v2</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Phillipe R. Sampaio</dc:creator>
    </item>
    <item>
      <title>Graph-Aware Learning Rates for Decentralized Optimization</title>
      <link>https://arxiv.org/abs/2509.14854</link>
      <description>arXiv:2509.14854v2 Announce Type: replace 
Abstract: We propose an adaptive step-size rule for decentralized optimization. Choosing a step-size that balances convergence and stability is challenging. This is amplified in the decentralized setting as agents observe only local (possibly stochastic) gradients and global information (like smoothness) is unavailable. We derive a step-size rule from first principles. The resulting formulation reduces to the well-known Polyak's rule in the single-agent setting, and is suitable for use with stochastic gradients. The method is parameter free, apart from requiring the optimal objective value, which is readily available in many applications. Numerical simulations demonstrate that the performance is comparable to the optimally fine-tuned step-size.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14854v2</guid>
      <category>math.OC</category>
      <category>eess.SP</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aaron Fainman, Stefan Vlaski</dc:creator>
    </item>
    <item>
      <title>Pareto-optimal Trade-offs Between Communication and Computation with Flexible Gradient Tracking</title>
      <link>https://arxiv.org/abs/2509.18129</link>
      <description>arXiv:2509.18129v2 Announce Type: replace 
Abstract: This paper addresses distributed stochastic optimization problems under non-i.i.d. data, focusing on the inherent trade-offs between communication and computational efficiency. To this end, we propose FlexGT, a flexible snapshot gradient tracking method that enables tunable numbers of local updates and neighbor communications per round, thereby adapting efficiently to diverse system resource conditions. Leveraging a unified convergence analysis framework, we derive tight communication and computational complexity for FlexGT with explicit dependence on objective properties and certain tunable parameters. Moreover, we introduce an accelerated variant, termed Acc-FlexGT, and prove that, with prior knowledge of the graph, it achieves Pareto-optimal trade-offs between communication and computation. Particularly, in the nonconvex case, Acc-FlexGT achieves the optimal iteration complexity of $\tilde{\mathcal{O}}\left( \left( L\sigma ^2 \right) /\left( n\epsilon ^2 \right) +L/\left( \epsilon \sqrt{1-\sqrt{\rho _W}} \right) \right) $ and optimal communication complexity of $\tilde{\mathcal{O}}\left( L/\left( \epsilon \sqrt{1-\sqrt{\rho _W}} \right) \right)$ for appropriately chosen numbers of local updates, matching existing lower bounds up to logarithmic factors. And, it improves the existing results for the strongly convex case by a factor of $\tilde{\mathcal{O}} \left( 1/\sqrt{\epsilon} \right)$, where $\epsilon$ is the targeted accuracy, $n$ the number of nodes, $L$ the Lipschitz constant, $\rho_W$ the connectivity of the graph, and $\sigma$ the stochastic gradient variance. Numerical experiments corroborate the theoretical results and demonstrate the effectiveness of the proposed methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.18129v2</guid>
      <category>math.OC</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yan Huang, Jinming Xu, Li Chai, Jiming Chen, Karl H. Johansson</dc:creator>
    </item>
    <item>
      <title>Efficient Douglas-Rachford Methods on Hadamard Manifolds with Applications to the Heron Problems</title>
      <link>https://arxiv.org/abs/2509.23939</link>
      <description>arXiv:2509.23939v2 Announce Type: replace 
Abstract: Our interest lies in developing some efficient methods for minimizing the sum of two geodesically convex functions on Hadamard manifolds, with the aim to enhance the convergence of the Douglas-Rachford algorithm in Hadamard manifolds. Specifically, we propose two types of algorithms: inertial and non-inertial algorithms. The convergence analysis of both algorithms is provided under suitable assumptions on algorithmic parameters and the geodesic convexity of the objective functions. This convergence analysis is based on fixed-point theory for nonexpansive operators. We also study the convergence rates of these two methods. Additionally, we introduce parallel Douglas-Rachford type algorithms for minimizing functionals containing multiple summands with applications to the generalized Heron problem on Hadamard manifolds. To demonstrate the effectiveness of the proposed algorithms, we present some numerical experiments for the generalized Heron problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.23939v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>D. R. Sahu, Shikher Sharma, Pankaj Gautam</dc:creator>
    </item>
    <item>
      <title>Inverse Mixed-Integer Programming: Learning Constraints then Objective Functions</title>
      <link>https://arxiv.org/abs/2510.04455</link>
      <description>arXiv:2510.04455v2 Announce Type: replace 
Abstract: Data-driven inverse optimization for mixed-integer linear programs (MILPs), which seeks to learn an objective function and constraints consistent with observed decisions, is important for building accurate mathematical models in a variety of domains, including power systems and scheduling. However, to the best of our knowledge, existing data-driven inverse optimization methods primarily focus on learning objective functions under known constraints, and learning both objective functions and constraints from data remains largely unexplored. In this paper, we propose a two-stage approach for a class of inverse optimization problems in which the objective is a linear combination of given feature functions and the constraints are parameterized by unknown functions and thresholds. Our method first learns the constraints and then, conditioned on the learned constraints, estimates the objective-function weights. On the theoretical side, we provide finite-sample guarantees for solving the proposed inverse optimization problem. To this end, we develop statistical learning tools for pseudo-metric spaces under sub-Gaussian assumptions and use them to derive a learning-theoretic framework for inverse optimization with both unknown objectives and constraints. On the experimental side, we demonstrate that our method successfully solves inverse optimization problems on scheduling instances formulated as ILPs with up to 100 decision variables.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.04455v2</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Akira Kitaoka</dc:creator>
    </item>
    <item>
      <title>Carleman Estimates for Backward Anisotropic Stochastic Parabolic Equations with General Dynamic Boundary Conditions and Applications</title>
      <link>https://arxiv.org/abs/2510.12345</link>
      <description>arXiv:2510.12345v2 Announce Type: replace 
Abstract: We investigate a backward anisotropic stochastic parabolic equation with general dynamic boundary conditions, where the drift involves both $\mathbb{L}^2$ and $\mathbb{H}^{-1}$ bulk--surface terms. We first establish the well-posedness of this equation. Subsequently, we derive a new Carleman estimate through a two-step approach. In the first step, using a weighted identity method together with a careful treatment of the boundary integral terms arising from the dynamic boundary conditions, we obtain an intermediate Carleman estimate for backward anisotropic stochastic parabolic equations without weak divergence source terms. In the second step, a duality method combined with suitable optimization techniques is employed to incorporate the weak divergence source terms. As applications of the derived Carleman estimate, we address two control problems. First, we establish null controllability for forward anisotropic stochastic parabolic equations with general dynamic boundary conditions. These equations involve both reaction and convection terms, with adapted, bounded stochastic bulk--surface coefficients. Moreover, we provide an explicit estimate of the null controllability cost, i.e., a bound on the minimal norm of controls required to drive the system to zero at the terminal time $T$. Second, we study an insensitizing control problem for this class of equations. The goal is to determine controls for systems with partially unknown initial data such that a given energy functional remains insensitive to small perturbations of these data. In this work, the functional involves the norm of the state over a localized bulk--surface region, together with the norm of its tangential gradient over a localized boundary region.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.12345v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Said Boulite, Abdellatif Elgrou, Lahcen Maniar, Abdelaziz Rhandi</dc:creator>
    </item>
    <item>
      <title>On the feasibility of generalized inverse linear programs</title>
      <link>https://arxiv.org/abs/2511.04549</link>
      <description>arXiv:2511.04549v2 Announce Type: replace 
Abstract: We investigate the feasibility problem for generalized inverse linear programs. Given an LP with affinely parametrized objective function and right-hand side as well as a target set Y, the goal is to decide whether the parameters can be chosen such that there exists an optimal solution that belongs to Y (optimistic scenario) or such that all optimal solutions belong to Y (pessimistic scenario). We study the complexity of this decision problem and show how it depends on the structure of the set Y, the form of the LP, the adjustable parameters, and the underlying scenario. For a target singleton Y={y}, we show that the problem is tractable if the given LP is in standard form, but NP-hard if the LP is given in natural form. If instead we are given a target basis B, the problem in standard form becomes NP-complete in the optimistic case, while remaining tractable in the pessimistic case. For partially fixed target solutions, the problem gets almost immediately NP-hard, but for particular cases we prove tractability if the number of free target variables is fixed. Moreover, we give a rigorous proof of membership in NP for any polyhedral target set, and discuss how this property can be extended to more general target sets using an oracle-based approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.04549v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christoph Buchheim, Lowig T. Duer</dc:creator>
    </item>
    <item>
      <title>Quadratic Mean-Field BSDEs and Exponential Utility Maximization</title>
      <link>https://arxiv.org/abs/2511.17214</link>
      <description>arXiv:2511.17214v3 Announce Type: replace 
Abstract: In this paper, we study a class of real-valued mean-field backward stochastic differential equations (BSDEs) with generators of quadratic growth in the control variable and the mean-field term. Under this assumption, together with a bounded terminal condition, we establish the existence and uniqueness of solutions. Our approach departs from classical fixed-point arguments and instead combines Malliavin calculus with refined BMO and stability estimates. The result bridges the gap between the quadratic BSDE results of [Ann. Probab. 45 (2017), pp.~3795--3828] and Hao et al. [Ann. Appl. Probab. 35 (2025), pp.~2128--2174]. Moreover, motivated by the structure of the mean-field exponential utility maximization problem introduced in our paper, we extend our framework to terminal conditions without continuity or the Markovian assumption. We establish the existence and uniqueness of solutions under a smallness terminla value on the terminal conditions. We then apply this extended theory to solve a mean-field exponential utility maximization problem, which developing the classical framework of Hu et al. [Ann. Appl. Probab. 15 (2005), pp.~1691--1712] to a fully coupled quadratic mean-field setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.17214v3</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yining Ding, Kihun Nam, Jiaqiang Wen</dc:creator>
    </item>
    <item>
      <title>Identifying faulty edges in resistive electrical networks</title>
      <link>https://arxiv.org/abs/2512.23527</link>
      <description>arXiv:2512.23527v2 Announce Type: replace 
Abstract: Given a resistive electrical network, we would like to determine whether all the resistances (edges) in the network are working, and if not, identify which edge (or edges) are faulty. To make this determination, we are allowed to measure the effective resistance between certain pairs of nodes (which can be done by measuring the amount of current when one unit of voltage difference is applied at the chosen pair of nodes). The goal is to determine which edge, if any, is not working in the network using the smallest number of measurements. We prove rigorous upper and lower bounds on this optimal number of measurements for different classes of graphs. These bounds are tight for several of these classes showing that our measurement strategies are optimal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.23527v2</guid>
      <category>math.OC</category>
      <category>cs.DM</category>
      <category>cs.IT</category>
      <category>math.CO</category>
      <category>math.IT</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Barbara Fiedorowicz, Amitabh Basu</dc:creator>
    </item>
    <item>
      <title>Winning Criteria for Open Games: A Game-Theoretic Approach to Prefix Codes</title>
      <link>https://arxiv.org/abs/2601.17521</link>
      <description>arXiv:2601.17521v2 Announce Type: replace 
Abstract: We study two-player games with alternating moves played on infinite trees. Our main focus is on the case where the trees are full (regular) and the winning set is open (with respect to the product topology on the tree). Gale and Stewart showed that in this setting one of the players always has a winning strategy, though it is not known in advance which player. We present simple necessary conditions for the first player to have a winning strategy, and establish an equivalence between winning sets that guarantee a win for the first player and maximal prefix codes. Using this equivalence, we derive a necessary algebraic condition for winning, and exhibit a family of games for which this algebraic condition is in fact equivalent to winning. We introduce the concept of coverings, and show that by covering the tree of the game with an infinite labeled tree corresponding to the free group, we can use "game-theoretic tools" to derive a simple trait of maximal prefix codes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.17521v2</guid>
      <category>math.OC</category>
      <category>cs.GT</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dean Kraizberg</dc:creator>
    </item>
    <item>
      <title>Enhancing Exploration in Global Optimization by Noise Injection in the Probability Measures Space</title>
      <link>https://arxiv.org/abs/2601.22753</link>
      <description>arXiv:2601.22753v2 Announce Type: replace 
Abstract: McKean-Vlasov (MKV) systems provide a unifying framework for recent state-of-the-art particlebased methods for global optimization. While individual particles follow stochastic trajectories, the probability law evolves deterministically in the mean-field limit, potentially limiting exploration in multimodal landscapes. We introduce two principled approaches to inject noise directly into the probability law dynamics: a perturbative method based on conditional MKV theory, and a geometric approach leveraging tangent space structure. While these approaches are of independent interest, the aim of this work is to apply them to global optimization. Our framework applies generically to any method that can be formulated as a MKV system. Extensive experiments on multimodal objective functions demonstrate that both our noise injection strategies enhance consistently the exploration and convergence across different configurations of dynamics, such as Langevin, Consensus-Based Optimization, and Stein Boltzmann Sampling, providing a versatile toolkit for global optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.22753v2</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ga\"etan Serr\'e (ENS Paris Saclay, CB), Pierre Germain (UNINE), Samuel Gruffaz (CB, ENS Paris Saclay), Argyris Kalogeratos (CB, ENS Paris Saclay)</dc:creator>
    </item>
    <item>
      <title>Optimization-based control by interconnection of nonlinear port-Hamiltonian systems</title>
      <link>https://arxiv.org/abs/2602.06670</link>
      <description>arXiv:2602.06670v2 Announce Type: replace 
Abstract: In this paper, we formulate an optimization-based control-by-interconnection approach to the stabilization problem of nonlinear port-Hamiltonian systems. Motivated by model predictive control, the feedback is defined as an initial part of a suboptimal solution of a finite horizon optimal control problem. To this end, we write the optimization method given by a primal-dual gradient dynamics arising from a possibly control-constrained optimal control problem as a port-Hamiltonian system. Then, using the port-Hamiltonian structure of the plant, we show that the MPC-type feedback law is indeed a structure-preserving interconnection of two port-Hamiltonian systems. We prove that, under an observability assumption, the interconnected system asymptotically stabilizes the plant dynamics. We illustrate the theoretical results by means of a numerical example.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.06670v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Till Preuster, Hannes Gernandt, Manuel Schaller</dc:creator>
    </item>
    <item>
      <title>Experimenting under Stochastic Congestion</title>
      <link>https://arxiv.org/abs/2302.12093</link>
      <description>arXiv:2302.12093v5 Announce Type: replace-cross 
Abstract: We study randomized experiments in a service system when stochastic congestion can arise from temporarily limited supply or excess demand. Such congestion gives rise to cross-unit interference between the waiting customers, and analytic strategies that do not account for this interference may be biased. In current practice, one of the most widely used ways to address stochastic congestion is to use switchback experiments that alternatively turn a target intervention on and off for the whole system. We find, however, that under a queueing model for stochastic congestion, the standard way of analyzing switchbacks is inefficient, and that estimators that leverage the queueing model can be materially more accurate. Additionally, we show how the queueing model enables estimation of total policy gradients from unit-level randomized experiments, thus giving practitioners an alternative experimental approach they can use without needing to pre-commit to a fixed switchback length before data collection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.12093v5</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <category>stat.ME</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuangning Li, Ramesh Johari, Xu Kuang, Stefan Wager</dc:creator>
    </item>
    <item>
      <title>A Theory of Feature Learning in Kernel Models</title>
      <link>https://arxiv.org/abs/2310.11736</link>
      <description>arXiv:2310.11736v4 Announce Type: replace-cross 
Abstract: We study feature learning in a compositional variant of kernel ridge regression in which the predictor is applied to a learnable linear transformation of the input. When the response depends on the input only through a low-dimensional predictive subspace, we show that all global minimizers of the population objective for the linear transformation annihilate directions orthogonal to this subspace, and in certain regimes, exactly identify the subspace. Moreover, we show that global minimizers of the finite-sample objective inherit the exact same low-dimensional structure with high probability, even without any explicit penalization on the linear transformation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.11736v4</guid>
      <category>math.ST</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yunlu Chen, Yang Li, Keli Liu, Feng Ruan</dc:creator>
    </item>
    <item>
      <title>Exact Solution to Data-Driven Inverse Optimization of MILPs in Finite Time via Gradient-Based Methods</title>
      <link>https://arxiv.org/abs/2405.14273</link>
      <description>arXiv:2405.14273v5 Announce Type: replace-cross 
Abstract: A data-driven inverse optimization problem (DDIOP) seeks to estimate an objective function (i.e., weights) that is consistent with observed optimal-solution data, and is important in many applications, including those involving mixed integer linear programs (MILPs). In the DDIOP for MILPs, the prediction loss on features (PLF), defined as the discrepancy between observed and predicted feature values, becomes discontinuous with respect to the weights, which makes it difficult to apply gradient-based optimization. To address this issue, we focus on a Lipschitz continuous and convex suboptimality loss. By exploiting its convex and piecewise-linear structure and the interiority of the minimum set, we show that a broad class of gradient-based optimization methods, including projected subgradient descent (PSGD), reaches the minimum suboptimality loss value in a finite number of iterations, thereby exactly solving the DDIOP for MILPs. Furthermore, as a corollary, we show that PSGD attains the minimum PLF in finitely many iterations. We also derive an upper bound on the number of iterations required for PSGD to reach finite convergence, and confirm the finite-step behavior through numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14273v5</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Akira Kitaoka</dc:creator>
    </item>
    <item>
      <title>Disintegrated optimal transport for metric fiber bundles</title>
      <link>https://arxiv.org/abs/2407.01879</link>
      <description>arXiv:2407.01879v3 Announce Type: replace-cross 
Abstract: We define a new two-parameter family of metrics on subsets of Borel probability measures on general metric fiber bundles, called the $ \textit{disintegrated Monge--Kantorovich metrics}$. This family contains the classical Monge-Kantorovich metrics, linearized optimal transport distance, and fibered Wasserstein distances, and certain cases admit isometric embeddings of the sliced and max-sliced Wasserstein spaces. We prove these metrics are complete, separable (except an endpoint case), and geodesic, with a dual representation. Our results cannot be obtained by applying the theory of $L^q$ maps valued in spaces of probability measures, in fact the $L^q$ map case can be recovered from our results by taking the underlying bundle as a trivial product bundle, and the geodesicness and duality results are new even in the fibered Wasserstein case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.01879v3</guid>
      <category>math.MG</category>
      <category>math.OC</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jun Kitagawa, Asuka Takatsu</dc:creator>
    </item>
    <item>
      <title>Strongly connected orientations and integer lattices</title>
      <link>https://arxiv.org/abs/2410.13665</link>
      <description>arXiv:2410.13665v3 Announce Type: replace-cross 
Abstract: Let $D=(V,A)$ be a digraph whose underlying undirected graph is $2$-edge-connected, and let $P$ be the polytope whose vertices are the incidence vectors of arc sets whose reversal makes $D$ strongly connected. We study the lattice theoretic properties of the integer points contained in a proper face $F$ of $P$ not contained in $\{x:x_a=i\}$ for any $a\in A,i\in \{0,1\}$. We prove under a mild necessary condition that $F\cap \{0,1\}^A$ contains an integral basis $B$, i.e., $B$ is linearly independent, and any integral vector in the linear hull of $F$ is an integral linear combination of $B$. This result is surprising as the integer points in $F$ do not necessarily form a Hilbert basis. In proving the result, we develop a theory similar to Matching Theory for degree-constrained dijoins in bipartite digraphs. Our result has consequences for head-disjoint strong orientations in hypergraphs, and also to a famous conjecture by Woodall that the minimum size of a dicut of $D$, say $\tau$, is equal to the maximum number of disjoint dijoins. We prove a relaxation of this conjecture, by finding for any prime number $p\geq 2$, a $p$-adic packing of dijoins of value $\tau$ and of support size at most $2|A|$. We also prove that the all-ones vector belongs to the lattice generated by $F\cap \{0,1\}^A$, where $F$ is the face of $P$ satisfying $x(\delta^+(U))=1$ for every dicut $\delta^+(U)$ with minimum size.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.13665v3</guid>
      <category>math.CO</category>
      <category>math.OC</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ahmad Abdi, G\'erard Cornu\'ejols, Siyue Liu, Olha Silina</dc:creator>
    </item>
    <item>
      <title>Denoising Diffusions with Optimal Transport: Localization, Curvature, and Multi-Scale Complexity</title>
      <link>https://arxiv.org/abs/2411.01629</link>
      <description>arXiv:2411.01629v2 Announce Type: replace-cross 
Abstract: Adding noise is easy; what about denoising? Diffusion is easy; what about reverting a diffusion? Diffusion-based generative models aim to denoise a Langevin diffusion chain, moving from a log-concave equilibrium measure $\nu$, say an isotropic Gaussian, back to a complex, possibly non-log-concave initial measure $\mu$. The score function performs denoising, moving backward in time, and predicting the conditional mean of the past location given the current one. We show that score denoising is the optimal backward map in transportation cost. What is its localization uncertainty? We show that the curvature function determines this localization uncertainty, measured as the conditional variance of the past location given the current. We study in this paper the effectiveness of the diffuse-then-denoise process: the contraction of the forward diffusion chain, offset by the possible expansion of the backward denoising chain, governs the denoising difficulty. For any initial measure $\mu$, we prove that this offset net contraction at time $t$ is characterized by the curvature complexity of a smoothed $\mu$ at a specific signal-to-noise ratio (SNR) scale $r(t)$. We discover that the multi-scale curvature complexity collectively determines the difficulty of the denoising chain. Our multi-scale complexity quantifies a fine-grained notion of average-case curvature instead of the worst-case. Curiously, it depends on an integrated tail function, measuring the relative mass of locations with positive curvature versus those with negative curvature; denoising at a specific SNR scale is easy if such an integrated tail is light. We conclude with several non-log-concave examples to demonstrate how the multi-scale complexity probes the bottleneck SNR for the diffuse-then-denoise process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.01629v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>Transactions on Machine Learning Research, 2026</arxiv:journal_reference>
      <dc:creator>Tengyuan Liang, Kulunu Dharmakeerthi, Takuya Koriyama</dc:creator>
    </item>
    <item>
      <title>Joint Optimization of Multimodal Transit Frequency and Shared Autonomous Vehicle Fleet Size with Hybrid Metaheuristic and Nonlinear Programming</title>
      <link>https://arxiv.org/abs/2412.19401</link>
      <description>arXiv:2412.19401v3 Announce Type: replace-cross 
Abstract: Shared autonomous vehicles (SAVs) bring competition to traditional transit services but redesigning multimodal transit network can utilize SAVs as feeders to enhance service efficiency and coverage. This paper presents an optimization framework for the joint multimodal transit frequency and SAV fleet size problem, a variant of the transit network frequency setting problem. The objective is to maximize total transit ridership (including SAV-fed trips and subtracting boarding rejections) across multiple time periods under budget constraints, considering endogenous mode choice (transit, point-to-point SAVs, driving) and route selection, while allowing for strategic route removal by setting frequencies to zero. Due to the problem's non-linear, non-convex nature and the computational challenges of large-scale networks, we develop a hybrid solution approach that combines a metaheuristic approach (particle swarm optimization) with nonlinear programming for local solution refinement. To ensure computational tractability, the framework integrates analytical approximation models for SAV waiting times based on fleet utilization, multimodal network assignment for route choice, and multinomial logit mode choice behavior, bypassing the need for computationally intensive simulations within the main optimization loop. Applied to the Chicago metropolitan area's multimodal network, our method illustrates a 33.3% increase in transit ridership through optimized transit route frequencies and SAV integration, particularly enhancing off-peak service accessibility and strategically reallocating resources.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.19401v3</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.trc.2026.105568</arxiv:DOI>
      <arxiv:journal_reference>Transportation Research Part C: Emerging Technologies, 2026</arxiv:journal_reference>
      <dc:creator>Max T. M. Ng, Hani S. Mahmassani, Draco Tong, Omer Verbas, Taner Cokyasar</dc:creator>
    </item>
    <item>
      <title>Faster Adaptive Optimization via Expected Gradient Outer Product Reparameterization</title>
      <link>https://arxiv.org/abs/2502.01594</link>
      <description>arXiv:2502.01594v2 Announce Type: replace-cross 
Abstract: Adaptive optimization algorithms -- such as Adagrad, Adam, and their variants -- have found widespread use in machine learning, signal processing and many other settings. Several methods in this family are not rotationally equivariant, meaning that simple reparameterizations (i.e. change of basis) can drastically affect their convergence. However, their sensitivity to the choice of parameterization has not been systematically studied; it is not clear how to identify a "favorable" change of basis in which these methods perform best. In this paper we propose a reparameterization method and demonstrate both theoretically and empirically its potential to improve their convergence behavior. Our method is an orthonormal transformation based on the expected gradient outer product (EGOP) matrix, which can be approximated using either full-batch or stochastic gradient oracles. We show that for a broad class of functions, the sensitivity of adaptive algorithms to choice-of-basis is influenced by the decay of the EGOP matrix spectrum. We illustrate the potential impact of EGOP reparameterization by presenting empirical evidence and theoretical arguments that common machine learning tasks with "natural" data exhibit EGOP spectral decay.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01594v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Adela DePavia, Jose Cruzado, Jiayou Liang, Vasileios Charisopoulos, Rebecca Willett</dc:creator>
    </item>
    <item>
      <title>Learning Rate Annealing Improves Tuning Robustness in Stochastic Optimization</title>
      <link>https://arxiv.org/abs/2503.09411</link>
      <description>arXiv:2503.09411v2 Announce Type: replace-cross 
Abstract: The learning rate in stochastic gradient methods is a critical hyperparameter that is notoriously costly to tune via standard grid search, especially for training modern large-scale models with billions of parameters. We identify a theoretical advantage of learning rate annealing schemes that decay the learning rate to zero at a polynomial rate, such as the widely-used cosine schedule, by demonstrating their increased robustness to initial parameter misspecification due to a coarse grid search. We present an analysis in a stochastic convex optimization setup demonstrating that the convergence rate of stochastic gradient descent with annealed schedules depends sublinearly on the multiplicative misspecification factor $\rho$ (i.e., the grid resolution), achieving a rate of $O(\rho^{1/(2p+1)}/\sqrt{T})$ where $p$ is the degree of polynomial decay and $T$ is the number of steps. This is in contrast to the $O(\rho/\sqrt{T})$ rate obtained under the inverse-square-root and fixed stepsize schedules, which depend linearly on $\rho$. Experiments confirm the increased robustness compared to tuning with a fixed stepsize, that has significant implications for the computational overhead of hyperparameter search in practical training scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09411v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amit Attia, Tomer Koren</dc:creator>
    </item>
    <item>
      <title>Asymptotics of the quantization problem on metric measure spaces</title>
      <link>https://arxiv.org/abs/2503.18779</link>
      <description>arXiv:2503.18779v2 Announce Type: replace-cross 
Abstract: The problem of quantization of measures looks for best approximations of probability measures on a metric space by discrete measures supported on $N$ points, where the error of approximation is measured with respect to the Wasserstein distance. Zador's theorem states that, for measures on $\mathbb{R}^d$ or $d$-dimensional Riemannian manifolds satisfying appropriate integrability conditions, the quantization error decays to zero as $N \to \infty$ at the rate $N^{-1/d}$.
  In this paper, we provide a general treatment of the asymptotics of quantization on metric measure spaces $(X, \nu)$. We show that a weaker version of Zador's theorem involving the Hausdorff densities of $\nu$ holds also in this general setting. We also prove Zador's theorem in full for appropriate $m$-rectifiable measures on Euclidean space, answering a conjecture by Graf and Luschgy in the affirmative. For both results, the higher integrability conditions of Zador's theorem are replaced with a general notion of $(p,s)$-quantizability, which follows from Pierce-type (non-asymptotic) upper bounds on the quantization error, and we also prove multiple such bounds at the level of metric measure spaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.18779v2</guid>
      <category>math.MG</category>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s00208-026-03376-x</arxiv:DOI>
      <arxiv:journal_reference>Math. Ann. 394, 48 (2026)</arxiv:journal_reference>
      <dc:creator>Ata Deniz Aydin</dc:creator>
    </item>
    <item>
      <title>The Statistical Fairness-Accuracy Frontier</title>
      <link>https://arxiv.org/abs/2508.17622</link>
      <description>arXiv:2508.17622v3 Announce Type: replace-cross 
Abstract: We study fairness-accuracy tradeoffs when a single predictive model must serve multiple demographic groups. A useful tool for understanding this tradeoff is the fairness-accuracy (FA) Pareto frontier, which characterizes the set of models that cannot be improved in either fairness or accuracy without worsening the other. While characterizing the FA frontier requires full knowledge of the data distribution, we focus on the finite-sample regime, quantifying how well a designer can approximate any point on the frontier from limited data and bounding the worst-case gap. In particular, we derive worst-case-optimal estimators that depend on the designer's knowledge of the covariate distribution. For each estimator, we characterize how finite-sample effects asymmetrically impact each group's welfare and identify optimal sample allocation strategies. Finally, we provide uniform finite-sample bounds for the entire FA frontier, yielding confidence bands that quantify the reliability of welfare comparisons across alternative fairness-accuracy tradeoffs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.17622v3</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>econ.TH</category>
      <category>math.OC</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alireza Fallah, Michael I. Jordan, Annie Ulichney</dc:creator>
    </item>
    <item>
      <title>Online reinforcement learning via sparse Gaussian mixture model Q-functions</title>
      <link>https://arxiv.org/abs/2509.14585</link>
      <description>arXiv:2509.14585v3 Announce Type: replace-cross 
Abstract: This paper introduces a structured and interpretable online policy-iteration framework for reinforcement learning (RL), built around the novel class of sparse Gaussian mixture model Q-functions (S-GMM-QFs). Extending earlier work that trained GMM-QFs offline, the proposed framework develops an online scheme that leverages streaming data to encourage exploration. Model complexity is regulated through sparsification by Hadamard overparametrization, which mitigates overfitting while preserving expressiveness. The parameter space of S-GMM-QFs is naturally endowed with a Riemannian manifold structure, allowing for principled parameter updates via online gradient descent on a smooth objective. Numerical experiments show that S-GMM-QFs match or even outperform dense deep RL (DeepRL) methods on standard benchmarks while using significantly fewer parameters. Moreover, they maintain strong performance even in low-parameter regimes where sparsified DeepRL methods fail to generalize.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14585v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Minh Vu, Konstantinos Slavakis</dc:creator>
    </item>
    <item>
      <title>EigenSafe: A Spectral Framework for Learning-Based Probabilistic Safety Assessment</title>
      <link>https://arxiv.org/abs/2509.17750</link>
      <description>arXiv:2509.17750v2 Announce Type: replace-cross 
Abstract: We present EigenSafe, an operator-theoretic framework for safety assessment of learning-enabled stochastic systems. In many robotic applications, the dynamics are inherently stochastic due to factors such as sensing noise and environmental disturbances, and it is challenging for conventional methods such as Hamilton-Jacobi reachability and control barrier functions to provide a well-calibrated safety critic that is tied to the actual safety probability. We derive a linear operator that governs the dynamic programming principle for safety probability, and find that its dominant eigenpair provides critical safety information for both individual state-action pairs and the overall closed-loop system. The proposed framework learns this dominant eigenpair, which can be used to either inform or constrain policy updates. We demonstrate that the learned eigenpair effectively facilitates safe reinforcement learning. Further, we validate its applicability in enhancing the safety of learned policies from imitation learning through robot manipulation experiments using a UR3 robotic arm in a food preparation task.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.17750v2</guid>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Inkyu Jang, Jonghae Park, Sihyun Cho, Chams E. Mballo, Claire J. Tomlin, H. Jin Kim</dc:creator>
    </item>
    <item>
      <title>Oracle-based Uniform Sampling from Convex Bodies</title>
      <link>https://arxiv.org/abs/2510.02983</link>
      <description>arXiv:2510.02983v2 Announce Type: replace-cross 
Abstract: We propose new Markov chain Monte Carlo algorithms to sample a uniform distribution on a convex body $K$. Our algorithms are based on the proximal sampler, which uses Gibbs sampling on an augmented distribution and assumes access to the so-called restricted Gaussian oracle (RGO). The key contribution of this work is an efficient implementation of the RGO for uniform sampling on convex $K$ that goes beyond the membership-oracle model used in many classical and modern uniform samplers, and instead leverages richer oracle access commonly assumed in convex optimization. We implement the RGO via rejection sampling and access to either a projection oracle or a separation oracle on $K$. In both oracle models, we provide non-asymptotic complexity guarantees for obtaining unbiased samples, with accuracy quantified in R\'enyi divergence and $\chi^2$-divergence, and we support these theoretical guarantees with numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.02983v2</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thanh Dang, Jiaming Liang</dc:creator>
    </item>
    <item>
      <title>Information-theoretic minimax and submodular optimization algorithms for multivariate Markov chains</title>
      <link>https://arxiv.org/abs/2511.00769</link>
      <description>arXiv:2511.00769v2 Announce Type: replace-cross 
Abstract: We study an information-theoretic minimax problem for finite multivariate Markov chains on $d$-dimensional product state spaces. Given a family $\mathcal B=\{P_1,\ldots,P_n\}$ of $\pi$-stationary transition matrices and a class $\mathcal F = \mathcal{F}(\mathbf{S})$ of factorizable models induced by a partition $\mathbf S$ of the coordinate set $[d]$, we seek to minimize the worst-case information loss by analyzing $$\min_{Q\in\mathcal F}\max_{P\in\mathcal B} D_{\mathrm{KL}}^{\pi}(P\|Q),$$ where $D_{\mathrm{KL}}^{\pi}(P\|Q)$ is the $\pi$-weighted KL divergence from $Q$ to $P$. We recast the above minimax problem into concave maximization over the $n$-probability-simplex via strong duality and Pythagorean identities that we derive. This leads us to formulate an information-theoretic game and show that a mixed strategy Nash equilibrium always exists; and propose a projected subgradient algorithm to approximately solve the minimax problem with provable guarantee. By transforming the minimax problem into an orthant submodular function in $\mathbf{S}$, this motivates us to consider a max-min-max submodular optimization problem and investigate a two-layer subgradient-greedy procedure to approximately solve this generalization. Numerical experiments for Markov chains on the Curie-Weiss and Bernoulli-Laplace models illustrate the practicality of these proposed algorithms and reveals sparse optimal structures in these examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00769v2</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <category>stat.CO</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zheyuan Lai, Michael C. H. Choi</dc:creator>
    </item>
    <item>
      <title>Va\u{i}nberg--Br\`{e}gman relative entropy and quasinonexpansive operators</title>
      <link>https://arxiv.org/abs/2511.14873</link>
      <description>arXiv:2511.14873v2 Announce Type: replace-cross 
Abstract: We review the theory of Va\u{i}nberg--Br\`{e}gman relative entropies and quasinonexpansive operators on reflexive Banach spaces, and obtain several new results. We also develop an extension of this theory to nonreflexive Banach spaces, which is a joint generalisation of the reflexive Banach space approach and the finite-dimensional information geometric approach. In the reflexive case, we study generalised pythagorean inequality, as well as norm-to-norm, uniform, and Lipschitz--H\"{o}lder continuity, of (left and right) entropic projections, proximal maps, and resolvents. We also provide a detailed study of a special (`gauge') family of Va\u{i}nberg--Br\`{e}gman geometries and operators that is tightly related with the geometric properties of the underlying Banach space norm. The extended theory belongs to the intersection of convex theoretic and homeomorphic approaches to nonlinear analysis. Its models are constructed, using integration theory on order unit spaces, via nonlinear embeddings into reflexive rearrangement invariant spaces. E.g., we compute the exponent parameters of Lipschitz--H\"{o}lder continuity of the extended entropic projections and resolvents, and establish composability of a suitable class of nonlinear quasinonexpansive operators, over normal state spaces of JBW- and W*-algebras, determined by `gauge' Va\u{i}nberg--Br\`{e}gman geometries over, respectively, nonassociative and noncommutative L$_p$ spaces, and extended via Mazur embeddings. Other examples of extended Va\u{i}nberg--Br\`{e}gman geometries feature the (commutative and noncommutative) Lozanovski\u{i} factorisation map, generalised spin factors, finite dimensional base normed spaces, and convex spectral functions on unitarily invariant ideals of compact operators. We also discuss several categories of entropic projections and quasinonexpansive operators naturally appearing in this framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14873v2</guid>
      <category>math.FA</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.OC</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ryshard-Pavel Kostecki</dc:creator>
    </item>
    <item>
      <title>Unbiased Single-Queried Gradient for Combinatorial Objective</title>
      <link>https://arxiv.org/abs/2602.05119</link>
      <description>arXiv:2602.05119v2 Announce Type: replace-cross 
Abstract: In a probabilistic reformulation of a combinatorial problem, we often face an optimization over a hypercube, which corresponds to the Bernoulli probability parameter for each binary variable in the primal problem. The combinatorial nature suggests that an exact gradient computation requires multiple queries. We propose a stochastic gradient that is unbiased and requires only a single query of the combinatorial function. This method encompasses a well-established REINFORCE (through an importance sampling), as well as including a class of new stochastic gradients.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.05119v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Thanawat Sornwanee</dc:creator>
    </item>
    <item>
      <title>Entropic vector quantile regression: Duality and Gaussian case</title>
      <link>https://arxiv.org/abs/2602.11290</link>
      <description>arXiv:2602.11290v2 Announce Type: replace-cross 
Abstract: Vector quantile regression (VQR) is an optimal transport (OT) problem subject to a mean-independence constraint that extends classical linear quantile regression to vector response variables. Motivated by computational considerations, prior work has considered entropic relaxation of VQR, but its fundamental structural and approximation properties are still much less understood than entropic OT. The goal of this paper is to address some of these gaps. First, we study duality theory for entropic VQR and establish strong duality and dual attainment for marginals with possibly unbounded supports. In addition, when all marginals are compactly supported, we show that dual potentials are real analytic. Second, building on our duality theory, when all marginals are Gaussian, we show that entropic VQR has a closed-form optimal solution, which is again Gaussian, and establish the precise approximation rate toward unregularized VQR.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11290v2</guid>
      <category>math.ST</category>
      <category>math.OC</category>
      <category>stat.TH</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kengo Kato, Boyu Wang</dc:creator>
    </item>
  </channel>
</rss>
