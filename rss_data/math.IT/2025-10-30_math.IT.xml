<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.IT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.IT</link>
    <description>math.IT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.IT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 31 Oct 2025 04:01:01 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Coherence-Aware Distributed Learning under Heterogeneous Downlink Impairments</title>
      <link>https://arxiv.org/abs/2510.25917</link>
      <description>arXiv:2510.25917v1 Announce Type: new 
Abstract: The performance of federated learning (FL) over wireless networks critically depends on accurate and timely channel state information (CSI) across distributed devices. This requirement is tightly linked to how rapidly the channel gains vary, i.e., the coherence intervals. In practice, edge devices often exhibit unequal coherence times due to differences in mobility and scattering environments, leading to unequal demands for pilot signaling and channel estimation resources. Conventional FL schemes that overlook this coherence disparity can suffer from severe communication inefficiencies and training overhead. This paper proposes a coherence-aware, communication-efficient framework for joint channel training and model updating in practical wireless FL systems operating under heterogeneous fading dynamics. Focusing on downlink impairments, we introduce a resource-reuse strategy based on product superposition, enabling the parameter server to efficiently schedule both static and dynamic devices by embedding global model updates for static devices within pilot transmissions intended for mobile devices. We theoretically analyze the convergence behavior of the proposed scheme and quantify its gains in expected communication efficiency and training accuracy. Experiments demonstrate the effectiveness of the proposed framework under mobility-induced dynamics and offer useful insights for the practical deployment of FL over wireless channels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25917v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mehdi Karbalayghareh, David J. Love, Christopher G. Brinton</dc:creator>
    </item>
    <item>
      <title>Duality-Based Fixed Point Iteration Algorithm for Beamforming Design in ISAC Systems</title>
      <link>https://arxiv.org/abs/2510.26147</link>
      <description>arXiv:2510.26147v1 Announce Type: new 
Abstract: In this paper, we investigate the beamforming design problem in an integrated sensing and communication (ISAC) system, where a multi-antenna base station simultaneously serves multiple communication users while performing radar sensing. We formulate the problem as the minimization of the total transmit power, subject to signal-to-interference-plus-noise ratio (SINR) constraints for communication users and mean-squared-error (MSE) constraints for radar sensing. The core challenge arises from the complex coupling between communication SINR requirements and sensing performance metrics. To efficiently address this challenge, we first establish the equivalence between the original ISAC beamforming problem and its semidefinite relaxation (SDR), derive its Lagrangian dual formulation, and further reformulate it as a generalized downlink beamforming (GDB) problem with potentially indefinite weighting matrices. Compared to the classical DB problem, the presence of indefinite weighting matrices in the GDB problem introduces substantial analytical and computational challenges. Our key technical contributions include (i) a necessary and sufficient condition for the boundedness of the GDB problem, and (ii) a tailored efficient fixed point iteration (FPI) algorithm with a provable convergence guarantee for solving the GDB problem. Building upon these results, we develop a duality-based fixed point iteration (Dual-FPI) algorithm, which integrates an outer subgradient ascent loop with an inner FPI loop. Simulation results demonstrate that the proposed Dual-FPI algorithm achieves globally optimal solutions while significantly reducing computational complexity compared with existing baseline approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.26147v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xilai Fan, Ya-Feng Liu</dc:creator>
    </item>
    <item>
      <title>Efficient Spectral Efficiency Maximization Design for IRS-aided MIMO Systems</title>
      <link>https://arxiv.org/abs/2510.26279</link>
      <description>arXiv:2510.26279v1 Announce Type: new 
Abstract: Driven by the growing demand for higher spectral efficiency in wireless communications, intelligent reflecting sur- faces (IRS) have attracted considerable attention for their ability to dynamically reconfigure the propagation environment. This work addresses the spectral efficiency maximization problem in IRS-assisted multiple-input multiple-output (MIMO) systems, which involves the joint optimization of the transmit precoding matrix and the IRS phase shift configuration. This problem is inherently challenging due to its non-convex nature. To tackle it effectively, we introduce a computationally efficient algorithm, termed ADMM-APG, which integrates the alternating direction method of multipliers (ADMM) with the accelerated projected gradient (APG) method. The proposed framework decomposes the original problem into tractable subproblems, each admitting a closed-form solution while maintaining low computational com- plexity. Simulation results demonstrate that the ADMM-APG algorithm consistently surpasses existing benchmark methods in terms of spectral efficiency and computational complexity, achieving significant performance gains across a range of system configurations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.26279v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Fuying Li, Yajun Wang, Zhuxian Lian, Wen Chen</dc:creator>
    </item>
    <item>
      <title>Diffusion-Aided Bandwidth-Efficient Semantic Communication with Adaptive Requests</title>
      <link>https://arxiv.org/abs/2510.26442</link>
      <description>arXiv:2510.26442v1 Announce Type: new 
Abstract: Semantic communication focuses on conveying the intrinsic meaning of data rather than its raw symbolic representation. For visual content, this paradigm shifts from traditional pixel-level transmission toward leveraging the semantic structure of images to communicate visual meaning. Existing approaches generally follow one of two paths: transmitting only text descriptions, which often fail to capture precise spatial layouts and fine-grained appearance details; or transmitting text alongside dense latent visual features, which tends to introduce substantial semantic redundancy. A key challenge, therefore, is to reduce semantic redundancy while preserving semantic understanding and visual fidelity, thereby improving overall transmission efficiency. This paper introduces a diffusion-based semantic communication framework with adaptive retransmission. The system transmits concise text descriptions together with a limited set of key latent visual features, and employs a diffusion-based inpainting model to reconstruct the image. A receiver-side semantic consistency mechanism is designed to evaluate the alignment between the reconstructed image and the original text description. When a semantic discrepancy is detected, the receiver triggers a retransmission to request a small set of additional latent blocks and refine the image reconstruction. This approach significantly reduces bandwidth usage while preserving high semantic accuracy, achieving an efficient balance between reconstruction quality and transmission overhead.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.26442v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xuesong Wang, Xinyan Xie, Mo Li, Zhaoqian Liu</dc:creator>
    </item>
    <item>
      <title>PolarZero: A Reinforcement Learning Approach for Low-Complexity Polarization Kernel Design</title>
      <link>https://arxiv.org/abs/2510.26452</link>
      <description>arXiv:2510.26452v1 Announce Type: new 
Abstract: Polar codes with large kernels can achieve improved error exponents but are challenging to design with low decoding com- plexity. This work investigates kernel construction under recursive maximum likelihood decoding (RMLD) using a reinforcement learning framework based on the Gumbel AlphaZero algorithm. The proposed method efficiently explores the design space and identifies large-size kernels that satisfy a given error exponent while minimizing decoding complexity. For a size-16 kernel, it achieves 17% lower decoding complexity than handcrafted designs while reaching an error exponent of 0.5183 compared to 0.5 for Arikan's kernel, demonstrating the effectiveness of the learning-based approach for practical polar code construction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.26452v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yi-Ting Hong, Stefano Rini, Luca Barletta</dc:creator>
    </item>
    <item>
      <title>Entropy Functions on Two-Dimensional Faces of Polymatroidal Region of Degree Four: Part II: Information Theoretic Constraints Breed New Combinatorial Structures</title>
      <link>https://arxiv.org/abs/2510.26552</link>
      <description>arXiv:2510.26552v1 Announce Type: new 
Abstract: Characterization of entropy functions is of fundamental importance in information theory. By imposing constraints on their Shannon outer bound, i.e., the polymatroidal region, one obtains the faces of the region and entropy functions on them with special structures. In this series of two papers, we characterize entropy functions on the $2$-dimensional faces of the polymatroidal region $\Gamma_4$. In Part I, we formulated the problem, enumerated all $59$ types of $2$-dimensional faces of $\Gamma_4$ by a algorithm, and fully characterized entropy functions on $49$ types of them. In this paper, i.e., Part II, we will characterize entropy functions on the remaining $10$ types of faces, among which $8$ types are fully characterized and $2$ types are partially characterized. To characterize these types of faces, we introduce some new combinatorial design structures which are interesting themself.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.26552v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shaocheng Liu, Qi Chen, Minquan Cheng</dc:creator>
    </item>
    <item>
      <title>Quantum Action-Dependent Channels</title>
      <link>https://arxiv.org/abs/2510.09834</link>
      <description>arXiv:2510.09834v1 Announce Type: cross 
Abstract: We study the quantum action-dependent channel. The model can be viewed as a quantum analog of the classical action-dependent channel model. In this setting, the communication channel has two inputs: Alice's transmission and the input environment. The action-dependent mechanism enables the transmitter to influence the channel's environment through an action channel. Specifically, Alice encodes her message into a quantum action, which subsequently affects the environment state. For example, a quantum measurement at the encoder can induce a state collapse of the environment. In addition, Alice has access to side information. Unlike the classical model, she cannot have a copy of the environment state due to the no-cloning theorem. Instead, she shares entanglement with this environment. We establish an achievable communication rate for reliable message transmission via the quantum action-dependent channel, thereby extending the classical action-dependent framework to the quantum domain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.09834v1</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael Korenberg, Uzi Pereg</dc:creator>
    </item>
    <item>
      <title>Transformers Provably Learn Directed Acyclic Graphs via Kernel-Guided Mutual Information</title>
      <link>https://arxiv.org/abs/2510.25542</link>
      <description>arXiv:2510.25542v1 Announce Type: cross 
Abstract: Uncovering hidden graph structures underlying real-world data is a critical challenge with broad applications across scientific domains. Recently, transformer-based models leveraging the attention mechanism have demonstrated strong empirical success in capturing complex dependencies within graphs. However, the theoretical understanding of their training dynamics has been limited to tree-like graphs, where each node depends on a single parent. Extending provable guarantees to more general directed acyclic graphs (DAGs) -- which involve multiple parents per node -- remains challenging, primarily due to the difficulty in designing training objectives that enable different attention heads to separately learn multiple different parent relationships.
  In this work, we address this problem by introducing a novel information-theoretic metric: the kernel-guided mutual information (KG-MI), based on the $f$-divergence. Our objective combines KG-MI with a multi-head attention framework, where each head is associated with a distinct marginal transition kernel to model diverse parent-child dependencies effectively. We prove that, given sequences generated by a $K$-parent DAG, training a single-layer, multi-head transformer via gradient ascent converges to the global optimum in polynomial time. Furthermore, we characterize the attention score patterns at convergence. In addition, when particularizing the $f$-divergence to the KL divergence, the learned attention scores accurately reflect the ground-truth adjacency matrix, thereby provably recovering the underlying graph structure. Experimental results validate our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25542v1</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuan Cheng, Yu Huang, Zhe Xiong, Yingbin Liang, Vincent Y. F. Tan</dc:creator>
    </item>
    <item>
      <title>Optimal Information Combining for Multi-Agent Systems Using Adaptive Bias Learning</title>
      <link>https://arxiv.org/abs/2510.25793</link>
      <description>arXiv:2510.25793v1 Announce Type: cross 
Abstract: Modern multi-agent systems ranging from sensor networks monitoring critical infrastructure to crowdsourcing platforms aggregating human intelligence can suffer significant performance degradation due to systematic biases that vary with environmental conditions. Current approaches either ignore these biases, leading to suboptimal decisions, or require expensive calibration procedures that are often infeasible in practice. This performance gap has real consequences: inaccurate environmental monitoring, unreliable financial predictions, and flawed aggregation of human judgments. This paper addresses the fundamental question: when can we learn and correct for these unknown biases to recover near-optimal performance, and when is such learning futile? We develop a theoretical framework that decomposes biases into learnable systematic components and irreducible stochastic components, introducing the concept of learnability ratio as the fraction of bias variance predictable from observable covariates. This ratio determines whether bias learning is worthwhile for a given system. We prove that the achievable performance improvement is fundamentally bounded by this learnability ratio, providing system designers with quantitative guidance on when to invest in bias learning versus simpler approaches. We present the Adaptive Bias Learning and Optimal Combining (ABLOC) algorithm, which iteratively learns bias-correcting transformations while optimizing combination weights through closedform solutions, guaranteeing convergence to these theoretical bounds. Experimental validation demonstrates that systems with high learnability ratios can recover significant performance (we achieved 40%-70% of theoretical maximum improvement in our examples), while those with low learnability show minimal benefit, validating our diagnostic criteria for practical deployment decisions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25793v1</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Siavash M. Alamouti, Fay Arjomandi</dc:creator>
    </item>
    <item>
      <title>The Information-Theoretic Imperative: Compression and the Epistemic Foundations of Intelligence</title>
      <link>https://arxiv.org/abs/2510.25883</link>
      <description>arXiv:2510.25883v1 Announce Type: cross 
Abstract: Existing frameworks converge on the centrality of compression to intelligence but leave underspecified why this process enforces the discovery of causal structure rather than superficial statistical patterns. We introduce a two-level framework to address this gap. The Information-Theoretic Imperative (ITI) establishes that any system persisting in uncertain environments must minimize epistemic entropy through predictive compression: this is the evolutionary "why" linking survival pressure to information-processing demands. The Compression Efficiency Principle (CEP) specifies how efficient compression mechanically selects for generative, causal models through exception-accumulation dynamics, making reality alignment a consequence rather than a contingent achievement. Together, ITI and CEP define a causal chain: from survival pressure to prediction necessity, compression requirement, efficiency optimization, generative structure discovery, and ultimately reality alignment. Each link follows from physical, information-theoretic, or evolutionary constraints, implying that intelligence is the mechanically necessary outcome of persistence in structured environments. This framework yields empirically testable predictions: compression efficiency, measured as approach to the rate-distortion frontier, correlates with out-of-distribution generalization; exception-accumulation rates differentiate causal from correlational models; hierarchical systems exhibit increasing efficiency across abstraction layers; and biological systems demonstrate metabolic costs that track representational complexity. ITI and CEP thereby provide a unified account of convergence across biological, artificial, and multi-scale systems, addressing the epistemic and functional dimensions of intelligence without invoking assumptions about consciousness or subjective experience.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25883v1</guid>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christian Dittrich, Jennifer Flygare Kinne</dc:creator>
    </item>
    <item>
      <title>Contrastive Predictive Coding Done Right for Mutual Information Estimation</title>
      <link>https://arxiv.org/abs/2510.25983</link>
      <description>arXiv:2510.25983v1 Announce Type: cross 
Abstract: The InfoNCE objective, originally introduced for contrastive representation learning, has become a popular choice for mutual information (MI) estimation, despite its indirect connection to MI. In this paper, we demonstrate why InfoNCE should not be regarded as a valid MI estimator, and we introduce a simple modification, which we refer to as InfoNCE-anchor, for accurate MI estimation. Our modification introduces an auxiliary anchor class, enabling consistent density ratio estimation and yielding a plug-in MI estimator with significantly reduced bias. Beyond this, we generalize our framework using proper scoring rules, which recover InfoNCE-anchor as a special case when the log score is employed. This formulation unifies a broad spectrum of contrastive objectives, including NCE, InfoNCE, and $f$-divergence variants, under a single principled framework. Empirically, we find that InfoNCE-anchor with the log score achieves the most accurate MI estimates; however, in self-supervised representation learning experiments, we find that the anchor does not improve the downstream task performance. These findings corroborate that contrastive representation learning benefits not from accurate MI estimation per se, but from the learning of structured density ratios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25983v1</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>stat.ML</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>J. Jon Ryu, Pavan Yeddanapudi, Xiangxiang Xu, Gregory W. Wornell</dc:creator>
    </item>
    <item>
      <title>Practical hybrid decoding scheme for parity-encoded spin systems</title>
      <link>https://arxiv.org/abs/2510.26189</link>
      <description>arXiv:2510.26189v1 Announce Type: cross 
Abstract: We propose a practical hybrid decoding scheme for the parity-encoding architecture. This architecture was first introduced by N. Sourlas as a computational technique for tackling hard optimization problems, especially those modeled by spin systems such as the Ising model and spin glasses, and reinvented by W. Lechner, P. Hauke, and P. Zoller to develop quantum annealing devices. We study the specific model, called the SLHZ model, aiming to achieve a near-term quantum annealing device implemented solely through geometrically local spin interactions. Taking account of the close connection between the SLHZ model and a classical low-density-parity-check code, two approaches can be chosen for the decoding: (1) finding the ground state of a spin Hamiltonian derived from the SLHZ model, which can be achieved via stochastic decoders such as quantum annealing or classical Monte Carlo samplers; (2) using deterministic decoding techniques for the classical LDPC code, such as belief propagation and bit-flip decoder. The proposed hybrid approach combines the two approaches by applying bit-flip decoding to the readout of the stochastic decoder based on the SLHZ model. We present simulations demonstrating that this approach can reveal the latent potential of the SLHZ model, realizing soft-annealing concept proposed by Sourlas.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.26189v1</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yoshihiro Nambu</dc:creator>
    </item>
    <item>
      <title>Sequential Change Detection Under A Markov Setup With Unknown Pre-Change and Post-Change Distributions</title>
      <link>https://arxiv.org/abs/2510.26204</link>
      <description>arXiv:2510.26204v1 Announce Type: cross 
Abstract: In this work we extend the results developed in 2022 for a sequential change detection algorithm making use of Page's CUSUM statistic, the empirical distribution as an estimate of the pre-change distribution, and a universal code as a tool for estimating the post-change distribution, from the i.i.d. case to the Markov setup.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.26204v1</guid>
      <category>math.ST</category>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <category>stat.TH</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ashish Bhoopesh Gulaguli, Shashwat Singh, Rakesh Kumar Bansal</dc:creator>
    </item>
    <item>
      <title>Multi-layer State Evolution Under Random Convolutional Design</title>
      <link>https://arxiv.org/abs/2205.13503</link>
      <description>arXiv:2205.13503v3 Announce Type: replace 
Abstract: Signal recovery under generative neural network priors has emerged as a promising direction in statistical inference and computational imaging. Theoretical analysis of reconstruction algorithms under generative priors is, however, challenging. For generative priors with fully connected layers and Gaussian i.i.d. weights, this was achieved by the multi-layer approximate message (ML-AMP) algorithm via a rigorous state evolution. However, practical generative priors are typically convolutional, allowing for computational benefits and inductive biases, and so the Gaussian i.i.d. weight assumption is very limiting. In this paper, we overcome this limitation and establish the state evolution of ML-AMP for random convolutional layers. We prove in particular that random convolutional layers belong to the same universality class as Gaussian matrices. Our proof technique is of an independent interest as it establishes a mapping between convolutional matrices and spatially coupled sensing matrices used in coding theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2205.13503v3</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Advances in Neural Information Processing Systems (2022), vol 52, pages 7089--7102</arxiv:journal_reference>
      <dc:creator>Mara Daniels, C\'edric Gerbelot, Florent Krzakala, Lenka Zdeborov\'a</dc:creator>
    </item>
    <item>
      <title>Unified Error Correction Code Transformer with Low Complexity</title>
      <link>https://arxiv.org/abs/2410.03364</link>
      <description>arXiv:2410.03364v4 Announce Type: replace 
Abstract: Channel coding is vital for reliable sixth-generation (6G) data transmission, employing diverse error correction codes for various application scenarios. Traditional decoders require dedicated hardware for each code, leading to high hardware costs. Recently, artificial intelligence (AI)-driven approaches, such as the error correction code Transformer (ECCT) and its enhanced version, the foundation error correction code Transformer (FECCT), have been proposed to reduce the hardware cost by leveraging the Transformer to decode multiple codes. However, their excessively high computational complexity of $\mathcal{O}(N^2)$ due to the self-attention mechanism in the Transformer limits scalability, where $N$ represents the sequence length. To reduce computational complexity, we propose a unified Transformer-based decoder that handles multiple linear block codes within a single framework. Specifically, a standardized unit is employed to align code length and code rate across different code types, while a redesigned low-rank unified attention module, with computational complexity of $\mathcal{O}(N)$, is shared across various heads in the Transformer. Additionally, a sparse mask, derived from the parity-check matrix's sparsity, is introduced to enhance the decoder's ability to capture inherent constraints between information and parity-check bits, improving decoding accuracy and further reducing computational complexity by $86\%$. Extensive experimental results demonstrate that the proposed unified Transformer-based decoder outperforms existing methods and provides a high-performance, low-complexity solution for next-generation wireless communication systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03364v4</guid>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yongli Yan, Jieao Zhu, Tianyue Zheng, Zhuo Xu, Chao Jiang, Linglong Dai</dc:creator>
    </item>
    <item>
      <title>Network Oblivious Transfer via Noisy Channels: Limits and Capacities</title>
      <link>https://arxiv.org/abs/2501.17021</link>
      <description>arXiv:2501.17021v2 Announce Type: replace 
Abstract: In this paper, we aim to study the information-theoretical limits of oblivious transfer. This work also investigates the problem of oblivious transfer over a noisy multiple access channel involving two non-colluding senders and a single receiver. The channel model is characterized by correlations among the parties, with the parties assumed to be either honest-but-curious or, in the receiver's case, potentially malicious. At first, we study the information-theoretical limits of oblivious transfer between two parties and extend it to the multiple access channel model. We propose a multiparty protocol for honest-but-curious parties where the general multiple access channel is reduced to a certain correlation. In scenarios where the receiver is malicious, the protocol achieves an achievable rate region.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.17021v2</guid>
      <category>cs.IT</category>
      <category>cs.CR</category>
      <category>math.IT</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hadi Aghaee, Bahareh Akhbari, Christian Deppe</dc:creator>
    </item>
    <item>
      <title>On the equivalence of NMDS codes</title>
      <link>https://arxiv.org/abs/2509.25645</link>
      <description>arXiv:2509.25645v2 Announce Type: replace 
Abstract: An $[n,k,d]$ linear code is said to be maximum distance separable (MDS) or almost maximum distance separable (AMDS) if $d=n-k+1$ or $d=n-k$, respectively. If a code and its dual code are both AMDS, then the code is said to be near maximum distance separable (NMDS). For $k=3$ and $k=4$, there are many constructions of NMDS codes by adding some suitable projective points to arcs in $\mathrm{PG}(k-1,q)$. In this paper, we consider the monomial equivalence problem for some NMDS codes with the same weight distributions and present new constructions of NMDS codes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.25645v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jianbing Lu, Yue Zhou</dc:creator>
    </item>
    <item>
      <title>Coding for Ordered Composite DNA Sequences</title>
      <link>https://arxiv.org/abs/2509.26119</link>
      <description>arXiv:2509.26119v3 Announce Type: replace 
Abstract: To increase the information capacity of DNA storage, composite DNA letters were introduced. We propose a novel channel model for composite DNA in which composite sequences are decomposed into ordered standard non-composite sequences. The model is designed to handle any alphabet size and composite resolution parameter. We study the problem of reconstructing composite sequences of arbitrary resolution over the binary alphabet under substitution errors. We define two families of error-correcting codes and provide lower and upper bounds on their cardinality. In addition, we analyze the case in which a single deletion error occurs in the channel and present a systematic code construction for this setting. Finally, we briefly discuss the channel's capacity, which remains an open problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.26119v3</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Besart Dollma, Ohad Elishco, Eitan Yaakobi</dc:creator>
    </item>
    <item>
      <title>Random pairing MLE for estimation of item parameters in Rasch model</title>
      <link>https://arxiv.org/abs/2406.13989</link>
      <description>arXiv:2406.13989v2 Announce Type: replace-cross 
Abstract: The Rasch model, a classical model in the item response theory, is widely used in psychometrics to model the relationship between individuals' latent traits and their binary responses to assessments or questionnaires. In this paper, we introduce a new likelihood-based estimator -- random pairing maximum likelihood estimator ($\mathrm{RP\text{-}MLE}$) and its bootstrapped variant multiple random pairing MLE ($\mathrm{MRP\text{-}MLE}$) which faithfully estimate the item parameters in the Rasch model. The new estimators have several appealing features compared to existing ones. First, both work for sparse observations, an increasingly important scenario in the big data era. Second, both estimators are provably minimax optimal in terms of finite sample $\ell_{\infty}$ estimation error. Lastly, both admit precise distributional characterization that allows uncertainty quantification on the item parameters, e.g., construction of confidence intervals for the item parameters. The main idea underlying $\mathrm{RP\text{-}MLE}$ and $\mathrm{MRP\text{-}MLE}$ is to randomly pair user-item responses to form item-item comparisons. This is carefully designed to reduce the problem size while retaining statistical independence. We also provide empirical evidence of the efficacy of the two new estimators using both simulated and real data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.13989v2</guid>
      <category>stat.ML</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuepeng Yang, Cong Ma</dc:creator>
    </item>
    <item>
      <title>Decoding for Punctured Convolutional and Turbo Codes: A Deep Learning Solution for Protocols Compliance</title>
      <link>https://arxiv.org/abs/2502.15475</link>
      <description>arXiv:2502.15475v3 Announce Type: replace-cross 
Abstract: Neural network-based decoding methods show promise in enhancing error correction performance but face challenges with punctured codes. In particular, existing methods struggle to adapt to variable code rates or meet protocol compatibility requirements. This paper proposes a unified long short-term memory (LSTM)-based neural decoder for punctured convolutional and Turbo codes to address these challenges. The key component of the proposed LSTM-based neural decoder is puncturing-aware embedding, which integrates puncturing patterns directly into the neural network to enable seamless adaptation to different code rates. Moreover, a balanced bit error rate training strategy is designed to ensure the decoder's robustness across various code lengths, rates, and channels. In this way, the protocol compatibility requirement can be realized. Extensive simulations in both additive white Gaussian noise (AWGN) and Rayleigh fading channels demonstrate that the proposed neural decoder outperforms conventional decoding techniques, offering significant improvements in decoding accuracy and robustness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.15475v3</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yongli Yan, Linglong Dai</dc:creator>
    </item>
    <item>
      <title>DSDE: Dynamic Speculative Decoding with KLD Stability for Real-World Serving</title>
      <link>https://arxiv.org/abs/2509.01083</link>
      <description>arXiv:2509.01083v3 Announce Type: replace-cross 
Abstract: Speculative decoding accelerates large language model inference, but its reliance on a fixed speculation length is suboptimal in large-batch serving environments with diverse requests. This paper explores a new direction for dynamic adaptation by investigating a novel class of post-hoc, diagnostic signals. We propose Dynamic Speculative Decoding Engine (DSDE), a training-free framework built on two primary components: (1) a predictive signal based on the variance of the Kullback-Leibler (KLD) divergence, which diagnoses the generation's regional stability, and (2) an adaptive speculation length cap to mitigate the straggler problem in per-sequence decoding. Experiments demonstrate the potential of using KLD-based stability signals for dynamic adaptation. An algorithm guided by these signals achieves end-to-end latency competitive with leading baselines and exhibits superior robustness across diverse workloads. This robustness is particularly valuable in challenging low-acceptance-rate regimes, where the proposed signal maintains its diagnostic utility. Collectively, these findings validate post-hoc signals as a valuable component for building more robust and intelligent LLM inference systems, and highlight a promising direction for future research on dynamic speculation length adaptation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.01083v3</guid>
      <category>cs.DC</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mingyu Yang, Jae-Young Choi, Kihyo Moon, Minsung Jang, Eunjoo Jeon</dc:creator>
    </item>
    <item>
      <title>PoPStat-COVID19: Leveraging Population Pyramids to Quantify Demographic Vulnerability to COVID-19</title>
      <link>https://arxiv.org/abs/2509.14213</link>
      <description>arXiv:2509.14213v2 Announce Type: replace-cross 
Abstract: Understanding how population age structure shapes COVID-19 burden is crucial for pandemic preparedness, yet common summary measures such as median age ignore key distributional features like skewness, bimodality, and the proportional weight of high-risk cohorts. We extend the PoPStat framework, originally devised to link entire population pyramids with cause-specific mortality by applying it to COVID-19. Using 2019 United Nations World Population Prospects age-sex distributions together with cumulative cases and deaths per million recorded up to 5 May 2023 by Our World in Data, we calculate PoPDivergence (the Kullback-Leibler divergence from an optimised reference pyramid) for 180+ countries and derive PoPStat-COVID19 as the Pearson correlation between that divergence and log-transformed incidence or mortality. Optimisation selects Malta's old-skewed pyramid as the reference, yielding strong negative correlations for cases (r=-0.86, p&lt;0.001, R^2=0.74) and deaths (r=-0.82, p&lt;0.001, R^2=0.67). Sensitivity tests across twenty additional, similarly old-skewed references confirm that these associations are robust to reference choice. Benchmarking against eight standard indicators like gross domestic product per capita, Gini index, Human Development Index, life expectancy at birth, median age, population density, Socio-demographic Index, and Universal Health Coverage Index shows that PoPStat-COVID19 surpasses GDP per capita, median age, population density, and several other traditional measures, and outperforms every comparator for fatality burden. PoPStat-COVID19 therefore provides a concise, distribution-aware scalar for quantifying demographic vulnerability to COVID-19.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14213v2</guid>
      <category>stat.AP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Buddhi Wijenayake, Athulya Ratnayake, Lelumi Edirisinghe, Uditha Wijeratne, Tharaka Fonseka, Roshan Godaliyadda, Samath Dharmaratne, Parakrama Ekanayake, Vijitha Herath, Insoha Alwis, Supun Manathunga</dc:creator>
    </item>
    <item>
      <title>Beyond the Use-and-then-Forget (UatF) Bound: Fixed Point Algorithms for Statistical Max-Min Power Control</title>
      <link>https://arxiv.org/abs/2510.11582</link>
      <description>arXiv:2510.11582v2 Announce Type: replace-cross 
Abstract: We introduce mathematical tools and fixed point algorithms for optimal statistical max-min power control in cellular and cell-less massive MIMO systems. Unlike previous studies that rely on the use-and-then-forget (UatF) lower bound on Shannon achievable (ergodic) rates, our proposed framework can deal with alternative bounds that explicitly consider perfect or imperfect channel state information (CSI) at the decoder. In doing so, we address limitations of UatF-based power control algorithms, which inherit the shortcomings of the UatF bound. For example, the UatF bound can be overly conservative: in extreme cases, under fully statistical (nonadaptive) beamforming in zero-mean channels, the UatF bound produces trivial (zero) rate bounds. It also lacks scale invariance: merely scaling the beamformers can change the bound drastically. In contrast, our framework is compatible with information-theoretic bounds that do not suffer from the above drawbacks. We illustrate the framework by solving a max-min power control problem considering a standard bound that exploits instantaneous CSI at the decoder.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.11582v2</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Renato Luis Garrido Cavalcante, Noor Ul Ain, Lorenzo Miretti, Slawomir Stanczak</dc:creator>
    </item>
  </channel>
</rss>
