<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 04 Nov 2025 05:01:00 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Optimal Allocations under Strongly Pigou-Dalton Criteria: Hidden Layer Structure &amp; Efficient Combinatorial Approach</title>
      <link>https://arxiv.org/abs/2511.00835</link>
      <description>arXiv:2511.00835v1 Announce Type: new 
Abstract: We investigate optimal social welfare allocations of $m$ items to $n$ agents with binary additive or submodular valuations. For binary additive valuations, we prove that the set of optimal allocations coincides with the set of so-called \emph{stable allocations}, as long as the employed criterion for evaluating social welfare is strongly Pigou-Dalton (SPD) and symmetric. Many common criteria are SPD and symmetric, such as Nash social welfare, leximax, leximin, Gini index, entropy, and envy sum. We also design efficient algorithms for finding a stable allocation, including an $O(m^2n)$ time algorithm for the case of indivisible items, and an $O(m^2n^5)$ time one for the case of divisible items. The first is faster than the existing algorithms or has a simpler analysis. The latter is the first combinatorial algorithm for that problem. It utilizes a hidden layer partition of items and agents admitted by all stable allocations, and cleverly reduces the case of divisible items to the case of indivisible items.
  In addition, we show that the profiles of different optimal allocations have a small Chebyshev distance, which is 0 for the case of divisible items under binary additive valuations, and is at most 1 for the case of indivisible items under binary submodular valuations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00835v1</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Taikun Zhu, Kai Jin, Ruixi Luo, Song Cao</dc:creator>
    </item>
    <item>
      <title>Pay for The Second-Best Service: A Game-Theoretic Approach Against Dishonest LLM Providers</title>
      <link>https://arxiv.org/abs/2511.00847</link>
      <description>arXiv:2511.00847v1 Announce Type: new 
Abstract: The widespread adoption of Large Language Models (LLMs) through Application Programming Interfaces (APIs) induces a critical vulnerability: the potential for dishonest manipulation by service providers. This manipulation can manifest in various forms, such as secretly substituting a proclaimed high-performance model with a low-cost alternative, or inflating responses with meaningless tokens to increase billing. This work tackles the issue through the lens of algorithmic game theory and mechanism design. We are the first to propose a formal economic model for a realistic user-provider ecosystem, where a user can iteratively delegate $T$ queries to multiple model providers, and providers can engage in a range of strategic behaviors. As our central contribution, we prove that for a continuous strategy space and any $\epsilon\in(0,\frac12)$, there exists an approximate incentive-compatible mechanism with an additive approximation ratio of $O(T^{1-\epsilon}\log T)$, and a guaranteed quasi-linear second-best user utility. We also prove an impossibility result, stating that no mechanism can guarantee an expected user utility that is asymptotically better than our mechanism. Furthermore, we demonstrate the effectiveness of our mechanism in simulation experiments with real-world API settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00847v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yuhan Cao, Yu Wang, Sitong Liu, Miao Li, Yixin Tao, Tianxing He</dc:creator>
    </item>
    <item>
      <title>Deliberation via Matching</title>
      <link>https://arxiv.org/abs/2511.00986</link>
      <description>arXiv:2511.00986v1 Announce Type: new 
Abstract: We study deliberative social choice, where voters refine their preferences through small-group discussions before collective aggregation. We introduce a simple and easily implementable deliberation-via-matching protocol: for each pair of candidates, we form an arbitrary maximum matching among voters who disagree on that pair, and each matched pair deliberates. The resulting preferences (individual and deliberative) are then appropriately weighted and aggregated using the weighted uncovered set tournament rule.
  We show that our protocol has a tight distortion bound of $3$ within the metric distortion framework. This breaks the previous lower bound of $3.11$ for tournament rules without deliberation and matches the lower bound for deterministic social choice rules without deliberation. Our result conceptually shows that tournament rules are just as powerful as general social choice rules, when the former are given the minimal added power of pairwise deliberations. We prove our bounds via a novel bilinear relaxation of the non-linear program capturing optimal distortion, whose vertices we can explicitly enumerate, leading to an analytic proof. Loosely speaking, our key technical insight is that the distortion objective, as a function of metric distances to any three alternatives, is both supermodular and convex. We believe this characterization provides a general analytical framework for studying the distortion of other deliberative protocols, and may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00986v1</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kamesh Munagala, Qilin Ye, Ian Zhang</dc:creator>
    </item>
    <item>
      <title>From Best Responses to Learning: Investment Efficiency in Dynamic Environment</title>
      <link>https://arxiv.org/abs/2511.01157</link>
      <description>arXiv:2511.01157v1 Announce Type: new 
Abstract: We study the welfare of a mechanism in a dynamic environment where a learning investor can make a costly investment to change her value. In many real-world problems, the common assumption that the investor always makes the best responses, i.e., choosing her utility-maximizing investment option, is unrealistic due to incomplete information in a dynamically evolving environment. To address this, we consider an investor who uses a no-regret online learning algorithm to adaptively select investments through repeated interactions with the environment. We analyze how the welfare guarantees of approximation allocation algorithms extend from static to dynamic settings when the investor learns rather than best-responds, by studying the approximation ratio for optimal welfare as a measurement of an algorithm's performance against different benchmarks in the dynamic learning environment. First, we show that the approximation ratio in the static environment remains unchanged in the dynamic environment against the best-in-hindsight benchmark. Second, we provide tight characterizations of the approximation upper and lower bounds relative to a stronger time-varying benchmark. Bridging mechanism design with online learning theory, our work shows how robust welfare guarantees can be maintained even when an agent cannot make best responses but learns their investment strategies in complex, uncertain environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01157v1</guid>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ce Li, Qianfan Zhang, Weiqiang Zheng</dc:creator>
    </item>
    <item>
      <title>Designing Non-monetary Intersection Control Mechanisms for Efficient Selfish Routing</title>
      <link>https://arxiv.org/abs/2511.01421</link>
      <description>arXiv:2511.01421v1 Announce Type: new 
Abstract: Urban traffic congestion stems from the misalignment between self-interested routing decisions and socially optimal flows. Intersections, as critical bottlenecks, amplify these inefficiencies because existing control schemes often neglect drivers' strategic behavior. Autonomous intersections, enabled by vehicle-to-infrastructure communication, permit vehicle-level scheduling based on individual requests. Leveraging this fine-grained control, we propose a non-monetary mechanism that strategically adjusts request timestamps-delaying or advancing passage times-to incentivize socially efficient routing. We present a hierarchical architecture separating local scheduling by roadside units from network-wide timestamp adjustments by a central planner. We establish an experimentally validated analytical model, prove the existence and essential uniqueness of equilibrium flows and formulate the planner's problem as an offline bilevel optimization program solvable with standard tools. Experiments on the Sioux Falls network show up to a 68% reduction in the efficiency gap between equilibrium and optimal flows, demonstrating scalability and effectiveness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01421v1</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yusuf Saltan, Jyun-Jhe Wang, Arda Kosay, Chung-Wei Lin, Muhammed O. Sayin</dc:creator>
    </item>
    <item>
      <title>Proximal Regret and Proximal Correlated Equilibria: A New Tractable Solution Concept for Online Learning and Games</title>
      <link>https://arxiv.org/abs/2511.01852</link>
      <description>arXiv:2511.01852v1 Announce Type: new 
Abstract: Learning and computation of equilibria are central problems in algorithmic game theory. In this work, we introduce proximal regret, a new notion of regret based on proximal operators that lies strictly between external and swap regret. When every player employs a no-proximal-regret algorithm in a general convex game, the empirical distribution of play converges to proximal correlated equilibria (PCE), a refinement of coarse correlated equilibria. Our framework unifies several emerging notions in online learning and game theory -- such as gradient equilibrium and semicoarse correlated equilibrium -- and introduces new ones. Our main result shows that the classic Online Gradient Descent (GD) algorithm achieves an optimal $O(\sqrt{T})$ bound on proximal regret, revealing that GD, without modification, minimizes a stronger regret notion than external regret. This provides a new explanation for the empirically superior performance of gradient descent in online learning and games. We further extend our analysis to Mirror Descent in the Bregman setting and to Optimistic Gradient Descent, which yields faster convergence in smooth convex games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01852v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yang Cai, Constantinos Daskalakis, Haipeng Luo, Chen-Yu Wei, Weiqiang Zheng</dc:creator>
    </item>
    <item>
      <title>Computation as a Game</title>
      <link>https://arxiv.org/abs/2511.00058</link>
      <description>arXiv:2511.00058v1 Announce Type: cross 
Abstract: We present a unifying representation of computation as a two-player game between an \emph{Algorithm} and \emph{Nature}, grounded in domain theory and game theory. The Algorithm produces progressively refined approximations within a Scott domain, while Nature assigns penalties proportional to their distance from the true value. Correctness corresponds to equilibrium in the limit of refinement. This framework allows us to define complexity classes game-theoretically, characterizing $\mathbf{P}$, $\mathbf{NP}$, and related classes as sets of problems admitting particular equilibria. The open question $\mathbf{P} \stackrel{?}{=} \mathbf{NP}$ becomes a problem about the equivalence of Nash equilibria under differing informational and temporal constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00058v1</guid>
      <category>cs.CC</category>
      <category>cs.GT</category>
      <category>cs.LO</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Paul Alexander Bilokon</dc:creator>
    </item>
    <item>
      <title>Evolutionary Dynamics in Continuous-time Finite-state Mean Field Games - Part I: Equilibria</title>
      <link>https://arxiv.org/abs/2511.01452</link>
      <description>arXiv:2511.01452v1 Announce Type: cross 
Abstract: We study a dynamic game with a large population of players who choose actions from a finite set in continuous time. Each player has a state in a finite state space that evolves stochastically with their actions. A player's reward depends not only on their own state and action but also on the distribution of states and actions across the population, capturing effects such as congestion in traffic networks. While prior work in evolutionary game theory has primarily focused on static games without individual player state dynamics, we present the first comprehensive evolutionary analysis of such dynamic games. We propose an evolutionary model together with a mean field approximation of the finite-population game and establish strong approximation guarantees. We show that standard solution concepts for dynamic games lack an evolutionary interpretation, and we propose a new concept - the Mixed Stationary Nash Equilibrium (MSNE) - which admits one. We analyze the relationship between MSNE and the rest points of the mean field evolutionary model and study the evolutionary stability of MSNE.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01452v1</guid>
      <category>eess.SY</category>
      <category>cs.GT</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Leonardo Pedroso, Andrea Agazzi, W. P. M. H. Heemels, Mauro Salazar</dc:creator>
    </item>
    <item>
      <title>Information Design with Elicitation and Strategic Coordination</title>
      <link>https://arxiv.org/abs/2302.12223</link>
      <description>arXiv:2302.12223v3 Announce Type: replace 
Abstract: We study linear-quadratic games of incomplete information with Gaussian uncertainty, where each player's payoff depends on a privately observed type and a common state. The designer observes the state, elicits types, and sells action recommendations. We characterize all implementable mechanisms with Gaussian joint distributions of actions and fundamentals, and identify the players-optimal, consumer-optimal, and revenue-maximizing designs. In games of strategic complements (substitutes), these optimal mechanisms maximally correlate (anticorrelate) players' actions. When type uncertainty is large, recommendations become deterministic linear functions of the state and reports, but remain only partially revealing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.12223v3</guid>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alessandro Bonatti, Munther A. Dahleh, Thibaut Horel</dc:creator>
    </item>
    <item>
      <title>Online Selection with Uncertain Disruption</title>
      <link>https://arxiv.org/abs/2505.22999</link>
      <description>arXiv:2505.22999v2 Announce Type: replace 
Abstract: In numerous online selection problems, decision-makers (DMs) must allocate on the fly limited resources to customers with uncertain values. The DM faces the tension between allocating resources to currently observed values and saving them for potentially better, unobserved values in the future. Addressing this tension becomes more demanding if an uncertain disruption occurs while serving customers. Without any disruption, the DM gets access to the capacity information to serve customers throughout the time horizon. However, with uncertain disruption, the DM must act more cautiously due to risk of running out of capacity abruptly or misusing the resources. Motivated by this tension, we introduce the Online Selection with Uncertain Disruption (OS-UD) problem. In OS-UD, a DM sequentially observes n non-negative values drawn from a common distribution and must commit to select or reject each value in real time, without revisiting past values. The disruption is modeled as a Bernoulli random variable with probability p each time DM selects a value. We aim to design an online algorithm that maximizes the expected sum of selected values before a disruption occurs, if any. We evaluate online algorithms using the competitive ratio. Using a quantile-based approach, we devise a non-adaptive single-threshold algorithm that attains a competitive ratio of at least 1-1/e, and an adaptive threshold algorithm characterized by a sequence of non-increasing thresholds that attains an asymptotic competitive ratio of at least 0.745. Both of these results are worst-case optimal within their corresponding class of algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.22999v2</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yihua Xu, S\"uleyman Kerimov, Sebastian Perez-Salazar</dc:creator>
    </item>
    <item>
      <title>On characterization and existence of constrained correlated equilibria in Markov games</title>
      <link>https://arxiv.org/abs/2507.03502</link>
      <description>arXiv:2507.03502v2 Announce Type: replace 
Abstract: Markov games with coupling constraints provide a natural framework to study constrained decision-making involving self-interested agents, where the feasibility of an individual agent's strategy depends on the joint strategies of the others. Such games arise in numerous real-world applications involving safety requirements and budget caps, for example, in environmental management, electricity markets, and transportation systems. While correlated equilibria have emerged as an important solution concept in unconstrained settings due to their computational tractability and amenability to learning, their constrained counterparts remain less explored. In this paper, we study constrained correlated equilibria-feasible policies where any unilateral modifications are either unprofitable or infeasible. We first characterize the constrained correlated equilibrium showing that different sets of modifications result in an equivalent notion, a result which may enable efficient learning algorithms. We then address existence conditions. In particular, we show that a strong Slater-type condition is necessary in games with playerwise coupling constraints, but can be significantly weakened when all players share common coupling constraints. Under this relaxed condition, we prove the existence of a constrained correlated equilibrium.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.03502v2</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Tingting Ni, Anna Maddux, Maryam Kamgarpour</dc:creator>
    </item>
    <item>
      <title>Subgame Credible Nash Equilibrium</title>
      <link>https://arxiv.org/abs/2206.05241</link>
      <description>arXiv:2206.05241v2 Announce Type: replace-cross 
Abstract: We propose the Subgame Credible Nash Equilibrium (SCNE), a refinement of subgame perfect Nash equilibrium (SPNE) for multi-stage games. SCNE retains the internal credibility requirement of SPNE -- equilibrium behavior in every subgame -- and adds an external credibility requirement across equivalent subgames: whenever a player's prescribed continuation strategy differs across equivalent subgames, her own continuation payoff must not decrease. The intuition is that credible punishments or promises should not strictly harm the punisher relative to an equivalent no-punishment subgame. The SCNE eliminates equilibria sustained by self-harming punishments or promises while preserving existence. Every multi-stage game admits an SCNE, and if each stage game has a unique Nash equilibrium, the SCNE is unique.</description>
      <guid isPermaLink="false">oai:arXiv.org:2206.05241v2</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mehmet Mars Seven</dc:creator>
    </item>
    <item>
      <title>You Are the Best Reviewer of Your Own Papers: The Isotonic Mechanism</title>
      <link>https://arxiv.org/abs/2206.08149</link>
      <description>arXiv:2206.08149v3 Announce Type: replace-cross 
Abstract: Machine learning (ML) and artificial intelligence (AI) conferences including NeurIPS and ICML have experienced a significant decline in peer review quality in recent years. To address this growing challenge, we introduce the Isotonic Mechanism, a computationally efficient approach to enhancing the accuracy of noisy review scores by incorporating authors' private assessments of their submissions. Under this mechanism, authors with multiple submissions are required to rank their papers in descending order of perceived quality. Subsequently, the raw review scores are calibrated based on this ranking to produce adjusted scores. We prove that authors are incentivized to truthfully report their rankings because doing so maximizes their expected utility, modeled as an additive convex function over the adjusted scores. Moreover, the adjusted scores are shown to be more accurate than the raw scores, with improvements being particularly significant when the noise level is high and the author has many submissions -- a scenario increasingly prevalent at large-scale ML/AI conferences.
  We further investigate whether submission quality information beyond a simple ranking can be truthfully elicited from authors. We establish that a necessary condition for truthful elicitation is that the mechanism be based on pairwise comparisons of the author's submissions. This result underscores the optimality of the Isotonic Mechanism, as it elicits the most fine-grained truthful information among all mechanisms we consider. We then present several extensions, including a demonstration that the mechanism maintains truthfulness even when authors have only partial rather than complete information about their submission quality. Finally, we discuss future research directions, focusing on the practical implementation of the mechanism and the further development of a theoretical framework inspired by our mechanism.</description>
      <guid isPermaLink="false">oai:arXiv.org:2206.08149v3</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Weijie Su</dc:creator>
    </item>
    <item>
      <title>LLM Strategic Reasoning: Agentic Study through Behavioral Game Theory</title>
      <link>https://arxiv.org/abs/2502.20432</link>
      <description>arXiv:2502.20432v3 Announce Type: replace-cross 
Abstract: Strategic decision-making involves interactive reasoning where agents adapt their choices in response to others, yet existing evaluations of large language models (LLMs) often emphasize Nash Equilibrium (NE) approximation, overlooking the mechanisms driving their strategic choices. To bridge this gap, we introduce an evaluation framework grounded in behavioral game theory, disentangling reasoning capability from contextual effects. Testing 22 state-of-the-art LLMs, we find that GPT-o3-mini, GPT-o1, and DeepSeek-R1 dominate most games yet also demonstrate that the model scale alone does not determine performance. In terms of prompting enhancement, Chain-of-Thought (CoT) prompting is not universally effective, as it increases strategic reasoning only for models at certain levels while providing limited gains elsewhere. Additionally, we investigate the impact of encoded demographic features on the models, observing that certain assignments impact the decision-making pattern. For instance, GPT-4o shows stronger strategic reasoning with female traits than males, while Gemma assigns higher reasoning levels to heterosexual identities compared to other sexual orientations, indicating inherent biases. These findings underscore the need for ethical standards and contextual alignment to balance improved reasoning with fairness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.20432v3</guid>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jingru Jia, Zehua Yuan, Junhao Pan, Paul E. McNamara, Deming Chen</dc:creator>
    </item>
    <item>
      <title>GTAlign: Game-Theoretic Alignment of LLM Assistants for Social Welfare</title>
      <link>https://arxiv.org/abs/2510.08872</link>
      <description>arXiv:2510.08872v3 Announce Type: replace-cross 
Abstract: Large Language Models (LLMs) have achieved remarkable progress in reasoning, yet sometimes produce responses that are suboptimal for users in tasks such as writing, information seeking, or providing practical guidance. Conventional alignment practices typically assume that maximizing model reward also maximizes user welfare, but this assumption frequently fails in practice: models may over-clarify or generate overly verbose reasoning when users prefer concise answers. Such behaviors resemble the prisoner's dilemma, where individually rational choices lead to socially suboptimal outcomes. The fundamental challenge is the lack of a principled decision making mechanism that mutually benefits both the LLM and the user. We propose Game-Theoretic Alignment (GTAlign), an alignment framework that integrates game-theoretic decision making into both reasoning and training. During reasoning, the model explicitly treats user-LLM interaction as a strategic game: it constructs payoff matrices within its reasoning chain to estimate welfare for both itself and the user, and then selects actions that are mutually beneficial. During training, we introduce a social welfare reward that reinforces cooperative responses, aligning model behavior with socially efficient outcomes. In addition, we introduce an inference technique that leverages game-theoretic reasoning to dynamically adapt LLM's response when pricing policies of LLM service change. Extensive experiments demonstrate that GTAlign substantially improves reasoning efficiency, answer quality, and social welfare compared to baselines across diverse tasks. The code is available at https://github.com/ulab-uiuc/GTAlign .</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.08872v3</guid>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.48550/arXiv.2510.08872</arxiv:DOI>
      <dc:creator>Siqi Zhu, David Zhang, Pedro Cisneros-Velarde, Jiaxuan You</dc:creator>
    </item>
  </channel>
</rss>
