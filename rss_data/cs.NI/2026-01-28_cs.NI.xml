<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 28 Jan 2026 05:00:01 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Intent2QoS: Language Model-Driven Automation of Traffic Shaping Configurations</title>
      <link>https://arxiv.org/abs/2601.18974</link>
      <description>arXiv:2601.18974v1 Announce Type: new 
Abstract: Traffic shaping and Quality of Service (QoS) enforcement are critical for managing bandwidth, latency, and fairness in networks. These tasks often rely on low-level traffic control settings, which require manual setup and technical expertise. This paper presents an automated framework that converts high-level traffic shaping intents in natural or declarative language into valid and correct traffic control rules. To the best of our knowledge, we present the first end-to-end pipeline that ties intent translation in a queuing-theoretic semantic model and, with a rule-based critic, yields deployable Linux traffic control configuration sets. The framework has three steps: (1) a queuing simulation with priority scheduling and Active Queue Management (AQM) builds a semantic model; (2) a language model, using this semantic model and a traffic profile, generates sub-intents and configuration rules; and (3) a rule-based critic checks and adjusts the rules for correctness and policy compliance. We evaluate multiple language models by generating traffic control commands from business intents that comply with relevant standards for traffic control protocols. Experimental results on 100 intents show significant gains, with LLaMA3 reaching 0.88 semantic similarity and 0.87 semantic coverage, outperforming other models by over 30\. A thorough sensitivity study demonstrates that AQM-guided prompting reduces variability threefold compared to zero-shot baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.18974v1</guid>
      <category>cs.NI</category>
      <category>cs.CL</category>
      <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Sudipta Acharya, Burak Kantarci</dc:creator>
    </item>
    <item>
      <title>Optimizing Network Topology Efficiency: A Resource-Centric Analysis of Non-Blocking Architectures</title>
      <link>https://arxiv.org/abs/2601.19008</link>
      <description>arXiv:2601.19008v1 Announce Type: new 
Abstract: In modern network design, "efficiency" is often conflated with raw performance metrics like latency or aggregate throughput. This paper proposes a resource-centric definition of efficiency, isolating the hardware cost required to maintain a non-blocking throughput constraint. By modeling network cost as a function of the Traffic Multiplier (Hop Count) and Router Complexity (Radix), we demonstrate that the optimal topology is determined by the technological ratio between link interface costs ($\alpha$), crossbar switching costs ($\beta$), and the network concentration ratio. We conclude that while high-radix direct networks optimize efficiency at small to medium scales, indirect networks (e.g., Fat Trees) are required to cap router complexity at massive scales. Furthermore, we posit that redundancy is most efficiently handled via parallel network instances (e.g., multi-plane Star networks) rather than intrinsic topological path diversity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.19008v1</guid>
      <category>cs.NI</category>
      <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jia Xu Wei, Wei Wei</dc:creator>
    </item>
    <item>
      <title>Design and Evaluation of Next-Generation Cellular Networks through Digital and Physical Open and Programmable Platforms</title>
      <link>https://arxiv.org/abs/2601.19027</link>
      <description>arXiv:2601.19027v1 Announce Type: new 
Abstract: The evolution of the Radio Access Network (RAN) in 5G and 6G technologies marks a shift toward open, programmable, and softwarized architectures, driven by the Open RAN paradigm. This approach emphasizes open interfaces for telemetry sharing, intelligent data-driven control loops for network optimization, and virtualization and disaggregation of multi-vendor RAN components. While promising, this transition introduces significant challenges, including the need to design interoperable solutions, acquire datasets to train and test AI/ML algorithms for inference and control, and develop testbeds to benchmark these solutions. Experimental wireless platforms and private 5G deployments play a key role, providing architectures comparable to real-world systems and enabling prototyping and testing in realistic environments. This dissertation focuses on the development and evaluation of complementary experimental platforms: Colosseum, the world's largest Open RAN digital twin, and X5G, an open, programmable, multi-vendor private 5G O-RAN testbed with GPU acceleration. The main contributions include: (i) CaST, enabling automated creation and validation of digital twin wireless scenarios through 3D modeling, ray-tracing, and channel sounding; (ii) validation of Colosseum digital twins at scale, demonstrating that emulated environments closely reproduce real-world setups; (iii) X5G, integrating NVIDIA Aerial GPU-accelerated PHY processing with OpenAirInterface higher layers; (iv) a GPU-accelerated dApp framework for real-time RAN inference, enabling sub-millisecond control loops for AI-native applications including ISAC; and (v) intelligent RAN applications spanning spectrum sharing, interference detection, network slicing, security, and CSI-based sensing. Overall, this dissertation provides an end-to-end methodology bridging digital and physical experimentation for next-generation cellular networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.19027v1</guid>
      <category>cs.NI</category>
      <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Davide Villa</dc:creator>
    </item>
    <item>
      <title>FTA-NTN: Fairness and Throughput Assurance in Non-Terrestrial Networks</title>
      <link>https://arxiv.org/abs/2601.19078</link>
      <description>arXiv:2601.19078v1 Announce Type: new 
Abstract: Designing optimal non-terrestrial network (NTN) constellations is essential for maximizing throughput and ensuring fair resource distribution. This paper presents FTA-NTN (Fairness and Throughput Assurance in Non-Terrestrial Networks), a multi-objective optimization framework that jointly maximizes throughput and fairness under realistic system constraints. The framework integrates multi-layer Walker Delta constellations, a parametric mobility model for user distributions across Canadian land regions, adaptive K-Means clustering for beamforming and user association, and Bayesian optimization for parameter tuning. Simulation results with 500 users show that FTA-NTN achieves over 9.88 Gbps of aggregate throughput with an average fairness of 0.42, corresponding to an optimal configuration of 9 planes with 15 satellites per plane in LEO and 7 planes with 3 satellites per plane in MEO. These values align with 3GPP NTN evaluation scenarios and representative system assumptions, confirming their relevance for realistic deployments. Overall, FTA-NTN demonstrates that throughput and fairness can be jointly optimized under practical constraints, advancing beyond throughput-centric designs in the literature and offering a scalable methodology for next-generation NTN deployments that supports efficient and equitable global connectivity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.19078v1</guid>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Sachin Ravikant Trankatwar, Heiko Straulino, Petar Djukic, Burak Kantarci</dc:creator>
    </item>
    <item>
      <title>In-Network Collective Operations: Game Changer or Challenge for AI Workloads?</title>
      <link>https://arxiv.org/abs/2601.19132</link>
      <description>arXiv:2601.19132v1 Announce Type: new 
Abstract: This paper summarizes the opportunities of in-network collective operations (INC) for accelerated collective operations in AI workloads. We provide sufficient detail to make this important field accessible to non-experts in AI or networking, fostering a connection between these communities. Consider two types of INC: Edge-INC, where the system is implemented at the node level, and Core-INC, where the system is embedded within network switches. We outline the potential performance benefits as well as six key obstacles in the context of both Edge-INC and Core-INC that may hinder their adoption. Finally, we present a set of predictions for the future development and application of INC.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.19132v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.AR</category>
      <category>cs.PF</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/MC.2025.3616048</arxiv:DOI>
      <arxiv:journal_reference>IEEE Computer Jan. 2026</arxiv:journal_reference>
      <dc:creator>Torsten Hoefler, Mikhail Khalilov, Josiah Clark, Surendra Anubolu, Mohan Kalkunte, Karen Schramm, Eric Spada, Duncan Roweth, Keith Underwood, Adrian Caulfield, Abdul Kabbani, Amirreza Rastegari</dc:creator>
    </item>
    <item>
      <title>Enabling SLO-Aware 5G Multi-Access Edge Computing with SMEC</title>
      <link>https://arxiv.org/abs/2601.19162</link>
      <description>arXiv:2601.19162v1 Announce Type: new 
Abstract: Multi-access edge computing (MEC) promises to enable latency-critical applications by bringing computational power closer to mobile devices, but our measurements on commercial MEC deployments reveal frequent SLO violations due to high tail latencies. We identify resource contention at the RAN and the edge server as the root cause, compounded by SLO-unaware schedulers. Existing SLO-aware approaches require RAN--edge coordination, making them impractical for deployment and prone to poor performance due to coordination delays, limited heterogeneous application support, and ignoring edge resource contention. This paper introduces SMEC, a practical, SLO-aware resource management framework that facilitates deadline-aware scheduling through fully decoupled operations at the RAN and edge servers. Our key insight is that standard 5G protocols and application behaviors naturally provide information exploitable for SLO-aware management without extensive infrastructure or application changes. Evaluation on our 5G MEC testbed shows that SMEC achieves 90-96% SLO satisfaction versus under 6% for existing approaches, while reducing tail latency by up to 122$\times$. We have open-sourced SMEC at https://github.com/smec-project.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.19162v1</guid>
      <category>cs.NI</category>
      <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiao Zhang, Daehyeok Kim</dc:creator>
    </item>
    <item>
      <title>Bridging Visual and Wireless Sensing: A Unified Radiation Field for 3D Radio Map Construction</title>
      <link>https://arxiv.org/abs/2601.19216</link>
      <description>arXiv:2601.19216v1 Announce Type: new 
Abstract: The emerging applications of next-generation wireless networks (e.g., immersive 3D communication, low-altitude networks, and integrated sensing and communication) necessitate high-fidelity environmental intelligence. 3D radio maps have emerged as a critical tool for this purpose, enabling spectrum-aware planning and environment-aware sensing by bridging the gap between physical environments and electromagnetic signal propagation. However, constructing accurate 3D radio maps requires fine-grained 3D geometric information and a profound understanding of electromagnetic wave propagation. Existing approaches typically treat optical and wireless knowledge as distinct modalities, failing to exploit the fundamental physical principles governing both light and electromagnetic propagation. To bridge this gap, we propose URF-GS, a unified radio-optical radiation field representation framework for accurate and generalizable 3D radio map construction based on 3D Gaussian splatting (3D-GS) and inverse rendering. By fusing visual and wireless sensing observations, URF-GS recovers scene geometry and material properties while accurately predicting radio signal behavior at arbitrary transmitter-receiver (Tx-Rx) configurations. Experimental results demonstrate that URF-GS achieves up to a 24.7% improvement in spatial spectrum prediction accuracy and a 10x increase in sample efficiency for 3D radio map construction compared with neural radiance field (NeRF)-based methods. This work establishes a foundation for next-generation wireless networks by integrating perception, interaction, and communication through holistic radiation field reconstruction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.19216v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chaozheng Wen, Jingwen Tong, Zehong Lin, Chenghong Bian, Jun Zhang</dc:creator>
    </item>
    <item>
      <title>NET4EXA: Pioneering the Future of Interconnects for Supercomputing and AI</title>
      <link>https://arxiv.org/abs/2601.19413</link>
      <description>arXiv:2601.19413v1 Announce Type: new 
Abstract: NET4EXA aims to develop a next-generation high-performance interconnect for HPC and AI systems, addressing the increasing demands of large-scale infrastructures, such as those required for training Large Language Models. Building upon the proven BXI (Bull eXascale Interconnect) European technology used in TOP15 supercomputers, NET4EXA will deliver the new BXI release, BXIv3, a complete hardware and software interconnect solution, including switch and network interface components. The project will integrate a fully functional pilot system at TRL 8, ready for deployment into upcoming exascale and post-exascale systems from 2025 onward. Leveraging prior research from European initiatives like RED-SEA, the previous achievements of consortium partners and over 20 years of expertise from BULL, NET4EXA also lays the groundwork for the future generation of BXI, BXIv4, providing analysis and preliminary design. The project will use a hybrid development and co-design approach, combining commercial switch technology with custom IP and FPGA-based NICs. Performances of NET4EXA BXIv3 interconnect will be evaluated using a broad portfolio of benchmarks, scientific scalable applications, and AI workloads.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.19413v1</guid>
      <category>cs.NI</category>
      <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michele Martinelli, Roberto Ammendola, Andrea Biagioni, Carlotta Chiarini, Ottorino Frezza, Francesca Lo Cicero, Alessandro Lonardo, Pier Stanislao Paolucci, Elena Pastorelli, Pierpaolo Perticaroli, Luca Pontisso, Cristian Rossi, Francesco Simula, Piero Vicini, David Colin, Gr\'egoire Pichon, Alexandre Louvet, John Gliksberg, Claire Chen, Matteo Turisini, Andrea Monterubbiano, Jean-Philippe Nomin\'e, Denis Dutoit, Hugo Taboada, Lilia Zaourar, Mohamed Benazouz, Angelos Bilas, Fabien Chaix, Manolis Katevenis, Nikolaos Chrysos, Evangelos Mageiropoulos, Christos Kozanitis, Thomas Moen, Steffen Persvold, Einar Rustad, Sandro Fiore, Fabrizio Granelli, Simone Pezzuto, Raffaello Potestio, Luca Tubiana, Philippe Velha, Flavio Vella, Daniele De Sensi, Salvatore Pontarelli</dc:creator>
    </item>
    <item>
      <title>Quantum Takes Flight: Two-Stage Resilient Topology Optimization for UAV Networks</title>
      <link>https://arxiv.org/abs/2601.19724</link>
      <description>arXiv:2601.19724v1 Announce Type: new 
Abstract: Next-generation Unmanned Aerial Vehicle (UAV) communication networks must maintain reliable connectivity under rapid topology changes, fluctuating link quality, and time-critical data exchange. Existing topology control methods rely on global optimization to produce a single optimal topology or involve high computational complexity, which limits adaptability in dynamic environments. This paper presents a two-stage quantum-assisted framework for efficient and resilient topology control in dynamic UAV networks by exploiting quantum parallelism to generate a set of high-quality and structurally diverse candidate topologies. In the offline stage, we formulate the problem as a Quadratic Unconstrained Binary Optimization (QUBO) model and leverage quantum annealing (QA) to parallelly sample multiple high-quality and structurally distinct topologies, providing a rich solution space for adaptive decision-making. In the online stage, a lightweight classical selection mechanism rapidly identifies the most suitable topology based on real-time link stability and channel conditions, substantially reducing the computation delay. The simulation results show that, compared to a single static optimal topology, the proposed framework improves performance retention by 6.6% in a 30-second dynamic window. Moreover, relative to the classic method, QA achieves an additional 5.15% reduction in objective value and a 28.3% increase in solution diversity. These findings demonstrate the potential of QA to enable fast and robust topology control for next-generation UAV communication networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.19724v1</guid>
      <category>cs.NI</category>
      <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Huixiang Zhang, Mahzabeen Emu, Octavia A. Dobre</dc:creator>
    </item>
    <item>
      <title>Time-Constrained Erasure Correction for Data Recovery in UAV-Aided IoT</title>
      <link>https://arxiv.org/abs/2403.09782</link>
      <description>arXiv:2403.09782v4 Announce Type: replace 
Abstract: We propose data-recovery schemes to improve the uplink reliability of Internet of Things (IoT) networks in which a gateway mounted on an unmanned aerial vehicle (UAV) collects data from sensor nodes on the ground. The proposed techniques employ fountain coding and message replication to correct frame erasures on the sensor-to-UAV links. A salient feature of the proposed schemes is their adaptive selection of the redundancy amount depending on the contact times between a sensor and the UAV. We illustrate our design philosophy for the special case of a network in which wake-up radios (WuRs) are used for activating the sensors upon the UAV's arrival, and the sensor-to-UAV data transfer employs the Long Range (LoRa) communication technology with random access.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.09782v4</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>0.1109/LCOMM.2025.3633952</arxiv:DOI>
      <dc:creator>Kushwanth Sistu, Siddhartha S. Borkotoky</dc:creator>
    </item>
    <item>
      <title>Online Convex Optimization for On-Board Routing in High-Throughput Satellites</title>
      <link>https://arxiv.org/abs/2409.01488</link>
      <description>arXiv:2409.01488v2 Announce Type: replace 
Abstract: The rise in low Earth orbit (LEO) satellite Internet services has led to increasing demand, often exceeding available data rates and compromising the quality of service. While deploying more satellites offers a short-term fix, designing higher-performance satellites with enhanced transmission capabilities provides a more sustainable solution. Achieving the necessary high capacity requires interconnecting multiple modem banks within a satellite payload. However, there is a notable gap in research on internal packet routing within extremely high-throughput satellites. To address this, we propose a real-time optimal flow allocation and priority queue scheduling method using online convex optimization-based model predictive control. We model the problem as a multi-commodity flow instance and employ an online interior-point method to solve the routing and scheduling optimization iteratively. This approach minimizes packet loss and supports real-time rerouting with low computational overhead. Our method is tested in simulation on a next-generation extremely high-throughput satellite model, demonstrating its effectiveness compared to a reference batch optimization and to traditional methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.01488v2</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Olivier B\'elanger, Jean-Luc Lupien, Olfa Ben Yahia, St\'ephane Martel, Antoine Lesage-Landry, Gunes Karabulut Kurt</dc:creator>
    </item>
    <item>
      <title>Traffic Engineering in Large-scale Networks with Generalizable Graph Neural Networks</title>
      <link>https://arxiv.org/abs/2503.24203</link>
      <description>arXiv:2503.24203v2 Announce Type: replace 
Abstract: Traffic Engineering (TE) in large-scale networks like cloud Wide Area Networks (WANs) and Low Earth Orbit (LEO) satellite constellations is a critical challenge. Although learning-based approaches have been proposed to address the scalability of traditional TE algorithms, their practical application is often hindered by a lack of generalization, high training overhead, and a failure to respect link capacities. This paper proposes TELGEN, a novel TE algorithm that learns to solve TE problems efficiently in large-scale network scenarios, while achieving superior generalizability across diverse network conditions. TELGEN is based on the novel idea of transforming the problem of "predicting the optimal TE solution" into "predicting the optimal TE algorithm", which enables TELGEN to learn and efficiently approximate the end-to-end solving process of classical optimal TE algorithms. The learned algorithm is agnostic to the exact underlying network topology or traffic patterns, and is able to very efficiently solve TE problems given arbitrary inputs and generalize well to unseen topologies and demands. We train and evaluate TELGEN with random and real-world topologies, with networks of up to 5000 nodes and 3.6x10^6 links in testing. TELGEN shows less than 3% optimality gap while ensuring feasibility in all testing scenarios, even when the test network has 2-20x more nodes than the largest training network. It also saves up to 84% TE solving time than traditional interior-point method, and reduces up to 79.6% training time per epoch than the state-of-the-art learning-based algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.24203v2</guid>
      <category>cs.NI</category>
      <category>cs.LG</category>
      <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fangtong Zhou, Xiaorui Liu, Ruozhou Yu, Guoliang Xue</dc:creator>
    </item>
    <item>
      <title>Route Planning and Online Routing for Quantum Key Distribution Networks</title>
      <link>https://arxiv.org/abs/2508.09735</link>
      <description>arXiv:2508.09735v2 Announce Type: replace 
Abstract: Quantum Key Distribution (QKD) networks harness the principles of quantum physics in order to securely transmit cryptographic key material, providing physical guarantees. These networks require traditional management and operational components, such as routing information through the network elements. However, due to the limitations on capacity and the particularities of information handling in these networks, traditional shortest paths algorithms for routing perform poorly on both route planning and online routing, which is counterintuitive. Moreover, due to the scarce resources in such networks, often the expressed demand cannot be met by any assignment of routes. To address both the route planning problem and the need for fair automated suggestions in infeasible cases, we propose to model this problem as a Quadratic Programming (QP) problem. For the online routing problem, we showcase that the shortest (available) paths routing strategy performs poorly in the online setting. Furthermore, we prove that the widest shortest path routing strategy has a competitive ratio greater or equal than $\frac{1}{2}$, efficiently addressing both routing modes in QKD networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.09735v2</guid>
      <category>cs.NI</category>
      <category>cs.CR</category>
      <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jorge L\'opez, Charalampos Chatzinakis, Marc Cartigny</dc:creator>
    </item>
    <item>
      <title>A Zero Added Loss Multiplexing (ZALM) Source Simulation</title>
      <link>https://arxiv.org/abs/2510.26009</link>
      <description>arXiv:2510.26009v3 Announce Type: replace 
Abstract: Zero Added Loss Multiplexing (ZALM) offers broadband, per channel heralded EPR pairs, with a rich parameter space that allows its performance to be tailored for specific applications. We present a modular ZALM simulator that demonstrates how design choices affect output rate and fidelity. Built in NetSquid with QSI controllers, it exposes 20+ tunable parameters, supports IDEAL and REALISTIC modes, and provides reusable components for Spontaneous Parametric Down Conversion (SPDC) sources, interference, Dense Wavelength Division Multiplexing (DWDM) filtering, fiber delay, active polarization gates, detectors, and lossy fiber. Physics based models capture Hong Ou Mandel (HOM) visibility, insertion loss, detector efficiency, gate errors, and attenuation. Using this tool, we map trade offs among fidelity, link distance, and entangled pairs per use, and show how SPDC bandwidth and DWDM grid spacing steer performance. Using the default configuration settings, average fidelity remains constant at 0.83 but the ebit rate decreases from 0.0175 at the source to 0.0 at 50 km; narrowing the SPDC degeneracy bandwidth increases the ebit rate significantly without affecting fidelity. The simulator enables codesign of source, filtering, and feedforward settings for specific quantum memories and integrates as a building block for end to end quantum network studies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.26009v3</guid>
      <category>cs.NI</category>
      <category>quant-ph</category>
      <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jerry Horgan, Alexander Nico-Katz, Shelbi L. Jenkins, Ashley N. Tittelbaugh, Vivek Visan, Rohan Bali, Marco Ruffini, Boulat A. Bash, Daniel C. Kilper</dc:creator>
    </item>
    <item>
      <title>An Efficient and Explainable KAN Framework for Wireless Radiation Field Prediction</title>
      <link>https://arxiv.org/abs/2601.11656</link>
      <description>arXiv:2601.11656v2 Announce Type: replace 
Abstract: Modeling wireless channels accurately remains a challenge due to environmental variations and signal uncertainties. Recent neural networks can learn radio frequency~(RF) signal propagation patterns, but they process each voxel on the ray independently, without considering global context or environmental factors. Our paper presents a new approach that learns comprehensive representations of complete rays rather than individual points, capturing more detailed environmental features. We integrate a Kolmogorov-Arnold network (KAN) architecture with transformer modules to achieve better performance across realistic and synthetic scenes while maintaining computational efficiency. Our experimental results show that this approach outperforms existing methods in various scenarios. Ablation studies confirm that each component of our model contributes to its effectiveness. Additional experiments provide clear explanations for our model's performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.11656v2</guid>
      <category>cs.NI</category>
      <category>cs.CV</category>
      <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/MASS66014.2025.00021</arxiv:DOI>
      <arxiv:journal_reference>2025 IEEE 22nd International Conference on Mobile Ad-Hoc and Smart Systems (MASS) 51-59</arxiv:journal_reference>
      <dc:creator>Jingzhou Shen, Xuyu Wang</dc:creator>
    </item>
  </channel>
</rss>
