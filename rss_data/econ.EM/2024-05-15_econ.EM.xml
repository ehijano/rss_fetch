<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.EM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.EM</link>
    <description>econ.EM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.EM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 15 May 2024 05:22:28 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 15 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Random Utility Models with Skewed Random Components: the Smallest versus Largest Extreme Value Distribution</title>
      <link>https://arxiv.org/abs/2405.08222</link>
      <description>arXiv:2405.08222v1 Announce Type: new 
Abstract: At the core of most random utility models (RUMs) is an individual agent with a random utility component following a largest extreme value Type I (LEVI) distribution. What if, instead, the random component follows its mirror image -- the smallest extreme value Type I (SEVI) distribution? Differences between these specifications, closely tied to the random component's skewness, can be quite profound. For the same preference parameters, the two RUMs, equivalent with only two choice alternatives, diverge progressively as the number of alternatives increases, resulting in substantially different estimates and predictions for key measures, such as elasticities and market shares.
  The LEVI model imposes the well-known independence-of-irrelevant-alternatives property, while SEVI does not. Instead, the SEVI choice probability for a particular option involves enumerating all subsets that contain this option. The SEVI model, though more complex to estimate, is shown to have computationally tractable closed-form choice probabilities. Much of the paper delves into explicating the properties of the SEVI model and exploring implications of the random component's skewness.
  Conceptually, the difference between the LEVI and SEVI models centers on whether information, known only to the agent, is more likely to increase or decrease the systematic utility parameterized using observed attributes. LEVI does the former; SEVI the latter. An immediate implication is that if choice is characterized by SEVI random components, then the observed choice is more likely to correspond to the systematic-utility-maximizing choice than if characterized by LEVI. Examining standard empirical examples from different applied areas, we find that the SEVI model outperforms the LEVI model, suggesting the relevance of its inclusion in applied researchers' toolkits.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.08222v1</guid>
      <category>econ.EM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Richard T. Carson, Derrick H. Sun, Yixiao Sun</dc:creator>
    </item>
    <item>
      <title>Predicting NVIDIA's Next-Day Stock Price: A Comparative Analysis of LSTM, MLP, ARIMA, and ARIMA-GARCH Models</title>
      <link>https://arxiv.org/abs/2405.08284</link>
      <description>arXiv:2405.08284v1 Announce Type: new 
Abstract: Forecasting stock prices remains a considerable challenge in financial markets, bearing significant implications for investors, traders, and financial institutions. Amid the ongoing AI revolution, NVIDIA has emerged as a key player driving innovation across various sectors. Given its prominence, we chose NVIDIA as the subject of our study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.08284v1</guid>
      <category>econ.EM</category>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yiluan Xing, Chao Yan, Cathy Chang Xie</dc:creator>
    </item>
    <item>
      <title>Latent group structure in linear panel data models with endogenous regressors</title>
      <link>https://arxiv.org/abs/2405.08687</link>
      <description>arXiv:2405.08687v1 Announce Type: new 
Abstract: This paper concerns the estimation of linear panel data models with endogenous regressors and a latent group structure in the coefficients. We consider instrumental variables estimation of the group-specific coefficient vector. We show that direct application of the Kmeans algorithm to the generalized method of moments objective function does not yield unique estimates. We newly develop and theoretically justify two-stage estimation methods that apply the Kmeans algorithm to a regression of the dependent variable on predicted values of the endogenous regressors. The results of Monte Carlo simulations demonstrate that two-stage estimation with the first stage modeled using a latent group structure achieves good classification accuracy, even if the true first-stage regression is fully heterogeneous. We apply our estimation methods to revisiting the relationship between income and democracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.08687v1</guid>
      <category>econ.EM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junho Choi, Ryo Okui</dc:creator>
    </item>
    <item>
      <title>Variational Bayes and non-Bayesian Updating</title>
      <link>https://arxiv.org/abs/2405.08796</link>
      <description>arXiv:2405.08796v1 Announce Type: cross 
Abstract: I show how variational Bayes can be used as a microfoundation for a popular model of non-Bayesian updating. All the results here are mathematically trivial, but I think this direction is potentially interesting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.08796v1</guid>
      <category>econ.TH</category>
      <category>econ.EM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tomasz Strzalecki</dc:creator>
    </item>
    <item>
      <title>Bounds on the Distribution of a Sum of Two Random Variables: Revisiting a problem of Kolmogorov with application to Individual Treatment Effects</title>
      <link>https://arxiv.org/abs/2405.08806</link>
      <description>arXiv:2405.08806v1 Announce Type: cross 
Abstract: We revisit the following problem, proposed by Kolmogorov: given prescribed marginal distributions $F$ and $G$ for random variables $X,Y$ respectively, characterize the set of compatible distribution functions for the sum $Z=X+Y$. Bounds on the distribution function for $Z$ were given by Markarov (1982), and Frank et al. (1987), the latter using copula theory. However, though they obtain the same bounds, they make different assertions concerning their sharpness. In addition, their solutions leave some open problems in the case when the given marginal distribution functions are discontinuous. These issues have led to some confusion and erroneous statements in subsequent literature, which we correct.
  Kolmogorov's problem is closely related to inferring possible distributions for individual treatment effects $Y_1 - Y_0$ given the marginal distributions of $Y_1$ and $Y_0$; the latter being identified from a randomized experiment. We use our new insights to sharpen and correct results due to Fan and Park (2010) concerning individual treatment effects, and to fill some other logical gaps.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.08806v1</guid>
      <category>math.ST</category>
      <category>econ.EM</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhehao Zhang, Thomas S. Richardson</dc:creator>
    </item>
    <item>
      <title>A One-Covariate-at-a-Time Method for Nonparametric Additive Models</title>
      <link>https://arxiv.org/abs/2204.12023</link>
      <description>arXiv:2204.12023v3 Announce Type: replace 
Abstract: This paper proposes a one-covariate-at-a-time multiple testing (OCMT) approach to choose significant variables in high-dimensional nonparametric additive regression models. Similarly to Chudik, Kapetanios and Pesaran (2018), we consider the statistical significance of individual nonparametric additive components one at a time and take into account the multiple testing nature of the problem. One-stage and multiple-stage procedures are both considered. The former works well in terms of the true positive rate only if the marginal effects of all signals are strong enough; the latter helps to pick up hidden signals that have weak marginal effects. Simulations demonstrate the good finite sample performance of the proposed procedures. As an empirical application, we use the OCMT procedure on a dataset we extracted from the Longitudinal Survey on Rural Urban Migration in China. We find that our procedure works well in terms of the out-of-sample forecast root mean square errors, compared with competing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2204.12023v3</guid>
      <category>econ.EM</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Liangjun Su, Thomas Tao Yang, Yonghui Zhang, Qiankun Zhou</dc:creator>
    </item>
    <item>
      <title>Forecasting Macroeconomic Tail Risk in Real Time: Do Textual Data Add Value?</title>
      <link>https://arxiv.org/abs/2302.13999</link>
      <description>arXiv:2302.13999v2 Announce Type: replace 
Abstract: We examine the incremental value of news-based data relative to the FRED-MD economic indicators for quantile predictions of employment, output, inflation and consumer sentiment in a high-dimensional setting. Our results suggest that news data contain valuable information that is not captured by a large set of economic indicators. We provide empirical evidence that this information can be exploited to improve tail risk predictions. The added value is largest when media coverage and sentiment are combined to compute text-based predictors. Methods that capture quantile-specific non-linearities produce overall superior forecasts relative to methods that feature linear predictive relationships. The results are robust along different modeling choices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.13999v2</guid>
      <category>econ.EM</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Philipp Ad\"ammer, Jan Pr\"user, Rainer Sch\"ussler</dc:creator>
    </item>
    <item>
      <title>Fast and simple inner-loop algorithms of static / dynamic BLP estimations</title>
      <link>https://arxiv.org/abs/2404.04494</link>
      <description>arXiv:2404.04494v2 Announce Type: replace 
Abstract: This study investigates computationally efficient inner-loop algorithms for estimating static/dynamic BLP models. It provides the following ideas to reduce the number of inner-loop iterations: (1). Add a term concerning the outside option share in the BLP contraction mapping; (2). Analytically represent mean product utilities as a function of value functions and solve for the value functions (for dynamic BLP); (3-1). Combine the spectral/SQUAREM algorithm; (3-2). Choice of the step sizes. They are independent and easy to implement. This study shows good performance of these methods by numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.04494v2</guid>
      <category>econ.EM</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Takeshi Fukasawa</dc:creator>
    </item>
    <item>
      <title>Dynamic Local Average Treatment Effects</title>
      <link>https://arxiv.org/abs/2405.01463</link>
      <description>arXiv:2405.01463v2 Announce Type: replace 
Abstract: We consider Dynamic Treatment Regimes (DTRs) with One Sided Noncompliance that arise in applications such as digital recommendations and adaptive medical trials. These are settings where decision makers encourage individuals to take treatments over time, but adapt encouragements based on previous encouragements, treatments, states, and outcomes. Importantly, individuals may not comply with encouragements based on unobserved confounders. For settings with binary treatments and encouragements, we provide nonparametric identification, estimation, and inference for Dynamic Local Average Treatment Effects (LATEs), which are expected values of multiple time period treatment contrasts for the respective complier subpopulations. Under standard assumptions in the Instrumental Variable and DTR literature, we show that one can identify Dynamic LATEs that correspond to treating at single time steps. Under an additional cross-period effect-compliance independence assumption, which is satisfied in Staggered Adoption settings and a generalization of them, which we define as Staggered Compliance settings, we identify Dynamic LATEs for treating in multiple time periods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.01463v2</guid>
      <category>econ.EM</category>
      <category>cs.LG</category>
      <category>stat.ME</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ravi B. Sojitra, Vasilis Syrgkanis</dc:creator>
    </item>
    <item>
      <title>Long-term Causal Inference Under Persistent Confounding via Data Combination</title>
      <link>https://arxiv.org/abs/2202.07234</link>
      <description>arXiv:2202.07234v4 Announce Type: replace-cross 
Abstract: We study the identification and estimation of long-term treatment effects when both experimental and observational data are available. Since the long-term outcome is observed only after a long delay, it is not measured in the experimental data, but only recorded in the observational data. However, both types of data include observations of some short-term outcomes. In this paper, we uniquely tackle the challenge of persistent unmeasured confounders, i.e., some unmeasured confounders that can simultaneously affect the treatment, short-term outcomes and the long-term outcome, noting that they invalidate identification strategies in previous literature. To address this challenge, we exploit the sequential structure of multiple short-term outcomes, and develop three novel identification strategies for the average long-term treatment effect. We further propose three corresponding estimators and prove their asymptotic consistency and asymptotic normality. We finally apply our methods to estimate the effect of a job training program on long-term employment using semi-synthetic data. We numerically show that our proposals outperform existing methods that fail to handle persistent confounders.</description>
      <guid isPermaLink="false">oai:arXiv.org:2202.07234v4</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guido Imbens, Nathan Kallus, Xiaojie Mao, Yuhao Wang</dc:creator>
    </item>
  </channel>
</rss>
