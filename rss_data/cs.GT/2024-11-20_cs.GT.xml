<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 20 Nov 2024 07:02:17 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>A Stable-Set Bound and Maximal Numbers of Nash Equilibria in Bimatrix Games</title>
      <link>https://arxiv.org/abs/2411.12385</link>
      <description>arXiv:2411.12385v1 Announce Type: new 
Abstract: Quint and Shubik (1997) conjectured that a non-degenerate n-by-n game has at most 2^n-1 Nash equilibria in mixed strategies. The conjecture is true for n at most 4 but false for n=6 or larger. We answer it positively for the remaining case n=5, which had been open since 1999. The problem can be translated to a combinatorial question about the vertices of a pair of simple n-polytopes with 2n facets. We introduce a novel obstruction based on the index of an equilibrium, which states that equilibrium vertices belong to two equal-sized disjoint stable sets of the graph of the polytope. This bound is verified directly using the known classification of the 159,375 combinatorial types of dual neighborly polytopes in dimension 5 with 10 facets. Non-neighborly polytopes are analyzed with additional combinatorial techniques where the bound is used for their disjoint facets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.12385v1</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Constantin Ickstadt, Thorsten Theobald, Bernhard von Stengel</dc:creator>
    </item>
    <item>
      <title>Weighted Envy Freeness With Limited Subsidies</title>
      <link>https://arxiv.org/abs/2411.12696</link>
      <description>arXiv:2411.12696v1 Announce Type: new 
Abstract: We explore solutions for fairly allocating indivisible items among agents assigned weights representing their entitlements. Our fairness goal is weighted-envy-freeness (WEF), where each agent deems their allocated portion relative to their entitlement at least as favorable as any other's relative to their own. In many cases, achieving WEF necessitates monetary transfers, which can be modeled as third-party subsidies. The goal is to attain WEF with bounded subsidies. Previous work in the unweighted setting of subsidies relied on basic characterizations of EF that fail in the weighted settings. This makes our new setting challenging and theoretically intriguing. We present polynomial-time algorithms that compute WEF-able allocations with an upper bound on the subsidy per agent in three distinct additive valuation scenarios: (1) general, (2) identical, and (3) binary. When all weights are equal, our bounds reduce to the bounds derived in the literature for the unweighted setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.12696v1</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Noga Klein Elmalem, Rica Gonen, Erel Segal-Halevi</dc:creator>
    </item>
    <item>
      <title>Reinforcement Learning, Collusion, and the Folk Theorem</title>
      <link>https://arxiv.org/abs/2411.12725</link>
      <description>arXiv:2411.12725v1 Announce Type: new 
Abstract: We explore the behaviour emerging from learning agents repeatedly interacting strategically for a wide range of learning dynamics that includes projected gradient, replicator and log-barrier dynamics. Going beyond the better-understood classes of potential games and zero-sum games, we consider the setting of a general repeated game with finite recall, for different forms of monitoring. We obtain a Folk Theorem-like result and characterise the set of payoff vectors that can be obtained by these dynamics, discovering a wide range of possibilities for the emergence of algorithmic collusion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.12725v1</guid>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <category>stat.ML</category>
      <pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Galit Askenazi-Golan, Domenico Mergoni Cecchelli, Edward Plumb</dc:creator>
    </item>
    <item>
      <title>Equitable Core Imputations via a New Adaptation of The Primal-Dual Framework</title>
      <link>https://arxiv.org/abs/2402.11437</link>
      <description>arXiv:2402.11437v2 Announce Type: replace 
Abstract: The classic paper of Shapley and Shubik \cite{Shapley1971assignment} characterized the core of the assignment game. We observe that a sub-coalition consisting of one player (or a set of players from the same side of the bipartition) can make zero profit, and therefore its profit under a core imputation can be an arbitrary amount. Hence an arbitrary core imputation makes {\em no fairness guarantee at the level of individual agents}. Can this deficiency be addressed by picking a ``good'' core imputation?
  To arrive at an appropriate solution concept, we give specific criteria for picking a special core imputation, and we undertake a detailed comparison of four solution concepts. Leximin and leximax core imputations come out as clear winners; we define these to be {\em equitable core imputations}. These imputations achieve ``fairness'' in different ways: whereas leximin tries to make poor agents more rich, leximax tries to make rich agents less rich.
  We give combinatorial strongly polynomial algorithms for computing these imputations via a novel adaptation of the classical primal-dual paradigm. It will not be surprising if our work leads to new uses of this powerful technique. Additionally, we expect more work on computing the leximin and leximax core imputations of other natural games, in addition to the recent follow-up work \cite{Leximin-max}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.11437v2</guid>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vijay V. Vazirani</dc:creator>
    </item>
    <item>
      <title>Resonance: Transaction Fees for Heterogeneous Computation</title>
      <link>https://arxiv.org/abs/2411.11789</link>
      <description>arXiv:2411.11789v2 Announce Type: replace 
Abstract: Blockchain networks are facing increasingly heterogeneous computational demands, and in response, protocol designers have started building specialized infrastructure to supply that demand. This paper introduces Resonance: a new kind of transaction fee mechanism for the general two-sided market setting (with users on one side and nodes on the other), where both sides of the market exhibit a high degree of heterogeneity. We allow users submitting transactions to have arbitrary valuations for inclusion, nodes responsible for executing transactions to incur arbitrary costs for running any bundle of transactions, and further allow for arbitrary additional constraints on what allocations are valid. These constraints can, for example, be used to prevent state conflicts by requiring transactions that utilize the same part of the network's state to not be executed in parallel. They also enable support for new transaction types, such as transactions that require multiple nodes for execution (e.g. to run multi-party computation for better transaction privacy).
  Resonance's design utilizes competition among sophisticated brokers to find individualized prices for each transaction and node. We show that at pure Nash equilibria, Resonance finds an efficient outcome and minimizes the need for strategization by users and nodes. It is also budget-balanced, individually rational for all parties, and computationally tractable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11789v2</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maryam Bahrani, Naveen Durvasula</dc:creator>
    </item>
    <item>
      <title>PAPAL: A Provable PArticle-based Primal-Dual ALgorithm for Mixed Nash Equilibrium</title>
      <link>https://arxiv.org/abs/2303.00970</link>
      <description>arXiv:2303.00970v3 Announce Type: replace-cross 
Abstract: We consider the non-convex non-concave objective function in two-player zero-sum continuous games. The existence of pure Nash equilibrium requires stringent conditions, posing a major challenge for this problem. To circumvent this difficulty, we examine the problem of identifying a mixed Nash equilibrium, where strategies are randomized and characterized by probability distributions over continuous domains. To this end, we propose PArticle-based Primal-dual ALgorithm (PAPAL) tailored for a weakly entropy-regularized min-max optimization over probability distributions. This algorithm employs the stochastic movements of particles to represent the updates of random strategies for the $\epsilon$-mixed Nash equilibrium. We offer a comprehensive convergence analysis of the proposed algorithm, demonstrating its effectiveness. In contrast to prior research that attempted to update particle importance without movements, PAPAL is the first implementable particle-based algorithm accompanied by non-asymptotic quantitative convergence results, running time, and sample complexity guarantees. Our framework contributes novel insights into the particle-based algorithms for continuous min-max optimization in the general non-convex non-concave setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.00970v3</guid>
      <category>math.OC</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shihong Ding, Hanze Dong, Cong Fang, Zhouchen Lin, Tong Zhang</dc:creator>
    </item>
  </channel>
</rss>
