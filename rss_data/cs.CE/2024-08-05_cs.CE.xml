<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CE</link>
    <description>cs.CE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 05 Aug 2024 04:00:04 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 05 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>HRFT: Mining High-Frequency Risk Factor Collections End-to-End via Transformer</title>
      <link>https://arxiv.org/abs/2408.01271</link>
      <description>arXiv:2408.01271v1 Announce Type: new 
Abstract: In quantitative trading, it is common to find patterns in short term volatile trends of the market. These patterns are known as High Frequency (HF) risk factors, serving as key indicators of future stock price volatility. Traditionally, these risk factors were generated by financial models relying heavily on domain-specific knowledge manually added rather than extensive market data. Inspired by symbolic regression (SR), which infers mathematical laws from data, we treat the extraction of formulaic risk factors from high-frequency trading (HFT) market data as an SR task. In this paper, we challenge the manual construction of risk factors and propose an end-to-end methodology, Intraday Risk Factor Transformer (IRFT), to directly predict complete formulaic factors, including constants. We use a hybrid symbolic-numeric vocabulary where symbolic tokens represent operators/stock features and numeric tokens represent constants. We train a Transformer model on the HFT dataset to generate complete formulaic HF risk factors without relying on a predefined skeleton of operators. It determines the general shape of the stock volatility law up to a choice of constants. We refine the predicted constants (a, b) using the Broyden Fletcher Goldfarb Shanno algorithm (BFGS) to mitigate non-linear issues. Compared to the 10 approaches in SRBench, a living benchmark for SR, IRFT gains a 30% excess investment return on the HS300 and SP500 datasets, with inference times orders of magnitude faster than theirs in HF risk factor mining tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01271v1</guid>
      <category>cs.CE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wenyan Xu, Rundong Wang, Chen Li, Yonghong Hu, Zhonghua Lu</dc:creator>
    </item>
    <item>
      <title>A Comprehensive Survey on Root Cause Analysis in (Micro) Services: Methodologies, Challenges, and Trends</title>
      <link>https://arxiv.org/abs/2408.00803</link>
      <description>arXiv:2408.00803v1 Announce Type: cross 
Abstract: The complex dependencies and propagative faults inherent in microservices, characterized by a dense network of interconnected services, pose significant challenges in identifying the underlying causes of issues. Prompt identification and resolution of disruptive problems are crucial to ensure rapid recovery and maintain system stability. Numerous methodologies have emerged to address this challenge, primarily focusing on diagnosing failures through symptomatic data. This survey aims to provide a comprehensive, structured review of root cause analysis (RCA) techniques within microservices, exploring methodologies that include metrics, traces, logs, and multi-model data. It delves deeper into the methodologies, challenges, and future trends within microservices architectures. Positioned at the forefront of AI and automation advancements, it offers guidance for future research directions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.00803v1</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Tingting Wang, Guilin Qi</dc:creator>
    </item>
    <item>
      <title>Enhancing Financial Market Predictions: Causality-Driven Feature Selection</title>
      <link>https://arxiv.org/abs/2408.01005</link>
      <description>arXiv:2408.01005v1 Announce Type: cross 
Abstract: This paper introduces the FinSen dataset that revolutionizes financial market analysis by integrating economic and financial news articles from 197 countries with stock market data. The dataset's extensive coverage spans 15 years from 2007 to 2023 with temporal information, offering a rich, global perspective with 160,000 records on financial market news. Our study leverages causally validated sentiment scores and LSTM models to enhance market forecast accuracy and reliability. Utilizing the FinSen dataset, we introduce an innovative Focal Calibration Loss, reducing Expected Calibration Error (ECE) to 3.34 percent with the DAN 3 model. This not only improves prediction accuracy but also aligns probabilistic forecasts closely with real outcomes, crucial for the financial sector where predicted probability is paramount. Our approach demonstrates the effectiveness of combining sentiment analysis with precise calibration techniques for trustworthy financial forecasting where the cost of misinterpretation can be high. Finsen Data can be found at [this github URL](https://github.com/EagleAdelaide/FinSen_Dataset.git).</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01005v1</guid>
      <category>cs.LG</category>
      <category>cs.CE</category>
      <category>cs.CL</category>
      <category>cs.DB</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenhao Liang, Zhengyang Li, Weitong Chen</dc:creator>
    </item>
    <item>
      <title>Model bias identification for Bayesian calibration of stochastic digital twins of bridges</title>
      <link>https://arxiv.org/abs/2312.00664</link>
      <description>arXiv:2312.00664v2 Announce Type: replace 
Abstract: Simulation-based digital twins must provide accurate, robust and reliable digital representations of their physical counterparts. Quantifying the uncertainty in their predictions plays, therefore, a key role in making better-informed decisions that impact the actual system. The update of the simulation model based on data must be then carefully implemented. When applied to complex standing structures such as bridges, discrepancies between the computational model and the real system appear as model bias, which hinders the trustworthiness of the digital twin and increases its uncertainty. Classical Bayesian updating approaches aiming to infer the model parameters often fail at compensating for such model bias, leading to overconfident and unreliable predictions. In this paper, two alternative model bias identification approaches are evaluated in the context of their applicability to digital twins of bridges. A modularized version of Kennedy and O'Hagan's approach and another one based on Orthogonal Gaussian Processes are compared with the classical Bayesian inference framework in a set of representative benchmarks. Additionally, two novel extensions are proposed for such models: the inclusion of noise-aware kernels and the introduction of additional variables not present in the computational model through the bias term. The integration of such approaches in the digital twin corrects the predictions, quantifies their uncertainty, estimates noise from unknown physical sources of error and provides further insight into the system by including additional pre-existing information without modifying the computational model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.00664v2</guid>
      <category>cs.CE</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Daniel Andr\'es Arcones, Martin Weiser, Phaedon-Stelios Koutsourelakis, J\"org F. Unger</dc:creator>
    </item>
    <item>
      <title>Parallel performance of shared memory parallel spectral deferred corrections</title>
      <link>https://arxiv.org/abs/2403.20135</link>
      <description>arXiv:2403.20135v2 Announce Type: replace 
Abstract: We investigate parallel performance of parallel spectral deferred corrections, a numerical approach that provides small-scale parallelism for the numerical solution of initial value problems. The scheme is applied to the shallow water equation and uses an IMEX splitting that integrates fast modes implicitly and slow modes explicitly in order to be efficient. We describe parallel $\texttt{OpenMP}$-based implementations of parallel SDC in two well established simulation codes: the finite volume based operational ocean model $\texttt{ICON-O}$ and the spherical harmonics based research code $\texttt{SWEET}$. The implementations are benchmarked on a single node of the JUSUF ($\texttt{SWEET}$) and JUWELS ($\texttt{ICON-O}$) system at J\"ulich Supercomputing Centre. We demonstrate a reduction of time-to-solution across a range of accuracies. For $\texttt{ICON-O}$, we show speedup over the currently used Adams--Bashforth-2 integrator with $\texttt{OpenMP}$ loop parallelization. For $\texttt{SWEET}$, we show speedup over serial spectral deferred corrections and a second order implicit-explicit integrator.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.20135v2</guid>
      <category>cs.CE</category>
      <category>cs.DC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Philip Freese, Sebastian G\"otschel, Thibaut Lunet, Daniel Ruprecht, Martin Schreiber</dc:creator>
    </item>
    <item>
      <title>Limits of isotropic damage models for complex load paths -- beyond stress triaxiality and Lode angle parameter</title>
      <link>https://arxiv.org/abs/2406.01659</link>
      <description>arXiv:2406.01659v3 Announce Type: replace 
Abstract: The stress triaxiality and the Lode angle parameter are two well established stress invariants for the characterization of damage evolution. This work assesses the limits of this tuple by using it for damage predictions in a continuum damage mechanics framework. Isotropic and anisotropic formulations of two well-established models are used to avoid model-specific restrictions. The damage evolution is analyzed for different load paths, while the stress triaxiality and the Lode angle parameter are controlled. The equivalent plastic strain is moreover added as a third parameter, but still does not suffice to uniquely define the damage state. As a consequence, well-established concepts such as fracture surfaces depending on this triple have to be taken with care, if complex paths are to be investgated. These include, e.g., load paths observed during metal forming applications with varying load directions or multiple stages.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01659v3</guid>
      <category>cs.CE</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>K. Feike, P. Kurzeja, J. Mosler, K. Langenfeld</dc:creator>
    </item>
    <item>
      <title>Design Tasks and Their Complexity for the European Train Control System with Hybrid Train Detection</title>
      <link>https://arxiv.org/abs/2308.02572</link>
      <description>arXiv:2308.02572v3 Announce Type: replace-cross 
Abstract: Railway networks have become increasingly important in recent times, especially to move freight and public transportation from road traffic and planes to more environmentally friendly trains. Since expanding the global railway network is time and resource-consuming, maximizing the rail capacity on the existing infrastructure is desirable. However, simply running more trains is infeasible as certain constraints enforced by the train control system must be satisfied. The capacity of a network depends (amongst others) on the distance between trains allowed by this safety system. While most signaling systems rely on fixed blocks defined by costly hardware, new specifications provided by Level 2 with Hybrid Train Detection of the European Train Control System (ETCS L2 HTD), formerly known as ETCS Hybrid Level 3, allow the usage of virtual subsections. This additional degree of freedom allows for shorter train following times and, thus, more trains on existing railway tracks. On the other hand, new design tasks arise on which automated methods might be helpful for designers of modern railway networks. However, although first approaches exist that solve design problems arising within ETCS L2 HTD, neither formal descriptions nor results on the computational complexity of the corresponding design tasks exist. In this paper, we fill this gap by providing a formal description of design tasks for ETCS L2 HTD and proof that these tasks are NP-complete or NP-hard, respectively. By that, we are providing a solid basis for the future development of methods to solve those tasks, which will be integrated into the Munich Train Control Toolkit available open-source on GitHub at https://github.com/cda-tum/mtct.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.02572v3</guid>
      <category>eess.SY</category>
      <category>cs.CE</category>
      <category>cs.SY</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stefan Engels, Tom Peham, Judith Przigoda, Nils Przigoda, Robert Wille</dc:creator>
    </item>
  </channel>
</rss>
