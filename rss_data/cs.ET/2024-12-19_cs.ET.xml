<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.ET updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.ET</link>
    <description>cs.ET updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.ET" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 19 Dec 2024 05:01:32 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Stochastic Analysis of Retention Time of Coupled Memory Topology</title>
      <link>https://arxiv.org/abs/2412.13197</link>
      <description>arXiv:2412.13197v1 Announce Type: new 
Abstract: Recently, it has been experimentally demonstrated that individual memory units coupled in certain topology can provide the intended performance. However, experimental or simulation based evaluation of different coupled memory topologies and materials are costly and time consuming. In this paper, inspired by Glauber dynamics models in non-equilibrium statistical mechanics, we propose a physically accurate generic mathematical framework for analyzing retention times of various coupled memory topologies and materials. We demonstrate efficacy of the proposed framework by deriving closed form expressions for a few popular coupled and uncoupled memory topologies, which match simulations. Our analysis also offers analytical insights helping us estimate the impact of materials and topologies on retention time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13197v1</guid>
      <category>cs.ET</category>
      <category>cs.CE</category>
      <category>physics.app-ph</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anirudh Bangalore Shankar, Avhishek Chatterjee, Bhaswar Chakrabarti, Anjan Chakravorty</dc:creator>
    </item>
    <item>
      <title>An introduction to reservoir computing</title>
      <link>https://arxiv.org/abs/2412.13212</link>
      <description>arXiv:2412.13212v1 Announce Type: new 
Abstract: There is a growing interest in the development of artificial neural networks that are implemented in a physical system. A major challenge in this context is that these networks are difficult to train since training here would require a change of physical parameters rather than simply of coefficients in a computer program. For this reason, reservoir computing, where one employs high-dimensional recurrent networks and trains only the final layer, is widely used in this context. In this chapter, I introduce the basic concepts of reservoir computing. Moreover, I present some important physical implementations coming from electronics, photonics, spintronics, mechanics, and biology. Finally, I provide a brief discussion of quantum reservoir computing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13212v1</guid>
      <category>cs.ET</category>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.mtrl-sci</category>
      <category>cs.AI</category>
      <category>physics.app-ph</category>
      <category>quant-ph</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael te Vrugt</dc:creator>
    </item>
    <item>
      <title>Robust UAV Jittering and Task Scheduling in Mobile Edge Computing with Data Compression</title>
      <link>https://arxiv.org/abs/2412.13676</link>
      <description>arXiv:2412.13676v1 Announce Type: new 
Abstract: Data compression technology is able to reduce data size, which can be applied to lower the cost of task offloading in mobile edge computing (MEC). This paper addresses the practical challenges for robust trajectory and scheduling optimization based on data compression in the unmanned aerial vehicle (UAV)-assisted MEC, aiming to minimize the sum energy cost of terminal users while maintaining robust performance during UAV flight. Considering the non-convexity of the problem and the dynamic nature of the scenario, the optimization problem is reformulated as a Markov decision process. Then, a randomized ensembled double Q-learning (REDQ) algorithm is adopted to solve the issue. The algorithm allows for higher feasible update-to-data ratio, enabling more effective learning from observed data. The simulation results show that the proposed scheme effectively reduces the energy consumption while ensuring flight robustness. Compared to the PPO and A2C algorithms, energy consumption is reduced by approximately $21.9\%$ and $35.4\%$, respectively. This method demonstrates significant advantages in complex environments and holds great potential for practical applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13676v1</guid>
      <category>cs.ET</category>
      <category>eess.SP</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bin Li, Xiao Zhu, Junyi Wang</dc:creator>
    </item>
    <item>
      <title>SafeDrive: Knowledge- and Data-Driven Risk-Sensitive Decision-Making for Autonomous Vehicles with Large Language Models</title>
      <link>https://arxiv.org/abs/2412.13238</link>
      <description>arXiv:2412.13238v1 Announce Type: cross 
Abstract: Recent advancements in autonomous vehicles (AVs) use Large Language Models (LLMs) to perform well in normal driving scenarios. However, ensuring safety in dynamic, high-risk environments and managing safety-critical long-tail events remain significant challenges. To address these issues, we propose SafeDrive, a knowledge- and data-driven risk-sensitive decision-making framework to enhance AV safety and adaptability. The proposed framework introduces a modular system comprising: (1) a Risk Module for quantifying multi-factor coupled risks involving driver, vehicle, and road interactions; (2) a Memory Module for storing and retrieving typical scenarios to improve adaptability; (3) a LLM-powered Reasoning Module for context-aware safety decision-making; and (4) a Reflection Module for refining decisions through iterative learning. By integrating knowledge-driven insights with adaptive learning mechanisms, the framework ensures robust decision-making under uncertain conditions. Extensive evaluations on real-world traffic datasets, including highways (HighD), intersections (InD), and roundabouts (RounD), validate the framework's ability to enhance decision-making safety (achieving a 100% safety rate), replicate human-like driving behaviors (with decision alignment exceeding 85%), and adapt effectively to unpredictable scenarios. SafeDrive establishes a novel paradigm for integrating knowledge- and data-driven methods, highlighting significant potential to improve safety and adaptability of autonomous driving in high-risk traffic scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13238v1</guid>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.RO</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhiyuan Zhou, Heye Huang, Boqi Li, Shiyue Zhao, Yao Mu</dc:creator>
    </item>
    <item>
      <title>PreMixer: MLP-Based Pre-training Enhanced MLP-Mixers for Large-scale Traffic Forecasting</title>
      <link>https://arxiv.org/abs/2412.13607</link>
      <description>arXiv:2412.13607v1 Announce Type: cross 
Abstract: In urban computing, precise and swift forecasting of multivariate time series data from traffic networks is crucial. This data incorporates additional spatial contexts such as sensor placements and road network layouts, and exhibits complex temporal patterns that amplify challenges for predictive learning in traffic management, smart mobility demand, and urban planning. Consequently, there is an increasing need to forecast traffic flow across broader geographic regions and for higher temporal coverage. However, current research encounters limitations because of the inherent inefficiency of model and their unsuitability for large-scale traffic network applications due to model complexity. This paper proposes a novel framework, named PreMixer, designed to bridge this gap. It features a predictive model and a pre-training mechanism, both based on the principles of Multi-Layer Perceptrons (MLP). The PreMixer comprehensively consider temporal dependencies of traffic patterns in different time windows and processes the spatial dynamics as well. Additionally, we integrate spatio-temporal positional encoding to manage spatiotemporal heterogeneity without relying on predefined graphs. Furthermore, our innovative pre-training model uses a simple patch-wise MLP to conduct masked time series modeling, learning from long-term historical data segmented into patches to generate enriched contextual representations. This approach enhances the downstream forecasting model without incurring significant time consumption or computational resource demands owing to improved learning efficiency and data handling flexibility. Our framework achieves comparable state-of-the-art performance while maintaining high computational efficiency, as verified by extensive experiments on large-scale traffic datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13607v1</guid>
      <category>cs.LG</category>
      <category>cs.ET</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tongtong Zhang, Zhiyong Cui, Bingzhang Wang, Yilong Ren, Haiyang Yu, Pan Deng, Yinhai Wang</dc:creator>
    </item>
    <item>
      <title>Towards an identity management solution on Arweave</title>
      <link>https://arxiv.org/abs/2412.13865</link>
      <description>arXiv:2412.13865v1 Announce Type: cross 
Abstract: Traditional identity management systems, often centralized, face challenges around privacy, data security, and user control, leaving users vulnerable to data breaches and misuse. This paper explores the potential of using the Arweave network to develop an identity management solution. By harnessing Arweave's permanent storage, our solution offers the users a Self-Sovereign Identity (SSI) framework, that uses Decentralized Identifiers (DIDs) and Verifiable Credentials (VCs) to allow individuals and other entities to create, own, and manage their digital identities. Further, the solution integrates privacy-preserving technologies, including zero-knowledge proofs and the BBS(+) signature scheme, enabling selective disclosure. This approach ultimately enhances user privacy and supports compliance with European Union legislation and regulatory standards like the General Data Protection Regulation (GDPR) by design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13865v1</guid>
      <category>cs.CR</category>
      <category>cs.ET</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andreea Elena Dragnoiu, Ruxandra F. Olimid</dc:creator>
    </item>
    <item>
      <title>A Review of the Duality of Adversarial Learning in Network Intrusion: Attacks and Countermeasures</title>
      <link>https://arxiv.org/abs/2412.13880</link>
      <description>arXiv:2412.13880v1 Announce Type: cross 
Abstract: Deep learning solutions are instrumental in cybersecurity, harnessing their ability to analyze vast datasets, identify complex patterns, and detect anomalies. However, malevolent actors can exploit these capabilities to orchestrate sophisticated attacks, posing significant challenges to defenders and traditional security measures. Adversarial attacks, particularly those targeting vulnerabilities in deep learning models, present a nuanced and substantial threat to cybersecurity. Our study delves into adversarial learning threats such as Data Poisoning, Test Time Evasion, and Reverse Engineering, specifically impacting Network Intrusion Detection Systems. Our research explores the intricacies and countermeasures of attacks to deepen understanding of network security challenges amidst adversarial threats. In our study, we present insights into the dynamic realm of adversarial learning and its implications for network intrusion. The intersection of adversarial attacks and defenses within network traffic data, coupled with advances in machine learning and deep learning techniques, represents a relatively underexplored domain. Our research lays the groundwork for strengthening defense mechanisms to address the potential breaches in network security and privacy posed by adversarial attacks. Through our in-depth analysis, we identify domain-specific research gaps, such as the scarcity of real-life attack data and the evaluation of AI-based solutions for network traffic. Our focus on these challenges aims to stimulate future research efforts toward the development of resilient network defense strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13880v1</guid>
      <category>cs.CR</category>
      <category>cs.ET</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shalini Saini, Anitha Chennamaneni, Babatunde Sawyerr</dc:creator>
    </item>
    <item>
      <title>Towards a Dynamic Future with Adaptable Computing and Network Convergence (ACNC)</title>
      <link>https://arxiv.org/abs/2403.07573</link>
      <description>arXiv:2403.07573v3 Announce Type: replace-cross 
Abstract: In the context of advancing 6G, a substantial paradigm shift is anticipated, highlighting comprehensive everything-to-everything interactions characterized by numerous connections and stringent adherence to Quality of Service/Experience (QoS/E) prerequisites. The imminent challenge stems from resource scarcity, prompting a deliberate transition to Computing-Network Convergence (CNC) as an auspicious approach for joint resource orchestration. While CNC-based mechanisms have garnered attention, their effectiveness in realizing future services, particularly in use cases like the Metaverse, may encounter limitations due to the continually changing nature of users, services, and resources. Hence, this paper presents the concept of Adaptable CNC (ACNC) as an autonomous Machine Learning (ML)-aided mechanism crafted for the joint orchestration of computing and network resources, catering to dynamic and voluminous user requests with stringent requirements. ACNC encompasses two primary functionalities: state recognition and context detection. Given the intricate nature of the user-service-computing-network space, the paper employs dimension reduction to generate live, holistic, abstract system states in a hierarchical structure. To address the challenges posed by dynamic changes, Continual Learning (CL) is employed, classifying the system state into contexts controlled by dedicated ML agents, enabling them to operate efficiently. These two functionalities are intricately linked within a closed loop overseen by the End-to-End (E2E) orchestrator to allocate resources. The paper introduces the components of ACNC, proposes a Metaverse scenario to exemplify ACNC's role in resource provisioning with Segment Routing v6 (SRv6), outlines ACNC's workflow, details a numerical analysis for efficiency assessment, and concludes with discussions on relevant challenges and potential avenues for future research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07573v3</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.DC</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Masoud Shokrnezhad, Hao Yu, Tarik Taleb, Richard Li, Kyunghan Lee, Jaeseung Song, Cedric Westphal</dc:creator>
    </item>
    <item>
      <title>Symbolic-AI-Fusion Deep Learning (SAIF-DL): Encoding Knowledge into Training with Answer Set Programming Loss Penalties by a Novel Loss Function Approach</title>
      <link>https://arxiv.org/abs/2411.08463</link>
      <description>arXiv:2411.08463v2 Announce Type: replace-cross 
Abstract: This paper presents a hybrid methodology that enhances the training process of deep learning (DL) models by embedding domain expert knowledge using ontologies and answer set programming (ASP). By integrating these symbolic AI methods, we encode domain-specific constraints, rules, and logical reasoning directly into the model's learning process, thereby improving both performance and trustworthiness. The proposed approach is flexible and applicable to both regression and classification tasks, demonstrating generalizability across various fields such as healthcare, autonomous systems, engineering, and battery manufacturing applications. Unlike other state-of-the-art methods, the strength of our approach lies in its scalability across different domains. The design allows for the automation of the loss function by simply updating the ASP rules, making the system highly scalable and user-friendly. This facilitates seamless adaptation to new domains without significant redesign, offering a practical solution for integrating expert knowledge into DL models in industrial settings such as battery manufacturing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08463v2</guid>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fadi Al Machot, Martin Thomas Horsch, Habib Ullah</dc:creator>
    </item>
    <item>
      <title>Building Trustworthy AI: Transparent AI Systems via Large Language Models, Ontologies, and Logical Reasoning (TranspNet)</title>
      <link>https://arxiv.org/abs/2411.08469</link>
      <description>arXiv:2411.08469v2 Announce Type: replace-cross 
Abstract: Growing concerns over the lack of transparency in AI, particularly in high-stakes fields like healthcare and finance, drive the need for explainable and trustworthy systems. While Large Language Models (LLMs) perform exceptionally well in generating accurate outputs, their "black box" nature poses significant challenges to transparency and trust. To address this, the paper proposes the TranspNet pipeline, which integrates symbolic AI with LLMs. By leveraging domain expert knowledge, retrieval-augmented generation (RAG), and formal reasoning frameworks like Answer Set Programming (ASP), TranspNet enhances LLM outputs with structured reasoning and verification.This approach strives to help AI systems deliver results that are as accurate, explainable, and trustworthy as possible, aligning with regulatory expectations for transparency and accountability. TranspNet provides a solution for developing AI systems that are reliable and interpretable, making it suitable for real-world applications where trust is critical.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08469v2</guid>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fadi Al Machot, Martin Thomas Horsch, Habib Ullah</dc:creator>
    </item>
    <item>
      <title>Hardware Accelerators for Artificial Intelligence</title>
      <link>https://arxiv.org/abs/2411.13717</link>
      <description>arXiv:2411.13717v2 Announce Type: replace-cross 
Abstract: In this chapter, we aim to explore an in-depth exploration of the specialized hardware accelerators designed to enhance Artificial Intelligence (AI) applications, focusing on their necessity, development, and impact on the field of AI. It covers the transition from traditional computing systems to advanced AI-specific hardware, addressing the growing demands of AI algorithms and the inefficiencies of conventional architectures. The discussion extends to various types of accelerators, including GPUs, FPGAs, and ASICs, and their roles in optimizing AI workloads. Additionally, it touches on the challenges and considerations in designing and implementing these accelerators, along with future prospects in the evolution of AI hardware. This comprehensive overview aims to equip readers with a clear understanding of the current landscape and future directions in AI hardware development, making it accessible to both experts and newcomers to the field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.13717v2</guid>
      <category>cs.AR</category>
      <category>cs.ET</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>S M Mojahidul Ahsan, Anurag Dhungel, Mrittika Chowdhury, Md Sakib Hasan, Tamzidul Hoque</dc:creator>
    </item>
  </channel>
</rss>
