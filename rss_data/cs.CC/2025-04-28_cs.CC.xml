<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CC</link>
    <description>cs.CC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 29 Apr 2025 04:00:04 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Worst-Case and Average-Case Hardness of Hypercycle and Database Problems</title>
      <link>https://arxiv.org/abs/2504.18640</link>
      <description>arXiv:2504.18640v1 Announce Type: new 
Abstract: In this paper we present tight lower-bounds and new upper-bounds for hypergraph and database problems. We give tight lower-bounds for finding minimum hypercycles. We give tight lower-bounds for a substantial regime of unweighted hypercycle. We also give a new faster algorithm for longer unweighted hypercycles. We give a worst-case to average-case reduction from detecting a subgraph of a hypergraph in the worst-case to counting subgraphs of hypergraphs in the average-case. We demonstrate two applications of this worst-case to average-case reduction, which result in average-case lower bounds for counting hypercycles in random hypergraphs and queries in average-case databases. Our tight upper and lower bounds for hypercycle detection in the worst-case have immediate implications for the average-case via our worst-case to average-case reductions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.18640v1</guid>
      <category>cs.CC</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Cheng-Hao Fu, Andrea Lincoln, Rene Reyes</dc:creator>
    </item>
    <item>
      <title>MODP: Multi Objective Directional Prompting</title>
      <link>https://arxiv.org/abs/2504.18722</link>
      <description>arXiv:2504.18722v1 Announce Type: new 
Abstract: Recent advances in large language models (LLMs) have led to their popularity across multiple use-cases. However, prompt engineering, the process for optimally utilizing such models, remains approximation-driven and subjective. Most of the current research on prompt engineering focuses on task-specific optimization, while neglecting the behavior of the LLM under consideration during prompt development. This paper introduces MODP -- Multi Objective Directional Prompting, a framework based on two key concepts: 1) multi-objectivity: the importance of considering an LLM's intrinsic behavior as an additional objective in prompt development, and 2) directional prompting: a metrics-driven method for prompt engineering to ensure development of robust and high-precision prompts. We demonstrate the effectiveness of our proposed ideas on a summarization task, using a synthetically created dataset, achieving a 26% performance gain over initial prompts. Finally, we apply MODP to develop prompts for Dell's Next Best Action support tool, which is now in production and is used by more than 10,000 internal support agents and serving millions of customers worldwide.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.18722v1</guid>
      <category>cs.CC</category>
      <category>cs.AI</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aashutosh Nema, Samaksh Gulati, Evangelos Giakoumakis, Bipana Thapaliya</dc:creator>
    </item>
    <item>
      <title>Hardness of Finding Kings and Strong Kings</title>
      <link>https://arxiv.org/abs/2504.19386</link>
      <description>arXiv:2504.19386v1 Announce Type: new 
Abstract: A king in a directed graph is a vertex $v$ such that every other vertex is reachable from $v$ via a path of length at most $2$. It is well known that every tournament (a complete graph where each edge has a direction) has at least one king. Our contributions in this work are:
  - We show that the query complexity of determining existence of a king in arbitrary $n$-vertex digraphs is $\Theta(n^2)$. This is in stark contrast to the case where the input is a tournament, where Shen, Sheng, and Wu [SICOMP'03] showed that a king can be found in $O(n^{3/2})$ queries.
  - In an attempt to increase the "fairness" in the definition of tournament winners, Ho and Chang [IPL'03] defined a strong king to be a king $k$ such that, for every $v$ that dominates $k$, the number of length-$2$ paths from $k$ to $v$ is strictly larger than the number of length-$2$ paths from $v$ to $k$. We show that the query complexity of finding a strong king in a tournament is $\Theta(n^2)$. This answers a question of Biswas, Jayapaul, Raman, and Satti [DAM'22] in the negative.
  A key component in our proofs is the design of specific tournaments where every vertex is a king, and analyzing certain properties of these tournaments. We feel these constructions and properties are independently interesting and may lead to more interesting results about tournament solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19386v1</guid>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>math.CO</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ziad Ismaili Alaoui, Nikhil S. Mande</dc:creator>
    </item>
    <item>
      <title>On the Complexity of Identifying Groups without Abelian Normal Subgroups: Parallel, First Order, and GI-Hardness</title>
      <link>https://arxiv.org/abs/2504.19777</link>
      <description>arXiv:2504.19777v1 Announce Type: new 
Abstract: In this paper, we exhibit an $\textsf{AC}^{3}$ isomorphism test for groups without Abelian normal subgroups (a.k.a. Fitting-free groups), a class for which isomorphism testing was previously known to be in $\mathsf{P}$ (Babai, Codenotti, and Qiao; ICALP '12). Here, we leverage the fact that $G/\text{PKer}(G)$ can be viewed as permutation group of degree $O(\log |G|)$. As $G$ is given by its multiplication table, we are able to implement the solution for the corresponding instance of Twisted Code Equivalence in $\textsf{AC}^{3}$.
  In sharp contrast, we show that when our groups are specified by a generating set of permutations, isomorphism testing of Fitting-free groups is at least as hard as Graph Isomorphism and Linear Code Equivalence (the latter being $\textsf{GI}$-hard and having no known subexponential-time algorithm).
  Lastly, we show that any Fitting-free group of order $n$ is identified by $\textsf{FO}$ formulas (without counting) using only $O(\log \log n)$ variables. This is in contrast to the fact that there are infinite families of Abelian groups that are not identified by $\textsf{FO}$ formulas with $o(\log n)$ variables (Grochow &amp; Levet, FCT '23).</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19777v1</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>cs.LO</category>
      <category>math.GR</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joshua A. Grochow, Dan Johnson, Michael Levet</dc:creator>
    </item>
    <item>
      <title>Probabilistic and Causal Satisfiability: Constraining the Model</title>
      <link>https://arxiv.org/abs/2504.19944</link>
      <description>arXiv:2504.19944v1 Announce Type: new 
Abstract: We study the complexity of satisfiability problems in probabilistic and causal reasoning. Given random variables $X_1, X_2,\ldots$ over finite domains, the basic terms are probabilities of propositional formulas over atomic events $X_i = x_i$, such as $P(X_1 = x_1)$ or $P(X_1 = x_1 \vee X_2 = x_2)$. The basic terms can be combined using addition (yielding linear terms) or multiplication (polynomial terms). The probabilistic satisfiability problem asks whether a joint probability distribution satisfies a Boolean combination of (in)equalities over such terms. Fagin et al. (1990) showed that for basic and linear terms, this problem is NP-complete, making it no harder than Boolean satisfiability, while Moss\'e et al. (2022) proved that for polynomial terms, it is complete for the existential theory of the reals.
  Pearl's Causal Hierarchy (PCH) extends the probabilistic setting with interventional and counterfactual reasoning, enriching the expressiveness of languages. However, Moss\'e et al. (2022) found that satisfiability complexity remains unchanged. Van der Zander et al. (2023) showed that introducing a marginalization operator to languages induces a significant increase in complexity.
  We extend this line of work by adding two new dimensions to the problem by constraining the models. First, we fix the graph structure of the underlying structural causal model, motivated by settings like Pearl's do-calculus, and give a nearly complete landscape across different arithmetics and PCH levels. Second, we study small models. While earlier work showed that satisfiable instances admit polynomial-size models, this is no longer guaranteed with compact marginalization. We characterize the complexities of satisfiability under small-model constraints across different settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19944v1</guid>
      <category>cs.CC</category>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Markus Bl\"aser, Julian D\"orfler, Maciej Li\'skiewicz, Benito van der Zander</dc:creator>
    </item>
    <item>
      <title>The Trichotomy of Regular Property Testing</title>
      <link>https://arxiv.org/abs/2504.19152</link>
      <description>arXiv:2504.19152v1 Announce Type: cross 
Abstract: Property testing is concerned with the design of algorithms making a sublinear number of queries to distinguish whether the input satisfies a given property or is far from having this property. A seminal paper of Alon, Krivelevich, Newman, and Szegedy in 2001 introduced property testing of formal languages: the goal is to determine whether an input word belongs to a given language, or is far from any word in that language. They constructed the first property testing algorithm for the class of all regular languages. This opened a line of work with improved complexity results and applications to streaming algorithms. In this work, we show a trichotomy result: the class of regular languages can be divided into three classes, each associated with an optimal query complexity. Our analysis yields effective characterizations for all three classes using so-called minimal blocking sequences, reasoning directly and combinatorially on automata.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19152v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gabriel Bathie, Nathana\"el Fijalkow, Corto Mascle</dc:creator>
    </item>
    <item>
      <title>Learning High-dimensional Gaussians from Censored Data</title>
      <link>https://arxiv.org/abs/2504.19446</link>
      <description>arXiv:2504.19446v1 Announce Type: cross 
Abstract: We provide efficient algorithms for the problem of distribution learning from high-dimensional Gaussian data where in each sample, some of the variable values are missing. We suppose that the variables are missing not at random (MNAR). The missingness model, denoted by $S(y)$, is the function that maps any point $y$ in $R^d$ to the subsets of its coordinates that are seen. In this work, we assume that it is known. We study the following two settings:
  (i) Self-censoring: An observation $x$ is generated by first sampling the true value $y$ from a $d$-dimensional Gaussian $N(\mu*, \Sigma*)$ with unknown $\mu*$ and $\Sigma*$. For each coordinate $i$, there exists a set $S_i$ subseteq $R^d$ such that $x_i = y_i$ if and only if $y_i$ in $S_i$. Otherwise, $x_i$ is missing and takes a generic value (e.g., "?"). We design an algorithm that learns $N(\mu*, \Sigma*)$ up to total variation (TV) distance epsilon, using $poly(d, 1/\epsilon)$ samples, assuming only that each pair of coordinates is observed with sufficiently high probability.
  (ii) Linear thresholding: An observation $x$ is generated by first sampling $y$ from a $d$-dimensional Gaussian $N(\mu*, \Sigma)$ with unknown $\mu*$ and known $\Sigma$, and then applying the missingness model $S$ where $S(y) = {i in [d] : v_i^T y &lt;= b_i}$ for some $v_1, ..., v_d$ in $R^d$ and $b_1, ..., b_d$ in $R$. We design an efficient mean estimation algorithm, assuming that none of the possible missingness patterns is very rare conditioned on the values of the observed coordinates and that any small subset of coordinates is observed with sufficiently high probability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19446v1</guid>
      <category>cs.LG</category>
      <category>cs.CC</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arnab Bhattacharyya, Constantinos Daskalakis, Themis Gouleakis, Yuhao Wang</dc:creator>
    </item>
    <item>
      <title>A Cautionary Note on Quantum Oracles</title>
      <link>https://arxiv.org/abs/2504.19470</link>
      <description>arXiv:2504.19470v1 Announce Type: cross 
Abstract: In recent years, the quantum oracle model introduced by Aaronson and Kuperberg (2007) has found a lot of use in showing oracle separations between complexity classes and cryptographic primitives. It is generally assumed that proof techniques that do not relativize with respect to quantum oracles will also not relativize with respect to classical oracles. In this note, we show that this is not the case: specifically, we show that there is a quantum oracle problem that is contained in the class QMA, but not in a class we call polyQCPH. The class polyQCPH is equal to PSPACE with respect to classical oracles, and it is a well-known result that QMA is contained in PSPACE (also with respect to classical oracles).
  We also show that the same separation holds relative to a distributional oracle, which is a model introduced by Natarajan and Nirkhe (2024). We believe our findings show the need for some caution when using these non-standard oracle models, particularly when showing separations between quantum and classical resources.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19470v1</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Avantika Agarwal, Srijita Kundu</dc:creator>
    </item>
    <item>
      <title>Quantum circuit lower bounds in the magic hierarchy</title>
      <link>https://arxiv.org/abs/2504.19966</link>
      <description>arXiv:2504.19966v1 Announce Type: cross 
Abstract: We introduce the magic hierarchy, a quantum circuit model that alternates between arbitrary-sized Clifford circuits and constant-depth circuits with two-qubit gates ($\textsf{QNC}^0$). This model unifies existing circuit models, such as $\textsf{QAC}^0_f$ and models with adaptive intermediate measurements. Despite its generality, we are able to prove nontrivial lower bounds.
  We prove new lower bounds in the first level of the hierarchy, showing that certain explicit quantum states cannot be approximately prepared by circuits consisting of a Clifford circuit followed by $\textsf{QNC}^0$. These states include ground states of some topologically ordered Hamiltonians and nonstabilizer quantum codes. Our techniques exploit the rigid structure of stabilizer codes and introduce an infectiousness property: if even a single state in a high distance code can be approximately prepared by one of these circuits, then the entire subspace must lie close to a perturbed stabilizer code. We also show that proving state preparation lower bounds beyond a certain level of the hierarchy would imply classical circuit lower bounds beyond the reach of current techniques in complexity theory.
  More broadly, our techniques go beyond lightcone-based methods and highlight how the magic hierarchy provides a natural framework for connecting circuit complexity, condensed matter, and Hamiltonian complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19966v1</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Natalie Parham</dc:creator>
    </item>
    <item>
      <title>Complexity and algorithms for Swap median and relation to other consensus problems</title>
      <link>https://arxiv.org/abs/2409.09734</link>
      <description>arXiv:2409.09734v2 Announce Type: replace 
Abstract: Genome rearrangements are events in which large blocks of DNA exchange pieces during evolution. The analysis of such events is a tool for understanding evolutionary genomics, based on finding the minimum number of rearrangements to transform one genome into another, which can be modeled as permutations of integers. In a general scenario, more than two genomes are considered, and new challenges arise. Given three input permutations, the Median problem consists of finding a permutation s that minimizes the sum of the distances between s and each of the three input permutations, according to a specified distance measure. We prove that Median problem over swap distances is NP-complete, a problem whose computational complexity has remained unsolved for nearly 20 years (Eriksen, Theor. Comput. Sci., 2007).
  To tackle this problem, we introduce a graph-based perspective by the class called 2-circles-intersection graphs. We show that for each 2-circles-intersection graph G, we can associate three permutations such that G has a large independent set iff the median of the three associated permutations reaches a specific lower bound. We then prove that maximum independent set is NP-complete in this graph class. By this approach, we also establish that the Closest problem which aims to minimize the maximum distance between the solution and the input permutations is NP-complete even with three input permutations.
  This last result closes the complexity gap in the dichotomy between P and NP-complete cases: with two input permutations, the problem is easily solvable, while for an arbitrary number of input permutations, the Closest problem was known to be NP-hard since 2007 (Popov, Theor. Comput. Sci., 2007). Additionally, we show that both the Swap Median and Swap Closest problems are APX-hard, further emphasizing the computational complexity of these genome-related problems through graph theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.09734v2</guid>
      <category>cs.CC</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lu\'is Cunha, Thiago Lopes, Arnaud Mary</dc:creator>
    </item>
    <item>
      <title>Low degree conjecture implies sharp computational thresholds in stochastic block model</title>
      <link>https://arxiv.org/abs/2502.15024</link>
      <description>arXiv:2502.15024v2 Announce Type: replace 
Abstract: We investigate implications of the (extended) low-degree conjecture (recently formalized in [MW23]) in the context of the symmetric stochastic block model. Assuming the conjecture holds, we establish that no polynomial-time algorithm can weakly recover community labels below the Kesten-Stigum (KS) threshold. In particular, we rule out polynomial-time estimators that, with constant probability, achieve correlation with the true communities that is significantly better than random. Whereas, above the KS threshold, polynomial-time algorithms are known to achieve constant correlation with the true communities with high probability[Mas14,AS15].
  To our knowledge, we provide the first rigorous evidence for the sharp transition in recovery rate for polynomial-time algorithms at the KS threshold. Notably, under a stronger version of the low-degree conjecture, our lower bound remains valid even when the number of blocks diverges. Furthermore, our results provide evidence of a computational-to-statistical gap in learning the parameters of stochastic block models.
  In contrast to prior work, which either (i) rules out polynomial-time algorithms for hypothesis testing with 1-o(1) success probability [Hopkins18, BBK+21a] under the low-degree conjecture, or (ii) rules out low-degree polynomials for learning the edge connection probability matrix [LG23], our approach provides stronger lower bounds on the recovery and learning problem.
  Our proof combines low-degree lower bounds from [Hopkins18, BBK+21a] with graph splitting and cross-validation techniques. In order to rule out general recovery algorithms, we employ the correlation preserving projection method developed in [HS17].</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.15024v2</guid>
      <category>cs.CC</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.TH</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jingqiu Ding, Yiding Hua, Lucas Slot, David Steurer</dc:creator>
    </item>
    <item>
      <title>The Cheeger Inequality and Coboundary Expansion: Beyond Constant Coefficients</title>
      <link>https://arxiv.org/abs/2208.01776</link>
      <description>arXiv:2208.01776v3 Announce Type: replace-cross 
Abstract: The Cheeger constant of a graph, or equivalently its coboundary expansion, quantifies the expansion of the graph. This notion assumes an implicit choice of a coefficient group, namely, $\mathbb{F}_2$. In this paper, we study Cheeger-type inequalities for graphs endowed with a generalized coefficient group, called a sheaf; this is motivated by applications to cosystolic expansion and locally testable codes. We prove that a graph is a good spectral expander if and only if it has good coboundary expansion relative to any (resp. some) constant sheaf, or equivalently, relative to any `ordinary' coefficient group. We moreover show that sheaves that are close to being constant in a well-defined sense are also good coboundary expanders, provided that their underlying graph is an expander, thus giving the first example of good coboundary expansion in non-cosntant sheaves on sparse graphs. By contrast, we observe that for general sheaves on graphs, it is impossible to relate the expansion of the graph and the coboundary expansion of the sheaf.
  We specialize our results to sheaves on (finite) spherical buildings. Specifically, we show that the normalized second eigenvalue of the (weighted) graph underlying a $q$-thick $d$-dimensional spherical building is $O(\frac{1}{\sqrt{q}-3d})$ if $q&gt;9d^2$. Plugging this into our results about coboundary expansion gives explicit lower bounds on the coboundary expansion of some constant and non-constant sheaves on spherical buildings; for a fixed dimension $d$, the bounds approach a constant as the thickness $q$ grows.
  Along the way, we prove a new version of the Expander Mixing Lemma for $r$-partite weighted graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.01776v3</guid>
      <category>math.CO</category>
      <category>cs.CC</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Uriya A. First, Tali Kaufman</dc:creator>
    </item>
    <item>
      <title>Noise-tolerant learnability of shallow quantum circuits from statistics and the cost of quantum pseudorandomness</title>
      <link>https://arxiv.org/abs/2405.12085</link>
      <description>arXiv:2405.12085v3 Announce Type: replace-cross 
Abstract: In this work, we study the learnability of quantum circuits in the near term. We demonstrate the natural robustness of quantum statistical queries for learning quantum processes, motivating their use as a theoretical tool for near-term learning problems. We adapt a learning algorithm for constant-depth quantum circuits to the quantum statistical query setting, and show that such circuits can be learned in our setting with only a linear overhead in the query complexity. We prove average-case quantum statistical query lower bounds for learning, within diamond distance, random quantum circuits with depth at least logarithmic and at most linear in the system size. Finally, we prove that pseudorandom unitaries (PRUs) cannot be constructed using circuits of constant depth by constructing an efficient distinguisher using existing learning algorithms. To show the correctness of our distinguisher, we prove a new variation of the quantum no free lunch theorem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12085v3</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.CR</category>
      <category>cs.LG</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chirag Wadhwa, Mina Doosti</dc:creator>
    </item>
    <item>
      <title>Improved Decoding of Tanner Codes</title>
      <link>https://arxiv.org/abs/2501.12293</link>
      <description>arXiv:2501.12293v3 Announce Type: replace-cross 
Abstract: In this paper, we present improved decoding algorithms for expander-based Tanner codes.
  We begin by developing a randomized linear-time decoding algorithm that, under the condition that $ \delta d_0 &gt; 2 $, corrects up to $ \alpha n $ errors for a Tanner code $ T(G, C_0) $, where $ G $ is a $ (c, d, \alpha, \delta) $-bipartite expander with $n$ left vertices, and $ C_0 \subseteq \mathbb{F}_2^d $ is a linear inner code with minimum distance $ d_0 $. This result improves upon the previous work of Cheng, Ouyang, Shangguan, and Shen (RANDOM 2024), which required $ \delta d_0 &gt; 3 $.
  We further derandomize the algorithm to obtain a deterministic linear-time decoding algorithm with the same decoding radius. Our algorithm improves upon the previous deterministic algorithm of Cheng et al. by achieving a decoding radius of $ \alpha n $, compared with the previous radius of $ \frac{2\alpha}{d_0(1 + 0.5c\delta) }n$.
  Additionally, we investigate the size-expansion trade-off introduced by the recent work of Chen, Cheng, Li, and Ouyang (IEEE TIT 2023), and use it to provide new bounds on the minimum distance of Tanner codes. Specifically, we prove that the minimum distance of a Tanner code $T(G,C_0)$ is approximately $f_\delta^{-1} \left( \frac{1}{d_0} \right) \alpha n $, where $ f_\delta(\cdot) $ is the Size-Expansion Function. As another application, we improve the decoding radius of our decoding algorithms from $\alpha n$ to approximately $f_\delta^{-1}\left(\frac{2}{d_0}\right)\alpha n$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12293v3</guid>
      <category>cs.IT</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>math.IT</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhaienhe Zhou, Zeyu Guo</dc:creator>
    </item>
    <item>
      <title>Complexity of Minimal Faithful Permutation Degree for Fitting-free Groups</title>
      <link>https://arxiv.org/abs/2501.16039</link>
      <description>arXiv:2501.16039v3 Announce Type: replace-cross 
Abstract: In this paper, we investigate the complexity of computing the minimal faithful permutation degree for groups without abelian normal subgroups. When our groups are given as quotients of permutation groups, we establish that this problem is in $\textsf{P}$. Furthermore, in the setting of permutation groups, we obtain an upper bound of $\textsf{NC}$ for this problem. This improves upon the work of Das and Thakkar (STOC 2024), who established a Las Vegas polynomial-time algorithm for this class in the setting of permutation groups.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.16039v3</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>math.GR</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Levet, Pranjal Srivastava, Dhara Thakkar</dc:creator>
    </item>
  </channel>
</rss>
