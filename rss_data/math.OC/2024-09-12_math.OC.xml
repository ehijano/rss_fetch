<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 13 Sep 2024 01:41:30 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 12 Sep 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Fourier series-based algorithm for control optimization in pendulum capsule drive: an integrated computational and experimental study</title>
      <link>https://arxiv.org/abs/2409.06824</link>
      <description>arXiv:2409.06824v1 Announce Type: new 
Abstract: Pendulum-driven systems have emerged as a notable modification of vibro-impact mechanisms, replacing the conventional mass-on-spring oscillator with a pendulum. Such systems exhibit intricate behavior resulting from the interplay of directional dynamics, pendulum motion, and contact forces between the designed device and the underlying surface. This paper delves into the application of a Fourier series-based greedy algorithm for control optimization in pendulum capsule drives, which hold potential for diverse scenarios, including endoscopy capsule robots, pipeline inspection, and rescue operations in confined spaces. The emphasis is placed on experimental studies involving prototype development to validate the system's efficacy with previous computational simulations. Empirical findings closely align (&lt;2% loss) with numerical investigations, showcasing the pendulum capsule drive's ability to achieve average speeds of 2.48 cm/s and 2.58 cm/s for three and six harmonics, respectively. These results are reinforced by high-quality signal-tracking accuracy, which demonstrates resilience against potential disturbances during motion. The authors envision the Fourier series-based control optimization method as a significant step towards ensuring enhanced locomotion performance in discontinuous systems, effectively handling the non-linearities arising from dry friction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06824v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 12 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Sandra Zarychta, Marek Balcerzak, Katarzyna Wojdalska, Rafa{\l} Dolny, Jerzy Wojewoda</dc:creator>
    </item>
    <item>
      <title>Contextual Stochastic Optimization for Omnichannel Multi-Courier Order Fulfillment Under Delivery Time Uncertainty</title>
      <link>https://arxiv.org/abs/2409.06918</link>
      <description>arXiv:2409.06918v1 Announce Type: new 
Abstract: The paper studies a large-scale order fulfillment problem for a leading e-commerce company in the United States. The challenge involves selecting fulfillment centers and shipping carriers with observational data only to efficiently process orders from a vast network of physical stores and warehouses. The company's current practice relies on heuristic rules that choose the cheapest fulfillment and shipping options for each unit, without considering opportunities for batching items or the reliability of carriers in meeting expected delivery dates. The paper develops a data-driven Contextual Stochastic Optimization (CSO) framework that integrates distributional forecasts of delivery time deviations with stochastic and robust order fulfillment optimization models. The framework optimizes the selection of fulfillment centers and carriers, accounting for item consolidation and delivery time uncertainty. Validated on a real-world data set containing tens of thousands of products, each with hundreds of fulfillment options, the proposed CSO framework significantly enhances the accuracy of meeting customer-expected delivery dates compared to current practices. It provides a flexible balance between reducing fulfillment costs and managing delivery time deviation risks, emphasizing the importance of contextual information and distributional forecasts in order fulfillment. This is the first paper that studies the omnichannel multi-courier order fulfillment problem with delivery time uncertainty through the lens of contextual optimization, fusing machine learning and optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06918v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 12 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tinghan Ye, Sikai Cheng, Amira Hijazi, Pascal Van Hentenryck</dc:creator>
    </item>
    <item>
      <title>Flexible block-iterative analysis for the Frank-Wolfe algorithm</title>
      <link>https://arxiv.org/abs/2409.06931</link>
      <description>arXiv:2409.06931v1 Announce Type: new 
Abstract: We prove that the block-coordinate Frank-Wolfe (BCFW) algorithm converges with state-of-the-art rates in both convex and nonconvex settings under a very mild "block-iterative" assumption, newly allowing for (I) progress without activating the most-expensive linear minimization oracle(s), LMO(s), at every iteration, (II) parallelized updates that do not require all LMOs, and therefore (III) deterministic parallel update strategies that take into account the numerical cost of the problem's LMOs. Our results apply for short-step BCFW as well as an adaptive method for convex functions. New relationships between updated coordinates and primal progress are proven, and a favorable speedup is demonstrated using FrankWolfe.jl.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06931v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 12 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>G\'abor Braun, Sebastian Pokutta, Zev Woodstock</dc:creator>
    </item>
    <item>
      <title>Two Decentralized Conjugate Gradient Methods with Global Convergence</title>
      <link>https://arxiv.org/abs/2409.07122</link>
      <description>arXiv:2409.07122v1 Announce Type: new 
Abstract: This paper considers the decentralized optimization problem of minimizing a finite sum of continuously differentiable functions over a fixed-connected undirected network. Summarizing the lack of previously developed decentralized conjugate gradient methods, we propose two decentralized conjugate gradient method, called NDCG and DMBFGS respectively. Firstly, the best of our knowledge, NDCG is the first decentralized conjugate gradient method to be shown to have global convergence with constant stepsizes for general nonconvex optimization problems, which profits from our designed conjugate parameter and relies only on the same mild conditions as the centralized conjugate gradient method. Secondly, we apply the memoryless BFGS technique and develop the DMBFGS method. It requires only vector-vector products to capture the curvature information of Hessian matrices. Under proper choice of stepsizes, DMBFGS has global linear convergence for solving strongly convex decentralized optimization problems. Our numerical results show DMBFGS is very efficient compared with other state-of-the-art methods for solving decentralized optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.07122v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 12 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liping Wang, Hao Wu, Hongchao Zhang</dc:creator>
    </item>
    <item>
      <title>A feedback control approach to convex optimization with inequality constraints</title>
      <link>https://arxiv.org/abs/2409.07168</link>
      <description>arXiv:2409.07168v1 Announce Type: new 
Abstract: We propose a novel continuous-time algorithm for inequality-constrained convex optimization inspired by proportional-integral control. Unlike the popular primal-dual gradient dynamics, our method includes a proportional term to control the primal variable through the Lagrange multipliers. This approach has both theoretical and practical advantages. On the one hand, it simplifies the proof of the exponential convergence in the case of smooth, strongly convex problems, with a more straightforward assessment of the convergence rate concerning prior literature. On the other hand, through several examples, we show that the proposed algorithm converges faster than primal-dual gradient dynamics. This paper aims to illustrate these points by thoroughly analyzing the algorithm convergence and discussing some numerical simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.07168v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 12 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>V. Cerone, S. M. Fosson, S. Pirrera, D. Regruto</dc:creator>
    </item>
    <item>
      <title>A note on the failure of the Faber-Krahn inequality for the vector Laplacian</title>
      <link>https://arxiv.org/abs/2409.07206</link>
      <description>arXiv:2409.07206v1 Announce Type: new 
Abstract: We consider a natural eigenvalue problem for the vector Laplacian related to stationary Maxwell's equations in a cavity and we prove that an analog of the celebrated Faber-Krahn inequality doesn't hold.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.07206v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <category>math.SP</category>
      <pubDate>Thu, 12 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David Krejcirik, Pier Domenico Lamberti, Michele Zaccaron</dc:creator>
    </item>
    <item>
      <title>Exact SDP relaxations for a class of quadratic programs with finite and infinite quadratic constraints</title>
      <link>https://arxiv.org/abs/2409.07213</link>
      <description>arXiv:2409.07213v1 Announce Type: new 
Abstract: We investigate exact semidefinite programming (SDP) relaxations for the problem of minimizing a nonconvex quadratic objective function over a feasible region defined by both finitely and infinitely many nonconvex quadratic inequality constraints (semi-infinite QCQPs). Specifically, we present two sufficient conditions on the feasible region under which the QCQP, with any quadratic objective function over the feasible region, is equivalent to its SDP relaxation. The first condition is an extension of a result recently proposed by the authors (arXiv:2308.05922, to appear in SIAM J. Optim.) from finitely constrained quadratic programs to semi-infinite QCQPs. The newly introduced second condition offers a clear geometric characterization of the feasible region for a broad class of QCQPs that are equivalent to their SDP relaxations. Several illustrative examples, including quadratic programs with ball-, parabola-, and hyperbola-based constraints, are also provided.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.07213v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 12 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Naohiko Arima, Sunyoung Kim, Masakazu Kojima</dc:creator>
    </item>
    <item>
      <title>An observability estimate for the wave equation and applications to the Neumann boundary controllability for semi-linear wave equations</title>
      <link>https://arxiv.org/abs/2409.07214</link>
      <description>arXiv:2409.07214v1 Announce Type: new 
Abstract: We give a boundary observability result for a $1$d wave equation with a potential. We then deduce with a Schauder fixed-point argument the existence of a Neumann boundary control for a semi-linear wave equation $\partial_{tt}y - \partial_{xx}y + f(y) = 0$ under an optimal growth assumption at infinity on $f$ of the type $s\ln^2s$. Moreover, assuming additional assumption on $f'$, we construct a minimizing sequence which converges to a control. Numerical experiments illustrate the results. This work extends to the Neumann boundary control case the work of Zuazua in $1993$ and the work of M\"unch and Tr\'elat in $2022$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.07214v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Thu, 12 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sue Claret</dc:creator>
    </item>
    <item>
      <title>On time-inconsistent extended mean-field control problems with common noise</title>
      <link>https://arxiv.org/abs/2409.07219</link>
      <description>arXiv:2409.07219v1 Announce Type: new 
Abstract: This paper addresses a class of time-inconsistent mean field control (MFC) problems in the presence of common noise under non-exponential discount, where the coefficients of the McKean-Vlasov dynamics depend on the conditional joint distribution of the state and control. We investigate the closed-loop time-consistent equilibrium strategies for these extended MFC problems and provide a sufficient and necessary condition for their characterization. Furthermore, we derive a master equation system that provides an equivalent characterization of our problem. We then apply these results to the time-inconsistent linear quadratic (LQ) MFC problems, characterizing the equilibrium strategies in terms of the solution to a non-local Riccati system. To illustrate these findings, two financial applications are presented. Finally, a non-LQ example is also discussed in which the closed-loop equilibrium strategy can be explicitly characterized and verified.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.07219v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 12 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zongxia Liang, Xiang Yu, Keyu Zhang</dc:creator>
    </item>
    <item>
      <title>Two-Phase Optimization for PINN Training</title>
      <link>https://arxiv.org/abs/2409.07296</link>
      <description>arXiv:2409.07296v1 Announce Type: new 
Abstract: This work presents an algorithm for training Neural Networks where the loss function can be decomposed into two non-negative terms to be minimized. The proposed method is an adaptation of Inexact Restoration algorithms, constituting a two-phase method that imposes descent conditions. Some performance tests are carried out in PINN training.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.07296v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 12 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dimary Moreno L\'opez</dc:creator>
    </item>
    <item>
      <title>Constraining Genetic Symbolic Regression via Semantic Backpropagation</title>
      <link>https://arxiv.org/abs/2409.07369</link>
      <description>arXiv:2409.07369v1 Announce Type: new 
Abstract: Evolutionary symbolic regression approaches are powerful tools that can approximate an explicit mapping between input features and observation for various problems. However, ensuring that explored expressions maintain consistency with domain-specific constraints remains a crucial challenge. While neural networks are able to employ additional information like conservation laws to achieve more appropriate and robust approximations, the potential remains unrealized within genetic algorithms. This disparity is rooted in the inherent discrete randomness of recombining and mutating to generate new mapping expressions, making it challenging to maintain and preserve inferred constraints or restrictions in the course of the exploration. To address this limitation, we propose an approach centered on semantic backpropagation incorporated into the Gene Expression Programming (GEP), which integrates domain-specific properties in a vector representation as corrective feedback during the evolutionary process. By creating backward rules akin to algorithmic differentiation and leveraging pre-computed subsolutions, the mechanism allows the enforcement of any constraint within an expression tree by determining the misalignment and propagating desired changes back. To illustrate the effectiveness of constraining GEP through semantic backpropagation, we take the constraint of physical dimension as an example. This framework is applied to discovering physical equations from the Feynman lectures. Results have shown not only an increased likelihood of recovering the original equation but also notable robustness in the presence of noisy data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.07369v1</guid>
      <category>math.OC</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <pubDate>Thu, 12 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maximilian Reissmann, Yuan Fang, Andrew Ooi, Richard Sandberg</dc:creator>
    </item>
    <item>
      <title>Bridging Autoencoders and Dynamic Mode Decomposition for Reduced-order Modeling and Control of PDEs</title>
      <link>https://arxiv.org/abs/2409.06101</link>
      <description>arXiv:2409.06101v1 Announce Type: cross 
Abstract: Modeling and controlling complex spatiotemporal dynamical systems driven by partial differential equations (PDEs) often necessitate dimensionality reduction techniques to construct lower-order models for computational efficiency. This paper explores a deep autoencoding learning method for reduced-order modeling and control of dynamical systems governed by spatiotemporal PDEs. We first analytically show that an optimization objective for learning a linear autoencoding reduced-order model can be formulated to yield a solution closely resembling the result obtained through the dynamic mode decomposition with control algorithm. We then extend this linear autoencoding architecture to a deep autoencoding framework, enabling the development of a nonlinear reduced-order model. Furthermore, we leverage the learned reduced-order model to design controllers using stability-constrained deep neural networks. Numerical experiments are presented to validate the efficacy of our approach in both modeling and control using the example of a reaction-diffusion system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06101v1</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 12 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Priyabrata Saha, Saibal Mukhopadhyay</dc:creator>
    </item>
    <item>
      <title>Bi-level regularization via iterative mesh refinement for aeroacoustics</title>
      <link>https://arxiv.org/abs/2409.06854</link>
      <description>arXiv:2409.06854v1 Announce Type: cross 
Abstract: In this work, we illustrate the connection between adaptive mesh refinement for finite element discretized PDEs and the recently developed \emph{bi-level regularization algorithm}. By adaptive mesh refinement according to data noise, regularization effect and convergence are immediate consequences. We moreover demonstrate its numerical advantages to the classical Landweber algorithm in term of time and reconstruction quality for the example of the Helmholtz equation in an aeroacoustic setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06854v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Thu, 12 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christian Aarset, Tram Thi Ngoc Nguyen</dc:creator>
    </item>
    <item>
      <title>A deep primal-dual BSDE method for optimal stopping problems</title>
      <link>https://arxiv.org/abs/2409.06937</link>
      <description>arXiv:2409.06937v1 Announce Type: cross 
Abstract: We present a new deep primal-dual backward stochastic differential equation framework based on stopping time iteration to solve optimal stopping problems. A novel loss function is proposed to learn the conditional expectation, which consists of subnetwork parameterization of a continuation value and spatial gradients from present up to the stopping time. Notable features of the method include: (i) The martingale part in the loss function reduces the variance of stochastic gradients, which facilitates the training of the neural networks as well as alleviates the error propagation of value function approximation; (ii) this martingale approximates the martingale in the Doob-Meyer decomposition, and thus leads to a true upper bound for the optimal value in a non-nested Monte Carlo way. We test the proposed method in American option pricing problems, where the spatial gradient network yields the hedging ratio directly.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06937v1</guid>
      <category>q-fin.CP</category>
      <category>math.OC</category>
      <pubDate>Thu, 12 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiefei Yang, Guanglian Li</dc:creator>
    </item>
    <item>
      <title>Fractional Backward Stochastic Partial Differential Equations with Applications to Stochastic Optimal Control of Partially Observed Systems driven by L\'evy Processes</title>
      <link>https://arxiv.org/abs/2409.07052</link>
      <description>arXiv:2409.07052v1 Announce Type: cross 
Abstract: In this paper, we study the Cauchy problem for backward stochastic partial differential equations (BSPDEs) involving fractional Laplacian operator. Firstly, by employing the martingale representation theorem and the fractional heat kernel, we construct an explicit form of the solution for fractional BSPDEs with space invariant coefficients, thereby demonstrating the existence and uniqueness of strong solution. Then utilizing the freezing coefficients method as well as the continuation method, we establish H\"older estimates and well-posedness for general fractional BSPDEs with coefficients dependent on space-time variables. As an application, we use the fractional adjoint BSPDEs to investigate stochastic optimal control of the partially observed systems driven by $\alpha$-stable L\'evy processes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.07052v1</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <pubDate>Thu, 12 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuyang Ye, Yunzhang Li, Shanjian Tang</dc:creator>
    </item>
    <item>
      <title>Riemannian Federated Learning via Averaging Gradient Stream</title>
      <link>https://arxiv.org/abs/2409.07223</link>
      <description>arXiv:2409.07223v1 Announce Type: cross 
Abstract: In recent years, federated learning has garnered significant attention as an efficient and privacy-preserving distributed learning paradigm. In the Euclidean setting, Federated Averaging (FedAvg) and its variants are a class of efficient algorithms for expected (empirical) risk minimization. This paper develops and analyzes a Riemannian Federated Averaging Gradient Stream (RFedAGS) algorithm, which is a generalization of FedAvg, to problems defined on a Riemannian manifold. Under standard assumptions, the convergence rate of RFedAGS with fixed step sizes is proven to be sublinear for an approximate stationary solution. If decaying step sizes are used, the global convergence is established. Furthermore, assuming that the objective obeys the Riemannian Polyak-{\L}ojasiewicz property, the optimal gaps generated by RFedAGS with fixed step size are linearly decreasing up to a tiny upper bound, meanwhile, if decaying step sizes are used, then the gaps sublinearly vanish.
  Numerical simulations conducted on synthetic and real-world data demonstrate the performance of the proposed RFedAGS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.07223v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 12 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhenwei Huang, Wen Huang, Pratik Jawanpuria, Bamdev Mishra</dc:creator>
    </item>
    <item>
      <title>Convergence of continuous-time stochastic gradient descent with applications to linear deep neural networks</title>
      <link>https://arxiv.org/abs/2409.07401</link>
      <description>arXiv:2409.07401v1 Announce Type: cross 
Abstract: We study a continuous-time approximation of the stochastic gradient descent process for minimizing the expected loss in learning problems. The main results establish general sufficient conditions for the convergence, extending the results of Chatterjee (2022) established for (nonstochastic) gradient descent. We show how the main result can be applied to the case of overparametrized linear neural network training.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.07401v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 12 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gabor Lugosi, Eulalia Nualart</dc:creator>
    </item>
    <item>
      <title>Multi-Objective Linear Ensembles for Robust and Sparse Training of Few-Bit Neural Networks</title>
      <link>https://arxiv.org/abs/2212.03659</link>
      <description>arXiv:2212.03659v2 Announce Type: replace 
Abstract: Training neural networks (NNs) using combinatorial optimization solvers has gained attention in recent years. In low-data settings, state-of-the-art mixed integer linear programming solvers can train exactly a NN, avoiding intensive GPU-based training and hyper-parameter tuning and simultaneously training and sparsifying the network. We study the case of few-bit discrete-valued neural networks, both Binarized Neural Networks (BNNs), whose values are restricted to +-1, and Integer Neural Networks (INNs), whose values lie in a range {-P, ..., P}. Few-bit NNs receive increasing recognition due to their lightweight architecture and ability to run on low-power devices. This paper proposes new methods to improve the training of BNNs and INNs. Our contribution is a multi-objective ensemble approach based on training a single NN for each possible pair of classes and applying a majority voting scheme to predict the final output. Our approach results in training robust sparsified networks whose output is not affected by small perturbations on the input and whose number of active weights is as small as possible. We compare this BeMi approach to the current state-of-the-art in solver-based NN training and gradient-based training, focusing on BNN learning in few-shot contexts. We compare the benefits and drawbacks of INNs versus BNNs, bringing new light to the distribution of weights over the {-P, ..., P} interval. Finally, we compare multi-objective versus single-objective training of INNs, showing that robustness and network simplicity can be acquired simultaneously, thus obtaining better test performances. While the previous state-of-the-art approaches achieve an average accuracy of 51.1% on the MNIST dataset, the BeMi ensemble approach achieves an average accuracy of 68.4% when trained with 10 images per class and 81.8% when trained with 40 images per class, having up to 75.3% NN links removed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.03659v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Thu, 12 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ambrogio Maria Bernardelli, Stefano Gualandi, Hoong Chuin Lau, Simone Milanesi, Neil Yorke-Smith</dc:creator>
    </item>
    <item>
      <title>Robustly Learning Regions of Attraction from Fixed Data</title>
      <link>https://arxiv.org/abs/2305.12813</link>
      <description>arXiv:2305.12813v2 Announce Type: replace 
Abstract: While stability analysis is a mainstay for control science, especially computing regions of attraction of equilibrium points, until recently most stability analysis tools always required explicit knowledge of the model or a high-fidelity simulator representing the system at hand. In this work, a new data-driven Lyapunov analysis framework is proposed. Without using the model or its simulator, the proposed approach can learn a piece-wise affine Lyapunov function with a finite and fixed off-line dataset. The learnt Lyapunov function is robust to any dynamics that are consistent with the off-line dataset, and its computation is based on second order cone programming. Along with the development of the proposed scheme, a slight generalization of classical Lyapunov stability criteria is derived, enabling an iterative inference algorithm to augment the region of attraction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.12813v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 12 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matteo Tacchi, Yingzhao Lian, Colin Jones</dc:creator>
    </item>
    <item>
      <title>On the true detection probability of the uniformly optimal search plan</title>
      <link>https://arxiv.org/abs/2311.18226</link>
      <description>arXiv:2311.18226v3 Announce Type: replace 
Abstract: The gold standard for designing a search plan is to select a target distribution and then find the uniformly optimal search plan based on it. This approach has been successfully applied in several high-profile civil and military search missions. Since the target distribution is subjective and chosen at an analyst's discretion, it is natural to ask whether this approach can generate a search plan that maximizes the true detection probability at each moment. This article gives a negative answer by establishing that, under mild conditions, for a given target distribution and the optimal search plan based on it, there is another target distribution whose induced uniformly optimal search plan leads to an increased true detection probability at every moment. In particular, it implies that the problem of finding a search plan that maximizes the true detection probability at each moment remains unsolved.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.18226v3</guid>
      <category>math.OC</category>
      <pubDate>Thu, 12 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Liang Hong</dc:creator>
    </item>
    <item>
      <title>A globalization of L-BFGS and the Barzilai-Borwein method for nonconvex unconstrained optimization</title>
      <link>https://arxiv.org/abs/2401.03805</link>
      <description>arXiv:2401.03805v4 Announce Type: replace 
Abstract: We present a modified limited memory BFGS (L-BFGS) method that converges globally and linearly for nonconvex objective functions. Its distinguishing feature is that it turns into L-BFGS if the iterates cluster at a point near which the objective is strongly convex with Lipschitz gradients, thereby inheriting the outstanding effectiveness of the classical method. These strong convergence guarantees are enabled by a novel form of cautious updating, where, among others, it is decided anew in each iteration which of the stored pairs are used for updating and which ones are skipped. In particular, this yields the first modification of cautious updating for which all cluster points are stationary while the spectrum of the L-BFGS operator is not permanently restricted, and this holds without Lipschitz continuity of the gradient. In fact, for Wolfe-Powell line searches we show that continuity of the gradient is sufficient for global convergence, which extends to other descent methods. Since we allow the memory size to be zero in the globalized L-BFGS method, we also obtain a new globalization of the Barzilai-Borwein spectral gradient (BB) method. The convergence analysis is developed in Hilbert space under comparably weak assumptions and covers Armijo and Wolfe-Powell line searches. We illustrate the theoretical findings with numerical experiments. The experiments indicate that if one of the parameters of the cautious updating is chosen sufficiently small, then the modified method agrees entirely with L-BFGS/BB. We also discuss this in the theoretical part. An implementation of the new method is available on arXiv.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.03805v4</guid>
      <category>math.OC</category>
      <pubDate>Thu, 12 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Florian Mannel</dc:creator>
    </item>
    <item>
      <title>Elliptical Pursuit and Evasion -Extended Version-</title>
      <link>https://arxiv.org/abs/2401.06338</link>
      <description>arXiv:2401.06338v3 Announce Type: replace 
Abstract: Many studies on one-on-one pursuit-evasion problems have shown that formulas about the pursuer's trajectory can be solved by supposing three conditions. First, the evader follows specific figures. Second, the pursuer's velocity vector always points toward the evader's position. Third, the ratio of their respective speed remains constant. However, previous studies often assumed that the evader moves at a steady speed. This study aims to investigate how changes in the evader's speed affect the pursuer's trajectory. We hypothesized that the pursuer's trajectory would remain unchanged. First, the pursuer's trajectories were obtained from three scenarios where the evader orbits an ellipse with different speeds and angular velocities. These trajectories coincided. Second, changes in the evader's speed correspond to changes in the evader's trajectory parameters. Replacing the evader's parameter is proven to be replacing the pursuer's parameter. It is shown that replacing the evader's parameter is equivalent to replacing the pursuer's parameter. Consequently, the shape of the pursuer's trajectory is unaffected by the evader's speed; only the speed ratio matters in the game.
  This version includes additional sections on the dynamical system that were not present in the original version. If the evader's speed is always one, a dynamical system can be derived from the three conditions of pursuit and evasion. When the evader orbits a circle, this dynamical system is autonomous and has an asymptotically stable equilibrium point. However, when the evader orbits an ellipse, the dynamical system becomes non-autonomous, and the solution trajectory converges to a closed curve. Additionally, we present a second-order nonlinear differential equation describing the angular difference between the velocity vectors of both players.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.06338v3</guid>
      <category>math.OC</category>
      <pubDate>Thu, 12 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sota Yoshihara</dc:creator>
    </item>
    <item>
      <title>A clustering approach for pairwise comparison matrices</title>
      <link>https://arxiv.org/abs/2402.06061</link>
      <description>arXiv:2402.06061v4 Announce Type: replace 
Abstract: We consider clustering in group decision making where the opinions are given by pairwise comparison matrices. In particular, the k-medoids model is suggested to classify the matrices since it has a linear programming problem formulation that may contain any condition on the properties of the cluster centres. Its objective function depends on the measure of dissimilarity between the matrices but not on the weights derived from them. Our methodology provides a convenient tool for decision support, for instance, it can be used to quantify the reliability of the aggregation. The proposed theoretical framework is applied to a large-scale experimental dataset, on which it is able to automatically detect some mistakes made by the decision-makers, as well as to identify a common source of inconsistency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.06061v4</guid>
      <category>math.OC</category>
      <category>stat.AP</category>
      <pubDate>Thu, 12 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kolos Csaba \'Agoston, S\'andor Boz\'oki, L\'aszl\'o Csat\'o</dc:creator>
    </item>
    <item>
      <title>Projected gradient descent accumulates at Bouligand stationary points</title>
      <link>https://arxiv.org/abs/2403.02530</link>
      <description>arXiv:2403.02530v2 Announce Type: replace 
Abstract: This paper considers the projected gradient descent (PGD) algorithm for the problem of minimizing a continuously differentiable function on a nonempty closed subset of a Euclidean vector space. Without further assumptions, this problem is intractable and algorithms are only expected to find a stationary point. PGD generates a sequence in the set whose accumulation points are known to be Mordukhovich stationary. In this paper, these accumulation points are proven to be Bouligand stationary, and even proximally stationary if the gradient is locally Lipschitz continuous. These are the strongest stationarity properties that can be expected for the considered problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02530v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 12 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guillaume Olikier, Ir\`ene Waldspurger</dc:creator>
    </item>
    <item>
      <title>Further remarks on absorbing Markov decision processes</title>
      <link>https://arxiv.org/abs/2403.20292</link>
      <description>arXiv:2403.20292v2 Announce Type: replace 
Abstract: In this note, based on the recent remarkable results of Dufour and Prieto-Rumeau, we deduce that for an absorbing MDP with a given initial state, under a standard compactness-continuity condition, the space of occupation measures has the same convergent sequences, when it is endowed with the weak topology and with the weak-strong topology. We provided two examples demonstrating that imposed condition cannot be replaced with its popular alternative, and the above assertion does not hold for the space of marginals of occupation measures on the state space. Moreover, the examples also clarify some results in the previous literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.20292v2</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Thu, 12 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yi Zhang, Xinran Zheng</dc:creator>
    </item>
    <item>
      <title>Sensing Resource Allocation Against Data-Poisoning Attacks in Traffic Routing</title>
      <link>https://arxiv.org/abs/2404.02876</link>
      <description>arXiv:2404.02876v2 Announce Type: replace 
Abstract: Data-poisoning attacks can disrupt the efficient operations of transportation systems by misdirecting traffic flows via falsified data. One challenge in countering these attacks is to reduce the uncertainties on the types of attacks, such as the distribution of their targets and intensities. We introduce a resource allocation method in transportation networks to detect and distinguish different types of attacks and facilitate efficient traffic routing. The idea is to first cluster different types of attacks based on the corresponding optimal routing strategies, then allocate sensing resources to a subset of network links to distinguish attacks from different clusters via lexicographical mixed-integer programming. We illustrate the application of the proposed method using the Anaheim network, a benchmark model in traffic routing that contains more than 400 nodes and 900 links.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02876v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 12 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yue Yu, Adam J. Thorpe, Jesse Milzman, David Fridovich-Keil, Ufuk Topcu</dc:creator>
    </item>
    <item>
      <title>Optimal Reflection Coefficients for ASK Modulated Backscattering from Passive Tags</title>
      <link>https://arxiv.org/abs/2406.17448</link>
      <description>arXiv:2406.17448v3 Announce Type: replace 
Abstract: This paper studies backscatter communication (BackCom) systems with a passive backscatter tag. The effectiveness of these tags is limited by the amount of energy they can harness from incident radio signals, which are used to backscatter information through the modulation of reflections. To address this limitation, we adopt a practical Constant-Linear-Constant (CLC) energy harvesting model that accounts for the harvester's sensitivity and saturation threshold, both of which depend on the input power. This paper aims to maximize this harvested power at a passive tag by optimally designing the underlying M-ary amplitude-shift keying (ASK) modulator in a monostatic BackCom system. Specifically, we derive the closed-form expression for the global optimal reflection coefficients that maximize the tag's harvested power while satisfying the minimum symbol error rate (SER) requirement, tag sensitivity, and reader sensitivity constraints. We also proposed optimal binary-ASK modulation design to gain novel design insights on practical BackCom systems with readers having superior sensitivity. We have validated these nontrivial analytical claims via extensive simulations. The numerical results provide insight into the impact of the transmit symbol probability, tag sensitivity constraint, and SER on the maximum average harvested power. Remarkably, our design achieves an overall gain of around 13% over the benchmark, signifying its utility in improving the efficiency of BackCom systems. Moreover, our proposed solution methodology for determining the maximum average harvested power is applicable to any type of energy harvesting model that exhibits a monotonic increasing relationship with the input power.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.17448v3</guid>
      <category>math.OC</category>
      <pubDate>Thu, 12 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Amus Chee Yuen Goay, Deepak Mishra, Aruna Seneviratne</dc:creator>
    </item>
    <item>
      <title>A Carbon Aware Ant Colony System (CAACS)</title>
      <link>https://arxiv.org/abs/2407.09404</link>
      <description>arXiv:2407.09404v2 Announce Type: replace 
Abstract: In an era where sustainability is becoming increasingly crucial, we introduce a new Carbon-Aware Ant Colony System (CAACS) Algorithm that addresses the Generalized Traveling Salesman Problem (GTSP) while minimizing carbon emissions. This novel approach leverages the natural efficiency of ant colony pheromone trails to find optimal routes, balancing both environmental and economic objectives. By integrating sustainability into transportation models, CAACS provides a powerful tool for real-world applications, including network design, delivery route planning, and commercial aircraft logistics. Our algorithm's unique bi-objective optimization advances the study of sustainable transportation solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09404v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>physics.soc-ph</category>
      <pubDate>Thu, 12 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marina Lin, Laura P. Schaposnik</dc:creator>
    </item>
    <item>
      <title>Extended mean field control problems with constraints: The generalized Fritz-John conditions and Lagrangian method</title>
      <link>https://arxiv.org/abs/2408.06865</link>
      <description>arXiv:2408.06865v2 Announce Type: replace 
Abstract: This paper studies the extended mean field control problems under general dynamic expectation constraints and/or dynamic pathwise state-control and law constraints. We aim to pioneer the establishment of the stochastic maximum principle (SMP) and the derivation of the backward SDE (BSDE) from the perspective of the constrained optimization using the method of Lagrangian multipliers. To this end, we first propose to embed the constrained extended mean-field control (C-MFC) problems into some abstract optimization problems with constraints on Banach spaces, for which we develop the generalized Fritz-John (FJ) optimality conditions. We then prove the stochastic maximum principle (SMP) for C-MFC problems by transforming the FJ type conditions into an equivalent stochastic first-order condition associated with a general type of constrained forward-backward SDEs (FBSDEs). Contrary to the existing literature, we treat the controlled Mckean-Vlasov SDE as an infinite-dimensional equality constraint such that the BSDE induced by the FJ first-order optimality condition can be interpreted as the generalized Lagrange multiplier to cope with the SDE constraint. Finally, we also present the SMP for stochastic control problems and mean field game problems under similar types of constraints as consequences of our main result for C-MFC problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06865v2</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Thu, 12 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lijun Bo, Jingfei Wang, Xiang Yu</dc:creator>
    </item>
    <item>
      <title>A Policy Iteration Method for Inverse Mean Field Games</title>
      <link>https://arxiv.org/abs/2409.06184</link>
      <description>arXiv:2409.06184v2 Announce Type: replace 
Abstract: We propose a policy iteration method to solve an inverse problem for a mean-field game (MFG) model, specifically to reconstruct the obstacle function in the game from the partial observation data of value functions, which represent the optimal costs for agents. The proposed approach decouples this complex inverse problem, which is an optimization problem constrained by a coupled nonlinear forward and backward PDE system in the MFG, into several iterations of solving linear PDEs and linear inverse problems. This method can also be viewed as a fixed-point iteration that simultaneously solves the MFG system and inversion. We prove its linear rate of convergence. In addition, numerical examples in 1D and 2D, along with performance comparisons to a direct least-squares method, demonstrate the superior efficiency and accuracy of the proposed method for solving inverse MFGs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06184v2</guid>
      <category>math.OC</category>
      <category>cs.GT</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.NA</category>
      <pubDate>Thu, 12 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kui Ren, Nathan Soedjak, Shanyin Tong</dc:creator>
    </item>
    <item>
      <title>Gradient descent provably escapes saddle points in the training of shallow ReLU networks</title>
      <link>https://arxiv.org/abs/2208.02083</link>
      <description>arXiv:2208.02083v2 Announce Type: replace-cross 
Abstract: Dynamical systems theory has recently been applied in optimization to prove that gradient descent algorithms bypass so-called strict saddle points of the loss function. However, in many modern machine learning applications, the required regularity conditions are not satisfied. In this paper, we prove a variant of the relevant dynamical systems result, a center-stable manifold theorem, in which we relax some of the regularity requirements. We explore its relevance for various machine learning tasks, with a particular focus on shallow rectified linear unit (ReLU) and leaky ReLU networks with scalar input. Building on a detailed examination of critical points of the square integral loss function for shallow ReLU and leaky ReLU networks relative to an affine target function, we show that gradient descent circumvents most saddle points. Furthermore, we prove convergence to global minima under favourable initialization conditions, quantified by an explicit threshold on the limiting loss.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.02083v2</guid>
      <category>cs.LG</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Thu, 12 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s10957-024-02513-3</arxiv:DOI>
      <arxiv:journal_reference>J Optim Theory Appl (2024)</arxiv:journal_reference>
      <dc:creator>Patrick Cheridito, Arnulf Jentzen, Florian Rossmannek</dc:creator>
    </item>
    <item>
      <title>A nearly optimal randomized algorithm for explorable heap selection</title>
      <link>https://arxiv.org/abs/2210.05982</link>
      <description>arXiv:2210.05982v2 Announce Type: replace-cross 
Abstract: Explorable heap selection is the problem of selecting the $n$th smallest value in a binary heap. The key values can only be accessed by traversing through the underlying infinite binary tree, and the complexity of the algorithm is measured by the total distance traveled in the tree (each edge has unit cost). This problem was originally proposed as a model to study search strategies for the branch-and-bound algorithm with storage restrictions by Karp, Saks and Widgerson (FOCS '86), who gave deterministic and randomized $n\cdot \exp(O(\sqrt{\log{n}}))$ time algorithms using $O(\log(n)^{2.5})$ and $O(\sqrt{\log n})$ space respectively. We present a new randomized algorithm with running time $O(n\log(n)^3)$ using $O(\log n)$ space, substantially improving the previous best randomized running time at the expense of slightly increased space usage. We also show an $\Omega(\log(n)n/\log(\log(n)))$ for any algorithm that solves the problem in the same amount of space, indicating that our algorithm is nearly optimal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.05982v2</guid>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Thu, 12 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sander Borst, Daniel Dadush, Sophie Huiberts, Danish Kashaev</dc:creator>
    </item>
    <item>
      <title>Identifiability of nonlinear ODE Models with Time-Varying Parameters: the General Analytical Solution and Applications in Viral Dynamics</title>
      <link>https://arxiv.org/abs/2211.13507</link>
      <description>arXiv:2211.13507v5 Announce Type: replace-cross 
Abstract: Identifiability is a structural property of any ODE model characterized by a set of unknown parameters. It describes the possibility of determining the values of these parameters from fusing the observations of the system inputs and outputs. This paper finds the general analytical solution of this fundamental problem and, based on this, provides a general and automated analytical method to determine the identifiability of the unknown parameters. In particular, the method can handle any model, regardless of its complexity and type of non-linearity, and provides the identifiability of the parameters even when they are time-varying. In addition, it is automatic as it simply needs to follow the steps of a systematic procedure that only requires to perform the calculation of derivatives and matrix ranks. Time-varying parameters are treated as unknown inputs and their identification is based on the very recent analytical solution of the unknown input observability problem [1, 2]. The method is used to determine the identifiability of the unknown time-varying parameters that characterize two non-linear models in the field of viral dynamics (HIV and Covid-19) and a non-linear model that characterizes the genetic toggle switch. New fundamental properties that characterize these models are determined and discussed in detail through a comparison with the state-of-the-art results. In particular, regarding the very popular HIV ODE model and the genetic toggle switch model, the method automatically finds new important results that are in contrast with the results in the current literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.13507v5</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <category>q-bio.QM</category>
      <pubDate>Thu, 12 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Agostino Martinelli</dc:creator>
    </item>
    <item>
      <title>Equivalent Conditions for the Synchronization of Identical Linear Systems over Arbitrary Interconnections</title>
      <link>https://arxiv.org/abs/2303.17321</link>
      <description>arXiv:2303.17321v3 Announce Type: replace-cross 
Abstract: We propose necessary and sufficient conditions for the synchronization of $N$ identical single-input-single-output (SISO) systems, connected through a directed graph {without imposing any assumption on the graph interconnection}. We consider both the continuous-time and the discrete-time case, and we provide conditions that {are equivalent to} the uniform global exponential stability, {with guaranteed convergence rate,} of the closed {and unbounded} attractor that corresponds to the synchronization set.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.17321v3</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 12 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.ejcon.2024.101099</arxiv:DOI>
      <dc:creator>Nicola Zaupa, Giulia Giordano, Isabelle Queinnec, Sophie Tarbouriech, Luca Zaccarian</dc:creator>
    </item>
    <item>
      <title>The Effectiveness of Local Updates for Decentralized Learning under Data Heterogeneity</title>
      <link>https://arxiv.org/abs/2403.15654</link>
      <description>arXiv:2403.15654v2 Announce Type: replace-cross 
Abstract: We revisit two fundamental decentralized optimization methods, Decentralized Gradient Tracking (DGT) and Decentralized Gradient Descent (DGD), with multiple local updates. We consider two settings and demonstrate that incorporating $K &gt; 1$ local update steps can reduce communication complexity. Specifically, for $\mu$-strongly convex and $L$-smooth loss functions, we proved that local DGT achieves communication complexity $\tilde{\mathcal{O}} \Big(\frac{L}{\mu K} + \frac{\delta}{\mu (1 - \rho)} + \frac{\rho }{(1 - \rho)^2} \cdot \frac{L+ \delta}{\mu}\Big)$, where $\rho$ measures the network connectivity and $\delta$ measures the second-order heterogeneity of the local loss. Our result reveals the tradeoff between communication and computation and shows increasing $K$ can effectively reduce communication costs when the data heterogeneity is low and the network is well-connected. We then consider the over-parameterization regime where the local losses share the same minimums, we proved that employing local updates in DGD, even without gradient correction, can yield a similar effect as DGT in reducing communication complexity. Numerical experiments validate our theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15654v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 12 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tongle Wu, Ying Sun</dc:creator>
    </item>
    <item>
      <title>State-Augmented Linear Games with Antagonistic Error for High-Dimensional, Nonlinear Hamilton-Jacobi Reachability</title>
      <link>https://arxiv.org/abs/2403.16982</link>
      <description>arXiv:2403.16982v2 Announce Type: replace-cross 
Abstract: Hamilton-Jacobi Reachability (HJR) is a popular method for analyzing the liveness and safety of a dynamical system with bounded control and disturbance. The corresponding HJ value function offers a robust controller and characterizes the reachable sets, but is traditionally solved with Dynamic Programming (DP) and limited to systems of dimension less than six. Recently, the space-parallelizeable, generalized Hopf formula has been shown to also solve the HJ value with a nearly three-log increase in dimension limit, but is limited to linear systems. To extend this potential, we demonstrate how state-augmented (SA) spaces, which are well-known for their improved linearization accuracy, may be used to solve tighter, conservative approximations of the value function with any linear model in this SA space. Namely, we show that with a representation of the true dynamics in the SA space, a series of inequalities confirms that the value of a SA linear game with antagonistic error is a conservative envelope of the true value function. It follows that if the optimal controller for the HJ SA linear game with error may succeed, it will also succeed in the true system. Unlike previous methods, this result offers the ability to safely approximate reachable sets and their corresponding controllers with the Hopf formula in a non-convex manner. Finally, we demonstrate this in the slow manifold system for clarity, and in the controlled Van der Pol system with different lifting functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16982v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 12 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Will Sharpless, Yat Tin Chow, Sylvia Herbert</dc:creator>
    </item>
    <item>
      <title>A variational formulation of a Multi-Population Mean Field Games with non-local interactions</title>
      <link>https://arxiv.org/abs/2408.03118</link>
      <description>arXiv:2408.03118v2 Announce Type: replace-cross 
Abstract: We propose a MFG model with quadratic Hamiltonian involving $N$ populations. This results in a system of $N$ Hamilton-Jacobi-Bellman and $N$ Fokker-Planck equations with non-local interactions. As in the classical case we introduce an Eulerian variational formulation which, despite the non convexity of the interaction, still gives a weak solution to the MFG model. The problem can be reformulated in Lagrangian terms and solved numerically by a Sinkhorn-like scheme. We present numerical results based on this approach, these simulations exhibit different behaviours depending on the nature (repulsive or attractive) of the non-local interaction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.03118v2</guid>
      <category>math.AP</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Thu, 12 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luigi De Pascale, Luca Nenna</dc:creator>
    </item>
    <item>
      <title>Non-convex matrix sensing: Breaking the quadratic rank barrier in the sample complexity</title>
      <link>https://arxiv.org/abs/2408.13276</link>
      <description>arXiv:2408.13276v2 Announce Type: replace-cross 
Abstract: For the problem of reconstructing a low-rank matrix from a few linear measurements, two classes of algorithms have been widely studied in the literature: convex approaches based on nuclear norm minimization, and non-convex approaches that use factorized gradient descent. Under certain statistical model assumptions, it is known that nuclear norm minimization recovers the ground truth as soon as the number of samples scales linearly with the number of degrees of freedom of the ground-truth. In contrast, while non-convex approaches are computationally less expensive, existing recovery guarantees assume that the number of samples scales at least quadratically with the rank $r$ of the ground-truth matrix. In this paper, we close this gap by showing that the non-convex approaches can be as efficient as nuclear norm minimization in terms of sample complexity. Namely, we consider the problem of reconstructing a positive semidefinite matrix from a few Gaussian measurements. We show that factorized gradient descent with spectral initialization converges to the ground truth with a linear rate as soon as the number of samples scales with $ \Omega (rd\kappa^2)$, where $d$ is the dimension, and $\kappa$ is the condition number of the ground truth matrix. This improves the previous rank-dependence in the sample complexity of non-convex matrix factorization from quadratic to linear. Our proof relies on a probabilistic decoupling argument, where we show that the gradient descent iterates are only weakly dependent on the individual entries of the measurement matrices. We expect that our proof technique is of independent interest for other non-convex problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.13276v2</guid>
      <category>stat.ML</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 12 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dominik St\"oger, Yizhe Zhu</dc:creator>
    </item>
    <item>
      <title>Modified Meta-Thompson Sampling for Linear Bandits and Its Bayes Regret Analysis</title>
      <link>https://arxiv.org/abs/2409.06329</link>
      <description>arXiv:2409.06329v2 Announce Type: replace-cross 
Abstract: Meta-learning is characterized by its ability to learn how to learn, enabling the adaptation of learning strategies across different tasks. Recent research introduced the Meta-Thompson Sampling (Meta-TS), which meta-learns an unknown prior distribution sampled from a meta-prior by interacting with bandit instances drawn from it. However, its analysis was limited to Gaussian bandit. The contextual multi-armed bandit framework is an extension of the Gaussian Bandit, which challenges agent to utilize context vectors to predict the most valuable arms, optimally balancing exploration and exploitation to minimize regret over time. This paper introduces Meta-TSLB algorithm, a modified Meta-TS for linear contextual bandits. We theoretically analyze Meta-TSLB and derive an $ O((m+\log(m))\sqrt{n\log(n)})$ bound on its Bayes regret, in which $m$ represents the number of bandit instances, and $n$ the number of rounds of Thompson Sampling. Additionally, our work complements the analysis of Meta-TS for linear contextual bandits. The performance of Meta-TSLB is evaluated experimentally under different settings, and we experimente and analyze the generalization capability of Meta-TSLB, showcasing its potential to adapt to unseen instances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06329v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 12 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hao Li, Dong Liang, Zheng Xie</dc:creator>
    </item>
  </channel>
</rss>
