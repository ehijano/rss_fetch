<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 15 Nov 2024 05:00:11 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 15 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>From Simulators to Digital Twins for Enabling Emerging Cellular Networks: A Tutorial and Survey</title>
      <link>https://arxiv.org/abs/2411.08907</link>
      <description>arXiv:2411.08907v1 Announce Type: new 
Abstract: Simulators are indispensable parts of the research and development necessary to advance countless industries, including cellular networks. With simulators, the evaluation, analysis, testing, and experimentation of novel designs and algorithms can be executed in a more cost-effective and convenient manner without the risk of real network service disruption. Additionally, recent trends indicate that the advancement of these Digital System Models (DSM), such as system-level simulators, will hold a pivotal role in advancing cellular networks by facilitating the development of digital twins. Given this growing significance, in this survey and tutorial paper, we present an extensive review of the currently available DSMs for 5G and beyond (5G&amp;B) networks. Specifically, we begin with a tutorial on the fundamental concepts of 5G&amp;B network simulations, followed by an identification of the essential design requirements needed to model the key features of these networks. We also devised a taxonomy of different types of 5G&amp;B network simulators. In contrast to existing simulator surveys, which mostly leverage traditional metrics applicable to legacy networks, we devise and use 5G-specific evaluation metrics that capture three key facets of a network simulator, namely realism, completeness, and computational efficiency. We evaluate each simulator according to the devised metrics to generate an applicability matrix that maps different 5G&amp;B simulators vis-a-vis the different research themes they can potentially enable. We also present the current challenges in developing 5G&amp;B simulators while laying out several potential solutions to address the issues. Finally, we discuss the future challenges related to simulator design provisions that will arise with the emergence of 6G networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08907v1</guid>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 15 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marvin Manalastas, Muhammad Umar Bin Farooq, Syed Muhammad Asad Zaidi, Haneya Naeem Qureshi, Yusuf Sambo, Ali Imran</dc:creator>
    </item>
    <item>
      <title>ABCI 3.0: Evolution of the leading AI infrastructure in Japan</title>
      <link>https://arxiv.org/abs/2411.09134</link>
      <description>arXiv:2411.09134v1 Announce Type: new 
Abstract: ABCI 3.0 is the latest version of the ABCI, a large-scale open AI infrastructure that AIST has been operating since August 2018 and will be fully operational in January 2025. ABCI 3.0 consists of computing servers equipped with 6128 of the NVIDIA H200 GPUs and an all-flash storage system. Its peak performance is 6.22 exaflops in half precision and 3.0 exaflops in single precision, which is 7 to 13 times faster than the previous system, ABCI 2.0. It also more than doubles both storage capacity and theoretical read/write performance. ABCI 3.0 is expected to accelerate research and development, evaluation, and workforce development of cutting-edge AI technologies, with a particular focus on generative AI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.09134v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <pubDate>Fri, 15 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ryousei Takano, Shinichiro Takizawa, Yusuke Tanimura, Hidemoto Nakada, Hirotaka Ogawa</dc:creator>
    </item>
    <item>
      <title>Toward Democratized Generative AI in Next-Generation Mobile Edge Networks</title>
      <link>https://arxiv.org/abs/2411.09148</link>
      <description>arXiv:2411.09148v1 Announce Type: new 
Abstract: The rapid development of generative AI technologies, including large language models (LLMs), has brought transformative changes to various fields. However, deploying such advanced models on mobile and edge devices remains challenging due to their high computational, memory, communication, and energy requirements. To address these challenges, we propose a model-centric framework for democratizing generative AI deployment on mobile and edge networks. First, we comprehensively review key compact model strategies, such as quantization, model pruning, and knowledge distillation, and present key performance metrics to optimize generative AI for mobile deployment. Next, we provide a focused review of mobile and edge networks, emphasizing the specific challenges and requirements of these environments. We further conduct a case study demonstrating the effectiveness of these strategies by deploying LLMs on real mobile edge devices. Experimental results highlight the practicality of democratized LLMs, with significant improvements in generalization accuracy, hallucination rate, accessibility, and resource consumption. Finally, we discuss potential research directions to further advance the deployment of generative AI in resource-constrained environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.09148v1</guid>
      <category>cs.NI</category>
      <pubDate>Fri, 15 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ruichen Zhang, Jiayi He, Xiaofeng Luo, Dusit Niyato, Jiawen Kang, Zehui Xiong, Yonghui Li, Biplab Sikdar</dc:creator>
    </item>
    <item>
      <title>Implementing an Optimized and Secured Multimedia Streaming Protocol in a Participatory Sensing Scenario</title>
      <link>https://arxiv.org/abs/2411.09252</link>
      <description>arXiv:2411.09252v1 Announce Type: new 
Abstract: Multimedia streaming protocols are becoming increasingly popular in Crowdsensing due to their ability to deliver high-quality video content over the internet in real-time. Streaming multimedia content, as in the context of live video streaming, requires high bandwidth and large storage capacity to ensure a sufficient throughput. Crowdsensing can distribute information about shared video contents among multiple users in network, reducing storage capacity and computational and bandwidth requirements. However, Crowdsensing introduces several security constraints that must be taken into account to ensure the confidentiality, integrity, and availability of the data. In the specific case of video streaming, commonly named as visual crowdsensing (VCS) within this context, data is transmitted over wireless networks, making it vulnerable to security breaches and susceptible to eavesdropping and interception by attackers. Multimedias often contains sensitive user data and may be subject to various privacy laws, including data protection laws and laws related to photography and video recording, based on local GDPR (General Data Protection Regulation). For this reason the realization of a secure protocol optimized for a distributed data streaming in real-time becomes increasingly important in crowdsensing and smart-enviroment context. In this article, we will discuss the use of a symmetric AES-CTR encryption based protocol for securing data streaming over a crowd-sensed network.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.09252v1</guid>
      <category>cs.NI</category>
      <category>cs.CR</category>
      <pubDate>Fri, 15 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Andrea Vaiuso, Federico Concone, Marco Morana, Giuseppe Lo Re</dc:creator>
    </item>
    <item>
      <title>Connecting the Unconnected: A DT Case Study of Nomadic Nodes Deployment in Nepal</title>
      <link>https://arxiv.org/abs/2411.09380</link>
      <description>arXiv:2411.09380v1 Announce Type: new 
Abstract: This paper addresses the challenge of robust cellular connectivity in dense, underdeveloped urban environments, specifically focusing on Kathmandu, Nepal. As cities grow, existing cellular infrastructure struggles to meet the demand for reliable, high-throughput, and low-latency communication services. The lack of investment in new technologies and the intricacies of the cities' landscape pose even more difficulties for robust connectivity. This work addresses the above challenges in a cost-effective and flexible way. We investigate the deployment of LTE Nomadic Nodes (NNs) at scale in order to enhance network capacity and coverage. Utilising a Digital Twin (DT), we simulate and optimise NN placement, considering Kathmandu's physical and environmental characteristics. Our approach leverages the DRIVE DT framework, which enables the systemic evaluation of various network configurations and user mobility scenarios. The results demonstrate that NNs significantly improve signal strength and expected user datarates, presenting a viable solution for enhancing urban cellular connectivity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.09380v1</guid>
      <category>cs.NI</category>
      <pubDate>Fri, 15 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ioannis Mavromatis, Angeliki Katsenou, Klodian Bardhi, Evangelos Xenos, Dimitra Simeonidou</dc:creator>
    </item>
    <item>
      <title>Capacity and Power Consumption of Multi-Layer 6G Networks Using the Upper Mid-Band</title>
      <link>https://arxiv.org/abs/2411.09660</link>
      <description>arXiv:2411.09660v1 Announce Type: new 
Abstract: This paper presents a new system model to evaluate the capacity and power consumption of multi-layer 6G networks utilising the upper mid-band (FR3). The model captures heteroge- neous 4G, 5G, and 6G deployments, analyzing their performance under different deployment strategies. Our results show that strategic 6G deployments, non-co-located with existing 5G sites, significantly enhance throughput, with median and peak user rates of 300 Mbps and exceeding 1 Gbps, respectively. We also emphasize the importance of priority-based cell reselection and beam configuration to fully leverage 6G capabilities. While 6G implementation increases power consumption by 33%, non-co- located deployments strike a balance between performance and power consumption.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.09660v1</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Fri, 15 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David L\'opez-P\'erez, Nicola Piovesan, Giovanni Geraci</dc:creator>
    </item>
    <item>
      <title>Demand-Aware Beam Hopping and Power Allocation for Load Balancing in Digital Twin empowered LEO Satellite Networks</title>
      <link>https://arxiv.org/abs/2411.08896</link>
      <description>arXiv:2411.08896v1 Announce Type: cross 
Abstract: Low-Earth orbit (LEO) satellites utilizing beam hopping (BH) technology offer extensive coverage, low latency, high bandwidth, and significant flexibility. However, the uneven geographical distribution and temporal variability of ground traffic demands, combined with the high mobility of LEO satellites, present significant challenges for efficient beam resource utilization. Traditional BH methods based on GEO satellites fail to address issues such as satellite interference, overlapping coverage, and mobility. This paper explores a Digital Twin (DT)-based collaborative resource allocation network for multiple LEO satellites with overlapping coverage areas. A two-tier optimization problem, focusing on load balancing and cell service fairness, is proposed to maximize throughput and minimize inter-cell service delay. The DT layer optimizes the allocation of overlapping coverage cells by designing BH patterns for each satellite, while the LEO layer optimizes power allocation for each selected service cell. At the DT layer, an Actor-Critic network is deployed on each agent, with a global critic network in the cloud center. The A3C algorithm is employed to optimize the DT layer. Concurrently, the LEO layer optimization is performed using a Multi-Agent Reinforcement Learning algorithm, where each beam functions as an independent agent. The simulation results show that this method reduces satellite load disparity by about 72.5% and decreases the average delay to 12ms. Additionally, our approach outperforms other benchmarks in terms of throughput, ensuring a better alignment between offered and requested data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08896v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <pubDate>Fri, 15 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ruili Zhao, Jun Cai, Jiangtao Luo, Junpeng Gao, Yongyi Ran</dc:creator>
    </item>
    <item>
      <title>A Range-Free Node Localization Method for Anisotropic Wireless Sensor Networks with Sparse Anchors</title>
      <link>https://arxiv.org/abs/2411.08902</link>
      <description>arXiv:2411.08902v1 Announce Type: cross 
Abstract: In sensor networks characterized by irregular layouts and poor connectivity, anisotropic properties can significantly reduce the accuracy of distance estimation between nodes, consequently impairing the localization precision of unidentified nodes. Since distance estimation is contingent upon the multi-hop paths between anchor node pairs, assigning differential weights based on the reliability of these paths could enhance localization accuracy. To address this, we introduce an adaptive weighted method, termed AW-MinMax, for range-free node localization. This method involves constructing a weighted mean nodes localization model, where each multi-hop path weight is inversely proportional to the number of hops. Despite the model's inherent non-convexity and non-differentiability, it can be reformulated into an optimization model with convex objective functions and non-convex constraints through matrix transformations. To resolve these constraints, we employ a Sequential Convex Approximation (SCA) algorithm that utilizes first-order Taylor expansion for iterative refinement. Simulation results validate that our proposed algorithm substantially improves stability and accuracy in estimating range-free node locations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08902v1</guid>
      <category>eess.SP</category>
      <category>cs.NI</category>
      <pubDate>Fri, 15 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yong Jin, Junfang Leng, Lin Zhou, Yu Jiang, Qian Wei</dc:creator>
    </item>
    <item>
      <title>Wireless Federated Learning over UAV-enabled Integrated Sensing and Communication</title>
      <link>https://arxiv.org/abs/2411.08918</link>
      <description>arXiv:2411.08918v1 Announce Type: cross 
Abstract: This paper studies a new latency optimization problem in unmanned aerial vehicles (UAVs)-enabled federated learning (FL) with integrated sensing and communication. In this setup, distributed UAVs participate in model training using sensed data and collaborate with a base station (BS) serving as FL aggregator to build a global model. The objective is to minimize the FL system latency over UAV networks by jointly optimizing UAVs' trajectory and resource allocation of both UAVs and the BS. The formulated optimization problem is troublesome to solve due to its non-convexity. Hence, we develop a simple yet efficient iterative algorithm to find a high-quality approximate solution, by leveraging block coordinate descent and successive convex approximation techniques. Simulation results demonstrate the effectiveness of our proposed joint optimization strategy under practical parameter settings, saving the system latency up to 68.54\% compared to benchmark schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08918v1</guid>
      <category>cs.IT</category>
      <category>cs.AI</category>
      <category>cs.NI</category>
      <category>math.IT</category>
      <pubDate>Fri, 15 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shaba Shaon, Tien Nguyen, Lina Mohjazi, Aryan Kaushik, Dinh C. Nguyen</dc:creator>
    </item>
    <item>
      <title>Field-based Security Testing of SDN configuration Updates</title>
      <link>https://arxiv.org/abs/2411.09433</link>
      <description>arXiv:2411.09433v1 Announce Type: cross 
Abstract: Software-defined systems revolutionized the management of hardware devices but introduced quality assurance challenges that remain to be tackled. For example, software defined networks (SDNs) became a key technology for the prompt reconfigurations of network services in many sectors including telecommunications, data centers, financial services, cloud providers, and manufacturing industry. Unfortunately, reconfigurations may lead to mistakes that compromise the dependability of the provided services. In this paper, we focus on the reconfigurations of network services in the satellite communication sector, and target security requirements, which are often hard to verify; for example, although connectivity may function properly, confidentiality may be broken by packets forwarded to a wrong destination. We propose an approach for FIeld-based Security Testing of SDN Configurations Updates (FISTS). First, it probes the network before and after configuration updates. Then, using the collected data, it relies on unsupervised machine learning algorithms to prioritize the inspection of suspicious node responses, after identifying the network nodes that likely match across the two configurations. Our empirical evaluation has been conducted with network data from simulated and real SDN configuration updates for our industry partner, a world-leading satellite operator. Our results show that, when combined with K-Nearest Neighbour, FISTS leads to best results (up to 0.95 precision and 1.00 recall). Further, we demonstrated its scalability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.09433v1</guid>
      <category>cs.SE</category>
      <category>cs.NI</category>
      <pubDate>Fri, 15 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jahanzaib Malik, Fabrizio Pastore</dc:creator>
    </item>
    <item>
      <title>Online Stochastic Matching: A Polytope Perspective</title>
      <link>https://arxiv.org/abs/2112.14457</link>
      <description>arXiv:2112.14457v5 Announce Type: replace 
Abstract: Stochastic dynamic matching problems have recently gained attention in the stochastic-modeling community due to their diverse applications, such as supply-chain management and kidney exchange programs. In this paper, we study a matching problem where items of different classes arrive according to independent Poisson processes. Unmatched items are stored in a queue, and compatibility between items is represented by a simple graph, where items can be matched if their classes are connected.We analyze matching policies in terms of stability, delay, and long-term matching rate optimization. Our approach relies on the conservation equation, which ensures a balance between arrivals and departures in any stable system. Our main contributions are as follows.We establish a link between the existence of stable policies, the dimensionality of the solution set of the conservation equation, and the compatibility graph's structure.We describe the convex polytope formed by non-negative solutions to the conservation equation, and we design policies that can achieve or closely approximate the vertices of this polytope.Lastly, we discuss potential extensions of our results beyond the main assumptions of this paper.</description>
      <guid isPermaLink="false">oai:arXiv.org:2112.14457v5</guid>
      <category>cs.NI</category>
      <pubDate>Fri, 15 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>C\'eline Comte (TU/e, CNRS, LAAS-SARA), Fabien Mathieu (LINCS), Sushil Mahavir Varma (DI-ENS, LINCS, DYOGENE, ARGO), Ana Bu\v{s}i\'c (DI-ENS, LINCS, DYOGENE, ARGO)</dc:creator>
    </item>
    <item>
      <title>CaRL: Cascade Reinforcement Learning with State Space Splitting for O-RAN based Traffic Steering</title>
      <link>https://arxiv.org/abs/2312.01970</link>
      <description>arXiv:2312.01970v2 Announce Type: replace 
Abstract: The Open Radio Access Network (O-RAN) architecture empowers intelligent and automated optimization of the RAN through applications deployed on the RAN Intelligent Controller (RIC) platform, enabling capabilities beyond what is achievable with traditional RAN solutions. Within this paradigm, Traffic Steering (TS) emerges as a pivotal RIC application that focuses on optimizing cell-level mobility settings in near-real-time, aiming to significantly improve network spectral efficiency. In this paper, we design a novel TS algorithm based on a Cascade Reinforcement Learning (CaRL) framework. We propose state space factorization and policy decomposition to reduce the need for large models and well-labeled datasets. For each sub-state space, an RL sub-policy will be trained to learn an optimized mapping onto the action space. To apply CaRL on new network regions, we propose a knowledge transfer approach to initialize a new sub-policy based on knowledge learned by the trained policies. To evaluate CaRL, we build a data-driven and scalable RIC digital twin (DT) that is modeled using important real-world data, including network configuration, user geo-distribution, and traffic demand, among others, from a tier-1 mobile operator in the US. We evaluate CaRL on two DT scenarios representing two network clusters in two different cities and compare its performance with the business-as-usual (BAU) policy and other competing optimization approaches using heuristic and Q-table algorithms. Benchmarking results show that CaRL performs the best and improves the average cluster-aggregated downlink throughput over the BAU policy by 24% and 18% in these two scenarios, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.01970v2</guid>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 15 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chuanneng Sun, Gueyoung Jung, Tuyen Xuan Tran, Dario Pompili</dc:creator>
    </item>
    <item>
      <title>Edge AI Empowered Physical Layer Security for 6G NTN: Potential Threats and Future Opportunities</title>
      <link>https://arxiv.org/abs/2401.01005</link>
      <description>arXiv:2401.01005v2 Announce Type: replace 
Abstract: Due to the enormous potential for economic profit offered by artificial intelligence (AI) servers, the field of cybersecurity has the potential to emerge as a prominent arena for competition among corporations and governments on a global scale. One of the prospective applications that stands to gain from the utilization of AI technology is the advancement in the field of cybersecurity. To this end, this paper provides an overview of the possible risks that the physical layer may encounter in the context of 6G Non-Terrestrial Networks (NTN). With the objective of showcasing the effectiveness of cutting-edge AI technologies in bolstering physical layer security, this study reviews the most foreseeable design strategies associated with the integration of edge AI in the realm of 6G NTN. The findings of this paper provide some insights and serve as a foundation for future investigations aimed at enhancing the physical layer security of edge servers/devices in the next generation of trustworthy 6G telecommunication networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.01005v2</guid>
      <category>cs.NI</category>
      <category>cs.CR</category>
      <pubDate>Fri, 15 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Hong-fu Chou, Sourabh Solanki, Vu Nguyen Ha, Lin Chen, Sean Longyu Ma, Hayder Al-Hraishawi, Geoffrey Eappen, Symeon Chatzinotas</dc:creator>
    </item>
    <item>
      <title>6G comprehensive intelligence: network operations and optimization based on Large Language Models</title>
      <link>https://arxiv.org/abs/2404.18373</link>
      <description>arXiv:2404.18373v2 Announce Type: replace 
Abstract: The sixth generation mobile communication standard (6G) can promote the development of Industrial Internet and Internet of Things (IoT). To achieve comprehensive intelligent development of the network and provide customers with higher quality personalized services. This paper proposes a network performance optimization and intelligent operation network architecture based on Large Language Model (LLM), aiming to build a comprehensive intelligent 6G network system. The Large Language Model, with more parameters and stronger learning ability, can more accurately capture patterns and features in data, which can achieve more accurate content output and high intelligence and provide strong support for related research such as network data security, privacy protection, and health assessment. This paper also presents the design framework of a network health assessment system based on LLM and focuses on its potential application value, through the case of network health management system, it is fully demonstrated that the 6G intelligent network system based on LLM has important practical significance for the comprehensive realization of intelligence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18373v2</guid>
      <category>cs.NI</category>
      <pubDate>Fri, 15 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Sifan Long, Fengxiao Tang, Yangfan Li, Tiao Tan, Zhengjie Jin, Ming Zhao, Nei Kato</dc:creator>
    </item>
    <item>
      <title>Technical Report: Toward Applying Quantum Computing to Network Verification</title>
      <link>https://arxiv.org/abs/2410.17184</link>
      <description>arXiv:2410.17184v2 Announce Type: replace-cross 
Abstract: Network verification (NWV), broadly defined as the verification of properties of distributed protocols used in network systems, cannot be efficiently solved on classical hardware via brute force. Prior work has developed a variety of methods that scale by observing a structure in the search space and then evaluating classes within the search space instead of individual instances. However, even these classification mechanisms have their limitations. In this paper, we consider a radically different approach: applying quantum computing to more efficiently solve NWV problems. We provide an overview of how to map variants of NWV problems into unstructured search problems that can be solved via quantum computing with quadratic speedup, making the approach feasible in theory to problems that are double in size (of the input). Emerging quantum systems cannot yet tackle problems of practical interest, but rapid advances in hardware and algorithm development make now a great time to start thinking about their application. With this in mind, we explore the limits of scale of the problem for which quantum computing can solve NWV problems as unstructured search.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.17184v2</guid>
      <category>quant-ph</category>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <pubDate>Fri, 15 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3696348.3696891</arxiv:DOI>
      <dc:creator>Kahlil Dozier, Justin Beltran, Kylie Berg, Hugo Matousek, Loqman Salamatian, Ethan Katz-Bassett, Dan Rubenstein</dc:creator>
    </item>
  </channel>
</rss>
