<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CC</link>
    <description>cs.CC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 09 Dec 2025 05:00:27 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>On the hardness of recognizing graphs of small mim-width and its variants</title>
      <link>https://arxiv.org/abs/2512.06186</link>
      <description>arXiv:2512.06186v1 Announce Type: cross 
Abstract: The mim-width of a graph is a powerful structural parameter that, when bounded by a constant, allows several hard problems to be polynomial-time solvable - with a recent meta-theorem encompassing a large class of problems [SODA2023]. Since its introduction, several variants such as sim-width and omim-width were developed, along with a linear version of these parameters. It was recently shown that mim-width and all these variants all paraNP-hard, a consequence of the NP-hardness of distinguishing between graphs of linear mim-width at most 1211 and graphs of sim-width at least 1216 [ICALP2025]. The complexity of recognizing graphs of small width, particularly those close to $1$, remained open, despite their especially attractive algorithmic applications.
  In this work, we show that the width recognition problems remain NP-hard even on small widths. Specifically, after introducing the novel parameter Omim-width sandwiched between omim-width and mim-width, we show that: (1) deciding whether a graph has sim-width = 1, omim-width = 1, or Omin-width = 1 is NP-hard, and the same is true for their linear variants; (2) the problems of deciding whether mim-width $\leq$ 2 or linear mim-width $\leq$ 2 are both NP-hard. Interestingly, our reductions are relatively simple and are from the Unrooted Quartet Consistency problem, which is of great interest in computational biology but is not commonly used (if ever) in the theory of algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.06186v1</guid>
      <category>cs.DM</category>
      <category>cs.CC</category>
      <category>math.CO</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Max Dupr\'e la Tour, Manuel Lafond, Ndiam\'e Ndiaye</dc:creator>
    </item>
    <item>
      <title>Algebra in Algorithmic Coding Theory</title>
      <link>https://arxiv.org/abs/2512.06478</link>
      <description>arXiv:2512.06478v1 Announce Type: cross 
Abstract: We survey the notion and history of error-correcting codes and the algorithms needed to make them effective in information transmission. We then give some basic as well as more modern constructions of, and algorithms for, error-correcting codes that depend on relatively simple elements of applied algebra. While the role of algebra in the constructions of codes has been widely acknowledged in texts and other writings, the role in the design of algorithms is often less widely understood, and this survey hopes to reduce this difference to some extent.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.06478v1</guid>
      <category>cs.IT</category>
      <category>cs.CC</category>
      <category>math.IT</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Madhu Sudan</dc:creator>
    </item>
    <item>
      <title>Optimal Preconditioning is a Geodesically Convex Optimization Problem</title>
      <link>https://arxiv.org/abs/2512.06618</link>
      <description>arXiv:2512.06618v1 Announce Type: cross 
Abstract: We introduce a unified framework for computing approximately-optimal preconditioners for solving linear and non-linear systems of equations. We demonstrate that the condition number minimization problem, under structured transformations such as diagonal and block-diagonal preconditioners, is geodesically convex with respect to unitarily invariant norms, including the Frobenius and Bombieri--Weyl norms. This allows us to introduce efficient first-order algorithms with precise convergence guarantees. 
For linear systems, we analyze the action of symmetric Lie subgroups $G \subseteq \GL_m(\CC) \times \GL_n(\CC)$ on the input matrix and prove that the logarithm of the condition number is a smooth geodesically convex function on the associated Riemannian quotient manifold. We obtain explicit gradient formulas, show Lipschitz continuity, and prove convergence rates for computing the optimal Frobenius condition number: $\widetilde{O}(1/\eps^2)$ iterations for general two-sided preconditioners and $\widetilde{O}(\kappa_F^2 \log(1/\eps))$ for strongly convex cases such as left preconditioning. We extend our framework to consider preconditioning of polynomial systems $\f(x) = 0$, where $\f$ is a system of multivariate polynomials. We analyze the local condition number $\mu(\f, \xi)$, at a root $\xi$ and prove that it also admits a geodesically convex formulation under appropriate group actions. We deduce explicit formulas for the Riemannian gradients and present convergence bounds for the corresponding optimization algorithms. To the best of our knowledge, this is the first preconditioning algorithm with theoretical guarantees for polynomial systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.06618v1</guid>
      <category>math.OC</category>
      <category>cs.CC</category>
      <category>cs.NA</category>
      <category>math.AG</category>
      <category>math.NA</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>M. Levent Do\u{g}an, Alperen Erg\"ur, Elias Tsigaridas</dc:creator>
    </item>
    <item>
      <title>Virtual Qudits for Simon's Problem: Dimension-Lifted Algorithms on Qubit Hardware</title>
      <link>https://arxiv.org/abs/2512.06756</link>
      <description>arXiv:2512.06756v1 Announce Type: cross 
Abstract: Simon's problem admits an exponential quantum speedup, but current quantum devices support only qubits. This work introduces a general construction for simulating qudit versions of Simon's algorithm on qubit hardware by defining virtual qudits implemented through controlled permutations and qudit phase operations. We build a dimension lifted oracle that encodes the hidden shift in dimension d and show how to realize its action using only qubit gates. We mathematically verify that the lifted circuit reproduces the correct measurement statistics, analyze the depth overhead tradeoffs as a function of d, and provide numerical simulations in QuTiP for example values. Our approach demonstrates how higher-dimensional structures can be embedded into qubit devices and provides a general method for extending qudit algorithms to current hardware.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.06756v1</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Abed Semre (Computer Science Department, Technion - Israel Institute of Technology, Haifa, Israel), Steven Frankel (Faculty of Mechanical Engineering, Technion - Israel Institute of Technology, Haifa, Israel)</dc:creator>
    </item>
    <item>
      <title>An Analysis of Decision Problems for Relational Pattern Languages under Various Constraints</title>
      <link>https://arxiv.org/abs/2512.07476</link>
      <description>arXiv:2512.07476v1 Announce Type: cross 
Abstract: Patterns are words with terminals and variables. The language of a pattern is the set of words obtained by uniformly substituting all variables with words that contain only terminals. In their original definition, patterns only allow for multiple distinct occurrences of some variables to be related by the equality relation, represented by using the same variable multiple times. In an extended notion, called relational patterns and relational pattern languages, variables may be related by arbitrary other relations. We extend the ongoing investigation of the main decision problems for patterns (namely, the membership problem, the inclusion problem, and the equivalence problem) to relational pattern languages under a wide range of individual relations. It is shown show that - even for many much simpler or less restrictive relations - the complexity and (un)decidability characteristics of these problems do not change compared to the classical case where variables are related only by equality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.07476v1</guid>
      <category>cs.FL</category>
      <category>cs.CC</category>
      <category>math.CO</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Klaus Jansen, Dirk Nowotka, Lis Pirotton, Corinna Wambsganz, Max Wiedenh\"oft</dc:creator>
    </item>
    <item>
      <title>The Agent Capability Problem: Predicting Solvability Through Information-Theoretic Bounds</title>
      <link>https://arxiv.org/abs/2512.07631</link>
      <description>arXiv:2512.07631v1 Announce Type: cross 
Abstract: When should an autonomous agent commit resources to a task? We introduce the Agent Capability Problem (ACP), a framework for predicting whether an agent can solve a problem under resource constraints. Rather than relying on empirical heuristics, ACP frames problem-solving as information acquisition: an agent requires $\Itotal$ bits to identify a solution and gains $\Istep$ bits per action at cost $\Cstep$, yielding an effective cost $\Ceff = (\Itotal/\Istep), \Cstep$ that predicts resource requirements before search. We prove that $\Ceff$ lower-bounds expected cost and provide tight probabilistic upper bounds. Experimental validation shows that ACP predictions closely track actual agent performance, consistently bounding search effort while improving efficiency over greedy and random strategies. The framework generalizes across LLM-based and agentic workflows, linking principles from active learning, Bayesian optimization, and reinforcement learning through a unified information-theoretic lens. \</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.07631v1</guid>
      <category>cs.AI</category>
      <category>cs.CC</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shahar Lutati</dc:creator>
    </item>
    <item>
      <title>Exponential Lower Bounds on the Size of ResLin Proofs of Nearly Quadratic Depth</title>
      <link>https://arxiv.org/abs/2507.23008</link>
      <description>arXiv:2507.23008v2 Announce Type: replace 
Abstract: Itsykson and Sokolov [IS14] identified resolution over parities, denoted by $\text{Res}(\oplus)$, as a natural and simple fragment of $\text{AC}^0[2]$-Frege for which no super-polynomial lower bounds on size of proofs are known. Building on a recent line of work ([EGI24], [BCD24], [AI25]), Efremenko and Itsykson [EI25] proved lower bounds of the form $\text{exp}(N^{\Omega(1)})$, on the size of $\text{Res}(\oplus)$ proofs whose depth is upper bounded by $O(N\log N)$, where $N$ is the number of variables of the unsatisfiable CNF formula. The hard formula they used was Tseitin on an appropriately expanding graph, lifted by a $2$-stifling gadget. They posed the natural problem of proving super-polynomial lower bounds on the size of proofs that are $\Omega(N^{1+\epsilon})$ deep, for any constant $\epsilon &gt; 0$.
  We prove the first such lower bounds. In fact, we show that $\text{Res}(\oplus)$ refutations of Tseitin formulas on constant-degree expanders on $m$ vertices, lifted with Inner-Product gadget of size $O(\log m)$, must have size $\text{exp}(\tilde{\Omega}(N^{\epsilon}))$, as long as the depth of the $\text{Res}(\oplus)$ proofs are $O(N^{2-\epsilon})$, for every $\epsilon &gt; 0$. Here $N=\Theta(m\log m)$ is the number of variables of the lifted formula. An important ingredient in our work is to show that arbitrary distributions lifted with such gadgets fool safe affine spaces, an idea which originates in the earlier work of Bhattacharya, Chattopadhyay and Dvorak [BCD24].</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.23008v2</guid>
      <category>cs.CC</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sreejata Kishor Bhattacharya, Arkadev Chattopadhyay</dc:creator>
    </item>
    <item>
      <title>The Complexity of Logarithmic Space Bounded Counting Classes</title>
      <link>https://arxiv.org/abs/2507.23563</link>
      <description>arXiv:2507.23563v3 Announce Type: replace 
Abstract: In this monograph, we study complexity classes that are defined using $O(\log n)$-space bounded non-deterministic Turing machines. We prove salient results of Computational Complexity in this topic such as the Immerman-Szelepcs$\rm\acute{e}$nyi Theorem, the Isolating Lemma, theorems of Mahajan-Vinay on the determinant and many consequences of these very important results. The manuscript is intended to be a comprehensive textbook on the topic of The Complexity of Logarithmic Space Bounded Counting Classes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.23563v3</guid>
      <category>cs.CC</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>T. C. Vijayaraghavan</dc:creator>
    </item>
    <item>
      <title>Revealing POMDPs: Qualitative and Quantitative Analysis for Parity Objectives</title>
      <link>https://arxiv.org/abs/2511.13134</link>
      <description>arXiv:2511.13134v2 Announce Type: replace 
Abstract: Partially observable Markov decision processes (POMDPs) are a central model for uncertainty in sequential decision making. The most basic objective is the reachability objective, where a target set must be eventually visited, and the more general parity objectives can model all omega-regular specifications. For such objectives, the computational analysis problems are the following: (a) qualitative analysis that asks whether the objective can be satisfied with probability 1 (almost-sure winning) or probability arbitrarily close to 1 (limit-sure winning); and (b) quantitative analysis that asks for the approximation of the optimal probability of satisfying the objective. For general POMDPs, almost-sure analysis for reachability objectives is EXPTIME-complete, but limit-sure and quantitative analyses for reachability objectives are undecidable; almost-sure, limit-sure, and quantitative analyses for parity objectives are all undecidable. A special class of POMDPs, called revealing POMDPs, has been studied recently in several works, and for this subclass the almost-sure analysis for parity objectives was shown to be EXPTIME-complete. In this work, we show that for revealing POMDPs the limit-sure analysis for parity objectives is EXPTIME-complete, and even the quantitative analysis for parity objectives can be achieved in EXPTIME.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.13134v2</guid>
      <category>cs.CC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Ali Asadi, Krishnendu Chatterjee, David Lurie, Raimundo Saona</dc:creator>
    </item>
    <item>
      <title>On the Incompressibility of Truth With Application to Circuit Complexity</title>
      <link>https://arxiv.org/abs/2511.21738</link>
      <description>arXiv:2511.21738v2 Announce Type: replace 
Abstract: We revisit the fundamentals of Circuit Complexity and the nature of efficient computation from a new perspective. We present a framework for understanding Circuit Complexity through the lens of Information Theory with analogies to results in Kolmogorov Complexity, viewing circuits as descriptions of truth tables, encoded in logical gates and wires, rather than purely computational devices. From this framework, we re-prove some existing strong Circuit Complexity bounds, explain what the optimal circuits for most Boolean functions look like structurally, give insight into new circuit bounds, and explain the aforementioned results in a unifying intuition that re-frames time entirely.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.21738v2</guid>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luke Tonon</dc:creator>
    </item>
    <item>
      <title>The Optimal Approximation Factor in Density Estimation</title>
      <link>https://arxiv.org/abs/1902.05876</link>
      <description>arXiv:1902.05876v4 Announce Type: replace-cross 
Abstract: Consider the following problem: given two arbitrary densities $q_1,q_2$ and a sample-access to an unknown target density $p$, find which of the $q_i$'s is closer to $p$ in total variation.
  A remarkable result due to Yatracos shows that this problem is tractable in the following sense: there exists an algorithm that uses $O(\epsilon^{-2})$ samples from $p$ and outputs~$q_i$ such that with high probability, $TV(q_i,p) \leq 3\cdot\mathsf{opt} + \epsilon$, where $\mathsf{opt}= \min\{TV(q_1,p),TV(q_2,p)\}$. Moreover, this result extends to any finite class of densities $\mathcal{Q}$: there exists an algorithm that outputs the best density in $\mathcal{Q}$ up to a multiplicative approximation factor of 3.
  We complement and extend this result by showing that: (i) the factor 3 can not be improved if one restricts the algorithm to output a density from $\mathcal{Q}$, and (ii) if one allows the algorithm to output arbitrary densities (e.g.\ a mixture of densities from $\mathcal{Q}$), then the approximation factor can be reduced to 2, which is optimal. In particular this demonstrates an advantage of improper learning over proper in this setup.
  We develop two approaches to achieve the optimal approximation factor of 2: an adaptive one and a static one. Both approaches are based on a geometric point of view of the problem and rely on estimating surrogate metrics to the total variation. Our sample complexity bounds exploit techniques from {\it Adaptive Data Analysis}.</description>
      <guid isPermaLink="false">oai:arXiv.org:1902.05876v4</guid>
      <category>cs.LG</category>
      <category>cs.CC</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Olivier Bousquet, Daniel Kane, Shay Moran</dc:creator>
    </item>
  </channel>
</rss>
