<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 16 Feb 2026 05:00:17 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 16 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Real-Time Dynamic N-1 Screening: Identifying High-Risk Lines and Transformers After Common Faults</title>
      <link>https://arxiv.org/abs/2602.12293</link>
      <description>arXiv:2602.12293v1 Announce Type: new 
Abstract: Power system operators routinely perform N-1 contingency analysis, yet conventional tools provide limited guidance on which lines or transformers deserve heightened attention during fast post-fault transients. In particular, static screening does not reveal whether (1) the same faulted line repeatedly triggers severe downstream overloads, or (2) a specific transformer emerges as vulnerable across many distinct fault scenarios. This paper introduces a real-time dynamic N-1 screening framework that addresses this gap by estimating, for each counterfactual single-phase transmission fault, the probability of transient overcurrent on critical grid elements. The output is an operator-facing dashboard that ranks (a) faulted lines whose outages most frequently lead to dangerous transformer overloads, and (b) transformers that consistently overload across top-risk scenarios, both of which are actionable indicators for real-time situational awareness. The approach models post-fault electromechanical dynamics using a linear stochastic formulation of the swing equations with short-lived, fault-localized uncertainty, and combines analytic transient evaluation with cross-entropy based importance sampling to efficiently estimate rare but high-impact events. All N-1 contingencies are evaluated in parallel with linear computational complexity. The framework is demonstrated on the IEEE 118-bus system, where it reveals latent high-risk lines and transformers that remain invisible under deterministic dynamic or static N-1 analysis. Results show orders-of-magnitude computational speedup relative to brute-force Monte Carlo, enabling practical deployment within real-time operational cycles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.12293v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 16 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ayrton Almada (Misha), Laurent Pagnier (Misha), Igal Goldshtein (Misha), Saif R. Kazi (Misha),  Michael (Misha),  Chertkov</dc:creator>
    </item>
    <item>
      <title>Existence Results and KKT Optimality Conditions for Generalized Quasiconvex Functions</title>
      <link>https://arxiv.org/abs/2602.12455</link>
      <description>arXiv:2602.12455v1 Announce Type: new 
Abstract: We studied a new notion of generalized convex functions called $e$-quasi\-con\-ve\-xi\-ty, which encompasses both quasiconvex and $e$-convex functions, including all Lipschitz functions. By extending the standard properties of quasiconvex functions to $e$-quasiconvex functions, we establish sufficient conditions for the nonemptiness and compactness of the solution set when minimizing an $e$-quasiconvex function, leveraging generalized asymptotic functions, a result which remains applicable even when the set of minimizers is nonconvex. Furthermore, in the differentiable case, we ensure the sufficiency of the KKT optimality conditions when the constraint functions in the mathematical programming problems are $e$-quasiconvex. Finally, we illustrate our new results with several nonconvex (non-quasiconvex) examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.12455v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 16 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>M. H. Alizadeh, F. Lara</dc:creator>
    </item>
    <item>
      <title>An LP-Based Approach for Bilinear Saddle Point Problem with Instance-dependent Guarantee and Noisy Feedback</title>
      <link>https://arxiv.org/abs/2602.12513</link>
      <description>arXiv:2602.12513v1 Announce Type: new 
Abstract: In this work, we study the sample complexity of obtaining a Nash equilibrium (NE) estimate in two-player zero-sum matrix games with noisy feedback. Specifically, we propose a novel algorithm that repeatedly solves linear programs (LPs) to obtain an NE estimate with bias at most $\varepsilon$ with a sample complexity of $O\left(\frac{m_1 m_2}{\varepsilon\min\{\delta^2,\sigma_0^2,\sigma^3\}} \log\frac{m_1 m_2}{\varepsilon}\right)$ for general $m_1 \times m_2$ game matrices, where $\sigma$, $\sigma_0$, $\delta$ are some problem-dependent constants. To our knowledge, this is the first instance-dependent sample complexity bound for finding an NE estimate with $\varepsilon$ bias in general-dimension matrix games with noisy feedback and potentially non-unique equilibria. Our algorithm builds on recent advances in online resource allocation and operates in two stages: (1) identifying the support set of an NE, and (2) computing the unique NE restricted to this support. Both stages rely on a careful analysis of LP solutions derived from noisy samples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.12513v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 16 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiashuo Jiang, Mengxiao Zhang</dc:creator>
    </item>
    <item>
      <title>Optimal bounds for the cost of fast controls of a KdV system</title>
      <link>https://arxiv.org/abs/2602.12698</link>
      <description>arXiv:2602.12698v1 Announce Type: new 
Abstract: We study the cost of fast controls for a linearized KdV system and a nonlinear KdV system locally, using right Neumann boundary control for non-critical lengths. Since the operator associated with the linearized system is neither self-adjoint nor skew-adjoint, its (known) spectral properties are not directly amenable to the moment method, leaving optimal cost bounds an open problem. We address this difficulty by shifting attention to a related KdV system and deriving the optimal bounds from the new one.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.12698v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Mon, 16 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Hoai-Minh Nguyen</dc:creator>
    </item>
    <item>
      <title>Constrained Mean Field Games with Grushin type dynamics</title>
      <link>https://arxiv.org/abs/2602.12807</link>
      <description>arXiv:2602.12807v1 Announce Type: new 
Abstract: This paper is devoted to a class of finite horizon deterministic mean field games with Grushin type dynamics, state constraints and nonlocal coupling. First, we consider the optimal control problem that each agent aims to solve when the evolution of the population is given and we establish some properties as: the existence of an optimal trajectory for any starting point $(x,t)$, the closed graph property for the multivalued map which associates to each point $(x,t)$ the set of optimal trajectories starting from that point, endowed with a suitable notion of convergence, the continuity of the value function. The main issue to overcome is due to the local interplay at boundary points between the set of state constraints and the degenerate dynamics. To this end, we shall point out two different sets of assumptions which are both sufficient for these properties. Afterwards, we tackle the mean field games; taking advantage of the aforementioned properties, we prove the existence of a relaxed equilibrium (which describes the evolution of the game in terms of a probability on the set of admissible trajectories) and derive the existence of a mild solution (which is a couple formed by the value function for the generic player and a family of time dependent measures on the state).</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.12807v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 16 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Alessandra Cutr\`i, Paola Mannucci, Claudio Marchi, Nicoletta Tchou</dc:creator>
    </item>
    <item>
      <title>Explicit data-dependent characterizations of the subdifferential of convex pointwise suprema and optimality conditions</title>
      <link>https://arxiv.org/abs/2602.12821</link>
      <description>arXiv:2602.12821v1 Announce Type: new 
Abstract: We establish explicit data-dependent and symmetric characterizations of the subdifferential of the supremum of convex functions, formulated directly in terms of the underlying data functions. In our approach, both active and non-active functions contribute equally through their subdifferentials, thereby avoiding the need for additional geometric constructions, such as the domain of the supremum, that arise in previous developments. Applications to infinite convex optimization yield sharp Karush-Kuhn-Tucker and Fritz-John optimality conditions, expressed exclusively in terms of the objective and constraint functions and clearly distinguishing the roles of (almost) active and non-active constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.12821v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 16 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Stephanie Caro, Abderrahim Hantoute</dc:creator>
    </item>
    <item>
      <title>Parametric Biobjective Linear Programming</title>
      <link>https://arxiv.org/abs/2602.12867</link>
      <description>arXiv:2602.12867v1 Announce Type: new 
Abstract: We consider parametric linear programming problems with multiple objective functions depending linearly on some parameter. Both parametric (single-objective) linear programming and (non-parametric) multi-objective linear programming are well-researched topics. However, literature on the combination of both, parametric linear programming with multiple objectives, is scarce. This research gap encourages our work in this field. Our main focus is on biobjective linear programs with a single parameter. We establish a connection of this problem to non-parametric multi-objective problems. Using the so-called weight set decomposition, we are able to explain the behavior of parametric biobjective linear programs when the parameter value is variated. We investigate two special cases of parametric biobjective linear programs: In the first, there is only one parametric objective and, in the second, the parametric dependency is the same for both objectives. We prove that there is a one-to-one correspondence between the solution of the parametric program and the solution of the triobjective program using the weighted sum scalarization. We provide structural insights to the solution of the parametric biobjective linear program with respect to extreme weights of the weight set of the triobjective linear program and develop solution strategies for the parametric program.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.12867v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 16 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Kezang Yuden, Levin Nemesch, Stefan Ruzika</dc:creator>
    </item>
    <item>
      <title>Well-posedness and mean-field limit estimate of a consensus-based algorithm for min-max problems</title>
      <link>https://arxiv.org/abs/2602.12886</link>
      <description>arXiv:2602.12886v1 Announce Type: new 
Abstract: The recent work arXiv:2407.17373 proposes a derivative-free consensus-based particle method that computes global solutions to nonconvex-nonconcave min-max problems and establishes global exponential convergence in the sense of the mean-field law. This paper aims to address the theoretical gaps in arXiv:2407.17373, specifically by providing a quantitative estimate of the mean-field limit with respect to the number of particles, as well as establishing the well-posedness of both the finite particle model and the corresponding mean-field dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.12886v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 16 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hui Huang, Jethro Warnett</dc:creator>
    </item>
    <item>
      <title>A Stochastic Optimal Control Formulation for Mine Counter Measure Simulations with Multiple Autonomous Survey Vehicles</title>
      <link>https://arxiv.org/abs/2602.12935</link>
      <description>arXiv:2602.12935v1 Announce Type: new 
Abstract: Modelling and simulating mine counter measure search missions performed by autonomous vehicles equipped with a sensor capable of detecting mines at sea is a challenging endeavour. To address this, we formulated and implemented the problem as a stochastic optimal control model. Our implementation computes an optimal path within a user chosen quadrilateral domain such that the mission duration is minimized for a given residual risk of undetected sea mines. First, we compare the stochastic optimal control implementation against the traditionally used boustrophedon implementation. We show that the mission duration in case of the stochastic optimal control implementation is shorter. Then, by building on our previous work, we introduce a novel mathematical approach that enables multiple autonomous survey vehicles to investigate the domain concurrently. We present results for up to six vehicles, including computed trajectories and an analysis of how mission duration varies with the number of vehicles. Our findings show that mission time decreases non-linearly, , i.e., we observe diminishing returns as more vehicles are added.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.12935v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 16 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Philippe Blondeel, Filip Van Utterbeeck, Ben Lauwens</dc:creator>
    </item>
    <item>
      <title>A linesearch-type normal map-based semismooth Newton method for nonsmooth nonconvex composite optimization</title>
      <link>https://arxiv.org/abs/2602.13000</link>
      <description>arXiv:2602.13000v1 Announce Type: new 
Abstract: We propose a novel linesearch variant of the trust region normal map-based semismooth Newton method developed in [Ouyang and Milzarek, Math. Program. 212(1-2), 389--435 (2025)] for solving a class of nonsmooth, nonconvex composite-type optimization problems. Our approach uses adaptive parameter estimation techniques, which allow us to avoid explicit and potentially expensive Lipschitz constant computations. We provide extensive convergence results including global convergence, convergence of the iterates under the Kurdyka-{\L}ojasiewicz inequality, and transition to fast local q-superlinear convergence. Compared to the original trust region framework, the linesearch-based algorithm is simpler and the overall convergence analysis can be conducted under weaker assumptions -- in particular, without requiring explicit boundedness conditions on the Hessian approximations and iterates. Numerical experiments on sparse logistic regression, image compression, and nonlinear least squares with group penalty terms demonstrate the efficiency of the proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.13000v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 16 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s10589-025-00754-0</arxiv:DOI>
      <arxiv:journal_reference>Comput. Optim. Appl. (2026)</arxiv:journal_reference>
      <dc:creator>Hanfeng Zeng, Wenqing Ouyang, Andre Milzarek</dc:creator>
    </item>
    <item>
      <title>Optimizing Initial Feature-Mapping Variables from Given Designs via Tracking</title>
      <link>https://arxiv.org/abs/2602.13005</link>
      <description>arXiv:2602.13005v1 Announce Type: new 
Abstract: A feature-mapping framework for inverse reconstruction of density-based topology optimization results is proposed. Unlike SIMP, whose voxelized outputs are hard to interpret or reuse, the method represents designs with high-level geometric primitives mapped to a fixed analysis grid. Capsule-shaped bars (endpoints plus radius) are used, with closed-form signed distances and smooth transition functions providing derivatives up to second order. Differentiable pseudo-densities are aggregated with smooth operators, enabling gradient-based optimization with exact Hessians. Robustness is improved through asymmetric transition functions that propagate sensitivities into void regions, a reward-only objective for initialization, and geometric safeguards against degenerate configurations. Reconstruction is performed in stages (exploration, bridging, convergence) with optional refinement that can add, remove, or merge features based on residuals and geometric criteria. Experiments on canonical SIMP benchmarks, including five-bar and cantilever layouts, show high-fidelity reconstructions using a moderate number of features. p-norm and softmax aggregation yield sharp results; pruning removes redundant features and additive refinement restores coverage. Exact Hessians accelerate convergence and improve robustness compared to quasi-Newton updates, providing a bridge from voxel-based outputs to explicit parametric models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.13005v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 16 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Patrick Jung (Friedrich-Alexander-Universitaet Erlangen-Nuernberg)</dc:creator>
    </item>
    <item>
      <title>Multi-type random game dynamics: limits at discontinuities and cyclic limits</title>
      <link>https://arxiv.org/abs/2602.13032</link>
      <description>arXiv:2602.13032v1 Announce Type: new 
Abstract: We consider (random) strategic interactions in a large population consisting of a variety of players. A rational player chooses actions that maximize certain utility functions, while a behavioral player chooses actions based on preferences such as avoid-the-crowd or follow-the-majority. We specifically study a turn-by-turn dynamic process in which players choose their actions sequentially and once; the utilities are realized either immediately or at the end of the game.
  In the literature, such dynamical systems are often analyzed using an appropriate approximating ordinary differential equation (ODE). However, the ODEs approximating the dynamics with pure actions are typically discontinuous. We adopt a differential inclusion (DI) based stochastic-approximation framework to derive the limiting analysis. The limits of the dynamics are characterized through the internally chain transitive (ICT) sets. We identify the presence of non-classical zeros as potential limits of the dynamics, a phenomenon not observed in classical settings involving continuous ODEs. These new limits arise precisely at the points of discontinuity of the dynamics. We further provide the conditions under which cyclic outcomes may occur at the limit.
  Finally, we study a queuing game with differential priority-based services and examine the impact of the proportions of avoid-the-crowd and two types of rational populations on the long-run outcomes of the strategic interactions. We identify potential point limits and establish the possibility of cyclic outcomes for certain parameter configurations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.13032v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 16 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Raghupati Vyas, Kousik Das, Veeraruna Kavitha, Souvik Roy</dc:creator>
    </item>
    <item>
      <title>Reinterpreting EMML as Mirror Descent for Constrained Maximum Likelihood Estimation</title>
      <link>https://arxiv.org/abs/2602.13063</link>
      <description>arXiv:2602.13063v1 Announce Type: new 
Abstract: The Expectation--Maximization Maximum Likelihood (EMML) algorithm belongs to the Expectation--Maximization family and is widely used for image reconstruction problems under Poisson noise.In this paper, we reinterpret EMML as a mirror descent method applied to a reparametrized objective function. This perspective allows us to incorporate convex constraints into the algorithm through appropriately chosen Bregman projections, while preserving the multiplicative structure of the EMML updates to ensure computational efficiency. We then establish the convergence of the resulting algorithm toward a solution of the constrained maximum-likelihood problem. Numerical experiments on hyperspectral unmixing problems demonstrate that the constrained EMML converges in fewer iterations than the classical EMML.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.13063v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 16 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Antonin Clerc, S\'egol\`ene Martin, Nicolas Papadakis, Gabriele Steidl</dc:creator>
    </item>
    <item>
      <title>New gradient methods with 3 dimensional quadratic termination</title>
      <link>https://arxiv.org/abs/2602.13141</link>
      <description>arXiv:2602.13141v1 Announce Type: new 
Abstract: A new stepsize for gradient method is proposed. Combining it with the exact line search stepsizes, the gradient method achieves the optimal solution in 5 steps for 3 dimensional quadratic function minimization problem. The new stepsize is plugged in the cyclic stepsize update strategy, and a new gradient method is proposed. By applying the quadratic interpolation for Cauchy approximation, the proposed gradient method is extended to solve general unconstrained problem. With the improved GLL line search, the global convergence of the proposed method is proved. Furthermore, its sublinear convergence rate for convex problems and R-linear convergence rate for problems with quadratic functional growth property are analyzed. Numerical results show that our proposed algorithm enjoys good performances in terms of computational cost, and line search requires very few trial stepsizes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.13141v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 16 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yixin Xie, Jin-Peng Liu, Cong Sun, Ya-Xiang Yuan</dc:creator>
    </item>
    <item>
      <title>A Data-Driven Algorithm for Model-Free Control Synthesis</title>
      <link>https://arxiv.org/abs/2602.13157</link>
      <description>arXiv:2602.13157v1 Announce Type: new 
Abstract: Presented is an algorithm to synthesize the optimal infinite-horizon LQR feedback controller for continuous-time systems. The algorithm does not require knowledge of the system dynamics but instead uses only a finite-length sampling of arbitrary input-output data. The algorithm is based on a constrained optimization problem that enforces a necessary condition on the dynamics of the optimal value function along any trajectory. In addition to calculating the standard LQR gain matrix, a feedforward gain can be found to implement a reference tracking controller. This paper presents a theoretical justification for the method and shows several examples, including a validation test on a real scale aircraft.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.13157v1</guid>
      <category>math.OC</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 16 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sean Bowerfind, Matthew R. Kirchner, Gary Hewer</dc:creator>
    </item>
    <item>
      <title>Operator Learning for Families of Finite-State Mean-Field Games</title>
      <link>https://arxiv.org/abs/2602.13169</link>
      <description>arXiv:2602.13169v1 Announce Type: new 
Abstract: Finite-state mean-field games (MFGs) arise as limits of large interacting particle systems and are governed by an MFG system, a coupled forward-backward differential equation consisting of a forward Kolmogorov-Fokker-Planck (KFP) equation describing the population distribution and a backward Hamilton-Jacobi-Bellman (HJB) equation defining the value function. Solving MFG systems efficiently is challenging, with the structure of each system depending on an initial distribution of players and the terminal cost of the game. We propose an operator learning framework that solves parametric families of MFGs, enabling generalization without retraining for new initial distributions and terminal costs. We provide theoretical guarantees on the approximation error, parametric complexity, and generalization performance of our method, based on a novel regularity result for an appropriately defined flow map corresponding to an MFG system. We demonstrate empirically that our framework achieves accurate approximation for two representative instances of MFGs: a cybersecurity example and a high-dimensional quadratic model commonly used as a benchmark for numerical methods for MFGs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.13169v1</guid>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Mon, 16 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>William Hofgard, Asaf Cohen, Mathieu Lauri\`ere</dc:creator>
    </item>
    <item>
      <title>Improved Regret Guarantees for Online Mirror Descent using a Portfolio of Mirror Maps</title>
      <link>https://arxiv.org/abs/2602.13177</link>
      <description>arXiv:2602.13177v1 Announce Type: new 
Abstract: OMD and its variants give a flexible framework for OCO where the performance depends crucially on the choice of the mirror map. While the geometries underlying OPGD and OEG, both special cases of OMD, are well understood, it remains a challenging open question on how to construct an optimal mirror map for any given constrained set and a general family of loss functions, e.g., sparse losses. Motivated by parameterizing a near-optimal set of mirror maps, we consider a simpler question: is it even possible to obtain polynomial gains in regret by using mirror maps for geometries that interpolate between $L_1$ and $L_2$, which may not be possible by restricting to only OEG ($L_1$) or OPGD ($L_2$).
  Our main result answers this question positively. We show that mirror maps based on block norms adapt better to the sparsity of loss functions, compared to previous $L_p$ (for $p \in [1, 2]$) interpolations. In particular, we construct a family of online convex optimization instances in $\mathbb{R}^d$, where block norm-based mirror maps achieve a provable polynomial (in $d$) improvement in regret over OEG and OPGD for sparse loss functions. We then turn to the setting in which the sparsity level of the loss functions is unknown. In this case, the choice of geometry itself becomes an online decision problem. We first show that naively switching between OEG and OPGD can incur linear regret, highlighting the intrinsic difficulty of geometry selection. To overcome this issue, we propose a meta-algorithm based on multiplicative weights that dynamically selects among a family of uniform block norms. We show that this approach effectively tunes OMD to the sparsity of the losses, yielding adaptive regret guarantees. Overall, our results demonstrate that online mirror-map selection can significantly enhance the ability of OMD to exploit sparsity in online convex optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.13177v1</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Mon, 16 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Swati Gupta, Jai Moondra, Mohit Singh</dc:creator>
    </item>
    <item>
      <title>Effective dynamics and defect expansions for polynomial PDEs on thin annuli</title>
      <link>https://arxiv.org/abs/2602.12308</link>
      <description>arXiv:2602.12308v1 Announce Type: cross 
Abstract: We develop a geometric and analytic framework for polynomial partial differential equations posed on thin annuli in the plane. Using renormalized Sobolev inner products, we construct Sobolev orthogonal polynomial bases adapted to the thin geometry and use them to define stable Galerkin approximations.
  We prove a general dimension-reduction theorem for polynomial Hamiltonian and dissipative PDEs, showing that solutions converge to effective one-dimensional dynamics on the limiting circle. Beyond the leading-order limit, we identify transverse defect correctors and derive cell problems describing anisotropic dispersive and homogenized effects.
  Our framework applies uniformly to integrable models (KdV, modified KdV, nonlinear Schr\"odinger, sine--Gordon), anisotropic dispersive systems such as Zakharov--Kuznetsov, and non-integrable perturbations including dissipation, forcing, and rapidly oscillating coefficients. We establish stability of the effective dynamics under changes of Sobolev order and of polynomial Hilbert geometry, and show robustness of the associated Galerkin schemes.
  The results provide a unified geometric perspective on dimension reduction, homogenization, and integrability in thin geometries, and introduce Sobolev orthogonal polynomial methods as a constructive tool for multiscale PDE analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.12308v1</guid>
      <category>nlin.SI</category>
      <category>hep-th</category>
      <category>math-ph</category>
      <category>math.AP</category>
      <category>math.MP</category>
      <category>math.OC</category>
      <pubDate>Mon, 16 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jean-Pierre Magnot</dc:creator>
    </item>
    <item>
      <title>An Autonomous, End-to-End, Convex-Based Framework for Close-Range Rendezvous Trajectory Design and Guidance with Hardware Testbed Validation</title>
      <link>https://arxiv.org/abs/2602.12421</link>
      <description>arXiv:2602.12421v1 Announce Type: cross 
Abstract: Autonomous satellite servicing missions must execute close-range rendezvous under stringent safety and operational constraints while remaining computationally tractable for onboard use and robust to uncertainty in sensing, actuation, and dynamics. This paper presents CORTEX (Convex Optimization for Rendezvous Trajectory Execution), an autonomous, perception-enabled, real-time trajectory design and guidance framework for close-range rendezvous. CORTEX integrates a deep-learning perception pipeline with convex-optimisation-based trajectory design and guidance, including reference regeneration and abort-to-safe-orbit logic to recover from large deviations caused by sensor faults and engine failures.
  CORTEX is validated in high-fidelity software simulation and hardware-in-the-loop experiments. The software pipeline (Basilisk) models high-fidelity relative dynamics, realistic thruster execution, perception, and attitude control. Hardware testing uses (i) an optical navigation testbed to assess perception-to-estimation performance and (ii) a planar air-bearing testbed to evaluate the end-to-end guidance loop under representative actuation and subsystem effects. A Monte-Carlo campaign in simulation includes initial-state uncertainty, thrust-magnitude errors, and missed-thrust events; under the strongest case investigated, CORTEX achieves terminal docking errors of $36.85 \pm 44.46$ mm in relative position and $1.25 \pm 2.26$ mm/s in relative velocity. On the planar air-bearing testbed, 18 cases are executed (10 nominal; 8 off-nominal requiring recomputation and/or abort due to simulated engine failure and sensor malfunctions), yielding terminal errors of $8.09 \pm 5.29$ mm in position and $2.23 \pm 1.72$ mm/s in velocity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.12421v1</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <pubDate>Mon, 16 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Minduli C. Wijayatunga, Julian Guinane, Nathan D. Wallace, Xiaofeng Wu</dc:creator>
    </item>
    <item>
      <title>Dynamic Programming Principle and Stabilization for Mean-Field Quantum Filtering Systems</title>
      <link>https://arxiv.org/abs/2602.12472</link>
      <description>arXiv:2602.12472v1 Announce Type: cross 
Abstract: Working within the quantum filtering framework, we establish a dynamic programming principle in an infinite-dimensional setting by embedding the state space into the Hilbert-Schmidt space. We then study a stabilization problem for continuously monitored Ising-coupled qubits and, in the mean-field limit, demonstrate quantum state reduction together with exponential convergence toward prescribed eigenstates under suitable feedback laws.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.12472v1</guid>
      <category>quant-ph</category>
      <category>math.OC</category>
      <pubDate>Mon, 16 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sofiane Chalal, Nina H. Amini, Hamed Amini, Mathieu Lauri\`ere</dc:creator>
    </item>
    <item>
      <title>Bench-MFG: A Benchmark Suite for Learning in Stationary Mean Field Games</title>
      <link>https://arxiv.org/abs/2602.12517</link>
      <description>arXiv:2602.12517v1 Announce Type: cross 
Abstract: The intersection of Mean Field Games (MFGs) and Reinforcement Learning (RL) has fostered a growing family of algorithms designed to solve large-scale multi-agent systems. However, the field currently lacks a standardized evaluation protocol, forcing researchers to rely on bespoke, isolated, and often simplistic environments. This fragmentation makes it difficult to assess the robustness, generalization, and failure modes of emerging methods. To address this gap, we propose a comprehensive benchmark suite for MFGs (Bench-MFG), focusing on the discrete-time, discrete-space, stationary setting for the sake of clarity. We introduce a taxonomy of problem classes, ranging from no-interaction and monotone games to potential and dynamics-coupled games, and provide prototypical environments for each. Furthermore, we propose MF-Garnets, a method for generating random MFG instances to facilitate rigorous statistical testing. We benchmark a variety of learning algorithms across these environments, including a novel black-box approach (MF-PSO) for exploitability minimization. Based on our extensive empirical results, we propose guidelines to standardize future experimental comparisons. Code available at \href{https://github.com/lorenzomagnino/Bench-MFG}{https://github.com/lorenzomagnino/Bench-MFG}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.12517v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <category>math.OC</category>
      <pubDate>Mon, 16 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lorenzo Magnino, Jiacheng Shen, Matthieu Geist, Olivier Pietquin, Mathieu Lauri\`ere</dc:creator>
    </item>
    <item>
      <title>About a Ball Removal Process on Bins</title>
      <link>https://arxiv.org/abs/2602.12523</link>
      <description>arXiv:2602.12523v1 Announce Type: cross 
Abstract: Consider the following process whereby $n$ balls are distributed into $k$ bins. Repeatedly, a ball is removed from a non-empty bin chosen uniformly at random. The process ends when a single non-empty bin remains. Will Ma (see~\cite[Sec.~1.1]{GS24}) asked whether the initial assignment that minimizes the expected number of remaining balls is one that is as balanced as possible. Using a coupling argument we answer this conjecture positively, and we discuss the case of non-uniform choice among the non-empty bins.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.12523v1</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <pubDate>Mon, 16 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jose Correa, Marcos Kiwi, Vasilis Livanos, Eilon Solan, Ron Solan</dc:creator>
    </item>
    <item>
      <title>AdaGrad-Diff: A New Version of the Adaptive Gradient Algorithm</title>
      <link>https://arxiv.org/abs/2602.13112</link>
      <description>arXiv:2602.13112v1 Announce Type: cross 
Abstract: Vanilla gradient methods are often highly sensitive to the choice of stepsize, which typically requires manual tuning. Adaptive methods alleviate this issue and have therefore become widely used. Among them, AdaGrad has been particularly influential. In this paper, we propose an AdaGrad-style adaptive method in which the adaptation is driven by the cumulative squared norms of successive gradient differences rather than gradient norms themselves. The key idea is that when gradients vary little across iterations, the stepsize is not unnecessarily reduced, while significant gradient fluctuations, reflecting curvature or instability, lead to automatic stepsize damping. Numerical experiments demonstrate that the proposed method is more robust than AdaGrad in several practically relevant settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.13112v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 16 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matia Bojovic, Saverio Salzo, Massimiliano Pontil</dc:creator>
    </item>
    <item>
      <title>Continuous-time q-Learning for Jump-Diffusion Models under Tsallis Entropy</title>
      <link>https://arxiv.org/abs/2407.03888</link>
      <description>arXiv:2407.03888v4 Announce Type: replace 
Abstract: This paper studies the continuous-time reinforcement learning in jump-diffusion models by featuring the q-learning (the continuous-time counterpart of Q-learning) under Tsallis entropy regularization. Contrary to the Shannon entropy, the general form of Tsallis entropy renders the optimal policy not necessarily a Gibbs measure. Herein, the Lagrange multiplier and KKT condition are needed to ensure that the learned policy is a probability density function. As a consequence, the characterization of the optimal policy using the q-function also involves a Lagrange multiplier. In response, we establish the martingale characterization of the q-function and devise two q-learning algorithms depending on whether the Lagrange multiplier can be derived explicitly or not. In the latter case, we consider different parameterizations of the optimal q-function and the optimal policy, and update them alternatively in an Actor-Critic manner. We also study two numerical examples, namely, an optimal liquidation problem in dark pools and a non-LQ control problem. It is interesting to see therein that the optimal policies under the Tsallis entropy regularization can be characterized explicitly, which are distributions concentrated on some compact support. The satisfactory performance of our q-learning algorithms is illustrated in each example.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03888v4</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Mon, 16 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lijun Bo, Yijie Huang, Xiang Yu, Tingting Zhang</dc:creator>
    </item>
    <item>
      <title>Measure-to-measure interpolation using Transformers</title>
      <link>https://arxiv.org/abs/2411.04551</link>
      <description>arXiv:2411.04551v3 Announce Type: replace 
Abstract: Transformers are deep neural network architectures that underpin the recent successes of large language models. Unlike more classical architectures that can be viewed as point-to-point maps, a Transformer acts as a measure-to-measure map implemented as specific interacting particle system on the unit sphere: the input is the empirical measure of tokens in a prompt and its evolution is governed by the continuity equation. In fact, Transformers are not limited to empirical measures and can in principle process any input measure. As the nature of data processed by Transformers is expanding rapidly, it is important to investigate their expressive power as maps from an arbitrary measure to another arbitrary measure. To that end, we provide an explicit choice of parameters that allows a single Transformer to match $N$ arbitrary input measures to $N$ arbitrary target measures, under the minimal assumption that every pair of input-target measures can be matched by some transport map.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04551v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Mon, 16 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Borjan Geshkovski, Philippe Rigollet, Dom\`enec Ruiz-Balet</dc:creator>
    </item>
    <item>
      <title>Optimization under uncertainty: understanding orders and testing programs with specifications</title>
      <link>https://arxiv.org/abs/2503.18561</link>
      <description>arXiv:2503.18561v3 Announce Type: replace 
Abstract: One of the most ubiquitous problems in optimization is that of finding all the elements of a finite set at which a function $f$ attains its minimum (or maximum). When the codomain of $f$ is equipped with a total order, it is easy to specify, implement, and verify generic solutions to this problem. But what if $f$ is affected by uncertainties? What if one seeks values that minimize more than one objective, or if $f$ does not return a single result but a set of possible results, or even a probability distribution? Such situations are common in climate science, economics, and engineering. Developing trustworthy solution methods for optimization under uncertainty requires formulating and answering these questions rigorously, including deciding which order relations to apply in different cases. We show how functional programming can support this task, and apply it to specify and test solution methods for cases where optimization is affected by two conceptually different kinds of uncertainty: value and functorial uncertainty. We analyze the interplay of orders in these contexts, demonstrate how standard minimization generalizes to partial orders in the multi-objective setting and how it can be lifted via monotonicity conditions to handle functorial uncertainty.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.18561v3</guid>
      <category>math.OC</category>
      <category>cs.SE</category>
      <pubDate>Mon, 16 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Patrik Jansson, Nicola Botta, Tim Richter</dc:creator>
    </item>
    <item>
      <title>Asymmetric Perturbation in Solving Bilinear Saddle-Point Optimization</title>
      <link>https://arxiv.org/abs/2506.05747</link>
      <description>arXiv:2506.05747v2 Announce Type: replace 
Abstract: This paper proposes an asymmetric perturbation technique for solving bilinear saddle-point optimization problems, commonly arising in minimax problems, game theory, and constrained optimization. Perturbing payoffs or values is known to be effective in stabilizing learning dynamics and equilibrium computation. However, it requires decreasing perturbation magnitudes to ensure convergence to an equilibrium in the underlying game, resulting in a slower rate. To overcome this, we introduce an asymmetric perturbation approach, where only one player's payoff function is perturbed. Exploiting the near-linear structure of bilinear problems, we show that, for a sufficiently small perturbation, the equilibrium strategy of the asymmetrically perturbed game coincides with an equilibrium strategy of the original game. Building on this property, we develop a perturbation-based learning algorithm with a linear last-iterate convergence rate to an equilibrium strategy of the original game, and we further show how to construct a parameter-free procedure that retains a linear rate. Finally, we empirically demonstrate fast convergence toward equilibria in both normal-form and extensive-form games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.05747v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 16 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kenshi Abe, Mitsuki Sakamoto, Kaito Ariu, Atsushi Iwasaki</dc:creator>
    </item>
    <item>
      <title>Sensor placement via large deviations in the Eikonal equation</title>
      <link>https://arxiv.org/abs/2508.21469</link>
      <description>arXiv:2508.21469v2 Announce Type: replace 
Abstract: In this work, we address the problem of optimally placing a finite number of sensors within a given region so as to minimize the mean or maximal distance to the points of the domain. To tackle this natural geometric performance criterion, formulated in terms of distance functions, we combine tools from geometric analysis with a classical result of Varadhan, which provides an efficient approximation of the distance function via the solution of a simple elliptic PDE. The effectiveness of the proposed approach is demonstrated through illustrative numerical simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.21469v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 16 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ilias Ftouhi, Enrique Zuazua</dc:creator>
    </item>
    <item>
      <title>Closed-loop solvability of delayed control problems: A stochastic Volterra system approach</title>
      <link>https://arxiv.org/abs/2510.02674</link>
      <description>arXiv:2510.02674v2 Announce Type: replace 
Abstract: A general and new stochastic linear quadratic optimal control problem is studied, where the coefficients are allowed to be time-varying, and both state delay and control delay can appear simultaneously in the state equation and the cost functional. The closed-loop outcome control of this delayed problem is given by a new Riccati system whose solvability is carefully established. To this end, a novel method is introduced to transform the delayed problem into a control problem driven by a stochastic Volterra integral system without delay. This method offers several advantages: it bypasses the difficulty of decoupling the forward delayed state equation and the backward anticipated adjoint equation, avoids the introduction of infinite-dimensional spaces and unbounded control operators, and ensures that the closed-loop outcome control depends only on past state and control, without relying on future state or complex conditional expectation calculations. Finally, several particular important stochastic systems are discussed. It is found that the model can cover a class of stochastic integro-differential systems, whose closed-loop solvability has not been available before.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.02674v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 16 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weijun Meng, Tianxiao Wang, Ji-Feng Zhang</dc:creator>
    </item>
    <item>
      <title>p-adic Ghobber-Jaming Uncertainty Principle</title>
      <link>https://arxiv.org/abs/2506.18913</link>
      <description>arXiv:2506.18913v2 Announce Type: replace-cross 
Abstract: Let $\{\tau_j\}_{j=1}^n$ and $\{\omega_k\}_{k=1}^n$ be two orthonormal bases for a finite dimensional p-adic Hilbert space $\mathcal{X}$. Let $M,N\subseteq \{1, \dots, n\}$ be such that \begin{align*} \displaystyle \max_{j \in M, k \in N}|\langle \tau_j, \omega_k \rangle|&lt;1, \end{align*} where $o(M)$ is the cardinality of $M$. Then for all $x \in \mathcal{X}$, we show that \begin{align} (1) \quad \quad \quad \quad \|x\|\leq \left(\frac{1}{1-\displaystyle \max_{j \in M, k \in N}|\langle \tau_j, \omega_k \rangle|}\right)\max\left\{\displaystyle \max_{j \in M^c}|\langle x, \tau_j\rangle |, \displaystyle \max_{k \in N^c}|\langle x, \omega_k\rangle |\right\}. \end{align}
  We call Inequality (1) as \textbf{p-adic Ghobber-Jaming Uncertainty Principle}. Inequality (1) is the p-adic version of uncertainty principle obtained by Ghobber and Jaming \textit{[Linear Algebra Appl., 2011]}. We also derive analogues of Inequality (1) for non-Archimedean Banach spaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.18913v2</guid>
      <category>math.FA</category>
      <category>cs.IT</category>
      <category>math-ph</category>
      <category>math.IT</category>
      <category>math.MP</category>
      <category>math.NT</category>
      <category>math.OC</category>
      <pubDate>Mon, 16 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>K. Mahesh Krishna</dc:creator>
    </item>
    <item>
      <title>Solving Conic Programs over Sparse Graphs using a Variational Quantum Approach: The Case of the Optimal Power Flow</title>
      <link>https://arxiv.org/abs/2509.00341</link>
      <description>arXiv:2509.00341v2 Announce Type: replace-cross 
Abstract: Conic programs arise broadly in physics, quantum information, machine learning, and engineering, many of which are defined over sparse graphs. Although such problems can be solved in polynomial time using classical interior-point solvers, the computational complexity scales unfavorably with graph size. In this context, this work proposes a variational quantum paradigm for solving conic programs, including quadratically constrained quadratic programs (QCQPs) and semidefinite programs (SDPs). We encode primal variables via the state of a parameterized quantum circuit (PQC), and dual variables via the probability mass function of a second PQC. The Lagrangian function can thus be expressed as scaled expectations of quantum observables. A primal-dual solution can be found by minimizing/maximizing the Lagrangian over the parameters of the first/second PQC. We pursue saddle points of the Lagrangian in a hybrid fashion. Gradients of the Lagrangian are estimated using the two PQCs, while PQC parameters are updated classically using a primal-dual method. We propose permuting the primal variables so that related observables are expressed in a banded form, enabling efficient measurement. The proposed framework is applied to the OPF problem, a large-scale optimization problem central to the operation of electric power systems. Numerical tests on the IEEE 57-node power system using Pennylane's simulator corroborate that the proposed doubly variational quantum framework can find high-quality OPF solutions. Although showcased for the OPF, this framework features a broader scope, including conic programs with numerous variables and constraints, problems defined over sparse graphs, and training quantum machine learning models to satisfy constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.00341v2</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <category>quant-ph</category>
      <pubDate>Mon, 16 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thinh Viet Le, Mark M. Wilde, Vassilis Kekatos</dc:creator>
    </item>
    <item>
      <title>Fourier Learning Machines: Nonharmonic Fourier-Based Neural Networks for Scientific Machine Learning</title>
      <link>https://arxiv.org/abs/2509.08759</link>
      <description>arXiv:2509.08759v2 Announce Type: replace-cross 
Abstract: We introduce the Fourier Learning Machine (FLM), a neural network (NN) architecture designed to represent a multidimensional nonharmonic Fourier series. The FLM uses a simple feedforward structure with cosine activation functions to learn the frequencies, amplitudes, and phase shifts of the series as trainable parameters. This design allows the model to create a problem-specific spectral basis adaptable to both periodic and nonperiodic functions. Unlike previous Fourier-inspired NN models, the FLM is the first architecture able to represent a multidimensional Fourier series with a complete set of basis functions in separable form, doing so by using a standard Multilayer Perceptron-like architecture. A one-to-one correspondence between the Fourier coefficients and amplitudes and phase-shifts is demonstrated, allowing for the translation between a full, separable basis form and the cosine phase-shifted one. Additionally, we evaluate the performance of FLMs on several scientific computing problems, including benchmark Partial Differential Equations (PDEs) and a family of Optimal Control Problems (OCPs). Computational experiments show that the performance of FLMs is comparable, and often superior, to that of established architectures like SIREN and vanilla feedforward NNs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.08759v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 16 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Transactions on Machine Learning Research, 2025</arxiv:journal_reference>
      <dc:creator>Mominul Rubel, Adam Meyers, Gabriel Nicolosi</dc:creator>
    </item>
    <item>
      <title>Optimal Control of an SIR Model with Noncompliance as a Social Contagion</title>
      <link>https://arxiv.org/abs/2509.09075</link>
      <description>arXiv:2509.09075v2 Announce Type: replace-cross 
Abstract: We propose and study a compartmental model for epidemiology with human behavioral effects. Specifically, our model incorporates governmental prevention measures aimed at lowering the disease infection rate, but we split the population into those who comply with the measures and those who do not comply and therefore do not receive the reduction in infectivity. We then allow the attitude of noncompliance to spread as a social contagion parallel to the disease. We derive the reproductive ratio for our model and provide stability analysis for the disease-free equilibria. We then propose an optimal control scenario wherein a policy-maker with access to control variables representing disease prevention mandates, treatment efforts, and educational campaigns aimed at encouraging compliance minimizes a cost functional incorporating several cost concerns. Via careful analysis of the control-to-state map, we are able to prove existence of optimal controls. Our proof applies to dynamics which can be nonlinear in the control variables and general cost functionals including the case of $L^1$ control costs. We numerically resolve optimal strategies using the sequential quadratic Hamiltonian method, a relatively new numerical method for optimal control which is easy to implement and has good convergence theory, as we demonstrate. We test our model in several parameter regimes with specific interest in observing how the policy-maker's optimal strategies depend on their particular preferences which are expressed via design of different cost functionals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.09075v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 16 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chloe Ngo, Christian Parkinson, Weinan Wang</dc:creator>
    </item>
    <item>
      <title>Online reinforcement learning via sparse Gaussian mixture model Q-functions</title>
      <link>https://arxiv.org/abs/2509.14585</link>
      <description>arXiv:2509.14585v2 Announce Type: replace-cross 
Abstract: This paper introduces a structured and interpretable online policy-iteration framework for reinforcement learning (RL), built around the novel class of sparse Gaussian mixture model Q-functions (S-GMM-QFs). Extending earlier work that trained GMM-QFs offline, the proposed framework develops an online scheme that leverages streaming data to encourage exploration. Model complexity is regulated through sparsification by Hadamard overparametrization, which mitigates overfitting while preserving expressiveness. The parameter space of S-GMM-QFs is naturally endowed with a Riemannian manifold structure, allowing for principled parameter updates via online gradient descent on a smooth objective. Numerical tests show that S-GMM-QFs match the performance of dense deep RL (DeepRL) methods on standard benchmarks while using significantly fewer parameters, and maintain strong performance even in low-parameter-count regimes where sparsified DeepRL methods fail to generalize.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14585v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 16 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Minh Vu, Konstantinos Slavakis</dc:creator>
    </item>
    <item>
      <title>Imitation Learning for Combinatorial Optimisation under Uncertainty</title>
      <link>https://arxiv.org/abs/2601.05383</link>
      <description>arXiv:2601.05383v2 Announce Type: replace-cross 
Abstract: Imitation learning (IL) provides a data-driven framework for approximating policies for large-scale combinatorial optimisation problems formulated as sequential decision problems (SDPs), where exact solution methods are computationally intractable. A central but underexplored aspect of IL in this context is the role of the \emph{expert} that generates training demonstrations. Existing studies employ a wide range of expert constructions, yet lack a unifying framework to characterise their modelling assumptions, computational properties, and impact on learning performance.
  This paper introduces a systematic taxonomy of experts for IL in combinatorial optimisation under uncertainty. Experts are classified along three dimensions: (i) their treatment of uncertainty, including myopic, deterministic, full-information, two-stage stochastic, and multi-stage stochastic formulations; (ii) their level of optimality, distinguishing task-optimal and approximate experts; and (iii) their interaction mode with the learner, ranging from one-shot supervision to iterative, interactive schemes. Building on this taxonomy, we propose a generalised Dataset Aggregation (DAgger) algorithm that supports multiple expert queries, expert aggregation, and flexible interaction strategies.
  The proposed framework is evaluated on a dynamic physician-to-patient assignment problem with stochastic arrivals and capacity constraints. Computational experiments compare learning outcomes across expert types and interaction regimes. The results show that policies learned from stochastic experts consistently outperform those learned from deterministic or full-information experts, while interactive learning improves solution quality using fewer expert demonstrations. Aggregated deterministic experts provide an effective alternative when stochastic optimisation becomes computationally challenging.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.05383v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 16 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Prakash Gawas, Antoine Legrain, Louis-Martin Rousseau</dc:creator>
    </item>
    <item>
      <title>Gauss-Newton Natural Gradient Descent for Shape Learning</title>
      <link>https://arxiv.org/abs/2602.00099</link>
      <description>arXiv:2602.00099v2 Announce Type: replace-cross 
Abstract: We explore the use of the Gauss-Newton method for optimization in shape learning, including implicit neural surfaces and geometry-informed neural networks. The method addresses key challenges in shape learning, such as the ill-conditioning of the underlying differential constraints and the mismatch between the optimization problem in parameter space and the function space where the problem is naturally posed. This leads to significantly faster and more stable convergence than standard first-order methods, while also requiring far fewer iterations. Experiments across benchmark shape optimization tasks demonstrate that the Gauss-Newton method consistently improves both training speed and final solution accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.00099v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 16 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>James King, Arturs Berzins, Siddhartha Mishra, Marius Zeinhofer</dc:creator>
    </item>
  </channel>
</rss>
