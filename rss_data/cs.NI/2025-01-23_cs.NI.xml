<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 23 Jan 2025 05:00:13 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Sequence Spreading-Based Semantic Communication Under High RF Interference</title>
      <link>https://arxiv.org/abs/2501.12502</link>
      <description>arXiv:2501.12502v1 Announce Type: new 
Abstract: In the evolving landscape of wireless communications, semantic communication (SemCom) has recently emerged as a 6G enabler that prioritizes the transmission of meaning and contextual relevance over conventional bit-centric metrics. However, the deployment of SemCom systems in industrial settings presents considerable challenges, such as high radio frequency interference (RFI), that can adversely affect system performance. To address this problem, in this work, we propose a novel approach based on integrating sequence spreading techniques with SemCom to enhance system robustness against such adverse conditions and enable scalable multi-user (MU) SemCom. In addition, we propose a novel signal refining network (SRN) to refine the received signal after despreading and equalization. The proposed network eliminates the need for computationally intensive end-to-end (E2E) training while improving performance metrics, achieving a 25% gain in BLEU score and a 12% increase in semantic similarity compared to E2E training using the same bandwidth.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12502v1</guid>
      <category>cs.NI</category>
      <category>cs.LG</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hazem Barka, Georges Kaddoum, Mehdi Bennis, Md Sahabul Alam, Minh Au</dc:creator>
    </item>
    <item>
      <title>D-LoRa: a Distributed Parameter Adaptation Scheme for LoRa Network</title>
      <link>https://arxiv.org/abs/2501.12589</link>
      <description>arXiv:2501.12589v1 Announce Type: new 
Abstract: The deployment of LoRa networks necessitates joint performance optimization, including packet delivery rate, energy efficiency, and throughput. Additionally, multiple LoRa parameters for packet transmission must be dynamically configured to tailor the performance metrics prioritization across varying channel environments. Because of the coupling relationship between LoRa parameters and metrics, existing works have opted to focus on certain parameters or specific metrics to circumvent the intricate coupling relationship, leading to limited adaptability. Therefore, we propose D-LoRa, a distributed parameter adaptation scheme, based on reinforcement learning towards network performance. We decompose the joint performance optimization problem into multiple independent Multi-Armed Bandit (MAB) problems with different reward functions. We have also built a comprehensive analytical model for the LoRa network that considers path loss, quasi-orthogonality of spreading factor, and packet collision. Experimental results show that our scheme can increase packet delivery rate by up to 28.8% and demonstrates superior adaptability across different performance metrics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12589v1</guid>
      <category>cs.NI</category>
      <category>cs.DC</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ruiqi Wang, Tongyu Song, Jing Ren, Xiong Wang, Shizhong Xu, Sheng Wang</dc:creator>
    </item>
    <item>
      <title>PPO-Based Vehicle Control for Ramp Merging Scheme Assisted by Enhanced C-V2X</title>
      <link>https://arxiv.org/abs/2501.12656</link>
      <description>arXiv:2501.12656v1 Announce Type: new 
Abstract: On-ramp merging presents a critical challenge in autonomous driving, as vehicles from merging lanes need to dynamically adjust their positions and speeds while monitoring traffic on the main road to prevent collisions. To address this challenge, we propose a novel merging control scheme based on reinforcement learning, which integrates lateral control mechanisms. This approach ensures the smooth integration of vehicles from the merging lane onto the main road, optimizing both fuel efficiency and passenger comfort. Furthermore, we recognize the impact of vehicle-to-vehicle (V2V) communication on control strategies and introduce an enhanced protocol leveraging Cellular Vehicle-to-Everything (C-V2X) Mode 4. This protocol aims to reduce the Age of Information (AoI) and improve communication reliability. In our simulations, we employ two AoI-based metrics to rigorously assess the protocol's effectiveness in autonomous driving scenarios. By combining the NS3 network simulator with Python, we simulate V2V communication and vehicle control simultaneously. The results demonstrate that the enhanced C-V2X Mode 4 outperforms the standard version, while the proposed control scheme ensures safe and reliable vehicle operation during on-ramp merging.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12656v1</guid>
      <category>cs.NI</category>
      <category>cs.LG</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qiong Wu, Maoxin Ji, Pingyi Fan, Kezhi Wang, Nan Cheng, Wen Chen, Khaled B. Letaief</dc:creator>
    </item>
    <item>
      <title>A Multi-Stakeholder Perspective on Self-Managing Networks</title>
      <link>https://arxiv.org/abs/2501.12659</link>
      <description>arXiv:2501.12659v1 Announce Type: new 
Abstract: Modern telecommunication networks face an increasing complexity due to the rapidly growing number of networked devices and rising amounts of data. The literature advocates for self-managing networks as a means to tackle the resulting challenges. While self-managing networks provide potential solutions to these challenges, current research solely focuses on the perspective of network operators. However, modern telecommunication networks involve various stakeholders, such as service providers and end users, and necessitate interactions between them. By transitioning from a single-stakeholder to a multi-stakeholder perspective, we address the preferences of all involved parties, acknowledging potential conflicts of interest and constraints like information asymmetries. This broader perspective facilitates the development of more effective self-managing networks, significantly enhancing their performance metrics compared to approaches that solely prioritize the concerns of network operators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12659v1</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Patrick Weber, Artur Sterz, Bernd Freisleben, Oliver Hinz</dc:creator>
    </item>
    <item>
      <title>Cost Optimization for Serverless Edge Computing with Budget Constraints using Deep Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2501.12783</link>
      <description>arXiv:2501.12783v1 Announce Type: new 
Abstract: Serverless computing adopts a pay-as-you-go billing model where applications are executed in stateless and shortlived containers triggered by events, resulting in a reduction of monetary costs and resource utilization. However, existing platforms do not provide an upper bound for the billing model which makes the overall cost unpredictable, precluding many organizations from managing their budgets. Due to the diverse ranges of serverless functions and the heterogeneous capacity of edge devices, it is challenging to receive near-optimal solutions for deployment cost in a polynomial time. In this paper, we investigated the function scheduling problem with a budget constraint for serverless computing in wireless networks. Users and IoT devices are sending requests to edge nodes, improving the latency perceived by users. We propose two online scheduling algorithms based on reinforcement learning, incorporating several important characteristics of serverless functions. Via extensive simulations, we justify the superiority of the proposed algorithm by comparing with an ILP solver (Midaco). Our results indicate that the proposed algorithms efficiently approximate the results of Midaco within a factor of 1.03 while our decision-making time is 5 orders of magnitude less than that of Midaco.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12783v1</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chen Chen, Peiyuan Guan, Ziru Chen, Amir Taherkordi, Fen Hou, Lin X. Cai</dc:creator>
    </item>
    <item>
      <title>Comparative Performance Evaluation of 5G-TSN Applications in Indoor Factory Environments</title>
      <link>https://arxiv.org/abs/2501.12792</link>
      <description>arXiv:2501.12792v1 Announce Type: new 
Abstract: While technologies such as Time-Sensitive Networking (TSN) enhance the determinism, real-time capabilities, and reliability of Ethernet, future industrial networks will not just have wired connections, but are increasingly using wireless communication links. Wireless networks enable mobility, have lower costs, and are easier to deploy. However, for many industrial applications, wired connections remain the preferred choice, particularly those requiring strict latency boundaries and ultra-reliable data flows, such as for controlling machinery or managing power electronics. The emergence of 5G, with its Ultra-Reliable Low-Latency Communication (URLLC) capabilities, presents a new opportunity for wireless industrial networks. 5G promises to enable high data rates, ultra-low latency, and minimal jitter. However, as 5G networks include wired links from the base station towards the core network, a combination of 5G with time-sensitive networking is needed to guarantee stringent QoS requirements. In this paper, we evaluate 5G-TSN performance for different indoor factory applications and environments through simulations. Our findings demonstrate that 5G-TSN can effectively address latency-sensitive scenarios in indoor factories environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12792v1</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kouros Zanbouri, Md. Noor-A-Rahim, Dirk Pesch</dc:creator>
    </item>
    <item>
      <title>A transformer-based deep q learning approach for dynamic load balancing in software-defined networks</title>
      <link>https://arxiv.org/abs/2501.12829</link>
      <description>arXiv:2501.12829v1 Announce Type: new 
Abstract: This study proposes a novel approach for dynamic load balancing in Software-Defined Networks (SDNs) using a Transformer-based Deep Q-Network (DQN). Traditional load balancing mechanisms, such as Round Robin (RR) and Weighted Round Robin (WRR), are static and often struggle to adapt to fluctuating traffic conditions, leading to inefficiencies in network performance. In contrast, SDNs offer centralized control and flexibility, providing an ideal platform for implementing machine learning-driven optimization strategies. The core of this research combines a Temporal Fusion Transformer (TFT) for accurate traffic prediction with a DQN model to perform real-time dynamic load balancing. The TFT model predicts future traffic loads, which the DQN uses as input, allowing it to make intelligent routing decisions that optimize throughput, minimize latency, and reduce packet loss. The proposed model was tested against RR and WRR in simulated environments with varying data rates, and the results demonstrate significant improvements in network performance. For the 500MB data rate, the DQN model achieved an average throughput of 0.275 compared to 0.202 and 0.205 for RR and WRR, respectively. Additionally, the DQN recorded lower average latency and packet loss. In the 1000MB simulation, the DQN model outperformed the traditional methods in throughput, latency, and packet loss, reinforcing its effectiveness in managing network loads dynamically. This research presents an important step towards enhancing network performance through the integration of machine learning models within SDNs, potentially paving the way for more adaptive, intelligent network management systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12829v1</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Evans Tetteh Owusu, Kwame Agyemang-Prempeh Agyekum, Marinah Benneh, Pius Ayorna, Justice Owusu Agyemang, George Nii Martey Colley, James Dzisi Gazde</dc:creator>
    </item>
    <item>
      <title>Mechanism Design for Blockchain Order Books against Selfish Miners</title>
      <link>https://arxiv.org/abs/2501.12576</link>
      <description>arXiv:2501.12576v1 Announce Type: cross 
Abstract: In blockchain-based order book systems, buyers and sellers trade assets, while it is miners to match them and include their transactions in the blockchain. It is found that many miners behave selfishly and myopically, prioritizing transactions with high fees and ignoring many desirable matches that could enhance social welfare. Existing blockchain mechanisms fail to address this issue by overlooking miners' selfish behaviors. To our best knowledge, this work presents the first analytical study to quantify and understand buyer and seller transaction fee choices and selfish miners' transaction matching strategies, proving an infinitely large price of anarchy (PoA) for social welfare loss. To mitigate this, we propose an adjustable block size mechanism that is easy to implement without altering the existing decentralized protocols and still allows buyers and sellers to freely decide transaction fees and miners to selfishly match. The analysis is challenging, as pure strategy Nash equilibria do not always exist, requiring the analysis of many buyers' or sellers' interactive mixed-strategy distributions. Moreover, the system designer may even lack information about each buyer's or seller's bid/ask prices and trading quantities. Nevertheless, our mechanism achieves a well-bounded PoA, and under the homogeneous-quantity trading for non-fungible tokens (NFT), it attains a PoA of 1 with no social welfare loss. We implement our mechanism on a local instance of Ethereum to demonstrate the feasibility of our approach. Experiments based on the realistic dataset demonstrate that our mechanism achieves social optimum for homogeneous-quantity trading like NFT. It can enhance social welfare up to 3.7 times compared to the existing order book benchmarks for heterogeneous-quantity trading of Bitcoin tokens. It exhibits robustness against random variations in buyers and sellers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12576v1</guid>
      <category>cs.GT</category>
      <category>cs.HC</category>
      <category>cs.NI</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Yunshu Liu, Lingjie Duan</dc:creator>
    </item>
    <item>
      <title>Making Temporal Betweenness Computation Faster and Restless</title>
      <link>https://arxiv.org/abs/2501.12708</link>
      <description>arXiv:2501.12708v1 Announce Type: cross 
Abstract: Bu{\ss} et al [KDD 2020] recently proved that the problem of computing the betweenness of all nodes of a temporal graph is computationally hard in the case of foremost and fastest paths, while it is solvable in time O(n 3 T 2 ) in the case of shortest and shortest foremost paths, where n is the number of nodes and T is the number of distinct time steps. A new algorithm for temporal betweenness computation is introduced in this paper. In the case of shortest and shortest foremost paths, it requires O(n + M ) space and runs in time where M is the number of temporal edges, thus significantly improving the algorithm of Bu{\ss} et al in terms of time complexity (note that T is usually large). Experimental evidence is provided that our algorithm performs between twice and almost 250 times better than the algorithm of Bu{\ss} et al. Moreover, we were able to compute the exact temporal betweenness values of several large temporal graphs with over a million of temporal edges. For such size, only approximate computation was possible by using the algorithm of Santoro and Sarpe [WWW 2022]. Maybe more importantly, our algorithm extends to the case of restless walks (that is, walks with waiting constraints in each node), thus providing a polynomial-time algorithm (with complexity O(nM )) for computing the temporal betweenness in the case of several different optimality criteria. Such restless computation was known only for the shortest criterion (Rymar et al [JGAA 2023]), with complexity O(n 2 M T 2 ). We performed an extensive experimental validation by comparing different waiting constraints and different optimisation criteria. Moreover, as a case study, we investigate six public transit networks including Berlin, Rome, and Paris. Overall we find a general consistency between the different variants of betweenness centrality. However, we do measure a sensible influence of waiting constraints, and note some cases of low correlation for certain pairs of criteria in some networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12708v1</guid>
      <category>cs.DS</category>
      <category>cs.NI</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3637528.3671825</arxiv:DOI>
      <arxiv:journal_reference>KDD '24: The 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, Aug 2024, Barcelona, Spain. pp.163-174</arxiv:journal_reference>
      <dc:creator>Filippo Brunelli (JRC), Pierluigi Crescenzi (GSSI), Laurent Viennot (DI-ENS, ARGO)</dc:creator>
    </item>
    <item>
      <title>Information Degradation and Misinformation in Gossip Networks</title>
      <link>https://arxiv.org/abs/2501.13086</link>
      <description>arXiv:2501.13086v1 Announce Type: cross 
Abstract: We study networks of gossiping users where a source observing a process sends updates to an underlying graph. Nodes in the graph update their neighbors randomly and nodes always accept packets that have newer information, thus attempting to minimize their age of information (AoI). We show that while gossiping reduces AoI, information can rapidly degrade in such a network. We model degradation by arbitrary discrete-time Markov chains on k states. As a packet is transmitted through the network it modifies its state according to the Markov chain. In the last section, we specialize the Markov chain to represent misinformation spread, and show that the rate of misinformation spread is proportional to the age of information in both the fully-connected graph and ring graph.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13086v1</guid>
      <category>cs.IT</category>
      <category>cs.NI</category>
      <category>math.IT</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thomas Jacob Maranzatto, Arunabh Srivastava, Sennur Ulukus</dc:creator>
    </item>
    <item>
      <title>Which Sensor to Observe? Timely Tracking of a Joint Markov Source with Model Predictive Control</title>
      <link>https://arxiv.org/abs/2501.13099</link>
      <description>arXiv:2501.13099v1 Announce Type: cross 
Abstract: In this paper, we investigate the problem of remote estimation of a discrete-time joint Markov process using multiple sensors. Each sensor observes a different component of the joint Markov process, and in each time slot, the monitor obtains a partial state value by sending a pull request to one of the sensors. The monitor chooses the sequence of sensors to observe with the goal of minimizing the mean of age of incorrect information (MAoII) by using the partial state observations obtained, which have different freshness levels. For instance, a monitor may be interested in tracking the location of an object by obtaining observations from two sensors, which observe the $x$ and $y$ coordinates of the object separately, in different time slots. The monitor, then, needs to decide which coordinate to observe in the next time slot given the history. In addition to this partial observability of the state of Markov process, there is an erasure channel with a fixed one-slot delay between each sensor and the monitor. First, we obtain a sufficient statistic, namely the \emph{belief}, representing the joint distribution of the age of incorrect information (AoII) and the current state of the observed process by using the history of all pull requests and observations. Then, we formulate the problem with a continuous state-space Markov decision problem (MDP), namely belief MDP. To solve the problem, we propose two model predictive control (MPC) methods, namely MPC without terminal costs (MPC-WTC) and reinforcement learning MPC (RL-MPC), that have different advantages in implementation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13099v1</guid>
      <category>cs.IT</category>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>eess.SY</category>
      <category>math.IT</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ismail Cosandal, Sennur Ulukus, Nail Akar</dc:creator>
    </item>
    <item>
      <title>6G comprehensive intelligence: network operations and optimization based on Large Language Models</title>
      <link>https://arxiv.org/abs/2404.18373</link>
      <description>arXiv:2404.18373v3 Announce Type: replace 
Abstract: The sixth generation mobile communication standard (6G) can promote the development of Industrial Internet and Internet of Things (IoT). To achieve comprehensive intelligent development of the network and provide customers with higher quality personalized services. This paper proposes a network performance optimization and intelligent operation network architecture based on Large Language Model (LLM), aiming to build a comprehensive intelligent 6G network system. The Large Language Model, with more parameters and stronger learning ability, can more accurately capture patterns and features in data, which can achieve more accurate content output and high intelligence and provide strong support for related research such as network data security, privacy protection, and health assessment. This paper also presents the design framework of a network health assessment system based on LLM and focuses on its potential application value, through the case of network health management system, it is fully demonstrated that the 6G intelligent network system based on LLM has important practical significance for the comprehensive realization of intelligence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18373v3</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <arxiv:DOI>10.1109/MNET.2024.3470774</arxiv:DOI>
      <arxiv:journal_reference>IEEE Network (2024)</arxiv:journal_reference>
      <dc:creator>Sifan Long, Fengxiao Tang, Yangfan Li, Tiao Tan, Zhengjie Jin, Ming Zhao, Nei Kato</dc:creator>
    </item>
    <item>
      <title>Energy Efficient Transmission Parameters Selection Method Using Reinforcement Learning in Distributed LoRa Networks</title>
      <link>https://arxiv.org/abs/2410.11270</link>
      <description>arXiv:2410.11270v2 Announce Type: replace 
Abstract: With the increase in demand for Internet of Things (IoT) applications, the number of IoT devices has drastically grown, making spectrum resources seriously insufficient. Transmission collisions and retransmissions increase power consumption. Therefore, even in long-range (LoRa) networks, selecting appropriate transmission parameters, such as channel and transmission power, is essential to improve energy efficiency. However, due to the limited computational ability and memory, traditional transmission parameter selection methods for LoRa networks are challenging to implement on LoRa devices. To solve this problem, a distributed reinforcement learning-based channel and transmission power selection method is proposed, which can be implemented on the LoRa devices to improve energy efficiency in this paper. Specifically, the channel and transmission power selection problem in LoRa networks is first mapped to the multi-armed-bandit (MAB) problem. Then, an MAB-based method is introduced to solve the formulated transmission parameter selection problem based on the acknowledgment (ACK) packet and the power consumption for data transmission of the LoRa device. The performance of the proposed method is evaluated by the constructed actual LoRa network. Experimental results show that the proposed method performs better than fixed assignment, adaptive data rate low-complexity (ADR-Lite), and $\epsilon$-greedy-based methods in terms of both transmission success rate and energy efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11270v2</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ryotai Airiyoshi, Mikio Hasegawa, Tomoaki Ohtsuki, Aohan Li</dc:creator>
    </item>
    <item>
      <title>Bootstrapping Social Networks: Lessons from Bluesky Starter Packs</title>
      <link>https://arxiv.org/abs/2501.11605</link>
      <description>arXiv:2501.11605v2 Announce Type: replace-cross 
Abstract: Microblogging is a crucial mode of online communication. However, launching a new microblogging platform remains challenging, largely due to network effects. This has resulted in entrenched (and undesirable) dominance by established players, such as X/Twitter. To overcome these network effects, Bluesky, an emerging microblogging platform, introduced starter packs -- curated lists of accounts that users can follow with a single click. We ask if starter packs have the potential to tackle the critical problem of social bootstrapping in new online social networks? This paper is the first to address this question: we asses whether starter packs have been indeed helpful in supporting Bluesky growth. Our dataset includes $25.05 \times 10^6$ users and $335.42 \times 10^3$ starter packs with $1.73 \times 10^6$ members, covering the entire lifecycle of Bluesky. We study the usage of these starter packs, their ability to drive network and activity growth, and their potential downsides. We also quantify the benefits of starter packs for members and creators on user visibility and activity while identifying potential challenges. By evaluating starter packs' effectiveness and limitations, we contribute to the broader discourse on platform growth strategies and competitive innovation in the social media landscape.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11605v2</guid>
      <category>cs.SI</category>
      <category>cs.NI</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Leonhard Balduf, Saidu Sokoto, Onur Ascigil, Gareth Tyson, Ignacio Castro, Andrea Baronchelli, George Pavlou, Bj\"orn Scheuermann, Micha{\l} Kr\'ol</dc:creator>
    </item>
  </channel>
</rss>
