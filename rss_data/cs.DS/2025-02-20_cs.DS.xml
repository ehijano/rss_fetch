<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 21 Feb 2025 02:45:11 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Sum-Of-Squares To Approximate Knapsack</title>
      <link>https://arxiv.org/abs/2502.13292</link>
      <description>arXiv:2502.13292v1 Announce Type: new 
Abstract: These notes give a self-contained exposition of Karlin, Mathieu and Nguyen's tight estimate of the integrality gap of the sum-of-squares semidefinite program for solving the knapsack problem. They are based on a sequence of three lectures in CMU course on Advanced Approximation Algorithms in Fall'21 that used the KMN result to introduce the Sum-of-Squares method for algorithm design. The treatment in these notes uses the pseudo-distribution view of solutions to the sum-of-squares SDPs and only rely on a few basic, reusable results about pseudo-distributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13292v1</guid>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pravesh K. Kothari, Sherry Sarkar</dc:creator>
    </item>
    <item>
      <title>Graph-Based Algorithms for Diverse Similarity Search</title>
      <link>https://arxiv.org/abs/2502.13336</link>
      <description>arXiv:2502.13336v1 Announce Type: new 
Abstract: Nearest neighbor search is a fundamental data structure problem with many applications in machine learning, computer vision, recommendation systems and other fields. Although the main objective of the data structure is to quickly report data points that are closest to a given query, it has long been noted (Carbonell and Goldstein, 1998) that without additional constraints the reported answers can be redundant and/or duplicative. This issue is typically addressed in two stages: in the first stage, the algorithm retrieves a (large) number $r$ of points closest to the query, while in the second stage, the $r$ points are post-processed and a small subset is selected to maximize the desired diversity objective. Although popular, this method suffers from a fundamental efficiency bottleneck, as the set of points retrieved in the first stage often needs to be much larger than the final output.
  In this paper we present provably efficient algorithms for approximate nearest neighbor search with diversity constraints that bypass this two stage process. Our algorithms are based on popular graph-based methods, which allows us to "piggy-back" on the existing efficient implementations. These are the first graph-based algorithms for nearest neighbor search with diversity constraints. For data sets with low intrinsic dimension, our data structures report a diverse set of $k$ points approximately closest to the query, in time that only depends on $k$ and $\log \Delta$, where $\Delta$ is the ratio of the diameter to the closest pair distance in the data set. This bound is qualitatively similar to the best known bounds for standard (non-diverse) graph-based algorithms. Our experiments show that the search time of our algorithms is substantially lower than that using the standard two-stage approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13336v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Piyush Anand, Piotr Indyk, Ravishankar Krishnaswamy, Sepideh Mahabadi, Vikas C. Raykar, Kirankumar Shiragur, Haike Xu</dc:creator>
    </item>
    <item>
      <title>Faster Minimization of Total Weighted Completion Time on Parallel Machines</title>
      <link>https://arxiv.org/abs/2502.13631</link>
      <description>arXiv:2502.13631v1 Announce Type: new 
Abstract: We study the classical problem of minimizing the total weighted completion time on a fixed set of $m$ identical machines working in parallel, the $Pm||\sum w_jC_j$ problem in the standard three field notation for scheduling problems. This problem is well known to be NP-hard, but only in the ordinary sense, and appears as one of the fundamental problems in any scheduling textbook. In particular, the problem served as a proof of concept for applying pseudo-polynomial time algorithms and approximation schemes to scheduling problems. The fastest known pseudo-polynomial time algorithm for $Pm||\sum w_jC_j$ is the famous Lawler and Moore algorithm from the late 1960's which runs in $\tilde{O}(P^{m-1}n)$ time, where $P$ is the total processing time of all jobs in the input. After more than 50 years, we are the first to present an algorithm, alternative to that of Lawler and Moore, which is faster for certain range of the problem parameters (e.g., when their values are all $O(1)$).</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13631v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Danny Hermelin, Tomohiro Koana, Dvir Shabtay</dc:creator>
    </item>
    <item>
      <title>Semi-Streaming Algorithms for Hypergraph Matching</title>
      <link>https://arxiv.org/abs/2502.13636</link>
      <description>arXiv:2502.13636v1 Announce Type: new 
Abstract: We propose two one-pass streaming algorithms for the NP-hard hypergraph matching problem. The first algorithm stores a small subset of potential matching edges in a stack using dual variables to select edges. It has an approximation guarantee of $\frac{1}{d(1+\varepsilon)}$ and requires $O((n/\varepsilon) \log^2{n})$ bits of memory.
  The second algorithm computes, stores, and updates a single matching as the edges stream, with an approximation ratio dependent on a parameter $\alpha$. Its best approximation ratio is $\frac{1}{(2d-1) + 2 \sqrt{d(d-1)}}$, and it requires only $O(n)$ memory.
  We have implemented both algorithms and have engineered variants for optimizing matching weights, memory consumption, and running times. These include relaxations of the rule for admitting edges into the stack and using a second pass to improve the weight. The evaluation is done on large-sized hypergraphs from circuit design and sparse matrix computations. Our results show that the streaming algorithms achieve much better approximation factors in practice than the worst-case bounds, reducing memory required by up to 50 times and outperforming the offline Greedy algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13636v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Henrik Reinst\"adtler, S M Ferdous, Alex Pothen, Bora U\c{c}ar, Christian Schulz</dc:creator>
    </item>
    <item>
      <title>A Query-Driven Approach to Space-Efficient Range Searching</title>
      <link>https://arxiv.org/abs/2502.13653</link>
      <description>arXiv:2502.13653v1 Announce Type: new 
Abstract: We initiate a study of a query-driven approach to designing partition trees for range-searching problems. Our model assumes that a data structure is to be built for an unknown query distribution that we can access through a sampling oracle, and must be selected such that it optimizes a meaningful performance parameter on expectation. Our first contribution is to show that a near-linear sample of queries allows the construction of a partition tree with a near-optimal expected number of nodes visited during querying. We enhance this approach by treating node processing as a classification problem, leveraging fast classifiers like shallow neural networks to obtain experimentally efficient query times. Our second contribution is to develop partition trees using sparse geometric separators. Our preprocessing algorithm, based on a sample of queries, builds a balanced tree with nodes associated with separators that minimize query stabs on expectation; this yields both fast processing of each node and a small number of visited nodes, significantly reducing query time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13653v1</guid>
      <category>cs.DS</category>
      <category>cs.CG</category>
      <category>cs.LG</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dimitris Fotakis, Andreas Kalavas, Ioannis Psarros</dc:creator>
    </item>
    <item>
      <title>FPT algorithms over linear delta-matroids with applications</title>
      <link>https://arxiv.org/abs/2502.13654</link>
      <description>arXiv:2502.13654v1 Announce Type: new 
Abstract: Matroids, particularly linear ones, have been a powerful tool in parameterized complexity for algorithms and kernelization. They have sped up or replaced dynamic programming. Delta-matroids generalize matroids by encapsulating structures such as non-maximum matchings in general graphs and various path-packing and topological configurations. Linear delta-matroids (represented by skew-symmetric matrices) offer significant expressive power and enable powerful algorithms. We investigate parameterized complexity aspects of problems defined over linear delta-matroids or with delta-matroid constraints. Our analysis of basic intersection and packing problems reveals a different complexity landscape compared to the familiar matroid case. In particular, there is a stark contrast between the cardinality parameter $k$ and the rank parameter $r$. For example, finding an intersection of size $k$ of three linear delta-matroids is W[1]-hard when parameterized by $k$, while more general problems (e.g., finding a set packing of size $k$ feasible in a linear delta-matroid) are FPT when parameterized by $r$. We extend the recent determinantal sieving procedure of Eiben, Koana and Wahlstr\"om (SODA 2024) to sieve a polynomial for a monomial whose support is feasible in a linear delta-matroid by $r$.
  Second, we investigate a class of problems that remains FPT when parameterized by $k$, even on delta-matroids of unbounded rank. We begin with Delta-matroid Triangle Cover - finding a feasible set of size $k$ that can be covered by a vertex-disjoint packing of triangles (sets of size 3) from a given collection. This approach allows us to find a packing of $K_3$'s and $K_2$'s in a graph with a maximum number of edges, parameterized above the matching number. As applications, we settle questions on the FPT status of Cluster Subgraph and Strong Triadic Closure parameterized above the matching number.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13654v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eduard Eiben, Tomohiro Koana, Magnus Wahlstr\"om</dc:creator>
    </item>
    <item>
      <title>Slant/Gokigen Naname is NP-complete, and Some Variations are in P</title>
      <link>https://arxiv.org/abs/2502.13536</link>
      <description>arXiv:2502.13536v1 Announce Type: cross 
Abstract: In this paper we show that a generalized version of the Nikoli puzzle Slant is NP-complete. We also give polynomial time algorithms for versions of the puzzle where some constraints are omitted. These problems correspond to simultaneously satisfying connectivity and vertex degree constraints in a grid graph and its dual.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13536v1</guid>
      <category>cs.DM</category>
      <category>cs.CG</category>
      <category>cs.DS</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jayson Lynch, Jack Spalding-Jamieson</dc:creator>
    </item>
    <item>
      <title>Scalable and Interpretable Identification of Minimal Undesignable RNA Structure Motifs with Rotational Invariance</title>
      <link>https://arxiv.org/abs/2402.17206</link>
      <description>arXiv:2402.17206v3 Announce Type: replace 
Abstract: RNA design aims to find a sequence that folds with highest probability into a designated target structure. However, certain structures are undesignable, meaning no sequence can fold into the target structure under the default (Turner) RNA folding model. Understanding the specific local structures (i.e., "motifs") that contribute to undesignability is crucial for refining RNA folding models and determining the limits of RNA designability. Despite its importance, this problem has received very little attention, and previous efforts are neither scalable nor interpretable. We develop a new theoretical framework for motif (un-)designability, and design scalable and interpretable algorithms to identify minimal undesignable motifs within a given RNA secondary structure. Our approach establishes motif undesignability by searching for rival motifs, rather than exhaustively enumerating all (partial) sequences that could potentially fold into the motif. Furthermore, we exploit rotational invariance in RNA structures to detect, group, and reuse equivalent motifs and to construct a database of unique minimal undesignable motifs. To achieve that, we propose a loop-pair graph representation for motifs and a recursive graph isomorphism algorithm for motif equivalence. Our algorithms successfully identify 24 unique minimal undesignable motifs among 18 undesignable puzzles from the Eterna100 benchmark. Surprisingly, we also find over 350 unique minimal undesignable motifs and 663 undesignable native structures in the ArchiveII dataset, drawn from a diverse set of RNA families. Our source code is available at https://github.com/shanry/RNA-Undesign and our web server is available at http://linearfold.org/motifs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.17206v3</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Tianshuo Zhou, Wei Yu Tang, Apoorv Malik, David H. Mathews, Liang Huang</dc:creator>
    </item>
    <item>
      <title>A Simple yet Exact Analysis of the MultiQueue</title>
      <link>https://arxiv.org/abs/2410.08714</link>
      <description>arXiv:2410.08714v2 Announce Type: replace 
Abstract: The MultiQueue is a relaxed concurrent priority queue consisting of $n$ internal priority queues, where an insertion uses a random queue and a deletion considers two random queues and deletes the minimum from the one with the smaller minimum. The rank error of the deletion is the number of smaller elements in the MultiQueue.
  Alistarh et al. [2] have demonstrated in a sophisticated potential argument that the expected rank error remains bounded by $O(n)$ over long sequences of deletions.
  In this paper we present a simpler analysis by identifying the stable distribution of an underlying Markov chain and with it the long-term distribution of the rank error exactly. Simple calculations then reveal the expected long-term rank error to be $\tfrac{5}{6}n-1+\tfrac{1}{6n}$. Our arguments generalize to deletion schemes where the probability to delete from a given queue depends only on the rank of the queue. Specifically, this includes deleting from the best of $c$ randomly selected queues for any $c&gt;1$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08714v2</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Stefan Walzer, Marvin Williams</dc:creator>
    </item>
    <item>
      <title>Faster feasibility for dynamic flows and transshipments on temporal networks</title>
      <link>https://arxiv.org/abs/2411.04906</link>
      <description>arXiv:2411.04906v2 Announce Type: replace 
Abstract: In this paper we study flow problems on temporal networks, where edge capacities and travel times change over time. We consider a network with $n$ nodes and $m$ edges where the capacity and length of each edge is a piecewise constant function, and use $\mu=\Omega(m)$ to denote the total number of pieces in all of the $2m$ functions. Our goal is to design exact algorithms for various flow problems that run in time polynomial in the parameter $\mu$. Importantly, the algorithms we design are strongly polynomial, i.e. have no dependence on the capacities, flow value, or the time horizon of the flow process, all of which can be exponentially large relative to the other parameters; and return an integral flow when all input parameters are integral.
  Our main result is an algorithm for checking feasibility of a dynamic transshipment problem on temporal networks -- given multiple sources and sinks with supply and demand values, is it possible to satisfy the desired supplies and demands within a given time horizon? We develop a fast ($O(\mu^3)$ time) algorithm for this feasibility problem when the input network has a certain canonical form, by exploiting the cut structure of the associated time expanded network. We then adapt an approach of \cite{hoppe2000} to show how other flow problems on temporal networks can be reduced to the canonical format.
  For computing dynamic transshipments on temporal networks, this results in a $O(\mu^7)$ time algorithm, whereas the previous best integral exact algorithm runs in time $\tilde O(\mu^{19})$. We achieve similar improvements for other flow problems on temporal networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04906v2</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kristin Sheridan, Shuchi Chawla</dc:creator>
    </item>
    <item>
      <title>Interior point methods are not worse than Simplex</title>
      <link>https://arxiv.org/abs/2206.08810</link>
      <description>arXiv:2206.08810v4 Announce Type: replace-cross 
Abstract: We develop a new `subspace layered least squares' interior point method (IPM) for solving linear programs. Applied to an $n$-variable linear program in standard form, the iteration complexity of our IPM is up to an $O(n^{1.5} \log n)$ factor upper bounded by the \emph{straight line complexity} (SLC) of the linear program. This term refers to the minimum number of segments of any piecewise linear curve that traverses the \emph{wide neighborhood} of the central path, a lower bound on the iteration complexity of any IPM that follows a piecewise linear trajectory along a path induced by a self-concordant barrier. In particular, our algorithm matches the number of iterations of any such IPM up to the same factor $O(n^{1.5}\log n)$. As our second contribution, we show that the SLC of any linear program is upper bounded by $2^{n + o(1)}$, which implies that our IPM's iteration complexity is at most exponential. This in contrast to existing iteration complexity bounds that depend on either bit-complexity or condition measures; these can be unbounded in the problem dimension. We achieve our upper bound by showing that the central path is well-approximated by a combinatorial proxy we call the \emph{max central path}, which consists of $2n$ shadow vertex simplex paths. Our upper bound complements the lower bounds of Allamigeon, Benchimol, Gaubert, and Joswig (SIAGA 2018), and Allamigeon, Gaubert, and Vandame (STOC 2022), who constructed linear programs with exponential SLC. Finally, we show that each iteration of our IPM can be implemented in strongly polynomial time. Along the way, we develop a deterministic algorithm that approximates the singular value decomposition of a matrix in strongly polynomial time to high accuracy, which may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2206.08810v4</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xavier Allamigeon, Daniel Dadush, Georg Loho, Bento Natura, L\'aszl\'o A. V\'egh</dc:creator>
    </item>
    <item>
      <title>Sampling from the Continuous Random Energy Model in Total Variation Distance</title>
      <link>https://arxiv.org/abs/2407.00868</link>
      <description>arXiv:2407.00868v2 Announce Type: replace-cross 
Abstract: The continuous random energy model (CREM) is a toy model of spin glasses on $\{0,1\}^N$ that, in the limit, exhibits an infinitely hierarchical correlation structure. We give two polynomial-time algorithms to approximately sample from the Gibbs distribution of the CREM in the high-temperature regime $\beta&lt;\beta_{\min}:=\min\{\beta_c,\beta_G\}$, based on a Markov chain and a sequential sampler. The running time depends algebraically on the desired TV distance and failure probability and exponentially in $(1/g)^{O(1)}$, where $g$ is the gap to a certain inverse temperature threshold $\beta_{\min}$; this contrasts with previous results which only attain $o(N)$ accuracy in KL divergence. If the covariance function $A$ of the CREM is concave, the algorithms work up to the critical threshold $\beta_c$, which is the static phase transition point; while for $A$ non-concave, if $\beta_G&lt;\beta_c$, the algorithms work up to the known algorithmic threshold $\beta_G$ proposed in Addario-Berry and Maillard (2020) for non-trivial sampling guarantees. Our result depends on quantitative bounds for the fluctuation of the partition function and a new contiguity result of the ``tilted" CREM obtained from sampling, which is of independent interest. We also show that the spectral gap is exponentially small with high probability, suggesting that the algebraic dependence is unavoidable with a Markov chain approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00868v2</guid>
      <category>math.PR</category>
      <category>cond-mat.dis-nn</category>
      <category>cs.DS</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Holden Lee, Qiang Wu</dc:creator>
    </item>
    <item>
      <title>A Space-Efficient Algebraic Approach to Robotic Motion Planning</title>
      <link>https://arxiv.org/abs/2409.08219</link>
      <description>arXiv:2409.08219v2 Announce Type: replace-cross 
Abstract: We consider efficient route planning for robots in applications such as infrastructure inspection and automated surgical imaging. These tasks can be modeled via the combinatorial problem Graph Inspection. The best known algorithms for this problem are limited in practice by exponential space complexity. In this paper, we develop a memory-efficient approach using algebraic tools related to monomial testing on the polynomials associated with certain arithmetic circuits. Our contributions are two-fold. We first repair a minor flaw in existing work on monomial detection using a new approach we call tree certificates. We further show that, in addition to detection, these tools allow us to efficiently recover monomials of interest from circuits, opening the door for significantly broadened application of related algebraic tools. For Graph Inspection, we design and evaluate a complete algebraic pipeline. Our engineered implementation demonstrates that circuit-based algorithms are indeed memory-efficient in practice, thus encouraging further engineering efforts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08219v2</guid>
      <category>cs.RO</category>
      <category>cs.DS</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matthias Bentert, Daniel Coimbra Salomao, Alex Crane, Yosuke Mizutani, Felix Reidl, Blair D. Sullivan</dc:creator>
    </item>
    <item>
      <title>Differentially Private Learning Beyond the Classical Dimensionality Regime</title>
      <link>https://arxiv.org/abs/2411.13682</link>
      <description>arXiv:2411.13682v2 Announce Type: replace-cross 
Abstract: We initiate the study of differentially private learning in the proportional dimensionality regime, in which the number of data samples $n$ and problem dimension $d$ approach infinity at rates proportional to one another, meaning that $d/n\to\delta$ as $n\to\infty$ for an arbitrary, given constant $\delta\in(0,\infty)$. This setting is significantly more challenging than that of all prior theoretical work in high-dimensional differentially private learning, which, despite the name, has assumed that $\delta = 0$ or is sufficiently small for problems of sample complexity $O(d)$, a regime typically considered "low-dimensional" or "classical" by modern standards in high-dimensional statistics. We provide sharp theoretical estimates of the error of several well-studied differentially private algorithms for robust linear regression and logistic regression, including output perturbation, objective perturbation, and noisy stochastic gradient descent, in the proportional dimensionality regime. The $1+o(1)$ factor precision of our error estimates enables a far more nuanced understanding of the price of privacy of these algorithms than that afforded by existing, coarser analyses, which are essentially vacuous in the regime we consider. Using our estimates, we discover a previously unobserved "double descent"-like phenomenon in the training error of objective perturbation for robust linear regression. We also identify settings in which output perturbation outperforms objective perturbation on average, and vice versa, demonstrating that the relative performance of these algorithms is less clear-cut than suggested by prior work. To prove our main theorems, we introduce several probabilistic tools that have not previously been used to analyze differentially private learning algorithms, such as a modern Gaussian comparison inequality and recent universality laws with origins in statistical physics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.13682v2</guid>
      <category>cs.LG</category>
      <category>cs.CR</category>
      <category>cs.DS</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cynthia Dwork, Pranay Tankala, Linjun Zhang</dc:creator>
    </item>
    <item>
      <title>On Diverse Solutions to Packing and Covering Problems</title>
      <link>https://arxiv.org/abs/2501.12261</link>
      <description>arXiv:2501.12261v2 Announce Type: replace-cross 
Abstract: We develop a general framework, called \emph{approximately-diverse dynamic programming (ADDP)} that provides PTASs for generating a collection of $k&gt;1$ maximally diverse solutions to various packing and covering problems. Given an approximation factor $0\le c\le 1$, this framework also allows for maximizing diversity in the larger space of $c$-optimal solutions. We showcase the power and limitations of our technique via three applications.
  1. Given an input to the knapsack problem, an integer $k$ and a $c\le 1$, we give an algorithm that runs in time $n^{O(1/\epsilon)}\text{poly}(k)f(\epsilon,\delta,\gamma)$ and returns $k$ solutions, each with value within $c(1-\delta)$ of optimal, weight at most $(1+\gamma)$ of the knapsack, and with diversity at least $(1-\epsilon)$ of any optimally diverse collection of $c$-optimal solutions.
  2. Given a planar graph $G$, an integer $k$ and a value $c\le 1$, we give algorithms running in time $2^{O(kf(\delta,\epsilon))}n^{O(1/\epsilon)}$ that return $(1-\epsilon)$-apx. diverse $(1-\delta)c$-optimal independent sets or vertex covers. When $k=O(\log n)$, this gives a PTAS. This is the \emph{first PTAS for diverse variants for any NP-complete problem}.
  3. We show how to generate diverse solutions for a geometric variant of the knapsack problem - the rectangle packing problem by [Coffman, Garey, Johnson, and Tarjan 1980]. In this problem, we are given a set of axis-aligned rectangles and a square knapsack, and the goal is to pack as many rectangles as possible into the knapsack. We present a poly-time algorithm that returns $k$ distinct solutions, where each solution achieves a profit of at least $(1-\epsilon)$ times the optimal value and fits into a $(1+\epsilon)$-enlarged knapsack. In this case, the diversity is at least $(1-\epsilon)$ of that of any collection of $k$ container based solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12261v2</guid>
      <category>cs.CG</category>
      <category>cs.DS</category>
      <pubDate>Thu, 20 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Waldo G\'alvez, Mayank Goswami, Arturo Merino, GiBeom Park, Meng-Tsung Tsai, Victor Verdugo</dc:creator>
    </item>
  </channel>
</rss>
