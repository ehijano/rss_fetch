<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.data-an updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.data-an</link>
    <description>physics.data-an updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.data-an" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 23 Sep 2025 04:00:24 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 23 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Comment on Frank Porter, "Confidence intervals for the Poisson distribution"</title>
      <link>https://arxiv.org/abs/2509.17339</link>
      <description>arXiv:2509.17339v1 Announce Type: new 
Abstract: Frank Porter has recently posted a review of "Confidence intervals for the Poisson distribution" (arXiv:2509.02852). The long, diverse history of such intervals is closely related to that of confidence intervals for the parameter of the binomial distribution. While much of Porter's paper is enlightening and food for thought, I believe that his discussion of the intervals advocated by Gary Feldman and myself (FC) based on the likelihood ratio test (arXiv:physics/9711021) is flawed. The fundamental point of disagreement is whether or not the likelihood function exists in a part of parameter space where the statistical model does not exist. (The new paper says yes; FC say no.) Here, I focus mainly on that issue and the consequences, along with a few other remarks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.17339v1</guid>
      <category>physics.data-an</category>
      <pubDate>Tue, 23 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Robert D. Cousins</dc:creator>
    </item>
    <item>
      <title>Particle Identification with MLPs and PINNs Using HADES Data</title>
      <link>https://arxiv.org/abs/2509.17685</link>
      <description>arXiv:2509.17685v1 Announce Type: new 
Abstract: In experimental nuclear and particle physics, the extraction of high-purity samples of rare events critically depends on the efficiency and accuracy of particle identification (PID). In this work, we present a PID method applied to HADES data at the level of fully reconstructed particle track candidates. The results demonstrate a significant improvement in PID performance compared to conventional techniques, highlighting the potential of physics-informed neural networks as a powerful tool for future data analyses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.17685v1</guid>
      <category>physics.data-an</category>
      <category>nucl-ex</category>
      <pubDate>Tue, 23 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marvin Kohls</dc:creator>
    </item>
    <item>
      <title>Functional Information in Quantum Darwinism: An Operational Measure of Objectivity</title>
      <link>https://arxiv.org/abs/2509.17775</link>
      <description>arXiv:2509.17775v1 Announce Type: cross 
Abstract: This paper investigates the emergence of classical objectivity in quantum systems through the measure of Functional Information in Quantum Darwinism ($FI_{QD}$). The goal is to quantify objectivity as the abundance of environment fragments that independently contain sufficient information about a system's pointer states. The method relies on the Holevo quantity -- an upper bound on accessible information -- and introduces a tolerance criterion called $\delta$-adequacy, where fragments are considered adequate if they retain at least $(1-\delta)H_S$ bits of pointer information. Numerical simulations of a dephasing model with fragment sampling reveal three robust features: (i) an early-time regime where $\log R_\delta(t)$ grows approximately linearly, (ii) capacity-limited plateaus determined by fragment size and environment dimension, and (iii) stability of the onset criterion under different sampling strategies and overlap corrections. These results establish $FI_{QD}$ as a practical and conservative yardstick for operational objectivity. Beyond numerical findings, the analysis links redundancy growth to thermodynamic costs of record formation and interprets $FI_{QD}$ as a resource monotone under noisy dynamics. The study suggests that classical objectivity emerges not as an assumption but as a quantifiable, resource-limited abundance of redundant records.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.17775v1</guid>
      <category>quant-ph</category>
      <category>physics.comp-ph</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 23 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arda Batin Tank</dc:creator>
    </item>
  </channel>
</rss>
