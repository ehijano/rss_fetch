<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 04 Feb 2026 03:02:31 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Learning in Bayesian Stackelberg Games With Unknown Follower's Types</title>
      <link>https://arxiv.org/abs/2602.00771</link>
      <description>arXiv:2602.00771v1 Announce Type: new 
Abstract: We study online learning in Bayesian Stackelberg games, where a leader repeatedly interacts with a follower whose unknown private type is independently drawn at each round from an unknown probability distribution. The goal is to design algorithms that minimize the leader's regret with respect to always playing an optimal commitment computed with knowledge of the game. We consider, for the first time to the best of our knowledge, the most realistic case in which the leader does not know anything about the follower's types, i.e., the possible follower payoffs. This raises considerable additional challenges compared to the commonly studied case in which the payoffs of follower types are known. First, we prove a strong negative result: no-regret is unattainable under action feedback, i.e., when the leader only observes the follower's best response at the end of each round. Thus, we focus on the easier type feedback model, where the follower's type is also revealed. In such a setting, we propose a no-regret algorithm that achieves a regret of $\widetilde{O}(\sqrt{T})$, when ignoring the dependence on other parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.00771v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matteo Bollini, Francesco Bacchiocchi, Samuel Coutts, Matteo Castiglioni, Alberto Marchesi</dc:creator>
    </item>
    <item>
      <title>ReACT-TTC: Capacity-Aware Top Trading Cycles for Post-Choice Reassignment in Shared CPS</title>
      <link>https://arxiv.org/abs/2602.00859</link>
      <description>arXiv:2602.00859v1 Announce Type: new 
Abstract: Cyber-physical systems (CPS) increasingly manage shared physical resources in the presence of human decision-making, where system-assigned actions must be executed by users or agents in the physical world. A fundamental challenge in such settings is user non-compliance: individuals may deviate from assigned resources due to personal preferences or local information, degrading system efficiency and requiring light-weight reassignment schemes. This paper proposes a post-deviation reassignment framework for shared-resource CPS that operates on top of any initial allocation algorithm and is invoked only when users diverge from prescribed assignments. We advance the Top-Trading-Cycle (TTC) mechanism to enable voluntary, preference-driven exchanges after deviation events, and extend it to handle many-to-one resource capacities and unassigned resource conditions that are not supported by the classical TTC. We formalize these structural cases, introduce capacity-aware cycle-detection rules, and prove termination along with the preservation of Pareto efficiency, individual rationality, and strategy-proofness. A Prospect-Theoretic (PT) preference model is further incorporated to capture realistic user satisfaction behavior. We demonstrate the applicability of this framework on an electric-vehicle (EV) charging case study using real-world data, where it increases user satisfaction and effective assignment quality under non-compliant behavior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.00859v1</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anurag Satpathy, Arindam Khanda, Chittaranjan Swain, Sajal K. Das</dc:creator>
    </item>
    <item>
      <title>Minimizing Inequity in Facility Location Games</title>
      <link>https://arxiv.org/abs/2602.01048</link>
      <description>arXiv:2602.01048v1 Announce Type: new 
Abstract: This paper studies the problem of minimizing group-level inequity in facility location games on the real line, where agents belong to different groups and may act strategically. We explore a fairness-oriented objective that minimizes the maximum group effect introduced by Marsh and Schilling (1994). Each group's effect is defined as its total or maximum distance to the nearest facility, weighted by group-specific factors. We show that this formulation generalizes several prominent optimization objectives, including the classical utilitarian (social cost) and egalitarian (maximum cost) objectives, as well as two group-fair objectives, maximum total and average group cost. In order to minimize the maximum group effect, we first propose two novel mechanisms for the single-facility case, the BALANCED mechanism and the MAJOR-PHANTOM mechanism. Both are strategyproof and achieve tight approximation guarantees under distinct formulations of the maximum group effect objective. Our mechanisms not only close the existing gap in approximation bounds for group-fairness objectives identified by Zhou, Li, and Chan (2022), but also unify many classical truthful mechanisms within a broader fairness-aware framework. For the two-facility case, we revisit and extend the classical endpoint mechanism to our generalized setting and demonstrate that it provides tight bounds for two distinct maximum group effect objectives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01048v1</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuhang Guo, Houyu Zhou</dc:creator>
    </item>
    <item>
      <title>Simple and Robust Quality Disclosure: The Power of Quantile Partition</title>
      <link>https://arxiv.org/abs/2602.01066</link>
      <description>arXiv:2602.01066v1 Announce Type: new 
Abstract: Quality information on online platforms is often conveyed through simple, percentile-based badges and tiers that remain stable across different market environments. Motivated by this empirical evidence, we study robust quality disclosure in a market where a platform commits to a public disclosure policy mapping the seller's product quality into a signal, and the seller subsequently sets a downstream monopoly price. Buyers have heterogeneous private types and valuations that are linear in quality. We evaluate a disclosure policy via a minimax competitive ratio: its worst-case revenue relative to the Bayesian-optimal disclosure-and-pricing benchmark, uniformly over all prior quality distributions, type distributions, and admissible valuations.
  Our main results provide a sharp theoretical justification for quantile-partition disclosure. For K-quantile partition policies, we fully characterize the robust optimum: the optimal worst-case ratio is pinned down by a one-dimensional fixed-point equation and the optimal thresholds follow a backward recursion. We also give an explicit formula for the robust ratio of any quantile partition as a simple "max-over-bins" expression, which explains why the robust-optimal partition allocates finer resolution to upper quantiles and yields tight guarantees such as 1 + 1/K for uniform percentile buckets. In contrast, we show a robustness limit for finite-signal monotone (quality-threshold) partitions, which cannot beat a factor-2 approximation. Technically, our analysis reduces the robust quality disclosure to a robust disclosure design program by establishing a tight functional characterization of all feasible indirect revenue functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01066v1</guid>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shipra Agrawal, Yiding Feng, Wei Tang</dc:creator>
    </item>
    <item>
      <title>Efficiently Solving Mixed-Hierarchy Games with Quasi-Policy Approximations</title>
      <link>https://arxiv.org/abs/2602.01568</link>
      <description>arXiv:2602.01568v1 Announce Type: new 
Abstract: Multi-robot coordination often exhibits hierarchical structure, with some robots' decisions depending on the planned behaviors of others. While game theory provides a principled framework for such interactions, existing solvers struggle to handle mixed information structures that combine simultaneous (Nash) and hierarchical (Stackelberg) decision-making. We study N-robot forest-structured mixed-hierarchy games, in which each robot acts as a Stackelberg leader over its subtree while robots in different branches interact via Nash equilibria. We derive the Karush-Kuhn-Tucker (KKT) first-order optimality conditions for this class of games and show that they involve increasingly high-order derivatives of robots' best-response policies as the hierarchy depth grows, rendering a direct solution intractable. To overcome this challenge, we introduce a quasi-policy approximation that removes higher-order policy derivatives and develop an inexact Newton method for efficiently solving the resulting approximated KKT systems. We prove local exponential convergence of the proposed algorithm for games with non-quadratic objectives and nonlinear constraints. The approach is implemented in a highly optimized Julia library (MixedHierarchyGames.jl) and evaluated in simulated experiments, demonstrating real-time convergence for complex mixed-hierarchy information structures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01568v1</guid>
      <category>cs.GT</category>
      <category>cs.RO</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hamzah Khan, Dong Ho Lee, Jingqi Li, Tianyu Qiu, Christian Ellis, Jesse Milzman, Wesley Suttle, David Fridovich-Keil</dc:creator>
    </item>
    <item>
      <title>Stable Matching with Predictions: Robustness and Efficiency under Pruned Preferences</title>
      <link>https://arxiv.org/abs/2602.02254</link>
      <description>arXiv:2602.02254v1 Announce Type: new 
Abstract: In this paper, we study the fundamental problem of finding a stable matching in two-sided matching markets. In the classic variant, it is assumed that both sides of the market submit a ranked list of all agents on the other side. However, in large matching markets such as the National Resident Matching Program (NRMP), it is infeasible for hospitals to interview or mutually rank each resident. In this paper, we study the stable matching problem with truncated preference lists. In particular, we assume that, based on historical datasets, each hospital has a predicted rank of its likely match and only ranks residents within a bounded interval around that prediction.
  We use the algorithms-with-predictions framework and show that the classic deferred-acceptance (DA) algorithm used to compute stable matchings is robust to such truncation. We present two algorithms and theoretically and empirically evaluate their performance. Our results show that even with reasonably accurate predictions, it is possible to significantly cut down on both instance size (the length of preference lists) as well as the number of proposals made. These results explain the practical success of the DA algorithm and connect market design to the emerging theory of algorithms with predictions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.02254v1</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Samuel McCauley, Benjamin Moseley, Helia Niaparast, Shikha Singh</dc:creator>
    </item>
    <item>
      <title>Carry-Over Lottery Allocation: Practical Incentive-Compatible Drafts</title>
      <link>https://arxiv.org/abs/2602.02487</link>
      <description>arXiv:2602.02487v2 Announce Type: new 
Abstract: The NBA Draft lottery is designed to promote competitive balance by awarding better draft positions to weaker teams, but it creates incentives to deliberately lose, a practice known as tanking. We propose a draft mechanism that is simultaneously practical, incentive-compatible, and advantages weaker teams. The Carry-Over Lottery Allocation (COLA) Draft Mechanism represents a paradigm shift in evaluating team quality, replacing a single season's standings with playoff outcomes over multiple years. COLA uses a draft lottery where every non-playoff team receives the same number of lottery tickets, removing incentives to lose additional games after elimination. Lottery tickets that do not win a top draft pick carry over to future lotteries, while playoff success or winning a top pick diminishes a team's accumulated tickets. Over time, COLA rewards teams with poor long-term performance and less prior draft assistance. By retaining the lottery format, COLA preserves transparency and fan engagement.
  Real-world implementation challenges are addressed to demonstrate feasibility, including transitioning from the current system, handling traded draft picks, and accommodating draft classes of varying strength. The most significant challenge occurs in years with exceptionally strong draft classes, where teams may prefer missing the playoffs in order to gain lottery access, violating a foundational assumption: that teams prefer playoff success to lottery participation. We provide a solution to this problem, employing a truth-elicitation mechanism to identify such years and expand lottery eligibility to include as many playoff teams as necessary to preserve anti-tanking incentives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.02487v2</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Timothy Highley, Tannah Duncan, Ilia Volkov</dc:creator>
    </item>
    <item>
      <title>Actor-Dual-Critic Dynamics for Zero-sum and Identical-Interest Stochastic Games</title>
      <link>https://arxiv.org/abs/2602.00606</link>
      <description>arXiv:2602.00606v1 Announce Type: cross 
Abstract: We propose a novel independent and payoff-based learning framework for stochastic games that is model-free, game-agnostic, and gradient-free. The learning dynamics follow a best-response-type actor-critic architecture, where agents update their strategies (actors) using feedback from two distinct critics: a fast critic that intuitively responds to observed payoffs under limited information, and a slow critic that deliberatively approximates the solution to the underlying dynamic programming problem. Crucially, the learning process relies on non-equilibrium adaptation through smoothed best responses to observed payoffs. We establish convergence to (approximate) equilibria in two-agent zero-sum and multi-agent identical-interest stochastic games over an infinite horizon. This provides one of the first payoff-based and fully decentralized learning algorithms with theoretical guarantees in both settings. Empirical results further validate the robustness and effectiveness of the proposed approach across both classes of games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.00606v1</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ahmed Said Donmez, Yuksel Arslantas, Muhammed O. Sayin</dc:creator>
    </item>
    <item>
      <title>Multi-Head Attention Is a Multi-Player Game</title>
      <link>https://arxiv.org/abs/2602.00861</link>
      <description>arXiv:2602.00861v1 Announce Type: cross 
Abstract: Modern transformer attention is internally multi-agent -- heads compete and coordinate -- yet we train it as if it were a monolithic optimizer. We formalize this gap: cross-entropy training induces an implicit potential game among heads, and gradient descent converges to Nash equilibria with potentially unbounded inefficiency due to unpriced externalities (redundancy, correlated errors). Our main result bounds the Price of Anarchy by $\Gamma(G)$, the off-diagonal mass of a head interaction matrix capturing weight and gradient coupling. Under mild smoothness assumptions, we prove that both \emph{excess hallucination probability} and \emph{excess head redundancy} scale with PoA, unifying two distinct failure modes into a single mechanism. The bound is prescriptive: regularization that reduces $\Gamma(G)$ provably tightens PoA. We instantiate this as GAME-LoRA, combining Barlow Twins decorrelation with log-determinant coordination pressure. Experiments validate the theory: $\Gamma(G)$ predicts hallucination ($p{&lt;}0.05$), emergent coalitions exhibit selective coordination, and GAME-LoRA achieves up to 18\% hallucination reduction (8\% average) with no knowledge degradation -- a Pareto improvement inaccessible to methods ignoring the game structure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.00861v1</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kushal Chakrabarti, Nirmal Balachundar</dc:creator>
    </item>
    <item>
      <title>FinEvo: From Isolated Backtests to Ecological Market Games for Multi-Agent Financial Strategy Evolution</title>
      <link>https://arxiv.org/abs/2602.00948</link>
      <description>arXiv:2602.00948v1 Announce Type: cross 
Abstract: Conventional financial strategy evaluation relies on isolated backtests in static environments. Such evaluations assess each policy independently, overlook correlations and interactions, and fail to explain why strategies ultimately persist or vanish in evolving markets. We shift to an ecological perspective, where trading strategies are modeled as adaptive agents that interact and learn within a shared market. Instead of proposing a new strategy, we present FinEvo, an ecological game formalism for studying the evolutionary dynamics of multi-agent financial strategies. At the individual level, heterogeneous ML-based traders-rule-based, deep learning, reinforcement learning, and large language model (LLM) agents-adapt using signals such as historical prices and external news. At the population level, strategy distributions evolve through three designed mechanisms-selection, innovation, and environmental perturbation-capturing the dynamic forces of real markets. Together, these two layers of adaptation link evolutionary game theory with modern learning dynamics, providing a principled environment for studying strategic behavior. Experiments with external shocks and real-world news streams show that FinEvo is both stable for reproducibility and expressive in revealing context-dependent outcomes. Strategies may dominate, collapse, or form coalitions depending on their competitors-patterns invisible to static backtests. By reframing strategy evaluation as an ecological game formalism, FinEvo provides a unified, mechanism-level protocol for analyzing robustness, adaptation, and emergent dynamics in multi-agent financial markets, and may offer a means to explore the potential impact of macroeconomic policies and financial regulations on price evolution and equilibrium.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.00948v1</guid>
      <category>physics.soc-ph</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mingxi Zou, Jiaxiang Chen, Aotian Luo, Jingyi Dai, Chi Zhang, Dongning Sun, Zenglin Xu</dc:creator>
    </item>
    <item>
      <title>Verification Required: The Impact of Information Credibility on AI Persuasion</title>
      <link>https://arxiv.org/abs/2602.00970</link>
      <description>arXiv:2602.00970v1 Announce Type: cross 
Abstract: Agents powered by large language models (LLMs) are increasingly deployed in settings where communication shapes high-stakes decisions, making a principled understanding of strategic communication essential. Prior work largely studies either unverifiable cheap-talk or fully verifiable disclosure, failing to capture realistic domains in which information has probabilistic credibility. We introduce MixTalk, a strategic communication game for LLM-to-LLM interaction that models information credibility. In MixTalk, a sender agent strategically combines verifiable and unverifiable claims to communicate private information, while a receiver agent allocates a limited budget to costly verification and infers the underlying state from prior beliefs, claims, and verification outcomes. We evaluate state-of-the-art LLM agents in large-scale tournaments across three realistic deployment settings, revealing their strengths and limitations in reasoning about information credibility and the explicit behavior that shapes these interactions. Finally, we propose Tournament Oracle Policy Distillation (TOPD), an offline method that distills tournament oracle policy from interaction logs and deploys it in-context at inference time. Our results show that TOPD significantly improves receiver robustness to persuasion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.00970v1</guid>
      <category>cs.CL</category>
      <category>cs.GT</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Saaduddin Mahmud, Eugene Bagdasarian, Shlomo Zilberstein</dc:creator>
    </item>
    <item>
      <title>The Domain of RSD Characterization by Efficiency, Symmetry, and Strategy-Proofness</title>
      <link>https://arxiv.org/abs/2602.01224</link>
      <description>arXiv:2602.01224v1 Announce Type: cross 
Abstract: Given a set of $n$ individuals with strict preferences over $m$ indivisible objects, the Random Serial Dictatorship (RSD) mechanism is a method for allocating objects to individuals in a way that is efficient, fair, and incentive-compatible. A random order of individuals is first drawn, and each individual, following this order, selects their most preferred available object. The procedure continues until either all objects have been assigned or all individuals have received an object.
  RSD is widely recognized for its application in fair allocation problems involving indivisible goods, such as school placements and housing assignments. Despite its extensive use, a comprehensive axiomatic characterization has remained incomplete. For the balanced case $n=m=3$, Bogomolnaia and Moulin have shown that RSD is uniquely characterized by Ex-Post Efficiency, Equal Treatment of Equals, and Strategy-Proofness. The possibility of extending this characterization to larger markets had been a long-standing open question, which Basteck and Ehlers recently answered in the negative for all markets with $n,m\geq5$.
  This work completes the picture by identifying exactly for which pairs $\left(n,m\right)$ these three axioms uniquely characterize the RSD mechanism and for which pairs they admit multiple mechanisms. In the latter cases, we construct explicit alternatives satisfying the axioms and examine whether augmenting the set of axioms could rule out these alternatives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01224v1</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maor Ben Zaquen, Ron Holzman</dc:creator>
    </item>
    <item>
      <title>Game of Thought: Robust Information Seeking with Large Language Models Using Game Theory</title>
      <link>https://arxiv.org/abs/2602.01708</link>
      <description>arXiv:2602.01708v1 Announce Type: cross 
Abstract: Large Language Models (LLMs) are increasingly deployed in real-world scenarios where they may lack sufficient information to complete a given task. In such settings, the ability to actively seek out missing information becomes a critical capability. Existing approaches to enhancing this ability often rely on simplifying assumptions that degrade \textit{worst-case} performance. This is an issue with serious implications in high-stakes applications. In this work, we use the game of Twenty Questions to evaluate the information-seeking ability of LLMs. We introduce and formalize its adversarial counterpart, the Strategic Language Search (SLS) problem along with its variants as a two-player zero-sum extensive form game. We propose Game of Thought (GoT), a framework that applies game-theoretic techniques to approximate a Nash equilibrium (NE) strategy for the restricted variant of the game. Empirical results demonstrate that our approach consistently improves worst-case performance compared to (1) direct prompting-based methods and (2) heuristic-guided search methods across all tested settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01708v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Langyuan Cui, Chun Kai Ling, Hwee Tou Ng</dc:creator>
    </item>
    <item>
      <title>Fostering Data Collaboration in Digital Transportation Marketplaces: The Role of Privacy-Preserving Mechanisms</title>
      <link>https://arxiv.org/abs/2602.01804</link>
      <description>arXiv:2602.01804v1 Announce Type: cross 
Abstract: Data collaboration between municipal authorities (MA) and mobility providers (MPs) has brought tremendous benefits to transportation systems in the era of big data. Engaging in collaboration can improve the service operations (e.g., reduced delay) of these data owners, however, it can also raise privacy concerns and discourage data-sharing willingness. Specifically, data owners may be concerned that the shared data may leak sensitive information about their customers' mobility patterns or business secrets, resulting in the failure of collaboration. This paper investigates how privacy-preserving mechanisms can foster data collaboration in such settings. We propose a game-theoretic framework to investigate data-sharing among transportation stakeholders, especially considering perturbation-based privacy-preserving mechanisms. Numerical studies demonstrate that lower data quality expectations can incentivize voluntary data sharing, improving transport-related welfare for both MAs and MPs. Our findings provide actionable insights for policymakers and system designers on how privacy-preserving technologies can help bridge data silos and promote collaborative, privacy-aware transportation systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01804v1</guid>
      <category>eess.SY</category>
      <category>cs.GT</category>
      <category>cs.SY</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qiqing Wang, Haokun Yu, Kaidi Yang</dc:creator>
    </item>
    <item>
      <title>Contracting with a Mechanism Designer</title>
      <link>https://arxiv.org/abs/2507.12054</link>
      <description>arXiv:2507.12054v2 Announce Type: replace 
Abstract: This paper explores the economic interactions within modern crowdsourcing markets. In these markets, employers issue requests for tasks, platforms facilitate the recruitment of crowd workers, and workers complete tasks for monetary rewards. Recognizing that these roles serve distinct functions within the ecosystem, we introduce a three-party model that distinguishes among the principal (the requester), the intermediary (the platform), and the pool of agents (the workers). The principal, unable to directly engage with agents, relies on the intermediary to recruit and incentivize them. This interaction unfolds in two stages: first, the principal designs a profit-sharing contract with the intermediary; second, the intermediary implements a mechanism to select an agent to complete the delegated task.
  We analyze the proposed model as an extensive-form Stackelberg game. Our contributions are threefold. First, we fully characterize the subgame perfect equilibrium of our model. In particular, the principal's contract design problem can be represented as virtual value pricing, a novel auction-theoretic formulation. We identify the optimality of linear contracts, even when the task has multiple outcomes and agents' cost distributions are asymmetric. Second, to quantify the principal's utility loss from delegation and information asymmetry, we introduce the price of double marginalization (PoDM) and the classical price of anarchy (PoA). We derive tight or nearly tight bounds on both ratios under regular and monotone hazard rate distributions. Finally, we extend our analysis to two natural variants of the base model: (i) the intermediary is restricted to anonymous pricing mechanisms, and (ii) the principal lacks precise information about the market size.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.12054v2</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tian Bai, Yiding Feng, Yaohao Liu, Mengfan Ma, Mingyu Xiao</dc:creator>
    </item>
    <item>
      <title>Large-Scale Auto-bidding with Nash Equilibrium Constraints</title>
      <link>https://arxiv.org/abs/2503.10304</link>
      <description>arXiv:2503.10304v2 Announce Type: replace-cross 
Abstract: Auto-bidding has become a cornerstone of modern online advertising platforms, enabling many advertisers to automate bidding at scale and optimize campaign performance. However, prevailing industrial systems rely on single-agent auto-bidding methods that are scalable but overlook the strategic interdependence among advertisers' bids, leading to unstable or suboptimal outcomes. While recent works recognize the game-theoretic nature of auto-bidding, existing approaches remain either computationally intractable at scale or lack a principled equilibrium-selection that aligns with platform-wide objectives. In this paper, we bridge this gap by introducing Nash Equilibrium-Constrained Bidding (NCB), a principled and scalable auto-bidding framework that recasts auto-bidding as a platform-wide optimization problem subject to Nash equilibrium constraints. This approach accounts for fine-grained strategic interdependencies among advertisers, ensuring both agent-level stability and ecosystem-level optimality. Notably, we develop a theoretically sound penalty-based primal-dual gradient method with rigorous convergence guarantees, supported by an efficient algorithm suitable for industrial deployment. Extensive experiments validate the effectiveness of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.10304v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhiyu Mou, Miao Xu, Rongquan Bai, Zhuoran Yang, Chuan Yu, Jian Xu, Bo Zheng</dc:creator>
    </item>
    <item>
      <title>Past-Discounting is Key for Learning Markovian Fairness with Long Horizons</title>
      <link>https://arxiv.org/abs/2504.01154</link>
      <description>arXiv:2504.01154v2 Announce Type: replace-cross 
Abstract: Fairness is an important consideration for dynamic resource allocation in multi-agent systems. Many existing methods treat fairness as a one-shot problem without considering temporal dynamics, which misses the nuances of accumulating inequalities over time. Recent approaches overcome this limitation by tracking allocations over time, assuming perfect recall of all past utilities. While the former neglects long-term equity, the latter introduces a critical challenge: the augmented state space required to track cumulative utilities grows unboundedly with time, hindering the scalability and convergence of learning algorithms. Motivated by behavioral insights that human fairness judgments discount distant events, we introduce a framework for temporal fairness that incorporates past-discounting into the learning problem. This approach offers a principled interpolation between instantaneous and perfect-recall fairness. Our central contribution is a past-discounted framework for memory tracking and a theoretical analysis of fairness memories, showing past-discounting guarantees a bounded, horizon-independent state space, a property that we prove perfect-recall methods lack. This result unlocks the ability to learn fair policies tractably over arbitrarily long horizons. We formalize this framework, demonstrate its necessity with experiments showing that perfect recall fails where past-discounting succeeds, and provide a clear path toward building scalable and equitable resource allocation systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.01154v2</guid>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ashwin Kumar, William Yeoh</dc:creator>
    </item>
    <item>
      <title>Is This Predictor More Informative than Another? A Decision-Theoretical Comparison</title>
      <link>https://arxiv.org/abs/2507.12094</link>
      <description>arXiv:2507.12094v2 Announce Type: replace-cross 
Abstract: In many real-world applications, a model provider provides probabilistic forecasts to downstream decision-makers who use them to make decisions under diverse payoff objectives. The provider may have access to multiple predictive models, each potentially miscalibrated, and must choose which model to deploy in order to maximize the usefulness of predictions for downstream decisions. A central challenge arises: how can the provider meaningfully compare two predictors when neither is guaranteed to be well-calibrated, and when the relevant decision tasks may differ across users and contexts?
  To answer this, our first contribution introduces the notion of the informativeness gap between any two predictors, defined as the maximum normalized payoff advantage one predictor offers over the other across all decision-making tasks. Our framework strictly generalizes several existing notions: it subsumes U-Calibration and Calibration Decision Loss, which compare a miscalibrated predictor to its calibrated counterpart, and it recovers Blackwell informativeness as a special case when both predictors are perfectly calibrated. Our second contribution is a dual characterization of the informativeness gap, which gives rise to a natural informativeness measure that can be viewed as a relaxed variant of the earth mover's distance between two prediction distributions. We show that this measure satisfies natural desiderata: it is complete and sound, and it can be estimated sample-efficiently in the prediction-only access setting. We complement our theory with experiments on LLM-based forecasters in real-world prediction tasks, showing that the informativeness gap offers a more decision-relevant alternative to traditional metrics, and provides a principled lens for evaluating how ad hoc calibration post-processing affects downstream decision usefulness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.12094v2</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yiding Feng, Liuhan Qian, Wei Tang</dc:creator>
    </item>
    <item>
      <title>Bilevel subsidy-enabled mobility hub network design with perturbed utility coalitional choice-based assignment</title>
      <link>https://arxiv.org/abs/2509.10465</link>
      <description>arXiv:2509.10465v2 Announce Type: replace-cross 
Abstract: Urban mobility is undergoing rapid transformation with the emergence of new services. Mobility hubs (MHs) have been proposed as physical-digital convergence points, offering a range of public and private mobility options in close proximity. By supporting Mobility-as-a-Service, these hubs can serve as focal points where travel decisions intersect with operator strategies. We develop a bilevel MH platform design model that treats MHs as control levers. The upper level (platform) maximizes revenue or flow by setting subsidies to incentivize last-mile operators; the lower level captures joint traveler-operator decisions with a link-based Perturbed Utility Route Choice (PURC) assignment, yielding a strictly convex quadratic program. We reformulate the bilevel problem to a single-level program via the KKT conditions of the lower level and solve it with a gap-penalty method and an iterative warm-start scheme that exploits the computationally cheap lower-level problem. Numerical experiments on a toy network and a Long Island Rail Road (LIRR) case (244 nodes, 469 links, 78 ODs) show that the method attains sub-1% optimality gaps in minutes. In the base LIRR case, the model allows policymakers to quantify the social surplus value of a MH, or the value of enabling subsidy or regulating the microtransit operator's pricing. Comparing link-based subsidies to hub-based subsidies, the latter is computationally more expensive but offers an easier mechanism for comparison and control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10465v2</guid>
      <category>math.OC</category>
      <category>cs.CY</category>
      <category>cs.GT</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Hai Yang, Joseph Y. J. Chow</dc:creator>
    </item>
    <item>
      <title>Auto-bidding under Return-on-Spend Constraints with Uncertainty Quantification</title>
      <link>https://arxiv.org/abs/2509.16324</link>
      <description>arXiv:2509.16324v3 Announce Type: replace-cross 
Abstract: Auto-bidding systems are widely used in advertising to automatically determine bid values under constraints such as total budget and Return-on-Spend (RoS) targets. Existing works often assume that the value of an ad impression, such as the conversion rate, is known. This paper considers the more realistic scenario where the true value is unknown. We propose a novel method that uses conformal prediction to quantify the uncertainty of these values based on machine learning methods trained on historical bidding data with contextual features, without assuming the data are i.i.d. This approach is compatible with current industry systems that use machine learning to predict values. Building on prediction intervals, we introduce an adjusted value estimator derived from machine learning predictions, and show that it provides performance guarantees without requiring knowledge of the true value. We apply this method to enhance existing auto-bidding algorithms with budget and RoS constraints, and establish theoretical guarantees for achieving high reward while keeping RoS violations low. Empirical results on both simulated and real-world industrial datasets demonstrate that our approach improves performance while maintaining computational efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.16324v3</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiale Han, Chun Gan, Chengcheng Zhang, Jie He, Zhangang Lin, Ching Law, Xiaowu Dai</dc:creator>
    </item>
    <item>
      <title>Introduction to Automated Negotiation</title>
      <link>https://arxiv.org/abs/2511.08659</link>
      <description>arXiv:2511.08659v2 Announce Type: replace-cross 
Abstract: This book is an introductory textbook targeted towards computer science students who are completely new to the topic of automated negotiation. It does not require any prerequisite knowledge, except for elementary mathematics and basic programming skills.
  This book comes with an simple toy-world negotiation framework implemented in Python that can be used by the readers to implement their own negotiation algorithms and perform experiments with them. This framework is small and simple enough that any reader who does not like to work in Python should be able to re-implement it very quickly in any other programming language of their choice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.08659v2</guid>
      <category>cs.MA</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Dave de Jonge</dc:creator>
    </item>
  </channel>
</rss>
