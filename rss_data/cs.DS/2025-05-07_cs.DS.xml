<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 07 May 2025 04:00:11 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Single-Sample and Robust Online Resource Allocation</title>
      <link>https://arxiv.org/abs/2505.02963</link>
      <description>arXiv:2505.02963v1 Announce Type: new 
Abstract: Online Resource Allocation problem is a central problem in many areas of Computer Science, Operations Research, and Economics. In this problem, we sequentially receive $n$ stochastic requests for $m$ kinds of shared resources, where each request can be satisfied in multiple ways, consuming different amounts of resources and generating different values. The goal is to achieve a $(1-\epsilon)$-approximation to the hindsight optimum, where $\epsilon&gt;0$ is a small constant, assuming each resource has a large budget.
  In this paper, we investigate the learnability and robustness of online resource allocation. Our primary contribution is a novel Exponential Pricing algorithm with the following properties: 1. It requires only a \emph{single sample} from each of the $n$ request distributions to achieve a $(1-\epsilon)$-approximation for online resource allocation with large budgets. Such an algorithm was previously unknown, even with access to polynomially many samples, as prior work either assumed full distributional knowledge or was limited to i.i.d.\,or random-order arrivals. 2. It is robust to corruptions in the outliers model and the value augmentation model. Specifically, it maintains its $(1 - \epsilon)$-approximation guarantee under both these robustness models, resolving the open question posed in Argue, Gupta, Molinaro, and Singla (SODA'22). 3. It operates as a simple item-pricing algorithm that ensures incentive compatibility.
  The intuition behind our Exponential Pricing algorithm is that the price of a resource should adjust exponentially as it is overused or underused. It differs from conventional approaches that use an online learning algorithm for item pricing. This departure guarantees that the algorithm will never run out of any resource, but loses the usual no-regret properties of online learning algorithms, necessitating a new analytical approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02963v1</guid>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rohan Ghuge, Sahil Singla, Yifan Wang</dc:creator>
    </item>
    <item>
      <title>Stochastic scheduling with Bernoulli-type jobs through policy stratification</title>
      <link>https://arxiv.org/abs/2505.03349</link>
      <description>arXiv:2505.03349v1 Announce Type: new 
Abstract: This paper addresses the problem of computing a scheduling policy that minimizes the total expected completion time of a set of $N$ jobs with stochastic processing times on $m$ parallel identical machines. When all processing times follow Bernoulli-type distributions, Gupta et al. (SODA '23) exhibited approximation algorithms with an approximation guarantee $\tilde{\text{O}}(\sqrt{m})$, where $m$ is the number of machines and $\tilde{\text{O}}(\cdot)$ suppresses polylogarithmic factors in $N$, improving upon an earlier ${\text{O}}(m)$ approximation by Eberle et al. (OR Letters '19) for a special case. The present paper shows that, quite unexpectedly, the problem with Bernoulli-type jobs admits a PTAS whenever the number of different job-size parameters is bounded by a constant. The result is based on a series of transformations of an optimal scheduling policy to a "stratified" policy that makes scheduling decisions at specific points in time only, while losing only a negligible factor in expected cost. An optimal stratified policy is computed using dynamic programming. Two technical issues are solved, namely (i) to ensure that, with at most a slight delay, the stratified policy has an information advantage over the optimal policy, allowing it to simulate its decisions, and (ii) to ensure that the delays do not accumulate, thus solving the trade-off between the complexity of the scheduling policy and its expected cost. Our results also imply a quasi-polynomial $\text{O}(\log N)$-approximation for the case with an arbitrary number of job sizes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03349v1</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Antonios Antoniadis, Ruben Hoeksma, Kevin Schewior, Marc Uetz</dc:creator>
    </item>
    <item>
      <title>Planar Disjoint Shortest Paths is Fixed-Parameter Tractable</title>
      <link>https://arxiv.org/abs/2505.03353</link>
      <description>arXiv:2505.03353v1 Announce Type: new 
Abstract: In the Disjoint Shortest Paths problem one is given a graph $G$ and a set $\mathcal{T}=\{(s_1,t_1),\dots,(s_k,t_k)\}$ of $k$ vertex pairs. The question is whether there exist vertex-disjoint paths $P_1,\dots,P_k$ in $G$ so that each $P_i$ is a shortest path between $s_i$ and $t_i$. While the problem is known to be W[1]-hard in general, we show that it is fixed-parameter tractable on planar graphs with positive edge weights. Specifically, we propose an algorithm for Planar Disjoint Shortest Paths with running time $2^{O(k\log k)}\cdot n^{O(1)}$. Notably, our parameter dependency is better than state-of-the-art $2^{O(k^2)}$ for the Planar Disjoint Paths problem, where the sought paths are not required to be shortest paths.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03353v1</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Micha{\l} Pilipczuk, Giannos Stamoulis, Micha{\l} W{\l}odarczyk</dc:creator>
    </item>
    <item>
      <title>GPU Implementation of the Wavelet Tree</title>
      <link>https://arxiv.org/abs/2505.03372</link>
      <description>arXiv:2505.03372v1 Announce Type: new 
Abstract: I present a new GPU implementation of the wavelet tree data structure. It includes binary rank and select support structures that provide at least 10 times higher throughput of binary rank and select queries than the best publicly available CPU implementations at comparable storage overhead. My work also presents a new parallel tree construction algorithm that, when excluding the time to copy the data from the CPU to the GPU, outperforms the current state of the art. The GPU implementation, given enough parallelism, processes access, rank, and select queries at least 2x faster than the wavelet tree implementation contained in the widely used Succinct Data Structure Library (SDSL), including the time necessary to copy the queries from the CPU to the GPU and the results back to the CPU from the GPU.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03372v1</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marco Franzreb, Martin Burtscher, Stephan Rudolph</dc:creator>
    </item>
    <item>
      <title>A practical algorithm for 2-admissibility</title>
      <link>https://arxiv.org/abs/2505.03419</link>
      <description>arXiv:2505.03419v1 Announce Type: new 
Abstract: The $2$-admissibility of a graph is a promising measure to identify real-world networks which have an algorithmically favourable structure. In contrast to other related measures, like the weak/strong $2$-colouring numbers or the maximum density of graphs that appear as $1$-subdivisions, the $2$-admissibility can be computed in polynomial time. However, so far these results are theoretical only and no practical implementation to compute the $2$-admissibility exists.
  Here we present an algorithm which decides whether the $2$-admissibility of an input graph $G$ is at most $p$ in time $O(p^4 |V(G)|)$ and space $O(|E(G)| + p^2)$. The simple structure of the algorithm makes it easy to implement. We evaluate our implementation on a corpus of 214 real-world networks and find that the algorithm runs efficiently even on networks with millions of edges, that it has a low memory footprint, and that indeed many real world networks have a small $2$-admissibility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03419v1</guid>
      <category>cs.DS</category>
      <category>math.CO</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christine Awofeso, Patrick Greaves, Oded Lachish, Felix Reidl</dc:creator>
    </item>
    <item>
      <title>Location-Restricted Stable Matching</title>
      <link>https://arxiv.org/abs/2505.03680</link>
      <description>arXiv:2505.03680v1 Announce Type: new 
Abstract: Motivated by group-project distribution, we introduce and study stable matching under the constraint of applicants needing to share a location to be matched with the same institute, which we call the Location-Restricted Stable Matching problem (LRSM). We show that finding a feasible matching is NP-hard, making finding a feasible and stable matching automatically NP-hard. We then analyze the subproblem where all the projects have the same capacity, and the applicant population of each location is a multiple of the universal project capacity, which mimics more realistic constraints and makes finding a feasible matching in P. Even under these conditions, a stable matching (a matching without blocking pairs) may not exist, so we look for a matching that minimizes the number of blocking pairs. We find that the blocking pair minimization problem for this subproblem is inapproximable within $|A|^{1-\epsilon}$ for $|A|$ agents and provide an $|A|$-approximation algorithm to show this result is almost tight. We extend this result to show that the problem of minimizing the number of agents in blocking pairs is also inapproximable within $|A|^{1-\epsilon}$, and since there are only $|A|$ agents, this result is also almost tight.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03680v1</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Garret Castro</dc:creator>
    </item>
    <item>
      <title>Parallel GPU-Accelerated Randomized Construction of Approximate Cholesky Preconditioners</title>
      <link>https://arxiv.org/abs/2505.02977</link>
      <description>arXiv:2505.02977v1 Announce Type: cross 
Abstract: We introduce a parallel algorithm to construct a preconditioner for solving a large, sparse linear system where the coefficient matrix is a Laplacian matrix (a.k.a., graph Laplacian). Such a linear system arises from applications such as discretization of a partial differential equation, spectral graph partitioning, and learning problems on graphs. The preconditioner belongs to the family of incomplete factorizations and is purely algebraic. Unlike traditional incomplete factorizations, the new method employs randomization to determine whether or not to keep fill-ins, i.e., newly generated nonzero elements during Gaussian elimination. Since the sparsity pattern of the randomized factorization is unknown, computing such a factorization in parallel is extremely challenging, especially on many-core architectures such as GPUs. Our parallel algorithm dynamically computes the dependency among row/column indices of the Laplacian matrix to be factorized and processes the independent indices in parallel. Furthermore, unlike previous approaches, our method requires little pre-processing time. We implemented the parallel algorithm for multi-core CPUs and GPUs, and we compare their performance to other state-of-the-art methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02977v1</guid>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tianyu Liang, Chao Chen, Yotam Yaniv, Hengrui Luo, David Tench, Xiaoye S. Li, Aydin Buluc, James Demmel</dc:creator>
    </item>
    <item>
      <title>Multiplication of polynomials over finite fields</title>
      <link>https://arxiv.org/abs/2505.03101</link>
      <description>arXiv:2505.03101v1 Announce Type: cross 
Abstract: Additive Fourier Transform is sdudied. The technique of Gao-Mateer is generalized, enabling us to a fast multiplication of polynomials over finite fields.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03101v1</guid>
      <category>math.NT</category>
      <category>cs.DS</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chunlei Liu</dc:creator>
    </item>
    <item>
      <title>Lower Bounds for Greedy Teaching Set Constructions</title>
      <link>https://arxiv.org/abs/2505.03223</link>
      <description>arXiv:2505.03223v1 Announce Type: cross 
Abstract: A fundamental open problem in learning theory is to characterize the best-case teaching dimension $\operatorname{TS}_{\min}$ of a concept class $\mathcal{C}$ with finite VC dimension $d$. Resolving this problem will, in particular, settle the conjectured upper bound on Recursive Teaching Dimension posed by [Simon and Zilles; COLT 2015]. Prior work used a natural greedy algorithm to construct teaching sets recursively, thereby proving upper bounds on $\operatorname{TS}_{\min}$, with the best known bound being $O(d^2)$ [Hu, Wu, Li, and Wang; COLT 2017]. In each iteration, this greedy algorithm chooses to add to the teaching set the $k$ labeled points that restrict the concept class the most. In this work, we prove lower bounds on the performance of this greedy approach for small $k$. Specifically, we show that for $k = 1$, the algorithm does not improve upon the halving-based bound of $O(\log(|\mathcal{C}|))$. Furthermore, for $k = 2$, we complement the upper bound of $O\left(\log(\log(|\mathcal{C}|))\right)$ from [Moran, Shpilka, Wigderson, and Yuhudayoff; FOCS 2015] with a matching lower bound. Most consequentially, our lower bound extends up to $k \le \lceil c d \rceil$ for small constant $c&gt;0$: suggesting that studying higher-order interactions may be necessary to resolve the conjecture that $\operatorname{TS}_{\min} = O(d)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03223v1</guid>
      <category>stat.ML</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>math.CO</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Spencer Compton, Chirag Pabbaraju, Nikita Zhivotovskiy</dc:creator>
    </item>
    <item>
      <title>Troika algorithm: approximate optimization for accurate clique partitioning and clustering of weighted networks</title>
      <link>https://arxiv.org/abs/2505.03573</link>
      <description>arXiv:2505.03573v1 Announce Type: cross 
Abstract: Clique partitioning is a fundamental network clustering task, with applications in a wide range of computational sciences. It involves identifying an optimal partition of the nodes for a real-valued weighted graph according to the edge weights. An optimal partition is one that maximizes the sum of within-cluster edge weights over all possible node partitions. This paper introduces a novel approximation algorithm named Troika to solve this NP-hard problem in small to mid-sized networks for instances of theoretical and practical relevance. Troika uses a branch-and-cut scheme for branching on node triples to find a partition that is within a user-specified optimality gap tolerance. Troika offers advantages over alternative methods like integer programming solvers and heuristics for clique partitioning. Unlike existing heuristics, Troika returns solutions within a guaranteed proximity to global optimality. And our results indicate that Troika is faster than using the state-of-the-art integer programming solver Gurobi for most benchmark instances. Besides its advantages for solving the clique partitioning problem, we demonstrate the applications of Troika in community detection and portfolio analysis. Troika returns partitions with higher proximity to optimal compared to eight modularity-based community detection algorithms. When used on networks of correlations among stocks, Troika reveals the dynamic changes in the structure of portfolio networks including downturns from the 2008 financial crisis and the reaction to the COVID-19 pandemic. Our comprehensive results based on benchmarks from the literature and new real and random networks point to Troika as a reliable and accurate method for solving clique partitioning instances with up to 5000 edges on standard hardware.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03573v1</guid>
      <category>cs.SI</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Samin Aref, Boris Ng</dc:creator>
    </item>
    <item>
      <title>Optimal Distributed Replacement Paths</title>
      <link>https://arxiv.org/abs/2502.15378</link>
      <description>arXiv:2502.15378v3 Announce Type: replace 
Abstract: We study the replacement paths problem in the $\mathsf{CONGEST}$ model of distributed computing. Given an $s$-$t$ shortest path $P$, the goal is to compute, for every edge $e$ in $P$, the shortest-path distance from $s$ to $t$ avoiding $e$. For unweighted directed graphs, we establish the tight randomized round complexity bound for this problem as $\widetilde{\Theta}(n^{2/3} + D)$ by showing matching upper and lower bounds. Our upper bound extends to $(1+\epsilon)$-approximation for weighted directed graphs. Our lower bound applies even to the second simple shortest path problem, which asks only for the smallest replacement path length. These results improve upon the very recent work of Manoharan and Ramachandran (SIROCCO 2024), who showed a lower bound of $\widetilde{\Omega}(n^{1/2} + D)$ and an upper bound of $\widetilde{O}(n^{2/3} + \sqrt{n h_{st}} + D)$, where $h_{st}$ is the number of hops in the given $s$-$t$ shortest path $P$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.15378v3</guid>
      <category>cs.DS</category>
      <category>cs.DC</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yi-Jun Chang, Yanyu Chen, Dipan Dey, Gopinath Mishra, Hung Thuan Nguyen, Bryce Sanchez</dc:creator>
    </item>
    <item>
      <title>Estimating Random-Walk Probabilities in Directed Graphs</title>
      <link>https://arxiv.org/abs/2504.16481</link>
      <description>arXiv:2504.16481v2 Announce Type: replace 
Abstract: We study discounted random walks in a directed graph. In each vertex, the walk will either terminate with some probability $\alpha$, or continue to a random out-neighbor. We are interested in the probability $\pi(s,t)$ that such a random walk starting in $s$ ends in $t$. We wish to, with constant probability, estimate $\pi(s, t)$ within a constant relative error, unless $\pi(s, t) &lt; \delta$ for some given threshold $\delta$.
  The current status is as follows. Algorithms with worst-case running time $\tilde O(m)$ and $O(1/\delta)$ are known. A more complicated algorithm is known, which does not perform better in the worst case, but for the average running time over all $n$ possible targets $t$, it achieves an alternative bound of $O(\sqrt{d/\delta})$. All the above algorithms assume query access to the adjacency list of a node.
  On the lower bound side, the best-known lower bound for the worst case is $\Omega(n^{1/2}m^{1/4})$ with $\delta \leq 1/(n^{1/2}m^{1/4})$, and for the average case it is $\Omega(\sqrt{n})$ with $\delta \leq 1/n$. This leaves substantial polynomial gaps in both cases.
  In this paper, we show that the above upper bounds are tight across all parameters $n$, $m$ and $\delta$. We show that the right bound is $\tilde\Theta(\min\{m, 1/\delta\})$ for the worst case, and $\tilde\Theta(\min\{m, \sqrt{d/\delta}, 1/\delta\})$ for the average case.
  We also consider some additional graph queries from the literature. One allows checking whether there is an edge from $u$ to $v$ in constant time. Another allows access to the adjacency list of $u$ sorted by out-degree. We prove that none of these access queries help in the worst case, but if we have both of them, we get an average-case bound of $\tilde \Theta(\min\{m,\sqrt{d/\delta}, (1/\delta)^{2/3}\})$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16481v2</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christian Bertram, Mads Vestergaard Jensen, Mikkel Thorup, Hanzhi Wang, Shuyi Yan</dc:creator>
    </item>
    <item>
      <title>Delta-modular ILP Problems of Bounded Codimension, Discrepancy, and Convolution (new version)</title>
      <link>https://arxiv.org/abs/2405.17001</link>
      <description>arXiv:2405.17001v4 Announce Type: replace-cross 
Abstract: For integers $k,n \geq 0$ and a cost vector $c \in Z^n$, we study two fundamental integer linear programming (ILP) problems: \[
  \text{(Standard Form)} \quad \max\bigl\{c^\top x \colon Ax = b,\ x \in Z^n_{\geq 0}\bigr\} \text{ with } A \in Z^{k \times n}, \text{rank}(A) = k, b \in Z^k, \] \[
  \text{(Canonical Form)} \quad \max\bigl\{c^\top x \colon Ax \leq b,\ x \in Z^n\bigr\} \text{ with } A \in Z^{(n+k) \times n}, \text{rank}(A) = n, b \in Z^{n+k}. \] We present improved algorithms for both problems and their feasibility versions, parameterized by $k$ and $\Delta$, where $\Delta$ denotes the maximum absolute value of $\text{rank}(A) \times \text{rank}(A)$ subdeterminants of $A$. Our main complexity results, stated in terms of required arithmetic operations, are: \[ \text{Optimization:}\quad O(\log k)^{2k} \cdot \Delta^2 / 2^{\Omega(\sqrt{\log \Delta})} + 2^{O(k)} \cdot \text{poly}(\varphi), \] \[ \text{Feasibility:} \quad O(\log k)^k \cdot \Delta \cdot (\log \Delta)^3 + 2^{O(k)} \cdot \text{poly}(\varphi), \] where $\varphi$ represents the input size measured by the bit-encoding length of $(A,b,c)$. We also examine several special cases when $k \in \{0,1\}$, which have important applications in: expected computational complexity of ILP with varying right-hand side $b$, ILP problems with generic constraint matrices, ILP problems on simplices. Our results yield improved complexity bounds for these specific scenarios.
  As independent contributions, we present: An $n^2/2^{\Omega(\sqrt{\log n})}$-time algorithm for the tropical convolution problem on sequences indexed by elements of a finite Abelian group of order $n$; A complete and self-contained error analysis of the generalized DFT over Abelian groups in the Word-RAM model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.17001v4</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>math.AC</category>
      <category>math.OC</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>M. Cherniavskii, D. Gribanov, D. Malyshev, P. M. Pardalos</dc:creator>
    </item>
  </channel>
</rss>
