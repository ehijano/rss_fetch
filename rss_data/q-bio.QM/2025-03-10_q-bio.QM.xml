<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.QM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.QM</link>
    <description>q-bio.QM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.QM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 10 Mar 2025 04:00:36 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>VenusMutHub: A systematic evaluation of protein mutation effect predictors on small-scale experimental data</title>
      <link>https://arxiv.org/abs/2503.04851</link>
      <description>arXiv:2503.04851v1 Announce Type: new 
Abstract: In protein engineering, while computational models are increasingly used to predict mutation effects, their evaluations primarily rely on high-throughput deep mutational scanning (DMS) experiments that use surrogate readouts, which may not adequately capture the complex biochemical properties of interest. Many proteins and their functions cannot be assessed through high-throughput methods due to technical limitations or the nature of the desired properties, and this is particularly true for the real industrial application scenario. Therefore, the desired testing datasets, will be small-size (~10-100) experimental data for each protein, and involve as many proteins as possible and as many properties as possible, which is, however, lacking. Here, we present VenusMutHub, a comprehensive benchmark study using 905 small-scale experimental datasets curated from published literature and public databases, spanning 527 proteins across diverse functional properties including stability, activity, binding affinity, and selectivity. These datasets feature direct biochemical measurements rather than surrogate readouts, providing a more rigorous assessment of model performance in predicting mutations that affect specific molecular functions. We evaluate 23 computational models across various methodological paradigms, such as sequence-based, structure-informed and evolutionary approaches. This benchmark provides practical guidance for selecting appropriate prediction methods in protein engineering applications where accurate prediction of specific functional properties is crucial.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.04851v1</guid>
      <category>q-bio.QM</category>
      <pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Liang Zhanga, Hua Pangb, Chenghao Zhang, Song Li, Yang Tan, Fan Jiang, Mingchen Li, Yuanxi Yu, Ziyi Zhou, Banghao Wu, Bingxin Zhou, Hao Liu, Pan Tan, Liang Hong</dc:creator>
    </item>
    <item>
      <title>Hierarchical Functional Group Ranking via IUPAC Name Analysis for Drug Discovery: A Case Study on TDP1 Inhibitors</title>
      <link>https://arxiv.org/abs/2503.05591</link>
      <description>arXiv:2503.05591v1 Announce Type: new 
Abstract: The article proposes a computational approach that can generate a descending order of the IUPAC-notated functional groups based on their importance for a given case study. Thus, a reduced list of functional groups could be obtained from which drug discovery can be successfully initiated. The approach, applicable to any study case with sufficient data, was demonstrated using a PubChem bioassay focused on TDP1 inhibitors. The Scikit Learn interpretation of the Random Forest Classifier (RFC) algorithm was employed. The machine learning (ML) model RFC obtained 70.9% accuracy, 73.1% precision, 66.1% recall, 69.4% F1 and 70.8% receiver-operating characteristic (ROC). In addition to the main study, the CID_SID ML model was developed, which, using only the PubChem compound and substance identifiers (CIDs and SIDs) data, can predict with 85.2% accuracy, 94.2% precision, 75% precision, F1 of 83.5% F1 and 85.2% ROC whether a compound is a TDP1 inhibitor.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.05591v1</guid>
      <category>q-bio.QM</category>
      <pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mariya L. Ivanova, Nicola Russo, Konstantin Nikolic</dc:creator>
    </item>
    <item>
      <title>ZAugNet for Z-Slice Augmentation in Bio-Imaging</title>
      <link>https://arxiv.org/abs/2503.04843</link>
      <description>arXiv:2503.04843v1 Announce Type: cross 
Abstract: Three-dimensional biological microscopy has significantly advanced our understanding of complex biological structures. However, limitations due to microscopy techniques, sample properties or phototoxicity often result in poor z-resolution, hindering accurate cellular measurements. Here, we introduce ZAugNet, a fast, accurate, and self-supervised deep learning method for enhancing z-resolution in biological images. By performing nonlinear interpolation between consecutive slices, ZAugNet effectively doubles resolution with each iteration. Compared on several microscopy modalities and biological objects, it outperforms competing methods on most metrics. Our method leverages a generative adversarial network (GAN) architecture combined with knowledge distillation to maximize prediction speed without compromising accuracy. We also developed ZAugNet+, an extended version enabling continuous interpolation at arbitrary distances, making it particularly useful for datasets with nonuniform slice spacing. Both ZAugNet and ZAugNet+ provide high-performance, scalable z-slice augmentation solutions for large-scale 3D imaging. They are available as open-source frameworks in PyTorch, with an intuitive Colab notebook interface for easy access by the scientific community.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.04843v1</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>eess.IV</category>
      <category>q-bio.QM</category>
      <pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Alessandro Pasqui, Sajjad Mahdavi, Benoit Vianay, Alexandra Colin, Alex McDougall, R\'emi Dumollard, Yekaterina A. Miroshnikova, Elsa Labrune, Herv\'e Turlier</dc:creator>
    </item>
    <item>
      <title>FOSS solution for Molecular Dynamics Simulation Automation and Collaboration with MDSGAT</title>
      <link>https://arxiv.org/abs/2503.05113</link>
      <description>arXiv:2503.05113v1 Announce Type: cross 
Abstract: The process of setting up and successfully running Molecular Dynamics Simulations (MDS) is outlined to be incredibly labour and computationally expensive with a very high barrier to entry for newcomers wishing to utilise the benefits and insights of MDS. Here, presented, is a unique Free and Open-Source Software (FOSS) solution that aims to not only reduce the barrier of entry for new Molecular Dynamics (MD) users, but also significantly reduce the setup time and hardware utilisation overhead for even highly experienced MD researchers. This is accomplished through the creation of the Molecular Dynamics Simulation Generator and Analysis Tool (MDSGAT) which currently serves as a viable alternative to other restrictive or privatised MDS Graphical solutions with a unique design that allows for seamless collaboration and distribution of exact MD simulation setups and initialisation parameters through a single setup file. This solution is designed from the start with a modular mindset allowing for additional software expansion to incorporate numerous extra MDS packages and analysis methods over time</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.05113v1</guid>
      <category>cs.CE</category>
      <category>q-bio.QM</category>
      <pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>J. G. Nelson, X. Liu, K. T. Yong</dc:creator>
    </item>
    <item>
      <title>Joint graphical model estimation using Stein-type shrinkage for fast large scale network inference in scRNAseq data</title>
      <link>https://arxiv.org/abs/2503.05448</link>
      <description>arXiv:2503.05448v1 Announce Type: cross 
Abstract: Graphical modeling is a widely used tool for analyzing conditional dependencies between variables and traditional methods may struggle to capture shared and distinct structures in multi-group or multi-condition settings. Joint graphical modeling (JGM) extends this framework by simultaneously estimating network structures across multiple related datasets, allowing for a deeper understanding of commonalities and differences. This capability is particularly valuable in fields such as genomics and neuroscience, where identifying variations in network topology can provide critical biological insights. Existing JGM methodologies largely fall into two categories: regularization-based approaches, which introduce additional penalties to enforce structured sparsity, and Bayesian frameworks, which incorporate prior knowledge to improve network inference. In this study, we explore an alternative method based on two-target linear covariance matrix shrinkage. Formula for optimal shrinkage intensities is proposed which leads to the development of JointStein framework. Performance of JointStein framework is proposed through simulation benchmarking which demonstrates its effectiveness for large-scale single-cell RNA sequencing (scRNA-seq) data analysis. Finally, we apply our approach to glioblastoma scRNA-seq data, uncovering dynamic shifts in T cell network structures across disease progression stages. The result highlights potential of JointStein framework in extracting biologically meaningful insights from high-dimensional data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.05448v1</guid>
      <category>stat.ME</category>
      <category>q-bio.MN</category>
      <category>q-bio.QM</category>
      <pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Duong H. T. Vo, Nelofer Syed, Thomas Thorne</dc:creator>
    </item>
    <item>
      <title>Global graph features unveiled by unsupervised geometric deep learning</title>
      <link>https://arxiv.org/abs/2503.05560</link>
      <description>arXiv:2503.05560v1 Announce Type: cross 
Abstract: Graphs provide a powerful framework for modeling complex systems, but their structural variability makes analysis and classification challenging. To address this, we introduce GAUDI (Graph Autoencoder Uncovering Descriptive Information), a novel unsupervised geometric deep learning framework that captures both local details and global structure. GAUDI employs an innovative hourglass architecture with hierarchical pooling and upsampling layers, linked through skip connections to preserve essential connectivity information throughout the encoding-decoding process. By mapping different realizations of a system - generated from the same underlying parameters - into a continuous, structured latent space, GAUDI disentangles invariant process-level features from stochastic noise. We demonstrate its power across multiple applications, including modeling small-world networks, characterizing protein assemblies from super-resolution microscopy, analyzing collective motion in the Vicsek model, and capturing age-related changes in brain connectivity. This approach not only improves the analysis of complex graphs but also provides new insights into emergent phenomena across diverse scientific domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.05560v1</guid>
      <category>cs.LG</category>
      <category>cond-mat.soft</category>
      <category>physics.bio-ph</category>
      <category>q-bio.QM</category>
      <pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mirja Granfors, Jes\'us Pineda, Blanca Zufiria Gerbol\'es, Joana B. Pereira, Carlo Manzo, Giovanni Volpe</dc:creator>
    </item>
    <item>
      <title>Joint 3D Point Cloud Segmentation using Real-Sim Loop: From Panels to Trees and Branches</title>
      <link>https://arxiv.org/abs/2503.05630</link>
      <description>arXiv:2503.05630v1 Announce Type: cross 
Abstract: Modern orchards are planted in structured rows with distinct panel divisions to improve management. Accurate and efficient joint segmentation of point cloud from Panel to Tree and Branch (P2TB) is essential for robotic operations. However, most current segmentation methods focus on single instance segmentation and depend on a sequence of deep networks to perform joint tasks. This strategy hinders the use of hierarchical information embedded in the data, leading to both error accumulation and increased costs for annotation and computation, which limits its scalability for real-world applications. In this study, we proposed a novel approach that incorporated a Real2Sim L-TreeGen for training data generation and a joint model (J-P2TB) designed for the P2TB task. The J-P2TB model, trained on the generated simulation dataset, was used for joint segmentation of real-world panel point clouds via zero-shot learning. Compared to representative methods, our model outperformed them in most segmentation metrics while using 40% fewer learnable parameters. This Sim2Real result highlighted the efficacy of L-TreeGen in model training and the performance of J-P2TB for joint segmentation, demonstrating its strong accuracy, efficiency, and generalizability for real-world applications. These improvements would not only greatly benefit the development of robots for automated orchard operations but also advance digital twin technology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.05630v1</guid>
      <category>cs.RO</category>
      <category>cs.CV</category>
      <category>q-bio.QM</category>
      <pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Tian Qiu, Ruiming Du, Nikolai Spine, Lailiang Cheng, Yu Jiang</dc:creator>
    </item>
    <item>
      <title>Mamba-based Deep Learning Approaches for Sleep Staging on a Wireless Multimodal Wearable System without Electroencephalography</title>
      <link>https://arxiv.org/abs/2412.15947</link>
      <description>arXiv:2412.15947v2 Announce Type: replace 
Abstract: Study Objectives: We investigate Mamba-based deep learning approaches for sleep staging on signals from ANNE One (Sibel Health, Evanston, IL), a non-intrusive dual-module wireless wearable system measuring chest electrocardiography (ECG), accelerometry, and temperature, and finger photoplethysmography (PPG) and temperature.
  Methods: We obtained wearable sensor recordings from 360 adults undergoing concurrent polysomnography (PSG) at a tertiary care sleep lab. Each PSG recording was manually scored and these annotations served as ground truth labels for training and evaluation of our models. PSG and wearable sensor data were automatically aligned using their ECG channels with manual confirmation by visual inspection. We trained Mamba-based models with convolutional-recurrent neural network (CRNN) and the recurrent neural network (RNN) architectures on these recordings. Ensembling of model variants with similar architectures was performed.
  Results: Our best approach, after ensembling, attains a 3-class (wake, non rapid eye movement [NREM] sleep, rapid eye movement [REM] sleep) balanced accuracy of 84.02%, F1 score of 84.23%, Cohen's $\kappa$ of 72.89%, and a Matthews correlation coefficient (MCC) score of 73.00%; a 4-class (wake, NREM stage 1/2 [N1/N2], NREM stage 3 [N3], REM) balanced accuracy of 75.30%, F1 score of 74.10%, Cohen's $\kappa$ of 61.51%, and MCC score of 61.95%; a 5-class (wake, N1, N2, N3, REM) balanced accuracy of 65.11%, F1 score of 66.15%, Cohen's $\kappa$ of 53.23%, MCC score of 54.38%.
  Conclusions: Deep learning models can infer major sleep stages from the ANNE One, a wearable system without electroencephalography (EEG), and can be successfully applied to data from adults attending a tertiary care sleep clinic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.15947v2</guid>
      <category>q-bio.QM</category>
      <category>cs.LG</category>
      <pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrew H. Zhang, Alex He-Mo, Richard Fei Yin, Chunlin Li, Yuzhi Tang, Dharmendra Gurve, Veronique van der Horst, Aron S. Buchman, Nasim Montazeri Ghahjaverestan, Maged Goubran, Bo Wang, Andrew S. P. Lim</dc:creator>
    </item>
    <item>
      <title>Brain states analysis of EEG predicts multiple sclerosis and mirrors disease duration and burden</title>
      <link>https://arxiv.org/abs/2406.15665</link>
      <description>arXiv:2406.15665v3 Announce Type: replace-cross 
Abstract: Background: Any treatment of multiple sclerosis should preserve mental function, considering how cognitive deterioration interferes with quality of life. However, mental assessment is still realized with neuro-psychological tests without monitoring cognition on neurobiological grounds whereas the ongoing neural activity is readily observable and readable.
  Objectives: The proposed method deciphers electrical brain states which as multi-dimensional cognetoms quantitatively discriminate normal from pathological patterns in an EEG.
  Methods: Baseline recordings from a prior EEG study of 93 subjects, 37 with MS, were analyzed. Spectral bands served to compute cognetoms and categorize subsequent feature combination sets.
  Results: A significant correlation arose between brain states predictors, clinical data and disease duration. Using cognetoms and spectral bands, a cross-sectional comparison separated patients from controls with a precision of 82% while using bands alone arrived at 64%.
  Conclusions: Brain states analysis successfully distinguishes controls from patients with MS. The congruity with disease duration is a neurobiological indicator for disease accumulation over time. Our results imply that data-driven comparisons of EEG data may complement customary diagnostic methods in neurology and psychiatry. However, thinking ahead for quantitative monitoring of disease time course and treatment efficacy, we hope to have established the analytic principles applicable to longitudinal clinical studies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15665v3</guid>
      <category>q-bio.NC</category>
      <category>q-bio.QM</category>
      <pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Istv\'an M\'orocz (McGill University Montreal QC Canada, Noisis Inc. Montreal QC Canada), Mojtaba Jouzizadeh (University of Ottawa Canada), Amir H. Ghaderi (University of Calgary Canada), Hamed Cheraghmakani (Mazandaran University of Medical Sciences Sari Iran), Seyed M. Baghbanian (Mazandaran University of Medical Sciences Sari Iran), Reza Khanbabaie (University of Ottawa Canada), Andrei Mogoutov (Noisis Inc. Montreal QC Canada)</dc:creator>
    </item>
    <item>
      <title>Redefining spectral unmixing for in-vivo brain tissue analysis from hyperspectral imaging</title>
      <link>https://arxiv.org/abs/2503.00198</link>
      <description>arXiv:2503.00198v2 Announce Type: replace-cross 
Abstract: In this paper, we propose a methodology for extracting molecular tumor biomarkers from hyperspectral imaging (HSI), an emerging technology for intraoperative tissue assessment. To achieve this, we employ spectral unmixing, allowing to decompose the spectral signals recorded by the HSI camera into their constituent molecular components. Traditional unmixing approaches are based on physical models that establish a relationship between tissue molecules and the recorded spectra. However, these methods commonly assume a linear relationship between the spectra and molecular content, which does not capture the whole complexity of light-matter interaction. To address this limitation, we introduce a novel unmixing procedure that allows to take into account non-linear optical effects while preserving the computational benefits of linear spectral unmixing. We validate our methodology on an in-vivo brain tissue HSI dataset and demonstrate that the extracted molecular information leads to superior classification performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00198v2</guid>
      <category>physics.med-ph</category>
      <category>q-bio.QM</category>
      <pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Martin Hartenberger, Huzeyfe Ayaz, Fatih Ozlugedik, Charly Caredda, Luca Giannoni, Fr\'ed\'eric Lange, Laurin Lux, Jonas Weidner, Alex Berger, Florian Kofler, Martin Menten, Bruno Montcel, Ilias Tachtsidis, Daniel Rueckert, Ivan Ezhov</dc:creator>
    </item>
  </channel>
</rss>
