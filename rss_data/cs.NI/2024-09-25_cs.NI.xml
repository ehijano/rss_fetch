<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 26 Sep 2024 01:48:53 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 25 Sep 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Generative AI-Enhanced Multi-Modal Semantic Communication in Internet of Vehicles: System Design and Methodologies</title>
      <link>https://arxiv.org/abs/2409.15642</link>
      <description>arXiv:2409.15642v1 Announce Type: new 
Abstract: Vehicle-to-everything (V2X) communication supports numerous tasks, from driving safety to entertainment services. To achieve a holistic view, vehicles are typically equipped with multiple sensors to compensate for undetectable blind spots. However, processing large volumes of multi-modal data increases transmission load, while the dynamic nature of vehicular networks adds to transmission instability. To address these challenges, we propose a novel framework, Generative Artificial intelligence (GAI)-enhanced multi-modal semantic communication (SemCom), referred to as G-MSC, designed to handle various vehicular network tasks by employing suitable analog or digital transmission. GAI presents a promising opportunity to transform the SemCom framework by significantly enhancing semantic encoding to facilitate the optimized integration of multi-modal information, enhancing channel robustness, and fortifying semantic decoding against noise interference. To validate the effectiveness of the G-MSC framework, we conduct a case study showcasing its performance in vehicular communication networks for predictive tasks. The experimental results show that the design achieves reliable and efficient communication in V2X networks. In the end, we present future research directions on G-MSC.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.15642v1</guid>
      <category>cs.NI</category>
      <pubDate>Wed, 25 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiayi Lu, Wanting Yang, Zehui Xiong, Chengwen Xing, Rahim Tafazolli, Tony Q. S. Quek, Merouane Debbah</dc:creator>
    </item>
    <item>
      <title>Toward Mixture-of-Experts Enabled Trustworthy Semantic Communication for 6G Networks</title>
      <link>https://arxiv.org/abs/2409.15695</link>
      <description>arXiv:2409.15695v1 Announce Type: new 
Abstract: Semantic Communication (SemCom) plays a pivotal role in 6G networks, offering a viable solution for future efficient communication. Deep Learning (DL)-based semantic codecs further enhance this efficiency. However, the vulnerability of DL models to security threats, such as adversarial attacks, poses significant challenges for practical applications of SemCom systems. These vulnerabilities enable attackers to tamper with messages and eavesdrop on private information, especially in wireless communication scenarios. Although existing defenses attempt to address specific threats, they often fail to simultaneously handle multiple heterogeneous attacks. To overcome this limitation, we introduce a novel Mixture-of-Experts (MoE)-based SemCom system. This system comprises a gating network and multiple experts, each specializing in different security challenges. The gating network adaptively selects suitable experts to counter heterogeneous attacks based on user-defined security requirements. Multiple experts collaborate to accomplish semantic communication tasks while meeting the security requirements of users. A case study in vehicular networks demonstrates the efficacy of the MoE-based SemCom system. Simulation results show that the proposed MoE-based SemCom system effectively mitigates concurrent heterogeneous attacks, with minimal impact on downstream task accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.15695v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.CR</category>
      <pubDate>Wed, 25 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiayi He, Xiaofeng Luo, Jiawen Kang, Hongyang Du, Zehui Xiong, Ci Chen, Dusit Niyato, Xuemin Shen</dc:creator>
    </item>
    <item>
      <title>Toward Scalable and Efficient Visual Data Transmission in 6G Networks</title>
      <link>https://arxiv.org/abs/2409.15961</link>
      <description>arXiv:2409.15961v1 Announce Type: new 
Abstract: 6G network technology will emerge in a landscape where visual data transmissions dominate global mobile traffic and are expected to grow continuously, driven by the increasing demand for AI-based computer vision applications. This will make already challenging task of visual data transmission even more difficult. In this work, we review effective techniques for visual data transmission, such as content compression and adaptive video streaming, highlighting their advantages and limitations. Further, considering the scalability and cost issues of cloud-based and on-device AI services, we explore distributed in-network computing architecture like fog-computing as a direction of 6G networks, and investigate the necessary technical properties for the timely delivery of visual data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.15961v1</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Wed, 25 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junhao Cai, Taegun An, Changhee Joo</dc:creator>
    </item>
    <item>
      <title>Twinning Commercial Network Traces on Experimental Open RAN Platforms</title>
      <link>https://arxiv.org/abs/2409.16217</link>
      <description>arXiv:2409.16217v1 Announce Type: new 
Abstract: While the availability of large datasets has been instrumental to advance fields like computer vision and natural language processing, this has not been the case in mobile networking. Indeed, mobile traffic data is often unavailable due to privacy or regulatory concerns. This problem becomes especially relevant in Open Radio Access Network (RAN), where artificial intelligence can potentially drive optimization and control of the RAN, but still lags behind due to the lack of training datasets. While substantial work has focused on developing testbeds that can accurately reflect production environments, the same level of effort has not been put into twinning the traffic that traverse such networks. To fill this gap, in this paper, we design a methodology to twin real-world cellular traffic traces in experimental Open RAN testbeds. We demonstrate our approach on the Colosseum Open RAN digital twin, and publicly release a large dataset (more than 500 hours and 450 GB) with PHY-, MAC-, and App-layer Key Performance Measurements (KPMs), and protocol stack logs. Our analysis shows that our dataset can be used to develop and evaluate a number of Open RAN use cases, including those with strict latency requirements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.16217v1</guid>
      <category>cs.NI</category>
      <pubDate>Wed, 25 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3636534.3697320</arxiv:DOI>
      <dc:creator>Leonardo Bonati, Ravis Shirkhani, Claudio Fiandrino, Stefano Maxenti, Salvatore D'Oro, Michele Polese, Tommaso Melodia</dc:creator>
    </item>
    <item>
      <title>Performance Comparison of HTTP/3 and HTTP/2: Proxy vs. Non-Proxy Environments</title>
      <link>https://arxiv.org/abs/2409.16267</link>
      <description>arXiv:2409.16267v1 Announce Type: new 
Abstract: This paper provides a systematic evaluation of the performance of QUIC/HTTP3 (H3) and TCP/HTTP2 (H2) protocols in proxy-enhanced environments. By leveraging features such as UDP-based flow-controlled streams, integrated TLS, multiplexed connections, and connection migration, H3 promises enhanced web communication. Despite extensive research, the impact of proxy integration and connection migration remains underexplored. This study addresses this gap by evaluating these protocols across various scenarios in noisy networks and proxy setups. Our findings reveal that H3 excels under high loss and latency conditions, significantly benefiting from its connection migration and multiplexing features. H3's connection migration remains robust, maintaining stable performance even in proxy-enhanced environments, ensuring seamless network transitions. The proxy has a more neutral impact on H3, while it significantly enhances H2 performance, especially when using BBR. Any improvements observed in H3 under a proxy are minor and do not fundamentally alter H3's performance as they do for H2. Importantly, while H2 with the right congestion control algorithm (CCA) can achieve performance comparable to H3, H3's performance is more robust, as it is less impacted by network conditions, proxy settings, and CCA variations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.16267v1</guid>
      <category>cs.NI</category>
      <pubDate>Wed, 25 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fan Liu, John Dehart, Jyoti Parwatikar, Behrooz Farkiani, Patrick Crowley</dc:creator>
    </item>
    <item>
      <title>Real-Time Pedestrian Detection on IoT Edge Devices: A Lightweight Deep Learning Approach</title>
      <link>https://arxiv.org/abs/2409.15740</link>
      <description>arXiv:2409.15740v1 Announce Type: cross 
Abstract: Artificial intelligence (AI) has become integral to our everyday lives. Computer vision has advanced to the point where it can play the safety critical role of detecting pedestrians at road intersections in intelligent transportation systems and alert vehicular traffic as to potential collisions. Centralized computing analyzes camera feeds and generates alerts for nearby vehicles. However, real-time applications face challenges such as latency, limited data transfer speeds, and the risk of life loss. Edge servers offer a potential solution for real-time applications, providing localized computing and storage resources and lower response times. Unfortunately, edge servers have limited processing power. Lightweight deep learning (DL) techniques enable edge servers to utilize compressed deep neural network (DNN) models.
  The research explores implementing a lightweight DL model on Artificial Intelligence of Things (AIoT) edge devices. An optimized You Only Look Once (YOLO) based DL model is deployed for real-time pedestrian detection, with detection events transmitted to the edge server using the Message Queuing Telemetry Transport (MQTT) protocol. The simulation results demonstrate that the optimized YOLO model can achieve real-time pedestrian detection, with a fast inference speed of 147 milliseconds, a frame rate of 2.3 frames per second, and an accuracy of 78%, representing significant improvements over baseline models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.15740v1</guid>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.NI</category>
      <pubDate>Wed, 25 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Muhammad Dany Alfikri, Rafael Kaliski</dc:creator>
    </item>
    <item>
      <title>Positioning Error Compensation by Channel Knowledge Map in UAV Communication Missions</title>
      <link>https://arxiv.org/abs/2409.15798</link>
      <description>arXiv:2409.15798v1 Announce Type: cross 
Abstract: When Unmanned Aerial Vehicles (UAVs) perform high-precision communication tasks, such as searching for users and providing emergency coverage, positioning errors between base stations and users make it challenging to deploy trajectory planning algorithms. To address these challenges caused by position errors, a framework was proposed to compensate it by Channel Knowledge Map (CKM), which stores channel state information (CSI). By taking the positions with errors as input, the generated CKM could give a prediction of signal attenuation which is close to true positions. Based on that, the predictions are utilized to calculate the received power and a PPO-based algorithm is applied to optimize the compensation. After training, the framework is able to find a strategy that minimize the flight time under communication constraints and positioning error. Besides, the confidence interval is calculated to assist the allocation of power and the update of CKM is studied to adapt to the dynamic environment. Simulation results show the robustness of CKM to positioning error and environmental changes, and the superiority of CKM-assisted UAV communication design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.15798v1</guid>
      <category>eess.SP</category>
      <category>cs.NI</category>
      <pubDate>Wed, 25 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chiya Zhang, Ting Wang, Chunlong He</dc:creator>
    </item>
    <item>
      <title>Edge-device Collaborative Computing for Multi-view Classification</title>
      <link>https://arxiv.org/abs/2409.15973</link>
      <description>arXiv:2409.15973v1 Announce Type: cross 
Abstract: Motivated by the proliferation of Internet-of-Thing (IoT) devices and the rapid advances in the field of deep learning, there is a growing interest in pushing deep learning computations, conventionally handled by the cloud, to the edge of the network to deliver faster responses to end users, reduce bandwidth consumption to the cloud, and address privacy concerns. However, to fully realize deep learning at the edge, two main challenges still need to be addressed: (i) how to meet the high resource requirements of deep learning on resource-constrained devices, and (ii) how to leverage the availability of multiple streams of spatially correlated data, to increase the effectiveness of deep learning and improve application-level performance. To address the above challenges, we explore collaborative inference at the edge, in which edge nodes and end devices share correlated data and the inference computational burden by leveraging different ways to split computation and fuse data. Besides traditional centralized and distributed schemes for edge-end device collaborative inference, we introduce selective schemes that decrease bandwidth resource consumption by effectively reducing data redundancy. As a reference scenario, we focus on multi-view classification in a networked system in which sensing nodes can capture overlapping fields of view. The proposed schemes are compared in terms of accuracy, computational expenditure at the nodes, communication overhead, inference latency, robustness, and noise sensitivity. Experimental results highlight that selective collaborative schemes can achieve different trade-offs between the above performance metrics, with some of them bringing substantial communication savings (from 18% to 74% of the transmitted data with respect to centralized inference) while still keeping the inference accuracy well above 90%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.15973v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <pubDate>Wed, 25 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marco Palena, Tania Cerquitelli, Carla Fabiana Chiasserini</dc:creator>
    </item>
    <item>
      <title>Age of Gossip in Networks with Multiple Views of a Source</title>
      <link>https://arxiv.org/abs/2409.16285</link>
      <description>arXiv:2409.16285v1 Announce Type: cross 
Abstract: We consider the version age of information (AoI) in a network where a subset of nodes act as sensing nodes, sampling a source that in general can follow a continuous distribution. Any sample of the source constitutes a new version of the information and the version age of the information is defined with respect to the most recent version of the information available for the whole network. We derive a recursive expression for the average version AoI between different subsets of the nodes which can be used to evaluate the average version AoI for any subset of the nodes including any single node. We derive asymptotic behavior of the average AoI on any single node of the network for various topologies including line, ring, and fully connected networks. The prior art result on version age of a network by Yates [ISIT'21] can be interpreted as in our derivation as a network with a single view of the source, e.g., through a Poisson process with rate $\lambda_{00}$. Our result indicates that there is no loss in the average version AoI performance by replacing a single view of the source with distributed sensing across multiple nodes by splitting the same rate $\lambda_{00}$. Particularly, we show that asymptotically, the average AoI scales with $O(\log(n))$ and $O(\sqrt{n})$ for fully connected and ring networks, respectively. More interestingly, we show that for the ring network the same $O(\sqrt{n})$ asymptotical performance on average AoI is still achieved with distributed sensing if the number of sensing nodes only scales with $O(\sqrt{n})$ instead of prior known result which requires $O(n)$. Our results indicate that the sensing nodes can be arbitrarily chosen as long as the maximum number of consecutive non-sensing nodes also scales as $O(\sqrt{n})$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.16285v1</guid>
      <category>cs.IT</category>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>eess.SY</category>
      <category>math.IT</category>
      <pubDate>Wed, 25 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kian J. Khojastepour, Matin Mortaheb, Sennur Ulukus</dc:creator>
    </item>
    <item>
      <title>Universal Session Protocol: A General Solution to Remote Code Execution</title>
      <link>https://arxiv.org/abs/2306.14339</link>
      <description>arXiv:2306.14339v2 Announce Type: replace-cross 
Abstract: Currently, the TCP/IP model enables exploitation of vulnerabilities anonymously by unconditionally fulfilling every request for a connection into an application; the model only incorporates authentication within applications themselves, rather than as a precondition for access into applications. I am proposing the Universal Session Protocol as a change to the architecture of the TCP/IP model to include a session layer featuring a structured generalized process for authentication negotiation and fulfillment. The Universal Session Protocol addresses an urgent and vital need to eliminate unauthenticated data processing on security critical systems. Previous work regarding TCP/IP security has focused on the application design and implementation and existing protocol layers, but has failed to posit the addition of a session layer as a mitigating control. Failing to implement a distinct authentication layer leaves every resource connected to the global Internet, including life and security critical infrastructure, vulnerable to attacks from anonymous and untraceable sources. The Universal Session Protocol provides a solution by establishing a TCP/IP Session Layer that explicitly provides authentication before a data stream is accessible within an application. After authentication, an identity is associated with the data stream so that all data may be related back to that identity for forensic purposes. If authentication fails, the application will never process user data, rendering the service safe from anonymous bad actors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.14339v2</guid>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <pubDate>Wed, 25 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jonathon Anderson</dc:creator>
    </item>
    <item>
      <title>Transport-Level Encryption in Datacenter Networks</title>
      <link>https://arxiv.org/abs/2406.15686</link>
      <description>arXiv:2406.15686v2 Announce Type: replace-cross 
Abstract: Cloud applications need network data encryption to isolate from other tenants and protect their data from potential eavesdroppers in the network infrastructure. This paper presents SDT, a protocol design for emerging datacenter transport protocols to integrate data encryption while using existing NIC offloading designed for TLS over TCP. Therefore, SDT could enable a deployment path of new transport protocols in data-centers without giving up hardware offloading.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15686v2</guid>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <pubDate>Wed, 25 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tianyi Gao, Xinshu Ma, Suhas Narreddy, Eugenio Luo, Steven W. D. Chien, Michio Honda</dc:creator>
    </item>
    <item>
      <title>NL-COMM: Demonstrating Gains of Non-Linear Processing in Open-RAN Ecosystem</title>
      <link>https://arxiv.org/abs/2409.12930</link>
      <description>arXiv:2409.12930v2 Announce Type: replace-cross 
Abstract: Multi-user multiple-input, multiple-output (MU-MIMO) designs can substantially increase wireless systems' achievable throughput and connectivity capabilities. However, existing MU-MIMO deployments typically utilize linear processing techniques that, despite their practical benefits, such as low computational complexity and easy integrability, can leave much of the available throughput and connectivity gains unexploited. They typically require many power-intensive antennas and RF chains to support a smaller number of MIMO streams, even when the transmitted information streams are of low rate. Alternatively, non-linear (NL) processing methods can maximize the capabilities of the MIMO channel. Despite their potential, traditional NL methods are challenged by high computational complexity and processing latency, making them impractical for real-time applications, especially in software-based systems envisioned for emerging Open Radio Access Networks (Open-RAN). Additionally, essential functionalities such as rate adaptation (RA) are currently unavailable for NL systems, limiting their practicality in real-world deployments. In this demo, we present the latest capabilities of our advanced NL processing framework (NL-COMM) in real-time and over-the-air, comparing them side-by-side with conventional linear processing. For the first time, NL-COMM not only meets the practical 5G-NR real-time latency requirements in pure software but also does so within a standard-compliant ecosystem. To achieve this, we significantly extended the NL-COMM algorithmic framework to support the first practical RA for NL processing. The demonstrated gains include enhanced connectivity by supporting four MIMO streams with a single base-station antenna, substantially increased throughput, and the ability to halve the number of base-station antennas without any performance loss to linear approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.12930v2</guid>
      <category>eess.SP</category>
      <category>cs.NI</category>
      <pubDate>Wed, 25 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chathura Jayawardena, Marcin Filo, George N. Katsaros, Konstantinos Nikitopoulos</dc:creator>
    </item>
  </channel>
</rss>
