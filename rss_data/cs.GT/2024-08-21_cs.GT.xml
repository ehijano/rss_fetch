<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 22 Aug 2024 01:37:10 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 21 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Toward Fair and Strategyproof Tournament Rules for Tournaments with Partially Transferable Utilities</title>
      <link>https://arxiv.org/abs/2408.10346</link>
      <description>arXiv:2408.10346v1 Announce Type: new 
Abstract: A tournament on $n$ agents is a complete oriented graph with the agents as vertices and edges that describe the win-loss outcomes of the $\binom{n}{2}$ matches played between each pair of agents. The winner of a tournament is determined by a tournament rule that maps tournaments to probability distributions over the agents. We want these rules to be fair (choose a high-quality agent) and robust to strategic manipulation. Prior work has shown that under minimally fair rules, manipulations between two agents can be prevented when utility is nontransferable but not when utility is completely transferable. We introduce a partially transferable utility model that interpolates between these two extremes using a selfishness parameter $\lambda$. Our model is that an agent may be willing to lose on purpose, sacrificing some of her own chance of winning, but only if the colluding pair's joint gain is more than $\lambda$ times the individual's sacrifice.
  We show that no fair tournament rule can prevent manipulations when $\lambda &lt; 1$. We computationally solve for fair and manipulation-resistant tournament rules for $\lambda = 1$ for up to 6 agents. We conjecture and leave as a major open problem that such a tournament rule exists for all $n$. We analyze the trade-offs between ``relative'' and ``absolute'' approximate strategyproofness for previously studied rules and derive as a corollary that all of these rules require $\lambda \geq \Omega(n)$ to be robust to manipulation. We show that for stronger notions of fairness, non-manipulable tournament rules are closely related to tournament rules that witness decreasing gains from manipulation as the number of agents increases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.10346v1</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David Pennock, Ariel Schvartzman, Eric Xue</dc:creator>
    </item>
    <item>
      <title>Price Competition Under A Consider-Then-Choose Model With Lexicographic Choice</title>
      <link>https://arxiv.org/abs/2408.10429</link>
      <description>arXiv:2408.10429v1 Announce Type: new 
Abstract: The sorting and filtering capabilities offered by modern e-commerce platforms significantly impact customers' purchase decisions, as well as the resulting prices set by competing sellers on these platforms. Motivated by this practical reality, we study price competition under a flexible choice model: Consider-then-Choose with Lexicographic Choice (CLC). In this model, a customer first forms a consideration set of sellers based on (i) her willingness-to-pay and (ii) an arbitrary set of criteria on items' non-price attributes; she then chooses the highest-ranked item according to a lexicographic ranking in which items with better performance on more important attributes are ranked higher. We provide a structural characterization of equilibria in the resulting game of price competition, and derive an economically interpretable condition, which we call gradient dominance, under which equilibria can be computed efficiently. For this subclass of CLC models, we prove that distributed gradient-based pricing dynamics converge to the set of equilibria. Extensive numerical experiments show robustness of our theoretical findings when gradient dominance does not hold.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.10429v1</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Siddhartha Banerjee, Chamsi Hssaine, Vijay Kamble</dc:creator>
    </item>
    <item>
      <title>Synchronization behind Learning in Periodic Zero-Sum Games Triggers Divergence from Nash equilibrium</title>
      <link>https://arxiv.org/abs/2408.10595</link>
      <description>arXiv:2408.10595v1 Announce Type: new 
Abstract: Learning in zero-sum games studies a situation where multiple agents competitively learn their strategy. In such multi-agent learning, we often see that the strategies cycle around their optimum, i.e., Nash equilibrium. When a game periodically varies (called a ``periodic'' game), however, the Nash equilibrium moves generically. How learning dynamics behave in such periodic games is of interest but still unclear. Interestingly, we discover that the behavior is highly dependent on the relationship between the two speeds at which the game changes and at which players learn. We observe that when these two speeds synchronize, the learning dynamics diverge, and their time-average does not converge. Otherwise, the learning dynamics draw complicated cycles, but their time-average converges. Under some assumptions introduced for the dynamical systems analysis, we prove that this behavior occurs. Furthermore, our experiments observe this behavior even if removing these assumptions. This study discovers a novel phenomenon, i.e., synchronization, and gains insight widely applicable to learning in periodic games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.10595v1</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <category>math.OC</category>
      <category>nlin.CD</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuma Fujimoto, Kaito Ariu, Kenshi Abe</dc:creator>
    </item>
    <item>
      <title>Multiwinner Temporal Voting with Aversion to Change</title>
      <link>https://arxiv.org/abs/2408.11017</link>
      <description>arXiv:2408.11017v1 Announce Type: new 
Abstract: We study two-stage committee elections where voters have dynamic preferences over candidates; at each stage, a committee is chosen under a given voting rule. We are interested in identifying a winning committee for the second stage that overlaps as much as possible with the first-stage committee. We show a full complexity dichotomy for the class of Thiele rules: this problem is tractable for Approval Voting (AV) and hard for all other Thiele rules (including, in particular, Proportional Approval Voting and the Chamberlin-Courant rule). We extend this dichotomy to the greedy variants of Thiele rules. We also explore this problem from a parameterized complexity perspective for several natural parameters. We complement the theory with experimental analysis: e.g., we investigate the average number of changes in the committee as a function of changes in voters' preferences and the role of ties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.11017v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.CC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Valentin Zech, Niclas Boehmer, Edith Elkind, Nicholas Teh</dc:creator>
    </item>
    <item>
      <title>Approval-Based Committee Voting under Incomplete Information</title>
      <link>https://arxiv.org/abs/2103.14847</link>
      <description>arXiv:2103.14847v3 Announce Type: replace 
Abstract: We investigate approval-based committee voting with incomplete information about the approval preferences of voters. We consider several models of incompleteness where each voter partitions the set of candidates into approved, disapproved, and unknown candidates, possibly with ordinal preference constraints among candidates in the latter category. This captures scenarios where voters have not evaluated all candidates and/or it is unknown where voters draw the threshold between approved and disapproved candidates. We study the complexity of some fundamental computational problems for a number of classic approval-based committee voting rules including Proportional Approval Voting and Chamberlin-Courant. These problems include determining whether a given set of candidates is a possible or necessary winning committee and whether a given candidate is possibly or necessarily a member of the winning committee. We also consider proportional representation axioms and the problem of deciding whether a given committee is possibly or necessarily representative.</description>
      <guid isPermaLink="false">oai:arXiv.org:2103.14847v3</guid>
      <category>cs.GT</category>
      <category>cs.CC</category>
      <category>cs.MA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aviram Imber, Jonas Israel, Markus Brill, Benny Kimelfeld</dc:creator>
    </item>
    <item>
      <title>Spatial Voting with Incomplete Voter Information</title>
      <link>https://arxiv.org/abs/2302.08929</link>
      <description>arXiv:2302.08929v2 Announce Type: replace 
Abstract: We consider spatial voting where candidates are located in the Euclidean $d$-dimensional space, and each voter ranks candidates based on their distance from the voter's ideal point. We explore the case where information about the location of voters' ideal points is incomplete: for each dimension, we are given an interval of possible values. We study the computational complexity of finding the possible and necessary winners for positional scoring rules. Our results show that we retain tractable cases of the classic model where voters have partial-order preferences. Moreover, we show that there are positional scoring rules under which the possible-winner problem is intractable for partial orders, but tractable in the one-dimensional spatial setting. We also consider approval voting in this setting. We show that for up to two dimensions, the necessary-winner problem is tractable, while the possible-winner problem is hard for any number of dimensions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.08929v2</guid>
      <category>cs.GT</category>
      <category>cs.CC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aviram Imber, Jonas Israel, Markus Brill, Hadas Shachnai, Benny Kimelfeld</dc:creator>
    </item>
    <item>
      <title>Minimally Modifying a Markov Game to Achieve Any Nash Equilibrium and Value</title>
      <link>https://arxiv.org/abs/2311.00582</link>
      <description>arXiv:2311.00582v4 Announce Type: replace 
Abstract: We study the game modification problem, where a benevolent game designer or a malevolent adversary modifies the reward function of a zero-sum Markov game so that a target deterministic or stochastic policy profile becomes the unique Markov perfect Nash equilibrium and has a value within a target range, in a way that minimizes the modification cost. We characterize the set of policy profiles that can be installed as the unique equilibrium of a game and establish sufficient and necessary conditions for successful installation. We propose an efficient algorithm that solves a convex optimization problem with linear constraints and then performs random perturbation to obtain a modification plan with a near-optimal cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.00582v4</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Young Wu, Jeremy McMahan, Yiding Chen, Yudong Chen, Xiaojin Zhu, Qiaomin Xie</dc:creator>
    </item>
    <item>
      <title>Nash Equilibrium and Learning Dynamics in Three-Player Matching $m$-Action Games</title>
      <link>https://arxiv.org/abs/2402.10825</link>
      <description>arXiv:2402.10825v2 Announce Type: replace 
Abstract: Learning in games discusses the processes where multiple players learn their optimal strategies through the repetition of game plays. The dynamics of learning between two players in zero-sum games, such as matching pennies, where their benefits are competitive, have already been well analyzed. However, it is still unexplored and challenging to analyze the dynamics of learning among three players. In this study, we formulate a minimalistic game where three players compete to match their actions with one another. Although interaction among three players diversifies and complicates the Nash equilibria, we fully analyze the equilibria. We also discuss the dynamics of learning based on some famous algorithms categorized into Follow the Regularized Leader. From both theoretical and experimental aspects, we characterize the dynamics by categorizing three-player interactions into three forces to synchronize their actions, switch their actions rotationally, and seek competition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.10825v2</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <category>math.OC</category>
      <category>nlin.CD</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuma Fujimoto, Kaito Ariu, Kenshi Abe</dc:creator>
    </item>
    <item>
      <title>HiBid: A Cross-Channel Constrained Bidding System with Budget Allocation by Hierarchical Offline Deep Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2312.17503</link>
      <description>arXiv:2312.17503v2 Announce Type: replace-cross 
Abstract: Online display advertising platforms service numerous advertisers by providing real-time bidding (RTB) for the scale of billions of ad requests every day. The bidding strategy handles ad requests cross multiple channels to maximize the number of clicks under the set financial constraints, i.e., total budget and cost-per-click (CPC), etc. Different from existing works mainly focusing on single channel bidding, we explicitly consider cross-channel constrained bidding with budget allocation. Specifically, we propose a hierarchical offline deep reinforcement learning (DRL) framework called ``HiBid'', consisted of a high-level planner equipped with auxiliary loss for non-competitive budget allocation, and a data augmentation enhanced low-level executor for adaptive bidding strategy in response to allocated budgets. Additionally, a CPC-guided action selection mechanism is introduced to satisfy the cross-channel CPC constraint. Through extensive experiments on both the large-scale log data and online A/B testing, we confirm that HiBid outperforms six baselines in terms of the number of clicks, CPC satisfactory ratio, and return-on-investment (ROI). We also deploy HiBid on Meituan advertising platform to already service tens of thousands of advertisers every day.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.17503v2</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hao Wang, Bo Tang, Chi Harold Liu, Shangqin Mao, Jiahong Zhou, Zipeng Dai, Yaqi Sun, Qianlong Xie, Xingxing Wang, Dong Wang</dc:creator>
    </item>
  </channel>
</rss>
