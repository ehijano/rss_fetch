<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.AR updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.AR</link>
    <description>cs.AR updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.AR" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 21 Mar 2025 01:56:31 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 20 Mar 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>NeCTAr: A Heterogeneous RISC-V SoC for Language Model Inference in Intel 16</title>
      <link>https://arxiv.org/abs/2503.14708</link>
      <description>arXiv:2503.14708v1 Announce Type: new 
Abstract: This paper introduces NeCTAr (Near-Cache Transformer Accelerator), a 16nm heterogeneous multicore RISC-V SoC for sparse and dense machine learning kernels with both near-core and near-memory accelerators. A prototype chip runs at 400MHz at 0.85V and performs matrix-vector multiplications with 109 GOPs/W. The effectiveness of the design is demonstrated by running inference on a sparse language model, ReLU-Llama.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.14708v1</guid>
      <category>cs.AR</category>
      <pubDate>Thu, 20 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1109/HCS61935.2024.10665203</arxiv:DOI>
      <dc:creator>Viansa Schmulbach, Jason Kim, Ethan Gao, Lucy Revina, Nikhil Jha, Ethan Wu, Borivoje Nikolic</dc:creator>
    </item>
    <item>
      <title>OpenLLM-RTL: Open Dataset and Benchmark for LLM-Aided Design RTL Generation</title>
      <link>https://arxiv.org/abs/2503.15112</link>
      <description>arXiv:2503.15112v1 Announce Type: new 
Abstract: The automated generation of design RTL based on large language model (LLM) and natural language instructions has demonstrated great potential in agile circuit design. However, the lack of datasets and benchmarks in the public domain prevents the development and fair evaluation of LLM solutions. This paper highlights our latest advances in open datasets and benchmarks from three perspectives: (1) RTLLM 2.0, an updated benchmark assessing LLM's capability in design RTL generation. The benchmark is augmented to 50 hand-crafted designs. Each design provides the design description, test cases, and a correct RTL code. (2) AssertEval, an open-source benchmark assessing the LLM's assertion generation capabilities for RTL verification. The benchmark includes 18 designs, each providing specification, signal definition, and correct RTL code. (3) RTLCoder-Data, an extended open-source dataset with 80K instruction-code data samples. Moreover, we propose a new verification-based method to verify the functionality correctness of training data samples. Based on this technique, we further release a dataset with 7K verified high-quality samples. These three studies are integrated into one framework, providing off-the-shelf support for the development and evaluation of LLMs for RTL code generation and verification. Finally, extensive experiments indicate that LLM performance can be boosted by enlarging the training dataset, improving data quality, and improving the training scheme.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.15112v1</guid>
      <category>cs.AR</category>
      <pubDate>Thu, 20 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Shang Liu, Yao Lu, Wenji Fang, Mengming Li, Zhiyao Xie</dc:creator>
    </item>
    <item>
      <title>Low Cost C-ITS Stations Using Raspberry Pi and the Open Source Software OScar</title>
      <link>https://arxiv.org/abs/2503.15461</link>
      <description>arXiv:2503.15461v1 Announce Type: new 
Abstract: The deployment of cooperative-intelligent transport systems (C-ITS) has started, and standardization and research activities are moving forward to improve road safety and vehicular efficiency. An aspect that is still felt as a limitation by the research groups active in the field, is the difficulty to validate the solutions with real hardware and software, because of the huge investments that are needed when multiple equipped vehicles need to be considered. In this work, we present a platform with low-cost hardware based on a Raspberry Pi and a Wi-Fi module transmitting at 5.9 GHz, and on the open-source software Open Stack for Car (OScar), which is compliant with the ETSI C-ITS standards. With a limited cost in the order of 200 EUR, the platform realizes a device which is standard compliant and can be used as either on-board unit (OBU) or road side unit (RSU). The limited cost makes the testbed scalable to several units with limited budget and the limited size makes it also deployable on mini-cars to test advanced connected and autonomous vehicle (CAV) networks and applications. Our tests demonstrate its interoperability with other devices, compliance in terms of power spectrum, and a range of a few hundred meters in line-of-sight (LOS) conditions using the standard settings of ITS-G5.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.15461v1</guid>
      <category>cs.AR</category>
      <pubDate>Thu, 20 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>L. Farina, M. Piccoli, S. Iandolo, A. Solida, C. A. Grazia, F. Raviglione, C. Casetti, A. Bazzi</dc:creator>
    </item>
    <item>
      <title>Formalising CXL Cache Coherence</title>
      <link>https://arxiv.org/abs/2410.15908</link>
      <description>arXiv:2410.15908v2 Announce Type: replace 
Abstract: We report our experience formally modelling and verifying CXL.cache, the inter-device cache coherence protocol of the Compute Express Link standard. We have used the Isabelle proof assistant to create a formal model for CXL.cache based on the prose English specification. This led to us identifying and proposing fixes to several problems we identified as unclear, ambiguous or inaccurate, some of which could lead to incoherence if left unfixed. Nearly all our issues and proposed fixes have been confirmed and tentatively accepted by the CXL consortium for adoption, save for one which is still under discussion. To validate the faithfulness of our model we performed scenario verification of essential restrictions such as "Snoop-pushes-GO", and produced a fully mechanised proof of a coherence property of the model. The considerable size of this proof, comprising tens of thousands of lemmas, prompted us to develop new proof automation tools, which we have made available for other Isabelle users working with similarly cumbersome proofs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15908v2</guid>
      <category>cs.AR</category>
      <category>cs.PL</category>
      <pubDate>Thu, 20 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3676641.3715999</arxiv:DOI>
      <arxiv:journal_reference>Proceedings of the 30th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, ASPLOS 2025, Rotterdam, Netherlands</arxiv:journal_reference>
      <dc:creator>Chengsong Tan, Alastair F. Donaldson, John Wickerson</dc:creator>
    </item>
    <item>
      <title>Event-based backpropagation on the neuromorphic platform SpiNNaker2</title>
      <link>https://arxiv.org/abs/2412.15021</link>
      <description>arXiv:2412.15021v4 Announce Type: replace-cross 
Abstract: Neuromorphic computing aims to replicate the brain's capabilities for energy efficient and parallel information processing, promising a solution to the increasing demand for faster and more efficient computational systems. Efficient training of neural networks on neuromorphic hardware requires the development of training algorithms that retain the sparsity of spike-based communication during training. Here, we report on the first implementation of event-based backpropagation on the SpiNNaker2 neuromorphic hardware platform. We use EventProp, an algorithm for event-based backpropagation in spiking neural networks (SNNs), to compute exact gradients using sparse communication of error signals between neurons. Our implementation computes multi-layer networks of leaky integrate-and-fire neurons using discretized versions of the differential equations and their adjoints, and uses event packets to transmit spikes and error signals between network layers. We demonstrate a proof-of-concept of batch-parallelized, on-chip training of SNNs using the Yin Yang dataset, and provide an off-chip implementation for efficient prototyping, hyper-parameter search, and hybrid training methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.15021v4</guid>
      <category>cs.NE</category>
      <category>cs.AR</category>
      <category>cs.ET</category>
      <pubDate>Thu, 20 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gabriel B\'ena, Timo Wunderlich, Mahmoud Akl, Bernhard Vogginger, Christian Mayr, Hector Andres Gonzalez</dc:creator>
    </item>
  </channel>
</rss>
