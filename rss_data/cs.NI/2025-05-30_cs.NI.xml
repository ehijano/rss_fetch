<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 30 May 2025 04:00:01 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Agile Orchestration at Will: An Entire Smart Service-Based Security Architecture Towards 6G</title>
      <link>https://arxiv.org/abs/2505.22963</link>
      <description>arXiv:2505.22963v1 Announce Type: new 
Abstract: The upcoming 6G will fundamentally reshape mobile networks beyond communications, unlocking a multitude of applications that were once considered unimaginable. Meanwhile, security and resilience are especially highlighted in the 6G design principles. However, safeguarding 6G networks will be quite challenging due to various known and unknown threats from highly heterogeneous networks and diversified security requirements of distinct use cases, calling for a comprehensive re-design of security architecture. This motivates us to propose ES3A (Entire Smart Service-based Security Architecture), a novel security architecture for 6G networks. Specifically, we first discuss six high-level principles of our ES3A that include hierarchy, flexibility, scalability, resilience, endogeny, and trust and privacy. With these goals in mind, we then introduce three guidelines from a deployment perspective, envisioning our ES3A that offers service-based security, end-to-end protection, and smart security automation for 6G networks. Our architecture consists of three layers and three domains. It relies on a two-stage orchestration mechanism to tailor smart security strategies for customized protection in high-dynamic 6G networks, thereby addressing the aforementioned challenges. Finally, we prototype the proposed ES3A on a real-world radio system based on Software-Defined Radio (SDR). Experiments show the effectiveness of our ES3A. We also provide a case to show the superiority of our architecture.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.22963v1</guid>
      <category>cs.NI</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhuoran Duan, Guoshun Nan, Rushan Li, Zijun Wang, Lihua Xiong, Chaoying Yuan, Guorong Liu, Hui Xu, Qimei Cui, Xiaofeng Tao, Tony Q. S. Quek</dc:creator>
    </item>
    <item>
      <title>Context-Aware Semantic Communication for the Wireless Networks</title>
      <link>https://arxiv.org/abs/2505.23249</link>
      <description>arXiv:2505.23249v1 Announce Type: new 
Abstract: In next-generation wireless networks, supporting real-time applications such as augmented reality, autonomous driving, and immersive Metaverse services demands stringent constraints on bandwidth, latency, and reliability. Existing semantic communication (SemCom) approaches typically rely on static models, overlooking dynamic conditions and contextual cues vital for efficient transmission. To address these challenges, we propose CaSemCom, a context-aware SemCom framework that leverages a Large Language Model (LLM)-based gating mechanism and a Mixture of Experts (MoE) architecture to adaptively select and encode only high-impact semantic features across multiple data modalities. Our multimodal, multi-user case study demonstrates that CaSemCom significantly improves reconstructed image fidelity while reducing bandwidth usage, outperforming single-agent deep reinforcement learning (DRL) methods and traditional baselines in convergence speed, semantic accuracy, and retransmission overhead.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.23249v1</guid>
      <category>cs.NI</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Guangyuan Liu, Yinqiu Liu, Jiacheng Wang, Hongyang Du, Dusit Niyato, Jiawen Kang, Zehui Xiong, Abbas Jamalipour</dc:creator>
    </item>
    <item>
      <title>Wireless Agentic AI with Retrieval-Augmented Multimodal Semantic Perception</title>
      <link>https://arxiv.org/abs/2505.23275</link>
      <description>arXiv:2505.23275v1 Announce Type: new 
Abstract: The rapid development of multimodal AI and Large Language Models (LLMs) has greatly enhanced real-time interaction, decision-making, and collaborative tasks. However, in wireless multi-agent scenarios, limited bandwidth poses significant challenges to exchanging semantically rich multimodal information efficiently. Traditional semantic communication methods, though effective, struggle with redundancy and loss of crucial details. To overcome these challenges, we propose a Retrieval-Augmented Multimodal Semantic Communication (RAMSemCom) framework. RAMSemCom incorporates iterative, retrieval-driven semantic refinement tailored for distributed multi-agent environments, enabling efficient exchange of critical multimodal elements through local caching and selective transmission. Our approach dynamically optimizes retrieval using deep reinforcement learning (DRL) to balance semantic fidelity with bandwidth constraints. A comprehensive case study on multi-agent autonomous driving demonstrates that our DRL-based retrieval strategy significantly improves task completion efficiency and reduces communication overhead compared to baseline methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.23275v1</guid>
      <category>cs.NI</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Guangyuan Liu, Yinqiu Liu, Ruichen Zhang, Hongyang Du, Dusit Niyato, Zehui Xiong, Sumei Sun, Abbas Jamalipour</dc:creator>
    </item>
    <item>
      <title>Distributed Federated Learning for Vehicular Network Security: Anomaly Detection Benefits and Multi-Domain Attack Threats</title>
      <link>https://arxiv.org/abs/2505.23706</link>
      <description>arXiv:2505.23706v1 Announce Type: new 
Abstract: In connected and autonomous vehicles, machine learning for safety message classification has become critical for detecting malicious or anomalous behavior. However, conventional approaches that rely on centralized data collection or purely local training face limitations due to the large scale, high mobility, and heterogeneous data distributions inherent in inter-vehicle networks. To overcome these challenges, this paper explores Distributed Federated Learning (DFL), whereby vehicles collaboratively train deep learning models by exchanging model updates among one-hop neighbors and propagating models over multiple hops. Using the Vehicular Reference Misbehavior (VeReMi) Extension Dataset, we show that DFL can significantly improve classification accuracy across all vehicles compared to learning strictly with local data. Notably, vehicles with low individual accuracy see substantial accuracy gains through DFL, illustrating the benefit of knowledge sharing across the network. We further show that local training data size and time-varying network connectivity correlate strongly with the model's overall accuracy. We investigate DFL's resilience and vulnerabilities under attacks in multiple domains, namely wireless jamming and training data poisoning attacks. Our results reveal important insights into the vulnerabilities of DFL when confronted with multi-domain attacks, underlining the need for more robust strategies to secure DFL in vehicular networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.23706v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.DC</category>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Utku Demir, Yalin E. Sagduyu, Tugba Erpek, Hossein Jafari, Sastry Kompella, Mengran Xue</dc:creator>
    </item>
    <item>
      <title>Towards Real-Time Interpolation for Enhanced AUV Deep Sea Mapping</title>
      <link>https://arxiv.org/abs/2505.22675</link>
      <description>arXiv:2505.22675v1 Announce Type: cross 
Abstract: Approximately seventy-one percent of the Earth is covered in water. Of that area, ninety-five percent of the ocean has never been explored or mapped. There are several engineering challenges that have prevented the exploration of the deep ocean through human or autonomous means. These challenges include but are not limited to high pressure, cold temperatures, little natural light, corrosion of materials, and communication. Ongoing research has been focused on trying to find optimal and low-cost solutions to effective communication between autonomous underwater vehicles (AUVs), and the surface or air. In this paper, an architecture is introduced that utilizes an edge computing approach to establish computation nearer to the source of data, allowing further exploration of the deep ocean. Taking the most common interpolation techniques used today in the field of bathymetry, the data are tested and analyzed to find the feasibility of switching from CPU to GPU computation. Specifically, the focus is on writing efficient interpolation algorithms that can be run on low-level GPUs, which can be carried onboard AUVs as payload.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.22675v1</guid>
      <category>physics.ao-ph</category>
      <category>cs.NI</category>
      <category>cs.RO</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Devanshu Saxena</dc:creator>
    </item>
    <item>
      <title>LUMION: Fast Fault Recovery for ML Jobs Using Programmable Optical Fabrics</title>
      <link>https://arxiv.org/abs/2505.23105</link>
      <description>arXiv:2505.23105v1 Announce Type: cross 
Abstract: When accelerators fail in modern ML datacenters, operators migrate the affected ML training or inference jobs to entirely new racks. This approach, while preserving network performance, is highly inefficient, requiring datacenters to reserve full racks of idle accelerators for fault tolerance. In this paper, we address this resource inefficiency by introducing LUMION, a novel reconfigurable optical fabric for connecting accelerators within a datacenter rack. Instead of migrating entire ML jobs, LUMION dynamically integrates spare accelerators into ongoing workloads as failures occur, thereby maintaining consistent performance without costly migrations. We show the benefits of LUMION by building an end-to-end hardware prototype. Our experiments fine-tune Llama 3.2 and show that LUMION swaps a failed GPU with a healthy one and restarts the ML job within ~ 1 second of the failure. LUMION achieves higher inter-GPU bandwidth compared to traditional electrical racks after replacing failed accelerators with spare ones, leading to nearly 2X improvement in fine-tuning throughput.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.23105v1</guid>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Abhishek Vijaya Kumar, Eric Ding, Arjun Devraj, Darius Bunandar, Rachee Singh</dc:creator>
    </item>
    <item>
      <title>Quantum Hilbert Transform</title>
      <link>https://arxiv.org/abs/2505.23581</link>
      <description>arXiv:2505.23581v1 Announce Type: cross 
Abstract: The Hilbert transform has been one of the foundational transforms in signal processing, finding it's way into multiple disciplines from cryptography to biomedical sciences. However, there does not exist any quantum analogue for the Hilbert transform. In this work, we introduce a formulation for the quantum Hilbert transform (QHT)and apply it to a quantum steganography protocol. By bridging classical phase-shift techniques with quantum operations, QHT opens new pathways in quantum signal processing, communications, sensing, and secure information hiding.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.23581v1</guid>
      <category>quant-ph</category>
      <category>cs.CR</category>
      <category>cs.DM</category>
      <category>cs.NI</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nitin Jha, Abhishek Parakh</dc:creator>
    </item>
    <item>
      <title>Towards A Global Quantum Internet: A Review of Challenges Facing Aerial Quantum Networks</title>
      <link>https://arxiv.org/abs/2505.23603</link>
      <description>arXiv:2505.23603v1 Announce Type: cross 
Abstract: Quantum networks use principles of quantum physics to create secure communication networks. Moving these networks off the ground using drones, balloons, or satellites could help increase the scalability of these networks. This article reviews how such aerial links work, what makes them difficult to build, and the possible solutions that can be used to overcome these problems. By combining ground stations, aerial relays, and orbiting satellites into one seamless system, we move closer to a practical quantum internet.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.23603v1</guid>
      <category>quant-ph</category>
      <category>cs.CR</category>
      <category>cs.CY</category>
      <category>cs.NI</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nitin Jha, Abhishek Parakh</dc:creator>
    </item>
    <item>
      <title>Promptus: Can Prompts Streaming Replace Video Streaming with Stable Diffusion</title>
      <link>https://arxiv.org/abs/2405.20032</link>
      <description>arXiv:2405.20032v2 Announce Type: replace 
Abstract: With the exponential growth of video traffic, traditional video streaming systems are approaching their limits in compression efficiency and communication capacity. To further reduce bitrate while maintaining quality, we propose Promptus, a disruptive semantic communication system that streaming prompts instead of video content, which represents real-world video frames with a series of "prompts" for delivery and employs Stable Diffusion to generate videos at the receiver. To ensure that the generated video is pixel-aligned with the original video, a gradient descent-based prompt fitting framework is proposed. Further, a low-rank decomposition-based bitrate control algorithm is introduced to achieve adaptive bitrate. For inter-frame compression, an interpolation-aware fitting algorithm is proposed. Evaluations across various video genres demonstrate that, compared to H.265, Promptus can achieve more than a 4x bandwidth reduction while preserving the same perceptual quality. On the other hand, at extremely low bitrates, Promptus can enhance the perceptual quality by 0.139 and 0.118 (in LPIPS) compared to VAE and H.265, respectively, and decreases the ratio of severely distorted frames by 89.3% and 91.7%. Our work opens up a new paradigm for efficient video communication. Promptus is open-sourced at: https://github.com/JiangkaiWu/Promptus.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20032v2</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.MM</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiangkai Wu, Liming Liu, Yunpeng Tan, Junlin Hao, Xinggong Zhang</dc:creator>
    </item>
    <item>
      <title>Design and Implementation of ARA Wireless Living Lab for Rural Broadband and Applications</title>
      <link>https://arxiv.org/abs/2408.00913</link>
      <description>arXiv:2408.00913v2 Announce Type: replace 
Abstract: Addressing the broadband gap between rural and urban regions requires rural-focused wireless research and innovation. In the meantime, rural regions provide rich, diverse use cases of advanced wireless, and they offer unique real-world settings for piloting applications that advance the frontiers of wireless systems (e.g., teleoperation of ground and aerial vehicles). To fill the broadband gap and to leverage the unique opportunities that rural regions provide for piloting advanced wireless applications, we design and implement the ARA wireless living lab for research and innovation in rural wireless systems and their applications in precision agriculture, community services, and so on. ARA focuses on the unique community, application, and economic context of rural regions, and it features the first-of-its-kind, real-world deployment of long-distance, high-capacity terrestrial wireless x-haul and access platforms as well as low-earth-orbit (LEO) satellite communications platforms across a rural area of diameter over 30 km. With both software-defined radios and programmable COTS systems, and through effective orchestration of these wireless resources with fiber as well as compute resources embedded end-to-end across user equipment (UE), base stations (BS), edge, and cloud, including support for Bring Your Own Device (BYOD), ARA offers programmability, performance, robustness, and heterogeneity at the same time, thus enabling rural-focused co-evolution of wireless and applications while helping advance the frontiers of wireless systems in domains such as Open RAN, NextG, and agriculture applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.00913v2</guid>
      <category>cs.NI</category>
      <category>cs.ET</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Taimoor Ul Islam, Joshua Ofori Boateng, Md Nadim, Guoying Zu, Mukaram Shahid, Xun Li, Tianyi Zhang, Salil Reddy, Wei Xu, Ataberk Atalar, Vincent Lee, Yung-Fu Chen, Evan Gosling, Elisabeth Permatasari, Christ Somiah, Owen Perrin, Zhibo Meng, Reshal Afzal, Sarath Babu, Mohammed Soliman, Ali Hussain, Daji Qiao, Mai Zheng, Ozdal Boyraz, Yong Guan, Anish Arora, Mohamed Y. Selim, Arsalan Ahmad, Myra B. Cohen, Mike Luby, Ranveer Chandra, James Gross, Kate Keahey, Hongwei Zhang</dc:creator>
    </item>
    <item>
      <title>Disruption-aware Microservice Re-orchestration for Cost-efficient Multi-cloud Deployments</title>
      <link>https://arxiv.org/abs/2501.16143</link>
      <description>arXiv:2501.16143v2 Announce Type: replace 
Abstract: Multi-cloud environments enable a cost-efficient scaling of cloud-native applications across geographically distributed virtual nodes with different pricing models. In this context, the resource fragmentation caused by frequent changes in the resource demands of deployed microservices, along with the allocation or termination of new and existing microservices, increases the deployment cost. Therefore, re-orchestrating deployed microservices on a cheaper configuration of multi-cloud nodes offers a practical solution to restore the cost efficiency of deployment. However, the rescheduling procedure causes frequent service interruptions due to the continuous termination and rebooting of the containerized microservices. Moreover, it may potentially interfere with and delay other deployment operations, compromising the stability of the running applications. To address this issue, we formulate a multi-objective integer linear programming (ILP) problem that computes a microservice rescheduling solution capable of providing minimum deployment cost without significantly affecting the service continuity. At the same time, the proposed formulation also preserves the quality of service (QoS) requirements, including latency, expressed through microservice co-location constraints. Additionally, we present a heuristic algorithm to approximate the optimal solution, striking a balance between cost reduction and service disruption mitigation. We integrate the proposed approach as a custom plugin of the Kubernetes (K8s) scheduler. Results reveal that our approach significantly reduces multi-cloud deployment costs and service disruptions compared to the benchmark schemes, while ensuring QoS requirements are consistently met.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.16143v2</guid>
      <category>cs.NI</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marco Zambianco, Silvio Cretti, Domenico Siracusa</dc:creator>
    </item>
    <item>
      <title>Rydberg Atomic Receiver: Next Frontier of Wireless Communications</title>
      <link>https://arxiv.org/abs/2412.12485</link>
      <description>arXiv:2412.12485v2 Announce Type: replace-cross 
Abstract: Rydberg Atomic REceiver (RARE) is driving a paradigm shift in electromagnetic (EM) wave measurement by harnessing the electron transition phenomenon of Rydberg atoms. Operating at the quantum scale, such receivers have the potential to breakthrough the performance limit of classic receivers, sparking a revolution in physical-layer wireless communications. The objective of this paper is to offer insights into RARE-empowered communications. We first provide a comprehensive introduction to the fundamental principles of RAREs. Then, a thorough comparison between RAREs and classic receivers is conducted in terms of the antenna size, sensitivity, and bandwidth. Subsequently, we overview the recent progresses in RARE-aided wireless communications, covering the frequency-division multiplexing, multiple-input-multiple-output, wireless sensing, and quantum many-body techniques. Moreover, the unique application of RARE in multiband sensing and communication is introduced. Finally, we conclude by providing promising research directions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.12485v2</guid>
      <category>eess.SP</category>
      <category>cs.NI</category>
      <category>physics.app-ph</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Mingyao Cui, Qunsong Zeng, Kaibin Huang</dc:creator>
    </item>
    <item>
      <title>Privacy-Aware Joint DNN Model Deployment and Partitioning Optimization for Collaborative Edge Inference Services</title>
      <link>https://arxiv.org/abs/2502.16091</link>
      <description>arXiv:2502.16091v3 Announce Type: replace-cross 
Abstract: Edge inference (EI) has emerged as a promising paradigm to address the growing limitations of cloud-based Deep Neural Network (DNN) inference services, such as high response latency, limited scalability, and severe data privacy exposure. However, deploying DNN models on resource-constrained edge devices introduces additional challenges, including limited computation/storage resources, dynamic service demands, and heightened privacy risks. To tackle these issues, this paper presents a novel privacy-aware optimization framework that jointly addresses DNN model deployment, user-server association, and model partitioning, with the goal of minimizing long-term average inference delay under resource and privacy constraints. The problem is formulated as a complex, NP-hard stochastic optimization. To efficiently handle system dynamics and computational complexity, we employ a Lyapunov-based approach to transform the long-term objective into tractable per-slot decisions. Furthermore, we introduce a coalition formation game to enable adaptive user-server association and design a greedy algorithm for model deployment within each coalition. Extensive simulations demonstrate that the proposed algorithm significantly reduces inference delay and consistently satisfies privacy constraints, outperforming state-of-the-art baselines across diverse scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16091v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhipeng Cheng, Xiaoyu Xia, Hong Wang, Minghui Liwang, Ning Chen, Xuwei Fan, Xianbin Wang</dc:creator>
    </item>
    <item>
      <title>Smaller, Smarter, Closer: The Edge of Collaborative Generative AI</title>
      <link>https://arxiv.org/abs/2505.16499</link>
      <description>arXiv:2505.16499v2 Announce Type: replace-cross 
Abstract: The rapid adoption of generative AI (GenAI), particularly Large Language Models (LLMs), has exposed critical limitations of cloud-centric deployments, including latency, cost, and privacy concerns. Meanwhile, Small Language Models (SLMs) are emerging as viable alternatives for resource-constrained edge environments, though they often lack the capabilities of their larger counterparts. This article explores the potential of collaborative inference systems that leverage both edge and cloud resources to address these challenges. By presenting distinct cooperation strategies alongside practical design principles and experimental insights, we offer actionable guidance for deploying GenAI across the computing continuum.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.16499v2</guid>
      <category>cs.DC</category>
      <category>cs.AI</category>
      <category>cs.NI</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Roberto Morabito, SiYoung Jang</dc:creator>
    </item>
    <item>
      <title>Edge-First Language Model Inference: Models, Metrics, and Tradeoffs</title>
      <link>https://arxiv.org/abs/2505.16508</link>
      <description>arXiv:2505.16508v2 Announce Type: replace-cross 
Abstract: The widespread adoption of Language Models (LMs) across industries is driving interest in deploying these services across the computing continuum, from the cloud to the network edge. This shift aims to reduce costs, lower latency, and improve reliability and privacy. Small Language Models (SLMs), enabled by advances in model compression, are central to this shift, offering a path to on-device inference on resource-constrained edge platforms. This work examines the interplay between edge and cloud deployments, starting from detailed benchmarking of SLM capabilities on single edge devices, and extending to distributed edge clusters. We identify scenarios where edge inference offers comparable performance with lower costs, and others where cloud fallback becomes essential due to limits in scalability or model capacity. Rather than proposing a one-size-fits-all solution, we present platform-level comparisons and design insights for building efficient, adaptive LM inference systems across heterogeneous environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.16508v2</guid>
      <category>cs.DC</category>
      <category>cs.AI</category>
      <category>cs.NI</category>
      <category>cs.PF</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>SiYoung Jang, Roberto Morabito</dc:creator>
    </item>
  </channel>
</rss>
