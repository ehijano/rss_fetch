<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 30 Sep 2025 03:29:31 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Future of Brain Health: From Developmental Insights to Clinical Translation</title>
      <link>https://arxiv.org/abs/2509.21332</link>
      <description>arXiv:2509.21332v1 Announce Type: new 
Abstract: This review highlights brain health as a dynamic process shaped by both genetic and environmental influences throughout development. Critical periods provide unique windows of heightened neural plasticity, during which genetic-environmental interactions and parental influences profoundly impact brain maturation. Frameworks such as DOHaD, ACEs, and neurosocial plasticity elucidate how early-life experiences modulate long-term cognitive and emotional outcomes. Brain health science is emerging as a field integrating neuroscience, public health, and social context. Resilience-oriented approaches and predictive processing, offer renewed perspectives on adaptive brain function. Clinically, understanding critical periods and plasticity spanning from fetal life to old age, has implications for early detection, targeted interventions, and resilience-oriented strategies, emphasizing the potential for lifelong optimization of mental health.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.21332v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mariela Chertoff, Martin G Frasch, Eduardo T C\'anepa, Gerlinde A. S. Metz, Marta Cristina Antonelli, Sheehan D. Fisher, Bea R. H. Van den Bergh</dc:creator>
    </item>
    <item>
      <title>Discovering alternative solutions beyond the simplicity bias in recurrent neural networks</title>
      <link>https://arxiv.org/abs/2509.21504</link>
      <description>arXiv:2509.21504v1 Announce Type: new 
Abstract: Training recurrent neural networks (RNNs) to perform neuroscience-style tasks has become a popular way to generate hypotheses for how neural circuits in the brain might perform computations. Recent work has demonstrated that task-trained RNNs possess a strong simplicity bias. In particular, this inductive bias often causes RNNs trained on the same task to collapse on effectively the same solution, typically comprised of fixed-point attractors or other low-dimensional dynamical motifs. While such solutions are readily interpretable, this collapse proves counterproductive for the sake of generating a set of genuinely unique hypotheses for how neural computations might be performed. Here we propose Iterative Neural Similarity Deflation (INSD), a simple method to break this inductive bias. By penalizing linear predictivity of neural activity produced by standard task-trained RNNs, we find an alternative class of solutions to classic neuroscience-style RNN tasks. These solutions appear distinct across a battery of analysis techniques, including representational similarity metrics, dynamical systems analysis, and the linear decodability of task-relevant variables. Moreover, these alternative solutions can sometimes achieve superior performance in difficult or out-of-distribution task regimes. Our findings underscore the importance of moving beyond the simplicity bias to uncover richer and more varied models of neural computation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.21504v1</guid>
      <category>q-bio.NC</category>
      <category>cs.NE</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>William Qian, Cengiz Pehlevan</dc:creator>
    </item>
    <item>
      <title>A Bio-Inspired Minimal Model for Non-Stationary K-Armed Bandits</title>
      <link>https://arxiv.org/abs/2509.22209</link>
      <description>arXiv:2509.22209v1 Announce Type: new 
Abstract: While reinforcement learning algorithms have made significant progress in solving multi-armed bandit problems, they often lack biological plausibility in architecture and dynamics. Here, we propose a bio-inspired neural model based on interacting populations of rate neurons, drawing inspiration from the orbitofrontal cortex and anterior cingulate cortex. Our model reports robust performance across various stochastic bandit problems, matching the effectiveness of standard algorithms such as Thompson Sampling and UCB. Notably, the model exhibits adaptive behavior: employing greedy strategies in low-uncertainty situations while increasing exploratory behavior as uncertainty rises. Through evolutionary optimization, the model's hyperparameters converged to values that align with known synaptic mechanisms, particularly in terms of synapse-dependent neural activity and learning rate adaptation. These findings suggest that biologically-inspired computational architectures can achieve competitive performance while providing insights into neural mechanisms of decision-making under uncertainty.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22209v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Krubeal Danieli, Mikkel Elle Lepper{\o}d</dc:creator>
    </item>
    <item>
      <title>Cycle is All You Need: More Is Different</title>
      <link>https://arxiv.org/abs/2509.21340</link>
      <description>arXiv:2509.21340v1 Announce Type: cross 
Abstract: We propose an information-topological framework in which cycle closure is the fundamental mechanism of memory and consciousness. Memory is not a static store but the ability to re-enter latent cycles in neural state space, with invariant cycles serving as carriers of meaning by filtering order-specific noise and preserving what persists across contexts. The dot-cycle dichotomy captures this: transient dots scaffold exploration, while nontrivial cycles encode low-entropy content invariants that stabilize memory. Biologically, polychronous neural groups realize 1-cycles through delay-locked spiking reinforced by STDP, nested within theta-gamma rhythms that enforce boundary cancellation. These micro-cycles compose hierarchically, extending navigation loops into general memory and cognition. The perception-action cycle introduces high-order invariance: closure holds even across sense-act alternations, generalizing ancestral homing behavior. Sheaf-cosheaf duality formalizes this process: sheaves glue perceptual fragments into global sections, cosheaves decompose global plans into actions and closure aligns top-down predictions with bottom-up cycles. Consciousness then arises as the persistence of high-order invariants that integrate (unity) yet differentiate (richness) across contexts. We conclude that cycle is all you need: persistent invariants enable generalization in non-ergodic environments with long-term coherence at minimal energetic cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.21340v1</guid>
      <category>cs.NE</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Xin Li</dc:creator>
    </item>
    <item>
      <title>Neuroprobe: Evaluating Intracranial Brain Responses to Naturalistic Stimuli</title>
      <link>https://arxiv.org/abs/2509.21671</link>
      <description>arXiv:2509.21671v1 Announce Type: cross 
Abstract: High-resolution neural datasets enable foundation models for the next generation of brain-computer interfaces and neurological treatments. The community requires rigorous benchmarks to discriminate between competing modeling approaches, yet no standardized evaluation frameworks exist for intracranial EEG (iEEG) recordings. To address this gap, we present Neuroprobe: a suite of decoding tasks for studying multi-modal language processing in the brain. Unlike scalp EEG, intracranial EEG requires invasive surgery to implant electrodes that record neural activity directly from the brain with minimal signal distortion. Neuroprobe is built on the BrainTreebank dataset, which consists of 40 hours of iEEG recordings from 10 human subjects performing a naturalistic movie viewing task. Neuroprobe serves two critical functions. First, it is a mine from which neuroscience insights can be drawn. Its high temporal and spatial resolution allows researchers to systematically determine when and where computations for each aspect of language processing occur in the brain by measuring the decodability of each feature across time and all electrode locations. Using Neuroprobe, we visualize how information flows from the superior temporal gyrus to the prefrontal cortex, and the progression from simple auditory features to more complex language features in a purely data-driven manner. Second, as the field moves toward neural foundation models, Neuroprobe provides a rigorous framework for comparing competing architectures and training protocols. We found that the linear baseline is surprisingly strong, beating frontier foundation models on many tasks. Neuroprobe is designed with computational efficiency and ease of use in mind. We make the code for Neuroprobe openly available and maintain a public leaderboard, aiming to enable rapid progress in the field of iEEG foundation models, at https://neuroprobe.dev/</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.21671v1</guid>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrii Zahorodnii, Christopher Wang, Bennett Stankovits, Charikleia Moraitaki, Geeling Chau, Andrei Barbu, Boris Katz, Ila R Fiete</dc:creator>
    </item>
    <item>
      <title>Universal scale-free representations in human visual cortex</title>
      <link>https://arxiv.org/abs/2409.06843</link>
      <description>arXiv:2409.06843v3 Announce Type: replace 
Abstract: How does the human brain encode complex visual information? While previous research has characterized individual dimensions of visual representation in cortex, we still lack a comprehensive understanding of how visual information is organized across the full range of neural population activity. Here, analyzing fMRI responses to natural scenes across multiple individuals, we discover that neural representations in human visual cortex follow a remarkably consistent scale-free organization -- their variance systematically decays as a power law, detected across four orders of magnitude of latent dimensions. This scale-free structure appears consistently across multiple visual regions and across individuals, suggesting it reflects a fundamental organizing principle of visual processing. Critically, when we align neural responses across individuals using hyperalignment, we find that these representational dimensions are largely shared between people, revealing a universal high-dimensional spectrum of visual information that emerges despite individual differences in brain anatomy and visual experience. Traditional analysis approaches in cognitive neuroscience have focused primarily on a small number of high-variance dimensions, potentially missing crucial aspects of visual representation. Our results demonstrate that visual information is distributed across the full dimensionality of cortical activity in a systematic way, suggesting we need to move beyond low-dimensional characterizations to fully understand how the brain represents the visual world. This work reveals a new fundamental principle of neural coding in human visual cortex and highlights the importance of examining neural representations across their full dimensionality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06843v3</guid>
      <category>q-bio.NC</category>
      <category>q-bio.QM</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Raj Magesh Gauthaman, Brice M\'enard, Michael F. Bonner</dc:creator>
    </item>
    <item>
      <title>Multimodal Recurrent Ensembles for Predicting Brain Responses to Naturalistic Movies (Algonauts 2025)</title>
      <link>https://arxiv.org/abs/2507.17897</link>
      <description>arXiv:2507.17897v3 Announce Type: replace 
Abstract: Accurately predicting distributed cortical responses to naturalistic stimuli requires models that integrate visual, auditory and semantic information over time. We present a hierarchical multimodal recurrent ensemble that maps pretrained video, audio, and language embeddings to fMRI time series recorded while four subjects watched almost 80 hours of movies provided by the Algonauts 2025 challenge. Modality-specific bidirectional RNNs encode temporal dynamics; their hidden states are fused and passed to a second recurrent layer, and lightweight subject-specific heads output responses for 1000 cortical parcels. Training relies on a composite MSE-correlation loss and a curriculum that gradually shifts emphasis from early sensory to late association regions. Averaging 100 model variants further boosts robustness. The resulting system ranked third on the competition leaderboard, achieving an overall Pearson r = 0.2094 and the highest single-parcel peak score (mean r = 0.63) among all participants, with particularly strong gains for the most challenging subject (Subject 5). The approach establishes a simple, extensible baseline for future multimodal brain-encoding benchmarks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.17897v3</guid>
      <category>q-bio.NC</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Semih Eren, Deniz Kucukahmetler, Nico Scherf</dc:creator>
    </item>
    <item>
      <title>Repetitive TMS-based Identification of Methamphetamine-Dependent Individuals Using EEG Spectra</title>
      <link>https://arxiv.org/abs/2508.11312</link>
      <description>arXiv:2508.11312v2 Announce Type: replace 
Abstract: The impact of repetitive transcranial magnetic stimulation (rTMS) on methamphetamine (METH) users' craving levels is often assessed using questionnaires. This study explores the feasibility of using neural signals to obtain more objective results. EEG signals recorded from 20 METH-addicted participants Before and After rTMS (MBT and MAT) and from 20 healthy participants (HC) are analyzed. In each EEG paradigm, participants are shown 15 METH-related and 15 neutral pictures randomly, and the relative band power (RBP) of each EEG sub-band frequency is derived. The average RBP across all 31 channels, as well as individual brain regions, is analyzed. Statistically, MAT's alpha, beta, and gamma RBPs are more like those of HC compared to MBT, as indicated by the power topographies. Utilizing a random forest (RF), the gamma RBP is identified as the optimal frequency band for distinguishing between MBT and HC with a 90% accuracy. The performance of classifying MAT versus HC is lower than that of MBT versus HC, suggesting that the efficacy of rTMS can be validated using RF with gamma RBP. Furthermore, the gamma RBP recorded by the TP10 and CP2 channels dominates the classification task of MBT versus HC when receiving METH-related image cues. The gamma RBP during exposure to METH-related cues can serve as a biomarker for distinguishing between MBT and HC and for evaluating the effectiveness of rTMS. Therefore, real-time monitoring of gamma RBP variations holds promise as a parameter for implementing a customized closed-loop neuromodulation system for treating METH addiction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.11312v2</guid>
      <category>q-bio.NC</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/JSEN.2025.3612041</arxiv:DOI>
      <dc:creator>Ziyi Zeng, Yun-Hsuan Chen, Xurong Gao, Wenyao Zheng, Hemmings Wu, Zhoule Zhu, Jie Yang, Chengkai Wang, Lihua Zhong, Weiwei Cheng, Mohamad Sawan</dc:creator>
    </item>
    <item>
      <title>On the Within-class Variation Issue in Alzheimer's Disease Detection</title>
      <link>https://arxiv.org/abs/2409.16322</link>
      <description>arXiv:2409.16322v3 Announce Type: replace-cross 
Abstract: Alzheimer's Disease (AD) detection employs machine learning classification models to distinguish between individuals with AD and those without. Different from conventional classification tasks, we identify within-class variation as a critical challenge in AD detection: individuals with AD exhibit a spectrum of cognitive impairments. Therefore, simplistic binary AD classification may overlook two crucial aspects: within-class heterogeneity and instance-level imbalance. In this work, we found using a sample score estimator can generate sample-specific soft scores aligning with cognitive scores. We subsequently propose two simple yet effective methods: Soft Target Distillation (SoTD) and Instance-level Re-balancing (InRe), targeting two problems respectively. Based on the ADReSS and CU-MARVEL corpora, we demonstrated and analyzed the advantages of the proposed approaches in detection performance. These findings provide insights for developing robust and reliable AD detection models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.16322v3</guid>
      <category>eess.AS</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <category>cs.SD</category>
      <category>q-bio.NC</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.21437/Interspeech.2025-2751</arxiv:DOI>
      <dc:creator>Jiawen Kang, Dongrui Han, Lingwei Meng, Jingyan Zhou, Jinchao Li, Xixin Wu, Helen Meng</dc:creator>
    </item>
    <item>
      <title>On the control of recurrent neural networks using constant inputs</title>
      <link>https://arxiv.org/abs/2410.17199</link>
      <description>arXiv:2410.17199v2 Announce Type: replace-cross 
Abstract: This paper investigates the controllability of a broad class of recurrent neural networks widely used in theoretical neuroscience, including models of large-scale human brain dynamics. Motivated by emerging applications in non-invasive neurostimulation such as transcranial direct current stimulation (tDCS), we study the control synthesis of these networks using constant and piecewise constant inputs. The neural model considered is a continuous-time Hopfield-type system with nonlinear activation functions and arbitrary input matrices representing inter-regional brain interactions. Our main contribution is the formulation and solution of a control synthesis problem for such nonlinear systems using specific solution representations. These representations yield explicit algebraic conditions for synthesizing constant and piecewise constant controls that solve a two-point boundary value problem in state space up to higher-order corrections with respect to the time horizon. In particular, the input is constructed to satisfy a tractable small-time algebraic relation involving the Jacobian of the nonlinear drift, ensuring that the synthesis reduces to verifying conditions on the system matrices. For canonical input matrices that directly actuate $k$ nodes, this implies that the reachable set (with constant inputs) of a given initial state is an affine subspace whose dimension equals the input rank and whose basis can be computed efficiently using a thin QR factorization. Numerical simulations illustrate the theoretical results and demonstrate the effectiveness of the proposed synthesis in guiding the design of brain stimulation protocols for therapeutic and cognitive applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.17199v2</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <category>q-bio.NC</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Cyprien Tamekue, Ruiqi Chen, ShiNung Ching</dc:creator>
    </item>
    <item>
      <title>Cross-Linguistic Analysis of Memory Load in Sentence Comprehension: Linear Distance and Structural Density</title>
      <link>https://arxiv.org/abs/2509.20916</link>
      <description>arXiv:2509.20916v2 Announce Type: replace-cross 
Abstract: This study examines whether sentence-level memory load in comprehension is better explained by linear proximity between syntactically related words or by the structural density of the intervening material. Building on locality-based accounts and cross-linguistic evidence for dependency length minimization, the work advances Intervener Complexity-the number of intervening heads between a head and its dependent-as a structurally grounded lens that refines linear distance measures. Using harmonized dependency treebanks and a mixed-effects framework across multiple languages, the analysis jointly evaluates sentence length, dependency length, and Intervener Complexity as predictors of the Memory-load measure. Studies in Psycholinguistics have reported the contributions of feature interference and misbinding to memory load during processing. For this study, I operationalized sentence-level memory load as the linear sum of feature misbinding and feature interference for tractability; current evidence does not establish that their cognitive contributions combine additively. All three factors are positively associated with memory load, with sentence length exerting the broadest influence and Intervener Complexity offering explanatory power beyond linear distance. Conceptually, the findings reconcile linear and hierarchical perspectives on locality by treating dependency length as an important surface signature while identifying intervening heads as a more proximate indicator of integration and maintenance demands. Methodologically, the study illustrates how UD-based graph measures and cross-linguistic mixed-effects modelling can disentangle linear and structural contributions to processing efficiency, providing a principled path for evaluating competing theories of memory load in sentence comprehension.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.20916v2</guid>
      <category>cs.CL</category>
      <category>q-bio.NC</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Krishna Aggarwal</dc:creator>
    </item>
  </channel>
</rss>
