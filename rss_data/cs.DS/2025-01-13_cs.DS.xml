<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 13 Jan 2025 05:00:11 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 13 Jan 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Faster Edge Coloring by Partition Sieving</title>
      <link>https://arxiv.org/abs/2501.05570</link>
      <description>arXiv:2501.05570v1 Announce Type: new 
Abstract: In the Edge Coloring problem, we are given an undirected graph $G$ with $n$ vertices and $m$ edges, and are tasked with finding the smallest positive integer $k$ so that the edges of $G$ can be assigned $k$ colors in such a way that no two edges incident to the same vertex are assigned the same color. Edge Coloring is a classic NP-hard problem, and so significant research has gone into designing fast exponential-time algorithms for solving Edge Coloring and its variants exactly. Prior work showed that Edge Coloring can be solved in $2^m\text{poly}(n)$ time and polynomial space, and in graphs with average degree $d$ in $2^{(1-\varepsilon_d)m}\text{poly}(n)$ time and exponential space, where $\varepsilon_d = (1/d)^{\Theta(d^3)}$.
  We present an algorithm that solves Edge Coloring in $2^{m-3n/5}\text{poly}(n)$ time and polynomial space. Our result is the first algorithm for this problem which simultaneously runs in faster than $2^m\text{poly}(m)$ time and uses only polynomial space. In graphs of average degree $d$, our algorithm runs in $2^{(1-6/(5d))m}\text{poly}(n)$ time, which has far better dependence in $d$ than previous results. We also generalize our algorithm to solve a problem known as List Edge Coloring, where each edge $e$ in the input graph comes with a list $L_e\subseteq\left\{1, \dots, k\right\}$ of colors, and we must determine whether we can assign each edge a color from its list so that no two edges incident to the same vertex receive the same color. We solve this problem in $2^{(1-6/(5k))m}\text{poly}(n)$ time and polynomial space. The previous best algorithm for List Edge Coloring took $2^m\text{poly}(n)$ time and space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.05570v1</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 13 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shyan Akmal, Tomohiro Koana</dc:creator>
    </item>
    <item>
      <title>Colorful Vertex Recoloring of Bipartite Graphs</title>
      <link>https://arxiv.org/abs/2501.05796</link>
      <description>arXiv:2501.05796v1 Announce Type: new 
Abstract: In vertex recoloring, we are given $n$ vertices with their initial coloring, and edges arrive in an online fashion. The algorithm must maintain a valid coloring by recoloring vertices, at a cost. The problem abstracts a scenario of job placement in machines (possibly in the cloud), where vertices represent jobs, colors represent machines, and edges represent ``anti affinity'' (disengagement) constraints. Online recoloring is a hard problem. One family of instances which is fairly well-understood is bipartite graphs, in which two colors are sufficient to satisfy all constraints. In this case it is known that the competitive ratio of vertex recoloring is $\Theta(\log n)$.
  We propose a generalization of the problem, which allows using additional colors (possibly at a higher cost), to improve overall performance. We analyze the simple case of bipartite graphs of bounded largest \emph{bond} (a bond of a connected graph is an edge-cut that partitions the graph into two connected components). First, we propose two algorithms. One exhibits a trade-off for the uniform-cost case: given $\Omega(\log\beta)\le c\le O(\log n)$ colors, the algorithm guarantees that its cost is at most $O(\frac{\log n}{c})$ times the optimal offline cost for two colors, where $n$ is the number of vertices and $\beta$ is the size of the largest bond. The other algorithm is for the case where the additional colors come at a higher cost, $D&gt;1$: given $\Delta$ additional colors, where $\Delta$ is the maximum degree in the graph, the algorithm guarantees $O(\log D)$ competitiveness. As to lower bounds, we show that if the cost of the extra colors is $D&gt;1$, no (randomized) algorithm can achieve a competitive ratio of $o(\log D)$. We also show that for bipartite graphs of unbounded bond size, any deterministic online algorithm has competitive ratio $\Omega(\min(D,\log n))$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.05796v1</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 13 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Boaz Patt-Shamir, Adi Rosen, Seeun William Umboh</dc:creator>
    </item>
    <item>
      <title>Mim-Width is paraNP-complete</title>
      <link>https://arxiv.org/abs/2501.05638</link>
      <description>arXiv:2501.05638v1 Announce Type: cross 
Abstract: We show that it is NP-hard to distinguish graphs of linear mim-width at most 1211 from graphs of sim-width at least 1216. This implies that Mim-Width, Sim-Width, One-Sided Mim-Width, and their linear counterparts are all paraNP-complete, i.e., NP-complete to compute even when upper bounded by a constant.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.05638v1</guid>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <pubDate>Mon, 13 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Benjamin Bergougnoux, \'Edouard Bonnet, Julien Duron</dc:creator>
    </item>
    <item>
      <title>Approximate Counting for Spin Systems in Sub-Quadratic Time</title>
      <link>https://arxiv.org/abs/2306.14867</link>
      <description>arXiv:2306.14867v3 Announce Type: replace 
Abstract: We present two randomised approximate counting algorithms with $\widetilde{O}(n^{2-c}/\varepsilon^2)$ running time for some constant $c&gt;0$ and accuracy $\varepsilon$:
  (1) for the hard-core model with fugacity $\lambda$ on graphs with maximum degree $\Delta$ when $\lambda=O(\Delta^{-1.5-c_1})$ where $c_1=c/(2-2c)$;
  (2) for spin systems with strong spatial mixing (SSM) on planar graphs with quadratic growth, such as $\mathbb{Z}^2$.
  For the hard-core model, Weitz's algorithm (STOC, 2006) achieves sub-quadratic running time when correlation decays faster than the neighbourhood growth, namely when $\lambda = o(\Delta^{-2})$. Our first algorithm does not require this property and extends the range where sub-quadratic algorithms exist.
  Our second algorithm appears to be the first to achieve sub-quadratic running time up to the SSM threshold, albeit on a restricted family of graphs. It also extends to (not necessarily planar) graphs with polynomial growth, such as $\mathbb{Z}^d$, but with a running time of the form $\widetilde{O}\left(n^2\varepsilon^{-2}/2^{c(\log n)^{1/d}}\right)$ where $d$ is the exponent of the polynomial growth and $c&gt;0$ is some constant.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.14867v3</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 13 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.46298/theoretics.25.3</arxiv:DOI>
      <arxiv:journal_reference>TheoretiCS, Volume 4 (2025), Article 3, 1-27</arxiv:journal_reference>
      <dc:creator>Konrad Anand, Weiming Feng, Graham Freifeld, Heng Guo, Jiaheng Wang</dc:creator>
    </item>
    <item>
      <title>Prophet Inequalities: Competing with the Top $\ell$ Items is Easy</title>
      <link>https://arxiv.org/abs/2408.07616</link>
      <description>arXiv:2408.07616v2 Announce Type: replace 
Abstract: We explore a prophet inequality problem, where the values of a sequence of items are drawn i.i.d. from some distribution, and an online decision maker must select one item irrevocably. We establish that $\mathrm{CR}_{\ell}$ the worst-case competitive ratio between the expected optimal performance of an online decision maker compared to that of a prophet who uses the average of the top $\ell$ items is exactly the solution to an integral equation. This quantity $\mathrm{CR}_{\ell}$ is larger than $1-e^{-\ell}$. This implies that the bound converges exponentially fast to $1$ as $\ell$ grows. In particular for $\ell=2$, $\mathrm{CR}_{2} \approx 0.966$ which is much closer to $1$ than the classical bound of $0.745$ for $\ell=1$. Additionally, we prove asymptotic lower bounds for the competitive ratio of a more general scenario, where the decision maker is permitted to select $k$ items. This subsumes the $k$ multi-unit i.i.d. prophet problem and provides the current best asymptotic guarantees, as well as enables broader understanding in the more general framework. Finally, we prove a tight asymptotic competitive ratio when only static threshold policies are allowed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.07616v2</guid>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Mon, 13 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mathieu Molina, Nicolas Gast, Patrick Loiseau, Vianney Perchet</dc:creator>
    </item>
    <item>
      <title>Approximation of Spanning Tree Congestion using Hereditary Bisection</title>
      <link>https://arxiv.org/abs/2410.00568</link>
      <description>arXiv:2410.00568v2 Announce Type: replace 
Abstract: The Spanning Tree Congestion (STC) problem is the following NP-hard problem: given a graph $G$, construct a spanning tree $T$ of $G$ minimizing its maximum edge congestion where the congestion of an edge $e\in T$ is the number of edges $uv$ in $G$ such that the unique path between $u$ and $v$ in $T$ passes through $e$; the optimal value for a given graph $G$ is denoted $STC(G)$.
  It is known that every spanning tree is an $n/2$-approximation for the STP problem. A long-standing problem is to design a better approximation algorithm. Our contribution towards this goal is an $O(\Delta\cdot\log^{3/2}n)$-approximation algorithm where $\Delta$ is the maximum degree in $G$ and $n$ the number of vertices. For graphs with a maximum degree bounded by a polylog of the number of vertices, this is an exponential improvement over the previous best approximation.
  Our main tool for the algorithm is a new lower bound on the spanning tree congestion which is of independent interest. Denoting by $hb(G)$ the hereditary bisection of $G$ which is the maximum bisection width over all subgraphs of $G$, we prove that for every graph $G$, $STC(G)\geq \Omega(hb(G)/\Delta)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00568v2</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <pubDate>Mon, 13 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Petr Kolman</dc:creator>
    </item>
    <item>
      <title>An Approximate Generalization of the Okamura-Seymour Theorem</title>
      <link>https://arxiv.org/abs/2208.00795</link>
      <description>arXiv:2208.00795v3 Announce Type: replace-cross 
Abstract: We consider the problem of multicommodity flows in planar graphs. Okamura and Seymour showed that if all the demands are incident on one face, then the cut-condition is sufficient for routing demands. We consider the following generalization of this setting and prove an approximate max flow-min cut theorem: for every demand edge, there exists a face containing both its end points. We show that the cut-condition is sufficient for routing $\Omega(1)$-fraction of all the demands. To prove this, we give a $L_1$-embedding of the planar metric which approximately preserves distance between all pair of points on the same face.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.00795v3</guid>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <pubDate>Mon, 13 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nikhil Kumar</dc:creator>
    </item>
    <item>
      <title>A Nearly Linear-Time Distributed Algorithm for Maximum Cardinality Matching</title>
      <link>https://arxiv.org/abs/2311.04140</link>
      <description>arXiv:2311.04140v3 Announce Type: replace-cross 
Abstract: In this paper, we propose a randomized $\tilde{O}(\mu(G))$-round algorithm for the maximum cardinality matching problem in the CONGEST model, where $\mu(G)$ means the maximum size of a matching of the input graph $G$. The proposed algorithm substantially improves the current best worst-case running time. The key technical ingredient is a new randomized algorithm of finding an augmenting path of length $\ell$ with high probability within $\tilde{O}(\ell)$ rounds, which positively settles an open problem left in the prior work by Ahmadi and Kuhn [DISC'20].
  The idea of our augmenting path algorithm is based on a recent result by Kitamura and Izumi [IEICE Trans.'22], which efficiently identifies a sparse substructure of the input graph containing an augmenting path, following a new concept called \emph{alternating base trees}. Their algorithm, however, resorts in part to a centralized approach of collecting the entire information of the substructure into a single vertex for constructing a long augmenting path. The technical highlight of this paper is to provide a fully-decentralized counterpart of such a centralized method. To develop the algorithm, we prove several new structural properties of alternating base trees, which are of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.04140v3</guid>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <pubDate>Mon, 13 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Taisuke Izumi, Naoki Kitamura, Yutaro Yamaguchi</dc:creator>
    </item>
    <item>
      <title>Relating Interleaving and Fr\'echet Distances via Ordered Merge Trees</title>
      <link>https://arxiv.org/abs/2312.11113</link>
      <description>arXiv:2312.11113v4 Announce Type: replace-cross 
Abstract: Merge trees are a common topological descriptor for data with a hierarchical component, such as terrains and scalar fields. The interleaving distance, in turn, is a common distance for comparing merge trees. However, the interleaving distance for merge trees is solely based on the hierarchical structure, and disregards any other geometrical or topological properties that might be present in the underlying data. Furthermore, the interleaving distance is NP-hard to compute. In this paper, we introduce a form of ordered merge trees that can capture intrinsic order present in the data. We further define a natural variant of the interleaving distance, the monotone interleaving distance, which is an order-preserving distance for ordered merge trees. Analogously to the regular interleaving distance for merge trees, we show that the monotone variant has three equivalent definitions in terms of two maps, a single map, or a labelling. Furthermore, we establish a connection between the monotone interleaving distance of ordered merge trees and the Fr\'echet distance of 1D curves. As a result, the monotone interleaving distance between two ordered merge trees can be computed exactly in near-quadratic time in their complexity. The connection between the monotone interleaving distance and the Fr\'echet distance builds a new bridge between the fields of topological data analysis, where interleaving distances are a common tool, and computational geometry, where Fr\'echet distances are studied extensively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.11113v4</guid>
      <category>cs.CG</category>
      <category>cs.DS</category>
      <pubDate>Mon, 13 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thijs Beurskens, Tim Ophelders, Bettina Speckmann, Kevin Verbeek</dc:creator>
    </item>
    <item>
      <title>Testing the Fairness-Accuracy Improvability of Algorithms</title>
      <link>https://arxiv.org/abs/2405.04816</link>
      <description>arXiv:2405.04816v4 Announce Type: replace-cross 
Abstract: Many organizations use algorithms that have a disparate impact, i.e., the benefits or harms of the algorithm fall disproportionately on certain social groups. Addressing an algorithm's disparate impact can be challenging, however, because it is often unclear whether it is possible to reduce this impact without sacrificing other objectives of the organization, such as accuracy or profit. Establishing the improvability of algorithms with respect to multiple criteria is of both conceptual and practical interest: in many settings, disparate impact that would otherwise be prohibited under US federal law is permissible if it is necessary to achieve a legitimate business interest. The question is how a policy-maker can formally substantiate, or refute, this "necessity" defense. In this paper, we provide an econometric framework for testing the hypothesis that it is possible to improve on the fairness of an algorithm without compromising on other pre-specified objectives. Our proposed test is simple to implement and can be applied under any exogenous constraint on the algorithm space. We establish the large-sample validity and consistency of our test, and microfound the test's robustness to manipulation based on a game between a policymaker and the analyst. Finally, we apply our approach to evaluate a healthcare algorithm originally considered by Obermeyer et al. (2019), and quantify the extent to which the algorithm's disparate impact can be reduced without compromising the accuracy of its predictions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04816v4</guid>
      <category>econ.EM</category>
      <category>cs.DS</category>
      <category>stat.AP</category>
      <pubDate>Mon, 13 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eric Auerbach, Annie Liang, Kyohei Okumura, Max Tabord-Meehan</dc:creator>
    </item>
    <item>
      <title>When are quarnets sufficient to reconstruct semi-directed phylogenetic networks?</title>
      <link>https://arxiv.org/abs/2408.12997</link>
      <description>arXiv:2408.12997v2 Announce Type: replace-cross 
Abstract: Phylogenetic networks are graphs that are used to represent evolutionary relationships between different taxa. They generalize phylogenetic trees since for example, unlike trees, they permit lineages to combine. Recently, there has been rising interest in semi-directed phylogenetic networks, which are mixed graphs in which certain lineage combination events are represented by directed edges coming together, whereas the remaining edges are left undirected. One reason to consider such networks is that it can be difficult to root a network using real data. In this paper, we consider the problem of when a semi-directed phylogenetic network is defined or encoded by the smaller networks that it induces on the 4-leaf subsets of its leaf set. These smaller networks are called quarnets. We prove that semi-directed binary level-2 phylogenetic networks are encoded by their quarnets, but that this is not the case for level-3. In addition, we prove that the so-called blob tree of a semi-directed binary network, a tree that give the coarse-grained structure of the network, is always encoded by the quarnets of the network. These results are relevant for proving the statistical consistency of programs that are currently being developed for reconstructing phylogenetic networks from practical data, such as the recently developed Squirrel software tool.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.12997v2</guid>
      <category>q-bio.PE</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <pubDate>Mon, 13 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Katharina T. Huber, Leo van Iersel, Mark Jones, Vincent Moulton, Leonie Veenema - Nipius</dc:creator>
    </item>
    <item>
      <title>The Conflict Graph Design: Estimating Causal Effects under Arbitrary Neighborhood Interference</title>
      <link>https://arxiv.org/abs/2411.10908</link>
      <description>arXiv:2411.10908v2 Announce Type: replace-cross 
Abstract: A fundamental problem in network experiments is selecting an appropriate experimental design in order to precisely estimate a given causal effect of interest. In this work, we propose the Conflict Graph Design, a general approach for constructing experiment designs under network interference with the goal of precisely estimating a pre-specified causal effect. A central aspect of our approach is the notion of a conflict graph, which captures the fundamental unobservability associated with the causal effect and the underlying network. In order to estimate effects, we propose a modified Horvitz--Thompson estimator. We show that its variance under the Conflict Graph Design is bounded as $O(\lambda(H) / n )$, where $\lambda(H)$ is the largest eigenvalue of the adjacency matrix of the conflict graph. These rates depend on both the underlying network and the particular causal effect under investigation. Not only does this yield the best known rates of estimation for several well-studied causal effects (e.g. the global and direct effects) but it also provides new methods for effects which have received less attention from the perspective of experiment design (e.g. spill-over effects). Finally, we construct conservative variance estimators which facilitate asymptotically valid confidence intervals for the causal effect of interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10908v2</guid>
      <category>stat.ME</category>
      <category>cs.DS</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 13 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vardis Kandiros, Charilaos Pipis, Constantinos Daskalakis, Christopher Harshaw</dc:creator>
    </item>
    <item>
      <title>Convergence analysis of wide shallow neural operators within the framework of Neural Tangent Kernel</title>
      <link>https://arxiv.org/abs/2412.05545</link>
      <description>arXiv:2412.05545v3 Announce Type: replace-cross 
Abstract: Neural operators are aiming at approximating operators mapping between Banach spaces of functions, achieving much success in the field of scientific computing. Compared to certain deep learning-based solvers, such as Physics-Informed Neural Networks (PINNs), Deep Ritz Method (DRM), neural operators can solve a class of Partial Differential Equations (PDEs). Although much work has been done to analyze the approximation and generalization error of neural operators, there is still a lack of analysis on their training error. In this work, we conduct the convergence analysis of gradient descent for the wide shallow neural operators and physics-informed shallow neural operators within the framework of Neural Tangent Kernel (NTK). The core idea lies on the fact that over-parameterization and random initialization together ensure that each weight vector remains near its initialization throughout all iterations, yielding the linear convergence of gradient descent. In this work, we demonstrate that under the setting of over-parametrization, gradient descent can find the global minimum regardless of whether it is in continuous time or discrete time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05545v3</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Mon, 13 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xianliang Xu, Ye Li, Zhongyi Huang</dc:creator>
    </item>
  </channel>
</rss>
