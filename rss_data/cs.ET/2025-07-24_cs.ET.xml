<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.ET updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.ET</link>
    <description>cs.ET updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.ET" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 25 Jul 2025 04:00:26 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Low-power switching of memristors exhibiting fractional-order dynamics</title>
      <link>https://arxiv.org/abs/2507.18487</link>
      <description>arXiv:2507.18487v1 Announce Type: new 
Abstract: In this conference contribution, we present some initial results on switching memristive devices exhibiting fractional-order behavior using current pulses. In our model, it is assumed that the evolution of a state variable follows a fractional-order differential equation involving a Caputo-type derivative. A study of Joule losses demonstrates that the best switching strategy minimizing these losses depends on the fractional derivative's order and the power exponent in the equation of motion. It is found that when the order of the fractional derivative exceeds half of the power exponent, the best approach is to employ a wide pulse. Conversely, when this condition is not met, Joule losses are minimized by applying a zero current followed by a narrow current pulse of the highest allowable amplitude. These findings are explored further in the context of multi-pulse control. Our research lays the foundation for the advancement of the next generation of energy-efficient neuromorphic computing architectures that more closely mimic their biological counterparts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.18487v1</guid>
      <category>cs.ET</category>
      <category>cond-mat.mes-hall</category>
      <pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nathan Astin, Yuriy V. Pershin</dc:creator>
    </item>
    <item>
      <title>ARCADE: A RAN Diagnosis Methodology in a Hybrid AI Environment for 6G Networks</title>
      <link>https://arxiv.org/abs/2507.17861</link>
      <description>arXiv:2507.17861v1 Announce Type: cross 
Abstract: Artificial Intelligence (AI) plays a key role in developing 6G networks. While current specifications already include Network Data Analytics Function (NWDAF) as a network element responsible for providing information about the core, a more comprehensive approach will be needed to enable automation of network segments that are not yet fully explored in the context of 5G. In this paper, we present Automated Radio Coverage Anomalies Detection and Evaluation (ARCADE), a methodology for identifying and diagnosing anomalies in the cellular access network. Furthermore, we demonstrate how a hybrid architecture of network analytics functions in the evolution toward 6G can enhance the application of AI in a broader network context, using ARCADE as a practical example of this approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.17861v1</guid>
      <category>cs.NI</category>
      <category>cs.ET</category>
      <pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.5753/w6g.2025.9532</arxiv:DOI>
      <dc:creator>Daniel Ricardo Cunha Oliveira, Rodrigo Moreira, Fl\'avio de Oliveira Silva</dc:creator>
    </item>
    <item>
      <title>Effects of variation in system responsiveness on user performance in virtual environments</title>
      <link>https://arxiv.org/abs/2507.18085</link>
      <description>arXiv:2507.18085v1 Announce Type: cross 
Abstract: System responsiveness (SR) is defined as the elapsed time until a system responds to user control. SR fluctuates over time, so it must be described statistically with mean (MSR) and standard deviation (SDSR). In this paper, we examine SR in virtual environments (VEs), outlining its components and methods of experimental measurement and manipulation. Three studies of MSR and SDSR effects on performance of grasp and placement tasks are then presented. The studies used within-subjects designs with 11, 12, and 10 participants, respectively. Results showed that SDSR affected performance only if it was above 82 ms. Placement required more frequent visual feedback and was more sensitive to SR. We infer that VE designers need not tightly control SDSR and may wish to vary SR control based on required visual feedback frequency. These results may be used to improve the human-computer interface in a wide range of interactive graphical applications, including scientific visualization, training, mental health, and entertainment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.18085v1</guid>
      <category>cs.HC</category>
      <category>cs.ET</category>
      <pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1518/001872098779591287</arxiv:DOI>
      <arxiv:journal_reference>Human Factors: The Journal of the Human Factors and Ergonomics Society Volume 40 Issue 3 Pages 403-414 Publisher SAGE Publications 1998</arxiv:journal_reference>
      <dc:creator>Benjamin Watson, Neff Walker, William Ribarsky, Victoria Spaulding</dc:creator>
    </item>
    <item>
      <title>Agentic AI framework for End-to-End Medical Data Inference</title>
      <link>https://arxiv.org/abs/2507.18115</link>
      <description>arXiv:2507.18115v1 Announce Type: cross 
Abstract: Building and deploying machine learning solutions in healthcare remains expensive and labor-intensive due to fragmented preprocessing workflows, model compatibility issues, and stringent data privacy constraints. In this work, we introduce an Agentic AI framework that automates the entire clinical data pipeline, from ingestion to inference, through a system of modular, task-specific agents. These agents handle both structured and unstructured data, enabling automatic feature selection, model selection, and preprocessing recommendation without manual intervention. We evaluate the system on publicly available datasets from geriatrics, palliative care, and colonoscopy imaging. For example, in the case of structured data (anxiety data) and unstructured data (colonoscopy polyps data), the pipeline begins with file-type detection by the Ingestion Identifier Agent, followed by the Data Anonymizer Agent ensuring privacy compliance, where we first identify the data type and then anonymize it. The Feature Extraction Agent identifies features using an embedding-based approach for tabular data, extracting all column names, and a multi-stage MedGemma-based approach for image data, which infers modality and disease name. These features guide the Model-Data Feature Matcher Agent in selecting the best-fit model from a curated repository. The Preprocessing Recommender Agent and Preprocessing Implementor Agent then apply tailored preprocessing based on data type and model requirements. Finally, the ``Model Inference Agent" runs the selected model on the uploaded data and generates interpretable outputs using tools like SHAP, LIME, and DETR attention maps. By automating these high-friction stages of the ML lifecycle, the proposed framework reduces the need for repeated expert intervention, offering a scalable, cost-efficient pathway for operationalizing AI in clinical environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.18115v1</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Soorya Ram Shimgekar, Shayan Vassef, Abhay Goyal, Navin Kumar, Koustuv Saha</dc:creator>
    </item>
    <item>
      <title>PRACtical: Subarray-Level Counter Update and Bank-Level Recovery Isolation for Efficient PRAC Rowhammer Mitigation</title>
      <link>https://arxiv.org/abs/2507.18581</link>
      <description>arXiv:2507.18581v1 Announce Type: cross 
Abstract: As DRAM density increases, Rowhammer becomes more severe due to heightened charge leakage, reducing the number of activations needed to induce bit flips. The DDR5 standard addresses this threat with in-DRAM per-row activation counters (PRAC) and the Alert Back-Off (ABO) signal to trigger mitigation. However, PRAC adds performance overhead by incrementing counters during the precharge phase, and recovery refreshes stalls the entire memory channel, even if only one bank is under attack.
  We propose PRACtical, a performance-optimized approach to PRAC+ABO that maintains the same security guarantees. First, we reduce counter update latency by introducing a centralized increment circuit, enabling overlap between counter updates and subsequent row activations in other subarrays. Second, we enhance the $RFM_{ab}$ mitigation by enabling bank-level granularity: instead of stalling the entire channel, only affected banks are paused. This is achieved through a DRAM-resident register that identifies attacked banks.
  PRACtical improves performance by 8% on average (up to 20%) over the state-of-the-art, reduces energy by 19%, and limits performance degradation from aggressive performance attacks to less than 6%, all while preserving Rowhammer protection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.18581v1</guid>
      <category>cs.AR</category>
      <category>cs.ET</category>
      <pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ravan Nazaraliyev, Saber Ganjisaffar, Nurlan Nazaraliyev, Nael Abu-Ghazaleh</dc:creator>
    </item>
    <item>
      <title>Quantum Machine Learning in Precision Medicine and Drug Discovery -- A Game Changer for Tailored Treatments?</title>
      <link>https://arxiv.org/abs/2502.18639</link>
      <description>arXiv:2502.18639v2 Announce Type: replace 
Abstract: The digitization of healthcare presents numerous challenges, including the complexity of biological systems, vast data generation, and the need for personalized treatment plans. Traditional computational methods often fall short, leading to delayed and sometimes ineffective diagnoses and treatments. Quantum Computing (QC) and Quantum Machine Learning (QML) offer transformative advancements with the potential to revolutionize medicine. This paper summarizes areas where QC promises unprecedented computational power, enabling faster, more accurate diagnostics, personalized treatments, and enhanced drug discovery processes. However, integrating quantum technologies into precision medicine also presents challenges, including errors in algorithms and high costs. We show that mathematically-based techniques for specifying, developing, and verifying software (formal methods) can enhance the reliability and correctness of QC. By providing a rigorous mathematical framework, formal methods help to specify, develop, and verify systems with high precision. In genomic data analysis, formal specification languages can precisely (1) define the behavior and properties of quantum algorithms designed to identify genetic markers associated with diseases. Model checking tools can systematically explore all possible states of the algorithm to (2) ensure it behaves correctly under all conditions, while theorem proving techniques provide mathematical (3) proof that the algorithm meets its specified properties, ensuring accuracy and reliability. Additionally, formal optimization techniques can (4) enhance the efficiency and performance of quantum algorithms by reducing resource usage, such as the number of qubits and gate operations. Therefore, we posit that formal methods can significantly contribute to enabling QC to realize its full potential as a game changer in precision medicine.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.18639v2</guid>
      <category>cs.ET</category>
      <category>cs.AI</category>
      <category>quant-ph</category>
      <pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Markus Bertl, Alan Mott, Salvatore Sinno, Bhavika Bhalgamiya</dc:creator>
    </item>
    <item>
      <title>Non-Variational Quantum Random Access Optimization with Alternating Operator Ansatz</title>
      <link>https://arxiv.org/abs/2502.04277</link>
      <description>arXiv:2502.04277v2 Announce Type: replace-cross 
Abstract: Solving hard optimization problems is one of the most promising application domains for quantum computers due to the ubiquity of such problems in industry and the availability of broadly applicable quantum speedups. However, the ability of near-term quantum computers to tackle industrial-scale optimization problems is limited by their size and the overheads of quantum error correction. Quantum Random Access Optimization (QRAO) has been proposed to reduce the space requirements of quantum optimization. However, to date QRAO has only been implemented using variational algorithms, which suffer from the need to train instance-specific variational parameters, making them difficult to scale. We propose and benchmark a non-variational approach to QRAO based on the Quantum Alternating Operator Ansatz (QAOA) for the MaxCut problem. We show that instance-independent ``fixed" parameters achieve good performance, removing the need for variational parameter optimization. Additionally, we evaluate different design choices, such as various mixers, initial states, and QRAO-specific implementations of the QAOA cost operator, and identify a strategy that performs well in practice. Our results pave the way for the practical execution of QRAO on early fault-tolerant quantum computers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04277v2</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zichang He, Rudy Raymond, Ruslan Shaydulin, Marco Pistoia</dc:creator>
    </item>
    <item>
      <title>Is Circuit Depth Accurate for Comparing Quantum Circuit Runtimes?</title>
      <link>https://arxiv.org/abs/2505.16908</link>
      <description>arXiv:2505.16908v2 Announce Type: replace-cross 
Abstract: Although quantum circuit depth is commonly used to approximate circuit runtimes, it overlooks a prevailing trait of current hardware implementation: different gates have different execution times. Recognizing the potential for discrepancies, we investigate depth's accuracy for comparing runtimes between compiled versions of the same circuit. In particular, we assess the accuracy of traditional and multi-qubit depth for (1) predicting relative differences in runtime and (2) identifying compiled circuit version(s) with the shortest runtime. Finding that circuit depth is not accurate for either task, we introduce a new metric, gate-aware depth, that weights gates' contributions to runtime using an architecture's average gate execution times. Using average gate times allows gate-aware depth to capture variations by gate type without requiring exact knowledge of all gate times, increasing accuracy while maintaining portability across devices of the same architecture. Compared to traditional and multi-qubit depth, gate-aware depth reduces the average relative error of predictions in task (1) by 68 and 18 times and increases the average number of correct identifications in task (2) by 20 and 43 percentage points, respectively. Finally, we provide gate-aware depth weight configurations for current IBM Eagle and Heron architectures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.16908v2</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matthew Tremba, Paul Hovland, Ji Liu</dc:creator>
    </item>
    <item>
      <title>OrQstrator: An AI-Powered Framework for Advanced Quantum Circuit Optimization</title>
      <link>https://arxiv.org/abs/2507.09682</link>
      <description>arXiv:2507.09682v2 Announce Type: replace-cross 
Abstract: We propose a novel approach, OrQstrator, which is a modular framework for conducting quantum circuit optimization in the Noisy Intermediate-Scale Quantum (NISQ) era. Our framework is powered by Deep Reinforcement Learning (DRL). Our orchestration engine intelligently selects among three complementary circuit optimizers: A DRL-based circuit rewriter trained to reduce depth and gate count via learned rewrite sequences; a domain-specific optimizer that performs efficient local gate resynthesis and numeric optimization; a parameterized circuit instantiator that improves compilation by optimizing template circuits during gate set translation. These modules are coordinated by a central orchestration engine that learns coordination policies based on circuit structure, hardware constraints, and backend-aware performance features such as gate count, depth, and expected fidelity. The system outputs an optimized circuit for hardware-aware transpilation and execution, leveraging techniques from an existing state-of-the-art approach, called the NISQ Analyzer, to adapt to backend constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.09682v2</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Laura Baird, Armin Moin</dc:creator>
    </item>
  </channel>
</rss>
