<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CC</link>
    <description>cs.CC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 22 Sep 2025 04:00:50 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Complexity of the Freezing Majority Rule with L-shaped Neighborhoods</title>
      <link>https://arxiv.org/abs/2509.16065</link>
      <description>arXiv:2509.16065v1 Announce Type: new 
Abstract: In this article we investigate the computational complexity of predicting two dimensional freezing majority cellular automata with states $\{-1,+1\}$, where the local interactions are based on an L-shaped neighborhood structure. In these automata, once a cell reaches state $+1$, it remains fixed in that state forever, while cells in state $-1$ update to the most represented state among their neighborhoods. We consider L-shaped neighborhoods, which mean that the vicinity of a given cell $c$ consists in a subset of cells in the north and east of $c$.
  We focus on the prediction problem, a decision problem that involves determining the state of a given cell after a given number of time-steps. We prove that when restricted to the simplest L-shaped neighborhood, consisting of the central cell and its nearest north and east neighbors, the prediction problem belongs to $\mathsf{NC}$, meaning it can be solved efficiently in parallel. We generalize this result for any L-shaped neighborhood of size two. On the other hand, for other L-shaped neighborhoods, the problem becomes $\mathsf{P}$-complete, indicating that the problem might be inherently sequential.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.16065v1</guid>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pablo Concha-Vega, Eric Goles, Pedro Montealegre, K\'evin Perrot</dc:creator>
    </item>
    <item>
      <title>Unentanglement and Post-Measurement Branching in Quantum Interactive Proofs</title>
      <link>https://arxiv.org/abs/2509.15319</link>
      <description>arXiv:2509.15319v1 Announce Type: cross 
Abstract: We investigate two resources whose effects on quantum interactive proofs remain poorly understood: the promise of unentanglement, and the verifier's ability to condition on an intermediate measurement, which we call post-measurement branching. We first show that unentanglement can dramatically increase computational power: three-round unentangled quantum interactive proofs equal NEXP, even if only the first message is quantum. By contrast, we prove that if the verifier uses no post-measurement branching, then the same type of unentangled proof system has at most the power of QAM. Finally, we investigate post-measurement branching in two-round quantum-classical proof systems. Unlike the equivalence between public-coin and private-coin classical interactive proofs, we give evidence of a separation in the quantum setting that arises from post-measurement branching.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.15319v1</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sabee Grewal, William Kretschmer</dc:creator>
    </item>
    <item>
      <title>Polynomial Equivalence of Extended Chemical Reaction Models</title>
      <link>https://arxiv.org/abs/2509.15584</link>
      <description>arXiv:2509.15584v1 Announce Type: cross 
Abstract: The ability to detect whether a species (or dimension) is zero in Chemical Reaction Networks (CRN), Vector Addition Systems, or Petri Nets is known to increase the power of these models -- making them capable of universal computation. While this ability may appear in many forms, such as extending the models to allow transitions to be inhibited, prioritized, or synchronized, we present an extension that directly performs this zero checking. We introduce a new void genesis CRN variant with a simple design that merely increments the count of a specific species when any other species' count goes to zero. As with previous extensions, we show that the model is Turing Universal. We then analyze several other studied CRN variants and show that they are all equivalent through a polynomial simulation with the void genesis model, which does not merely follow from Turing-universality. Thus, inhibitor species, reactions that occur at different rates, being allowed to run reactions in parallel, or even being allowed to continually add more volume to the CRN, does not add additional simulation power beyond simply detecting if a species count becomes zero.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.15584v1</guid>
      <category>q-bio.MN</category>
      <category>cs.CC</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Divya Bajaj, Jose Luis Castellanos, Ryan Knobel, Austin Luchsinger, Aiden Massie, Adrian Salinas, Pablo Santos, Ramiro Santos, Robert Schweller, Tim Wylie</dc:creator>
    </item>
    <item>
      <title>Solvability Complexity Index Classification For Koopman Operator Spectra In $L^p$ For $1&lt;p&lt;\infty$</title>
      <link>https://arxiv.org/abs/2509.16016</link>
      <description>arXiv:2509.16016v1 Announce Type: cross 
Abstract: We study the computation of the approximate point spectrum and the approximate point $\varepsilon$-pseudospectrum of bounded Koopman operators acting on $L^p(\mathcal{X},\omega)$ for $1&lt;p&lt;\infty$ and a compact metric space $(\mathcal{X}, d_{\mathcal{X}})$ with finite Borel measure $\omega$. Building on finite sections in a computable unconditional Schauder basis of $L^p(\mathcal{X},\omega)$, we design residual tests that use only finitely many evaluations of the underlying map and produce compact sets on a planar grid, that converge in the Hausdorff metric to the target spectral sets, without spectral pollution. From these constructions we obtain a complete classification, in the sense of the Solvability Complexity Index, of how many limiting procedures are inherently necessary. Also we analyze the sufficiency and existence of a Wold-von Neumann decomposition analog, that was used in the special $L^2$-case.
  The main difficulty in extending from the already analyzed Hilbert setting $(p=2)$ to general $L^p$ is the loss of orthogonality and Hilbertian structure: there is no orthonormal basis with orthogonal coordinate projections in general, the canonical truncations $E_n$ in a computable Schauder dictionary need not be contractive (and may oscillate) and the Wold-von Neumann reduction has no directly computable analog in $L^p$. We overcome these obstacles by working with computable unconditional dictionaries adapted to dyadic/Lipschitz filtrations and proving stability of residual tests under non-orthogonal truncations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.16016v1</guid>
      <category>math.SP</category>
      <category>cs.CC</category>
      <category>cs.NA</category>
      <category>math.DS</category>
      <category>math.NA</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christopher Sorg</dc:creator>
    </item>
    <item>
      <title>Is Graph Local Complementation Inherently Sequential?</title>
      <link>https://arxiv.org/abs/2503.24144</link>
      <description>arXiv:2503.24144v3 Announce Type: replace 
Abstract: Local complementation of a graph $G$ on vertex $v$ is an operation that results in a new graph $G*v$, where the neighborhood of $v$ is complemented. Two graph are locally equivalent if on can be reached from the other one through local complementation.
  It was previously established that recognizing locally equivalent graphs can be done in $\mathcal{O}(n^4)$ time. We sharpen this result by proving it can be decided in $\mathcal{O}(\log^2(n))$ parallel time with $n^{\mathcal{O}(1)}$ processors.
  As a second contribution, we introduce the Local Complementation Problem, a decision problem that captures the complexity of applying a sequence of local complementations. Given a graph $G$, a sequence of vertices $s$, and a pair of vertices $u,v$, the problem asks whether the edge $(u,v)$ is present in the graph obtained after applying local complementations according to $s$. Regardless it simplicity, it is proven to be $\mathsf{P}$-complete, therefore it is unlikely to be efficiently parallelizable.
  Finally, it is conjectured that Local Complementation Problem remains $\mathsf{P}$-complete when restricted to circle graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.24144v3</guid>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pablo Concha-Vega (Aix-Marseille Universit\'e Toulon, LIS, CNRS UMR 7020, Marseille, France)</dc:creator>
    </item>
  </channel>
</rss>
