<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.TH updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.TH</link>
    <description>econ.TH updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.TH" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 01 Aug 2025 10:38:19 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Capturing Misalignment</title>
      <link>https://arxiv.org/abs/2506.17176</link>
      <description>arXiv:2506.17176v3 Announce Type: replace 
Abstract: We introduce and formalize misalignment, a phenomenon of interactive environments perceived from an analyst's perspective where an agent holds beliefs about another agent's beliefs that do not correspond to the actual beliefs of the latter. We demonstrate that standard frameworks, such as type structures, fail to capture misalignment, necessitating new tools to analyze this phenomenon. To this end, we characterize misalignment through non-belief-closed state spaces and introduce agent-dependent type structures, which provide a flexible tool to understand the varying degrees of misalignment. Furthermore, we establish that appropriately adapted modal operators on agent-dependent type structures behave consistently with standard properties, enabling us to explore the implications of misalignment for interactive reasoning. Finally, we show how speculative trade can arise under misalignment, even when imposing the corresponding assumptions that rule out such trades in standard environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.17176v3</guid>
      <category>econ.TH</category>
      <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Pierfrancesco Guarino, Gabriel Ziegler</dc:creator>
    </item>
    <item>
      <title>Reasoning about Bounded Reasoning</title>
      <link>https://arxiv.org/abs/2506.19737</link>
      <description>arXiv:2506.19737v3 Announce Type: replace 
Abstract: Interactive decision-making relies on strategic reasoning. Two prominent frameworks are (1) models of bounded reasoning, exemplified by level-$k$ models, which keep reasoning implicit, and (2) epistemic game theory, which makes reasoning explicit. We connect these approaches by "lifting" static complete-information games into incomplete-information settings where payoff types reflect players' reasoning depths as in level-$k$ models. We introduce downward rationalizability, defined via minimal belief restrictions capturing the basic idea common to level-$k$ models, to provide robust and well-founded predictions in games where bounded reasoning matters. We then refine these belief restrictions to analyze the foundations of two seminal models of bounded reasoning: the classic level-$k$ model and the cognitive hierarchy model. Our findings shed light on the distinction between hard cognitive bounds on reasoning and beliefs about co-players' types. Furthermore, they offer insights into robustness issues relevant for market design. Thus, our approach unifies key level-$k$ models building on clear foundations of strategic reasoning stemming from epistemic game theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.19737v3</guid>
      <category>econ.TH</category>
      <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Shuige Liu, Gabriel Ziegler</dc:creator>
    </item>
    <item>
      <title>AI Agents and the Attention Lemons Problem in Two-Sided Ad Markets</title>
      <link>https://arxiv.org/abs/2507.22435</link>
      <description>arXiv:2507.22435v2 Announce Type: replace 
Abstract: I develop a theoretical model to examine how the rise of autonomous AI (artificial intelligence) agents disrupts two-sided digital advertising markets. Through this framework, I demonstrate that users' rational, private decisions to delegate browsing to agents create a negative externality, precipitating declines in ad prices, publisher revenues, and overall market efficiency. The model identifies the conditions under which publisher interventions such as blocking AI agents or imposing tolls may mitigate these effects, although they risk fragmenting access and value. I formalize the resulting inefficiency as an ``attention lemons" problem, where synthetic agent traffic dilutes the quality of attention sold to advertisers, generating adverse selection. To address this, I propose a Pigouvian correction mechanism: a per-delegation fee designed to internalize the externality and restore welfare. The model demonstrates that, for an individual publisher, charging AI agents toll fees for access strictly dominates both the `Blocking' and `Null (inaction)' strategies. Finally, I characterize a critical tipping point beyond which unchecked delegation triggers a collapse of the ad-funded digital market.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.22435v2</guid>
      <category>econ.TH</category>
      <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Md Mahadi Hasan</dc:creator>
    </item>
  </channel>
</rss>
