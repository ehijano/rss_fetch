<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.ME updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.ME</link>
    <description>stat.ME updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.ME" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 05 Dec 2024 02:44:59 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Dynamic Prediction of High-density Generalized Functional Data with Fast Generalized Functional Principal Component Analysis</title>
      <link>https://arxiv.org/abs/2412.02014</link>
      <description>arXiv:2412.02014v1 Announce Type: new 
Abstract: Dynamic prediction, which typically refers to the prediction of future outcomes using historical records, is often of interest in biomedical research. For datasets with large sample sizes, high measurement density, and complex correlation structures, traditional methods are often infeasible because of the computational burden associated with both data scale and model complexity. Moreover, many models do not directly facilitate out-of-sample predictions for generalized outcomes. To address these issues, we develop a novel approach for dynamic predictions based on a recently developed method estimating complex patterns of variation for exponential family data: fast Generalized Functional Principal Components Analysis (fGFPCA). Our method is able to handle large-scale, high-density repeated measures much more efficiently with its implementation feasible even on personal computational resources (e.g., a standard desktop or laptop computer). The proposed method makes highly flexible and accurate predictions of future trajectories for data that exhibit high degrees of nonlinearity, and allows for out-of-sample predictions to be obtained without reestimating any parameters. A simulation study is designed and implemented to illustrate the advantages of this method. To demonstrate its practical utility, we also conducted a case study to predict diurnal active/inactive patterns using accelerometry data from the National Health and Nutrition Examination Survey (NHANES) 2011-2014. Both the simulation study and the data application demonstrate the better predictive performance and high computational efficiency of the proposed method compared to existing methods. The proposed method also obtains more personalized prediction that improves as more information becomes available, which is an essential goal of dynamic prediction that other methods fail to achieve.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.02014v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ying Jin, Andrew Leroux</dc:creator>
    </item>
    <item>
      <title>The causal effects of modified treatment policies under network interference</title>
      <link>https://arxiv.org/abs/2412.02105</link>
      <description>arXiv:2412.02105v1 Announce Type: new 
Abstract: Modified treatment policies are a widely applicable class of interventions used to study the causal effects of continuous exposures. Approaches to evaluating their causal effects assume no interference, meaning that such effects cannot be learned from data in settings where the exposure of one unit affects the outcome of others, as is common in spatial or network data. We introduce a new class of intervention, induced modified treatment policies, which we show identify such causal effects in the presence of network interference. Building on recent developments in network causal inference, we provide flexible, semi-parametric efficient estimators of the identified statistical estimand. Simulation experiments demonstrate that an induced modified treatment policy can eliminate causal (or identification) bias resulting from interference. We use the methods developed to evaluate the effect of zero-emission vehicle uptake on air pollution in California, strengthening prior evidence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.02105v1</guid>
      <category>stat.ME</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Salvador V. Balkus, Scott W. Delaney, Nima S. Hejazi</dc:creator>
    </item>
    <item>
      <title>Efficient Analysis of Latent Spaces in Heterogeneous Networks</title>
      <link>https://arxiv.org/abs/2412.02151</link>
      <description>arXiv:2412.02151v1 Announce Type: new 
Abstract: This work proposes a unified framework for efficient estimation under latent space modeling of heterogeneous networks. We consider a class of latent space models that decompose latent vectors into shared and network-specific components across networks. We develop a novel procedure that first identifies the shared latent vectors and further refines estimates through efficient score equations to achieve statistical efficiency. Oracle error rates for estimating the shared and heterogeneous latent vectors are established simultaneously. The analysis framework offers remarkable flexibility, accommodating various types of edge weights under exponential family distributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.02151v1</guid>
      <category>stat.ME</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuang Tian, Jiajin Sun, Yinqiu He</dc:creator>
    </item>
    <item>
      <title>Searching for local associations while controlling the false discovery rate</title>
      <link>https://arxiv.org/abs/2412.02182</link>
      <description>arXiv:2412.02182v1 Announce Type: new 
Abstract: We introduce local conditional hypotheses that express how the relation between explanatory variables and outcomes changes across different contexts, described by covariates. By expanding upon the model-X knockoff filter, we show how to adaptively discover these local associations, all while controlling the false discovery rate. Our enhanced inferences can help explain sample heterogeneity and uncover interactions, making better use of the capabilities offered by modern machine learning models. Specifically, our method is able to leverage any model for the identification of data-driven hypotheses pertaining to different contexts. Then, it rigorously test these hypotheses without succumbing to selection bias. Importantly, our approach is efficient and does not require sample splitting. We demonstrate the effectiveness of our method through numerical experiments and by studying the genetic architecture of Waist-Hip-Ratio across different sexes in the UKBiobank.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.02182v1</guid>
      <category>stat.ME</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Paula Gablenz, Matteo Sesia, Tianshu Sun, Chiara Sabatti</dc:creator>
    </item>
    <item>
      <title>Estimation of a multivariate von Mises distribution for contaminated torus data</title>
      <link>https://arxiv.org/abs/2412.02333</link>
      <description>arXiv:2412.02333v1 Announce Type: new 
Abstract: The occurrence of atypical circular observations on the torus can badly affect parameters estimation of the multivariate von Mises distribution. This paper addresses the problem of robust fitting of the multivariate von Mises model using the weighted likelihood methodology. The key ingredients are non-parametric density estimation for multivariate circular data and the definition of appropriate weighted estimating equations. The finite sample behavior of the proposed weighted likelihood estimator has been investigated by Monte Carlo numerical studies and real data examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.02333v1</guid>
      <category>stat.ME</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Giulia Bertagnolli, Luca Greco, Claudio Agostinelli</dc:creator>
    </item>
    <item>
      <title>Quantile-Crossing Spectrum and Spline Autoregression Estimation</title>
      <link>https://arxiv.org/abs/2412.02513</link>
      <description>arXiv:2412.02513v1 Announce Type: new 
Abstract: The quantile-crossing spectrum is the spectrum of quantile-crossing processes created from a time series by the indicator function that shows whether or not the time series lies above or below a given quantile at a given time. This bivariate function of frequency and quantile level provides a richer view of serial dependence than that offered by the ordinary spectrum. We propose a new method for estimating the quantile-crossing spectrum as a bivariate function of frequency and quantile level. The proposed method, called spline autoregression (SAR), jointly fits an AR model to the quantile-crossing series across multiple quantiles; the AR coefficients are represented as spline functions of the quantile level and penalized for their roughness. Numerical experiments show that when the underlying spectrum is smooth in quantile level the proposed method is able to produce more accurate estimates in comparison with the alternative that ignores the smoothness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.02513v1</guid>
      <category>stat.ME</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ta-Hsin Li</dc:creator>
    </item>
    <item>
      <title>The Landscape of Causal Discovery Data: Grounding Causal Discovery in Real-World Applications</title>
      <link>https://arxiv.org/abs/2412.01953</link>
      <description>arXiv:2412.01953v1 Announce Type: cross 
Abstract: Causal discovery aims to automatically uncover causal relationships from data, a capability with significant potential across many scientific disciplines. However, its real-world applications remain limited. Current methods often rely on unrealistic assumptions and are evaluated only on simple synthetic toy datasets, often with inadequate evaluation metrics. In this paper, we substantiate these claims by performing a systematic review of the recent causal discovery literature. We present applications in biology, neuroscience, and Earth sciences - fields where causal discovery holds promise for addressing key challenges. We highlight available simulated and real-world datasets from these domains and discuss common assumption violations that have spurred the development of new methods. Our goal is to encourage the community to adopt better evaluation practices by utilizing realistic datasets and more adequate metrics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01953v1</guid>
      <category>cs.LG</category>
      <category>stat.ME</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Philippe Brouillard, Chandler Squires, Jonas Wahl, Konrad P. Kording, Karen Sachs, Alexandre Drouin, Dhanya Sridhar</dc:creator>
    </item>
    <item>
      <title>TITE-CLRM: Towards efficient time-to-event dose-escalation guidance of multi-cycle cancer therapies</title>
      <link>https://arxiv.org/abs/2412.02355</link>
      <description>arXiv:2412.02355v1 Announce Type: cross 
Abstract: Treatment of cancer has rapidly evolved over time in quite dramatic ways, for example from chemotherapies, targeted therapies to immunotherapies and chimeric antigen receptor T-cells. Nonetheless, the basic design of early phase I trials in oncology still follows pre-dominantly a dose-escalation design. These trials monitor safety over the first treatment cycle in order to escalate the dose of the investigated drug. However, over time studying additional factors such as drug combinations and/or variation in the timing of dosing became important as well. Existing designs were continuously enhanced and expanded to account for increased trial complexity. With toxicities occurring at later stages beyond the first cycle and the need to treat patients over multiple cycles, the focus on the first treatment cycle only is becoming a limitation in nowadays multi-cycle treatment therapies. Here we introduce a multi-cycle time-to-event model (TITE-CLRM: Time-Interval-To-Event Complementary-Loglog Regression Model) allowing guidance of dose-escalation trials studying multi-cycle therapies. The challenge lies in balancing the need to monitor safety of longer treatment periods with the need to continuously enroll patients safely. The proposed multi-cycle time to event model is formulated as an extension to established concepts like the escalation with over dose control principle. The model is motivated from a current drug development project and evaluated in a simulation study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.02355v1</guid>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lukas Andreas Widmer, Sebastian Weber, Yunnan Xu, Hans-Jochen Weber</dc:creator>
    </item>
    <item>
      <title>Nature versus nurture in galaxy formation: the effect of environment on star formation with causal machine learning</title>
      <link>https://arxiv.org/abs/2412.02439</link>
      <description>arXiv:2412.02439v1 Announce Type: cross 
Abstract: Understanding how galaxies form and evolve is at the heart of modern astronomy. With the advent of large-scale surveys and simulations, remarkable progress has been made in the last few decades. Despite this, the physical processes behind the phenomena, and particularly their importance, remain far from known, as correlations have primarily been established rather than the underlying causality. We address this challenge by applying the causal inference framework. Specifically, we tackle the fundamental open question of whether galaxy formation and evolution depends more on nature (i.e., internal processes) or nurture (i.e., external processes), by estimating the causal effect of environment on star-formation rate in the IllustrisTNG simulations. To do so, we develop a comprehensive causal model and employ cutting-edge techniques from epidemiology to overcome the long-standing problem of disentangling nature and nurture. We find that the causal effect is negative and substantial, with environment suppressing the SFR by a maximal factor of $\sim100$. While the overall effect at $z=0$ is negative, in the early universe, environment is discovered to have a positive impact, boosting star formation by a factor of $\sim10$ at $z\sim1$ and by even greater amounts at higher redshifts. Furthermore, we show that: (i) nature also plays an important role, as ignoring it underestimates the causal effect in intermediate-density environments by a factor of $\sim2$, (ii) controlling for the stellar mass at a snapshot in time, as is common in the literature, is not only insufficient to disentangle nature and nurture but actually has an adverse effect, though (iii) stellar mass is an adequate proxy of the effects of nature. Finally, this work may prove a useful blueprint for extracting causal insights in other fields that deal with dynamical systems with closed feedback loops, such as the Earth's climate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.02439v1</guid>
      <category>astro-ph.GA</category>
      <category>cs.LG</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sunil Mucesh, William G. Hartley, Ciar\'an M. Gilligan-Lee, Ofer Lahav</dc:creator>
    </item>
    <item>
      <title>On the optimality of coin-betting for mean estimation</title>
      <link>https://arxiv.org/abs/2412.02640</link>
      <description>arXiv:2412.02640v1 Announce Type: cross 
Abstract: Confidence sequences are sequences of confidence sets that adapt to incoming data while maintaining validity. Recent advances have introduced an algorithmic formulation for constructing some of the tightest confidence sequences for bounded real random variables. These approaches use a coin-betting framework, where a player sequentially bets on differences between potential mean values and observed data. This letter establishes that such coin-betting formulation is optimal among all possible algorithmic frameworks for constructing confidence sequences that build on e-variables and sequential hypothesis testing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.02640v1</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eugenio Clerico</dc:creator>
    </item>
    <item>
      <title>Estimating Treatment Effect under Additive Hazards Models with High-dimensional Covariates</title>
      <link>https://arxiv.org/abs/1907.00287</link>
      <description>arXiv:1907.00287v2 Announce Type: replace 
Abstract: Estimating causal effects for survival outcomes in the high-dimensional setting is an extremely important topic for many biomedical applications as well as areas of social sciences. We propose a new orthogonal score method for treatment effect estimation and inference that results in asymptotically valid confidence intervals assuming only good estimation properties of the hazard outcome model and the conditional probability of treatment. This guarantee allows us to provide valid inference for the conditional treatment effect under the high-dimensional additive hazards model under considerably more generality than existing approaches. In addition, we develop a new Hazards Difference (HDi), estimator. We showcase that our approach has double-robustness properties in high dimensions: with cross-fitting, the HDi estimate is consistent under a wide variety of treatment assignment models; the HDi estimate is also consistent when the hazards model is misspecified and instead the true data generating mechanism follows a partially linear additive hazards model. We further develop a novel sparsity doubly robust result, where either the outcome or the treatment model can be a fully dense high-dimensional model. We apply our methods to study the treatment effect of radical prostatectomy versus conservative management for prostate cancer patients using the SEER-Medicare Linked Data.</description>
      <guid isPermaLink="false">oai:arXiv.org:1907.00287v2</guid>
      <category>stat.ME</category>
      <category>q-bio.QM</category>
      <category>stat.AP</category>
      <category>stat.ML</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1080/01621459.2021.1930546</arxiv:DOI>
      <arxiv:journal_reference>Journal of the American Statistical Association 118(541) 327-342 (2021)</arxiv:journal_reference>
      <dc:creator>Jue Hou, Jelena Bradic, Ronghui Xu</dc:creator>
    </item>
    <item>
      <title>Nonstationary Gaussian Process Surrogates</title>
      <link>https://arxiv.org/abs/2305.19242</link>
      <description>arXiv:2305.19242v2 Announce Type: replace 
Abstract: We provide a survey of nonstationary surrogate models which utilize Gaussian processes (GPs) or variations thereof, including nonstationary kernel adaptations, partition and local GPs, and spatial warpings through deep Gaussian processes. We also overview publicly available software implementations and conclude with a bake-off involving an 8-dimensional satellite drag computer experiment. Code for this example is provided in a public git repository.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.19242v2</guid>
      <category>stat.ME</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Annie S. Booth, Andrew Cooper, Robert B. Gramacy</dc:creator>
    </item>
    <item>
      <title>Multi-resolution filters via linear projection for large spatio-temporal datasets</title>
      <link>https://arxiv.org/abs/2401.05315</link>
      <description>arXiv:2401.05315v2 Announce Type: replace 
Abstract: Advances in compact sensing devices mounted on satellites have facilitated the collection of large spatio-temporal datasets with coordinates. Since such datasets are often incomplete and noisy, it is useful to create the prediction surface of a spatial field. To this end, we consider an online filtering inference by using the Kalman filter based on linear Gaussian state-space models. However, the Kalman filter is impractically time-consuming when the number of locations in spatio-temporal datasets is large. To address this problem, we propose a multi-resolution filter via linear projection (MRF-lp), a fast computation method for online filtering inference. In the MRF-lp, by carrying out a multi-resolution approximation via linear projection (MRA-lp), the forecast covariance matrix can be approximated while capturing both the large- and small-scale spatial variations. As a result of this approximation, our proposed MRF-lp preserves a block-sparse structure of some matrices appearing in the MRF-lp through time, which leads to the scalability of this algorithm. Additionally, we discuss extensions of the MRF-lp to a nonlinear and non-Gaussian case. Simulation studies and real data analysis for total precipitable water vapor demonstrate that our proposed approach performs well compared with the related methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.05315v2</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Toshihiro Hirano, Tsunehiro Ishihara</dc:creator>
    </item>
    <item>
      <title>Computational Considerations for the Linear Model of Coregionalization</title>
      <link>https://arxiv.org/abs/2402.08877</link>
      <description>arXiv:2402.08877v2 Announce Type: replace 
Abstract: In the last two decades, the linear model of coregionalization (LMC) has been widely used to model multivariate spatial processes. However, it can be a challenging task to conduct likelihood-based inference for such models because of the cubic cost associated with Gaussian likelihood evaluations. Starting from an analogy with matrix normal models, we propose a reformulation of the LMC likelihood that highlights the linear, rather than cubic, computational complexity as a function of the dimension of the response vector. We describe how those simplifications can be exploited in Gaussian hierarchical models. In addition, we propose a new sparsity-inducing approach to the LMC that introduces structural zeros in the coregionalization matrix in an attempt to reduce the number of parameters in a principled and data-driven way. Our reformulation of the LMC likelihood ensures that our sparse approach comes at virtually no additional cost when included in a Markov chain Monte Carlo (MCMC) algorithm. It is shown, on synthetic data, to significantly improve predictive performance. We also apply our methodology to a dataset comprised of air pollutant measurements from the state of California. We investigate the strength of the correlation among the measurements by providing new insights from our sparse method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.08877v2</guid>
      <category>stat.ME</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Renaud Alie, David A. Stephens, Alexandra M. Schmidt</dc:creator>
    </item>
    <item>
      <title>Doubly robust estimation of marginal cumulative incidence curves for competing risk analysis</title>
      <link>https://arxiv.org/abs/2403.16256</link>
      <description>arXiv:2403.16256v2 Announce Type: replace 
Abstract: Covariate imbalance between treatment groups makes it difficult to compare cumulative incidence curves in competing risk analyses. In this paper we discuss different methods to estimate adjusted cumulative incidence curves including inverse probability of treatment weighting and outcome regression modeling. For these methods to work, correct specification of the propensity score model or outcome regression model, respectively, is needed. We introduce a new doubly robust estimator, which requires correct specification of only one of the two models. We conduct a simulation study to assess the performance of these three methods, including scenarios with model misspecification of the relationship between covariates and treatment and/or outcome. We illustrate their usage in a cohort study of breast cancer patients estimating covariate-adjusted marginal cumulative incidence curves for recurrence, second primary tumour development and death after undergoing mastectomy treatment or breast-conserving therapy. Our study points out the advantages and disadvantages of each covariate adjustment method when applied in competing risk analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16256v2</guid>
      <category>stat.ME</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Patrick van Hage, Saskia le Cessie, Marissa C. van Maaren, Hein Putter, Nan van Geloven</dc:creator>
    </item>
    <item>
      <title>Density-Calibrated Conformal Quantile Regression</title>
      <link>https://arxiv.org/abs/2411.19523</link>
      <description>arXiv:2411.19523v2 Announce Type: replace 
Abstract: This paper introduces the Density-Calibrated Conformal Quantile Regression (CQR-d) method, a novel approach for constructing prediction intervals that adapts to varying uncertainty across the feature space. Building upon conformal quantile regression, CQR-d incorporates local information through a weighted combination of local and global conformity scores, where the weights are determined by local data density. We prove that CQR-d provides valid marginal coverage at level $1 - \alpha - \epsilon$, where $\epsilon$ represents a small tolerance from numerical optimization. Through extensive simulation studies and an application to the a heteroscedastic dataset available in R, we demonstrate that CQR-d maintains the desired coverage while producing substantially narrower prediction intervals compared to standard conformal quantile regression (CQR). The method's effectiveness is particularly pronounced in settings with clear local uncertainty patterns, making it a valuable tool for prediction tasks in heterogeneous data environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19523v2</guid>
      <category>stat.ME</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuan Lu</dc:creator>
    </item>
    <item>
      <title>SpaCE: The Spatial Confounding Environment</title>
      <link>https://arxiv.org/abs/2312.00710</link>
      <description>arXiv:2312.00710v3 Announce Type: replace-cross 
Abstract: Spatial confounding poses a significant challenge in scientific studies involving spatial data, where unobserved spatial variables can influence both treatment and outcome, possibly leading to spurious associations. To address this problem, we introduce SpaCE: The Spatial Confounding Environment, the first toolkit to provide realistic benchmark datasets and tools for systematically evaluating causal inference methods designed to alleviate spatial confounding. Each dataset includes training data, true counterfactuals, a spatial graph with coordinates, and smoothness and confounding scores characterizing the effect of a missing spatial confounder. It also includes realistic semi-synthetic outcomes and counterfactuals, generated using state-of-the-art machine learning ensembles, following best practices for causal inference benchmarks. The datasets cover real treatment and covariates from diverse domains, including climate, health and social sciences. SpaCE facilitates an automated end-to-end pipeline, simplifying data loading, experimental setup, and evaluating machine learning and causal inference models. The SpaCE project provides several dozens of datasets of diverse sizes and spatial complexity. It is publicly available as a Python package, encouraging community feedback and contributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.00710v3</guid>
      <category>cs.LG</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Published at ICLR 2024</arxiv:journal_reference>
      <dc:creator>Mauricio Tec, Ana Trisovic, Michelle Audirac, Sophie Woodward, Jie Kate Hu, Naeem Khoshnevis, Francesca Dominici</dc:creator>
    </item>
    <item>
      <title>Identifying Treatment and Spillover Effects Using Exposure Contrasts</title>
      <link>https://arxiv.org/abs/2403.08183</link>
      <description>arXiv:2403.08183v3 Announce Type: replace-cross 
Abstract: To report spillover effects, a common practice is to regress outcomes on statistics capturing treatment variation among neighboring units. This paper studies the causal interpretation of nonparametric analogs of these estimands, which we refer to as exposure contrasts. We demonstrate that their signs can be inconsistent with those of the unit-level effects of interest even under unconfounded assignment. We then provide interpretable restrictions under which exposure contrasts are sign preserving and therefore have causal interpretations. We discuss the implications of our results for cluster-randomized trials, network experiments, and observational settings with peer effects in selection into treatment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.08183v3</guid>
      <category>econ.EM</category>
      <category>stat.ME</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael P. Leung</dc:creator>
    </item>
    <item>
      <title>Interventional Causal Discovery in a Mixture of DAGs</title>
      <link>https://arxiv.org/abs/2406.08666</link>
      <description>arXiv:2406.08666v2 Announce Type: replace-cross 
Abstract: Causal interactions among a group of variables are often modeled by a single causal graph. In some domains, however, these interactions are best described by multiple co-existing causal graphs, e.g., in dynamical systems or genomics. This paper addresses the hitherto unknown role of interventions in learning causal interactions among variables governed by a mixture of causal systems, each modeled by one directed acyclic graph (DAG). Causal discovery from mixtures is fundamentally more challenging than single-DAG causal discovery. Two major difficulties stem from (i)~an inherent uncertainty about the skeletons of the component DAGs that constitute the mixture and (ii)~possibly cyclic relationships across these component DAGs. This paper addresses these challenges and aims to identify edges that exist in at least one component DAG of the mixture, referred to as the true edges. First, it establishes matching necessary and sufficient conditions on the size of interventions required to identify the true edges. Next, guided by the necessity results, an adaptive algorithm is designed that learns all true edges using $O(n^2)$ interventions, where $n$ is the number of nodes. Remarkably, the size of the interventions is optimal if the underlying mixture model does not contain cycles across its components. More generally, the gap between the intervention size used by the algorithm and the optimal size is quantified. It is shown to be bounded by the cyclic complexity number of the mixture model, defined as the size of the minimal intervention that can break the cycles in the mixture, which is upper bounded by the number of cycles among the ancestors of a node.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.08666v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Burak Var{\i}c{\i}, Dmitriy Katz-Rogozhnikov, Dennis Wei, Prasanna Sattigeri, Ali Tajer</dc:creator>
    </item>
    <item>
      <title>Discovering influential text using convolutional neural networks</title>
      <link>https://arxiv.org/abs/2406.10086</link>
      <description>arXiv:2406.10086v3 Announce Type: replace-cross 
Abstract: Experimental methods for estimating the impacts of text on human evaluation have been widely used in the social sciences. However, researchers in experimental settings are usually limited to testing a small number of pre-specified text treatments. While efforts to mine unstructured texts for features that causally affect outcomes have been ongoing in recent years, these models have primarily focused on the topics or specific words of text, which may not always be the mechanism of the effect. We connect these efforts with NLP interpretability techniques and present a method for flexibly discovering clusters of similar text phrases that are predictive of human reactions to texts using convolutional neural networks. When used in an experimental setting, this method can identify text treatments and their effects under certain assumptions. We apply the method to two datasets. The first enables direct validation of the model's ability to detect phrases known to cause the outcome. The second demonstrates its ability to flexibly discover text treatments with varying textual structures. In both cases, the model learns a greater variety of text treatments compared to benchmark methods, and these text features quantitatively meet or exceed the ability of benchmark methods to predict the outcome.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.10086v3</guid>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <category>stat.ME</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Megan Ayers, Luke Sanford, Margaret Roberts, Eddie Yang</dc:creator>
    </item>
    <item>
      <title>On the Unknowable Limits to Prediction</title>
      <link>https://arxiv.org/abs/2411.19223</link>
      <description>arXiv:2411.19223v2 Announce Type: replace-cross 
Abstract: This short Correspondence critiques the classic dichotomization of prediction error into reducible and irreducible components, noting that certain types of error can be eliminated at differential speeds. We propose an improved analytical framework that better distinguishes epistemic from aleatoric uncertainty, emphasizing that predictability depends on information sets and cautioning against premature claims of unpredictability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19223v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>stat.ME</category>
      <pubDate>Wed, 04 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiani Yan, Charles Rahal</dc:creator>
    </item>
  </channel>
</rss>
