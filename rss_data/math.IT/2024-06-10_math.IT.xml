<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.IT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.IT</link>
    <description>math.IT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.IT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 11 Jun 2024 04:00:02 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 11 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>A Matrix Exponential Generalization of the Laplace Transform of Poisson Shot Noise</title>
      <link>https://arxiv.org/abs/2406.05212</link>
      <description>arXiv:2406.05212v1 Announce Type: new 
Abstract: We consider a generalization of the Laplace transform of Poisson shot noise defined as an integral transform with respect to a matrix exponential. We denote this integral transform as the {\em matrix Laplace transform} given its similarity to the Laplace-Stieltjes transform. We establish that the matrix Laplace transform is in general a natural matrix function extension of the typical scalar Laplace transform, and that the matrix Laplace transform of Poisson shot noise admits an expression that is analogous to the expression implied by Campbell's theorem for the Laplace functional of a Poisson point process. We demonstrate the utility of our generalization of Campbell's theorem in two important applications: the characterization of a Poisson shot noise process and the derivation of the complementary cumulative distribution function (CCDF) of signal to interference and noise (SINR) models with phase-type distributed fading powers. In the former application, we demonstrate how the higher order moments of a linear combination of samples of a Poisson shot noise process may be obtained directly from the elements of its matrix Laplace transform. We further show how arbitrarily tight approximations and bounds on the CCDF of this object may be obtained from the summation of the first row of its matrix Laplace transform. For the latter application, we show how the CCDF of SINR models with phase-type distributed fading powers may be obtained in terms of an expectation of the matrix Laplace transform of the interference and noise, analogous to the canonical case of SINR models with Rayleigh fading.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05212v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicholas R. Olson, Jeffrey G. Andrews</dc:creator>
    </item>
    <item>
      <title>Information-Theoretic Thresholds for the Alignments of Partially Correlated Graphs</title>
      <link>https://arxiv.org/abs/2406.05428</link>
      <description>arXiv:2406.05428v1 Announce Type: new 
Abstract: This paper studies the problem of recovering the hidden vertex correspondence between two correlated random graphs. We propose the partially correlated Erd\H{o}s-R\'enyi graphs model, wherein a pair of induced subgraphs with a certain number are correlated. We investigate the information-theoretic thresholds for recovering the latent correlated subgraphs and the hidden vertex correspondence. We prove that there exists an optimal rate for partial recovery for the number of correlated nodes, above which one can correctly match a fraction of vertices and below which correctly matching any positive fraction is impossible, and we also derive an optimal rate for exact recovery. In the proof of possibility results, we propose correlated functional digraphs, which partition the edges of the intersection graph into two types of components, and bound the error probability by lower-order cumulant generating functions. The proof of impossibility results build upon the generalized Fano's inequality and the recovery thresholds settled in correlated Erd\H{o}s-R\'enyi graphs model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05428v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dong Huang, Xianwen Song, Pengkun Yang</dc:creator>
    </item>
    <item>
      <title>Joint Cooperative Clustering and Power Control for Energy-Efficient Cell-Free XL-MIMO with Multi-Agent Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2406.05481</link>
      <description>arXiv:2406.05481v1 Announce Type: new 
Abstract: In this paper, we investigate the amalgamation of cell-free (CF) and extremely large-scale multiple-input multiple-output (XL-MIMO) technologies, referred to as a CF XL-MIMO, as a promising advancement for enabling future mobile networks. To address the computational complexity and communication power consumption associated with conventional centralized optimization, we focus on user-centric dynamic networks in which each user is served by an adaptive subset of access points (AP) rather than all of them. We begin our research by analyzing a joint resource allocation problem for energy-efficient CF XL-MIMO systems, encompassing cooperative clustering and power control design, where all clusters are adaptively adjustable. Then, we propose an innovative double-layer multi-agent reinforcement learning (MARL)-based scheme, which offers an effective strategy to tackle the challenges of high-dimensional signal processing. In the section of numerical results, we compare various algorithms with different network architectures. These comparisons reveal that the proposed MARL-based cooperative architecture can effectively strike a balance between system performance and communication overhead, thereby improving energy efficiency performance. It is important to note that increasing the number of user equipments participating in information sharing can effectively enhance SE performance, which also leads to an increase in power consumption, resulting in a non-trivial trade-off between the number of participants and EE performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05481v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ziheng Liu, Jiayi Zhang, Zhilong Li, Derrick Wing Kwan Ng, Bo Ai</dc:creator>
    </item>
    <item>
      <title>Uplink resource allocation optimization for user-centric cell-free MIMO networks</title>
      <link>https://arxiv.org/abs/2406.05576</link>
      <description>arXiv:2406.05576v1 Announce Type: new 
Abstract: We examine the problem of optimizing resource allocation in the uplink for a user-centric, cell-free, multi-input multi-output network. We start by modeling and developing resource allocation algorithms for two standard network operation modes. The centralized mode provides high data rates but suffers multiple issues, including scalability. On the other hand, the distributed mode has the opposite problem: relatively low rates, but is scalable. To address these challenges, we combine the strength of the two standard modes, creating a new semi-distributed operation mode. To avoid the need for information exchange between access points, we introduce a new quality of service metric to decentralize the resource allocation algorithms. Our results show that we can eliminate the need for information exchange with a relatively small penalty on data rates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05576v1</guid>
      <category>cs.IT</category>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>eess.SY</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TWC.2024.3393869</arxiv:DOI>
      <dc:creator>Zehua Li, Raviraj Adve</dc:creator>
    </item>
    <item>
      <title>Physically-Consistent Modeling and Optimization of Non-local RIS-Assisted Multi-User MIMO Communication Systems</title>
      <link>https://arxiv.org/abs/2406.05617</link>
      <description>arXiv:2406.05617v1 Announce Type: new 
Abstract: Mutual Coupling (MC) emerges as an inherent feature in Reconfigurable Intelligent Surfaces (RISs), particularly, when they are fabricated with sub-wavelength inter-element spacing. Hence, any physically-consistent model of the RIS operation needs to accurately describe MC-induced effects. In addition, the design of the ElectroMagnetic (EM) transmit/receive radiation patterns constitutes another critical factor for efficient RIS operation. The latter two factors lead naturally to the emergence of non-local RIS structures, whose operation can be effectively described via non-diagonal phase shift matrices. In this paper, we focus on jointly optimizing MC and the radiation patterns in multi-user MIMO communication systems assisted by non-local RISs, which are modeled via the scattering parameters. We particularly present a novel problem formulation for the joint optimization of MC, radiation patterns, and the active and passive beamforming in a physically-consistent manner, considering either reflective or transmissive RIS setups. Differently from the current approaches that design the former two parameters on the fly, we present an offline optimization method which is solved for both considered RIS functionalities. Our extensive simulation results, using both parametric and geometric channel models, showcase the validity of the proposed optimization framework over benchmark schemes, indicating that improved performance is achievable without the need for optimizing MC and the radiation patterns of the RIS on the fly, which can be rather cumbersome.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05617v1</guid>
      <category>cs.IT</category>
      <category>cs.ET</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Dilki Wijekoon, Amine Mezghani, George C. Alexandropoulos, Ekram Hossain</dc:creator>
    </item>
    <item>
      <title>Rapid Optimization of Superposition Codes for Multi-Hop NOMA MANETs via Deep Unfolding</title>
      <link>https://arxiv.org/abs/2406.05747</link>
      <description>arXiv:2406.05747v1 Announce Type: new 
Abstract: Various communication technologies are expected to utilize mobile ad hoc networks (MANETs). By combining MANETs with non-orthogonal multiple access (NOMA) communications, one can support scalable, spectrally efficient, and flexible network topologies. To achieve these benefits of NOMA MANETs, one should determine the transmission protocol, particularly the superposition code. However, the latter involves lengthy optimization that has to be repeated when the topology changes. In this work, we propose an algorithm for rapidly optimizing superposition codes in multi-hop NOMA MANETs. To achieve reliable tunning with few iterations, we adopt the emerging deep unfolding methodology, leveraging data to boost reliable settings. Our superposition coding optimization algorithm utilizes a small number of projected gradient steps while learning its per-user hyperparameters to maximize the minimal rate over past channels in an unsupervised manner. The learned optimizer is designed for both settings with full channel state information, as well as when the channel coefficients are to be estimated from pilots. We show that the combination of principled optimization and machine learning yields a scalable optimizer, that once trained, can be applied to different topologies. We cope with the non-convex nature of the optimization problem by applying parallel-learned optimization with different starting points as a form of ensemble learning. Our numerical results demonstrate that the proposed method enables the rapid setting of high-rate superposition codes for various channels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05747v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tomer Alter, Nir Shlezinger</dc:creator>
    </item>
    <item>
      <title>Multi-UAV Trajectory Design for Fair and Secure Communication</title>
      <link>https://arxiv.org/abs/2406.05936</link>
      <description>arXiv:2406.05936v1 Announce Type: new 
Abstract: Unmanned aerial vehicles (UAVs) play an essential role in future wireless communication networks due to their high mobility, low cost, and on-demand deployment. In air-to-ground links, UAVs are widely used to enhance the performance of wireless communication systems due to the presence of high-probability line-of-sight (LoS) links. However, the high probability of LoS links also increases the risk of being eavesdropped, posing a significant challenge to the security of wireless communications. In this work, the secure communication problem in a multi-UAV-assisted communication system is investigated in a moving airborne eavesdropping scenario. To improve the secrecy performance of the considered communication system, aerial eavesdropping capability is suppressed by sending jamming signals from a friendly UAV. An optimization problem under flight conditions, fairness, and limited energy consumption constraints of multiple UAVs is formulated to maximize the fair sum secrecy throughput. Given the complexity and non-convex nature of the problem, we propose a two-step-based optimization approach. The first step employs the $K$-means algorithm to cluster users and associate them with multiple communication UAVs. Then, a multi-agent deep deterministic policy gradient-based algorithm is introduced to solve this optimization problem. The effectiveness of this proposed algorithm is not only theoretically but also rigorously verified by simulation results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05936v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hongjiang Lei, Dongyang Meng, Haoxiang Ran, Ki-Hong Park, Gaofeng Pan, Mohamed-Slim Alouini</dc:creator>
    </item>
    <item>
      <title>Improved bounds on the size of permutation codes under Kendall $\tau$-metric</title>
      <link>https://arxiv.org/abs/2406.06029</link>
      <description>arXiv:2406.06029v1 Announce Type: new 
Abstract: In order to overcome the challenges caused by flash memories and also to protect against errors related to reading information stored in DNA molecules in the shotgun sequencing method, the rank modulation is proposed. In the rank modulation framework, codewords are permutations. In this paper, we study the largest size $P(n, d)$ of permutation codes of length $n$, i.e., subsets of the set $S_n$ of all permutations on $\{1,\ldots, n\}$ with the minimum distance at least $d\in\{1,\ldots ,\binom{n}{2}\}$ under the Kendall $\tau$-metric. By presenting an algorithm and some theorems, we managed to improve the known lower and upper bounds for $P(n,d)$. In particular, we show that $P(n,d)=4$ for all $n\geq 6$ and $\frac{3}{5}\binom{n}{2}&lt; d \leq \frac{2}{3} \binom{n}{2}$. Additionally, we prove that for any prime number $n$ and integer $r\leq \frac{n}{6}$, $ P(n,3)\leq (n-1)!-\dfrac{n-6r}{\sqrt{n^2-8rn+20r^2}}\sqrt{\dfrac{(n-1)!}{n(n-r)!}}. $ This result greatly improves the upper bound of $P(n,3)$ for all primes $n\geq 37$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06029v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Farzad Parvaresh, Reza Sobhani, Alireza Abdollahi, Javad Bagherian, Fatemeh Jafari, Maryam Khatami</dc:creator>
    </item>
    <item>
      <title>6DMA Enhanced Wireless Network with Flexible Antenna Position and Rotation: Opportunities and Challenges</title>
      <link>https://arxiv.org/abs/2406.06064</link>
      <description>arXiv:2406.06064v1 Announce Type: new 
Abstract: 6DMA (six-dimensional movable antenna) is a new and revolutionizing technology that fully exploits the wireless channel spatial variation at the transmitter/receiver by flexibly adjusting the three-dimensional (3D) positions and 3D rotations of distributed antennas/antenna surfaces (arrays). In this article, we provide an overview of 6DMA for unveiling its great potential in wireless networks, including its motivation and competitive advantages over existing technologies, system/channel modeling, and practical implementation. In particular, we present a variety of 6DMA-enabled performance enhancement in terms of array gain, spatial multiplexing, interference suppression, and geometric gain. Furthermore, we illustrate the main applications of 6DMA in wireless communication and sensing, and elaborate their design challenges as well as promising solutions. Finally, numerical results are provided to demonstrate the significant capacity improvement of 6DMA-aided communication in wireless network.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06064v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaodan Shao, Rui Zhang</dc:creator>
    </item>
    <item>
      <title>Federated Machine Reasoning for Resource Provisioning in 6G O-RAN</title>
      <link>https://arxiv.org/abs/2406.06128</link>
      <description>arXiv:2406.06128v1 Announce Type: new 
Abstract: O-RAN specifications reshape RANs with function disaggregation and open interfaces, driven by RAN Intelligent Controllers. This enables data-driven management through AI/ML but poses trust challenges due to human operators' limited understanding of AI/ML decision-making. Balancing resource provisioning and avoiding overprovisioning and underprovisioning is critical, especially among the multiple virtualized base station(vBS) instances. Thus, we propose a novel Federated Machine Reasoning (FLMR) framework, a neurosymbolic method for federated reasoning, learning, and querying. FLMR optimizes CPU demand prediction based on contextual information and vBS configuration using local monitoring data from virtual base stations (vBS) on a shared O-Cloud platform.This optimization is critical, as insufficient computing resources can result in synchronization loss and significantly reduce network throughput. In the telecom domain, particularly in the virtual Radio Access Network (vRAN) sector, predicting and managing the CPU load of vBSs poses a significant challenge for network operators. Our proposed FLMR framework ensures transparency and human understanding in AI/ML decisions and addresses the evolving demands of the 6G O-RAN landscape, where reliability and performance are paramount. Furthermore, we performed a comparative analysis using \textit{DeepCog} as the baseline method. The outcomes highlight how our proposed approach outperforms the baseline and strikes a better balance between resource overprovisioning and underprovisioning. Our method notably lowers both provisioning relative to the baseline by a factor of 6.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06128v1</guid>
      <category>cs.IT</category>
      <category>cs.NI</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Swastika Roy, Hatim Chergui, Adlen Ksentini, Christos Verikoukis</dc:creator>
    </item>
    <item>
      <title>Optimal sensing policy with interference-model uncertainty</title>
      <link>https://arxiv.org/abs/2406.06280</link>
      <description>arXiv:2406.06280v1 Announce Type: new 
Abstract: Assume that an interferer behaves according to a parametric model but one does not know the value of the model parameters. Sensing enables to improve the model knowledge and therefore perform a better link adaptation. However, we consider a half-duplex scenario where, at each time slot, the communication system should decide between sensing and communication. We thus propose to investigate the optimal policy to maximize the expected sum rate given a finite-time communication. % the following question therefore arises: At a given time slot, should one sense or communicate? We first show that this problem can be modelled in the Markov decision process (MDP) framework. We then demonstrate that the optimal open-loop and closed-loop policies can be found significantly faster than the standard backward-induction algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06280v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vincent Corlay, Jean-Christophe Sibel, Nicolas Gresset</dc:creator>
    </item>
    <item>
      <title>An ODMA-Based Unsourced Random Access Scheme with a Multiple Antenna Receiver</title>
      <link>https://arxiv.org/abs/2406.06284</link>
      <description>arXiv:2406.06284v1 Announce Type: new 
Abstract: We investigate the unsourced random access scheme assuming that the base station is equipped with multiple antennas, and propose a high-performing solution utilizing on-off-division multiple access. We assume that each user spreads its pilot sequence and polar codeword to the pilot and data parts of the transmission frame, respectively, based on a transmission pattern. The iterative receiver operation consists of pilot and pattern detection followed by channel vector and symbol estimation, polar decoding, and successive interference cancellation. Numerical findings demonstrate that the proposed scheme has superior performance compared to the state-of-the-art in various antenna settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06284v1</guid>
      <category>cs.IT</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mert Ozates, Mohammad Kazemi, Tolga M. Duman</dc:creator>
    </item>
    <item>
      <title>Memory Complexity of Entropy Estimation</title>
      <link>https://arxiv.org/abs/2406.06312</link>
      <description>arXiv:2406.06312v1 Announce Type: new 
Abstract: We observe an infinite sequence of independent identically distributed random variables $X_1,X_2,\ldots$ drawn from an unknown distribution $p$ over $[n]$, and our goal is to estimate the entropy $H(p)=-\mathbb{E}[\log p(X)]$ within an $\varepsilon$-additive error. To that end, at each time point we are allowed to update a finite-state machine with $S$ states, using a possibly randomized but time-invariant rule, where each state of the machine is assigned an entropy estimate. Our goal is to characterize the minimax memory complexity $S^*$ of this problem, which is the minimal number of states for which the estimation task is feasible with probability at least $1-\delta$ asymptotically, uniformly in $p$. Specifically, we show that there exist universal constants $C_1$ and $C_2$ such that $ S^* \leq C_1\cdot\frac{n (\log n)^4}{\varepsilon^2\delta}$ for $\varepsilon$ not too small, and $S^* \geq C_2 \cdot \max \{n, \frac{\log n}{\varepsilon}\}$ for $\varepsilon$ not too large. The upper bound is proved using approximate counting to estimate the logarithm of $p$, and a finite memory bias estimation machine to estimate the expectation operation. The lower bound is proved via a reduction of entropy estimation to uniformity testing. We also apply these results to derive bounds on the memory complexity of mutual information estimation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06312v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Tomer Berg, Or Ordentlich, Ofer Shayevitz</dc:creator>
    </item>
    <item>
      <title>ARMA Processes with Discrete-Continuous Excitation: Compressibility Beyond Sparsity</title>
      <link>https://arxiv.org/abs/2406.06349</link>
      <description>arXiv:2406.06349v1 Announce Type: new 
Abstract: R\'enyi Information Dimension (RID) plays a central role in quantifying the compressibility of random variables with singularities in their distribution, encompassing and extending beyond the class of sparse sources. The RID, from a high perspective, presents the average number of bits that is needed for coding the i.i.d. samples of a random variable with high precision. There are two main extensions of the RID for stochastic processes: information dimension rate (IDR) and block information dimension (BID). In addition, a more recent approach towards the compressibility of stochastic processes revolves around the concept of $\epsilon$-achievable compression rates, which treat a random process as the limiting point of finite-dimensional random vectors and apply the compressed sensing tools on these random variables. While there is limited knowledge about the interplay of the the BID, the IDR, and $\epsilon$-achievable compression rates, the value of IDR and BID themselves are known only for very specific types of processes, namely i.i.d. sequences (i.e., discrete-domain white noise) and moving-average (MA) processes. This paper investigates the IDR and BID of discrete-time Auto-Regressive Moving-Average (ARMA) processes in general, and their relations with $\epsilon$-achievable compression rates when the excitation noise has a discrete-continuous measure. To elaborate, this paper shows that the RID and $\epsilon$-achievable compression rates of this type of processes are equal to that of their excitation noise. In other words, the samples of such ARMA processes can be compressed as much as their sparse excitation noise, although the samples themselves are by no means sparse. The results of this paper can be used to evaluate the compressibility of various types of locally correlated data with finite- or infinite-memory as they are often modelled via ARMA processes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06349v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammad-Amin Charusaie, Stefano Rini, Arash Amini</dc:creator>
    </item>
    <item>
      <title>Deep Generative Modeling Reshapes Compression and Transmission: From Efficiency to Resiliency</title>
      <link>https://arxiv.org/abs/2406.06446</link>
      <description>arXiv:2406.06446v1 Announce Type: new 
Abstract: Information theory and machine learning are inextricably linked and have even been referred to as "two sides of the same coin". One particularly elegant connection is the essential equivalence between probabilistic generative modeling and data compression or transmission. In this article, we reveal the dual-functionality of deep generative models that reshapes both data compression for efficiency and transmission error concealment for resiliency. We present how the contextual predictive capabilities of powerful generative models can be well positioned to be strong compressors and estimators. In this sense, we advocate for viewing the deep generative modeling problem through the lens of end-to-end communications, and evaluate the compression and error restoration capabilities of foundation generative models. We show that the kernel of many large generative models is powerful predictor that can capture complex relationships among semantic latent variables, and the communication viewpoints provide novel insights into semantic feature tokenization, contextual learning, and usage of deep generative models. In summary, our article highlights the essential connections of generative AI to source and channel coding techniques, and motivates researchers to make further explorations in this emerging topic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06446v1</guid>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>cs.MM</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jincheng Dai, Xiaoqi Qin, Sixian Wang, Lexi Xu, Kai Niu, Ping Zhang</dc:creator>
    </item>
    <item>
      <title>Near-Field Channel Estimation for Extremely Large-Scale Terahertz Communications</title>
      <link>https://arxiv.org/abs/2406.05452</link>
      <description>arXiv:2406.05452v1 Announce Type: cross 
Abstract: Future Terahertz communications exhibit significant potential in accommodating ultra-high-rate services. Employing extremely large-scale array antennas is a key approach to realize this potential, as they can harness substantial beamforming gains to overcome the severe path loss and leverage the electromagnetic advantages in the near field. This paper proposes novel estimation methods designed to enhance efficiency in Terahertz widely-spaced multi-subarray (WSMS) systems. Initially, we introduce three sparse channel representation methods: polar-domain representation (PD-R), multi-angular-domain representation (MAD-R), and two-dimensional polar-angular-domain representation (2D-PAD-R). Each method is meticulously developed for near-field WSMS channels, capitalizing on their sparsity characteristics. Building on this, we propose four estimation frameworks using the sparse recovery theory: polar-domain estimation (PD-E), multi-angular-domain estimation (MAD-E), two-stage polar-angular-domain estimation (TS-PAD-E), and two-dimensional polar-angular-domain estimation (2D-PAD-E). Particularly, 2D-PAD-E, integrating a 2D dictionary process, and TS-PAD-E, with its sequential approach to angle and distance estimation, stand out as particularly effective for near-field angle-distance estimation, enabling decoupled calculation of these parameters. Overall, these frameworks provide versatile and efficient solutions for WSMS channel estimation, balancing low complexity with high-performance outcomes. Additionally, they represent a fresh perspective on near-field signal processing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05452v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Songjie Yang, Yizhou Peng, Wanting Lyu, Ya Li, Hongjun He, Zhongpei Zhang, Chau Yuen</dc:creator>
    </item>
    <item>
      <title>Reliable Quantum Memories with Unreliable Components</title>
      <link>https://arxiv.org/abs/2406.05599</link>
      <description>arXiv:2406.05599v1 Announce Type: cross 
Abstract: Quantum memory systems are vital in quantum information processing for dependable storage and retrieval of quantum states. Inspired by classical reliability theories that synthesize reliable computing systems from unreliable components, we formalize the problem of reliable storage of quantum information using noisy components. We introduce the notion of stable quantum memories and define the storage rate as the ratio of the number of logical qubits to the total number of physical qubits, as well as the circuit complexity of the decoder, which includes both quantum gates and measurements. We demonstrate that a strictly positive storage rate can be achieved by constructing a quantum memory system with quantum expander codes. Moreover, by reducing the reliable storage problem to reliable quantum communication, we provide upper bounds on the achievable storage capacity. In the case of physical qubits corrupted by noise satisfying hypercontractivity conditions, we provide a tighter upper bound on storage capacity using an entropy dissipation argument. Furthermore, observing that the time complexity of the decoder scales non-trivially with the number of physical qubits, achieving asymptotic rates may not be possible due to the induced dependence of the noise on the number of physical qubits. In this constrained non-asymptotic setting, we derive upper bounds on storage capacity using finite blocklength communication bounds. Finally, we numerically analyze the gap between upper and lower bounds in both asymptotic and non-asymptotic cases, and provide suggestions to tighten the gap.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05599v1</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anuj K. Nayak, Eric Chitambar, Lav R. Varshney</dc:creator>
    </item>
    <item>
      <title>Movable Antenna Assisted OAM Wireless Communications With Misaligned Transceiver</title>
      <link>https://arxiv.org/abs/2406.05663</link>
      <description>arXiv:2406.05663v1 Announce Type: cross 
Abstract: The vortex electromagnetic wave carried by multiple orthogonal orbital angular momentum (OAM) modes in the same frequency band can be applied to the field of wireless communications, which greatly increases the spectrum efficiency. The uniform circular array (UCA) is the classical structure to generate and receive vortex electromagnetic waves with multiple OAM-modes. However, when the transmit and receive UCAs are misaligned, there will be interference among the OAM-modes and the signal cannot be recovered at the receiver. In order to solve this problem, we propose movable antenna (MA) assisted OAM wireless communications scheme. We estimate the rotation angle between transmit and receive UCAs and feed it back to the transmitter. Then, the MA at the transmitter adjusts the rotation angle to achieve alignment of the UCA at both the receiver and transmitter. Simulation results show that our scheme can significantly improve the spectrum efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05663v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongyun Jin, Wenchi Cheng, Haiyue Jing, Jingqing Wang</dc:creator>
    </item>
    <item>
      <title>Achieving High Capacity Transmission With N-Dimensional Quasi-Fractal UCA</title>
      <link>https://arxiv.org/abs/2406.05667</link>
      <description>arXiv:2406.05667v1 Announce Type: cross 
Abstract: The vortex electromagnetic wave carried by multiple orthogonal orbital angular momentum (OAM) modes in the same frequency band can be applied to the field of wireless communications, which greatly increases the spectrum efficiency. The uniform circular array (UCA) is widely used to generate and receive vortex electromagnetic waves with multiple OAM-modes. However, the maximum number of orthogonal OAM-modes based on UCA is usually limited to the number of array-elements of the UCA antenna, leaving how to utilize more OAM-modes to achieve higher channel capacity with a fixed number of arrayelements as an intriguing question. In this paper, we propose an N-dimensional quasi-fractal UCA (ND QF-UCA) antenna structure in different fractal geometry layouts to break through the limits of array-elements number on OAM-modes number. We develop the N-dimensional OAM modulation (NOM) and demodulation (NOD) schemes for OAM multiplexing transmission with the OAM-modes number exceeding the array-elements number, which is beyond the traditional concept of multiple antenna based wireless communications. Then, we investigate different dimensional multiplexing transmission schemes based on the corresponding QF-UCA antenna structure with various array-element layouts and evaluate the optimal layout type and dimension to obtain the highest channel capacity with a fixed number of array-elements. Simulation results show that our proposed schemes can obtain a higher spectrum efficiency, surpassing those of alternative array-element layouts of QF-UCA and the traditional multiple antenna systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05667v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongyun Jin, Wenchi Cheng, Haiyue Jing, Jingqing Wang, Wei Zhang</dc:creator>
    </item>
    <item>
      <title>Near or far: On determining the appropriate channel estimation strategy in cross-field communication</title>
      <link>https://arxiv.org/abs/2406.05716</link>
      <description>arXiv:2406.05716v1 Announce Type: cross 
Abstract: The use of ultra-massive multiple-input multiple-output and high-frequency large bandwidth systems is likely in the next-generation wireless communication systems. In such systems, the user moves between near- and far-field regions, and consequently, the channel estimation will need to be carried out in the cross-field scenario. Channel estimation strategies have been proposed for both near- and far-fields, but in the cross-field problem, the first step is to determine whether the near- or far-field is applicable so that an appropriate channel estimation strategy can be employed. In this work, we propose using a hidden Markov model over an ensemble of region estimates to enhance the accuracy of selecting the actual region. The region indicators are calculated using the pair-wise power differences between received signals across the subarrays within an array-of-subarrays architecture. Numerical results show that the proposed method achieves a high success rate in determining the appropriate channel estimation strategy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05716v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Simon Tarboush, Anum Ali, Tareq Y. Al-Naffouri</dc:creator>
    </item>
    <item>
      <title>Information Theoretic Guarantees For Policy Alignment In Large Language Models</title>
      <link>https://arxiv.org/abs/2406.05883</link>
      <description>arXiv:2406.05883v1 Announce Type: cross 
Abstract: Policy alignment of large language models refers to constrained policy optimization, where the policy is optimized to maximize a reward while staying close to a reference policy with respect to an $f$-divergence such as the $\mathsf{KL}$ divergence. The best of $n$ alignment policy selects a sample from the reference policy that has the maximum reward among $n$ independent samples. For both cases (policy alignment and best of $n$), recent works showed empirically that the reward improvement of the aligned policy on the reference one scales like $\sqrt{\mathsf{KL}}$, with an explicit bound in $n$ on the $\mathsf{KL}$ for the best of $n$ policy. We show in this paper that the $\sqrt{\mathsf{KL}}$ information theoretic upper bound holds if the reward under the reference policy has sub-gaussian tails. Moreover, we prove for the best of $n$ policy, that the $\mathsf{KL}$ upper bound can be obtained for any $f$-divergence via a reduction to exponential order statistics owing to the R\'enyi representation of order statistics, and a data processing inequality. If additional information is known on the tails of the aligned policy we show that tighter control on the reward improvement can be obtained via the R\'enyi divergence. Finally we demonstrate how these upper bounds transfer from proxy rewards to golden rewards which results in a decrease in the golden reward improvement due to overestimation and approximation errors of the proxy reward.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05883v1</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Youssef Mroueh</dc:creator>
    </item>
    <item>
      <title>Zak-OTFS and Turbo Signal Processing for Joint Sensing and Communication</title>
      <link>https://arxiv.org/abs/2406.06024</link>
      <description>arXiv:2406.06024v1 Announce Type: cross 
Abstract: The Zak-OTFS input/output (I/O) relation is predictable and non-fading when the delay and Doppler periods are greater than the effective channel delay and Doppler spreads, a condition which we refer to as the crystallization condition. The filter taps can simply be read off from the response to a single Zak-OTFS pilot pulsone, and the I/O relation can be reconstructed for a sampled system that operates under finite duration and bandwidth constraints. In previous work we had measured BER performance of a baseline system where we used separate Zak-OTFS subframes for sensing and data transmission. In this Letter we demonstrate how to use turbo signal processing to match BER performance of this baseline system when we integrate sensing and communication within the same Zak-OTFS subframe. The turbo decoder alternates between channel sensing using a noise-like waveform (spread pulsone) and recovery of data transmitted using point pulsones.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06024v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jinu Jayachandran, Muhammad Ubadah, Saif Khan Mohammed, Ronny Hadani, Ananthanarayanan Chockalingam, Robert Calderbank</dc:creator>
    </item>
    <item>
      <title>The Evolution of Applications, Hardware Design, and Channel Modeling for Terahertz (THz) Band Communications and Sensing: Ready for 6G?</title>
      <link>https://arxiv.org/abs/2406.06105</link>
      <description>arXiv:2406.06105v1 Announce Type: cross 
Abstract: For decades, the terahertz (THz) frequency band had been primarily explored in the context of radar, imaging, and spectroscopy, where multi-gigahertz (GHz) and even THz-wide channels and the properties of terahertz photons offered attractive target accuracy, resolution, and classification capabilities. Meanwhile, the exploitation of the terahertz band for wireless communication had originally been limited due to several reasons, including (i) no immediate need for such high data rates available via terahertz bands and (ii) challenges in designing sufficiently high power terahertz systems at reasonable cost and efficiency, leading to what was often referred to as "the terahertz gap". This roadmap paper first reviews the evolution of the hardware design approaches for terahertz systems, including electronic, photonic, and plasmonic approaches, and the understanding of the terahertz channel itself, in diverse scenarios, ranging from common indoors and outdoors scenarios to intra-body and outer-space environments. The article then summarizes the lessons learned during this multi-decade process and the cutting-edge state-of-the-art findings, including novel methods to quantify power efficiency, which will become more important in making design choices. Finally, the manuscript presents the authors' perspective and insights on how the evolution of terahertz systems design will continue toward enabling efficient terahertz communications and sensing solutions as an integral part of next-generation wireless systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06105v1</guid>
      <category>cs.NI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Josep M. Jornet, Vitaly Petrov, Hua Wang, Zoya Popovic, Dipankar Shakya, Jose V. Siles, Theodore S. Rappaport</dc:creator>
    </item>
    <item>
      <title>Generalized Nested Latent Variable Models for Lossy Coding applied to Wind Turbine Scenarios</title>
      <link>https://arxiv.org/abs/2406.06165</link>
      <description>arXiv:2406.06165v1 Announce Type: cross 
Abstract: Rate-distortion optimization through neural networks has accomplished competitive results in compression efficiency and image quality. This learning-based approach seeks to minimize the compromise between compression rate and reconstructed image quality by automatically extracting and retaining crucial information, while discarding less critical details. A successful technique consists in introducing a deep hyperprior that operates within a 2-level nested latent variable model, enhancing compression by capturing complex data dependencies. This paper extends this concept by designing a generalized L-level nested generative model with a Markov chain structure. We demonstrate as L increases that a trainable prior is detrimental and explore a common dimensionality along the distinct latent variables to boost compression performance. As this structured framework can represent autoregressive coders, we outperform the hyperprior model and achieve state-of-the-art performance while reducing substantially the computational cost. Our experimental evaluation is performed on wind turbine scenarios to study its application on visual inspections</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06165v1</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ra\"ul P\'erez-Gonzalo, Andreas Espersen, Antonio Agudo</dc:creator>
    </item>
    <item>
      <title>2D Moore CA with new boundary conditions and its reversibility</title>
      <link>https://arxiv.org/abs/2406.06195</link>
      <description>arXiv:2406.06195v1 Announce Type: cross 
Abstract: In this paper, under certain conditions we consider two-dimensional cellular automata with the Moore neighborhood. Namely, the characterization of 2D linear cellular automata defined by the Moore neighborhood with some mixed boundary conditions over the field $\mathbb{Z}_{p}$ is studied. Furthermore, we investigate the rule matrices of 2D Moore CA under some mixed boundary conditions by applying rotation. Finally, we give the conditions under which the obtained rule matrices for 2D finite CAs are reversible.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06195v1</guid>
      <category>math.DS</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>B. A. Omirov, Sh. B. Redjepov, J. B. Usmonov</dc:creator>
    </item>
    <item>
      <title>Unified Fourier bases for GSP on stochastic block model graphs</title>
      <link>https://arxiv.org/abs/2406.06306</link>
      <description>arXiv:2406.06306v1 Announce Type: cross 
Abstract: We consider a recently proposed approach to graph signal processing based on graphons. We show how the graphon-based approach to GSP applies to graphs sampled from a stochastic block model. We obtain a basis for the graphon Fourier transform on such samples directly from the link probability matrix and the block sizes of the model. This formulation allows us to bound the sensitivity of the Fourier transform to small changes in block sizes. We then focus on the case where the probability matrix corresponds to a (weighted) Cayley graph. If block sizes are equal, a nice Fourier basis can be derived from the underlying group. We explore how, in the case where block sizes are not equal, some or all nice properties of the group basis can be maintained. We complement the theoretical results with simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06306v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mahya Ghandehari, Jeannette Janssen, Silo Murphy</dc:creator>
    </item>
    <item>
      <title>On the Physical Layer Security of Visible Light Communications Empowered by Gold Nanoparticles</title>
      <link>https://arxiv.org/abs/2208.06132</link>
      <description>arXiv:2208.06132v3 Announce Type: replace 
Abstract: Visible light is a proper spectrum for secure wireless communications because of its high directivity and impermeability in indoor scenarios. However, if an eavesdropper is located very close to a legitimate receiver, secure communications become highly risky. In this paper, to further increase the level of security of visible light communication (VLC) and increase its resilience against to malicious attacks, we propose to capitalize on the recently synthesized gold nanoparticles (GNPs) with chiroptical properties for circularly polarized light resulting the phase retardation that interacts with the linear polarizer angle. GNP plates made by judiciously stacking many GNPs perform as physical secret keys. Transmitters send both the intended symbol and artificial noise to exploit the channel variation effect by the GNP plates, which is highly effective when an eavesdropper is closely located to the legitimate receiver. A new VLC channel model is first developed by representing the effect of GNP plates and linear polarizers in the circular polarization domain. Based on the new channel model, the angles of linear polarizers at the transmitters and legitimate receiver are optimized considering the effect of GNP plates to increase the secrecy rate in wiretapping scenarios. Simulations verify that when the transmitters are equipped with GNP plates, even if the eavesdropper is located right next to the legitimate receiver, insightful results on the physical layer security metrics are gained as follows: 1) the secrecy rate is significantly improved and 2) the symbol error rate gap between the legitimate receiver and eavesdropper becomes much larger due to the chiroptical properties of GNP plates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.06132v3</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Geonho Han, Hyuckjin Choi, Ryeong Myeong Kim, Ki Tae Nam, Junil Choi, Theodoros A. Tsiftsis</dc:creator>
    </item>
    <item>
      <title>Moments of Autocorrelation Demerit Factors of Binary Sequences</title>
      <link>https://arxiv.org/abs/2307.14281</link>
      <description>arXiv:2307.14281v3 Announce Type: replace 
Abstract: Sequences with low aperiodic autocorrelation are used in communications and remote sensing for synchronization and ranging. The autocorrelation demerit factor of a sequence is the sum of the squared magnitudes of its autocorrelation values at every nonzero shift when we normalize the sequence to have unit Euclidean length. The merit factor, introduced by Golay, is the reciprocal of the demerit factor. We consider the uniform probability measure on the $2^\ell$ binary sequences of length $\ell$ and investigate the distribution of the demerit factors of these sequences. Sarwate and Jedwab have respectively calculated the mean and variance of this distribution. We develop new combinatorial techniques to calculate the $p$th central moment of the demerit factor for binary sequences of length $\ell$. These techniques prove that for $p\geq 2$ and $\ell \geq 4$, all the central moments are strictly positive. For any given $p$, one may use the technique to obtain an exact formula for the $p$th central moment of the demerit factor as a function of the length $\ell$. Jedwab's formula for variance is confirmed by our technique with a short calculation, and we go beyond previous results by also deriving an exact formula for the skewness. A computer-assisted application of our method also obtains exact formulas for the kurtosis, which we report here, as well as the fifth central moment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.14281v3</guid>
      <category>cs.IT</category>
      <category>cs.DM</category>
      <category>eess.SP</category>
      <category>math.CO</category>
      <category>math.IT</category>
      <category>math.PR</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniel J. Katz, Miriam E. Ramirez</dc:creator>
    </item>
    <item>
      <title>Diffusion Models for Accurate Channel Distribution Generation</title>
      <link>https://arxiv.org/abs/2309.10505</link>
      <description>arXiv:2309.10505v3 Announce Type: replace 
Abstract: Strong generative models can accurately learn channel distributions. This could save recurring costs for physical measurements of the channel. Moreover, the resulting differentiable channel model supports training neural encoders by enabling gradient-based optimization. The initial approach in the literature draws upon the modern advancements in image generation, utilizing generative adversarial networks (GANs) or their enhanced variants to generate channel distributions. In this paper, we address this channel approximation challenge with diffusion models (DMs), which have demonstrated high sample quality and mode coverage in image generation. In addition to testing the generative performance of the channel distributions, we use an end-to-end (E2E) coded-modulation framework underpinned by DMs and propose an efficient training algorithm. Our simulations with various channel models show that a DM can accurately learn channel distributions, enabling an E2E framework to achieve near-optimal symbol error rates (SERs). Furthermore, we examine the trade-off between mode coverage and sampling speed through skipped sampling using sliced Wasserstein distance (SWD) and the E2E SER. We investigate the effect of noise scheduling on this trade-off, demonstrating that with an appropriate choice of parameters and techniques, sampling time can be significantly reduced with a minor increase in SWD and SER. Finally, we show that the DM can generate a correlated fading channel, whereas a strong GAN variant fails to learn the covariance. This paper highlights the potential benefits of using DMs for learning channel distributions, which could be further investigated for various channels and advanced techniques of DMs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.10505v3</guid>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Muah Kim, Rick Fritschek, Rafael F. Schaefer</dc:creator>
    </item>
    <item>
      <title>New optimal trade-off point for coded caching systems with limited cache size</title>
      <link>https://arxiv.org/abs/2310.07686</link>
      <description>arXiv:2310.07686v2 Announce Type: replace 
Abstract: This paper presents a new achievable scheme for coded caching systems with $\mathsf{N}$ files, $\mathsf{K}=\mathsf{N}$ users, and cache size $\mathsf{M}=1/(\mathsf{N}-1)$. The scheme employs linear coding during the cache placement phase, and a three-stage transmissions designed to eliminate interference in the delivery phase. The achievable load meets a known converse bound, which impose no constraint on the cache placement, and is thus optimal. This new result, together with known inner and outer bounds, shows optimality of linear coding placement for $\mathsf{M} \leq 1/(\mathsf{N}-1)$ when $\mathsf{K}=\mathsf{N}\geq 3$. Interestingly and surprisingly, the proposed scheme is relatively simple but requires operations on a finite field of size at least 3.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.07686v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yinbin Ma, Daniela Tuninetti</dc:creator>
    </item>
    <item>
      <title>A Fractal-based Complex Belief Entropy for Uncertainty Measure in Complex Evidence Theory</title>
      <link>https://arxiv.org/abs/2312.16080</link>
      <description>arXiv:2312.16080v2 Announce Type: replace 
Abstract: Complex Evidence Theory (CET), an extension of the traditional D-S evidence theory, has garnered academic interest for its capacity to articulate uncertainty through Complex Basic Belief Assignment (CBBA) and to perform uncertainty reasoning using complex combination rules. Nonetheless, quantifying uncertainty within CET remains a subject of ongoing research. To enhance decision-making, a method for Complex Pignistic Belief Transformation (CPBT) has been introduced, which allocates CBBAs of multi-element focal elements to subsets. CPBT's core lies in the fractal-inspired redistribution of the complex mass function. This paper presents an experimental simulation and analysis of CPBT's generation process along the temporal dimension, rooted in fractal theory. Subsequently, a novel Fractal-Based Complex Belief (FCB) entropy is proposed to gauge the uncertainty of CBBA. The properties of FCB entropy are examined, and its efficacy is demonstrated through various numerical examples and practical application.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.16080v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Keming Wu, Fuyuan Xiao, Yi Zhang</dc:creator>
    </item>
    <item>
      <title>Energy-Efficient STAR-RIS Enhanced UAV-Enabled MEC Networks with Bi-Directional Task Offloading</title>
      <link>https://arxiv.org/abs/2401.05725</link>
      <description>arXiv:2401.05725v2 Announce Type: replace 
Abstract: This paper introduces a novel multi-user mobile edge computing (MEC) scheme facilitated by the simultaneously transmitting and reflecting reconfigurable intelligent surface (STAR-RIS) and the unmanned aerial vehicle (UAV). Unlike existing MEC approaches, the proposed scheme enables bidirectional offloading, allowing users to concurrently offload tasks to the MEC servers located at the ground base station (BS) and UAV with STAR-RIS support. Specifically, we formulate an optimization problem aiming at maximizing the energy efficiency of the system while ensuring the quality of service (QoS) constraints by jointly optimizing the resource allocation, user scheduling, passive beamforming of the STAR-RIS, and the UAV trajectory. A block coordinate descent (BCD) iterative algorithm designed with the Dinkelbach's algorithm and the successive convex approximation (SCA) technique is proposed to effectively handle the formulated non-convex optimization problem with significant coupling among variables. Simulation results indicate that the proposed STAR-RIS enhanced UAV-enabled MEC scheme possesses significant advantages in enhancing the system energy efficiency over other baseline schemes including the conventional RIS-aided scheme.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.05725v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Han Xiao, Xiaoyan Hu, Weile Zhang, Wenjie Wang, Kai-Kit Wong, Kun Yang</dc:creator>
    </item>
    <item>
      <title>A Novel Scheme for Coded Caching with Coded Placement in Small Memory Regime</title>
      <link>https://arxiv.org/abs/2404.17767</link>
      <description>arXiv:2404.17767v2 Announce Type: replace 
Abstract: This paper presents a novel achievable scheme for coded caching systems with $N$ files and $K$ users, specifically when $N \leq K$. This new scheme employs linear coding both during the placement phase - where cache contents are linear combinations of files from the library - and the delivery phase. The multi-step delivery phase enables users to decode the cached coded content and eliminate interference effectively. In the small memory regime, the proposed scheme outperforms existing methods, particularly when $K$ and $N$ values are similar, it maintains manageable sub-packetization levels, and operates over a finite field of size $3$ regardless of the system parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17767v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yinbin Ma, Daniela Tuninetti</dc:creator>
    </item>
    <item>
      <title>A transversality theorem for semi-algebraic sets with application to signal recovery from the second moment and cryo-EM</title>
      <link>https://arxiv.org/abs/2405.04354</link>
      <description>arXiv:2405.04354v2 Announce Type: replace 
Abstract: Semi-algebraic priors are ubiquitous in signal processing and machine learning. Prevalent examples include a) linear models where the signal lies in a low-dimensional subspace; b) sparse models where the signal can be represented by only a few coefficients under a suitable basis; and c) a large family of neural network generative models. In this paper, we prove a transversality theorem for semi-algebraic sets in orthogonal or unitary representations of groups: with a suitable dimension bound, a generic translate of any semi-algebraic set is transverse to the orbits of the group action. This, in turn, implies that if a signal lies in a low-dimensional semi-algebraic set, then it can be recovered uniquely from measurements that separate orbits.
  As an application, we consider the implications of the transversality theorem to the problem of recovering signals that are translated by random group actions from their second moment. As a special case, we discuss cryo-EM: a leading technology to constitute the spatial structure of biological molecules, which serves as our prime motivation. In particular, we derive explicit bounds for recovering a molecular structure from the second moment under a semi-algebraic prior and deduce information-theoretic implications. We also obtain information-theoretic bounds for three additional applications: factoring Gram matrices, multi-reference alignment, and phase retrieval. Finally, we deduce bounds for designing permutation invariant separators in machine learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04354v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.AG</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tamir Bendory, Nadav Dym, Dan Edidin, Arun Suresh</dc:creator>
    </item>
    <item>
      <title>Artificial General Intelligence (AGI) for the oil and gas industry: a review</title>
      <link>https://arxiv.org/abs/2406.00594</link>
      <description>arXiv:2406.00594v2 Announce Type: replace 
Abstract: Artificial General Intelligence (AGI) is set to profoundly impact the oil and gas industry by introducing unprecedented efficiencies and innovations. This paper explores AGI's foundational principles and its transformative applications, particularly focusing on the advancements brought about by large language models (LLMs) and extensive computer vision systems in the upstream sectors of the industry. The integration of Artificial Intelligence (AI) has already begun reshaping the oil and gas landscape, offering enhancements in production optimization, downtime reduction, safety improvements, and advancements in exploration and drilling techniques. These technologies streamline logistics, minimize maintenance costs, automate monotonous tasks, refine decision-making processes, foster team collaboration, and amplify profitability through error reduction and actionable insights extraction. Despite these advancements, the deployment of AI technologies faces challenges, including the necessity for skilled professionals for implementation and the limitations of model training on constrained datasets, which affects the models' adaptability across different contexts. The advent of generative AI, exemplified by innovations like ChatGPT and the Segment Anything Model (SAM), heralds a new era of high-density innovation. These developments highlight a shift towards natural language interfaces and domain-knowledge-driven AI, promising more accessible and tailored solutions for the oil and gas industry. This review articulates the vast potential AGI holds for tackling complex operational challenges within the upstream oil and gas industry, requiring near-human levels of intelligence. We discussed the promising applications, the hurdles of large-scale AGI model deployment, and the necessity for domain-specific knowledge in maximizing the benefits of these technologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00594v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jimmy Xuekai Li, Tiancheng Zhang, Yiran Zhu, Zhongwei Chen</dc:creator>
    </item>
    <item>
      <title>Two Facets of SDE Under an Information-Theoretic Lens: Generalization of SGD via Training Trajectories and via Terminal States</title>
      <link>https://arxiv.org/abs/2211.10691</link>
      <description>arXiv:2211.10691v2 Announce Type: replace-cross 
Abstract: Stochastic differential equations (SDEs) have been shown recently to characterize well the dynamics of training machine learning models with SGD. When the generalization error of the SDE approximation closely aligns with that of SGD in expectation, it provides two opportunities for understanding better the generalization behaviour of SGD through its SDE approximation. Firstly, viewing SGD as full-batch gradient descent with Gaussian gradient noise allows us to obtain trajectory-based generalization bound using the information-theoretic bound from Xu and Raginsky [2017]. Secondly, assuming mild conditions, we estimate the steady-state weight distribution of SDE and use information-theoretic bounds from Xu and Raginsky [2017] and Negrea et al. [2019] to establish terminal-state-based generalization bounds. Our proposed bounds have some advantages, notably the trajectory-based bound outperforms results in Wang and Mao [2022], and the terminal-state-based bound exhibits a fast decay rate comparable to stability-based bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.10691v2</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ziqiao Wang, Yongyi Mao</dc:creator>
    </item>
    <item>
      <title>Lessons from Generalization Error Analysis of Federated Learning: You May Communicate Less Often!</title>
      <link>https://arxiv.org/abs/2306.05862</link>
      <description>arXiv:2306.05862v2 Announce Type: replace-cross 
Abstract: We investigate the generalization error of statistical learning models in a Federated Learning (FL) setting. Specifically, we study the evolution of the generalization error with the number of communication rounds $R$ between $K$ clients and a parameter server (PS), i.e., the effect on the generalization error of how often the clients' local models are aggregated at PS. In our setup, the more the clients communicate with PS the less data they use for local training in each round, such that the amount of training data per client is identical for distinct values of $R$. We establish PAC-Bayes and rate-distortion theoretic bounds on the generalization error that account explicitly for the effect of the number of rounds $R$, in addition to the number of participating devices $K$ and individual datasets size $n$. The bounds, which apply to a large class of loss functions and learning algorithms, appear to be the first of their kind for the FL setting. Furthermore, we apply our bounds to FL-type Support Vector Machines (FSVM); and derive (more) explicit bounds in this case. In particular, we show that the generalization bound of FSVM increases with $R$, suggesting that more frequent communication with PS diminishes the generalization power. This implies that the population risk decreases less fast with $R$ than does the empirical risk. Moreover, our bound suggests that the generalization error of FSVM decreases faster than that of centralized learning by a factor of $\mathcal{O}(\sqrt{\log(K)/K})$. Finally, we provide experimental results obtained using neural networks (ResNet-56) which show evidence that not only may our observations for FSVM hold more generally but also that the population risk may even start to increase beyond some value of $R$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.05862v2</guid>
      <category>stat.ML</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Milad Sefidgaran, Romain Chor, Abdellatif Zaidi, Yijun Wan</dc:creator>
    </item>
    <item>
      <title>Analog information decoding of bosonic quantum LDPC codes</title>
      <link>https://arxiv.org/abs/2311.01328</link>
      <description>arXiv:2311.01328v2 Announce Type: replace-cross 
Abstract: Quantum error correction is crucial for scalable quantum information processing applications. Traditional discrete-variable quantum codes that use multiple two-level systems to encode logical information can be hardware-intensive. An alternative approach is provided by bosonic codes, which use the infinite-dimensional Hilbert space of harmonic oscillators to encode quantum information. Two promising features of bosonic codes are that syndrome measurements are natively analog and that they can be concatenated with discrete-variable codes. In this work, we propose novel decoding methods that explicitly exploit the analog syndrome information obtained from the bosonic qubit readout in a concatenated architecture. Our methods are versatile and can be generally applied to any bosonic code concatenated with a quantum low-density parity-check (QLDPC) code. Furthermore, we introduce the concept of quasi-single-shot protocols as a novel approach that significantly reduces the number of repeated syndrome measurements required when decoding under phenomenological noise. To realize the protocol, we present a first implementation of time-domain decoding with the overlapping window method for general QLDPC codes, and a novel analog single-shot decoding method. Our results lay the foundation for general decoding algorithms using analog information and demonstrate promising results in the direction of fault-tolerant quantum computation with concatenated bosonic-QLDPC codes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.01328v2</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1103/PRXQuantum.5.020349</arxiv:DOI>
      <arxiv:journal_reference>PRX Quantum 5, 020349 (2024)</arxiv:journal_reference>
      <dc:creator>Lucas Berent, Timo Hillmann, Jens Eisert, Robert Wille, Joschka Roffe</dc:creator>
    </item>
    <item>
      <title>Improved Sample Complexity Bounds for Diffusion Model Training</title>
      <link>https://arxiv.org/abs/2311.13745</link>
      <description>arXiv:2311.13745v2 Announce Type: replace-cross 
Abstract: Diffusion models have become the most popular approach to deep generative modeling of images, largely due to their empirical performance and reliability. From a theoretical standpoint, a number of recent works~\cite{chen2022,chen2022improved,benton2023linear} have studied the iteration complexity of sampling, assuming access to an accurate diffusion model. In this work, we focus on understanding the \emph{sample complexity} of training such a model; how many samples are needed to learn an accurate diffusion model using a sufficiently expressive neural network? Prior work~\cite{BMR20} showed bounds polynomial in the dimension, desired Total Variation error, and Wasserstein error. We show an \emph{exponential improvement} in the dependence on Wasserstein error and depth, along with improved dependencies on other relevant parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.13745v2</guid>
      <category>cs.LG</category>
      <category>cs.CV</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shivam Gupta, Aditya Parulekar, Eric Price, Zhiyang Xun</dc:creator>
    </item>
    <item>
      <title>Cuff-less Arterial Blood Pressure Waveform Synthesis from Single-site PPG using Transformer &amp; Frequency-domain Learning</title>
      <link>https://arxiv.org/abs/2401.05452</link>
      <description>arXiv:2401.05452v2 Announce Type: replace-cross 
Abstract: We develop and evaluate two novel purpose-built deep learning (DL) models for synthesis of the arterial blood pressure (ABP) waveform in a cuff-less manner, using a single-site photoplethysmography (PPG) signal. We train and evaluate our DL models on the data of 209 subjects from the public UCI dataset on cuff-less blood pressure (CLBP) estimation. Our transformer model consists of an encoder-decoder pair that incorporates positional encoding, multi-head attention, layer normalization, and dropout techniques for ABP waveform synthesis. Secondly, under our frequency-domain (FD) learning approach, we first obtain the discrete cosine transform (DCT) coefficients of the PPG and ABP signals, and then learn a linear/non-linear (L/NL) regression between them. The transformer model (FD L/NL model) synthesizes the ABP waveform with a mean absolute error (MAE) of 3.01 (4.23). Further, the synthesis of ABP waveform also allows us to estimate the systolic blood pressure (SBP) and diastolic blood pressure (DBP) values. To this end, the transformer model reports an MAE of 3.77 mmHg and 2.69 mmHg, for SBP and DBP, respectively. On the other hand, the FD L/NL method reports an MAE of 4.37 mmHg and 3.91 mmHg, for SBP and DBP, respectively. Both methods fulfill the AAMI criterion. As for the BHS criterion, our transformer model (FD L/NL regression model) achieves grade A (grade B).</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.05452v2</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Muhammad Wasim Nawaz, Muhammad Ahmad Tahir, Ahsan Mehmood, Muhammad Mahboob Ur Rahman, Kashif Riaz, Qammer H. Abbasi</dc:creator>
    </item>
    <item>
      <title>Channel Estimation and Beamforming for Beyond Diagonal Reconfigurable Intelligent Surfaces</title>
      <link>https://arxiv.org/abs/2403.18087</link>
      <description>arXiv:2403.18087v2 Announce Type: replace-cross 
Abstract: Beyond diagonal reconfigurable intelligent surface (BD-RIS) is a new advance and generalization of the RIS technique. BD-RIS breaks through the isolation between RIS elements by creatively introducing inter-element connections, thereby enabling smarter wave manipulation and enlarging coverage. However, exploring proper channel estimation schemes suitable for BD-RIS aided communication systems still remains an open problem. In this paper, we study channel estimation and beamforming design for BD-RIS aided multi-antenna systems. We first describe the channel estimation strategy based on the least square (LS) method, derive the mean square error (MSE) of the LS estimation, and formulate the joint pilot sequence and BD-RIS design problem with unique constraints induced by BD-RIS architectures. Specifically, we propose an efficient pilot sequence and BD-RIS design which theoretically guarantees to achieve the minimum MSE. With the estimated channel, we then consider two BD-RIS scenarios and propose beamforming design algorithms. Finally, we provide simulation results to verify the effectiveness of the proposed channel estimation scheme and beamforming design algorithms. We also show that more interelement connections in BD-RIS improves the performance while increasing the training overhead for channel estimation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.18087v2</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hongyu Li, Shanpu Shen, Yumeng Zhang, Bruno Clerckx</dc:creator>
    </item>
    <item>
      <title>Localized Adaptive Risk Control</title>
      <link>https://arxiv.org/abs/2405.07976</link>
      <description>arXiv:2405.07976v2 Announce Type: replace-cross 
Abstract: Adaptive Risk Control (ARC) is an online calibration strategy based on set prediction that offers worst-case deterministic long-term risk control, as well as statistical marginal coverage guarantees. ARC adjusts the size of the prediction set by varying a single scalar threshold based on feedback from past decisions. In this work, we introduce Localized Adaptive Risk Control (L-ARC), an online calibration scheme that targets statistical localized risk guarantees ranging from conditional risk to marginal risk, while preserving the worst-case performance of ARC. L-ARC updates a threshold function within a reproducing kernel Hilbert space (RKHS), with the kernel determining the level of localization of the statistical risk guarantee. The theoretical results highlight a trade-off between localization of the statistical risk and convergence speed to the long-term risk target. Thanks to localization, L-ARC is demonstrated via experiments to produce prediction sets with risk guarantees across different data subpopulations, significantly improving the fairness of the calibrated model for tasks such as image segmentation and beam selection in wireless networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07976v2</guid>
      <category>stat.ML</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Matteo Zecchin, Osvaldo Simeone</dc:creator>
    </item>
    <item>
      <title>Physics-informed deep learning and compressive collocation for high-dimensional diffusion-reaction equations: practical existence theory and numerics</title>
      <link>https://arxiv.org/abs/2406.01539</link>
      <description>arXiv:2406.01539v2 Announce Type: replace-cross 
Abstract: On the forefront of scientific computing, Deep Learning (DL), i.e., machine learning with Deep Neural Networks (DNNs), has emerged a powerful new tool for solving Partial Differential Equations (PDEs). It has been observed that DNNs are particularly well suited to weakening the effect of the curse of dimensionality, a term coined by Richard E. Bellman in the late `50s to describe challenges such as the exponential dependence of the sample complexity, i.e., the number of samples required to solve an approximation problem, on the dimension of the ambient space. However, although DNNs have been used to solve PDEs since the `90s, the literature underpinning their mathematical efficiency in terms of numerical analysis (i.e., stability, accuracy, and sample complexity), is only recently beginning to emerge. In this paper, we leverage recent advancements in function approximation using sparsity-based techniques and random sampling to develop and analyze an efficient high-dimensional PDE solver based on DL. We show, both theoretically and numerically, that it can compete with a novel stable and accurate compressive spectral collocation method. In particular, we demonstrate a new practical existence theorem, which establishes the existence of a class of trainable DNNs with suitable bounds on the network architecture and a sufficient condition on the sample complexity, with logarithmic or, at worst, linear scaling in dimension, such that the resulting networks stably and accurately approximate a diffusion-reaction PDE with high probability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01539v2</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>cs.NA</category>
      <category>math.IT</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Simone Brugiapaglia, Nick Dexter, Samir Karam, Weiqi Wang</dc:creator>
    </item>
  </channel>
</rss>
