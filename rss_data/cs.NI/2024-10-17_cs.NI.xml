<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 18 Oct 2024 02:16:37 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Enhancing IoT Communication and Localization via Smarter Antenna</title>
      <link>https://arxiv.org/abs/2410.12100</link>
      <description>arXiv:2410.12100v1 Announce Type: new 
Abstract: The convergence of sensing and communication functionalities is poised to become a pivotal feature of the sixth-generation (6G) wireless networks. This vision represents a paradigm shift in wireless network design, moving beyond mere communication to a holistic integration of sensing and communication capabilities, thereby further narrowing the gap between the physical and digital worlds. While Internet of Things (IoT) devices are integral to future wireless networks, their current capabilities in sensing and communication are constrained by their power and resource limitations. On one hand, their restricted power budget limits their transmission power, leading to reduced communication range and data rates. On the other hand, their limited hardware and processing abilities hinder the adoption of sophisticated sensing technologies, such as direction finding and localization. In this work, we introduce Wi-Pro, a system which seamlessly integrates today's WiFi protocol with smart antenna design to enhance the communication and sensing capabilities of existing IoT devices. This plug-and-play system can be easily installed by replacing the IoT device's antenna. Wi-Pro seamlessly integrates smart antenna hardware with current WiFi protocols, utilizing their inherent features to not only enhance communication but also to enable precise localization on low-cost IoT devices. Our evaluation results demonstrate that Wi-Pro achieves up to 150\% data rate improvement, up to five times range improvement, accurate direction finding, and localization on single-chain IoT devices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12100v1</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tianxiang Li, Haofan Lu, Omid Abari</dc:creator>
    </item>
    <item>
      <title>IRS-aided Near-field Communication: Prospects and Challenges with Codebook Approach</title>
      <link>https://arxiv.org/abs/2410.12664</link>
      <description>arXiv:2410.12664v1 Announce Type: new 
Abstract: Intelligent reflecting surfaces (IRSs) are gaining attention as a low-cost solution to the coverage reduction in high-frequency bands used in next-generation communications. IRSs achieve low costs by controlling only the reflection of radio waves. However, to improve further the propagation environment, larger IRS sizes are required owing to their inability to amplify and retransmit signals. As the IRS size increases, the near-field region expands, requiring beamfocusing instead of beamforming, which is extensively used in existing research. This results in considerable overhead for IRS control decisions. To address this, constructing a codebook that achieves high communication quality with fewer IRS control patterns is effective. This article presents experimental results demonstrating the effectiveness of beamfocusing, construction policy for nonuniform three-dimensional codebooks, and simulation evaluation results of communication performance when operating IRSs with various codebooks. We believe these insights will foster further value for IRSs in next-generation communications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12664v1</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ryuhei Hibi, Hiroaki Hashida, Yuichi Kawamoto, Nei Kato</dc:creator>
    </item>
    <item>
      <title>Experimental Validation of User Experience-focused Dynamic Onboard Service Orchestration for Software Defined Vehicles</title>
      <link>https://arxiv.org/abs/2410.11847</link>
      <description>arXiv:2410.11847v1 Announce Type: cross 
Abstract: In response to the growing need for dynamic software features in automobiles, Software Defined Vehicles (SDVs) have emerged as a promising solution. They integrate dynamic onboard service management to handle the large variety of user-requested services during vehicle operation. Allocating onboard resources efficiently in this setting is a challenging task, as it requires a balance between maximizing user experience and guaranteeing mixed-criticality Quality-of-Service (QoS) network requirements. Our previous research introduced a dynamic resource-based onboard service orchestration algorithm. This algorithm considers real-time invehicle and V2X network health, along with onboard resource constraints, to globally select degraded modes for onboard applications. It maximizes the overall user experience at all times while being embeddable onboard for on-the-fly decisionmaking. A key enabler of this approach is the introduction of the Automotive eXperience Integrity Level (AXIL), a metric expressing runtime priority for non-safety-critical applications. While initial simulation results demonstrated the algorithm's effectiveness, a comprehensive performance assessment would greatly contribute in validating its industrial feasibility. In this current work, we present experimental results obtained from a dedicated test bench. These results illustrate, validate, and assess the practicality of our proposed solution, providing a solid foundation for the continued advancement of dynamic onboard service orchestration in SDVs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11847v1</guid>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <category>cs.SE</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pierre Laclau (Heudiasyc), St\'ephane Bonnet (Heudiasyc), Bertrand Ducourthial (Heudiasyc), Trista Lin (Toulouse INP), Xiaoting Li (Toulouse INP)</dc:creator>
    </item>
    <item>
      <title>LPUF-AuthNet: A Lightweight PUF-Based IoT Authentication via Tandem Neural Networks and Split Learning</title>
      <link>https://arxiv.org/abs/2410.12190</link>
      <description>arXiv:2410.12190v1 Announce Type: cross 
Abstract: By 2025, the internet of things (IoT) is projected to connect over 75 billion devices globally, fundamentally altering how we interact with our environments in both urban and rural settings. However, IoT device security remains challenging, particularly in the authentication process. Traditional cryptographic methods often struggle with the constraints of IoT devices, such as limited computational power and storage. This paper considers physical unclonable functions (PUFs) as robust security solutions, utilizing their inherent physical uniqueness to authenticate devices securely. However, traditional PUF systems are vulnerable to machine learning (ML) attacks and burdened by large datasets. Our proposed solution introduces a lightweight PUF mechanism, called LPUF-AuthNet, combining tandem neural networks (TNN) with a split learning (SL) paradigm. The proposed approach provides scalability, supports mutual authentication, and enhances security by resisting various types of attacks, paving the way for secure integration into future 6G technologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12190v1</guid>
      <category>cs.CR</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Brahim Mefgouda, Raviha Khan, Omar Alhussein, Hani Saleh, Hossien B. Eldeeb, Anshul Pandey, Sami Muhaidat</dc:creator>
    </item>
    <item>
      <title>Designing, Developing, and Validating Network Intelligence for Scaling in Service-Based Architectures based on Deep Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2405.04441</link>
      <description>arXiv:2405.04441v2 Announce Type: replace 
Abstract: Automating network processes without human intervention is crucial for the complex Sixth Generation (6G) environment. Thus, 6G networks must advance beyond basic automation, relying on Artificial Intelligence (AI) and Machine Learning (ML) for self-optimizing and autonomous operation. This requires zero-touch management and orchestration, the integration of Network Intelligence (NI) into the network architecture, and the efficient lifecycle management of intelligent functions. Despite its potential, integrating NI poses challenges in model development and application. To tackle those issues, this paper presents a novel methodology to manage the complete lifecycle of Reinforcement Learning (RL) applications in networking, thereby enhancing existing Machine Learning Operations (MLOps) frameworks to accommodate RL-specific tasks. We focus on scaling computing resources in service-based architectures, modeling the problem as a Markov Decision Process (MDP). Two RL algorithms, guided by distinct Reward Functions (RFns), are proposed to autonomously determine the number of service replicas in dynamic environments. Our proposed methodology is anchored on a dual approach: firstly, it evaluates the training performance of these algorithms under varying RFns, and secondly, it validates their performance after being trained to discern the practical applicability in real-world settings. We show that, despite significant progress, the development stage of RL techniques for networking applications, particularly in scaling scenarios, still leaves room for significant improvements. This study underscores the importance of ongoing research and development to enhance the practicality and resilience of RL techniques in real-world networking environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04441v2</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Paola Soto, Miguel Camelo, Danny De Vleeschauwer, Yorick De Bock, Nina Slamnik-Krije\v{s}torac, Chia-Yu Chang, Natalia Gaviria, Erik Mannens, Juan F. Botero, Steven Latr\'e</dc:creator>
    </item>
    <item>
      <title>SplitLLM: Collaborative Inference of LLMs for Model Placement and Throughput Optimization</title>
      <link>https://arxiv.org/abs/2410.10759</link>
      <description>arXiv:2410.10759v2 Announce Type: replace-cross 
Abstract: Large language models (LLMs) have been a disruptive innovation in recent years, and they play a crucial role in our daily lives due to their ability to understand and generate human-like text. Their capabilities include natural language understanding, information retrieval and search, translation, chatbots, virtual assistance, and many more. However, it is well known that LLMs are massive in terms of the number of parameters. Additionally, the self-attention mechanism in the underlying architecture of LLMs, Transformers, has quadratic complexity in terms of both computation and memory with respect to the input sequence length. For these reasons, LLM inference is resource-intensive, and thus, the throughput of LLM inference is limited, especially for the longer sequences. In this report, we design a collaborative inference architecture between a server and its clients to alleviate the throughput limit. In this design, we consider the available resources on both sides, i.e., the computation and communication costs. We develop a dynamic programming-based algorithm to optimally allocate computation between the server and the client device to increase the server throughput, while not violating the service level agreement (SLA). We show in the experiments that we are able to efficiently distribute the workload allowing for roughly 1/3 reduction in the server workload, while achieving 19 percent improvement over a greedy method. As a result, we are able to demonstrate that, in an environment with different types of LLM inference requests, the throughput of the server is improved.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10759v2</guid>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Akrit Mudvari, Yuang Jiang, Leandros Tassiulas</dc:creator>
    </item>
  </channel>
</rss>
