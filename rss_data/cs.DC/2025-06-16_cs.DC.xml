<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DC</link>
    <description>cs.DC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 17 Jun 2025 02:28:27 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>SwiftSpec: Ultra-Low Latency LLM Decoding by Scaling Asynchronous Speculative Decoding</title>
      <link>https://arxiv.org/abs/2506.11309</link>
      <description>arXiv:2506.11309v1 Announce Type: new 
Abstract: Low-latency decoding for large language models (LLMs) is crucial for applications like chatbots and code assistants, yet generating long outputs remains slow in single-query settings. Prior work on speculative decoding (which combines a small draft model with a larger target model) and tensor parallelism has each accelerated decoding. However, conventional approaches fail to apply both simultaneously due to imbalanced compute requirements (between draft and target models), KV-cache inconsistencies, and communication overheads under small-batch tensor-parallelism. This paper introduces SwiftSpec, a system that targets ultra-low latency for LLM decoding. SwiftSpec redesigns the speculative decoding pipeline in an asynchronous and disaggregated manner, so that each component can be scaled flexibly and remove draft overhead from the critical path. To realize this design, SwiftSpec proposes parallel tree generation, tree-aware KV cache management, and fused, latency-optimized kernels to overcome the challenges listed above. Across 5 model families and 6 datasets, SwiftSpec achieves an average of 1.75x speedup over state-of-the-art speculative decoding systems and, as a highlight, serves Llama3-70B at 348 tokens/s on 8 Nvidia Hopper GPUs, making it the fastest known system for low-latency LLM serving at this scale.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11309v1</guid>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ziyi Zhang, Ziheng Jiang, Chengquan Jiang, Menghan Yu, Size Zheng, Haibin Lin, Henry Hoffmann, Xin Liu</dc:creator>
    </item>
    <item>
      <title>Capsule: Efficient Player Isolation for Datacenters</title>
      <link>https://arxiv.org/abs/2506.11483</link>
      <description>arXiv:2506.11483v1 Announce Type: new 
Abstract: Cloud gaming is increasingly popular. A challenge for cloud provider is to keep datacenter utilization high: a non-trivial task due to application variety. These applications come in different shapes and sizes. So do cloud datacenter resources, e.g., CPUs, GPUs, NPUs.
  Part of the challenge stems from game engines being predominantly designed to run only one player. One player in a lightweight game might utilize only a fraction of the cloud server GPU. The remaining GPU capacity will be left underutilized, an undesired outcome for the cloud provider. We introduce Capsule, a mechanism that allows multiple players to seamlessly share one GPU.
  We implemented Capsule in O3DE, a popular open source game engine. Our evaluations show that Capsule can increase datacenter resource utilization by accommodating up to 2.25x more players, without degrading player gaming experience. Capsule is also application agnostic. We ran four applications on Capsule-based O3DE with no application changes. Our experiences show that Capsule design can be adopted by other game engines to increase datacenter utilization across cloud providers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11483v1</guid>
      <category>cs.DC</category>
      <category>cs.GR</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhouheng Du, Nima Davari, Li Li, Nodir Kodirov</dc:creator>
    </item>
    <item>
      <title>Bounded Memory in Distributed Networks</title>
      <link>https://arxiv.org/abs/2506.11644</link>
      <description>arXiv:2506.11644v1 Announce Type: new 
Abstract: The recent advent of programmable switches makes distributed algorithms readily deployable in real-world datacenter networks. However, there are still gaps between theory and practice that prevent the smooth adaptation of CONGEST algorithms to these environments. In this paper, we focus on the memory restrictions that arise in real-world deployments. We introduce the $\mu$-CONGEST model where on top of the bandwidth restriction, the memory of nodes is also limited to $\mu$ words, in line with real-world systems. We provide fast algorithms of two main flavors.
  First, we observe that many algorithms in the CONGEST model are memory-intensive and do not work in $\mu$-CONGEST. A prime example of a family of algorithms that use large memory is clique-listing algorithms. We show that the memory issue that arises here cannot be resolved without incurring a cost in the round complexity, by establishing a lower bound on the round complexity of listing cliques in $\mu$-CONGEST. We introduce novel techniques to overcome these issues and generalize the algorithms to work within a given memory bound. Combined with our lower bound, these provide tight tradeoffs between the running time and memory of nodes.
  Second, we show that it is possible to efficiently simulate various families of streaming algorithms in $\mu$-CONGEST. These include fast simulations of $p$-pass algorithms, random order streams, and various types of mergeable streaming algorithms.
  Combining our contributions, we show that we can use streaming algorithms to efficiently generate statistics regarding combinatorial structures in the network. An example of an end result of this type is that we can efficiently identify and provide the per-color frequencies of the frequent monochromatic triangles in $\mu$-CONGEST.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11644v1</guid>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3694906.3743302</arxiv:DOI>
      <dc:creator>Ran Ben Basat, Keren Censor-Hillel, Yi-Jun Chang, Wenchen Han, Dean Leitersdorf, Gregory Schwartzman</dc:creator>
    </item>
    <item>
      <title>A retrospective on DISPEED -- Leveraging heterogeneity in a drone swarm for IDS execution</title>
      <link>https://arxiv.org/abs/2506.11800</link>
      <description>arXiv:2506.11800v1 Announce Type: new 
Abstract: Swarms of drones are gaining more and more autonomy and efficiency during their missions. However, security threats can disrupt their missions' progression. To overcome this problem, Network Intrusion Detection Systems ((N)IDS) are promising solutions to detect malicious behavior on network traffic. However, modern NIDS rely on resource-hungry machine learning techniques, that can be difficult to deploy on a swarm of drones. The goal of the DISPEED project is to leverage the heterogeneity (execution platforms, memory) of the drones composing a swarm to deploy NIDS. It is decomposed in two phases: (1) a characterization phase that consists in characterizing various IDS implementations on diverse embedded platforms, and (2) an IDS implementation mapping phase that seeks to develop selection strategies to choose the most relevant NIDS depending on the context. On the one hand, the characterization phase allowed us to identify 36 relevant IDS implementations on three different embedded platforms: a Raspberry Pi 4B, a Jetson Xavier, and a Pynq-Z2. On the other hand, the IDS implementation mapping phase allowed us to design both standalone and distributed strategies to choose the best NIDSs to deploy depending on the context. The results of the project have led to three publications in international conferences, and one publication in a journal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11800v1</guid>
      <category>cs.DC</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vincent Lannurien, Cam\'elia Slimani, Louis Morge-Rollet, Laurent Lemarchand, David Espes, Fr\'ed\'eric Le Roy, Jalil Boukhobza</dc:creator>
    </item>
    <item>
      <title>Secure API-Driven Research Automation to Accelerate Scientific Discovery</title>
      <link>https://arxiv.org/abs/2506.11950</link>
      <description>arXiv:2506.11950v1 Announce Type: new 
Abstract: The Secure Scientific Service Mesh (S3M) provides API-driven infrastructure to accelerate scientific discovery through automated research workflows. By integrating near real-time streaming capabilities, intelligent workflow orchestration, and fine-grained authorization within a service mesh architecture, S3M revolutionizes programmatic access to high performance computing (HPC) while maintaining uncompromising security. This framework allows intelligent agents and experimental facilities to dynamically provision resources and execute complex workflows, accelerating experimental lifecycles, and unlocking the full potential of AI-augmented autonomous science. S3M signals a new era in scientific computing infrastructure that eliminates traditional barriers between researchers, computational resources, and experimental facilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11950v1</guid>
      <category>cs.DC</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tyler J. Skluzacek, Paul Bryant, A. J. Ruckman, Daniel Rosendo, Suzanne Prentice, Michael J. Brim, Ryan Adamson, Sarp Oral, Mallikarjun Shankar, Rafael Ferreira da Silva</dc:creator>
    </item>
    <item>
      <title>On the Effectiveness of the 'Follow-the-Sun' Strategy in Mitigating the Carbon Footprint of AI in Cloud Instances</title>
      <link>https://arxiv.org/abs/2506.10990</link>
      <description>arXiv:2506.10990v1 Announce Type: cross 
Abstract: 'Follow-the-Sun' (FtS) is a theoretical computational model aimed at minimizing the carbon footprint of computer workloads. It involves dynamically moving workloads to regions with cleaner energy sources as demand increases and energy production relies more on fossil fuels. With the significant power consumption of Artificial Intelligence (AI) being a subject of extensive debate, FtS is proposed as a strategy to mitigate the carbon footprint of training AI models. However, the literature lacks scientific evidence on the advantages of FtS to mitigate the carbon footprint of AI workloads. In this paper, we present the results of an experiment conducted in a partial synthetic scenario to address this research gap. We benchmarked four AI algorithms in the anomaly detection domain and measured the differences in carbon emissions in four cases: no strategy, FtS, and two strategies previously introduced in the state of the art, namely Flexible Start and Pause and Resume. To conduct our experiment, we utilized historical carbon intensity data from the year 2021 for seven European cities. Our results demonstrate that the FtS strategy not only achieves average reductions of up to 14.6% in carbon emissions (with peaks of 16.3%) but also helps in preserving the time needed for training.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10990v1</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.DC</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Roberto Vergallo, Lu\'is Cruz, Alessio Errico, Luca Mainetti</dc:creator>
    </item>
    <item>
      <title>Not All Clients Are Equal: Personalized Federated Learning on Heterogeneous Multi-Modal Clients</title>
      <link>https://arxiv.org/abs/2506.11024</link>
      <description>arXiv:2506.11024v1 Announce Type: cross 
Abstract: Foundation models have shown remarkable capabilities across diverse multi-modal tasks, but their centralized training raises privacy concerns and induces high transmission costs. In contrast, federated learning (FL) offers a distributed alternative without the need to share data. Recently, for the growing demand for personalizing AI models for different user purposes, personalized federated learning (PFL) has emerged. PFL allows each client to leverage the knowledge of other clients for further adaptation to individual user preferences, again without the need to share data. Despite its potential, most PFL studies remain confined to simulated environments, overlooking the data and model heterogeneity that arise in real-world scenarios. In contrast, we first consider large data heterogeneity, evaluating on a new benchmark for multi-modal PFL, spanning 40 distinct tasks with realistic data distribution shifts. We then consider model heterogeneity in that we do not assume that all clients share similar model architectures. To address data heterogeneity, we propose a task-similarity-aware model aggregation method that provides customized global models to each client. For model heterogeneity, we propose a dimension-invariant module that enables knowledge sharing across heterogeneous models. Empirical validations demonstrate that the proposed approach outperforms the state-of-the-art, excelling in both personalization and generalization capabilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11024v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.DC</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Minhyuk Seo, Taeheon Kim, Hankook Lee, Jonghyun Choi, Tinne Tuytelaars</dc:creator>
    </item>
    <item>
      <title>An Active Learning-Based Streaming Pipeline for Reduced Data Training of Structure Finding Models in Neutron Diffractometry</title>
      <link>https://arxiv.org/abs/2506.11100</link>
      <description>arXiv:2506.11100v1 Announce Type: cross 
Abstract: Structure determination workloads in neutron diffractometry are computationally expensive and routinely require several hours to many days to determine the structure of a material from its neutron diffraction patterns. The potential for machine learning models trained on simulated neutron scattering patterns to significantly speed up these tasks have been reported recently. However, the amount of simulated data needed to train these models grows exponentially with the number of structural parameters to be predicted and poses a significant computational challenge. To overcome this challenge, we introduce a novel batch-mode active learning (AL) policy that uses uncertainty sampling to simulate training data drawn from a probability distribution that prefers labelled examples about which the model is least certain. We confirm its efficacy in training the same models with about 75% less training data while improving the accuracy. We then discuss the design of an efficient stream-based training workflow that uses this AL policy and present a performance study on two heterogeneous platforms to demonstrate that, compared with a conventional training workflow, the streaming workflow delivers about 20% shorter training time without any loss of accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11100v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.DC</category>
      <category>physics.atm-clus</category>
      <category>physics.data-an</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/BigData62323.2024.10825990</arxiv:DOI>
      <arxiv:journal_reference>2024 IEEE International Conference on Big Data (BigData), Washington, DC, USA, 2024, pp. 1873-1882</arxiv:journal_reference>
      <dc:creator>Tianle Wang, Jorge Ramirez, Cristina Garcia-Cardona, Thomas Proffen, Shantenu Jha, Sudip K. Seal</dc:creator>
    </item>
    <item>
      <title>Model Discovery and Graph Simulation: A Lightweight Alternative to Chaos Engineering</title>
      <link>https://arxiv.org/abs/2506.11176</link>
      <description>arXiv:2506.11176v1 Announce Type: cross 
Abstract: Microservice applications are prone to cascading failures because of dense inter-service dependencies. Ensuring resilience usually demands fault-injection experiments in production-like setups. We propose \textit{model discovery} -- an automated CI/CD step that extracts a live dependency graph from trace data -- and show that this lightweight representation is sufficient for accurate resilience prediction. Using the DeathStarBench Social Network, we build the graph, simulate failures via Monte-Carlo, and run matching chaos experiments on the real system. The graph model closely matches reality: with no replication, 16 trials yield an observed resilience of 0.186 versus a predicted 0.161; with replication, both observed and predicted values converge to 0.305 (mean absolute error \leq 0.0004). These results indicate that even a simple, automatically discovered graph can estimate microservice availability with high fidelity, offering rapid design-time insight without full-scale failure testing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11176v1</guid>
      <category>cs.SE</category>
      <category>cs.DC</category>
      <category>cs.DM</category>
      <category>cs.ET</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Anatoly A. Krasnovsky, Alexander Zorkin</dc:creator>
    </item>
    <item>
      <title>Topology-Aware Virtualization over Inter-Core Connected Neural Processing Units</title>
      <link>https://arxiv.org/abs/2506.11446</link>
      <description>arXiv:2506.11446v1 Announce Type: cross 
Abstract: With the rapid development of artificial intelligence (AI) applications, an emerging class of AI accelerators, termed Inter-core Connected Neural Processing Units (NPU), has been adopted in both cloud and edge computing environments, like Graphcore IPU, Tenstorrent, etc. Despite their innovative design, these NPUs often demand substantial hardware resources, leading to suboptimal resource utilization due to the imbalance of hardware requirements across various tasks. To address this issue, prior research has explored virtualization techniques for monolithic NPUs, but has neglected inter-core connected NPUs with the hardware topology.
  This paper introduces vNPU, the first comprehensive virtualization design for inter-core connected NPUs, integrating three novel techniques: (1) NPU route virtualization, which redirects instruction and data flow from virtual NPU cores to physical ones, creating a virtual topology; (2) NPU memory virtualization, designed to minimize translation stalls for SRAM-centric and NoC-equipped NPU cores, thereby maximizing the memory bandwidth; and (3) Best-effort topology mapping, which determines the optimal mapping from all candidate virtual topologies, balancing resource utilization with end-to-end performance. We have developed a prototype of vNPU on both an FPGA platform (Chipyard+FireSim) and a simulator (DCRA). Evaluation results indicate that, compared to other virtualization approaches such as unified virtual memory and MIG, vNPU achieves up to a 2x performance improvement across various ML models, with only 2% hardware cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11446v1</guid>
      <category>cs.AR</category>
      <category>cs.DC</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dahu Feng, Erhu Feng, Dong Du, Pinjie Xu, Yubin Xia, Haibo Chen, Rong Zhao</dc:creator>
    </item>
    <item>
      <title>Advancing Hybrid Defense for Byzantine Attacks in Federated Learning</title>
      <link>https://arxiv.org/abs/2409.06474</link>
      <description>arXiv:2409.06474v3 Announce Type: replace 
Abstract: Federated learning (FL) enables multiple clients to collaboratively train a global model without sharing their local data. Recent studies have highlighted the vulnerability of FL to Byzantine attacks, where malicious clients send poisoned updates to degrade model performance. In particular, many attacks have been developed targeting specific aggregation rules, whereas various defense mechanisms have been designed for dedicated threat models. This paper studies the resilience of attack-agnostic FL scenarios, where the server lacks prior knowledge of both the attackers' strategies and the number of malicious clients involved. We first introduce hybrid defenses against state-of-the-art attacks. Our goal is to identify a general-purpose aggregation rule that performs well on average while also avoiding worst-case vulnerabilities. By adaptively selecting from available defenses, we demonstrate that the server remains robust even when confronted with a substantial proportion of poisoned updates. We also emphasize that existing FL defenses should not automatically be regarded as secure, as demonstrated by the newly proposed Trapsetter attack. The proposed attack outperforms other state-of-the-art attacks by further increasing the impact of the attack by 5-15%. Our findings highlight the ongoing need for the development of Byzantine-resilient aggregation algorithms in FL.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06474v3</guid>
      <category>cs.DC</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kai Yue, Richeng Jin, Chau-Wai Wong, Huaiyu Dai</dc:creator>
    </item>
    <item>
      <title>To Compress or Not To Compress: Energy Trade-Offs and Benefits of Lossy Compressed I/O</title>
      <link>https://arxiv.org/abs/2410.23497</link>
      <description>arXiv:2410.23497v2 Announce Type: replace 
Abstract: Modern scientific simulations generate massive volumes of data, creating significant challenges for I/O and storage systems. Error-bounded lossy compression (EBLC) offers a solution by reducing data set sizes while preserving data quality within user-specified limits. This study provides the first comprehensive energy characterization of state-of-the-art EBLC algorithms--SZ2, SZ3, ZFP, QoZ, and SZx--across various scientific data sets, CPU generations, and parallel/serial modes. We analyze the energy consumption patterns of compression and decompression operations, as well as the energy trade-offs in data I/O scenarios.
  Our work demonstrates the relationships between compression ratios, runtime, energy efficiency, and data quality, highlighting the importance of considering compressors and error bounds for specific use cases. We demonstrate that EBLC can significantly reduce I/O energy consumption, with savings of up to two orders of magnitude compared to uncompressed I/O for large data sets. In multi-node HPC environments, we observe energy reductions of approximately 25% when using EBLC. We also show that EBLC can achieve compression ratios of 10-100x, potentially reducing storage device requirements by nearly two orders of magnitude. This work provides a framework for system operators and computational scientists to make informed decisions about implementing EBLC for energy-efficient data management in HPC environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.23497v2</guid>
      <category>cs.DC</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Grant Wilkins, Sheng Di, Jon C. Calhoun, Robert Underwood, Franck Cappello</dc:creator>
    </item>
    <item>
      <title>PIPO: Pipelined Offloading for Efficient Inference on Consumer Devices</title>
      <link>https://arxiv.org/abs/2504.03664</link>
      <description>arXiv:2504.03664v2 Announce Type: replace 
Abstract: The high memory and computation demand of large language models (LLMs) makes them challenging to be deployed on consumer devices due to limited GPU memory. Offloading can mitigate the memory constraint but often suffers from low GPU utilization, leading to low inference efficiency. In this work, we propose a novel framework, called pipelined offloading (PIPO), for efficient inference on consumer devices. PIPO designs a fine-grained offloading pipeline, complemented with optimized data transfer and computation, to achieve high concurrency and efficient scheduling for inference. Experimental results show that compared with state-of-the-art baseline, PIPO increases GPU utilization from below 40% to over 90% and achieves up to 3.1$\times$ higher throughput, running on a laptop equipped with a RTX3060 GPU of 6GB memory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03664v2</guid>
      <category>cs.DC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Yangyijian Liu, Jun Li, Wu-Jun Li</dc:creator>
    </item>
    <item>
      <title>You can lie but not deny: SWMR registers with signature properties in systems with Byzantine processes</title>
      <link>https://arxiv.org/abs/2504.09805</link>
      <description>arXiv:2504.09805v2 Announce Type: replace 
Abstract: We define and show how to implement SWMR registers that provide properties of unforgeable digital signatures - without actually using such signatures - in systems with Byzantine processes. Intuitively, processes can use these registers to write values as if they are ``signed'', such that these ``signed values'' can be ``verified'' by any process and ``relayed'' to any process. All our register implementations are from SWMR registers, and they work in systems with $n &gt; 3f$ processes, $f$ of which can be Byzantine. We show that these implementations are optimal in the number of Byzantine processes they can tolerate: more precisely, we prove that if $3 \le n \le 3f$, the registers that we propose cannot be implemented from SWMR registers without using signatures. The registers that we introduce in this paper can also be implemented without signatures in message-passing systems with $n &gt; 3f$ processes, $f$ of which can be Byzantine: this is because SWMR registers can be implemented in such systems (Most\'efaoui, Petrolia, Raynal, and Jard 2017).</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.09805v2</guid>
      <category>cs.DC</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xing Hu, Sam Toueg</dc:creator>
    </item>
    <item>
      <title>WindVE: Collaborative CPU-NPU Vector Embedding</title>
      <link>https://arxiv.org/abs/2504.14941</link>
      <description>arXiv:2504.14941v4 Announce Type: replace 
Abstract: Retrieval-Augmented Generation is a technology that enhances large language models by integrating information retrieval. In the industry, inference services based on LLMs are highly sensitive to cost-performance ratio, prompting the need for improving hardware resource utilization in the inference service. Specifically, vector embedding and retrieval processes take up to 20% of the total latency. Therefore, optimizing the utilization of computational resources in vector embeddings is crucial for enhancing the cost-performance ratio of inference processes, which in turn boosts their product competitiveness.In this paper, we analyze the deployment costs of vector embedding technology in inference services, propose a theoretical formula, and determine through the mathematical expression that increasing the capacity to process concurrent queries is the key to reducing the deployment costs of vector embeddings. Therefore, in this paper, we focus on improving the product's capability to process concurrent queries. To optimize concurrency without sacrificing performance, we have designed a queue manager that adeptly offloads CPU peak queries. This manager utilizes a linear regression model to ascertain the optimal queue depths, a critical parameter that significantly influences the efficacy of the system. We further develop a system named WindVE that uses a CPU-NPU heterogeneous architecture to offload peak concurrent queries, which leverages the performance differences between the two processors to effectively manage traffic surges. Through experiments, we compare WindVE to the state-of-the-art vector embedding framework FlagEmbedding, and achieve a concurrency level up to 22.3% higher than the scheme without offloading.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14941v4</guid>
      <category>cs.DC</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jinqi Huang, Xuebing Yu, Yi Xiong, Wenjie Huang, Entong Li, Li Zeng, Xin chen</dc:creator>
    </item>
    <item>
      <title>EvalNet: A Practical Toolchain for Generation and Analysis of Extreme-Scale Interconnects</title>
      <link>https://arxiv.org/abs/2105.12663</link>
      <description>arXiv:2105.12663v3 Announce Type: replace-cross 
Abstract: The diversity of communication paths in a network - especially non-minimal paths - is a key enabler of performance at extreme scales. We present EvalNet, a toolchain for scalable generation and analysis over 25 important network topologies, such as Slim Fly, PolarFly, and Orthogonal Fat Trees, with a strong focus on path diversity metrics. EvalNet provides an extensive and fine-grained analysis of shortest and non-shortest paths, including their multiplicities, lengths, and interference. It supports exact measurement and visualization of bandwidth and throughput between every router pair, enabling unprecedented insight into routing potential. EvalNet also includes detailed models for construction cost and power consumption, and interfaces seamlessly with established simulators, which we tune to support large-scale evaluations on low-cost hardware. Using EvalNet, we deliver the widest and most comprehensive path diversity study to date, demonstrating how path diversity underpins throughput and scalability, and facilitating progress towards new frontiers in extreme-scale network design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2105.12663v3</guid>
      <category>cs.NI</category>
      <category>cs.DC</category>
      <category>cs.PF</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maciej Besta, Patrick Iff, Marcel Schneider, Nils Blach, Alessandro Maissen, Salvatore Di Girolamo, Jens Domke, Jascha Krattenmacher, Ankit Singla, Kartik Lakhotia, Laura Monroe, Fabrizio Petrini, Robert Gerstenberger, Torsten Hoefler</dc:creator>
    </item>
    <item>
      <title>Auctions with Tokens: Monetary Policy as a Mechanism Design Choice</title>
      <link>https://arxiv.org/abs/2301.13794</link>
      <description>arXiv:2301.13794v4 Announce Type: replace-cross 
Abstract: I study a repeated auction in which payments are made with a blockchain token created and initially owned by the auction designer. Unlike the ``virtual money'' previously examined in mechanism design, such tokens can be saved and traded outside the mechanism. I show that the present-discounted value of expected revenues equals that of a conventional dollar auction, but revenues accrue earlier and are less volatile. The optimal monetary policy burns the tokens used for payment, a practice common in blockchain-based protocols. I also show that the same outcome can be reproduced in a dollar auction if the auctioneer issues a suitable dollar-denominated security. This equivalence breaks down with moral hazard and contracting frictions: with severe contracting frictions the token auction dominates, whereas with mild contracting frictions the dollar auction combined with a dollar-denominated financial instrument is preferred.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.13794v4</guid>
      <category>econ.TH</category>
      <category>cs.DC</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrea Canidio</dc:creator>
    </item>
    <item>
      <title>Byzantine-Resilient Secure Aggregation for Federated Learning Without Privacy Compromises</title>
      <link>https://arxiv.org/abs/2405.08698</link>
      <description>arXiv:2405.08698v3 Announce Type: replace-cross 
Abstract: Federated learning (FL) shows great promise in large scale machine learning, but brings new risks in terms of privacy and security. We propose ByITFL, a novel scheme for FL that provides resilience against Byzantine users while keeping the users' data private from the federator and private from other users. The scheme builds on the preexisting non-private FLTrust scheme, which tolerates malicious users through trust scores (TS) that attenuate or amplify the users' gradients. The trust scores are based on the ReLU function, which we approximate by a polynomial. The distributed and privacy-preserving computation in ByITFL is designed using a combination of Lagrange coded computing, verifiable secret sharing and re-randomization steps. ByITFL is the first Byzantine resilient scheme for FL with full information-theoretic privacy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.08698v3</guid>
      <category>cs.IT</category>
      <category>cs.CR</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/ITW61385.2024.10807034</arxiv:DOI>
      <dc:creator>Yue Xia, Christoph Hofmeister, Maximilian Egger, Rawad Bitar</dc:creator>
    </item>
    <item>
      <title>LoByITFL: Low Communication Secure and Private Federated Learning</title>
      <link>https://arxiv.org/abs/2405.19217</link>
      <description>arXiv:2405.19217v2 Announce Type: replace-cross 
Abstract: Privacy of the clients' data and security against Byzantine clients are key challenges in Federated Learning (FL). Existing solutions to joint privacy and security incur sacrifices on the privacy guarantee. We introduce LoByITFL, the first communication-efficient information-theoretically private and secure FL scheme that makes no sacrifices on the privacy guarantees while ensuring security against Byzantine adversaries. The key components are a small and representative dataset available to the federator, a careful modification of the FLTrust algorithm, and the one-time use of a trusted third party during an initialization period. We provide theoretical guarantees on the privacy and Byzantine resilience, as well as experimental results showing the convergence of LoByITFL.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.19217v2</guid>
      <category>cs.IT</category>
      <category>cs.CR</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yue Xia, Maximilian Egger, Christoph Hofmeister, Rawad Bitar</dc:creator>
    </item>
    <item>
      <title>Level set-based inverse homogenisation of three-dimensional piezoelectric materials</title>
      <link>https://arxiv.org/abs/2410.03148</link>
      <description>arXiv:2410.03148v3 Announce Type: replace-cross 
Abstract: In this paper we use memory-distributed level set-based topology optimisation to design three-dimensional periodic piezoelectric materials with enhanced properties. We compare and assess several existing iterative solvers with respect to their weak scalability and find that an approximate Schur complement preconditioned generalized minimal residual method method demonstrates the best performance and scalability for solving the piezoelectric homogenisation equations. We use the developed techniques to computationally design high-resolution piezoelectric metamaterials with enhanced stiffness and piezoelectric properties that yield new insights into material design for sensor, hydrophone, and actuator applications. We suggest two robust structures with no fine-scale features that exhibit enhanced piezoelectric properties several times larger than those of the base material. We find that level set-based topology optimisation is well suited to problems involving piezoelectricity and has the advantage of avoiding large regions of intermediate density material. Our memory-distributed level-set implementation is open source and provided for practitioners in the community.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03148v3</guid>
      <category>cs.CE</category>
      <category>cs.DC</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zachary J. Wegert, Anthony P. Roberts, Vivien J. Challis</dc:creator>
    </item>
    <item>
      <title>MindFlayer SGD: Efficient Parallel SGD in the Presence of Heterogeneous and Random Worker Compute Times</title>
      <link>https://arxiv.org/abs/2410.04285</link>
      <description>arXiv:2410.04285v2 Announce Type: replace-cross 
Abstract: We investigate the problem of minimizing the expectation of smooth nonconvex functions in a distributed setting with multiple parallel workers that are able to compute stochastic gradients. A significant challenge in this context is the presence of arbitrarily heterogeneous and stochastic compute times among workers, which can severely degrade the performance of existing parallel stochastic gradient descent (SGD) methods. While some parallel SGD algorithms achieve optimal performance under deterministic but heterogeneous delays, their effectiveness diminishes when compute times are random - a scenario not explicitly addressed in their design. To bridge this gap, we introduce MindFlayer SGD, a novel parallel SGD method specifically designed to handle stochastic and heterogeneous compute times. Through theoretical analysis and empirical evaluation, we demonstrate that MindFlayer SGD consistently outperforms existing baselines, particularly in environments with heavy-tailed noise. Our results highlight its robustness and scalability, making it a compelling choice for large-scale distributed learning tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04285v2</guid>
      <category>math.OC</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Artavazd Maranjyan, Omar Shaikh Omar, Peter Richt\'arik</dc:creator>
    </item>
    <item>
      <title>CoBRA: A Universal Strategyproof Confirmation Protocol for Quorum-based Proof-of-Stake Blockchains</title>
      <link>https://arxiv.org/abs/2503.16783</link>
      <description>arXiv:2503.16783v2 Announce Type: replace-cross 
Abstract: We present a formal analysis of quorum-based State Machine Replication (SMR) protocols in Proof-of-Stake (PoS) systems under a hybrid threat model comprising honest, Byzantine, and rational validators. Our analysis of traditional quorum-based protocols establishes two fundamental impossibility results: (1) in partially synchronous networks, no quorum-based protocol can achieve SMR when rational and Byzantine validators comprise more than $1/3$ of participants, and (2) in synchronous networks, SMR remains impossible when rational and Byzantine validators comprise $2/3$ or more of participants.
  To overcome these limitations, we propose two complementary solutions in our hybrid model. First, we introduce a protocol that enforces a bound on the volume of the total transacted amount that is finalized within any time window $\Delta$ and prove that this bound is necessary for secure SMR protocols in our model. Second, we present the \emph{strongest chain rule}, which enables efficient finalization of transactions when the majority of honest participants provably support the SMR execution. Through empirical analysis of Ethereum and Cosmos networks, we demonstrate that validator participation consistently exceeds the required ${5}/{6}$ threshold, establishing the practical feasibility of our solution in production PoS systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16783v2</guid>
      <category>cs.CR</category>
      <category>cs.DC</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zeta Avarikioti, Eleftherios Kokoris Kogias, Ray Neiheiser, Christos Stefo</dc:creator>
    </item>
  </channel>
</rss>
