<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.CO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.CO</link>
    <description>stat.CO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.CO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 30 May 2024 04:00:44 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 30 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Sampling metastable systems using collective variables and Jarzynski-Crooks paths</title>
      <link>https://arxiv.org/abs/2405.18160</link>
      <description>arXiv:2405.18160v1 Announce Type: cross 
Abstract: We consider the problem of sampling a high dimensional multimodal target probability measure. We assume that a good proposal kernel to move only a subset of the degrees of freedoms (also known as collective variables) is known a priori. This proposal kernel can for example be built using normalizing flows. We show how to extend the move from the collective variable space to the full space and how to implement an accept-reject step in order to get a reversible chain with respect to a target probability measure. The accept-reject step does not require to know the marginal of the original measure in the collective variable (namely to know the free energy). The obtained algorithm admits several variants, some of them being very close to methods which have been proposed previously in the literature. We show how the obtained acceptance ratio can be expressed in terms of the work which appears in the Jarzynski-Crooks equality, at least for some variants. Numerical illustrations demonstrate the efficiency of the approach on various simple test cases, and allow us to compare the variants of the algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.18160v1</guid>
      <category>cond-mat.stat-mech</category>
      <category>stat.CO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christoph Sch\"onle, Marylou Gabri\'e, Tony Leli\`evre, Gabriel Stoltz</dc:creator>
    </item>
    <item>
      <title>Guided sequential ABC schemes for intractable Bayesian models</title>
      <link>https://arxiv.org/abs/2206.12235</link>
      <description>arXiv:2206.12235v5 Announce Type: replace 
Abstract: Sequential algorithms such as sequential importance sampling (SIS) and sequential Monte Carlo (SMC) have proven fundamental in Bayesian inference for models not admitting a readily available likelihood function. For approximate Bayesian computation (ABC), SMC-ABC is the state-of-art sampler. However, since the ABC paradigm is intrinsically wasteful, sequential ABC schemes can benefit from well-targeted proposal samplers that efficiently avoid improbable parameter regions. We contribute to the ABC modeller's toolbox with novel proposal samplers that are conditional to summary statistics of the data. In a sense, the proposed parameters are "guided" to rapidly reach regions of the posterior surface that are compatible with the observed data. This speeds up the convergence of these sequential samplers, thus reducing the computational effort, while preserving the accuracy in the inference. We provide a variety of guided Gaussian and copula-based samplers for both SIS-ABC and SMC-ABC easing inference for challenging case-studies, including multimodal posteriors, highly correlated posteriors, hierarchical models with about 20 parameters, and a simulation study of cell movements using more than 400 summary statistics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2206.12235v5</guid>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Umberto Picchini, Massimiliano Tamborrino</dc:creator>
    </item>
    <item>
      <title>nhppp: Simulating Nonhomogeneous Poisson Point Processes in R</title>
      <link>https://arxiv.org/abs/2402.00358</link>
      <description>arXiv:2402.00358v2 Announce Type: replace 
Abstract: We introduce the `nhppp' package for simulating events from one-dimensional non-homogeneous Poisson point processes (NHPPPs) in R fast and with a small memory footprint. We developed it to facilitate the sampling of event times in discrete event and statistical simulations. The package's functions are based on three algorithms that provably sample from a target NHPPP: the time-transformation of a homogeneous Poisson process (of intensity one) via the inverse of the integrated intensity function; the generation of a Poisson number of order statistics from a fixed density function; and the thinning of a majorizing NHPPP via an acceptance-rejection scheme. We present a study of numerical accuracy and time performance of the algorithms. We illustrate use with simple reproducible examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.00358v2</guid>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thomas A. Trikalinos, Yuliia Sereda</dc:creator>
    </item>
    <item>
      <title>The Importance of Discussing Assumptions when Teaching Bootstrapping</title>
      <link>https://arxiv.org/abs/2112.07737</link>
      <description>arXiv:2112.07737v3 Announce Type: replace-cross 
Abstract: Bootstrapping and other resampling methods are increasingly appearing in the textbooks and curricula of courses that introduce undergraduate students to statistical methods. In order to teach the bootstrap well, students and instructors need to be aware of the assumptions behind these intervals. In this article we discuss important assumptions about simple non-parametric bootstrap intervals and their corresponding hypothesis tests. We present simulations that instructors can use to help students understand some of the assumptions behind these methods. The simulations will be especially relevant to instructors who desire to increase accessibility for students from non-mathematical backgrounds, including those with math anxiety.</description>
      <guid isPermaLink="false">oai:arXiv.org:2112.07737v3</guid>
      <category>stat.OT</category>
      <category>stat.CO</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Njesa Totty (Framingham State University), James Molyneux (Oregon State University), Claudio Fuentes (Oregon State University)</dc:creator>
    </item>
    <item>
      <title>Non-Log-Concave and Nonsmooth Sampling via Langevin Monte Carlo Algorithms</title>
      <link>https://arxiv.org/abs/2305.15988</link>
      <description>arXiv:2305.15988v2 Announce Type: replace-cross 
Abstract: We study the problem of approximate sampling from non-log-concave distributions, e.g., Gaussian mixtures, which is often challenging even in low dimensions due to their multimodality. We focus on performing this task via Markov chain Monte Carlo (MCMC) methods derived from discretizations of the overdamped Langevin diffusions, which are commonly known as Langevin Monte Carlo algorithms. Furthermore, we are also interested in two nonsmooth cases for which a large class of proximal MCMC methods have been developed: (i) a nonsmooth prior is considered with a Gaussian mixture likelihood; (ii) a Laplacian mixture distribution. Such nonsmooth and non-log-concave sampling tasks arise from a wide range of applications to Bayesian inference and imaging inverse problems such as image deconvolution. We perform numerical simulations to compare the performance of most commonly used Langevin Monte Carlo algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.15988v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tim Tsz-Kit Lau, Han Liu, Thomas Pock</dc:creator>
    </item>
    <item>
      <title>Diffusive Gibbs Sampling</title>
      <link>https://arxiv.org/abs/2402.03008</link>
      <description>arXiv:2402.03008v5 Announce Type: replace-cross 
Abstract: The inadequate mixing of conventional Markov Chain Monte Carlo (MCMC) methods for multi-modal distributions presents a significant challenge in practical applications such as Bayesian inference and molecular dynamics. Addressing this, we propose Diffusive Gibbs Sampling (DiGS), an innovative family of sampling methods designed for effective sampling from distributions characterized by distant and disconnected modes. DiGS integrates recent developments in diffusion models, leveraging Gaussian convolution to create an auxiliary noisy distribution that bridges isolated modes in the original space and applying Gibbs sampling to alternately draw samples from both spaces. A novel Metropolis-within-Gibbs scheme is proposed to enhance mixing in the denoising sampling step. DiGS exhibits a better mixing property for sampling multi-modal distributions than state-of-the-art methods such as parallel tempering, attaining substantially improved performance across various tasks, including mixtures of Gaussians, Bayesian neural networks and molecular dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.03008v5</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>stat.CO</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenlin Chen, Mingtian Zhang, Brooks Paige, Jos\'e Miguel Hern\'andez-Lobato, David Barber</dc:creator>
    </item>
  </channel>
</rss>
