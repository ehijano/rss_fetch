<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 04 Jul 2024 04:00:18 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 04 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>A Novel Approach to Image EEG Sleep Data for Improving Quality of Life in Patients Suffering From Brain Injuries Using DreamDiffusion</title>
      <link>https://arxiv.org/abs/2407.02673</link>
      <description>arXiv:2407.02673v1 Announce Type: new 
Abstract: Those experiencing strokes, traumatic brain injuries, and drug complications can often end up hospitalized and diagnosed with coma or locked-in syndrome. Such mental impediments can permanently alter the neurological pathways in work and significantly decrease the quality of life (QoL). It is critical to translate brain signals into images to gain a deeper understanding of the thoughts of a comatose patient. Traditionally, brain signals collected by an EEG could only be translated into text, but with the novel method of an open-source model available on GitHub, DreamDiffusion can be used to convert brain waves into images directly. DreamDiffusion works by extracting features from EEG signals and then using the features to create images through StableDiffusion. Upon this, we made further improvements that could make StableDiffusion the forerunner technology in waves to media translation. In our study, we begin by modifying the existing DreamDiffusion codebase so that it does not require any prior setup, avoiding any confusing steps needed to run the model from GitHub. For many researchers, the incomplete setup process, errors in the existing code, and a lack of directions made it nearly impossible to run, not even considering the model's performance. We brought the code into Google Colab so users could run and evaluate problems cell-by-cell, eliminating the specific file and repository dependencies. We also provided the original training data file so users do not need to purchase the necessary computing power to train the model from the given dataset. The second change is utilizing the mutability of the code and optimizing the model so it can be used to generate images from other given inputs, such as sleep data. Additionally, the affordability of EEG technology allows for global dissemination and creates the opportunity for those who want to work on the shared DreamDiffusion model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.02673v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>David Fahim, Joshveer Grewal, Ritvik Ellendula</dc:creator>
    </item>
    <item>
      <title>Spatio-Temporal Adaptive Diffusion Models for EEG Super-Resolution in Epilepsy Diagnosis</title>
      <link>https://arxiv.org/abs/2407.03089</link>
      <description>arXiv:2407.03089v1 Announce Type: cross 
Abstract: Electroencephalogram (EEG) technology, particularly high-density EEG (HD EEG) devices, is widely used in fields such as neuroscience. HD EEG devices improve the spatial resolution of EEG by placing more electrodes on the scalp, meeting the requirements of clinical diagnostic applications such as epilepsy focus localization. However, this technique faces challenges such as high acquisition costs and limited usage scenarios. In this paper, spatio-temporal adaptive diffusion models (STADMs) are proposed to pioneer the use of diffusion models for achieving spatial SR reconstruction from low-resolution (LR, 64 channels or fewer) EEG to high-resolution (HR, 256 channels) EEG. Specifically, a spatio-temporal condition module is designed to extract the spatio-temporal features of LR EEG, which then serve as conditional inputs to guide the reverse denoising process of diffusion models. Additionally, a multi-scale Transformer denoising module is constructed to leverage multi-scale convolution blocks and cross-attention-based diffusion Transformer blocks for conditional guidance to generate subject-adaptive SR EEG. Experimental results demonstrate that the proposed method effectively enhances the spatial resolution of LR EEG and quantitatively outperforms existing methods. Furthermore, STADMs demonstrate their value by applying synthetic SR EEG to classification and source localization tasks of epilepsy patients, indicating their potential to significantly improve the spatial resolution of LR EEG.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03089v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tong Zhou, Shuqiang Wang</dc:creator>
    </item>
    <item>
      <title>Brain waves are a repetition of a pause and an activity</title>
      <link>https://arxiv.org/abs/2205.08734</link>
      <description>arXiv:2205.08734v3 Announce Type: replace 
Abstract: Brain waves still cannot reliably distinguish between awake and asleep states. Here, I present new original indices, voltage subthreshold wave {\tau} and abovethreshold wave burst, for advanced LFP/EEG readings. Assuming that {\tau} is a microwave that fluctuates every sample such as the equipotential, the total number of {\tau} (N{\tau}) is inferred to be the maximum, and the amplitude of burst (Abst) is inferred to be the minimum. In fact, they invariably had a mean {\tau} duration (M{\tau}) of 2-3 sample intervals in any case. In addition, {\tau} and burst exhibited self-similarity for sample frequency while occupying approximately 30% and 70% of LFP in the natural state, respectively. Its threshold and Abst were correlated with the vigilance state and decreased to 70% by doubling the sample frequency. The dose of sevoflurane, which inhibits and synchronizes neural activity, was linearly correlated with decreases in the threshold and N{\tau}. Thus, {\tau} could reflect the uncertainty of the membrane potential. I propose that {\tau} and burst represent a pause and an activity such as the rhythm of the brain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2205.08734v3</guid>
      <category>q-bio.NC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Chika Koyama</dc:creator>
    </item>
    <item>
      <title>Formulation of downward causation in the brain: whole beats its parts</title>
      <link>https://arxiv.org/abs/2310.10005</link>
      <description>arXiv:2310.10005v4 Announce Type: replace 
Abstract: Downward causation is self-causation: the causal effect from the whole at the macro level to its parts at the micro level, and is regarded as a solution to the mind-body problem. However, no actual example of downward causation has not been propsed. Here, we argue that a feedback control of micro-level neural mechanisms using macro-level algebraic structure information between neural network modules that is physically composed of neurons is a model of downward causation in the brain. We speculate that downward causation causes mathematical structure in our perceptual experience by controlling algebraic structure in the brain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.10005v4</guid>
      <category>q-bio.NC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yoshiyuki Ohmura, Yasuo Kuniyoshi</dc:creator>
    </item>
    <item>
      <title>Functions of Direct and Indirect Pathways for Action Selection Are Quantitatively Analyzed in A Spiking Neural Network of The Basal Ganglia</title>
      <link>https://arxiv.org/abs/2404.13888</link>
      <description>arXiv:2404.13888v2 Announce Type: replace 
Abstract: We are concerned about action selection in the basal ganglia (BG). We quantitatively analyze functions of direct pathway (DP) and indirect pathway (IP) for action selection in a spiking neural network with 3 competing channels. For such quantitative analysis, in each channel, we obtain the competition degree ${\cal C}_d$, given by the ratio of strength of DP (${\cal S}_{DP}$) to strength of IP (${\cal S}_{IP}$) (i.e., ${\cal C}_d = {\cal S}_{DP} / {\cal S}_{IP}$). Then, a desired action is selected in the channel with the largest ${\cal C}_d$. Desired action selection is made mainly due to strong focused inhibitory projection to the output nucleus, SNr (substantia nigra pars reticulata) via the DP in the corresponding channel. Unlike the case of DP, there are two types of IPs; intra-channel IP and inter-channel IP, due to widespread diffusive excitation from the STN (subthalamic nucleus). The intra-channel IP serves a function of brake to suppress the desired action selection. In contrast, the inter-channel IP to the SNr in the neighboring channels suppresses competing actions, leading to highlight the desired action selection. In this way, function of the inter-channel IP is opposite to that of the intra-channel IP. However, to the best of our knowledge, no quantitative analysis for such functions of the DP and the two IPs was made. Here, through direct calculations of the DP and the intra- and the inter-channel IP presynaptic currents into the SNr in each channel, we obtain the competition degree of each channel to determine a desired action, and then functions of the DP and the intra- and inter-channel IPs are quantitatively made clear.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13888v2</guid>
      <category>q-bio.NC</category>
      <category>physics.bio-ph</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Sang-Yoon Kim, Woochang Lim</dc:creator>
    </item>
    <item>
      <title>Deconvolving Complex Neuronal Networks into Interpretable Task-Specific Connectomes</title>
      <link>https://arxiv.org/abs/2407.00201</link>
      <description>arXiv:2407.00201v2 Announce Type: replace 
Abstract: Task-specific functional MRI (fMRI) images provide excellent modalities for studying the neuronal basis of cognitive processes. We use fMRI data to formulate and solve the problem of deconvolving task-specific aggregate neuronal networks into a set of basic building blocks called canonical networks, to use these networks for functional characterization, and to characterize the physiological basis of these responses by mapping them to regions of the brain. Our results show excellent task-specificity of canonical networks, i.e., the expression of a small number of canonical networks can be used to accurately predict tasks; generalizability across cohorts, i.e., canonical networks are conserved across diverse populations, studies, and acquisition protocols; and that canonical networks have strong anatomical and physiological basis. From a methods perspective, the problem of identifying these canonical networks poses challenges rooted in the high dimensionality, small sample size, acquisition variability, and noise. Our deconvolution technique is based on non-negative matrix factorization (NMF) that identifies canonical networks as factors of a suitably constructed matrix. We demonstrate that our method scales to large datasets, yields stable and accurate factors, and is robust to noise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00201v2</guid>
      <category>q-bio.NC</category>
      <category>cs.LG</category>
      <category>eess.IV</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yifan Wang, Vikram Ravindra, Ananth Grama</dc:creator>
    </item>
    <item>
      <title>Neurodevelopmental disorders modeling using isogeometric analysis, dynamic domain expansion and local refinement</title>
      <link>https://arxiv.org/abs/2407.00810</link>
      <description>arXiv:2407.00810v2 Announce Type: replace 
Abstract: Neurodevelopmental disorders (NDDs) have arisen as one of the most prevailing chronic diseases within the US. Often associated with severe adverse impacts on the formation of vital central and peripheral nervous systems during the neurodevelopmental process, NDDs are comprised of a broad spectrum of disorders, such as autism spectrum disorder, attention deficit hyperactivity disorder, and epilepsy, characterized by progressive and pervasive detriments to cognitive, speech, memory, motor, and other neurological functions in patients. However, the heterogeneous nature of NDDs poses a significant roadblock to identifying the exact pathogenesis, impeding accurate diagnosis and the development of targeted treatment planning. A computational NDDs model holds immense potential in enhancing our understanding of the multifaceted factors involved and could assist in identifying the root causes to expedite treatment development. To tackle this challenge, we introduce optimal neurotrophin concentration to the driving force and degradation of neurotrophin to the synaptogenesis process of a 2D phase field neuron growth model using isogeometric analysis to simulate neurite retraction and atrophy. The optimal neurotrophin concentration effectively captures the inverse relationship between neurotrophin levels and neurite survival, while its degradation regulates concentration levels. Leveraging dynamic domain expansion, the model efficiently expands the domain based on outgrowth patterns to minimize degrees of freedom. Based on truncated T-splines, our model simulates the evolving process of complex neurite structures by applying local refinement adaptively to the cell/neurite boundary. Furthermore, a thorough parameter investigation is conducted with detailed comparisons against neuron cell cultures in experiments, enhancing our fundamental understanding of the mechanisms underlying NDDs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00810v2</guid>
      <category>q-bio.NC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kuanren Qian, Genesis Omana Suarez, Toshihiko Nambara, Takahisa Kanekiyo, Ashlee S. Liao, Victoria A. Webster-Wood, Yongjie Jessica Zhang</dc:creator>
    </item>
    <item>
      <title>Discontinuous transition to chaos in a canonical random neural network</title>
      <link>https://arxiv.org/abs/2405.14607</link>
      <description>arXiv:2405.14607v3 Announce Type: replace-cross 
Abstract: We study a paradigmatic random recurrent neural network introduced by Sompolinsky, Crisanti, and Sommers (SCS). In the infinite size limit, this system exhibits a direct transition from a homogeneous rest state to chaotic behavior, with the Lyapunov exponent gradually increasing from zero. We generalize the SCS model considering odd saturating nonlinear transfer functions, beyond the usual choice $\phi(x)=\tanh x$. A discontinuous transition to chaos occurs whenever the slope of $\phi$ at 0 is a local minimum (i.e., for $\phi'''(0)&gt;0$). Chaos appears out of the blue, by an attractor-repeller fold. Accordingly, the Lyapunov exponent stays away from zero at the birth of chaos.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14607v3</guid>
      <category>nlin.CD</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1103/PhysRevE.110.014201</arxiv:DOI>
      <arxiv:journal_reference>Phys. Rev. E 110, 014201 (2024)</arxiv:journal_reference>
      <dc:creator>Diego Paz\'o</dc:creator>
    </item>
  </channel>
</rss>
