<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.AP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.AP</link>
    <description>stat.AP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.AP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 30 Jul 2025 04:01:49 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Predicting VBAC Outcomes from U.S. Natality Data using Deep and Classical Machine Learning Models</title>
      <link>https://arxiv.org/abs/2507.21330</link>
      <description>arXiv:2507.21330v1 Announce Type: new 
Abstract: Accurately predicting the outcome of a trial of labor after cesarean (TOLAC) is essential for guiding prenatal counseling and minimizing delivery-related risks. This study presents supervised machine learning models for predicting vaginal birth after cesarean (VBAC) using 643,029 TOLAC cases from the CDC WONDER Natality dataset (2017-2023). After filtering for singleton births with one or two prior cesareans and complete data across 47 prenatal-period features, three classifiers were trained: logistic regression, XGBoost, and a multilayer perceptron (MLP). The MLP achieved the highest performance with an AUC of 0.7287, followed closely by XGBoost (AUC = 0.727), both surpassing the logistic regression baseline (AUC = 0.709). To address class imbalance, class weighting was applied to the MLP, and a custom loss function was implemented in XGBoost. Evaluation metrics included ROC curves, confusion matrices, and precision-recall analysis. Logistic regression coefficients highlighted maternal BMI, education, parity, comorbidities, and prenatal care indicators as key predictors. Overall, the results demonstrate that routinely collected, early-pregnancy variables can support scalable and moderately high-performing VBAC prediction models. These models offer potential utility in clinical decision support, particularly in settings lacking access to specialized intrapartum data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.21330v1</guid>
      <category>stat.AP</category>
      <category>cs.LG</category>
      <pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ananya Anand</dc:creator>
    </item>
    <item>
      <title>A Bayesian Ensemble Projection of Climate Change and Technological Impacts on Future Crop Yields</title>
      <link>https://arxiv.org/abs/2507.21559</link>
      <description>arXiv:2507.21559v1 Announce Type: new 
Abstract: This paper introduces a Bayesian hierarchical modeling framework within a fully probabilistic setting for crop yield estimation, model selection, and uncertainty forecasting under multiple future greenhouse gas emission scenarios. By informing on regional agricultural impacts, this approach addresses broader risks to global food security. Extending an established multivariate econometric crop-yield model to incorporate country-specific error variances, the framework systematically relaxes restrictive homogeneity assumptions and enables transparent decomposition of predictive uncertainty into contributions from climate models, emission scenarios, and crop model parameters. In both in-sample and out-of-sample analyses focused on global wheat production, the results demonstrate significant improvements in calibration and probabilistic accuracy of yield projections. These advances provide policymakers and stakeholders with detailed, risk-sensitive information to support the development of more resilient and adaptive agricultural and climate strategies in response to escalating climate-related risks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.21559v1</guid>
      <category>stat.AP</category>
      <category>econ.EM</category>
      <pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dan Li, Vassili Kitsios, David Newth, Terence John O'Kane</dc:creator>
    </item>
    <item>
      <title>Domain Generalization and Adaptation in Intensive Care with Anchor Regression</title>
      <link>https://arxiv.org/abs/2507.21783</link>
      <description>arXiv:2507.21783v1 Announce Type: new 
Abstract: The performance of predictive models in clinical settings often degrades when deployed in new hospitals due to distribution shifts. This paper presents a large-scale study of causality-inspired domain generalization on heterogeneous multi-center intensive care unit (ICU) data. We apply anchor regression and introduce anchor boosting, a novel, tree-based nonlinear extension, to a large dataset comprising 400,000 patients from nine distinct ICU databases. The anchor regularization consistently improves out-of-distribution performance, particularly for the most dissimilar target domains. The methods appear robust to violations of theoretical assumptions, such as anchor exogeneity. Furthermore, we propose a novel conceptual framework to quantify the utility of large external data datasets. By evaluating performance as a function of available target-domain data, we identify three regimes: (i) a domain generalization regime, where only the external model should be used, (ii) a domain adaptation regime, where refitting the external model is optimal, and (iii) a data-rich regime, where external data provides no additional value.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.21783v1</guid>
      <category>stat.AP</category>
      <category>cs.LG</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Malte Londschien, Manuel Burger, Gunnar R\"atsch, Peter B\"uhlmann</dc:creator>
    </item>
    <item>
      <title>Uncertainty Estimation of the Optimal Decision with Application to Cure Process Optimization</title>
      <link>https://arxiv.org/abs/2507.21995</link>
      <description>arXiv:2507.21995v1 Announce Type: new 
Abstract: Decision-making in manufacturing often involves optimizing key process parameters using data collected from simulation experiments. Gaussian processes are widely used to surrogate the underlying system and guide optimization. Uncertainty often inherent in the decisions given by the surrogate model due to limited data and model assumptions. This paper proposes a surrogate model-based framework for estimating the uncertainty of optimal decisions and analyzing its sensitivity with respect to the objective function. The proposed approach is applied to the composite cure process simulation in manufacturing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.21995v1</guid>
      <category>stat.AP</category>
      <pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yezhuo Li, Qiong Zhang, Madhura Limaye, Gang Li</dc:creator>
    </item>
    <item>
      <title>NIST Post-Quantum Cryptography Standard Algorithms Based on Quantum Random Number Generators</title>
      <link>https://arxiv.org/abs/2507.21151</link>
      <description>arXiv:2507.21151v1 Announce Type: cross 
Abstract: In recent years, the advancement of quantum computing technology has posed potential security threats to RSA cryptography and elliptic curve cryptography. In response, the National Institute of Standards and Technology (NIST) published several Federal Information Processing Standards (FIPS) of post-quantum cryptography (PQC) in August 2024, including the Module-Lattice-Based Key-Encapsulation Mechanism (ML-KEM), Module-Lattice-Based Digital Signature Algorithm (ML-DSA), and Stateless Hash-Based Digital Signature Algorithm (SLH-DSA). Although these PQC algorithms are designed to resist quantum computing attacks, they may not provide adequate security in certain specialized application scenarios. To address this issue, this study proposes quantum random number generator (QRNG)-based PQC algorithms. These algorithms leverage quantum computing to generate random numbers, which serve as the foundation for key pair generation, key encapsulation, and digital signature generation. A generalized architecture of QRNG is proposed, along with the design of six QRNGs. Each generator is evaluated according to the statistical validation procedures outlined in NIST SP 800-90B, including tests for verification of entropy sources and independent and identically distributed (IID) outputs. Experimental results assess the computation time of the six QRNGs, as well as the performance of QRNG-based ML-KEM, QRNG-based ML-DSA, and QRNG-based SLH-DSA. These findings provide valuable reference data for future deployment of PQC systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.21151v1</guid>
      <category>cs.CR</category>
      <category>cs.PF</category>
      <category>quant-ph</category>
      <category>stat.AP</category>
      <pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Abel C. H. Chen</dc:creator>
    </item>
    <item>
      <title>An empirical comparison of some outlier detection methods with longitudinal data</title>
      <link>https://arxiv.org/abs/2507.21203</link>
      <description>arXiv:2507.21203v1 Announce Type: cross 
Abstract: This note investigates the problem of detecting outliers in longitudinal data. It compares well-known methods used in official statistics with proposals from the fields of data mining and machine learning that are based on the distance between observations or binary partitioning trees. This is achieved by applying the methods to panel survey data related to different types of statistical units. Traditional methods are quite simple, enabling the direct identification of potential outliers, but they require specific assumptions. In contrast, recent methods provide only a score whose magnitude is directly related to the likelihood of an outlier being present. All the methods require the user to set a number of tuning parameters. However, the most recent methods are more flexible and sometimes more effective than traditional methods. In addition, these methods can be applied to multidimensional data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.21203v1</guid>
      <category>stat.ME</category>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Marcello D'Orazio</dc:creator>
    </item>
    <item>
      <title>Exploring the Interplay of Adiposity, Ethnicity, and Hormone Receptor Profiles in Breast Cancer Subtypes</title>
      <link>https://arxiv.org/abs/2507.21348</link>
      <description>arXiv:2507.21348v1 Announce Type: cross 
Abstract: This study explores how obesity and race jointly influence the development and prognosis of Luminal subtypes of breast cancer, with a focus on distinguishing Luminal A from the more aggressive Luminal B tumors. Drawing on large-scale epidemiological data and employing statistical approaches such as logistic regression and mediation analysis, the research examines biological factors like estrogen metabolism, adipokines, and chronic inflammation alongside social determinants including healthcare access, socioeconomic status, and cultural attitudes toward body weight. The findings reveal that both obesity and racial background are significant predictors of risk for Luminal B breast cancers. The study highlights the need for a dual approach that combines medical treatment with targeted social interventions aimed at reducing disparities. These insights can improve individualized risk assessments, guide tailored screening programs, and support policies that address the heightened cancer burden experienced by marginalized communities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.21348v1</guid>
      <category>q-bio.QM</category>
      <category>stat.AP</category>
      <pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Izabel Valdez, Paramahansa Pramanik</dc:creator>
    </item>
    <item>
      <title>Distributed Iterative ML and Message Passing for Grant-Free Cell-Free Massive MIMO Systems</title>
      <link>https://arxiv.org/abs/2507.21363</link>
      <description>arXiv:2507.21363v1 Announce Type: cross 
Abstract: Cell-Free (CF) Massive Multiple-Input Multiple-Output (MaMIMO) is considered one of the leading candidates for enabling next-generation wireless communication. With the growing interest in the Internet of Things (IoT), the Grant-Free (GF) access scheme has emerged as a promising solution to support massive device connectivity. The integration of GF and CF-MaMIMO introduces significant challenges, particularly in designing distributed algorithms for activity detection and pilot contamination mitigation. In this paper, we propose a distributed algorithm that addresses these challenges. Our method first employs a component-wise iterative distributed Maximum Likelihood (ML) approach for activity detection, which considers both the pilot and data portions of the received signal. This is followed by a Pseudo-Prior Hybrid Variational Bayes and Expectation Propagation (PP-VB-EP) algorithm for joint data detection and channel estimation. Compared to conventional VB-EP, the proposed PP-VB-EP demonstrates improved convergence behavior and reduced sensitivity to initialization, especially when data symbols are drawn from a finite alphabet. The pseudo prior used in PP-VB-EP acts as an approximated posterior and serves as a regularization term that prevents the Message Passing (MP) algorithm from diverging. To compute the pseudo prior in a distributed fashion, we further develop a distributed version of the Variable-Level Expectation Propagation (VL-EP) algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.21363v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <category>stat.AP</category>
      <pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Zilu Zhao, Christian Forsch, Laura Cottatellucci, Dirk Slock</dc:creator>
    </item>
    <item>
      <title>Multivariate Spatio-temporal Modelling for Completing Cancer Registries and Forecasting Incidence</title>
      <link>https://arxiv.org/abs/2507.21714</link>
      <description>arXiv:2507.21714v1 Announce Type: cross 
Abstract: Cancer data, particularly cancer incidence and mortality, are fundamental to understand the cancer burden, to set targets for cancer control and to evaluate the evolution of the implementation of a cancer control policy. However, the complexity of data collection, classification, validation and processing result in cancer incidence figures often lagging two to three years behind the calendar year. In response, national or regional population-based cancer registries (PBCRs) are increasingly interested in methods for forecasting cancer incidence. However, in many countries there is an additional difficulty in projecting cancer incidence as regional registries are usually not established in the same year and therefore cancer incidence data series between different regions of a country are not harmonised over time. This study addresses the challenge of forecasting cancer incidence with incomplete data at both regional and national levels. To achieve our objective, we propose the use of multivariate spatio-temporal shared component models that jointly model mortality data and available cancer incidence data. The performance of these multivariate models are analyzed using lung cancer incidence data, together with the number of deaths reported in England in the period 2001-2019. Different model predictive measures have been calculated to select the best model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.21714v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Garazi Retegui, Jaione Etxeberria, Mar\'ia Dolores Ugarte</dc:creator>
    </item>
    <item>
      <title>Towards a rigorous evaluation of RAG systems: the challenge of due diligence</title>
      <link>https://arxiv.org/abs/2507.21753</link>
      <description>arXiv:2507.21753v1 Announce Type: cross 
Abstract: The rise of generative AI, has driven significant advancements in high-risk sectors like healthcare and finance. The Retrieval-Augmented Generation (RAG) architecture, combining language models (LLMs) with search engines, is particularly notable for its ability to generate responses from document corpora. Despite its potential, the reliability of RAG systems in critical contexts remains a concern, with issues such as hallucinations persisting. This study evaluates a RAG system used in due diligence for an investment fund. We propose a robust evaluation protocol combining human annotations and LLM-Judge annotations to identify system failures, like hallucinations, off-topic, failed citations, and abstentions. Inspired by the Prediction Powered Inference (PPI) method, we achieve precise performance measurements with statistical guarantees. We provide a comprehensive dataset for further analysis. Our contributions aim to enhance the reliability and scalability of RAG systems evaluation protocols in industrial applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.21753v1</guid>
      <category>cs.AI</category>
      <category>stat.AP</category>
      <pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gr\'egoire Martinon (ENSIIE, LaMME), Alexandra Lorenzo de Brionne (ENSIIE, LaMME), J\'er\^ome Bohard (ENSIIE, LaMME), Antoine Lojou (ENSIIE, LaMME), Damien Hervault (ENSIIE, LaMME), Nicolas J-B. Brunel (ENSIIE, LaMME)</dc:creator>
    </item>
    <item>
      <title>Nonlinear Treatment Effects in Shift-Share Designs</title>
      <link>https://arxiv.org/abs/2507.21915</link>
      <description>arXiv:2507.21915v1 Announce Type: cross 
Abstract: We analyze heterogenous, nonlinear treatment effects in shift-share designs with exogenous shares. We employ a triangular model and correct for treatment endogeneity using a control function. Our tools identify four target parameters. Two of them capture the observable heterogeneity of treatment effects, while one summarizes this heterogeneity in a single measure. The last parameter analyzes counterfactual, policy-relevant treatment assignment mechanisms. We propose flexible parametric estimators for these parameters and apply them to reevaluate the impact of Chinese imports on U.S. manufacturing employment. Our results highlight substantial treatment effect heterogeneity, which is not captured by commonly used shift-share tools.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.21915v1</guid>
      <category>econ.EM</category>
      <category>stat.AP</category>
      <pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Luigi Garzon, Vitor Possebom</dc:creator>
    </item>
    <item>
      <title>Backward Joint Model for the Joint Dynamic Prediction of Time-to-Event and Longitudinal Data: Basic Formulation and New Developments</title>
      <link>https://arxiv.org/abs/2311.00878</link>
      <description>arXiv:2311.00878v3 Announce Type: replace-cross 
Abstract: Dynamic prediction of future clinical outcomes based on longitudinally measured predictors plays a crucial role in disease management and patient counseling, particularly when conventional static models are inadequate. Joint modeling of longitudinal and time-to-event data provides a useful framework for addressing this challenge. In this paper, we present a comprehensive development of the recently proposed backward joint model (BJM; Shen and Li 2021}, which factorizes the likelihood into the distribution of time-to-event data and the conditional distribution of longitudinal data given the event time. This structure facilitates computation and is well-suited for multivariate longitudinal data. We introduce several novel developments to the BJM, including the extrapolation and two-part specifications, as well as the incorporation of competing risks. We also address an important yet underexplored problem in the literature: predicting future longitudinal trajectories conditional on predicted event times. Additionally, we explore the connection between BJM and existing joint modeling approaches. All these extensions preserve the computational advantages of the basic BJM formulation, including one-dimensional numerical integration, convex optimization via the EM algorithm, and a quick procedure for consistent estimation using standard software. We evaluate the method's performance through simulation studies and illustrate its utility in a chronic kidney disease application.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.00878v3</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wenhao Li, Shikun Wang, Zhe Yin, Brad C. Astor, Wei Yang, Tom H. Greene, Liang Li</dc:creator>
    </item>
    <item>
      <title>A dimension reduction approach to edge weight estimation for use in spatial models</title>
      <link>https://arxiv.org/abs/2407.02684</link>
      <description>arXiv:2407.02684v2 Announce Type: replace-cross 
Abstract: Models for areal data are traditionally defined using the neighborhood structure of the regions on which data are observed. The unweighted adjacency matrix of a graph is commonly used to characterize the relationships between locations, resulting in the implicit assumption that all pairs of neighboring regions interact similarly, an assumption which may not be true in practice. It has been shown that more complex spatial relationships between graph nodes may be represented when edge weights are allowed to vary. Christensen and Hoff (2023) introduced a covariance model for data observed on graphs which is more flexible than traditional alternatives, parameterizing covariance as a function of an unknown edge weights matrix. A potential issue with their approach is that each edge weight is treated as a unique parameter, resulting in increasingly challenging parameter estimation as graph size increases. Within this article we propose a framework for estimating edge weight matrices that reduces their effective dimension via a basis function representation of of the edge weights. We show that this method may be used to enhance the performance and flexibility of covariance models parameterized by such matrices in a series of illustrations, simulations and data examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.02684v2</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael F. Christensen, Jo Eidsvik</dc:creator>
    </item>
    <item>
      <title>Robust Estimation of Polychoric Correlation</title>
      <link>https://arxiv.org/abs/2407.18835</link>
      <description>arXiv:2407.18835v4 Announce Type: replace-cross 
Abstract: Polychoric correlation is often an important building block in the analysis of rating data, particularly for structural equation models. However, the commonly employed maximum likelihood (ML) estimator is highly susceptible to misspecification of the polychoric correlation model, for instance through violations of latent normality assumptions. We propose a novel estimator that is designed to be robust against partial misspecification of the polychoric model, that is, when the model is misspecified for an unknown fraction of observations, such as careless respondents. To this end, the estimator minimizes a robust loss function based on the divergence between observed frequencies and theoretical frequencies implied by the polychoric model. In contrast to existing literature, our estimator makes no assumption on the type or degree of model misspecification. It furthermore generalizes ML estimation, is consistent as well as asymptotically normally distributed, and comes at no additional computational cost. We demonstrate the robustness and practical usefulness of our estimator in simulation studies and an empirical application on a Big Five administration. In the latter, the polychoric correlation estimates of our estimator and ML differ substantially, which, after further inspection, is likely due to the presence of careless respondents that the estimator helps identify.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18835v4</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.OT</category>
      <category>stat.TH</category>
      <pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Max Welz, Patrick Mair, Andreas Alfons</dc:creator>
    </item>
    <item>
      <title>Causal Inference for Circular Data</title>
      <link>https://arxiv.org/abs/2507.19889</link>
      <description>arXiv:2507.19889v2 Announce Type: replace-cross 
Abstract: In causal inference, a fundamental task is to estimate the effect resulting from a specific treatment, which is often handled with inverse probability weighting. Despite an abundance of attention to the advancement of this task, most articles have focused on linear data rather than circular data, which are measured in angles. In this article, we extend the causal inference framework to accommodate circular data. Specifically, two new treatment effects, average direction treatment effect (ADTE) and average length treatment effect (ALTE), are introduced to offer a proper causal explanation for these data. As the average direction and average length describe the location and concentration of a random sample of circular data, the ADTE and ALTE measure the change in direction and length between two counterfactual outcomes. With inverse probability weighting, we propose estimators that exhibit ideal theoretical properties, which are validated by a simulation study. To illustrate the practical utility of our estimator, we analyze the effect of different job types on dispatchers' sleep patterns using data from Federal Railroad Administration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.19889v2</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kuan-Hsun Wu</dc:creator>
    </item>
  </channel>
</rss>
