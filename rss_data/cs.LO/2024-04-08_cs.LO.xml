<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.LO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.LO</link>
    <description>cs.LO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.LO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 08 Apr 2024 04:00:08 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 08 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Proceedings 12th International Workshop on Theorem proving components for Educational software</title>
      <link>https://arxiv.org/abs/2404.03709</link>
      <description>arXiv:2404.03709v1 Announce Type: new 
Abstract: The ThEdu series pursues the smooth transition from an intuitive way of doing mathematics at secondary school to a more formal approach to the subject in STEM education, while favouring software support for this transition by exploiting the power of theorem-proving technologies. What follows is a brief description of how the present volume contributes to this enterprise.
  The 12th International Workshop on Theorem Proving Components for Educational Software(ThEdu'23), was a satellite event of the 29th international Conference on Automated Deduction (CADE 2023), July 1-4, 2023, Rome, Italy. ThEdu'23 was very successful, with one invited talk, by Yves Bertot (Inria, France), "The challenges of using Type Theory to teach Mathematics", and seven regular contributions. An open call  for papers was then issued, to which eight contributions were submitted. Seven submissions have been accepted by our reviewers, who jointly produced at least three careful reports on each of the contributions. The resulting revised papers are collected in the present volume.
  We, the volume editors, hope that this collection of papers will further promote the development of theorem-proving based software, and that it will allow to improve the mutual understanding between computer scientists, mathematicians and stakeholders in education.
  PC Chairs:Julien Narboux (University of Strasbourg, France); Walther Neuper (JKU, Johannes Kepler University, Linz, Austria); Pedro Quaresma (University of Coimbra, Portugal)</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03709v1</guid>
      <category>cs.LO</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.400</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 400, 2024</arxiv:journal_reference>
      <dc:creator>Julien Narboux (University of Strasbourg, France), Walther Neuper (JKU, Johannes Kepler University), Pedro Quaresma (University of Coimbra, Portugal)</dc:creator>
    </item>
    <item>
      <title>A Reinforcement Learning based Reset Policy for CDCL SAT Solvers</title>
      <link>https://arxiv.org/abs/2404.03753</link>
      <description>arXiv:2404.03753v1 Announce Type: new 
Abstract: Restart policy is an important technique used in modern Conflict-Driven Clause Learning (CDCL) solvers, wherein some parts of the solver state are erased at certain intervals during the run of the solver. In most solvers, variable activities are preserved across restart boundaries, resulting in solvers continuing to search parts of the assignment tree that are not far from the one immediately prior to a restart. To enable the solver to search possibly "distant" parts of the assignment tree, we study the effect of resets, a variant of restarts which not only erases the assignment trail, but also randomizes the activity scores of the variables of the input formula after reset, thus potentially enabling a better global exploration of the search space.
  In this paper, we model the problem of whether to trigger reset as a multi-armed bandit (MAB) problem, and propose two reinforcement learning (RL) based adaptive reset policies using the Upper Confidence Bound (UCB) and Thompson sampling algorithms. These two algorithms balance the exploration-exploitation tradeoff by adaptively choosing arms (reset vs. no reset) based on their estimated rewards during the solver's run. We implement our reset policies in four baseline SOTA CDCL solvers and compare the baselines against the reset versions on Satcoin benchmarks and SAT Competition instances. Our results show that RL-based reset versions outperform the corresponding baseline solvers on both Satcoin and the SAT competition instances, suggesting that our RL policy helps to dynamically and profitably adapt the reset frequency for any given input instance. We also introduce the concept of a partial reset, where at least a constant number of variable activities are retained across reset boundaries. Building on previous results, we show that there is an exponential separation between O(1) vs. $\Omega(n)$-length partial resets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03753v1</guid>
      <category>cs.LO</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chunxiao Li (John), Charlie Liu (John), Jonathan Chung (John),  Zhengyang (John),  Lu, Piyush Jha, Vijay Ganesh</dc:creator>
    </item>
    <item>
      <title>Parametricity via Cohesion</title>
      <link>https://arxiv.org/abs/2404.03825</link>
      <description>arXiv:2404.03825v1 Announce Type: new 
Abstract: Parametricity is a key metatheoretic property of type systems, which implies strong uniformity &amp; modularity properties of the structure of types within systems possessing it. In recent years, various systems of dependent type theory have emerged with the aim of expressing such parametric reasoning in their internal logic, toward the end of solving various problems arising from the complexity of higher-dimensional coherence conditions in type theory. This paper presents a first step toward the unification, simplification, and extension of these various methods for internalizing parametricity. Specifically, I argue that there is an essentially modal aspect of parametricity, which is intimately connected with the category-theoretic concept of cohesion. On this basis, I describe a general categorical semantics for modal parametricity, develop a corresponding framework of axioms (with computational interpretations) in dependent type theory that can be used to internally represent and reason about such parametricity, and show this in practice by implementing these axioms in Agda and using them to verify parametricity theorems therein. I then demonstrate the utility of these axioms in managing the complexity of higher-dimensional coherence by deriving induction principles for higher inductive types, and in closing, I sketch the outlines of a more general synthetic theory of parametricity, with applications in domains ranging from homotopy type theory to the analysis of program modules.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03825v1</guid>
      <category>cs.LO</category>
      <category>cs.PL</category>
      <category>math.CT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>C. B. Aberl\'e</dc:creator>
    </item>
    <item>
      <title>Implicit automata in {\lambda}-calculi III: affine planar string-to-string functions</title>
      <link>https://arxiv.org/abs/2404.03985</link>
      <description>arXiv:2404.03985v1 Announce Type: new 
Abstract: We prove a characterization of first-order string-to-string transduction via $\lambda$-terms typed in non-commutative affine logic that compute with Church encoding, extending the analogous known characterization of star-free languages. We show that every first-order transduction can be computed by a $\lambda$-term using a known Krohn-Rhodes-style decomposition lemma. The converse direction is given by compiling $\lambda$-terms into two-way reversible planar transducers. The soundness of this translation involves showing that the transition functions of those transducers live in a monoidal closed category of diagrams in which we can interpret purely affine $\lambda$-terms. One challenge is that the unit of the tensor of the category in question is not a terminal object. As a result, our interpretation does not identify $\beta$-equivalent terms, but it does turn $\beta$-reductions into inequalities in a poset-enrichment of the category of diagrams.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03985v1</guid>
      <category>cs.LO</category>
      <category>cs.FL</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>C\'ecilia Pradic, Ian Price</dc:creator>
    </item>
    <item>
      <title>Refutability as Recursive as Provability</title>
      <link>https://arxiv.org/abs/2404.04038</link>
      <description>arXiv:2404.04038v1 Announce Type: new 
Abstract: Godel numbering is an arithmetization of sintax which defines provability by coding a primitive recursive predicate, Pf(x,v). A multiplicity of researches and results all around this well-known recursive predicate are today widespread in many areas of logic and AI. Not equally investigated is the refutability predicate defined by Godel numbering within the same primitive recursive status. Rf(x,v) can be defined as a recursive predicate meaning that x is the Godel number of a refutation in PA of the formula with Godel number v. This article proposes a logical investigation of the interactive links between provability and refutability predicates when defined within the same recursive status. The resulting Lemmas are clarifying and open new perspectives for the incompleteness argument and the codings of its underlying notions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.04038v1</guid>
      <category>cs.LO</category>
      <category>math.LO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Paola Cattabriga</dc:creator>
    </item>
    <item>
      <title>A note on Turing's 1936</title>
      <link>https://arxiv.org/abs/1308.0497</link>
      <description>arXiv:1308.0497v3 Announce Type: cross 
Abstract: To a close reading of the original Turing article of 1936, we can learn it is based on the claim to have defined a number which is not computable, arguing that there can be no machine computing the diagonal on the enumeration of the computable sequences. This article carefully analyses the original 1936 argument, displaying how it cannot be considered a demonstration, and that there is indeed no evidence of such a defined number that is not computable.</description>
      <guid isPermaLink="false">oai:arXiv.org:1308.0497v3</guid>
      <category>cs.CC</category>
      <category>cs.LO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Paola Cattabriga</dc:creator>
    </item>
    <item>
      <title>$\Pi_{2}^{P}$ vs PSpace Dichotomy for the Quantified Constraint Satisfaction Problem</title>
      <link>https://arxiv.org/abs/2404.03844</link>
      <description>arXiv:2404.03844v1 Announce Type: cross 
Abstract: The Quantified Constraint Satisfaction Problem is the problem of evaluating a sentence with both quantifiers, over relations from some constraint language, with conjunction as the only connective. We show that for any constraint language on a finite domain the Quantified Constraint Satisfaction Problem is either in $\Pi_{2}^{P}$, or PSpace-complete. Additionally, we build a constraint language on a 6-element domain such that the Quantified Constraint Satisfaction Problem over this language is $\Pi_{2}^{P}$-complete.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03844v1</guid>
      <category>cs.CC</category>
      <category>cs.LO</category>
      <category>math.LO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dmitriy Zhuk</dc:creator>
    </item>
    <item>
      <title>Large language models as oracles for instantiating ontologies with domain-specific knowledge</title>
      <link>https://arxiv.org/abs/2404.04108</link>
      <description>arXiv:2404.04108v1 Announce Type: cross 
Abstract: Background. Endowing intelligent systems with semantic data commonly requires designing and instantiating ontologies with domain-specific knowledge. Especially in the early phases, those activities are typically performed manually by human experts possibly leveraging on their own experience. The resulting process is therefore time-consuming, error-prone, and often biased by the personal background of the ontology designer. Objective. To mitigate that issue, we propose a novel domain-independent approach to automatically instantiate ontologies with domain-specific knowledge, by leveraging on large language models (LLMs) as oracles. Method. Starting from (i) an initial schema composed by inter-related classes andproperties and (ii) a set of query templates, our method queries the LLM multi- ple times, and generates instances for both classes and properties from its replies. Thus, the ontology is automatically filled with domain-specific knowledge, compliant to the initial schema. As a result, the ontology is quickly and automatically enriched with manifold instances, which experts may consider to keep, adjust, discard, or complement according to their own needs and expertise. Contribution. We formalise our method in general way and instantiate it over various LLMs, as well as on a concrete case study. We report experiments rooted in the nutritional domain where an ontology of food meals and their ingredients is semi-automatically instantiated from scratch, starting from a categorisation of meals and their relationships. There, we analyse the quality of the generated ontologies and compare ontologies attained by exploiting different LLMs. Finally, we provide a SWOT analysis of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.04108v1</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.IR</category>
      <category>cs.LG</category>
      <category>cs.LO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Giovanni Ciatto, Andrea Agiollo, Matteo Magnini, Andrea Omicini</dc:creator>
    </item>
    <item>
      <title>Positivity-hardness results on Markov decision processes</title>
      <link>https://arxiv.org/abs/2302.13675</link>
      <description>arXiv:2302.13675v2 Announce Type: replace 
Abstract: This paper investigates a series of optimization problems for one-counter Markov decision processes (MDPs) and integer-weighted MDPs with finite state space. Specifically, it considers problems addressing termination probabilities and expected termination times for one-counter MDPs, as well as satisfaction probabilities of energy objectives, conditional and partial expectations, satisfaction probabilities of constraints on the total accumulated weight, the computation of quantiles for the accumulated weight, and the conditional value-at-risk for accumulated weights for integer-weighted MDPs. Although algorithmic results are available for some special instances, the decidability status of the decision versions of these problems is unknown in general. The paper demonstrates that these optimization problems are inherently mathematically difficult by providing polynomial-time reductions from the Positivity problem for linear recurrence sequences. This problem is a well-known number-theoretic problem whose decidability status has been open for decades and it is known that decidability of the Positivity problem would have far-reaching consequences in analytic number theory. So, the reductions presented in the paper show that an algorithmic solution to any of the investigated problems is not possible without a major breakthrough in analytic number theory. The reductions rely on the construction of MDP-gadgets that encode the initial values and linear recurrence relations of linear recurrence sequences. These gadgets can flexibly be adjusted to prove the various Positivity-hardness results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.13675v2</guid>
      <category>cs.LO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.46298/theoretics.24.9</arxiv:DOI>
      <arxiv:journal_reference>TheoretiCS, Volume 3 (2024), Article 9, 1-47</arxiv:journal_reference>
      <dc:creator>Jakob Piribauer, Christel Baier</dc:creator>
    </item>
    <item>
      <title>Object-Centric Conformance Alignments with Synchronization (Extended Version)</title>
      <link>https://arxiv.org/abs/2312.08537</link>
      <description>arXiv:2312.08537v2 Announce Type: replace 
Abstract: Real-world processes operate on objects that are inter-dependent. To accurately reflect the nature of such processes, object-centric process mining techniques are needed, notably conformance checking. However, while the object-centric perspective has recently gained traction, few concrete process mining techniques have been presented so far. Moreover, existing approaches are severely limited in their abilities to keep track of object identity and object dependencies. Consequently, serious problems in logs remain undetected. In this paper, we present a new formalism that combines the key modelling features of two existing approaches, in particular the ability of object-centric Petri nets to capture one-to-many relations and the one of Petri nets with identifiers to compare and synchronize objects based on their identity. We call the resulting formalism 'object-centric Petri nets with identifiers', and define alignments and the conformance checking task for this setting. We propose a conformance checking approach for such nets based on an encoding in satisfiability modulo theories (SMT), and illustrate how it can be effectively used to overcome shortcomings of earlier work. To assess its practicality, we perform an evaluation on data from the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.08537v2</guid>
      <category>cs.LO</category>
      <category>cs.AI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alessandro Gianola, Marco Montali, Sarah Winkler</dc:creator>
    </item>
    <item>
      <title>A rewriting-logic-with-SMT-based formal analysis and parameter synthesis framework for parametric time Petri nets</title>
      <link>https://arxiv.org/abs/2401.01884</link>
      <description>arXiv:2401.01884v2 Announce Type: replace 
Abstract: This paper presents a concrete and a symbolic rewriting logic semantics for parametric time Petri nets with inhibitor arcs (PITPNs), a flexible model of timed systems where parameters are allowed in firing bounds. We prove that our semantics is bisimilar to the "standard" semantics of PITPNs. This allows us to use the rewriting logic tool Maude, combined with SMT solving, to provide sound and complete formal analyses for PITPNs. We develop and implement a new general folding approach for symbolic reachability, so that Maude-with-SMT reachability analysis terminates whenever the parametric state-class graph of the PITPN is finite. Our work opens up the possibility of using the many formal analysis capabilities of Maude -- including full LTL model checking, analysis with user-defined analysis strategies, and even statistical model checking -- for such nets. We illustrate this by explaining how almost all formal analysis and parameter synthesis methods supported by the state-of-the-art PITPN tool Romeo can be performed using Maude with SMT. In addition, we also support analysis and parameter synthesis from parametric initial markings, as well as full LTL model checking and analysis with user-defined execution strategies. Experiments show that our methods outperform Romeo in many cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.01884v2</guid>
      <category>cs.LO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jaime Arias, Kyungmin Bae, Carlos Olarte, Peter Csaba \"Olveczky, Laure Petrucci</dc:creator>
    </item>
    <item>
      <title>DRAT Proofs of Unsatisfiability for SAT Modulo Monotonic Theories</title>
      <link>https://arxiv.org/abs/2401.10703</link>
      <description>arXiv:2401.10703v2 Announce Type: replace 
Abstract: Generating proofs of unsatisfiability is a valuable capability of most SAT solvers, and is an active area of research for SMT solvers. This paper introduces the first method to efficiently generate proofs of unsatisfiability specifically for an important subset of SMT: SAT Modulo Monotonic Theories (SMMT), which includes many useful finite-domain theories (e.g., bit vectors and many graph-theoretic properties) and is used in production at Amazon Web Services. Our method uses propositional definitions of the theory predicates, from which it generates compact Horn approximations of the definitions, which lead to efficient DRAT proofs, leveraging the large investment the SAT community has made in DRAT. In experiments on practical SMMT problems, our proof generation overhead is minimal (7.41% geometric mean slowdown, 28.8% worst-case), and we can generate and check proofs for many problems that were previously intractable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.10703v2</guid>
      <category>cs.LO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nick Feng, Alan J. Hu, Sam Bayless, Syed M. Iqbal, Patrick Trentin, Mike Whalen, Lee Pike, John Backes</dc:creator>
    </item>
    <item>
      <title>Control-Flow Refinement for Probabilistic Programs in KoAT</title>
      <link>https://arxiv.org/abs/2402.03891</link>
      <description>arXiv:2402.03891v2 Announce Type: replace 
Abstract: Recently, we showed how to use control-flow refinement (CFR) to improve automatic complexity analysis of integer programs. While up to now CFR was limited to classical programs, in this paper we extend CFR to probabilistic programs and show its soundness for complexity analysis. To demonstrate its benefits, we implemented our new CFR technique in our complexity analysis tool KoAT.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.03891v2</guid>
      <category>cs.LO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nils Lommen, \'El\'eanore Meyer, J\"urgen Giesl</dc:creator>
    </item>
    <item>
      <title>Parallel Play Saves Quantifiers</title>
      <link>https://arxiv.org/abs/2402.10293</link>
      <description>arXiv:2402.10293v2 Announce Type: replace 
Abstract: The number of quantifiers needed to express first-order properties is captured by two-player combinatorial games called multi-structural (MS) games. We play these games on linear orders and strings, and introduce a technique we call "parallel play", that dramatically reduces the number of quantifiers needed in many cases. Linear orders and strings are the most basic representatives of ordered structures -- a class of structures that has historically been notoriously difficult to analyze. Yet, in this paper, we provide upper bounds on the number of quantifiers needed to characterize different-sized subsets of these structures, and prove that they are tight up to constant factors, including, in some cases, up to a factor of $1+\varepsilon$, for arbitrarily small $\varepsilon$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.10293v2</guid>
      <category>cs.LO</category>
      <category>cs.CC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marco Carmosino, Ronald Fagin, Neil Immerman, Phokion Kolaitis, Jonathan Lenchner, Rik Sengupta, Ryan Williams</dc:creator>
    </item>
    <item>
      <title>CryptoVampire: Automated Reasoning for the Complete Symbolic Attacker Cryptographic Model</title>
      <link>https://arxiv.org/abs/2305.12173</link>
      <description>arXiv:2305.12173v2 Announce Type: replace-cross 
Abstract: Cryptographic protocols are hard to design and prove correct, as witnessed by the ever-growing list of attacks even on protocol standards. Symbolic models of cryptography enable automated formal security proofs of such protocols against an idealized model, which abstracts away from the algebraic properties of cryptographic schemes and thus misses attacks. Computational models yield rigorous guarantees but support at present only interactive proofs and/or restricted classes of protocols. A promising approach is given by the computationally complete symbolic attacker (CCSA), formalized in the BC Logic, which aims at bridging and getting the best of the two worlds, obtaining cryptographic guarantees by symbolic analysis. The BC Logic is supported by a recently developed interactive theorem prover, Squirrel, which enables machine-checked interactive security proofs, as opposed to automated ones, thus requiring expert knowledge.
  We introduce the CryptoVampire cryptographic protocol verifier, which for the first time fully automates proofs of trace properties in the BC Logic. The key technical contribution is a first-order (FO) formalization of protocol properties with tailored handling of subterm relations. We overcome the burden of interactive proving in higher-order (HO) logic and automatically establish soundness of cryptographic protocols using only FO reasoning. On the theoretical side, we restrict full FO logic with cryptographic axioms to ensure that, by losing the expressivity of the HO BC Logic, we do not lose soundness. On the practical side, CryptoVampire integrates dedicated proof techniques using FO saturation algorithms and heuristics, which enable leveraging the state-of-the-art Vampire FO theorem prover as the underlying proving engine. Our experimental results show CryptoVampire's effectiveness of as a standalone verifier and in terms of automation support for Squirrel.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.12173v2</guid>
      <category>cs.CR</category>
      <category>cs.LO</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Simon Jeanteur, Laura Kov\'acs, Matteo Maffei, Michael Rawson</dc:creator>
    </item>
    <item>
      <title>Risk-Aware MPC for Stochastic Systems with Runtime Temporal Logics</title>
      <link>https://arxiv.org/abs/2402.03165</link>
      <description>arXiv:2402.03165v2 Announce Type: replace-cross 
Abstract: This paper concerns the risk-aware control of stochastic systems with temporal logic specifications dynamically assigned during runtime. Conventional risk-aware control typically assumes that all specifications are predefined and remain unchanged during runtime. In this paper, we propose a novel, provably correct model predictive control scheme for linear systems with additive unbounded stochastic disturbances that dynamically evaluates the feasibility of runtime signal temporal logic specifications and automatically reschedules the control inputs accordingly. The control method guarantees the probabilistic satisfaction of newly accepted specifications without sacrificing the satisfaction of the previously accepted ones. The proposed control method is validated by a robotic motion planning case study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.03165v2</guid>
      <category>eess.SY</category>
      <category>cs.LO</category>
      <category>cs.SY</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Maico H. W. Engelaar, Zengjie Zhang, Mircea Lazar, Sofie Haesaert</dc:creator>
    </item>
  </channel>
</rss>
