<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.NA</link>
    <description>math.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 10 Jan 2025 05:00:10 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 10 Jan 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Dynamics of a Family of Rational Operators of Arbitrary Degree</title>
      <link>https://arxiv.org/abs/2501.04767</link>
      <description>arXiv:2501.04767v1 Announce Type: new 
Abstract: In this paper we analyse the dynamics of a family of rational operators coming from a fourth-order family of root-finding algorithms. We first show that it may be convenient to redefine the parameters to prevent redundancies and unboundedness of problematic parameters. After reparametrization, we observe that these rational maps belong to a more general family $O_{a,n,k}$ of degree $n+k$ operators, which includes several other families of maps obtained from other numerical methods. We study the dynamics of $O_{a,n,k}$ and discuss for which parameters $n$ and $k$ these operators would be suitable from the numerical point of view.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.04767v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 10 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.3846/mma.2021.12642</arxiv:DOI>
      <arxiv:journal_reference>Math. Model. Anal. 26 (2021), no.2, 188-208</arxiv:journal_reference>
      <dc:creator>Beatriz Campos, Jordi Canela, Antonio Garijo, Pura Vindel</dc:creator>
    </item>
    <item>
      <title>A hybrid pressure formulation of the face-centred finite volume method for viscous laminar incompressible flows</title>
      <link>https://arxiv.org/abs/2501.04864</link>
      <description>arXiv:2501.04864v1 Announce Type: new 
Abstract: This work presents a hybrid pressure face-centred finite volume (FCFV) solver to simulate steady-state incompressible Navier-Stokes flows. The method leverages the robustness, in the incompressible limit, of the hybridisable discontinuous Galerkin paradigm for compressible and weakly compressible flows to derive the formulation of a novel, low-order face-based discretisation. The incompressibility constraint is enforced in a weak sense, by introducing an inter-cell mass flux defined in terms of a new, hybrid variable, representing the pressure at the cell faces. This results in a new hybridisation strategy where cell variables (velocity, pressure and deviatoric strain rate tensor) are expressed as a function of velocity and pressure at the barycentre of the cell faces. The hybrid pressure formulation provides first-order convergence of all variables, including the stress, independently of cell type, stretching and distortion. Numerical benchmarks of Navier-Stokes flows at low and moderate Reynolds numbers, in two and three dimensions, are presented to evaluate accuracy and robustness of the method. In particular, the hybrid pressure formulation outperforms the FCFV method when convective effects are relevant, achieving accurate predictions on significantly coarser meshes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.04864v1</guid>
      <category>math.NA</category>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>physics.flu-dyn</category>
      <pubDate>Fri, 10 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matteo Giacomini, Davide Cortellessa, Luan M. Vieira, Ruben Sevilla, Antonio Huerta</dc:creator>
    </item>
    <item>
      <title>A Moving Mesh Isogeometric Method Based on Harmonic Maps</title>
      <link>https://arxiv.org/abs/2501.05118</link>
      <description>arXiv:2501.05118v1 Announce Type: new 
Abstract: Although the isogeometric analysis has shown its great potential in achieving highly accurate numerical solutions of partial differential equations, its efficiency is the main factor making the method more competitive in practical simulations. In this paper, an integration of isogeometric analysis and a moving mesh method is proposed, providing a competitive approach to resolve the efficiency issue. Focusing on the Poisson equation, the implementation of the algorithm and related numerical analysis are presented in detail, including the numerical discretization of the governing equation utilizing isogeometric analysis, and a mesh redistribution technique developed via harmonic maps. It is found that the isogeometric analysis brings attractive features in the realization of moving mesh method, such as it provides an accurate expression for moving direction of mesh nodes, and allows for more choices for constructing monitor functions. Through a series of numerical experiments, the effectiveness of the proposed method is successfully validated and the potential of the method towards the practical application is also well presented with the simulation of a helium atom in Kohn--Sham density functional theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.05118v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 10 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tao Wang, Xucheng Meng, Ran Zhang, Guanghui Hu</dc:creator>
    </item>
    <item>
      <title>Super-Localized Orthogonal Decomposition Method for Heterogeneous Linear Elasticity</title>
      <link>https://arxiv.org/abs/2501.05193</link>
      <description>arXiv:2501.05193v1 Announce Type: new 
Abstract: We present the Super-Localized Orthogonal Decomposition (SLOD) method for the numerical homogenization of linear elasticity problems with multiscale microstructures modeled by a heterogeneous coefficient field without any periodicity or scale separation assumptions. Compared to the established Localized Orthogonal Decomposition (LOD) and its linear localization approach, SLOD achieves significantly improved sparsity properties through a nonlinear superlocalization technique, leading to computationally efficient solutions with significantly less oversampling - without compromising accuracy. We generalize the method to vector-valued problems and provide a supporting numerical analysis. We also present a scalable implementation of SLOD using the deal.II finite element library, demonstrating its feasibility for high-performance simulations. Numerical experiments illustrate the efficiency and accuracy of SLOD in addressing key computational challenges in multiscale elasticity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.05193v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 10 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Camilla Belponer, Jos\'e C. Garay, Peter Munch, Daniel Peterseim</dc:creator>
    </item>
    <item>
      <title>A study on the 1-$\Gamma$ inverse of tensors via the M-Product</title>
      <link>https://arxiv.org/abs/2501.05201</link>
      <description>arXiv:2501.05201v1 Announce Type: new 
Abstract: In this paper, we will study the issue about the 1-$\Gamma$ inverse, where $\Gamma\in\{\dag, D, *\}$, via the M-product. The aim of the current study is threefold. Firstly, the definition and characteristic of the 1-$\Gamma$ inverse is introduced. Equivalent conditions for a tensor to be a 1-$\Gamma$ inverse are established. Secondly, using the singular value decomposition, the corresponding numerical algorithms for computing the 1-$\Gamma$ inverse are given. Finally, the solutions of the multilinear equations related 1-$\Gamma$ inverse are studied, and numerical calculations are given to verify our conclusions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.05201v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.RA</category>
      <pubDate>Fri, 10 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Siran Chen, Hongwei Jin, Shaowu Huang, Julio Ben\'itez</dc:creator>
    </item>
    <item>
      <title>Direct coupling of continuum and shell elements in large deformation problems</title>
      <link>https://arxiv.org/abs/2501.05251</link>
      <description>arXiv:2501.05251v1 Announce Type: new 
Abstract: In many applications, thin shell-like structures are integrated within or attached to volumetric bodies. This includes reinforcements placed in soft matrix material in lightweight structure design, or hollow structures that are partially or completely filled. Finite element simulations of such setups are highly challenging. A brute force discretization of structural as well as volumetric parts using well-shaped three-dimensional elements may be accurate, but leads to problems of enormous computational complexity even for simple models. One desired alternative is the use of shell elements for thin-walled parts, as such a discretization greatly alleviates size restrictions on the underlying finite element mesh. However, the coupling of different formulations within a single framework is often not straightforward and may lead to locking if not done carefully. Neunteufel and Sch\"oberl proposed a mixed shell element where, apart from displacements of the center surface, bending moments are used as independent unknowns. These elements were not only shown to be locking free and highly accurate in large-deformation regime, but also do not require differentiability of the shell surface. They can directly be coupled to classical volume elements of arbitrary order by sharing displacement degrees of freedom at the center surface, thus achieving the desired coupled discretization. As the elements can be used on unstructured meshes, adaptive mesh refinement based on local stress and bending moments can be used. We present computational results that confirm exceptional accuracy for problems where thin-walled structures are embedded as reinforcements within soft matrix material.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.05251v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 10 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Astrid Pechstein, Michael Neunteufel</dc:creator>
    </item>
    <item>
      <title>Adaptive refinement for eigenvalue problems based on an associated source problem</title>
      <link>https://arxiv.org/abs/2501.05311</link>
      <description>arXiv:2501.05311v1 Announce Type: new 
Abstract: We introduce an adaptive finite element scheme for the efficient approximation of a (large) collection of eigenpairs of selfadjoint elliptic operators in which the adaptive refinement is driven by the solution of a single source problem -- the so-called landscape problem for the operator -- instead of refining based on the computed eigenpairs. Some theoretical justification for the approach is provided, and extensive empirical results indicate that it can provide an attractive alternative to standard adaptive schemes, particularly in the hp-adaptive environment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.05311v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 10 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Stefano Giani, Jeffrey Ovall, Gabriel Pinochet-Soto</dc:creator>
    </item>
    <item>
      <title>Interior point methods for an algebraic system involving complementarity equations for geomechanical fractures</title>
      <link>https://arxiv.org/abs/2501.04710</link>
      <description>arXiv:2501.04710v1 Announce Type: cross 
Abstract: Many applications like subseismic fault modeling, fractured reservoir modeling and interpretation/validation of fault connectivity involve the solution to an elliptic boundary value problem in a background medium perturbed by the presence of cracks that take the form of one or many pieces of surface (with boundary). When the background medium can be considered as homogeneous, boundary integral equations appear as a method of choice for the numerical solution to fractures problems. With such an approach, the problem is reformulated as a fully non-local equation posed at the surface of cracks. Discretization of boundary integral resulting in the so-called Boundary Element Method (BEM) leads to densely populated matrices due to the full non-locality of the operators under consideration. After the discretization process, geologists are faced with a system of equations that turns out difficult to solve numerically. Many empirical algorithms have been proposed by geologists to solve this system of equations. Unfortunately, none of them is guaranteed to converge in theory (in particular when faults (fractures) intersect each other forming a geometrically highly irregular structure). In practice, none of them appears to be either robust or efficient. We investigate another approach, referred to as interior point methods, for which convergence can be ensured (even if faults are too close). Interior point methods have proved their efficiency in a wide variety of domains, most notably for linear programming. Here, even though we do not have any optimization problem, we can adapt ideas from interior point methods for the numerical resolution of the system considered. The numerical results obtained demonstrate computational efficiency and accuracy, highlighting the robustness and effectiveness of the implemented methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.04710v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 10 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Trung Hau Hoang</dc:creator>
    </item>
    <item>
      <title>Inexact Catching-Up Algorithm for Moreau's Sweeping Processes</title>
      <link>https://arxiv.org/abs/2501.04781</link>
      <description>arXiv:2501.04781v1 Announce Type: cross 
Abstract: In this paper, we develop an inexact version of the catching-up algorithm for sweeping processes. We define a new notion of approximate projection, which is compatible with any numerical method for approximating exact projections, as this new notion is not restricted to remain strictly within the set. We provide several properties of the new approximate projections, which enable us to prove the convergence of the inexact catching-up algorithm in three general frameworks: prox-regular moving sets, subsmooth moving sets, and merely closed sets. Additionally, we apply our numerical results to address complementarity dynamical systems, particularly electrical circuits with ideal diodes. In this context, we implement the inexact catching-up algorithm using a primal-dual optimization method, which typically does not necessarily guarantee a feasible point. Our results are illustrated through an electrical circuit with ideal diodes. Our results recover classical existence results in the literature and provide new insights into the numerical simulation of sweeping processes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.04781v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 10 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Juan Guillermo Garrido, Maximiliano Lioi, Emilio Vilches</dc:creator>
    </item>
    <item>
      <title>Constructing PDFs of spatially dependent fields using finite elements</title>
      <link>https://arxiv.org/abs/2501.05115</link>
      <description>arXiv:2501.05115v1 Announce Type: cross 
Abstract: A probability density function (PDF) of a spatially dependent field provides a means of calculating moments of the field or, equivalently, the proportion of a spatial domain that is mapped to a given set of values. This paper describes a finite element approach to estimating the PDF of a spatially dependent field and its numerical implementation in the Python package NumDF.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.05115v1</guid>
      <category>physics.flu-dyn</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 10 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Paul M. Mannix, David A. Ham, John Craske</dc:creator>
    </item>
    <item>
      <title>Not-Quite-Transcendental Functions For Logarithmic Interpolation of Tabulated Data</title>
      <link>https://arxiv.org/abs/2501.05410</link>
      <description>arXiv:2501.05410v1 Announce Type: cross 
Abstract: From tabulated nuclear and degenerate equations of state to photon and neutrino opacities, to nuclear reaction rates: tabulated data is ubiquitous in computational astrophysics. The dynamic range that must be covered by these tables typically spans many orders of magnitude. Here we present a novel strategy for accurately and performantly interpolating tabulated data that spans these large dynamic ranges. We demonstrate the efficacy of this strategy in tabulated lookups for nuclear and terrestrial equations of state. We show that this strategy is a faster \textit{drop-in} replacement for linear interpolation of logarithmic grids.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.05410v1</guid>
      <category>physics.comp-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 10 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Peter C. Hammond, Jacob M. Fields, Jonah M. Miller, Brandon L. Barker</dc:creator>
    </item>
    <item>
      <title>Error analysis of the Lie splitting for semilinear wave equations with finite-energy solutions</title>
      <link>https://arxiv.org/abs/2311.03245</link>
      <description>arXiv:2311.03245v2 Announce Type: replace 
Abstract: We study time integration schemes for $\dot H^1$-solutions to the energy-(sub)critical semilinear wave equation on $\mathbb{R}^3$. We show first-order convergence in $L^2$ for the Lie splitting and convergence order $3/2$ for a corrected Lie splitting. To our knowledge this includes the first error analysis performed for scaling-critical dispersive problems. Our approach is based on discrete-time Strichartz estimates, including one (with a logarithmic correction) for the case of the forbidden endpoint. Our schemes and the Strichartz estimates contain frequency cut-offs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.03245v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <pubDate>Fri, 10 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maximilian Ruff, Roland Schnaubelt</dc:creator>
    </item>
    <item>
      <title>Multilevel Markov Chain Monte Carlo with likelihood scaling for Bayesian inversion with high-resolution observations</title>
      <link>https://arxiv.org/abs/2401.15978</link>
      <description>arXiv:2401.15978v3 Announce Type: replace 
Abstract: We propose a multilevel Markov chain Monte Carlo (MCMC) method for the Bayesian inference of random field parameters in PDEs using high-resolution data. Compared to existing multilevel MCMC methods, we additionally consider level-dependent data resolution and introduce a suitable likelihood scaling to enable consistent cross-level comparisons. We theoretically show that this approach attains the same convergence rates as when using level-independent treatment of data, but at significantly reduced computational cost. The convergence analysis focuses on Lipschitz continuous transformations of Gaussian random fields with Mat\'ern covariance structure. These results are illustrated using numerical experiments for a 2D plane stress problem, where the Young's modulus is estimated from discretisations of the displacement field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.15978v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 10 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pieter Vanmechelen, Geert Lombaert, Giovanni Samaey</dc:creator>
    </item>
    <item>
      <title>Mixed precision HODLR matrices</title>
      <link>https://arxiv.org/abs/2407.21637</link>
      <description>arXiv:2407.21637v5 Announce Type: replace 
Abstract: Hierarchical matrix computations have attracted significant attention in the science and engineering community as exploiting data-sparse structures can significantly reduce the computational complexity of many important kernels. One particularly popular option within this class is the Hierarchical Off-Diagonal Low-Rank (HODLR) format. In this paper, we show that the off-diagonal blocks of HODLR matrices that are approximated by low-rank matrices can be represented in low precision without degenerating the quality of the overall approximation (with the error growth bounded by a factor of $2$). We also present an adaptive-precision scheme for constructing and storing HODLR matrices, and we prove that the use of mixed precision does not compromise the numerical stability of the resulting HODLR matrix--vector product and LU factorization. That is, the resulting error in these computations is not significantly greater than the case where we use one precision (say, double) for constructing and storing the HODLR matrix. Our analyses further give insight on how one must choose the working precision in HODLR matrix computations relative to the approximation error in order to not observe the effects of finite precision. Intuitively, when a HODLR matrix is subject to a high degree of approximation error, subsequent computations can be performed in a lower precision without detriment. We demonstrate the validity of our theoretical results through a range of numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.21637v5</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 10 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Erin Carson, Xinye Chen, Xiaobo Liu</dc:creator>
    </item>
    <item>
      <title>Using Linearized Optimal Transport to Predict the Evolution of Stochastic Particle Systems</title>
      <link>https://arxiv.org/abs/2408.01857</link>
      <description>arXiv:2408.01857v2 Announce Type: replace 
Abstract: We develop an algorithm to approximate the time evolution of a probability distribution without explicitly learning an operator that governs the evolution. A particular application of interest is discrete measures $\mu_t^N$ that arise from systems of $N$ particles in $\mathbb R^d$. In many such situations, the individual particles move chaotically on short time scales, making it difficult to learn the dynamics of a governing operator, but the bulk distribution $\mu_t^N$ approximates an absolutely continuous measure $\mu_t$ that evolves ``smoothly.'' If $\mu_t$ is known on some time interval, then linearized optimal transport theory provides an Euler-like scheme for approximating the evolution of $\mu_t$ using its ``tangent vector field'' (represented as a time-dependent vector field on $\mathbb R^d$), which can be computed as a limit of optimal transport maps. We propose an analog of this Euler approximation to predict the evolution of the discrete measure $\mu_t^N$ (without knowing $\mu_t$). To approximate the analogous tangent vector field, we use a finite difference over a time step that sits between two time scales of the system -- long enough for a large-$N$ evolution ($\mu_t$) to emerge but short enough to satisfactorily approximate the derivative object used in the Euler scheme. The emergence of the limiting behavior ensures the optimal transport maps closely approximate the vector field describing the bulk distribution's smooth evolution instead of the individual particles' more chaotic movements. We demonstrate the efficacy of our approach with two illustrative examples, Gaussian diffusion and a cell chemotaxis model, and show that our method succeeds in predicting the bulk behavior over relatively large steps.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01857v2</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Fri, 10 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicholas Karris, Evangelos A. Nikitopoulos, Ioannis Kevrekidis, Seungjoon Lee, Alexander Cloninger</dc:creator>
    </item>
    <item>
      <title>Expression Rates of Neural Operators for Linear Elliptic PDEs in Polytopes</title>
      <link>https://arxiv.org/abs/2409.17552</link>
      <description>arXiv:2409.17552v2 Announce Type: replace 
Abstract: We study the approximation rates of a class of deep neural network approximations of operators, which arise as data-to-solution maps $\mathcal{G}^\dagger$ of linear elliptic partial differential equations (PDEs), and act between pairs $X,Y$ of suitable infinite-dimensional spaces. We prove expression rate bounds for approximate neural operators $\mathcal{G}$ with the structure $\mathcal{G} = \mathcal{R} \circ \mathcal{A} \circ \mathcal{E}$, with linear encoders $\mathcal{E}$ and decoders $\mathcal{R}$. The constructive proofs are via a recurrent NN structure obtained by unrolling exponentially convergent, self-consistent (``Richardson'') iterations. We bound the operator approximation error with respect to the linear Kolmogorov $N$-widths of the data and solution sets and in terms of the size of the approximation network. We prove expression rate bounds for approximate, neural solution operators emulating the coefficient-to-solution maps for elliptic PDEs set in $d$-dimensional polytopes, with $d\in\{2,3\}$, and subject to Dirichlet-, Neumann- or mixed boundary conditions. Exploiting weighted norm characterizations of the solution sets of elliptic PDEs in polytopes, we show algebraic rates of expression for problems with data with finite regularity, and exponential operator expression rates for analytic data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.17552v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 10 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Carlo Marcati, Christoph Schwab</dc:creator>
    </item>
    <item>
      <title>Rate of convergence for numerical $\alpha$-dissipative solutions of the Hunter-Saxton equation</title>
      <link>https://arxiv.org/abs/2411.07712</link>
      <description>arXiv:2411.07712v2 Announce Type: replace 
Abstract: We prove that $\alpha$-dissipative solutions to the Cauchy problem of the Hunter-Saxton equation, where $\alpha \in W^{1, \infty}(\mathbb{R}, [0, 1))$, can be computed numerically with order $\mathcal{O}(\Delta x^{{1}/{8}}+\Delta x^{{\beta}/{4}})$ in $L^{\infty}(\mathbb{R})$, provided there exist constants $C &gt; 0$ and $\beta \in (0, 1]$ such that the initial spatial derivative $\bar{u}_{x}$ satisfies $\|\bar{u}_x(\cdot + h) - \bar{u}_x(\cdot)\|_2 \leq Ch^{\beta}$ for all $h \in (0, 2]$. The derived convergence rate is exemplified by a number of numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.07712v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <pubDate>Fri, 10 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas Christiansen, Katrin Grunert</dc:creator>
    </item>
    <item>
      <title>Scaling Optimized Hermite Approximation Methods</title>
      <link>https://arxiv.org/abs/2412.08044</link>
      <description>arXiv:2412.08044v2 Announce Type: replace 
Abstract: Hermite polynomials and functions have extensive applications in scientific and engineering problems. While it is recognized that employing the scaled Hermite functions rather than the standard ones can remarkably enhance the approximation performance, the understanding of the scaling factor remains insufficient. Due to the lack of theoretical analysis, some literature still cast doubts on whether the Hermite spectral method is inferior to other methods. To dispel these doubts, we show in this article that the inefficiency of the Hermite spectral method comes from the imbalance in the decay speed of the objective function within the spatial and frequency domains. Moreover, proper scaling can render the Hermite spectral methods comparable to other methods. To illustrate this idea in more detail, we propose a novel error analysis framework for the scaled Hermite approximation. Taking the $L^2$ projection error as an example, our framework illustrates that there are three different components of errors: the spatial truncation error, the frequency truncation error, and the Hermite spectral approximation error. Through this perspective, finding the optimal scaling factor is equivalent to balancing the spatial and frequency truncation error. As applications, we show that geometric convergence can be recovered by proper scaling for a class of functions. Furthermore, we show that proper scaling can double the convergence order for smooth functions with algebraic decay. The perplexing pre-asymptotic sub-geometric convergence when approximating algebraic decay functions can be perfectly explained by this framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.08044v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 10 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Hao Hu, Haijun Yu</dc:creator>
    </item>
    <item>
      <title>Convergence of a second-order central scheme for conservation laws with discontinuous flux</title>
      <link>https://arxiv.org/abs/2501.04620</link>
      <description>arXiv:2501.04620v2 Announce Type: replace 
Abstract: In this article, we propose a Nessyahu-Tadmor-type second-order central scheme for a class of scalar conservation laws with discontinuous flux and present its convergence analysis. Since solutions to problems with discontinuous flux typically do not belong to the space of bounded variation (BV), we employ the theory of compensated compactness as the main tool for the convergence of approximate solutions. A central component of the analysis involves establishing the maximum principle and the $\mathrm{W}^{-1,2}_{\mathrm{loc}}$ compactness of the approximate solutions, the latter achieved through the derivation of several essential estimates. Finally, by introducing a mesh-dependent correction term in the slope limiter, we show that the numerical solutions generated by the the proposed second-order scheme converge to the entropy solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.04620v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 10 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nikhil Manoj, Sudarshan Kumar K</dc:creator>
    </item>
    <item>
      <title>Effective Rank and the Staircase Phenomenon: New Insights into Neural Network Training Dynamics</title>
      <link>https://arxiv.org/abs/2412.05144</link>
      <description>arXiv:2412.05144v2 Announce Type: replace-cross 
Abstract: In recent years, deep learning, powered by neural networks, has achieved widespread success in solving high-dimensional problems, particularly those with low-dimensional feature structures. This success stems from their ability to identify and learn low dimensional features tailored to the problems. Understanding how neural networks extract such features during training dynamics remains a fundamental question in deep learning theory. In this work, we propose a novel perspective by interpreting the neurons in the last hidden layer of a neural network as basis functions that represent essential features. To explore the linear independence of these basis functions throughout the deep learning dynamics, we introduce the concept of 'effective rank'. Our extensive numerical experiments reveal a notable phenomenon: the effective rank increases progressively during the learning process, exhibiting a staircase-like pattern, while the loss function concurrently decreases as the effective rank rises. We refer to this observation as the 'staircase phenomenon'. Specifically, for deep neural networks, we rigorously prove the negative correlation between the loss function and effective rank, demonstrating that the lower bound of the loss function decreases with increasing effective rank. Therefore, to achieve a rapid descent of the loss function, it is critical to promote the swift growth of effective rank. Ultimately, we evaluate existing advanced learning methodologies and find that these approaches can quickly achieve a higher effective rank, thereby avoiding redundant staircase processes and accelerating the rapid decline of the loss function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05144v2</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 10 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiang Yang, Yuxiang Zhao, Quanhui Zhu</dc:creator>
    </item>
    <item>
      <title>An OpenFOAM face-centred solver for incompressible flows robust to mesh distortion</title>
      <link>https://arxiv.org/abs/2501.00450</link>
      <description>arXiv:2501.00450v2 Announce Type: replace-cross 
Abstract: This work presents an overview of mesh-induced errors commonly experienced by cell-centred finite volumes (CCFV), for which the face-centred finite volume (FCFV) paradigm offers competitive solutions. In particular, a robust FCFV solver for incompressible laminar flows is integrated in OpenFOAM and tested on a set of steady-state and transient benchmarks. The method outperforms standard simpleFoam and pimpleFoam algorithms in terms of optimal convergence, accuracy, stability, and robustness. Special attention is devoted to motivate and numerically demonstrate the ability of the FCFV method to treat non-orthogonal, stretched, and skewed meshes, where CCFV schemes exhibit shortcomings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.00450v2</guid>
      <category>physics.flu-dyn</category>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 10 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Davide Cortellessa, Matteo Giacomini, Antonio Huerta</dc:creator>
    </item>
  </channel>
</rss>
