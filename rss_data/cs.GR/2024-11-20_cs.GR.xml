<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GR updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GR</link>
    <description>cs.GR updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GR" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 21 Nov 2024 02:38:42 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Newclid: A User-Friendly Replacement for AlphaGeometry</title>
      <link>https://arxiv.org/abs/2411.11938</link>
      <description>arXiv:2411.11938v1 Announce Type: new 
Abstract: We introduce a new symbolic solver for geometry, called Newclid, which is based on AlphaGeometry. Newclid contains a symbolic solver called DDARN (derived from DDAR-Newclid), which is a significant refactoring and upgrade of AlphaGeometry's DDAR symbolic solver by being more user-friendly - both for the end user as well as for a programmer wishing to extend the codebase. For the programmer, improvements include a modularized codebase and new debugging and visualization tools. For the user, Newclid contains a new command line interface (CLI) that provides interfaces for agents to guide DDARN. DDARN is flexible with respect to its internal reasoning, which can be steered by agents. Further, we support input from GeoGebra to make Newclid accessible for educational contexts. Further, the scope of problems that Newclid can solve has been expanded to include the ability to have an improved understanding of metric geometry concepts (length, angle) and to use theorems such as the Pythagorean theorem in proofs. Bugs have been fixed, and reproducibility has been improved. Lastly, we re-evaluated the five remaining problems from the original AG-30 dataset that AlphaGeometry was not able to solve and contrasted them with the abilities of DDARN, running in breadth-first-search agentic mode (which corresponds to how DDARN runs by default), finding that DDARN solves an additional problem. We have open-sourced our code under: https://github.com/LMCRC/Newclid</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11938v1</guid>
      <category>cs.GR</category>
      <category>cs.AI</category>
      <pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vladmir Sicca, Tianxiang Xia, Math\"is F\'ed\'erico, Philip John Gorinski, Simon Frieder, Shangling Jui</dc:creator>
    </item>
    <item>
      <title>NeuMaDiff: Neural Material Synthesis via Hyperdiffusion</title>
      <link>https://arxiv.org/abs/2411.12015</link>
      <description>arXiv:2411.12015v1 Announce Type: new 
Abstract: High-quality material synthesis is essential for replicating complex surface properties to create realistic digital scenes. However, existing methods often suffer from inefficiencies in time and memory, require domain expertise, or demand extensive training data, with high-dimensional material data further constraining performance. Additionally, most approaches lack multi-modal guidance capabilities and standardized evaluation metrics, limiting control and comparability in synthesis tasks. To address these limitations, we propose NeuMaDiff, a novel neural material synthesis framework utilizing hyperdiffusion. Our method employs neural fields as a low-dimensional representation and incorporates a multi-modal conditional hyperdiffusion model to learn the distribution over material weights. This enables flexible guidance through inputs such as material type, text descriptions, or reference images, providing greater control over synthesis. To support future research, we contribute two new material datasets and introduce two BRDF distributional metrics for more rigorous evaluation. We demonstrate the effectiveness of NeuMaDiff through extensive experiments, including a novel statistics-based constrained synthesis approach, which enables the generation of materials of desired categories.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.12015v1</guid>
      <category>cs.GR</category>
      <pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Chenliang Zhou, Zheyuan Hu, Alejandro Sztrajman, Yancheng Cai, Yaru Liu, Cengiz Oztirel</dc:creator>
    </item>
    <item>
      <title>FruitNinja: 3D Object Interior Texture Generation with Gaussian Splatting</title>
      <link>https://arxiv.org/abs/2411.12089</link>
      <description>arXiv:2411.12089v1 Announce Type: cross 
Abstract: In the real world, objects reveal internal textures when sliced or cut, yet this behavior is not well-studied in 3D generation tasks today. For example, slicing a virtual 3D watermelon should reveal flesh and seeds. Given that no available dataset captures an object's full internal structure and collecting data from all slices is impractical, generative methods become the obvious approach. However, current 3D generation and inpainting methods often focus on visible appearance and overlook internal textures. To bridge this gap, we introduce FruitNinja, the first method to generate internal textures for 3D objects undergoing geometric and topological changes. Our approach produces objects via 3D Gaussian Splatting (3DGS) with both surface and interior textures synthesized, enabling real-time slicing and rendering without additional optimization. FruitNinja leverages a pre-trained diffusion model to progressively inpaint cross-sectional views and applies voxel-grid-based smoothing to achieve cohesive textures throughout the object. Our OpaqueAtom GS strategy overcomes 3DGS limitations by employing densely distributed opaque Gaussians, avoiding biases toward larger particles that destabilize training and sharp color transitions for fine-grained textures. Experimental results show that FruitNinja substantially outperforms existing approaches, showcasing unmatched visual quality in real-time rendered internal views across arbitrary geometry manipulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.12089v1</guid>
      <category>cs.CV</category>
      <category>cs.GR</category>
      <category>cs.HC</category>
      <pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fangyu Wu, Yuhao Chen</dc:creator>
    </item>
    <item>
      <title>Sketch-guided Cage-based 3D Gaussian Splatting Deformation</title>
      <link>https://arxiv.org/abs/2411.12168</link>
      <description>arXiv:2411.12168v1 Announce Type: cross 
Abstract: 3D Gaussian Splatting (GS) is one of the most promising novel 3D representations that has received great interest in computer graphics and computer vision. While various systems have introduced editing capabilities for 3D GS, such as those guided by text prompts, fine-grained control over deformation remains an open challenge. In this work, we present a novel sketch-guided 3D GS deformation system that allows users to intuitively modify the geometry of a 3D GS model by drawing a silhouette sketch from a single viewpoint. Our approach introduces a new deformation method that combines cage-based deformations with a variant of Neural Jacobian Fields, enabling precise, fine-grained control. Additionally, it leverages large-scale 2D diffusion priors and ControlNet to ensure the generated deformations are semantically plausible. Through a series of experiments, we demonstrate the effectiveness of our method and showcase its ability to animate static 3D GS models as one of its key applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.12168v1</guid>
      <category>cs.CV</category>
      <category>cs.GR</category>
      <pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tianhao Xie, Noam Aigerman, Eugene Belilovsky, Tiberiu Popa</dc:creator>
    </item>
    <item>
      <title>3D Reconstruction by Looking: Instantaneous Blind Spot Detector for Indoor SLAM through Mixed Reality</title>
      <link>https://arxiv.org/abs/2411.12514</link>
      <description>arXiv:2411.12514v1 Announce Type: cross 
Abstract: Indoor SLAM often suffers from issues such as scene drifting, double walls, and blind spots, particularly in confined spaces with objects close to the sensors (e.g. LiDAR and cameras) in reconstruction tasks. Real-time visualization of point cloud registration during data collection may help mitigate these issues, but a significant limitation remains in the inability to in-depth compare the scanned data with actual physical environments. These challenges obstruct the quality of reconstruction products, frequently necessitating revisit and rescan efforts. For this regard, we developed the LiMRSF (LiDAR-MR-RGB Sensor Fusion) system, allowing users to perceive the in-situ point cloud registration by looking through a Mixed-Reality (MR) headset. This tailored framework visualizes point cloud meshes as holograms, seamlessly matching with the real-time scene on see-through glasses, and automatically highlights errors detected while they overlap. Such holographic elements are transmitted via a TCP server to an MR headset, where it is calibrated to align with the world coordinate, the physical location. This allows users to view the localized reconstruction product instantaneously, enabling them to quickly identify blind spots and errors, and take prompt action on-site. Our blind spot detector achieves an error detection precision with an F1 Score of 75.76% with acceptably high fidelity of monitoring through the LiMRSF system (highest SSIM of 0.5619, PSNR of 14.1004, and lowest MSE of 0.0389 in the five different sections of the simplified mesh model which users visualize through the LiMRSF device see-through glasses). This method ensures the creation of detailed, high-quality datasets for 3D models, with potential applications in Building Information Modeling (BIM) but not limited.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.12514v1</guid>
      <category>cs.HC</category>
      <category>cs.CV</category>
      <category>cs.GR</category>
      <pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Hanbeom Chang, Jongseong Brad Choi, Chul Min Yeum</dc:creator>
    </item>
    <item>
      <title>Multi-LoRA Composition for Image Generation</title>
      <link>https://arxiv.org/abs/2402.16843</link>
      <description>arXiv:2402.16843v2 Announce Type: replace-cross 
Abstract: Low-Rank Adaptation (LoRA) is extensively utilized in text-to-image models for the accurate rendition of specific elements like distinct characters or unique styles in generated images. Nonetheless, existing methods face challenges in effectively composing multiple LoRAs, especially as the number of LoRAs to be integrated grows, thus hindering the creation of complex imagery. In this paper, we study multi-LoRA composition through a decoding-centric perspective. We present two training-free methods: LoRA Switch, which alternates between different LoRAs at each denoising step, and LoRA Composite, which simultaneously incorporates all LoRAs to guide more cohesive image synthesis. To evaluate the proposed approaches, we establish ComposLoRA, a new comprehensive testbed as part of this research. It features a diverse range of LoRA categories with 480 composition sets. Utilizing an evaluation framework based on GPT-4V, our findings demonstrate a clear improvement in performance with our methods over the prevalent baseline, particularly evident when increasing the number of LoRAs in a composition. The code, benchmarks, LoRA weights, and all evaluation details are available on our project website: https://maszhongming.github.io/Multi-LoRA-Composition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.16843v2</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.GR</category>
      <category>cs.LG</category>
      <pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ming Zhong, Yelong Shen, Shuohang Wang, Yadong Lu, Yizhu Jiao, Siru Ouyang, Donghan Yu, Jiawei Han, Weizhu Chen</dc:creator>
    </item>
    <item>
      <title>Discrete Variable Topology Optimization Using Multi-Cut Formulation and Adaptive Trust Regions</title>
      <link>https://arxiv.org/abs/2406.12215</link>
      <description>arXiv:2406.12215v2 Announce Type: replace-cross 
Abstract: We present a new framework for solving general topology optimization (TO) problems that find an optimal material distribution within a design space to maximize the performance of a structure while satisfying design constraints. These problems involve state variables that nonlinearly depend on the design variables, with objective functions that can be convex or non-convex, and may include multiple candidate materials. The framework is designed to greatly enhance computational efficiency, primarily by diminishing optimization iteration counts and thereby reducing the solving of associated state-equilibrium partial differential equations (PDEs). It maintains binary design variables and addresses the large-scale mixed integer nonlinear programming (MINLP) problem that arises from discretizing the design space and PDEs. The core of this framework is the integration of the generalized Benders' decomposition and adaptive trust regions. The trust-region radius adapts based on a merit function. To mitigate ill-conditioning due to extreme parameter values, we further introduce a parameter relaxation scheme where two parameters are relaxed in stages at different paces. Numerical tests validate the framework's superior performance, including minimum compliance and compliant mechanism problems in single-material and multi-material designs. We compare our results with those of other methods and demonstrate significant reductions in optimization iterations by about one order of magnitude, while maintaining comparable optimal objective function values. As the design variables and constraints increase, the framework maintains consistent solution quality and efficiency, underscoring its good scalability. We anticipate this framework will be especially advantageous for TO applications involving substantial design variables and constraints and requiring significant computational resources for PDE solving.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12215v2</guid>
      <category>math.NA</category>
      <category>cs.GR</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Wed, 20 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Zisheng Ye, Wenxiao Pan</dc:creator>
    </item>
  </channel>
</rss>
