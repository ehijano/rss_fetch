<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>eess.SP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/eess.SP</link>
    <description>eess.SP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/eess.SP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 04 Feb 2026 05:00:08 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Joint single-shot ToA and DoA estimation for VAA-based BLE ranging with phase ambiguity: A deep learning-based approach</title>
      <link>https://arxiv.org/abs/2602.02503</link>
      <description>arXiv:2602.02503v1 Announce Type: new 
Abstract: Conventional direction-of-arrival (DoA) estimation methods rely on multi-antenna arrays, which are costly to implement on size-constrained Bluetooth Low Energy (BLE) devices. Virtual antenna array (VAA) techniques enable DoA estimation with a single antenna, making angle estimation feasible on such devices. However, BLE only provides a single-shot two-way channel frequency response (CFR) with a binary phase ambiguity issue, which hinders the direct application of VAA. To address this challenge, we propose a unified model that combines VAA with BLE two-way CFR, and introduce a neural network based phase recovery framework that employs row / column predictors with a voting mechanism to resolve the ambiguity. The recovered one-way CFR then enables super resolution algorithms such as MUSIC for joint time of arrival (ToA) and DoA estimation. Simulation results demonstrate that the proposed method achieves superior performance under non-uniform VAAs, with mean square errors approaching the Cramer Rao bound at SNR $\geq$ 5 dB.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.02503v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jincheng Xie, Yili Deng, Jiguang He, Pengyu Wang, Miaomiao Dong, Rui Tang, Zhongyi Huang</dc:creator>
    </item>
    <item>
      <title>Pilots and Other Predictable Elements of the Starlink Ku-Band Downlink</title>
      <link>https://arxiv.org/abs/2602.02627</link>
      <description>arXiv:2602.02627v1 Announce Type: new 
Abstract: We identify and characterize dedicated pilot symbols and other predictable elements embedded within the Starlink Ku-band downlink waveform. Exploitation of these predictable elements enables precise opportunistic positioning, navigation, and timing using compact, low-gain receivers by maximizing the signal processing gain available for signal acquisition and time-of-arrival (TOA) estimation. We develop an acquisition and demodulation framework to decode Starlink frames and disclose the explicit sequences of the edge pilots -- bands of 4QAM symbols located at both edges of each Starlink channel that apparently repeat identically across all frames, beams, channels, and satellites. We further reveal that the great majority of QPSK-modulated symbols do not carry high-entropy user data but instead follow a regular tessellated structure superimposed on a constant reference template. We demonstrate that exploiting frame-level predictable elements yields a processing gain of approximately 48 dB, thereby enabling low-cost, compact receivers to extract precise TOA measurements even from low-SNR Starlink side beams.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.02627v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenkai Qin, Mark L. Psiaki, John R. Bowman, Todd E. Humphreys</dc:creator>
    </item>
    <item>
      <title>STAR-RIS-Assisted Full-Space Angle Estimation via Finite Rate of Innovation</title>
      <link>https://arxiv.org/abs/2602.02893</link>
      <description>arXiv:2602.02893v1 Announce Type: new 
Abstract: Conventional sensor architectures typically restrict angle estimation to the half-space. By enabling simultaneous transmission and reflection, simultaneously transmitting and reflecting reconfigurable intelligent surfaces (STAR-RIS) can support full-space angle detection. This paper develops a fullspace angle estimation framework by leveraging a finite rate of innovation (FRI) model enabled by STAR-RIS. We distinguish two practical STAR-RIS configurations: (i) an element-wise uniform setting, where all metasurface elements share identical energy-splitting (ES) coefficients and phase differences, and (ii) a nonuniform ES setting, where the phase difference is common across elements while the ES coefficients vary element-wise to increase design flexibility. For each regime, we formulate the corresponding FRI-based signal model and derive the Ziv-Zakai bound (ZZB) for angle estimation. To recover the underlying FRI sampling structure, we develop a proximal-gradient algorithm implemented via alternating projections in matrix space and establish its convergence. Exploiting the recovered FRI structure, we construct an annihilating filter whose zeros encode user angles, enabling gridless estimation via polynomial root finding. Numerical results demonstrate that the proposed methods operate reliably across both configuration regimes and achieve improved angle estimation performance with low overhead.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.02893v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ziming Liu, Tao Chen, Muran Guo, Francesco Verde</dc:creator>
    </item>
    <item>
      <title>Tri-Hybrid Holographic Beamforming for Integrated Sensing and Communication</title>
      <link>https://arxiv.org/abs/2602.03000</link>
      <description>arXiv:2602.03000v1 Announce Type: new 
Abstract: Integrated sensing and communication (ISAC) can perform both communication and sensing tasks using the same frequency band and hardware, making it a key technology for 6G. As a low-cost implementation for large-scale antenna arrays, reconfigurable holographic surfaces (RHSs) can be integrated into ISAC systems to realize the holographic ISAC paradigm, where enlarged radiation apertures achieve significant beamforming gains. In this paper, we investigate the tri-hybrid holographic ISAC framework, where the beamformer comprises digital, analog, and RHS-based electromagnetic (EM) layers. The analog layer employs a small number of phase shifters (PSs) to provide subarray-level phase control for the amplitude-modulated RHSs. Tri-hybrid beamforming provides a pathway for low-cost large-scale holographic ISAC. However, compared to conventional ISAC systems, it is challenging to achieve joint subarray-level phase control via PSs and element-level radiation amplitude control via RHSs for holographic ISAC. To address this, we present a tri-hybrid holographic ISAC scheme that minimizes sensing waveform error while satisfying the minimum user rate requirement. A joint optimization approach for PS phases and RHS amplitude responses is designed to address inter-layer coupling and distinct feasible regions. Theoretical analyses reveal that the optimized amplitude responses cluster near boundary values, i.e., 1-bit amplitude control, to reduce hardware and algorithmic complexity. Simulation results show that the proposed scheme achieves a controllable performance trade-off between communication and sensing tasks. Measured RHS beam gain validates the enhancement of holographic beamforming through subarray-level phase shifting. Moreover, as the number of RHS elements increases, the proposed approach exceeds the performance of conventional hybrid beamforming while significantly reducing the number of PSs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.03000v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shupei Zhang, Shuhao Zeng, Boya Di, Lingyang Song</dc:creator>
    </item>
    <item>
      <title>Stationarity and Spectral Characterization of Random Signals on Simplicial Complexes</title>
      <link>https://arxiv.org/abs/2602.03055</link>
      <description>arXiv:2602.03055v1 Announce Type: new 
Abstract: It is increasingly common for data to possess intricate structure, necessitating new models and analytical tools. Graphs, a prominent type of structure, can encode the relationships between any two entities (nodes). However, graphs neither allow connections that are not dyadic nor permit relationships between sets of nodes. We thus turn to simplicial complexes for connecting more than two nodes as well as modeling relationships between simplices, such as edges and triangles. Our data then consist of signals lying on topological spaces, represented by simplicial complexes. Much recent work explores these topological signals, albeit primarily through deterministic formulations. We propose a probabilistic framework for random signals defined on simplicial complexes. Specifically, we generalize the classical notion of stationarity. By spectral dualities of Hodge and Dirac theory, we define stationary topological signals as the outputs of topological filters given white noise. This definition naturally extends desirable properties of stationarity that hold for both time-series and graph signals. Crucially, we properly define topological power spectral density (PSD) through a clear spectral characterization. We then discuss the advantages of topological stationarity due to spectral properties via the PSD. In addition, we empirically demonstrate the practicality of these benefits through multiple synthetic and real-world simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.03055v1</guid>
      <category>eess.SP</category>
      <category>stat.ML</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Madeline Navarro, Andrei Buciulea, Santiago Segarra, Antonio Marques</dc:creator>
    </item>
    <item>
      <title>Multipath Extended Target Tracking with Labeled Random Finite Sets</title>
      <link>https://arxiv.org/abs/2602.03464</link>
      <description>arXiv:2602.03464v1 Announce Type: new 
Abstract: High-resolution radar sensors are critical for autonomous systems but pose significant challenges to traditional tracking algorithms due to the generation of multiple measurements per object and the presence of multipath effects. Existing solutions often rely on the point target assumption or treat multipath measurements as clutter, whereas current extended target trackers often lack the capability to maintain trajectory continuity in complex multipath environments. To address these limitations, this paper proposes the multipath extended target generalized labeled multi-Bernoulli (MPET-GLMB) filter. A unified Bayesian framework based on labeled random finite set theory is derived to jointly model target existence, measurement partitioning, and the association between measurements, targets, and propagation paths. This formulation enables simultaneous trajectory estimation for both targets and reflectors without requiring heuristic post-processing. To enhance computational efficiency, a joint prediction and update implementation based on Gibbs sampling is developed. Furthermore, a measurement-driven adaptive birth model is introduced to initialize tracks without prior knowledge of target positions. Experimental results from simulated scenarios and real-world automotive radar data demonstrate that the proposed filter outperforms state-of-the-art methods, achieving superior state estimation accuracy and robust trajectory maintenance in dynamic multipath environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.03464v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guanhua Ding, Tao Huang, Qinchen Wu, Jinping Sun, Yanping Wang, Bing Zhu, Guoqiang Mao</dc:creator>
    </item>
    <item>
      <title>Channel-Aware Conditional Diffusion Model for Secure MU-MISO Communications</title>
      <link>https://arxiv.org/abs/2602.03524</link>
      <description>arXiv:2602.03524v1 Announce Type: new 
Abstract: While information securityis a fundamental requirement for wireless communications, conventional optimization based approaches often struggle with real-time implementation, and deep models, typically discriminative in nature, may lack the ability to cope with unforeseen scenarios. To address this challenge, this paper investigates the design of legitimate beamforming and artificial noise (AN) to achieve physical layer security by exploiting the conditional diffusion model. Specifically, we reformulate the security optimization as a conditional generative process, using a diffusion model to learn the inherent distribution of near-optimal joint beamforming and AN strategies. We employ a U-Net architecture with cross-attention to integrate channel state information, as the basis for the generative process. Moreover, we fine-tune the trained model using an objective incorporating the sum secrecy rate such that the security performance is further enhanced. Finally, simulation results validate the learning process convergence and demonstrate that the proposed generative method achieves superior secrecy performance across various scenarios as compared with the baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.03524v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tong Hui, Xiao Tang, Yichen Wang, Qinghe Du, Dusit Niyato, Zhu Han</dc:creator>
    </item>
    <item>
      <title>Low-Complexity Distributed Combining Design for Near-Field Cell-Free XL-MIMO Systems</title>
      <link>https://arxiv.org/abs/2602.03581</link>
      <description>arXiv:2602.03581v1 Announce Type: new 
Abstract: In this paper, we investigate the low-complexity distributed combining scheme design for near-field cell-free extremely large-scale multiple-input-multiple-output (CF XL-MIMO) systems. Firstly, we construct the uplink spectral efficiency (SE) performance analysis framework for CF XL-MIMO systems over centralized and distributed processing schemes. Notably, we derive the centralized minimum mean-square error (CMMSE) and local minimum mean-square error (LMMSE) combining schemes over arbitrary channel estimators. Then, focusing on the CMMSE and LMMSE combining schemes, we propose five low-complexity distributed combining schemes based on the matrix approximation methodology or the symmetric successive over relaxation (SSOR) algorithm. More specifically, we propose two matrix approximation methodology-aided combining schemes: Global Statistics \&amp; Local Instantaneous information-based MMSE (GSLI-MMSE) and Statistics matrix Inversion-based LMMSE (SI-LMMSE). These two schemes are derived by approximating the global instantaneous information in the CMMSE combining and the local instantaneous information in the LMMSE combining with the global and local statistics information by asymptotic analysis and matrix expectation approximation, respectively. Moreover, by applying the low-complexity SSOR algorithm to iteratively solve the matrix inversion in the LMMSE combining, we derive three distributed SSOR-based LMMSE combining schemes, distinguished from the applied information and initial values.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.03581v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhe Wang, Jiayi Zhang, Bokai Xu, Dusit Niyato, Bo Ai, Shiwen Mao, Zhu Han</dc:creator>
    </item>
    <item>
      <title>Statistics Approximation-Enabled Distributed Beamforming for Cell-Free Massive MIMO</title>
      <link>https://arxiv.org/abs/2602.03590</link>
      <description>arXiv:2602.03590v1 Announce Type: new 
Abstract: We study a distributed beamforming approach for cell-free massive multiple-input multiple-output networks, referred to as Global Statistics \&amp; Local Instantaneous information-based minimum mean-square error (GSLI-MMSE). The scenario with multi-antenna access points (APs) is considered over three different channel models: correlated Rician fading with fixed or random line-of-sight (LoS) phase-shifts, and correlated Rayleigh fading. With the aid of matrix inversion derivations, we can construct the conventional MMSE combining from the perspective of each AP, where global instantaneous information is involved. Then, for an arbitrary AP, we apply the statistics approximation methodology to approximate instantaneous terms related to other APs by channel statistics to construct the distributed combining scheme at each AP with local instantaneous information and global statistics. With the aid of uplink-downlink duality, we derive the respective GSLI-MMSE precoding schemes. Numerical results showcase that the proposed GSLI-MMSE scheme demonstrates performance comparable to the optimal centralized MMSE scheme, under the stable LoS conditions, e.g., with static users having Rician fading with a fixed LoS path.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.03590v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhe Wang, Emil Bj\"ornson, Jiayi Zhang, Peng Zhang, Vitaly Petrov, Bo Ai</dc:creator>
    </item>
    <item>
      <title>A Multi-decoder Neural Tracking Method for Accurately Predicting Speech Intelligibility</title>
      <link>https://arxiv.org/abs/2602.03624</link>
      <description>arXiv:2602.03624v1 Announce Type: new 
Abstract: Objective: EEG-based methods can predict speech intelligibility, but their accuracy and robustness lag behind behavioral tests, which typically show test-retest differences under 1 dB. We introduce the multi-decoder method to predict speech reception thresholds (SRTs) from EEG recordings, enabling objective assessment for populations unable to perform behavioral tests; such as those with disorders of consciousness or during hearing aid fitting. Approach: The method aggregates data from hundreds of decoders, each trained on different speech features and EEG preprocessing setups to quantify neural tracking (NT) of speech signals. Using data from 39 participants (ages 18-24), we recorded 29 minutes of EEG per person while they listened to speech at six signal-to-noise ratios and a quiet story. NT values were combined into a high-dimensional feature vector per subject, and a support vector regression model was trained to predict SRTs from these vectors. Main Result: Predictions correlated significantly with behavioral SRTs (r = 0.647, p &lt; 0.001; NRMSE = 0.19), with all differences under 1 dB. SHAP analysis showed theta/delta bands and early lags had slightly greater influence. Using pretrained subject-independent decoders reduced required EEG data collection to 15 minutes (3 minutes of story, 12 minutes across six SNR conditions) without losing accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.03624v1</guid>
      <category>eess.SP</category>
      <category>cs.SD</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Rien Sonck, Bernd Accou, Tom Francart, Jonas Vanthornhout</dc:creator>
    </item>
    <item>
      <title>VR-VFL: Joint Rate and Client Selection for Vehicular Federated Learning Under Imperfect CSI</title>
      <link>https://arxiv.org/abs/2602.03711</link>
      <description>arXiv:2602.03711v1 Announce Type: new 
Abstract: Federated learning in vehicular edge networks faces major challenges in efficient resource allocation, largely due to high vehicle mobility and the presence of imperfect channel state information. Many existing methods oversimplify these realities, often assuming fixed communication rounds or ideal channel conditions, which limits their effectiveness in real-world scenarios. To address this, we propose variable rate vehicular federated learning (VR-VFL), a novel federated learning method designed specifically for vehicular networks under imperfect channel state information. VR-VFL combines dynamic client selection with adaptive transmission rate selection, while also allowing round times to flex in response to changing wireless conditions. At its core, VR-VFL is built on a bi-objective optimization framework that strikes a balance between improving learning convergence and minimizing the time required to complete each round. By accounting for both the challenges of mobility and realistic wireless constraints, VR-VFL offers a more practical and efficient approach to federated learning in vehicular edge networks. Simulation results show that the proposed VR-VFL scheme achieves convergence approximately 40% faster than other methods in the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.03711v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Metehan Karatas, Subhrakanti Dey, Christian Rohner, Jose Mairton Barros da Silva Jr</dc:creator>
    </item>
    <item>
      <title>A Narrowband Fully-Analog Multi-Antenna Transmitter</title>
      <link>https://arxiv.org/abs/2602.03718</link>
      <description>arXiv:2602.03718v1 Announce Type: new 
Abstract: This paper proposes a narrowband fully-analog $N$-antenna transmitter that emulates the functionality of a narrowband fully-digital $N$-antenna transmitter. Specifically, in symbol interval $m$, the proposed fully-analog transmitter synthesizes an arbitrary complex excitation vector $\bm x[m]\in\mathbb{C}^N$ with prescribed total power $\|\bm x[m]\|_2^2=P$ from a single coherent RF tone, using only tunable phase-control elements embedded in a passive interferometric programmable network. The programmable network is excited through one input port while the remaining $N - 1$ input ports are impedance matched. In the ideal lossless case, the network transfer is unitary and therefore redistributes RF power among antenna ports without dissipative amplitude control.
  The synthesis task is posed as a unitary state-preparation problem: program a unitary family so that $\bm V(\bm\varphi)\bm e_1=\bm c$, where $\bm c=\bm x/\sqrt{P}$ and $\|\bm c\|_2=1$. We provide a constructive realization and a closed-form programming rule: a binary magnitude-splitting tree allocates the desired per-antenna magnitudes $|c_n|$ using $N -1$ tunable split ratios, and a per-antenna output phase bank assigns the target phases using $N$ tunable phase shifts. The resulting architecture uses $2N-1$ real tunable degrees of freedom and admits a deterministic $O(N)$ programming procedure with no iterative optimization, enabling symbol-by-symbol updates when the chosen phase-control technology supports the required tuning speed.
  Using representative COTS components, we model the RF-front-end DC power of the proposed fully-analog transmitter and compare it against an equivalent COTS fully-digital array. For $N\le 16$, the comparison indicates significant RF-front-end power savings for the fully-analog architecture.
  The results in this paper are intended as a proof-of-concept for a narrowband fully-analog transmitter.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.03718v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nikola Zlatanov</dc:creator>
    </item>
    <item>
      <title>Digital-Twin Empowered Deep Reinforcement Learning For Site-Specific Radio Resource Management in NextG Wireless Aerial Corridor</title>
      <link>https://arxiv.org/abs/2602.03801</link>
      <description>arXiv:2602.03801v1 Announce Type: new 
Abstract: Joint base station (BS) association and beam selection in multi-UAV aerial corridors constitutes a challenging radio resource management (RRM) problem. It is driven by high-dimensional action spaces, need for substantial overhead to acquire global channel state information (CSI), rapidly varying propagation channels, and stringent latency requirements. Conventional combinatorial optimization methods, while near-optimal, are computationally prohibitive for real-time operation in such dynamic environments. While learning-based approaches can mitigate computational complexity and CSI overhead, the need for extensive site-specific (SS) datasets for model training remains a key challenge. To address these challenges, we develop a Digital Twin (DT)-enabled two-stage optimization framework that couples physics-based beam gain modeling with DRL for scalable online decision-making. In the first stage, a channel twin (CT) is constructed using a high-fidelity ray-tracing solver with geo-spatial contexts, and network information to capture SS propagation characteristics, and dual annealing algorithm is employed to precompute optimal transmission beam directions. In the second stage, a Multi-Head Proximal Policy Optimization (MH-PPO) agent, equipped with a scalable multi-head actor-critic architecture, is trained on the DT-generated channel dataset to directly map complex channel and beam states to jointly execute UAV-BS-beam association decisions. The proposed PPO agent achieves a 44%-121% improvement over DQN and 249%-807% gain over traditional heuristic based optimization schemes in a dense UAV scenario, while reducing inference latency by several orders of magnitude. These results demonstrate that DT-driven training pipelines can deliver high-performance, low-latency RRM policies tailored to SS deployments suitable for real-time resource management in next-generation aerial corridor networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.03801v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pulok Tarafder, Zoheb Hassan, Imtiaz Ahmed, Danda B. Rawat, Kamrul Hasan, Cong Pu</dc:creator>
    </item>
    <item>
      <title>Scaled Dot-Product Attention implements projection of inputs onto a common surface</title>
      <link>https://arxiv.org/abs/2602.02521</link>
      <description>arXiv:2602.02521v1 Announce Type: cross 
Abstract: Scaled dot-product attention (SDPA) is a fundamental component responsible for the success of large-language models and other nonlinear signal processing applications. The rationale for SDPA has been based upon "query, key, value" concepts borrowed from database theory, but these concepts are difficult to reconcile with standard methods in mathematical signal processing. We show that SDPA can be rewritten in a different but mathematically equivalent form as a projection of the input vectors onto a common surface determined by the inputs themselves. Therefore SDPA discovers nonlinear dependencies in the input that are time-dependent and context-dependent. The rewritten form of SDPA permits increased speed of both feedforward and learning algorithms, but more importantly suggests potential extensions. In the context of language, we re-interpret the role of SDPA as finding a time-dependent contextual meaning determined by the surface on which the set of input vectors lies. Input token embeddings are then modified by the local context surface. This interpretation differs substantially from the concept of "self-attention", and provides a strong justification for the use of SDPA for time-series data with time-varying local nonlinear dependencies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.02521v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>eess.SP</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Terence D Sanger</dc:creator>
    </item>
    <item>
      <title>Auto-Augmentation Contrastive Learning for Wearable-based Human Activity Recognition</title>
      <link>https://arxiv.org/abs/2602.02542</link>
      <description>arXiv:2602.02542v1 Announce Type: cross 
Abstract: For low-semantic sensor signals from human activity recognition (HAR), contrastive learning (CL) is essential to implement novel applications or generic models without manual annotation, which is a high-performance self-supervised learning (SSL) method. However, CL relies heavily on data augmentation for pairwise comparisons. Especially for low semantic data in the HAR area, conducting good performance augmentation strategies in pretext tasks still rely on manual attempts lacking generalizability and flexibility. To reduce the augmentation burden, we propose an end-to-end auto-augmentation contrastive learning (AutoCL) method for wearable-based HAR. AutoCL is based on a Siamese network architecture that shares the parameters of the backbone and with a generator embedded to learn auto-augmentation. AutoCL trains the generator based on the representation in the latent space to overcome the disturbances caused by noise and redundant information in raw sensor data. The architecture empirical study indicates the effectiveness of this design. Furthermore, we propose a stop-gradient design and correlation reduction strategy in AutoCL to enhance encoder representation learning. Extensive experiments based on four wide-used HAR datasets demonstrate that the proposed AutoCL method significantly improves recognition accuracy compared with other SOTA methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.02542v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>eess.SP</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qingyu Wu, Jianfei Shen, Feiyi Fan, Yang Gu, Chenyang Xu, Yiqiang Chen</dc:creator>
    </item>
    <item>
      <title>Learning Consistent Causal Abstraction Networks</title>
      <link>https://arxiv.org/abs/2602.02623</link>
      <description>arXiv:2602.02623v1 Announce Type: cross 
Abstract: Causal artificial intelligence aims to enhance explainability, trustworthiness, and robustness in AI by leveraging structural causal models (SCMs). In this pursuit, recent advances formalize network sheaves and cosheaves of causal knowledge. Pushing in the same direction, we tackle the learning of consistent causal abstraction network (CAN), a sheaf-theoretic framework where (i) SCMs are Gaussian, (ii) restriction maps are transposes of constructive linear causal abstractions (CAs) adhering to the semantic embedding principle, and (iii) edge stalks correspond--up to permutation--to the node stalks of more detailed SCMs. Our problem formulation separates into edge-specific local Riemannian problems and avoids nonconvex objectives. We propose an efficient search procedure, solving the local problems with SPECTRAL, our iterative method with closed-form updates and suitable for positive definite and semidefinite covariance matrices. Experiments on synthetic data show competitive performance in the CA learning task, and successful recovery of diverse CAN structures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.02623v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>eess.SP</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gabriele D'Acunto, Paolo Di Lorenzo, Sergio Barbarossa</dc:creator>
    </item>
    <item>
      <title>Neural Probabilistic Amplitude Shaping for Nonlinear Fiber Channels</title>
      <link>https://arxiv.org/abs/2602.02716</link>
      <description>arXiv:2602.02716v1 Announce Type: cross 
Abstract: We introduce neural probabilistic amplitude shaping, a joint-distribution learning framework for coherent fiber systems. The proposed scheme provides a 0.5 dB signal-to-noise ratio gain over sequence selection for dual-polarized 64-QAM transmission across a single-span 205 km link.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.02716v1</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Mohammad Taha Askari, Lutz Lampe, Amirhossein Ghazisaeidi</dc:creator>
    </item>
    <item>
      <title>Automated Dysphagia Screening Using Noninvasive Neck Acoustic Sensing</title>
      <link>https://arxiv.org/abs/2602.02725</link>
      <description>arXiv:2602.02725v1 Announce Type: cross 
Abstract: Pharyngeal health plays a vital role in essential human functions such as breathing, swallowing, and vocalization. Early detection of swallowing abnormalities, also known as dysphagia, is crucial for timely intervention. However, current diagnostic methods often rely on radiographic imaging or invasive procedures. In this study, we propose an automated framework for detecting dysphagia using portable and noninvasive acoustic sensing coupled with applied machine learning. By capturing subtle acoustic signals from the neck during swallowing tasks, we aim to identify patterns associated with abnormal physiological conditions. Our approach achieves promising test-time abnormality detection performance, with an AUC-ROC of 0.904 under 5 independent train-test splits. This work demonstrates the feasibility of using noninvasive acoustic sensing as a practical and scalable tool for pharyngeal health monitoring.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.02725v1</guid>
      <category>cs.LG</category>
      <category>cs.SD</category>
      <category>eess.AS</category>
      <category>eess.SP</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jade Chng, Rong Xing, Yunfei Luo, Kristen Linnemeyer-Risser, Tauhidur Rahman, Andrew Yousef, Philip A Weissbrod</dc:creator>
    </item>
    <item>
      <title>WST-X Series: Wavelet Scattering Transform for Interpretable Speech Deepfake Detection</title>
      <link>https://arxiv.org/abs/2602.02980</link>
      <description>arXiv:2602.02980v1 Announce Type: cross 
Abstract: Designing front-ends for speech deepfake detectors primarily focuses on two categories. Hand-crafted filterbank features are transparent but are limited in capturing high-level semantic details, often resulting in performance gaps compared to self-supervised (SSL) features. SSL features, in turn, lack interpretability and may overlook fine-grained spectral anomalies. We propose the WST-X series, a novel family of feature extractors that combines the best of both worlds via the wavelet scattering transform (WST), integrating wavelets with nonlinearities analogous to deep convolutional networks. We investigate 1D and 2D WSTs to extract acoustic details and higher-order structural anomalies, respectively. Experimental results on the recent and challenging Deepfake-Eval-2024 dataset indicate that WST-X outperforms existing front-ends by a wide margin. Our analysis reveals that a small averaging scale ($J$), combined with high-frequency and directional resolutions ($Q, L$), is critical for capturing subtle artifacts. This underscores the value of translation-invariant and deformation-stable features for robust and interpretable speech deepfake detection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.02980v1</guid>
      <category>eess.AS</category>
      <category>cs.CL</category>
      <category>eess.SP</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xi Xuan, Davide Carbone, Ruchi Pandey, Wenxin Zhang, Tomi H. Kinnunen</dc:creator>
    </item>
    <item>
      <title>Function-Space Empirical Bayes Regularisation with Large Vision-Language Model Priors</title>
      <link>https://arxiv.org/abs/2602.03119</link>
      <description>arXiv:2602.03119v1 Announce Type: cross 
Abstract: Bayesian deep learning (BDL) provides a principled framework for reliable uncertainty quantification by combining deep neural networks with Bayesian inference. A central challenge in BDL lies in the design of informative prior distributions that scale effectively to high-dimensional data. Recent functional variational inference (VI) approaches address this issue by imposing priors directly in function space; however, most existing methods rely on Gaussian process (GP) priors, whose expressiveness and generalisation capabilities become limited in high-dimensional regimes. In this work, we propose VLM-FS-EB, a novel function-space empirical Bayes regularisation framework, leveraging large vision-language models (VLMs) to generates semantically meaningful context points. These synthetic samples are then used VLMs for embeddings to construct expressive functional priors. Furthermore, the proposed method is evaluated against various baselines, and experimental results demonstrate that our method consistently improves predictive performance and yields more reliable uncertainty estimates, particularly in out-of-distribution (OOD) detection tasks and data-scarce regimes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.03119v1</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Pengcheng Hao, Huaze Tang, Ercan Engin Kuruoglu, Wenbo Ding</dc:creator>
    </item>
    <item>
      <title>Efficient Computation of Time-Index Powered Weighted Sums Using Cascaded Accumulators</title>
      <link>https://arxiv.org/abs/2509.15069</link>
      <description>arXiv:2509.15069v2 Announce Type: replace 
Abstract: This letter presents a novel approach for \mbox{efficiently} computing time-index powered weighted sums of the form $\sum_{n=0}^{N-1} n^{K} v[n]$ using cascaded accumulators. Traditional direct computation requires $K{\times}N$ general multiplications, which become prohibitive for large $N$, while alternative strategies based on lookup tables or signal reversal require storing entire data blocks. By exploiting accumulator properties, the proposed method eliminates the need for such storage and reduces the multiplicative cost to only $K{+}1$ constant multiplications, enabling efficient real-time implementation. The approach is particularly useful when such sums need to be efficiently computed in sample-by-sample processing systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.15069v2</guid>
      <category>eess.SP</category>
      <category>cs.DS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Deijany Rodriguez Linares, Oksana Moryakova, H{\aa}kan Johansson</dc:creator>
    </item>
    <item>
      <title>On the Performance of Tri-Hybrid Beamforming Using Pinching Antennas</title>
      <link>https://arxiv.org/abs/2511.01099</link>
      <description>arXiv:2511.01099v2 Announce Type: replace 
Abstract: The Pinching-Antenna System (PASS) reconfigures wireless channels through \emph{pinching beamforming}, in which the active positions of pinching antennas (PAs) along dielectric waveguides are optimized to shape the radiation pattern. This article investigates the performance of PASS-enabled tri-hybrid beamforming, where pinched waveguides are integrated with a hybrid digital-analog beamformer to mitigate path loss and enhance spectral efficiency. The channel capacity of the proposed system is characterized by deriving the optimal tri-hybrid beamformer at both the digital and analog domains, as well as the optimal placement of PAs. Closed-form upper and lower bounds of the channel capacity are obtained, leading to a capacity scaling law with respect to the number of PAs. Numerical results verify the tightness of the derived bounds and demonstrate that applying PASS to tri-hybrid beamforming yields a significant performance gain over conventional hybrid beamforming under the same number of radio-frequency chains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01099v2</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhenqiao Cheng, Chongjun Ouyang, Nicola Marchetti</dc:creator>
    </item>
    <item>
      <title>AIRMap: AI-Generated Radio Maps for Wireless Digital Twins</title>
      <link>https://arxiv.org/abs/2511.05522</link>
      <description>arXiv:2511.05522v2 Announce Type: replace 
Abstract: Accurate, low-latency channel modeling is essential for real-time wireless network simulation and digital-twin applications. Traditional modeling methods like ray tracing are however computationally demanding and unsuited to model dynamic conditions. In this paper, we propose AIRMap, a deep-learning framework for ultra-fast radio-map estimation, along with an automated pipeline for creating the largest radio-map dataset to date. AIRMap uses a single-input U-Net autoencoder that processes only a 2D elevation map of terrain and building heights. Trained on 1.2M Boston-area samples and validated across four distinct urban and rural environments with varying terrain and building density, AIRMap predicts path gain with under 4 dB RMSE in 4 ms per inference on an NVIDIA L40S-over 7000x faster than GPU-accelerated ray tracing based radio maps. A lightweight calibration using just 20% of field measurements reduces the median error to approximately 5%, significantly outperforming traditional simulators, which exceed 50% error. Integration into the Colosseum emulator and the Sionna SYS platform demonstrate near-zero error in spectral efficiency and block-error rate compared to measurement-based channels. These findings validate AIRMap's potential for scalable, accurate, and real-time radio map estimation in wireless digital twins.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.05522v2</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ali Saeizadeh, Miead Tehrani-Moayyed, Davide Villa, J. Gordon Beattie Jr., Pedram Johari, Stefano Basagni, Tommaso Melodia</dc:creator>
    </item>
    <item>
      <title>Approximating Univariate Factored Distributions via Message-Passing Algorithms</title>
      <link>https://arxiv.org/abs/2602.01377</link>
      <description>arXiv:2602.01377v2 Announce Type: replace 
Abstract: Gaussian Mixture Models (GMMs) commonly arise in communication systems, particularly in bilinear joint estimation and detection problems. Although the product of GMMs is still a GMM, as the number of factors increases, the number of components in the resulting product GMM grows exponentially. To obtain a tractable approximation for a univariate factored probability density function (PDF), such as a product of GMMs, we investigate iterative message-passing algorithms. Based on Belief Propagation (BP), we propose a Variable Duplication and Gaussian Belief Propagation (VDBP)-based algorithm. The key idea of VDBP is to construct a multivariate measurement model whose marginal posterior is equal to the given univariate factored PDF. We then apply Gaussian BP (GaBP) to transform the global inference problem into local ones. Expectation propagation (EP) is another branch of message passing algorithms. In addition to converting the global approximation problem into local ones, it features a projection operation that ensures the intermediate functions (messages) belong to a desired family. Due to this projection, EP can be used to approximate the factored PDF directly. However, even if every factor is integrable, the division operation in EP may still cause the algorithm to fail when the mean and variance of a non-integrable belief are required. Therefore, this paper proposes two methods that combine EP with our previously proposed techniques for handling non-integrable beliefs to approximate univariate factored distributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01377v2</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Zilu Zhao, Dirk Slock</dc:creator>
    </item>
    <item>
      <title>An Overview of Low-Rank Structures in the Training and Adaptation of Large Models</title>
      <link>https://arxiv.org/abs/2503.19859</link>
      <description>arXiv:2503.19859v3 Announce Type: replace-cross 
Abstract: The substantial computational demands of modern large-scale deep learning present significant challenges for efficient training and deployment. Recent research has revealed a widespread phenomenon wherein deep networks inherently learn low-rank structures in their weights and representations during training. This tutorial paper provides a comprehensive review of advances in identifying and exploiting these low-rank structures, bridging mathematical foundations with practical applications. We present two complementary theoretical perspectives on the emergence of low-rankness: viewing it through the optimization dynamics of gradient descent throughout training, and understanding it as a result of implicit regularization effects at convergence. Practically, these theoretical perspectives provide a foundation for understanding the success of techniques such as Low-Rank Adaptation (LoRA) in fine-tuning, inspire new parameter-efficient low-rank training strategies, and explain the effectiveness of masked training approaches like dropout and masked self-supervised learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.19859v3</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.OC</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Laura Balzano, Tianjiao Ding, Benjamin D. Haeffele, Soo Min Kwon, Qing Qu, Peng Wang, Zhangyang Wang, Can Yaras</dc:creator>
    </item>
    <item>
      <title>Lightweight and Interpretable Transformer via Mixed Graph Algorithm Unrolling for Traffic Forecast</title>
      <link>https://arxiv.org/abs/2505.13102</link>
      <description>arXiv:2505.13102v3 Announce Type: replace-cross 
Abstract: Unlike conventional "black-box" transformers with classical self-attention mechanism, we build a lightweight and interpretable transformer-like neural net by unrolling a mixed-graph-based optimization algorithm to forecast traffic with spatial and temporal dimensions. We construct two graphs: an undirected graph $\mathcal{G}^u$ capturing spatial correlations across geography, and a directed graph $\mathcal{G}^d$ capturing sequential relationships over time. We predict future samples of signal $\mathbf{x}$, assuming it is "smooth" with respect to both $\mathcal{G}^u$ and $\mathcal{G}^d$, where we design new $\ell_2$ and $\ell_1$-norm variational terms to quantify and promote signal smoothness (low-frequency reconstruction) on a directed graph. We design an iterative algorithm based on alternating direction method of multipliers (ADMM), and unroll it into a feed-forward network for data-driven parameter learning. We periodically insert graph learning modules for $\mathcal{G}^u$ and $\mathcal{G}^d$ that play the role of self-attention. Experiments show that our unrolled networks achieve competitive traffic forecast performance as state-of-the-art prediction schemes, while reducing parameter counts drastically.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13102v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>eess.SP</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ji Qi, Tam Thuc Do, Mingxiao Liu, Zhuoshi Pan, Yuzhe Li, Gene Cheung, H. Vicky Zhao</dc:creator>
    </item>
    <item>
      <title>The Role of Entanglement in Quantum Reservoir Computing with Coupled Kerr Nonlinear Oscillators</title>
      <link>https://arxiv.org/abs/2508.11175</link>
      <description>arXiv:2508.11175v2 Announce Type: replace-cross 
Abstract: Quantum Reservoir Computing (QRC) uses quantum dynamics to efficiently process temporal data. In this work, we investigate a QRC framework based on two coupled Kerr nonlinear oscillators, a system well-suited for time-series prediction tasks due to its complex nonlinear interactions and potentially high-dimensional state space. We explore how its performance in forecasting both linear and nonlinear time-series depends on key physical parameters: input drive strength, Kerr nonlinearity, and oscillator coupling, and analyze the role of entanglement in improving the reservoir's computational performance, focusing on its effect on predicting non-trivial time series. Using logarithmic negativity to quantify entanglement and normalized root mean square error (NRMSE) to evaluate predictive accuracy, our results suggest that entanglement provides a computational advantage on average -- up to a threshold in the input frequency -- that persists under some levels of dissipation and dephasing. In particular, we find that higher dissipation rates can enhance performance. While the entanglement advantage manifests as improvements in both average and worst-case performance, it does not lead to improvements in the best-case error. These findings contribute to the broader understanding of quantum reservoirs for high performance, efficient quantum machine learning and time-series forecasting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.11175v2</guid>
      <category>quant-ph</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ali Karimi, Hadi Zadeh-Haghighi, Youssef Kora, Christoph Simon</dc:creator>
    </item>
    <item>
      <title>A High-Performance Training-Free Pipeline for Robust Random Telegraph Signal Characterization via Adaptive Wavelet-Based Denoising and Bayesian Digitization Methods</title>
      <link>https://arxiv.org/abs/2510.10752</link>
      <description>arXiv:2510.10752v2 Announce Type: replace-cross 
Abstract: Random telegraph signal (RTS) analysis is increasingly important for characterizing meaningful temporal fluctuations in physical, chemical, and biological systems. The simplest RTS arises from discrete stochastic switching events between two binary states, quantified by their transition amplitude and dwell times in each state. Quantitative analysis of RTSs provides valuable insights into microscopic processes such as charge trapping in semiconductors. However, analyzing RTS becomes considerably complex when signals exhibit multi-level structures or are corrupted by background white or pink noise. To address these challenges and support high-throughput RTS characterization, we propose a modular, training-free signal processing pipeline that integrates adaptive dual-tree complex wavelet transform (DTCWT) denoising with a lightweight Bayesian digitization strategy. The adaptive DTCWT denoiser incorporates autonomous parameter selection rules for its decomposition level and thresholds, optimizing white noise suppression without manual tuning. Our Bayesian digitizer formulates RTS level assignment as a probabilistic latent-state inference problem incorporating temporal regularization without iterative optimization, effectively resolving binary trap states even under residual notorious background pink noise. Quantitative benchmarking on large synthetic datasets with known ground truth demonstrates improved RTS reconstruction accuracy, trap-state resolution, and dwell-time estimation across diverse noise regimes and multi-trap scenarios, while achieving up to 83x speedups over classical and neural baselines. Qualitative validation on experimental RTS data when no ground truth is available illustrates practical usability and flexibility for real-time or large-scale analysis in real measurement settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.10752v2</guid>
      <category>physics.app-ph</category>
      <category>eess.SP</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tonghe Bai, Ayush Kapoor, Na Young Kim</dc:creator>
    </item>
    <item>
      <title>S4ECG: Exploring the impact of long-range interactions for arrhythmia prediction</title>
      <link>https://arxiv.org/abs/2510.17406</link>
      <description>arXiv:2510.17406v2 Announce Type: replace-cross 
Abstract: The electrocardiogram (ECG) exemplifies biosignal-based time series with continuous, temporally ordered structure reflecting cardiac physiological and pathophysiological dynamics. Detailed analysis of these dynamics has proven challenging, as conventional methods capture either global trends or local waveform features but rarely their simultaneous interplay at high temporal resolution. To bridge global and local signal analysis, we introduce S4ECG, a novel deep learning architecture leveraging structured state space models for multi-epoch arrhythmia classification. Our joint multi-epoch predictions significantly outperform single-epoch approaches by 1.0-11.6% in macro-AUROC, with atrial fibrillation specificity improving from 0.718-0.979 to 0.967-0.998, demonstrating superior performance in-distribution and enhanced out-of-distribution robustness. Systematic investigation reveals optimal temporal dependency windows spanning 10-20 minutes for peak performance. This work contributes to a paradigm shift toward temporally-aware arrhythmia detection algorithms, opening new possibilities for ECG interpretation, in particular for complex arrhythmias like atrial fibrillation and atrial flutter.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.17406v2</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tiezhi Wang, Wilhelm Haverkamp, Nils Strodthoff</dc:creator>
    </item>
    <item>
      <title>Time2Vec Transformer for Robust Gesture Recognition from Low-Density sEMG</title>
      <link>https://arxiv.org/abs/2602.01855</link>
      <description>arXiv:2602.01855v2 Announce Type: replace-cross 
Abstract: Accurate and responsive myoelectric prosthesis control typically relies on complex, dense multi-sensor arrays, which limits consumer accessibility. This paper presents a novel, data-efficient deep learning framework designed to achieve precise and accurate control using minimal sensor hardware. Leveraging an external dataset of 8 subjects, our approach implements a hybrid Transformer optimized for sparse, two-channel surface electromyography (sEMG). Unlike standard architectures that use fixed positional encodings, we integrate Time2Vec learnable temporal embeddings to capture the stochastic temporal warping inherent in biological signals. Furthermore, we employ a normalized additive fusion strategy that aligns the latent distributions of spatial and temporal features, preventing the destructive interference common in standard implementations. A two-stage curriculum learning protocol is utilized to ensure robust feature extraction despite data scarcity. The proposed architecture achieves a state-of-the-art multi-subject F1-score of 95.7% $\pm$ 0.20% for a 10-class movement set, statistically outperforming both a standard Transformer with fixed encodings and a recurrent CNN-LSTM model. Architectural optimization reveals that a balanced allocation of model capacity between spatial and temporal dimensions yields the highest stability. Furthermore, while direct transfer to a new unseen subject led to poor accuracy due to domain shifts, a rapid calibration protocol utilizing only two trials per gesture recovered performance from 21.0% $\pm$ 2.98% to 96.9% $\pm$ 0.52%. By validating that high-fidelity temporal embeddings can compensate for low spatial resolution, this work challenges the necessity of high-density sensing. The proposed framework offers a robust, cost-effective blueprint for next-generation prosthetic interfaces capable of rapid personalization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01855v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>eess.SP</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Blagoj Hristov, Hristijan Gjoreski, Vesna Ojleska Latkoska, Gorjan Nadzinski</dc:creator>
    </item>
  </channel>
</rss>
