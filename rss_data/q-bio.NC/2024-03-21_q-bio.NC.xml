<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 21 Mar 2024 04:00:00 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 21 Mar 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Beyond Sight: Probing Alignment Between Image Models and Blind V1</title>
      <link>https://arxiv.org/abs/2403.12990</link>
      <description>arXiv:2403.12990v1 Announce Type: new 
Abstract: Neural activity in the visual cortex of blind humans persists in the absence of visual stimuli. However, little is known about the preservation of visual representation capacity in these cortical regions, which could have significant implications for neural interfaces such as visual prostheses. In this work, we present a series of analyses on the shared representations between evoked neural activity in the primary visual cortex (V1) of a blind human with an intracortical visual prosthesis, and latent visual representations computed in deep neural networks (DNNs). In the absence of natural visual input, we examine two alternative forms of inducing neural activity: electrical stimulation and mental imagery. We first quantitatively demonstrate that latent DNN activations are aligned with neural activity measured in blind V1. On average, DNNs with higher ImageNet accuracy or higher sighted primate neural predictivity are more predictive of blind V1 activity. We further probe blind V1 alignment in ResNet-50 and propose a proof-of-concept approach towards interpretability of blind V1 neurons. The results of these studies suggest the presence of some form of natural visual processing in blind V1 during electrically evoked visual perception and present unique directions in mechanistically understanding and interfacing with blind V1.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12990v1</guid>
      <category>q-bio.NC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jacob Granley, Galen Pogoncheff, Alfonso Rodil, Leili Soo, Lily Marie Turkstra, Lucas Gil Nadolskis, Arantxa Alfaro Saez, Cristina Soto Sanchez, Eduardo Fernandez Jover, Michael Beyeler</dc:creator>
    </item>
    <item>
      <title>A systematic review on visual-processing deficits in Neurofibromatosis type 1: what possible impact on learning to read?</title>
      <link>https://arxiv.org/abs/2403.13033</link>
      <description>arXiv:2403.13033v1 Announce Type: new 
Abstract: This systematic review aimed to examine the possible implication of visual-perceptual, visuo-attentional and oculomotor processing in the reading deficits frequently experienced by children with Neurofibromatosis type 1 (NF1), as previously shown in dyslexia. Using PRISMA methodological guidelines, we examined 49 studies; most of these reported visual-processing deficits in this population, raising the importance of directly studying the visuo-perceptual and visuo-attentional processes and eye-movement control involved in the learning-to-read process in NF1. The discussion provides a reflection for a better understanding of how visual-processing skills interact with reading deficits in NF1, as well as new avenues for their screening and care.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.13033v1</guid>
      <category>q-bio.NC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1080/87565641.2024.2326151</arxiv:DOI>
      <arxiv:journal_reference>Developmental Neuropsychology, 2024</arxiv:journal_reference>
      <dc:creator>Marie Vernet (LPL, ToNIC), St\'ephanie Ducrot (LPL, AMU, ILCB), Yves Chaix (ToNIC)</dc:creator>
    </item>
    <item>
      <title>Network bottlenecks and task structure control the evolution of interpretable learning rules in a foraging agent</title>
      <link>https://arxiv.org/abs/2403.13649</link>
      <description>arXiv:2403.13649v1 Announce Type: new 
Abstract: Developing reliable mechanisms for continuous local learning is a central challenge faced by biological and artificial systems. Yet, how the environmental factors and structural constraints on the learning network influence the optimal plasticity mechanisms remains obscure even for simple settings. To elucidate these dependencies, we study meta-learning via evolutionary optimization of simple reward-modulated plasticity rules in embodied agents solving a foraging task. We show that unconstrained meta-learning leads to the emergence of diverse plasticity rules. However, regularization and bottlenecks to the model help reduce this variability, resulting in interpretable rules. Our findings indicate that the meta-learning of plasticity rules is very sensitive to various parameters, with this sensitivity possibly reflected in the learning rules found in biological networks. When included in models, these dependencies can be used to discover potential objective functions and details of biological learning via comparisons with experimental observations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.13649v1</guid>
      <category>q-bio.NC</category>
      <category>cs.NE</category>
      <category>nlin.AO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Emmanouil Giannakakis, Sina Khajehabdollahi, Anna Levina</dc:creator>
    </item>
    <item>
      <title>Thalamocortical interactions shape hierarchical neural variability during stimulus perception</title>
      <link>https://arxiv.org/abs/2403.09965</link>
      <description>arXiv:2403.09965v3 Announce Type: replace 
Abstract: The brain is hierarchically organized to process sensory signals. But, to what extent do functional connections within and across areas shape this hierarchical order? We addressed this problem in the thalamocortical network, while monkeys judged the presence or absence of a vibrotactile stimulus. We quantified the variability by means of intrinsic timescales and Fano factor, and functional connectivity by means of a directionality measure in simultaneously recorded neurons sharing the same cutaneous receptive field from the somatosensory thalamus (VPL) and areas 3b and 1 from the somatosensory cortex. During the pre-stimulus periods, VPL and area 3b exhibited similarly fast dynamics while area 1 showed much slower timescales. Furthermore, during the stimulus presence, the Fano factor increased along the network VPL-3b-1. In parallel, VPL established two separate main feedforward pathways with areas 3b and 1 to process stimulus information. While feedforward interactions from VPL and area 3b were favored by neurons within specific Fano factor ranges, neural variability in area 1 was invariant to the incoming pathways. In contrast to VPL and area 3b, during the stimulus arrival, area 1 showed significant intra-area interactions, which mainly pointed to neurons with slow intrinsic timescales. Overall, our results suggest that the lower variability of VPL and area 3b regulates feedforward thalamocortical communication, while the higher variability of area 1 supports intra-cortical interactions during sensory processing. These results provide evidence of a hierarchical order along the thalamocortical network.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.09965v3</guid>
      <category>q-bio.NC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Adri\`a Tauste Campo, Antonio Zainos, Yuriria V\'azquez, Raul Adell Segarra, Manuel \'Alvarez, Gustavo Deco, H\'ector D\'iaz, Sergio Parra, Ranulfo Romo, Rom\'an Rossi-Pool</dc:creator>
    </item>
    <item>
      <title>Extracting the Multiscale Causal Backbone of Brain Dynamics</title>
      <link>https://arxiv.org/abs/2311.00118</link>
      <description>arXiv:2311.00118v2 Announce Type: replace-cross 
Abstract: The bulk of the research effort on brain connectivity revolves around statistical associations among brain regions, which do not directly relate to the causal mechanisms governing brain dynamics. Here we propose the multiscale causal backbone (MCB) of brain dynamics, shared by a set of individuals across multiple temporal scales, and devise a principled methodology to extract it.
  Our approach leverages recent advances in multiscale causal structure learning and optimizes the trade-off between the model fit and its complexity. Empirical assessment on synthetic data shows the superiority of our methodology over a baseline based on canonical functional connectivity networks. When applied to resting-state fMRI data, we find sparse MCBs for both the left and right brain hemispheres. Thanks to its multiscale nature, our approach shows that at low-frequency bands, causal dynamics are driven by brain regions associated with high-level cognitive functions; at higher frequencies instead, nodes related to sensory processing play a crucial role. Finally, our analysis of individual multiscale causal structures confirms the existence of a causal fingerprint of brain connectivity, thus supporting the existing extensive research in brain connectivity fingerprinting from a causal perspective.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.00118v2</guid>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gabriele D'Acunto, Francesco Bonchi, Gianmarco De Francisci Morales, Giovanni Petri</dc:creator>
    </item>
  </channel>
</rss>
