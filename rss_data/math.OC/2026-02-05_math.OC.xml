<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 05 Feb 2026 05:00:28 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Fast Relax-and-Round Approach to Unit Commitment with Sub Hourly Mechanical and Ramp Constraints</title>
      <link>https://arxiv.org/abs/2602.03977</link>
      <description>arXiv:2602.03977v1 Announce Type: new 
Abstract: We propose a novel computational method for unit commitment (UC), which does not require linearized approximation and provides several orders of magnitude performance improvement over current state-of-the-art. The performance improvement is achieved by introducing a heuristic tailored for UC problems. The method can be implemented using existing continuous optimization solvers and adapted for different applications. We demonstrate value of the new method in examples of advanced UC analyses at the scale where use of current state-of-the-art tools is infeasible. We expect that the capability demonstrated in this paper will be critical to address emerging power systems challenges with more volatile large loads, such as data centers, and generation that is composed of larger number of smaller units, including significant behind-the-meter generation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.03977v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shaked Regev, Eve Tsybina, Slaven Peles</dc:creator>
    </item>
    <item>
      <title>Convex duality contracts for production-grade mathematical optimization</title>
      <link>https://arxiv.org/abs/2602.04048</link>
      <description>arXiv:2602.04048v1 Announce Type: new 
Abstract: Deploying mathematical optimization in autonomous production systems requires precise contracts for objects returned by an optimization solver. Unfortunately, conventions on dual solution and infeasibility certificates (rays) vary widely across solvers and classes of problems. This paper presents the theoretical framework used by MathOpt (a domain-specific language developed and used at Google) to unify these notions. We propose an abstract primal-dual pair based on a simplified Fenchel duality scheme that allows for the mechanical derivation of dual problems and associated contracts for all classes of problems currently supported by MathOpt (including those with linear and quadratic objectives plus linear, conic, quadratic, and two-sided linear constraints). We also show how these contracts can improve clarity of complementary-slackness based optimality conditions for certain classes of problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.04048v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Juan Pablo Vielma, Ross Anderson, Joey Huchette</dc:creator>
    </item>
    <item>
      <title>New Outer Approximation Algorithms for Nonsmooth Convex MINLP Problems</title>
      <link>https://arxiv.org/abs/2602.04122</link>
      <description>arXiv:2602.04122v1 Announce Type: new 
Abstract: This paper presents a novel outer approximation algorithm for nonsmooth mixed-integer nonlinear programming (MINLP) problems. The method proceeds by fixing the integer variables and solving the resulting nonlinear convex subproblem. When the subproblem is feasible, valid linear cuts are derived by computing suitable subgradients of the objective and constraint functions at the optimal solution, utilizing KKT optimality conditions. A new parameter, defined through the nonlinear constraint functions, is introduced to facilitate the generation of these cuts. For infeasible subproblems, a feasibility problem is solved, and valid linear cuts are generated via KKT-based subgradients to exclude the infeasible integer assignment.
  By integrating both types of cuts, a mixed-integer linear programming (MILP) master problem is formulated and proven equivalent to the original MINLP. This equivalence underpins a new outer approximation algorithm, which is guaranteed to terminate after a finite number of iterations.
  Numerical experiments on smooth convex MINLP problems demonstrate that the proposed algorithm produces tighter MILP relaxations than the classical outer approximation method. Furthermore, the approach offers an alternative mechanism for generating linear cuts, extending beyond reliance solely on first-order Taylor expansions and shows that the efficiency of outer approximation algorithm is strongly dependent on the inherent structure of the MINLP problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.04122v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Zhou Wei, He-Yi Liu, Bo Zeng</dc:creator>
    </item>
    <item>
      <title>Variable Aggregation-based Perspective Reformulation for Mixed-Integer Convex Optimization with Symmetry</title>
      <link>https://arxiv.org/abs/2602.04123</link>
      <description>arXiv:2602.04123v1 Announce Type: new 
Abstract: This paper addresses the challenging issue of symmetry in mixed-integer convex optimization problems, which frequently arise in real-world applications such as the unit commitment problem. Although variable aggregation techniques have been employed to mitigate symmetry, their impact on tightening the corresponding continuous relaxation has not been thoroughly investigated. In this work, we propose a new formulation that integrates the perspective reformulation method into the variable aggregation framework, yielding a tighter continuous relaxation for mixed-integer convex optimization problems with symmetric structures. We prove that, in the presence of symmetry, the convex hull of the feasible region associated with each set of aggregated variables can be exactly characterized. These results demonstrate the effectiveness of the proposed reformulation and establish new theoretical foundations for achieving tightness in variable aggregation-based mixed-integer programming formulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.04123v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Junhao Wu, Shaoze Li, Cheng Lu, Zhibin Deng, Shu-Cherng Fang</dc:creator>
    </item>
    <item>
      <title>Inertial dynamical systems and accelerated algorithms with implicit Hessian-driven damping for nonconvex optimization</title>
      <link>https://arxiv.org/abs/2602.04143</link>
      <description>arXiv:2602.04143v1 Announce Type: new 
Abstract: This paper is devoted to the investigation of inertial dynamical systems with implicit Hessian-driven damping for strongly quasiconvex optimization which is a specific class of nonconvex optimization problems. We first establish exponential convergence rate properties for this system without requiring Lipschitz continuity of the gradient on the function. Then, we obtain an inertial accelerated algorithm for minimizing strongly quasiconvex functions through natural explicit time discretization to the dynamical system. Meanwhile, we consider an exogenous additive perturbation term to this dynamical system and obtain the corresponding algorithm. By utilizing the Lyapunov method, we establish convergence rates of iterative sequences and their function values. Furthermore, we conduct numerical experiments to illustrate the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.04143v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zeying Gao, Xiangkai Sun, Liang He</dc:creator>
    </item>
    <item>
      <title>Restart-Free (Accelerated) Gradient Sliding Methods for Strongly Convex Composite Optimization</title>
      <link>https://arxiv.org/abs/2602.04161</link>
      <description>arXiv:2602.04161v1 Announce Type: new 
Abstract: In this paper, we study a class of composite optimization problems whose objective function is given by the summation of a general smooth and nonsmooth component, together with a relatively simple nonsmooth term. While restart strategies are commonly employed in first-order methods to achieve optimal convergence under strong convexity, they introduce structural complexity and practical overhead, making algorithm design and nesting cumbersome. To address this, we propose a \emph{restart-free} stochastic gradient sliding algorithm that eliminates the need for explicit restart phases when the simple nonsmooth component is strongly convex. Through a novel and carefully designed parameter selection strategy, we prove that the proposed algorithm achieves an $\epsilon$-solution with only $\mathcal{O}(\log(\frac{1}{\epsilon}))$ gradient evaluations for the smooth component and $\mathcal{O}(\frac{1}{\epsilon})$ stochastic subgradient evaluations for the nonsmooth component, matching the optimal complexity of existing multi-phase (restart-based) methods. Moreover, for the case where the nonsmooth component is structured, allowing the overall problem to be reformulated as a bilinear saddle-point problem, we develop a restart-free accelerated stochastic gradient sliding algorithm. We show that the resulting method requires only $\mathcal{O}(\log(\frac{1}{\epsilon}))$ gradient computations for the smooth component while preserving an overall iteration complexity of $\mathcal{O}(\frac{1}{\sqrt{\epsilon}})$ for solving the corresponding saddle-point problems. Our work thus provides simpler, restart-f</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.04161v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xinming Wu, Zi Xu, Huiling Zhang</dc:creator>
    </item>
    <item>
      <title>Sampled-Data Wasserstein Distributionally Robust Control of Multiplicative Systems: A Convex Relaxation with Performance Guarantees</title>
      <link>https://arxiv.org/abs/2602.04219</link>
      <description>arXiv:2602.04219v1 Announce Type: new 
Abstract: This paper investigates the robust optimal control of sampled-data stochastic systems with multiplicative noise and distributional ambiguity. We consider a class of discrete-time optimal control problems where the controller \emph{jointly} selects a feedback policy and a sampling period to maximize the worst-case expected concave utility of the inter-sample growth factor. Modeling uncertainty via a Wasserstein ambiguity set, we confront the structural obstacle of~``concave-max'' geometry arising from maximizing a concave utility against an adversarial distribution. Unlike standard convex loss minimization, the dual reformulation here requires a minimax interchange within the semi-infinite constraints, where the utility's concavity precludes exact strong duality. To address this, we utilize a general minimax inequality to derive a tractable convex relaxation. Our approach yields a rigorous lower bound that functions as a probabilistic performance guarantee. We establish an explicit, non-asymptotic bound on the resulting duality gap, proving that the approximation error is uniformly controlled by the Lipschitz-smoothness of the stage reward and the diameter of the disturbance support. Furthermore, we introduce necessary and sufficient conditions for \emph{robust viability}, ensuring state positivity invariance across the entire ambiguity set. Finally, we bridge the gap between static optimization and dynamic performance, proving that the optimal value of the relaxation serves as a rigorous deterministic floor for the asymptotic average utility rate almost surely. The framework is illustrated on a log-optimal portfolio control problem, which serves as a canonical instance of multiplicative stochastic control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.04219v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>q-fin.PM</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chung-Han Hsieh</dc:creator>
    </item>
    <item>
      <title>An Improved Boosted DC Algorithm for Nonsmooth Functions with Applications in Image Recovery</title>
      <link>https://arxiv.org/abs/2602.04237</link>
      <description>arXiv:2602.04237v1 Announce Type: new 
Abstract: We propose a new approach to perform the boosted difference of convex functions algorithm (BDCA) on non-smooth and non-convex problems involving the difference of convex (DC) functions. The recently proposed BDCA uses an extrapolation step from the point computed by the classical DC algorithm (DCA) via a line search procedure in a descent direction to get an additional decrease of the objective function and accelerate the convergence of DCA. However, when the first function in DC decomposition is non-smooth, the direction computed by BDCA can be ascent and a monotone line search cannot be performed. In this work, we proposed a monotone improved boosted difference of convex functions algorithm (IBDCA) for certain types of non-smooth DC programs, namely those that can be formulated as the difference of a possibly non-smooth function and a smooth one. We show that any cluster point of the sequence generated by IBDCA is a critical point of the problem under consideration and that the corresponding objective value is monotonically decreasing and convergent. We also present the global convergence and the convergent rate under the Kurdyka-Lojasiewicz property. The applications of IBDCA in image recovery show the effectiveness of our proposed method. The corresponding numerical experiments demonstrate that our IBDCA outperforms DCA and other state-of-the-art DC methods in both computational time and number of iterations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.04237v1</guid>
      <category>math.OC</category>
      <category>cs.CV</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>ZeYu Li, Te Qi, TieYong Zeng</dc:creator>
    </item>
    <item>
      <title>A Path-Complete Approach for Optimal Control of Switched Systems</title>
      <link>https://arxiv.org/abs/2602.04310</link>
      <description>arXiv:2602.04310v1 Announce Type: new 
Abstract: We study the problem of estimating the value function of discrete-time switched systems under arbitrary switching. Unlike the switched LQR problem, where both inputs and mode sequences are optimized, we consider the case where switching is exogenous. For such systems, the number of possible mode sequences grows exponentially with time, making the exact computation of the value function intractable. This motivates the development of tractable bounds that approximate it. We propose a novel framework, based on path-complete graphs, for constructing computable upper bounds on the value function. In this framework, multiple quadratic functions are combined through a directed graph that encodes dynamic programming inequalities, yielding convex and sound formulations. For example, for switched linear systems with quadratic cost, we derive tractable LMI-based formulations and provide computational complexity bounds. We further establish approximation guarantees for the upper bounds and show asymptotic non-conservativeness using concepts from graph theory. Finally, we extend the approach to controller synthesis for systems with affine control inputs and demonstrate its effectiveness on numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.04310v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>L\'ea Ninite, Adrien Banse, Guillaume O. Berger, Rapha\"el M. Jungers</dc:creator>
    </item>
    <item>
      <title>Lower Bounds for Frank-Wolfe on Strongly Convex Sets</title>
      <link>https://arxiv.org/abs/2602.04378</link>
      <description>arXiv:2602.04378v1 Announce Type: new 
Abstract: We present a constructive lower bound of $\Omega(1/\sqrt{\varepsilon})$ for Frank-Wolfe (FW) when both the objective and the constraint set are smooth and strongly convex, showing that the known uniform $\mathcal{O}(1/\sqrt{\varepsilon})$ guarantees in this regime are tight. It is known that under additional assumptions on the position of the optimizer, FW can converge linearly. However, it remained unclear whether strong convexity of the set can yield rates uniformly faster than $\mathcal{O}(1/\sqrt{\varepsilon})$, i.e., irrespective of the position of the optimizer. To investigate this question, we focus on a simple yet representative problem class: minimizing a strongly convex quadratic over the Euclidean unit ball, with the optimizer on the boundary. We analyze the dynamics of FW for this problem in detail and develop a novel computational approach to construct worst-case FW trajectories, which is of independent interest. Guided by these constructions, we develop an analytical proof establishing the lower bound.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.04378v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jannis Halbey, Daniel Deza, Max Zimmer, Christophe Roux, Bartolomeo Stellato, Sebastian Pokutta</dc:creator>
    </item>
    <item>
      <title>Decentralized Optimization with Mixed Affine Constraints</title>
      <link>https://arxiv.org/abs/2602.04479</link>
      <description>arXiv:2602.04479v1 Announce Type: new 
Abstract: This paper considers decentralized optimization of convex functions with mixed affine equality constraints involving both local and global variables. Constraints on global variables may vary across different nodes in the network, while local variables are subject to coupled and node-specific constraints. Such problem formulations arise in machine learning applications, including federated learning and multi-task learning, as well as in resource allocation and distributed control. We analyze this problem under smooth and non-smooth assumptions, considering both strongly convex and general convex objective functions. Our main contribution is an optimal algorithm for the smooth, strongly convex regime, whose convergence rate matches established lower complexity bounds. We further provide near-optimal methods for the remaining cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.04479v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Demyan Yarmoshik, Nhat Trung Nguyen, Alexander Rogozin, Alexander Gasnikov</dc:creator>
    </item>
    <item>
      <title>A GPU-accelerated Nonlinear Branch-and-Bound Framework for Sparse Linear Models</title>
      <link>https://arxiv.org/abs/2602.04551</link>
      <description>arXiv:2602.04551v1 Announce Type: new 
Abstract: We study exact sparse linear regression with an $\ell_0-\ell_2$ penalty and develop a branch-and-bound (BnB) algorithm explicitly designed for GPU execution. Starting from a perspective reformulation, we derive an interval relaxation that can be solved by ADMM with closed-form, coordinate-wise updates. We structure these updates so that the main work at each BnB node reduces to batched matrix-vector operations with a shared data matrix, enabling fine-grained parallelism across coordinates and coarse-grained parallelism across many BnB nodes on a single GPU. Feasible solutions (upper bounds) are generated by a projected gradient method on the active support, implemented in a batched fashion so that many candidate supports are updated in parallel on the GPU. We discuss practical design choices such as memory layout, batching strategies, and load balancing across nodes that are crucial for obtaining good utilization on modern GPUs. On synthetic and real high-dimensional datasets, our GPU-based approach achieves clear runtime improvements over a CPU implementation of our method, an existing specialized BnB method, and commercial MIP solvers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.04551v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiang Meng, Ryan Lucas, Rahul Mazumder</dc:creator>
    </item>
    <item>
      <title>Mobility-as-a-service (MaaS) system as a multi-leader-multi-follower game: A single-level variational inequality (VI) formulation</title>
      <link>https://arxiv.org/abs/2601.19880</link>
      <description>arXiv:2601.19880v1 Announce Type: cross 
Abstract: This study models a Mobility-as-a-Service (MaaS) system as a multi-leader-multi-follower game that captures the complex interactions among the MaaS platform, service operators, and travelers. We consider a coopetitive setting where the MaaS platform purchases service capacity from service operators and sells multi-modal trips to travelers following an origin-destination-based pricing scheme; meanwhile, service operators use their remaining capacities to serve single-modal trips. As followers, travelers make both mode choices, including whether to use MaaS, and route choices in the multi-modal transportation network, subject to prices and congestion. Inspired by the dual formulation for traffic assignment problems, we propose a novel single-level variational inequality (VI) formulation by introducing a virtual traffic operator, along with the MaaS platform and multiple service operators. A key advantage of the proposed VI formulation is that it supports parallel solution procedures and thus enables large-scale applications. We prove that an equilibrium solution always exists given the negotiated wholesale price of service capacity. Numerical experiments on a small network further demonstrate that the wholesale price can be tailored to align with varying system-wide objectives. The proposed MaaS system demonstrates potential for creating a "win-win-win" outcome -- service operators and travelers are better off compared to the "without MaaS" scenario, meanwhile the MaaS platform remains profitable. Such a Pareto-improving regime can be explicitly specified with the wholesale capacity price. Similar conclusions are drawn from the experiment of an extended multi-modal Sioux Falls network, which also validates the scalability of the proposed model and solution algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.19880v1</guid>
      <category>econ.GN</category>
      <category>cs.GT</category>
      <category>math.OC</category>
      <category>q-fin.EC</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rui Yao, Xinyu Ma, Kenan Zhang</dc:creator>
    </item>
    <item>
      <title>Byzantine Machine Learning: MultiKrum and an optimal notion of robustness</title>
      <link>https://arxiv.org/abs/2602.03899</link>
      <description>arXiv:2602.03899v1 Announce Type: cross 
Abstract: Aggregation rules are the cornerstone of distributed (or federated) learning in the presence of adversaries, under the so-called Byzantine threat model. They are also interesting mathematical objects from the point of view of robust mean estimation. The Krum aggregation rule has been extensively studied, and endowed with formal robustness and convergence guarantees. Yet, MultiKrum, a natural extension of Krum, is often preferred in practice for its superior empirical performance, even though no theoretical guarantees were available until now. In this work, we provide the first proof that MultiKrum is a robust aggregation rule, and bound its robustness coefficient. To do so, we introduce $\kappa^\star$, the optimal *robustness coefficient* of an aggregation rule, which quantifies the accuracy of mean estimation in the presence of adversaries in a tighter manner compared with previously adopted notions of robustness. We then construct an upper and a lower bound on MultiKrum's robustness coefficient. As a by-product, we also improve on the best-known bounds on Krum's robustness coefficient. We show that MultiKrum's bounds are never worse than Krum's, and better in realistic regimes. We illustrate this analysis by an experimental investigation on the quality of the lower bound.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.03899v1</guid>
      <category>stat.ML</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Gilles Bareilles, Wassim Bouaziz, Julien Fageot, El-Mahdi El-Mhamdi</dc:creator>
    </item>
    <item>
      <title>The Role of Target Update Frequencies in Q-Learning</title>
      <link>https://arxiv.org/abs/2602.03911</link>
      <description>arXiv:2602.03911v1 Announce Type: cross 
Abstract: The target network update frequency (TUF) is a central stabilization mechanism in (deep) Q-learning. However, their selection remains poorly understood and is often treated merely as another tunable hyperparameter rather than as a principled design decision. This work provides a theoretical analysis of target fixing in tabular Q-learning through the lens of approximate dynamic programming. We formulate periodic target updates as a nested optimization scheme in which each outer iteration applies an inexact Bellman optimality operator, approximated by a generic inner loop optimizer. Rigorous theory yields a finite-time convergence analysis for the asynchronous sampling setting, specializing to stochastic gradient descent in the inner loop. Our results deliver an explicit characterization of the bias-variance trade-off induced by the target update period, showing how to optimally set this critical hyperparameter. We prove that constant target update schedules are suboptimal, incurring a logarithmic overhead in sample complexity that is entirely avoidable with adaptive schedules. Our analysis shows that the optimal target update frequency increases geometrically over the course of the learning process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.03911v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Simon Weissmann, Tilman Aach, Benedikt Wille, Sebastian Kassing, Leif D\"oring</dc:creator>
    </item>
    <item>
      <title>RAPO: Risk-Aware Preference Optimization for Generalizable Safe Reasoning</title>
      <link>https://arxiv.org/abs/2602.04224</link>
      <description>arXiv:2602.04224v1 Announce Type: cross 
Abstract: Large Reasoning Models (LRMs) have achieved tremendous success with their chain-of-thought (CoT) reasoning, yet also face safety issues similar to those of basic language models. In particular, while algorithms are designed to guide them to deliberately refuse harmful prompts with safe reasoning, this process often fails to generalize against diverse and complex jailbreak attacks. In this work, we attribute these failures to the generalization of the safe reasoning process, particularly their insufficiency against complex attack prompts. We provide both theoretical and empirical evidence to show the necessity of a more sufficient safe reasoning process to defend against advanced attack prompts. Building on this insight, we propose a Risk-Aware Preference Optimization (RAPO) framework that enables LRM to adaptively identify and address the safety risks with appropriate granularity in its thinking content. Extensive experiments demonstrate that RAPO successfully generalizes multiple LRMs' safe reasoning adaptively across diverse attack prompts whilst preserving general utility, contributing a robust alignment technique for LRM safety. Our code is available at https://github.com/weizeming/RAPO.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.04224v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.CR</category>
      <category>math.OC</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zeming Wei, Qiaosheng Zhang, Xia Hu, Xingcheng Xu</dc:creator>
    </item>
    <item>
      <title>Parameter Privacy-Preserving Data Sharing: A Particle-Belief MDP Formulation</title>
      <link>https://arxiv.org/abs/2602.04262</link>
      <description>arXiv:2602.04262v1 Announce Type: cross 
Abstract: This paper investigates parameter-privacy-preserving data sharing in continuous-state dynamical systems, where a data owner designs a data-sharing policy to support downstream estimation and control while preventing adversarial inference of a sensitive parameter. This data-sharing problem is formulated as an optimization problem that trades off privacy leakage and the impact of data sharing on the data owner's utility, subject to a data-usability constraint. We show that this problem admits an equivalent belief Markov decision process (MDP) formulation, which provides a simplified representation of the optimal policy. To efficiently characterize information-theoretic privacy leakage in continuous state and action spaces, we propose a particle-belief MDP formulation that tracks the parameter posterior via sequential Monte Carlo, yielding a tractable belief-state approximation that converges asymptotically as the number of particles increases. We further derive a tractable closed-form upper bound on particle-based MI via Gaussian mixture approximations, which enables efficient optimization of the particle-belief MDP. Experiments on a mixed-autonomy platoon show that the learned continuous policy substantially impedes inference attacks on human-driving behavior parameters while maintaining data usability and system performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.04262v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haokun Yu, Jingyuan Zhou, Kaidi Yang</dc:creator>
    </item>
    <item>
      <title>Peak Bounds for the Estimation Error under Sensor Attacks</title>
      <link>https://arxiv.org/abs/2602.04568</link>
      <description>arXiv:2602.04568v1 Announce Type: cross 
Abstract: This paper investigates bounds on the estimation error of a linear system affected by norm-bounded disturbances and full sensor attacks. The system is equipped with a detector that evaluates the norm of the innovation signal to detect faults, and the attacker wants to avoid detection. We utilize induced $L_\infty$ system norms, also called \emph{peak-to-peak} norms, to compare the estimation error bounds under nominal operations and under attack. This leads to a sufficient condition for when the bound on the estimation error is smaller during an attack than during nominal operation. This condition is independent of the attack strategy and depends only on the attacker's desire to remain undetected and (indirectly) the observer gain. Therefore, we investigate both an observer design method, that seeks to reduce the error bound under attack while keeping the nominal error bound low, and detector threshold tuning. As a numerical illustration, we show how a sensor attack can deactivate a robust safety filter based on control barrier functions if the attacked error bound is larger than the nominal one. We also statistically evaluate our observer design method and the effect of the detector threshold.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.04568v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Axel Stafstr\"om, Daniel Arnstr\"om, Adam Miksits, David Umsonst</dc:creator>
    </item>
    <item>
      <title>The matrix-vector complexity of $Ax=b$</title>
      <link>https://arxiv.org/abs/2602.04842</link>
      <description>arXiv:2602.04842v1 Announce Type: cross 
Abstract: Matrix-vector algorithms, particularly Krylov subspace methods, are widely viewed as the most effective algorithms for solving large systems of linear equations. This paper establishes lower bounds on the worst-case number of matrix-vector products needed by such an algorithm to approximately solve a general linear system. The first main result is that, for a matrix-vector algorithm which can perform products with both a matrix and its transpose, $\Omega(\kappa \log(1/\varepsilon))$ matrix-vector products are necessary to solve a linear system with condition number $\kappa$ to accuracy $\varepsilon$, matching an upper bound for conjugate gradient on the normal equations. The second main result is that one-sided algorithms, which lack access to the transpose, must use $n$ matrix-vector products to solve an $n \times n$ linear system, even when the problem is perfectly conditioned. Both main results include explicit constants that match known upper bounds up to a factor of four. These results rigorously demonstrate the limitations of matrix-vector algorithms and confirm the optimality of widely used Krylov subspace algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.04842v1</guid>
      <category>cs.DS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Micha{\l} Derezi\'nski, Ethan N. Epperly, Raphael A. Meyer</dc:creator>
    </item>
    <item>
      <title>Dictionary Learning under Symmetries via Group Representations</title>
      <link>https://arxiv.org/abs/2305.19557</link>
      <description>arXiv:2305.19557v3 Announce Type: replace 
Abstract: The dictionary learning problem can be viewed as a data-driven process to learn a suitable transformation so that data is sparsely represented directly from example data. In this paper, we examine the problem of learning a dictionary that is invariant under a pre-specified group of transformations. Natural settings include Cryo-EM, multi-object tracking, synchronization, pose estimation, etc. We specifically study this problem under the lens of mathematical representation theory. Leveraging the power of non-abelian Fourier analysis for functions over compact groups, we prescribe an algorithmic recipe for learning dictionaries that obey such invariances. We relate the dictionary learning problem in the physical domain, which is naturally modelled as being infinite dimensional, with the associated computational problem, which is necessarily finite dimensional. We establish that the dictionary learning problem can be effectively understood as an optimization instance over certain matrix orbitopes having a particular block-diagonal structure governed by the irreducible representations of the group of symmetries. This perspective enables us to introduce a band-limiting procedure which obtains dimensionality reduction in applications. We provide guarantees for our computational ansatz to provide a desirable dictionary learning outcome. We apply our paradigm to investigate the dictionary learning problem for the groups SO(2) and SO(3). While the SO(2)-orbitope admits an exact spectrahedral description, substantially less is understood about the SO(3)-orbitope. We describe a tractable spectrahedral outer approximation of the SO(3)-orbitope, and contribute an alternating minimization paradigm to perform optimization in this setting. We provide numerical experiments to highlight the efficacy of our approach in learning SO(3)-invariant dictionaries, both on synthetic and on real world data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.19557v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>stat.ML</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Subhroshekhar Ghosh, Aaron Y. R. Low, Yong Sheng Soh, Zhuohang Feng, Brendan K. Y. Tan</dc:creator>
    </item>
    <item>
      <title>An Overview and Comparison of Spectral Bundle Methods for Primal and Dual Semidefinite Programs</title>
      <link>https://arxiv.org/abs/2307.07651</link>
      <description>arXiv:2307.07651v2 Announce Type: replace 
Abstract: The spectral bundle method developed by Helmberg and Rendl is well-established for solving large-scale semidefinite programs (SDPs) in the dual form, especially when the SDPs admit $\textit{low-rank primal solutions}$. Under mild regularity conditions, a recent result by Ding and Grimmer has established fast linear convergence rates when the bundle method captures $\textit{the rank of primal solutions}$. In this paper, we present an overview and comparison of spectral bundle methods for solving both $\textit{primal}$ and $\textit{dual}$ SDPs. In particular, we introduce a new family of spectral bundle methods for solving SDPs in the $\textit{primal}$ form. The algorithm developments are parallel to those by Helmberg and Rendl, mirroring the elegant duality between primal and dual SDPs. The new family of spectral bundle methods also achieves linear convergence rates for primal feasibility, dual feasibility, and duality gap when the algorithm captures $\textit{the rank of the dual solutions}$. Therefore, the original spectral bundle method by Helmberg and Rendl is well-suited for SDPs with $\textit{low-rank primal solutions}$, while on the other hand, our new spectral bundle method works well for SDPs with $\textit{low-rank dual solutions}$. These theoretical findings are supported by a range of large-scale numerical experiments. Finally, we demonstrate that our new spectral bundle method achieves state-of-the-art efficiency and scalability for solving polynomial optimization compared to a set of baseline solvers $\textsf{SDPT3}$, $\textsf{MOSEK}$, $\textsf{CDCS}$, and $\textsf{SDPNAL+}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.07651v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Feng-Yi Liao, Lijun Ding, Yang Zheng</dc:creator>
    </item>
    <item>
      <title>The Lov\'asz Theta Function for Recovering Planted Clique Covers and Graph Colorings</title>
      <link>https://arxiv.org/abs/2310.00257</link>
      <description>arXiv:2310.00257v2 Announce Type: replace 
Abstract: The problems of computing graph colorings and clique covers are central challenges in combinatorial optimization. Both of these are known to be NP-hard, and thus computationally intractable in the worst-case instance. A prominent approach for computing approximate solutions to these problems is the celebrated Lov\'asz theta function $\vartheta(G)$, which is specified as the solution of a semidefinite program (SDP), and hence tractable to compute. In this work, we move beyond the worst-case analysis and set out to understand whether the Lov\'asz theta function recovers clique covers for random instances that have a latent clique cover structure, possibly obscured by noise. We answer this question in the affirmative and show that for graphs generated from the planted clique model we introduce in this work, the SDP formulation of $\vartheta(G)$ has a unique solution that reveals the underlying clique-cover structure with high-probability. The main technical step is an intermediate result where we prove a deterministic condition of recovery based on an appropriate notion of sparsity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.00257v2</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <category>cs.IT</category>
      <category>math.CO</category>
      <category>math.IT</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiaxin Hou, Yong Sheng Soh, Antonios Varvitsiotis</dc:creator>
    </item>
    <item>
      <title>Path Planning for Aerial Relays via Probabilistic Roadmaps</title>
      <link>https://arxiv.org/abs/2310.11752</link>
      <description>arXiv:2310.11752v5 Announce Type: replace 
Abstract: Autonomous uncrewed aerial vehicles (UAVs) can be utilized as aerial relays to serve users far from terrestrial infrastructure. Unfortunately, existing algorithms for aerial relay path planning cannot accommodate general flight constraints or channel models. This is required in practice due to connectivity constraints, the presence of obstacles (e.g., buildings), and regulations. This paper proposes a framework that overcomes these limitations by spatially discretizing the flight region. To cope with the resulting exponential growth in complexity, the framework adopts a probabilistic roadmap approach, where a shortest path is found through a graph of randomly generated states. To attain high optimality with affordable complexity, the probability distribution used to generate these states is designed based on heuristic path planners with theoretical guarantees. The algorithms derived in this framework not only overcome the main limitations of existing schemes but also entail smaller computational complexity. Extensive theoretical and numerical results corroborate the merits of the proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.11752v5</guid>
      <category>math.OC</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pham Q. Viet, Daniel Romero</dc:creator>
    </item>
    <item>
      <title>Error bounds, PL condition, and quadratic growth for weakly convex functions, and linear convergences of proximal point methods</title>
      <link>https://arxiv.org/abs/2312.16775</link>
      <description>arXiv:2312.16775v3 Announce Type: replace 
Abstract: Many practical optimization problems lack strong convexity. Fortunately, recent studies have revealed that first-order algorithms also enjoy linear convergences under various weaker regularity conditions. While the relationship among different conditions for convex and smooth functions is well-understood, it is not the case for the nonsmooth setting. In this paper, we go beyond convexity and smoothness, and clarify the connections among common regularity conditions in the class of weakly convex functions, including $\textit{strong convexity}$, $\textit{restricted secant inequality}$, $\textit{subdifferential error bound}$, $\textit{Polyak-{\L}ojasiewicz inequality}$, and $\textit{quadratic growth}$. In addition, using these regularity conditions, we present a simple and modular proof for the linear convergence of the proximal point method (PPM) for convex and weakly convex optimization problems. The linear convergence also holds when the subproblems of PPM are solved inexactly with a proper control of inexactness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.16775v3</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Feng-Yi Liao, Lijun Ding, Yang Zheng</dc:creator>
    </item>
    <item>
      <title>Source reconstruction algorithms for coupled parabolic systems from internal measurements of one scalar state</title>
      <link>https://arxiv.org/abs/2402.07593</link>
      <description>arXiv:2402.07593v4 Announce Type: replace 
Abstract: This paper is devoted to the study of source reconstruction algorithms for coupled systems of heat equations, with either constant or spatially dependent coupling terms, where internal measurements are available from a reduced number of observed states. Two classes of systems are considered. The first comprises parabolic equations with constant zero-order coupling terms (through a matrix potential term or via the diffusion matrix). The second type considers parabolic equations coupled by a matrix potential that depends on spatial variables, which leads to the analysis of a non-self-adjoint operator. In all configurations, the source is assumed to be of separate variables, the temporal part is a known scalar function, and the spatial dependence is an unknown vector field. Several numerical examples using the finite element method in 1D and 2D are presented to show the reconstruction of space-dependent sources.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.07593v4</guid>
      <category>math.OC</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Cristhian Montoya, Ignacio Brevis, David Bolivar</dc:creator>
    </item>
    <item>
      <title>Sequential Selection with Expirations</title>
      <link>https://arxiv.org/abs/2406.15691</link>
      <description>arXiv:2406.15691v2 Announce Type: replace 
Abstract: Motivated by applications where impatience is pervasive and evaluation times are uncertain, we study a selection model where options may expire at an unknown point in time and evaluation times are stochastic. Initially, the decision-maker (DM) has access to $n$ options with known non-negative values: these options have unknown stochastic evaluation and expiration times with known distributional information, which we assume to be independent. When the DM is free, we can select an available option that occupies the DM for an unknown amount of time and collect its value. The objective is to maximize the expected total value obtained from options selected by the DM. Natural formulations of this problem suffer from the curse of dimensionality. In fact, this problem is NP-hard even in the deterministic case. Hence, we focus on efficiently computable approximation algorithms that can provide high expected reward compared to the optimal expected value. Towards this end, we first provide a compact linear programming (LP) relaxation that gives an upper bound on the expected value obtained by the optimal policy. Then we design a polynomial-time algorithm that is nearly a $(1/2)\cdot (1-1/e)$-approximation to the optimal LP value (so also to the optimal expected value). We next shift our focus to the case of independent and identically distributed (i.i.d.) evaluation times. In this case, we show that the greedy policy that always selects the highest-valued option whenever the DM is free obtains a $1/2$-approximation to the optimal expected value. Our approaches extend effortlessly, and we demonstrate their flexibility by providing approximations to natural extensions of our problem. Finally, we evaluate our LP-based policies and the greedy policy empirically on synthetic and real datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15691v2</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yihua Xu, Rohan Ghuge, Sebastian Perez-Salazar</dc:creator>
    </item>
    <item>
      <title>Acceleration via Perturbations on Low-resolution Ordinary Differential Equations</title>
      <link>https://arxiv.org/abs/2504.01497</link>
      <description>arXiv:2504.01497v2 Announce Type: replace 
Abstract: Recently, the high-resolution ordinary differential equation (ODE) framework, which retains higher-order terms, has been proposed to analyze gradient-based optimization algorithms. Through this framework, the term $\nabla^2 f(X_t)\dot{X_t}$, known as the gradient-correction term, was found to be essential for reducing oscillations and accelerating the convergence rate of function values. Despite the importance of this term, simply adding it to the low-resolution ODE may sometimes lead to a slower convergence rate. To fully understand this phenomenon, we propose a generalized perturbed ODE and analyze the role of the gradient and gradient-correction perturbation terms under both continuous-time and discrete-time settings. We demonstrate that while the gradient-correction perturbation is essential for obtaining accelerations, it can hinder the convergence rate of function values in certain cases. However, this adverse effect can be mitigated by involving an additional gradient perturbation term. Moreover, by conducting a comprehensive analysis, we derive proper choices of perturbation parameters. Numerical experiments are also provided to validate our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.01497v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xudong Li, Lei Shi, Mingqi Song</dc:creator>
    </item>
    <item>
      <title>Efficient Quadratic Corrections for Frank-Wolfe Algorithms</title>
      <link>https://arxiv.org/abs/2506.02635</link>
      <description>arXiv:2506.02635v4 Announce Type: replace 
Abstract: We develop a Frank-Wolfe algorithm with corrective steps, generalizing previous algorithms including blended conditional gradients, blended pairwise conditional gradients, and fully-corrective Frank-Wolfe. For this, we prove tight convergence guarantees together with an optimal face identification property. Furthermore, we propose two highly efficient corrective steps for convex quadratic objectives based on linear optimization or linear system solving, akin to Wolfe's minimum-norm point, and show that they converge in finite time under suitable conditions. Beyond optimization problems that are directly quadratic, we revisit two algorithms - split conditional gradient and second-order conditional gradient sliding - which can leverage quadratic corrections to accelerate their quadratic subproblems. We demonstrate improved convergence rates for the first and broader applicability for the second, which may be of independent interest. Finally, we show substantial computational speedups for Frank-Wolfe-based algorithms with quadratic corrections across the considered problem classes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02635v4</guid>
      <category>math.OC</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jannis Halbey, Seta Rakotomandimby, Mathieu Besan\c{c}on, S\'ebastien Designolle, Sebastian Pokutta</dc:creator>
    </item>
    <item>
      <title>Attack Detection in Dynamic Games with Quadratic Measurements</title>
      <link>https://arxiv.org/abs/2510.00241</link>
      <description>arXiv:2510.00241v2 Announce Type: replace 
Abstract: This paper studies attack detection for discrete-time linear systems with stochastic process noise that produce both a vulnerable (i.e., attackable) linear measurement and a secured (i.e., unattackable) quadratic measurement. The motivating application of this model is a dynamic-game setting where the quadratic measurement is interpreted as a system-level utility or reward, and control inputs into the linear system are interpreted as control policies that, once applied, are known to all game participants and which steer the system towards a game-theoretic equilibrium (e.g., Nash equilibrium). To detect attacks on the linear channel, we develop a novel quadratic-utility-aware observer that leverages the secured quadratic output and enforces measurement consistency via a projection step. We establish three properties for this observer: feasibility of the true state, prox-regularity of the quadratic-constraint set, and a monotone error-reduction guarantee in the noise-free case. To detect adversarial manipulation, we compare linear and quadratic observer trajectories using a wild bootstrap maximum mean discrepancy (MMD) test that provides valid inference under temporal dependence. We validate our framework using numerical experiments of a pursuit-evasion game, where the quadratic observer preserves estimation accuracy under linear-sensor attacks, while the statistical test detects distributional divergence between the observers' trajectories.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.00241v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Muyan Jiang, Anil Aswani</dc:creator>
    </item>
    <item>
      <title>Some Remarks on Positive/Negative Feedback</title>
      <link>https://arxiv.org/abs/2512.09474</link>
      <description>arXiv:2512.09474v2 Announce Type: replace 
Abstract: In the context of linear control systems, a commonly-held intuition is that negative and positive feedback cannot both be stability enhancing. The canonical linear prototype is the scalar system $\dot x=u$ which, under negative linear feedback $u=-kx$ ($k &gt;0$) is exponentially stable for all $k &gt;0 $, whereas the lack of exponential instability of the (marginally stable) uncontrolled system is amplified by positive feedback $u=kx$ ($k &gt;0)$. By contrast, for nonlinear systems it is shown, by example, that this intuitive dichotomy may fail to hold.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.09474v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas Berger, Achim Ilchmann, Eugene P. Ryan</dc:creator>
    </item>
    <item>
      <title>Boundary control systems on a one-dimension spatial domain</title>
      <link>https://arxiv.org/abs/2601.01634</link>
      <description>arXiv:2601.01634v2 Announce Type: replace 
Abstract: The aim of this paper is to investigate the well-posedness of a class of boundary control and observation systems on a one dimensional spatial domain. We derive a necessary and sufficient condition characterizing the well-posedness of these systems. Furthermore, we show that the well-posedness and full control and observation implies exact controllability and exact observability. The theoretical results are illustrated using Euler-Bernoulli beam models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.01634v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bouchra Elghazi, Birgit Jacob, Hans Zwart</dc:creator>
    </item>
    <item>
      <title>On the SOS Rank of Simple and Diagonal Biquadratic Forms</title>
      <link>https://arxiv.org/abs/2601.19195</link>
      <description>arXiv:2601.19195v3 Announce Type: replace 
Abstract: We study the sum-of-squares (SOS) rank of simple and diagonal biquadratic forms. For simple biquadratic forms in $3 \times 3$ variables, we show that the maximum SOS rank is exactly $6$, attained by a specific six-term form. We further prove that for any $m \ge 3$, there exists an $m \times m$ simple biquadratic form whose SOS rank is exactly $2m$. Moreover, we show that for all $m, n \ge 3$, the maximum SOS rank over $m \times n$ simple biquadratic forms is at least $m+n$, which implies $\mathrm{BSR}(m,n) \ge m+n$. For diagonal biquadratic forms with nonnegative coefficients, we prove an SOS rank upper bound of $7$, improving the general bound of $8$ for $3 \times 3$ forms. These results provide new lower and upper bounds on the worst-case SOS rank of biquadratic forms and highlight the role of structure in reducing the required number of squares.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.19195v3</guid>
      <category>math.OC</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yi Xu, Chufeng Cui, Liqun Qi</dc:creator>
    </item>
    <item>
      <title>Convergence Analysis of the Upwind Difference Methods for Hamilton-Jacobi-Bellman Equations</title>
      <link>https://arxiv.org/abs/2301.06415</link>
      <description>arXiv:2301.06415v2 Announce Type: replace-cross 
Abstract: This paper investigates the convergence properties of the upwind difference scheme for the Hamilton--Jacobi--Bellman (HJB) equation, a central partial differential equation in optimal control theory. First, assuming the existence of a classical solution, we show that the numerical solution converges to the true solution with a first-order rate with respect to the time step. This result complements the square-root rate established in previous studies for viscosity solutions. Second, by exploiting the correspondence between HJB equations and conservation laws, we prove the convergence of the optimal control input. This analysis is crucial for practical applications where the control input is the primary quantity of interest, yet it has rarely been addressed in previous studies. Finally, we confirm the validity of our theoretical results through numerical experiments on typical control problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.06415v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daisuke Inoue, Yuji Ito, Takahito Kashiwabara, Norikazu Saito, Hiroaki Yoshida</dc:creator>
    </item>
    <item>
      <title>Convex relaxation for the generalized maximum-entropy sampling problem</title>
      <link>https://arxiv.org/abs/2404.01390</link>
      <description>arXiv:2404.01390v4 Announce Type: replace-cross 
Abstract: The generalized maximum-entropy sampling problem (GMESP) is to select an order-$s$ principal submatrix from an order-$n$ covariance matrix, to maximize the product of its $t$ greatest eigenvalues, $0&lt;t\leq s &lt;n$. Introduced more than 25 years ago, GMESP is a natural generalization of two fundamental problems in statistical design theory: (i) maximum-entropy sampling problem (MESP); (ii) binary D-optimality (D-Opt). In the general case, it can be motivated by a selection problem in the context of principal component analysis (PCA).
  We introduce the first convex-optimization based relaxation for GMESP, study its behavior, compare it to an earlier spectral bound, and demonstrate its use in a branch-and-bound scheme. We find that such an approach is practical when $s-t$ is very small.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.01390v4</guid>
      <category>math.ST</category>
      <category>math.OC</category>
      <category>stat.TH</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gabriel Ponte, Marcia Fampa, Jon Lee</dc:creator>
    </item>
    <item>
      <title>A Decomposition Theorem for Dynamic Flows</title>
      <link>https://arxiv.org/abs/2407.04761</link>
      <description>arXiv:2407.04761v2 Announce Type: replace-cross 
Abstract: The famous flow decomposition theorem of Gallai (1985) states that any static edge $s$,$d$-flow in a directed graph can be decomposed into a nonnegative linear combination of incidence vectors of paths and cycles. In this paper, we study the decomposition problem for the setting of dynamic edge $s$,$d$-flows assuming a quite general dynamic flow propagation model. We prove the following decomposition theorem: For any integrable dynamic edge $s$,$d$-flow, there exists a decomposition into a nonnegative linear combination of $s$,$d$-walk inflows and cycles of zero transit time. We show that a variant of the classical algorithmic approach of iteratively subtracting walk inflows from the current dynamic edge flow converges to a dynamic circulation and that every such circulation can be induced by inflows into cycles of zero transit time. The algorithm terminates in finite time, if there is a lower bound on the minimum edge travel times and the flow is finitely supported. We further characterize those dynamic edge flows which can be decomposed purely into nonnegative linear combinations of $s$,$d$-walk inflows.
  The proofs rely on the new concept of autonomous network loadings which allows us to describe how particles of a different walk flow would hypothetically propagate throughout the network under the fixed travel times induced by the given edge flow. We show several technical properties of this type of network loading and, as a byproduct, we also derive some general results on dynamic flows which could be of interest outside the context of this paper as well.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04761v2</guid>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lukas Graf, Tobias Harks, Julian Schwarz</dc:creator>
    </item>
    <item>
      <title>On the Mean-Field limit of diffusive games through the master equation: $L^{\infty}$ estimates and extreme value behavior</title>
      <link>https://arxiv.org/abs/2410.18869</link>
      <description>arXiv:2410.18869v3 Announce Type: replace-cross 
Abstract: We consider an $N$-player game where the states of the players evolve with time as Stochastic Differential Equations (SDEs) with interaction only in the drift terms. Each player controls the drift of the SDE satisfied by her state process, aiming to minimize the expected value of a cost that depends on the paths of the player's state and the empirical measure of the states of all the players until a terminal time. When $N \to \infty$, previous works have established Central Limit Theorems and Large Deviation Principles for the state processes when the game is in Nash Equilibrium (the Nash states), by using the Master Equation to construct approximations of those processes that evolve with time as SDEs with classical Mean-Field interaction. Staying in this framework, we improve an existing $L^{1}$ estimate for the total error of approximating all the Nash states to an $L^{\infty}$ one, and we also establish the $N \to \infty$ asymptotic behavior of the upper order statistics of the Nash states. The latter initiates the development of an Extreme Value Theory for Stochastic Differential Games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.18869v3</guid>
      <category>math.PR</category>
      <category>math.AP</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>q-fin.MF</category>
      <category>stat.TH</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Erhan Bayraktar, Nikolaos Kolliopoulos</dc:creator>
    </item>
    <item>
      <title>Revisiting Multi-Agent Asynchronous Online Optimization with Delays: the Strongly Convex Case</title>
      <link>https://arxiv.org/abs/2503.10013</link>
      <description>arXiv:2503.10013v2 Announce Type: replace-cross 
Abstract: We revisit multi-agent asynchronous online optimization with delays, where only one of the agents becomes active for making the decision at each round, and the corresponding feedback is received by all the agents after unknown delays. Although previous studies have established an $O(\sqrt{dT})$ regret bound for this problem, they assume that the maximum delay $d$ is knowable or the arrival order of feedback satisfies a special property, which may not hold in practice. In this paper, we surprisingly find that when the loss functions are strongly convex, these assumptions can be eliminated, and the existing regret bound can be significantly improved to $O(d\log T)$ meanwhile. Specifically, to exploit the strong convexity of functions, we first propose a delayed variant of the classical follow-the-leader algorithm, namely FTDL, which is very simple but requires the full information of functions as feedback. Moreover, to handle the more general case with only the gradient feedback, we develop an approximate variant of FTDL by combining it with surrogate loss functions. Experimental results show that the approximate FTDL outperforms the existing algorithm in the strongly convex case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.10013v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lingchan Bao, Tong Wei, Yuanyu Wan</dc:creator>
    </item>
    <item>
      <title>Robust Adaptive Discrete-Time Control Barrier Certificate</title>
      <link>https://arxiv.org/abs/2508.08153</link>
      <description>arXiv:2508.08153v2 Announce Type: replace-cross 
Abstract: This work develops a robust adaptive control strategy for discrete-time systems using Control Barrier Functions (CBFs) to ensure safety under parametric model uncertainty and disturbances. A key contribution of this work is establishing a barrier function certificate in discrete time for general online parameter estimation algorithms. This barrier function certificate guarantees positive invariance of the safe set despite disturbances and parametric uncertainty without access to the true system parameters. In addition, real-time implementation and inherent robustness guarantees are provided. The proposed robust adaptive safe control framework demonstrates that the parameter estimation module can be designed separately from the CBF-based safety filter, simplifying the development of safe adaptive controllers for discrete-time systems. The resulting safe control approach guarantees that the system remains within the safe set while adapting to model uncertainties, making it a promising strategy for discrete-time safety-critical systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.08153v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Changrui Liu, Anil Alan, Shengling Shi, Bart De Schutter</dc:creator>
    </item>
    <item>
      <title>Achieving Logarithmic Regret in KL-Regularized Zero-Sum Markov Games</title>
      <link>https://arxiv.org/abs/2510.13060</link>
      <description>arXiv:2510.13060v2 Announce Type: replace-cross 
Abstract: Reverse Kullback-Leibler (KL) divergence-based regularization with respect to a fixed reference policy is widely used in modern reinforcement learning to preserve the desired traits of the reference policy and sometimes to promote exploration (using uniform reference policy, known as entropy regularization). Beyond serving as a mere anchor, the reference policy can also be interpreted as encoding prior knowledge about good actions in the environment. In the context of alignment, recent game-theoretic approaches have leveraged KL regularization with pretrained language models as reference policies, achieving notable empirical success in self-play methods. Despite these advances, the theoretical benefits of KL regularization in game-theoretic settings remain poorly understood. In this work, we develop and analyze algorithms that provably achieve improved sample efficiency under KL regularization. We study both two-player zero-sum matrix games and Markov games: for matrix games, we propose OMG, an algorithm based on best response sampling with optimistic bonuses, and extend this idea to Markov games through the algorithm SOMG, which also uses best response sampling and a novel concept of superoptimistic bonuses. Both algorithms achieve a logarithmic regret in $T$ that scales inversely with the KL regularization strength $\beta$ in addition to the traditional $\widetilde{\mathcal{O}}(\sqrt{T})$ regret without the $\beta^{-1}$ dependence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.13060v2</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Anupam Nayak, Tong Yang, Osman Yagan, Gauri Joshi, Yuejie Chi</dc:creator>
    </item>
    <item>
      <title>Analytical Inverse Kinematic Solution for "Moz1" NonSRS 7-DOF Robot arm with novel arm angle</title>
      <link>https://arxiv.org/abs/2511.22996</link>
      <description>arXiv:2511.22996v2 Announce Type: replace-cross 
Abstract: This paper presents an analytical solution to the inverse kinematic problem(IKP) for the seven degree-of-freedom (7-DOF) Moz1 Robot Arm with offsets on wrist. We provide closed-form solutions with the novel arm angle . it allow fully self-motion and solve the problem of algorithmic singularities within the workspace. It also provides information on how the redundancy is resolved in a new arm angle representation where traditional SEW angle faied to be defined and how singularities are handled. The solution is simple, fast and exact, providing full solution space (i.e. all 16 solutions) per pose.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.22996v2</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ke Chen</dc:creator>
    </item>
    <item>
      <title>Monge solutions and uniqueness in multi-marginal optimal transport with hierarchical jumps</title>
      <link>https://arxiv.org/abs/2512.14072</link>
      <description>arXiv:2512.14072v2 Announce Type: replace-cross 
Abstract: We introduce Hierarchical Jump multi-marginal transport (HJMOT), a generalization of multi-marginal optimal transport where mass can "jump" over intermediate spaces via augmented isolated points. Established on Polish spaces, the framework guarantees the existence of Kantorovich solutions and, under sequential differentiability and a twist condition, the existence and uniqueness of Monge solutions. This core theory extends robustly to diverse settings, including smooth Riemannian manifolds, demonstrating its versatility as a unified framework for optimal transport across complex geometries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.14072v2</guid>
      <category>math.PR</category>
      <category>math.DG</category>
      <category>math.OC</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zijian Xu</dc:creator>
    </item>
    <item>
      <title>Inference-Time Alignment for Diffusion Models via Variationally Stable Doob's Matching</title>
      <link>https://arxiv.org/abs/2601.06514</link>
      <description>arXiv:2601.06514v2 Announce Type: replace-cross 
Abstract: Inference-time alignment for diffusion models aims to adapt a pre-trained reference diffusion model toward a target distribution without retraining the reference score network, thereby preserving the generative capacity of the reference model while enforcing desired properties at the inference time. A central mechanism for achieving such alignment is guidance, which modifies the sampling dynamics through an additional drift term. In this work, we introduce variationally stable Doob's matching, a novel framework for provable guidance estimation grounded in Doob's $h$-transform. Our approach formulates guidance as the gradient of logarithm of an underlying Doob's $h$-function and employs gradient-regularized regression to simultaneously estimate both the $h$-function and its gradient, resulting in a consistent estimator of the guidance. Theoretically, we establish non-asymptotic convergence rates for the estimated guidance. Moreover, we analyze the resulting controllable diffusion processes and prove non-asymptotic convergence guarantees for the generated distributions in the 2-Wasserstein distance. Finally, we show that variationally stable guidance estimators are adaptive to unknown low dimensionality, effectively mitigating the curse of dimensionality under low-dimensional subspace assumptions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06514v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jinyuan Chang, Chenguang Duan, Yuling Jiao, Yi Xu, Jerry Zhijian Yang</dc:creator>
    </item>
    <item>
      <title>Totally $\Delta$-Modular Tree Decompositions of Graphic Matrices for Integer Programming</title>
      <link>https://arxiv.org/abs/2602.01499</link>
      <description>arXiv:2602.01499v2 Announce Type: replace-cross 
Abstract: We introduce the tree-decomposition-based parameter totally $\Delta$-modular treewidth (TDM-treewidth) for matrices with two nonzero entries per row. We show how to solve integer programs whose matrices have bounded TDM-treewidth when variables are bounded. This extends previous graph-based decomposition parameters for matrices with at most two nonzero entries per row to include matrices with entries outside of $\{-1,0,1\}$. We also give an analogue of the Grid Theorem of Robertson and Seymour for matrices of bounded TDM-treewidth in the language of rooted signed graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01499v2</guid>
      <category>math.CO</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Caleb McFarland</dc:creator>
    </item>
    <item>
      <title>Numerical methods for diffusion coefficient recovery</title>
      <link>https://arxiv.org/abs/2602.01656</link>
      <description>arXiv:2602.01656v2 Announce Type: replace-cross 
Abstract: We revisit the inverse problem of reconstructing a spatially varying diffusion coefficient in stationary elliptic equations from boundary Cauchy data. From a theoretical perspective, we introduce a gradient-weighted modification of the coupled complex-boundary method (CCBM) incorporating an \(H^1\)-type term, and formulate the reconstruction as a regularized optimization problem over bounded admissible coefficients. We establish continuity and differentiability of the forward map, Lipschitz continuity of the modified cost functional, existence of minimizers, stability with respect to noisy data, and convergence under vanishing noise. From a numerical perspective, reconstructions are computed using a Sobolev-gradient descent scheme and evaluated through extensive numerical experiments across a range of noise levels, boundary inputs, and coefficient structures. In the reported tests, for sufficiently large but not excessive $H^1$-weights, the modified CCBM is observed to yield more stable reconstructions and to reduce certain high-frequency artifacts. Across the numerical scenarios considered in this study, the method often demonstrates favorable stability and robustness properties relative to several classical boundary-based formulations, although performance remains problem- and parameter-dependent. A projection-based extension further supports stable recovery of piecewise-constant diffusion coefficients in multi-subregion test cases. Our results indicate that, as long as all subdomains share a portion of the boundary, the proposed CCBM-based Tikhonov regularization approach with a pick-a-point strategy enables stable and reliable reconstruction of diffusion parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01656v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sahat Pandapotan Nainggolan, Julius Fergy Tiongson Rabago, Hirofumi Notsu</dc:creator>
    </item>
    <item>
      <title>Habit Formation, Labor Supply, and the Dynamics of Retirement and Annuitization</title>
      <link>https://arxiv.org/abs/2602.02816</link>
      <description>arXiv:2602.02816v2 Announce Type: replace-cross 
Abstract: The decision to annuitize wealth in retirement planning has become increasingly complex due to rising longevity risk and changing retirement patterns, including increased labor force participation at older ages. While an extensive literature studies consumption, labor, and annuitization decisions, these elements are typically examined in isolation. This paper develops a unified stochastic control and optimal stopping framework in which habit formation and endogenous labor supply shape retirement and annuitization decisions under age-dependent mortality. We derive optimal consumption, labor, portfolio, and annuitization policies in a continuous-time lifecycle model. The solution is characterized via dynamic programming and a Hamilton-Jacobi-Bellman variational inequality. Our results reveal a rich sequence of retirement dynamics. When wealth is low relative to habit, labor is supplied defensively to protect consumption standards. As wealth increases, agents enter a work-to-retire phase in which labor is supplied at its maximum level to accelerate access to retirement. Human capital acts as a stabilizing asset, justifying a more aggressive pre-retirement investment portfolio, followed by abrupt de-risking upon annuitization. Subjective mortality beliefs are a key determinant in shaping retirement dynamics. Agents with pessimistic longevity beliefs rationally perceive annuities as unattractive, leading them to avoid or delay annuitization. This framework provides a behavior-based explanation for low annuity demand and offers guidance for retirement planning jointly linking labor supply, portfolio choice, and the timing of annuitization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.02816v2</guid>
      <category>q-fin.MF</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Criscent Birungi, Cody Hyndman</dc:creator>
    </item>
  </channel>
</rss>
