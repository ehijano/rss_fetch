<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-fin.CP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-fin.CP</link>
    <description>q-fin.CP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-fin.CP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 09 Jan 2026 05:01:33 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 09 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Forecasting Equity Correlations with Hybrid Transformer Graph Neural Network</title>
      <link>https://arxiv.org/abs/2601.04602</link>
      <description>arXiv:2601.04602v1 Announce Type: new 
Abstract: This paper studies forward-looking stock-stock correlation forecasting for S\&amp;P 500 constituents and evaluates whether learned correlation forecasts can improve graph-based clustering used in basket trading strategies. We cast 10-day ahead correlation prediction in Fisher-z space and train a Temporal-Heterogeneous Graph Neural Network (THGNN) to predict residual deviations from a rolling historical baseline. The architecture combines a Transformer-based temporal encoder, which captures non-stationary, complex, temporal dependencies, with an edge-aware graph attention network that propagates cross-asset information over the equity network. Inputs span daily returns, technicals, sector structure, previous correlations, and macro signals, enabling regime-aware forecasts and attention-based feature and neighbor importance to provide interpretability. Out-of-sample results from 2019-2024 show that the proposed model meaningfully reduces correlation forecasting error relative to rolling-window estimates. When integrated into a graph-based clustering framework, forward-looking correlations produce adaptable and economically meaningfully baskets, particularly during periods of market stress. These findings suggest that improvements in correlation forecasts translate into meaningful gains during portfolio construction tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.04602v1</guid>
      <category>q-fin.CP</category>
      <category>q-fin.TR</category>
      <pubDate>Fri, 09 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jack Fanshawe, Rumi Masih, Alexander Cameron</dc:creator>
    </item>
    <item>
      <title>Deep Reinforcement Learning for Optimum Order Execution: Mitigating Risk and Maximizing Returns</title>
      <link>https://arxiv.org/abs/2601.04896</link>
      <description>arXiv:2601.04896v1 Announce Type: new 
Abstract: Optimal Order Execution is a well-established problem in finance that pertains to the flawless execution of a trade (buy or sell) for a given volume within a specified time frame. This problem revolves around optimizing returns while minimizing risk, yet recent research predominantly focuses on addressing one aspect of this challenge. In this paper, we introduce an innovative approach to Optimal Order Execution within the US market, leveraging Deep Reinforcement Learning (DRL) to effectively address this optimization problem holistically. Our study assesses the performance of our model in comparison to two widely employed execution strategies: Volume Weighted Average Price (VWAP) and Time Weighted Average Price (TWAP). Our experimental findings clearly demonstrate that our DRL-based approach outperforms both VWAP and TWAP in terms of return on investment and risk management. The model's ability to adapt dynamically to market conditions, even during periods of market stress, underscores its promise as a robust solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.04896v1</guid>
      <category>q-fin.CP</category>
      <pubDate>Fri, 09 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Khabbab Zakaria, Jayapaulraj Jerinsh, Andreas Maier, Patrick Krauss, Stefano Pasquali, Dhagash Mehta</dc:creator>
    </item>
    <item>
      <title>Forecasting the U.S. Treasury Yield Curve: A Distributionally Robust Machine Learning Approach</title>
      <link>https://arxiv.org/abs/2601.04608</link>
      <description>arXiv:2601.04608v1 Announce Type: cross 
Abstract: We study U.S. Treasury yield curve forecasting under distributional uncertainty and recast forecasting as an operations research and managerial decision problem. Rather than minimizing average forecast error, the forecaster selects a decision rule that minimizes worst case expected loss over an ambiguity set of forecast error distributions. To this end, we propose a distributionally robust ensemble forecasting framework that integrates parametric factor models with high dimensional nonparametric machine learning models through adaptive forecast combinations. The framework consists of three machine learning components. First, a rolling window Factor Augmented Dynamic Nelson Siegel model captures level, slope, and curvature dynamics using principal components extracted from economic indicators. Second, Random Forest models capture nonlinear interactions among macro financial drivers and lagged Treasury yields. Third, distributionally robust forecast combination schemes aggregate heterogeneous forecasts under moment uncertainty, penalizing downside tail risk via expected shortfall and stabilizing second moment estimation through ridge regularized covariance matrices. The severity of the worst case criterion is adjustable, allowing the forecaster to regulate the trade off between robustness and statistical efficiency. Using monthly data, we evaluate out of sample forecasts across maturities and horizons from one to twelve months ahead. Adaptive combinations deliver superior performance at short horizons, while Random Forest forecasts dominate at longer horizons. Extensions to global sovereign bond yields confirm the stability and generalizability of the proposed framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.04608v1</guid>
      <category>q-fin.MF</category>
      <category>q-fin.CP</category>
      <category>stat.ML</category>
      <pubDate>Fri, 09 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Jinjun Liu, Ming-Yen Cheng</dc:creator>
    </item>
    <item>
      <title>Realised Volatility Forecasting: Machine Learning via Financial Word Embedding</title>
      <link>https://arxiv.org/abs/2108.00480</link>
      <description>arXiv:2108.00480v5 Announce Type: replace 
Abstract: We examine whether news can improve realised volatility forecasting using a modern yet operationally simple NLP framework. News text is transformed into embedding-based representations, and forecasts are evaluated both as a standalone, news-only model and as a complement to standard realised volatility benchmarks. In out-of-sample tests on a cross-section of stocks, news contains useful predictive information, with stronger effects for stock-related content and during high volatility days. Combining the news-based signal with a leading benchmark yields consistent improvements in statistical performance and economically meaningful gains, while explainability analysis highlights the news themes most relevant for volatility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2108.00480v5</guid>
      <category>q-fin.CP</category>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <pubDate>Fri, 09 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.2139/ssrn.3895272</arxiv:DOI>
      <dc:creator>Eghbal Rahimikia, Stefan Zohren, Ser-Huang Poon</dc:creator>
    </item>
    <item>
      <title>Adaptive Multilevel Splitting: First Application to Rare-Event Derivative Pricing</title>
      <link>https://arxiv.org/abs/2510.23461</link>
      <description>arXiv:2510.23461v3 Announce Type: replace 
Abstract: This work investigates the computational burden of pricing binary options in rare event regimes and introduces an adaptation of the adaptive multilevel splitting (AMS) method for financial derivatives. Standard Monte Carlo becomes inefficient for deep out-of-the-money binaries due to discontinuous payoffs and extremely small exercise probabilities, requiring prohibitively large sample sizes for accurate estimation. The proposed AMS framework reformulates the rare-event problem as a sequence of conditional events and is applied under both Black-Scholes and Heston dynamics. Numerical experiments cover European, Asian, and up-and-in barrier digital options, together with a multidimensional digital payoff designed as a stress test. Across all contracts, AMS achieves substantial gains, reaching up to 200-fold improvements over standard Monte Carlo, while preserving unbiasedness and showing robust performance with respect to the choice of importance function. To the best of our knowledge, this is the first application of AMS to derivative pricing. An open-source Rcpp implementation is provided, supporting multiple discretisation schemes and alternative importance functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.23461v3</guid>
      <category>q-fin.CP</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 09 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Riccardo Gozzo</dc:creator>
    </item>
    <item>
      <title>Improving Bayesian Optimization for Portfolio Management with an Adaptive Scheduling</title>
      <link>https://arxiv.org/abs/2504.13529</link>
      <description>arXiv:2504.13529v3 Announce Type: replace-cross 
Abstract: Existing black-box portfolio management systems are prevalent in the financial industry due to commercial and safety constraints, though their performance can fluctuate dramatically with changing market regimes. Evaluating these non-transparent systems is computationally expensive, as fixed budgets limit the number of possible observations. Therefore, achieving stable and sample-efficient optimization for these systems has become a critical challenge. This work presents a novel Bayesian optimization framework (TPE-AS) that improves search stability and efficiency for black-box portfolio models under these limited observation budgets. Standard Bayesian optimization, which solely maximizes expected return, can yield erratic search trajectories and misalign the surrogate model with the true objective, thereby wasting the limited evaluation budget. To mitigate these issues, we propose a weighted Lagrangian estimator that leverages an adaptive schedule and importance sampling. This estimator dynamically balances exploration and exploitation by incorporating both the maximization of model performance and the minimization of the variance of model observations. It guides the search from broad, performance-seeking exploration towards stable and desirable regions as the optimization progresses. Extensive experiments and ablation studies, which establish our proposed method as the primary approach and other configurations as baselines, demonstrate its effectiveness across four backtest settings with three distinct black-box portfolio management models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.13529v3</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>q-fin.CP</category>
      <category>q-fin.PM</category>
      <pubDate>Fri, 09 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3787279.3787285</arxiv:DOI>
      <arxiv:journal_reference>In 2025 9th International Conference on Advances in Artificial Intelligence (ICAAI 2025), November 14-16, 2025, Manchester, United Kingdom. ACM, New York, NY, USA, 5 pages</arxiv:journal_reference>
      <dc:creator>Zinuo You, John Cartlidge, Karen Elliott, Menghan Ge, Daniel Gold</dc:creator>
    </item>
    <item>
      <title>American options valuation in time-dependent jump-diffusion models via integral equations and characteristic functions</title>
      <link>https://arxiv.org/abs/2506.18210</link>
      <description>arXiv:2506.18210v3 Announce Type: replace-cross 
Abstract: Despite significant advancements in machine learning for derivative pricing, the efficient and accurate valuation of American options remains a persistent challenge due to complex exercise boundaries, near-expiry behavior, and intricate contractual features. This paper extends a semi-analytical approach for pricing American options in time-inhomogeneous models, including pure diffusions, jump-diffusions, and Levy processes. Building on prior work, we derive and solve Volterra integral equations of the second kind to determine the exercise boundary explicitly, offering a computationally superior alternative to traditional finite-difference and Monte Carlo methods. We address key open problems: (1) extending the decomposition method, i.e. splitting the American option price into its European counterpart and an early exercise premium, to general jump-diffusion and Levy models; (2) handling cases where closed-form transition densities are unavailable by leveraging characteristic functions via, e.g., the COS method; and (3) generalizing the framework to multidimensional diffusions. Numerical examples demonstrate the method's efficiency and robustness. Our results underscore the advantages of the integral equation approach for large-scale industrial applications, while resolving some limitations of existing techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.18210v3</guid>
      <category>q-fin.PR</category>
      <category>q-fin.CP</category>
      <category>q-fin.MF</category>
      <pubDate>Fri, 09 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrey Itkin</dc:creator>
    </item>
    <item>
      <title>Community-level Contagion among Diverse Financial Assets</title>
      <link>https://arxiv.org/abs/2509.15232</link>
      <description>arXiv:2509.15232v2 Announce Type: replace-cross 
Abstract: As global financial markets become increasingly interconnected, financial contagion has developed into a major influencer of asset price dynamics. Motivated by this context, our study explores financial contagion both within and between asset communities. We contribute to the literature by examining the contagion phenomenon at the community level rather than among individual assets. Our experiments rely on high-frequency data comprising cryptocurrencies, stocks and US ETFs over the 4-year period from April 2019 to May 2023. Using the Louvain community detection algorithm, Vector Autoregression contagion detection model and Tracy-Widom random matrix theory for noise removal from financial assets, we present three main findings. Firstly, while the magnitude of contagion remains relatively stable over time, contagion density (the percentage of asset pairs exhibiting contagion within a financial system) increases. This suggests that market uncertainty is better characterized by the transmission of shocks more broadly than by the strength of any single spillover. Secondly, there is no significant difference between intra- and inter-community contagion, indicating that contagion is a system-wide phenomenon rather than being confined to specific asset groups. Lastly, certain communities themselves, especially those dominated by Information Technology assets, tend to act as major contagion transmitters in the financial network over the examined period, spreading shocks with high densities to many other communities. Our findings suggest that traditional risk management strategies such as portfolio diversification through investing in low-correlated assets or different types of investment vehicle might be insufficient due to widespread contagion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.15232v2</guid>
      <category>physics.soc-ph</category>
      <category>q-fin.CP</category>
      <pubDate>Fri, 09 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.chaos.2025.117858</arxiv:DOI>
      <arxiv:journal_reference>Chaos, Solitons &amp; Fractals 205, 117858 (2026)</arxiv:journal_reference>
      <dc:creator>An Pham Ngoc Nguyen, Marija Bezbradica, Martin Crane</dc:creator>
    </item>
    <item>
      <title>All That Glisters Is Not Gold: A Benchmark for Reference-Free Counterfactual Financial Misinformation Detection</title>
      <link>https://arxiv.org/abs/2601.04160</link>
      <description>arXiv:2601.04160v2 Announce Type: replace-cross 
Abstract: We introduce RFC Bench, a benchmark for evaluating large language models on financial misinformation under realistic news. RFC Bench operates at the paragraph level and captures the contextual complexity of financial news where meaning emerges from dispersed cues. The benchmark defines two complementary tasks: reference free misinformation detection and comparison based diagnosis using paired original perturbed inputs. Experiments reveal a consistent pattern: performance is substantially stronger when comparative context is available, while reference free settings expose significant weaknesses, including unstable predictions and elevated invalid outputs. These results indicate that current models struggle to maintain coherent belief states without external grounding. By highlighting this gap, RFC Bench provides a structured testbed for studying reference free reasoning and advancing more reliable financial misinformation detection in real world settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.04160v2</guid>
      <category>cs.CL</category>
      <category>cs.CE</category>
      <category>q-fin.CP</category>
      <pubDate>Fri, 09 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuechen Jiang, Zhiwei Liu, Yupeng Cao, Yueru He, Chen Xu, Ziyang Xu, Zhiyang Deng, Prayag Tiwari, Xi Chen, Alejandro Lopez-Lira, Jimin Huang, Junichi Tsujii, Sophia Ananiadou</dc:creator>
    </item>
  </channel>
</rss>
