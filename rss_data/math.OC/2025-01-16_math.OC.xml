<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 17 Jan 2025 02:31:22 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Revisiting Continuous p-Hub Location Problems with the L1 Metric</title>
      <link>https://arxiv.org/abs/2501.08439</link>
      <description>arXiv:2501.08439v1 Announce Type: new 
Abstract: Motivated by emerging urban applications in commercial, public sector, and humanitarian logistics, we revisit continuous $p$-hub location problems in which several facilities must be located in a continuous space such that the expected minimum Manhattan travel distance from a random service provider to a random customer through exactly one hub facility is minimized. In this paper, we begin by deriving closed-form results for a one-dimensional case and two-dimensional cases with up to two hubs. Subsequently, a simulation-based approximation method is proposed for more complex two-dimensional scenarios with more than two hubs. Moreover, an extended problem with multiple service providers is analyzed to reflect real-life service settings. Finally, we apply our model and approximation method using publicly available data as a case study to optimize the deployment of public-access automated external defibrillators in Virginia Beach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08439v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yifan Wu, Joseph Geunes, Xiaofeng Nie</dc:creator>
    </item>
    <item>
      <title>Energy Storage Arbitrage Under Price Uncertainty: Market Risks and Opportunities</title>
      <link>https://arxiv.org/abs/2501.08472</link>
      <description>arXiv:2501.08472v1 Announce Type: new 
Abstract: We investigate the profitability and risk of energy storage arbitrage in electricity markets under price uncertainty, exploring both robust and chance-constrained optimization approaches. We analyze various uncertainty representations, including polyhedral, ellipsoidal uncertainty sets and probabilistic approximations, to model price fluctuations and construct efficient frontiers that highlight the tradeoff between risk and profit. Using historical electricity price data, we quantify the impact of uncertainty on arbitrage strategies and compare their performance under distinct market conditions. The results reveal that arbitrage strategies under uncertainties can effectively secure expected profits, and robust strategies perform better in risk management across varying levels of conservativeness, especially under highly volatile market conditions. This work provides insights into storage arbitrage strategy selection for market participants with differing risk preferences, emphasizing the adaptability of efficient frontiers to the electricity market.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08472v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yiqian Wu, Bolun Xu, James Anderson</dc:creator>
    </item>
    <item>
      <title>Geometry of Sparsity-Inducing Norms</title>
      <link>https://arxiv.org/abs/2501.08651</link>
      <description>arXiv:2501.08651v1 Announce Type: new 
Abstract: Sparse optimization seeks an optimal solution with few nonzero entries.  To  achieve this, it is common to add to the criterion a penalty term proportional  to the $\ell_1$-norm, which is recognized as the archetype of sparsity-inducing  norms.  In this approach, the number of nonzero entries is not controlled a  priori.  By contrast, in this paper, we focus on finding an optimal solution  with at most~$k$ nonzero coordinates (or for short, $k$-sparse vectors), where  $k$ is a given sparsity level (or ``sparsity budget'').  For this purpose, we  study the class of generalized $k$-support norms that arise from a given  source norm.  When added as a penalty term, we provide conditions under which  such generalized $k$-support norms promote $k$-sparse solutions.  The result  follows from an analysis of the exposed faces of closed convex sets generated  by $k$-sparse vectors, and of how primal support identification can be deduced  from dual information.  Finally, we study some of the geometric properties of  the unit balls for the $k$-support norms and their dual norms when the source  norm belongs to the family of $\ell_p$-norms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08651v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jean-Philippe Chancelier (CERMICS), Michel de Lara (GALaC - LRI), Antoine Deza (GALaC - LRI), Lionel Pournin (UP13)</dc:creator>
    </item>
    <item>
      <title>$H^\infty$-control for a class of boundary controlled hyperbolic PDEs</title>
      <link>https://arxiv.org/abs/2501.08658</link>
      <description>arXiv:2501.08658v1 Announce Type: new 
Abstract: A solution to the suboptimal $H^\infty$-control problem is given for a class of hyperbolic partial differential equations (PDEs). The first result of this manuscript shows that the considered class of PDEs admits an equivalent representation as an infinite-dimensional discrete-time system. Taking advantage of this, this manuscript shows that it is equivalent to solve the suboptimal $H^\infty$-control problem for a finite-dimensional discrete-time system whose matrices are derived from the PDEs. After computing the solution to this much simpler problem, the solution to the original problem can be deduced easily. In particular, the optimal compensator solution to the suboptimal $H^\infty$-control problem is governed by a set of hyperbolic PDEs, actuated and observed at the boundary. We illustrate our results with a boundary controlled and boundary observed vibrating string.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08658v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anthony Hastir, Birgit Jacob, Hans Zwart</dc:creator>
    </item>
    <item>
      <title>Optimal control of counter-terrorism tactics</title>
      <link>https://arxiv.org/abs/2501.08706</link>
      <description>arXiv:2501.08706v1 Announce Type: new 
Abstract: This paper presents an optimal control problem to analyze the efficacy of counter-terrorism tactics. We present an algorithm that efficiently combines the Minimum Principle of Pontryagin, the shooting method and the cyclic descent of coordinates. We also present a result that allows us to know a priori the steady state solutions. Using this technique we are able to choose parameters that reach a specific solution, of which there are two. Numerical examples are presented to illustrate the possibilities of the method. Finally, we study the sufficient conditions for optimality and suggest an improvement on the functional which also guarantees local optimality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08706v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.amc.2018.11.022</arxiv:DOI>
      <arxiv:journal_reference>Applied Mathematics and Computation, Volume 347, 15 April 2019, Pages 477-491</arxiv:journal_reference>
      <dc:creator>L. Bayon, P. Fortuny Ayuso, P. J. Garcia-Nieto, J. M. Grau, M. M. Ruiz</dc:creator>
    </item>
    <item>
      <title>Kernel EDMD for data-driven nonlinear Koopman MPC with stability guarantees</title>
      <link>https://arxiv.org/abs/2501.08709</link>
      <description>arXiv:2501.08709v1 Announce Type: new 
Abstract: Extended dynamic mode decomposition (EDMD) is a popular data-driven method to predict the action of the Koopman operator, i.e., the evolution of an observable function along the flow of a dynamical system. In this paper, we leverage a recently-introduced kernel EDMD method for control systems for data-driven model predictive control. Building upon pointwise error bounds proportional in the state, we rigorously show practical asymptotic stability of the origin w.r.t. the MPC closed loop without stabilizing terminal conditions. The key novelty is that we avoid restrictive invariance conditions. Last, we verify our findings by numerical simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08709v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lea Bold, Manuel Schaller, Irene Schimperna, Karl Worthmann</dc:creator>
    </item>
    <item>
      <title>Extrapolated Hard Thresholding Algorithms with Finite Length for Composite $\ell_0$ Penalized Problems</title>
      <link>https://arxiv.org/abs/2501.08719</link>
      <description>arXiv:2501.08719v1 Announce Type: new 
Abstract: For a class of sparse optimization problems with the penalty function of $\|(\cdot)_+\|_0$, we first characterize its local minimizers and then propose an extrapolated hard thresholding algorithm to solve such problems. We show that the iterates generated by the proposed algorithm with $\epsilon&gt;0$ (where $\epsilon$ is the dry friction coefficient) have finite length, without relying on the Kurdyka-{\L}ojasiewicz inequality. Furthermore, we demonstrate that the algorithm converges to an $\epsilon$-local minimizer of this problem. For the special case that $\epsilon=0$, we establish that any accumulation point of the iterates is a local minimizer of the problem. Additionally, we analyze the convergence when an error term is present in the algorithm, showing that the algorithm still converges in the same manner as before, provided that the errors asymptotically approach zero. Finally, we conduct numerical experiments to verify the theoretical results of the proposed algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08719v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fan Wu, Jiazhen Wei, Wei Bian</dc:creator>
    </item>
    <item>
      <title>Major-Minor Mean Field Game of Stopping: An Entropy Regularization Approach</title>
      <link>https://arxiv.org/abs/2501.08770</link>
      <description>arXiv:2501.08770v1 Announce Type: new 
Abstract: This paper studies a discrete-time major-minor mean field game of stopping where the major player can choose either an optimal control or stopping time. We look for the relaxed equilibrium as a randomized stopping policy, which is formulated as a fixed point of a set-valued mapping, whose existence is challenging by direct arguments. To overcome the difficulties caused by the presence of a major player, we propose to study an auxiliary problem by considering entropy regularization in the major player's problem while formulating the minor players' optimal stopping problems as linear programming over occupation measures. We first show the existence of regularized equilibria as fixed points of some simplified set-valued operator using the Kakutani-Fan-Glicksberg fixed-point theorem. Next, we prove that the regularized equilibrium converges as the regularization parameter $\lambda$ tends to 0, and the limit corresponds to a fixed point of the original operator, thereby confirming the existence of a relaxed equilibrium in the original mean field game problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08770v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiang Yu, Jiacheng Zhang, Keyu Zhang, Zhou Zhou</dc:creator>
    </item>
    <item>
      <title>Nesterov Acceleration for Ensemble Kalman Inversion and Variants</title>
      <link>https://arxiv.org/abs/2501.08779</link>
      <description>arXiv:2501.08779v1 Announce Type: new 
Abstract: Ensemble Kalman inversion (EKI) is a derivative-free, particle-based optimization method for solving inverse problems. It can be shown that EKI approximates a gradient flow, which allows the application of methods for accelerating gradient descent. Here, we show that Nesterov acceleration is effective in speeding up the reduction of the EKI cost function on a variety of inverse problems. We also implement Nesterov acceleration for two EKI variants, unscented Kalman inversion and ensemble transform Kalman inversion. Our specific implementation takes the form of a particle-level nudge that is demonstrably simple to couple in a black-box fashion with any existing EKI variant algorithms, comes with no additional computational expense, and with no additional tuning hyperparameters. This work shows a pathway for future research to translate advances in gradient-based optimization into advances in gradient-free Kalman optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08779v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.CO</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sydney Vernon, Eviatar Bach, Oliver R. A. Dunbar</dc:creator>
    </item>
    <item>
      <title>Improved Compression Bounds for Scenario Decision Making</title>
      <link>https://arxiv.org/abs/2501.08884</link>
      <description>arXiv:2501.08884v1 Announce Type: new 
Abstract: Scenario decision making offers a flexible way of making decision in an uncertain environment while obtaining probabilistic guarantees on the risk of failure of the decision. The idea of this approach is to draw samples of the uncertainty and make a decision based on the samples, called "scenarios". The probabilistic guarantees take the form of a bound on the probability of sampling a set of scenarios that will lead to a decision whose risk of failure is above a given maximum tolerance. This bound can be expressed as a function of the number of sampled scenarios, the maximum tolerated risk, and some intrinsic property of the problem called the "compression size". Several such bounds have been proposed in the literature under various assumptions on the problem. We propose new bounds that improve upon the existing ones without requiring stronger assumptions on the problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08884v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guillaume O. Berger, Rapha\"el M. Jungers</dc:creator>
    </item>
    <item>
      <title>A consensus-based optimization method for nonsmooth nonconvex programs with approximated gradient descent scheme</title>
      <link>https://arxiv.org/abs/2501.08906</link>
      <description>arXiv:2501.08906v1 Announce Type: new 
Abstract: In this paper, we are interested in finding the global minimizer of a nonsmooth nonconvex unconstrained optimization problem. By combining the discrete consensus-based optimization (CBO) algorithm and the gradient descent method, we develop a novel CBO algorithm with an extra gradient descent scheme evaluated by the forward-difference technique on the function values, where only the objective function values are used in the proposed algorithm. First, we prove that the proposed algorithm can exhibit global consensus in an exponential rate in two senses and possess a unique global consensus point. Second, we evaluate the error estimate between the objective function value on the global consensus point and its global minimum. In particular, as the parameter $\beta$ tends to $\infty$, the error converges to zero and the convergence rate is $\mathcal{O}\left(\frac{\log\beta}{\beta}\right)$. Third, under some suitable assumptions on the objective function, we provide the number of iterations required for the mean square error in expectation to reach the desired accuracy. It is worth underlining that the theoretical analysis in this paper does not use the mean-field limit. Finally, we illustrate the improved efficiency and promising performance of our novel CBO method through some experiments on several nonconvex benchmark problems and the application to train deep neural networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08906v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiazhen Wei, Fan Wu, Wei Bian</dc:creator>
    </item>
    <item>
      <title>Market Power and Withholding Behavior of Energy Storage Units</title>
      <link>https://arxiv.org/abs/2405.01442</link>
      <description>arXiv:2405.01442v1 Announce Type: cross 
Abstract: Electricity markets are experiencing a rapid increase in energy storage unit participation. Unlike conventional generation resources, quantifying the competitive operation and identifying if a storage unit is exercising market power is challenging, particularly in the context of multi-interval bidding strategies. We present a framework to differentiate strategic capacity withholding behaviors attributed to market power from inherent competitive bidding in storage unit strategies. Our framework evaluates the profitability of strategic storage unit participation, analyzing bidding behaviors as both price takers and price makers using a self-scheduling model, and investigates how they leverage market inefficiencies. Specifically, we propose a price sensitivity model derived from the linear supply function equilibrium model to examine the price-anticipating bidding strategy, effectively capturing the influence of market power. We introduce a sufficient ex-post analysis for market operators to identify potential exploitative behaviors by monitoring instances of withholding within the bidding profiles, ensuring market resilience and competitiveness. We discuss and verify applicability of the proposed framework to realistic settings. Our analysis substantiates commonly observed economic bidding behaviors of storage units. Furthermore, it demonstrates that significant price volatility offers considerable profit opportunities not only for participants possessing market power but also for typical strategic profit seekers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.01442v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yiqian Wu, Bolun Xu, James Anderson</dc:creator>
    </item>
    <item>
      <title>OptiChat: Bridging Optimization Models and Practitioners with Large Language Models</title>
      <link>https://arxiv.org/abs/2501.08406</link>
      <description>arXiv:2501.08406v1 Announce Type: cross 
Abstract: Optimization models have been applied to solve a wide variety of decision-making problems. These models are usually developed by optimization experts but are used by practitioners without optimization expertise in various application domains. As a result, practitioners often struggle to interact with and draw useful conclusions from optimization models independently. To fill this gap, we introduce OptiChat, a natural language dialogue system designed to help practitioners interpret model formulation, diagnose infeasibility, analyze sensitivity, retrieve information, evaluate modifications, and provide counterfactual explanations. By augmenting large language models (LLMs) with functional calls and code generation tailored for optimization models, we enable seamless interaction and minimize the risk of hallucinations in OptiChat. We develop a new dataset to evaluate OptiChat's performance in explaining optimization models. Experiments demonstrate that OptiChat effectively bridges the gap between optimization models and practitioners, delivering autonomous, accurate, and instant responses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08406v1</guid>
      <category>cs.HC</category>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hao Chen, Gonzalo Esteban Constante-Flores, Krishna Sri Ipsit Mantri, Sai Madhukiran Kompalli, Akshdeep Singh Ahluwalia, Can Li</dc:creator>
    </item>
    <item>
      <title>Differentiable Singular Value Decomposition</title>
      <link>https://arxiv.org/abs/2501.08522</link>
      <description>arXiv:2501.08522v1 Announce Type: cross 
Abstract: Singular value decomposition is widely used in modal analysis, such as proper orthogonal decomposition and resolvent analysis, to extract key features from complex problems. SVD derivatives need to be computed efficiently to enable the large scale design optimization. However, for a general complex matrix, no method can accurately compute this derivative to machine precision and remain scalable with respect to the number of design variables without requiring the all of the singular variables. We propose two algorithms to efficiently compute this derivative based on the adjoint method and reverse automatic differentiation and RAD-based singular value derivative formula. Differentiation results for each method proposed were compared with FD results for one square and one tall rectangular matrix example and matched with the FD results to about 5 to 7 digits. Finally, we demonstrate the scalability of the proposed method by calculating the derivatives of singular values with respect to the snapshot matrix derived from the POD of a large dataset for a laminar-turbulent transitional flow over a flat plate, sourced from the John Hopkins turbulence database.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08522v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.CV</category>
      <category>math.FA</category>
      <category>math.OC</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Rohit Kanchi, Sicheng He</dc:creator>
    </item>
    <item>
      <title>Some remarks on practical stabilization via CLF-based control under measurement noise</title>
      <link>https://arxiv.org/abs/2501.08688</link>
      <description>arXiv:2501.08688v1 Announce Type: cross 
Abstract: Practical stabilization of input-affine systems in the presence of measurement errors and input constraints is considered in this brief note. Assuming that a Lyapunov function and a stabilizing control exist for an input-affine system, the required measurement accuracy at each point of the state space is computed. This is done via the Lyapunov function-based decay condition, which describes along with the input constraints a set of admissible controls. Afterwards, the measurement time points are computed based on the system dynamics. It is shown that between these self-triggered measurement time points, the system evolves and converges into the so-called target ball, i.e. a vicinity of the origin, where it remains. Furthermore, it is shown that the approach ensures the existence of a control law, which is admissible for all possible states and it introduces a connection between measurement time points, measurement accuracy, target ball, and decay. The results of the approach are shown in three examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08688v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Patrick Schmidt, Pavel Osinenko, Stefan Streif</dc:creator>
    </item>
    <item>
      <title>Markov decision processes: on the convergence of the Monte-Carlo first visit algorithm</title>
      <link>https://arxiv.org/abs/2501.08800</link>
      <description>arXiv:2501.08800v1 Announce Type: cross 
Abstract: We consider the Monte-Carlo first visit algorithm, of which the goal is to find the optimal control in a Markov decision process with finite state space and finite number of possible actions. We show its convergence when the discount factor is smaller than $1/2$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08800v1</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sylvain Delattre, Nicolas Fournier</dc:creator>
    </item>
    <item>
      <title>PAC Learnability of Scenario Decision-Making Algorithms: Necessary and Sufficient Conditions</title>
      <link>https://arxiv.org/abs/2501.08887</link>
      <description>arXiv:2501.08887v1 Announce Type: cross 
Abstract: We study the PAC property of scenario decision-making algorithms, that is, the ability to make a decision that has an arbitrarily low risk of violating an unknown safety constraint, provided sufficiently many realizations (called scenarios) of the safety constraint are sampled. Sufficient conditions for scenario decision-making algorithms to be PAC are available in the literature, such as finiteness of the VC dimension of its associated classifier and existence of a compression scheme. We study the question of whether these sufficient conditions are also necessary. We show with counterexamples that this is not the case in general. This contrasts with binary classification learning, for which the analogous conditions are sufficient and necessary. Popular scenario decision-making algorithms, such as scenario optimization, enjoy additional properties, such as stability and consistency. We show that even under these additional assumptions the above conclusions hold. Finally, we derive a necessary condition for scenario decision-making algorithms to be PAC, inspired by the VC dimension and the so-called no-free-lunch theorem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08887v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guillaume O. Berger, Rapha\"el M. Jungers</dc:creator>
    </item>
    <item>
      <title>Separable approximations of optimal value functions under a decaying sensitivity assumption</title>
      <link>https://arxiv.org/abs/2304.06379</link>
      <description>arXiv:2304.06379v3 Announce Type: replace 
Abstract: An efficient approach for the construction of separable approximations of optimal value functions from interconnected optimal control problems is presented. The approach is based on assuming decaying sensitivities between subsystems, enabling a curse-of-dimensionality free approximation, for instance by deep neural networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.06379v3</guid>
      <category>math.OC</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/CDC49753.2023.10383497</arxiv:DOI>
      <dc:creator>Mario Sperl, Luca Saluzzi, Lars Gr\"une, Dante Kalise</dc:creator>
    </item>
    <item>
      <title>Observer-based Periodic Event-triggered and Self-triggered Boundary Control of a Class of Parabolic PDEs</title>
      <link>https://arxiv.org/abs/2312.01313</link>
      <description>arXiv:2312.01313v2 Announce Type: replace 
Abstract: This paper introduces the first observer-based periodic event-triggered control (PETC) and self-triggered control (STC) for boundary control of a class of parabolic PDEs using PDE backstepping control. We introduce techniques to convert a certain class of continuous-time event-triggered control into PETC and STC, eliminating the need for continuous monitoring of the event-triggering function. For the PETC, the event-triggering function requires only periodic evaluations to detect events, while the STC proactively computes the time of the next event right at the current event time using the system model and the continuously available measurements. For both strategies, the control input is updated exclusively at events and is maintained using a zero-order hold between events. We demonstrate that the closed-loop system is Zeno-free. We offer criteria for selecting an appropriate sampling period for the PETC and for determining the time until the next event under the STC. We prove the system's global exponential convergence to zero in the spatial $L^2$ norm for both anti-collocated and collocated sensing and actuation under the PETC. For the STC, local exponential convergence to zero in the spatial $L^2$ norm for collocated sensing and actuation is proven. Simulations are provided to illustrate the theoretical claims.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.01313v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bhathiya Rathnayake, Mamadou Diagne</dc:creator>
    </item>
    <item>
      <title>A Unifying System Theory Framework for Distributed Optimization and Games</title>
      <link>https://arxiv.org/abs/2401.12623</link>
      <description>arXiv:2401.12623v3 Announce Type: replace 
Abstract: This paper introduces a systematic methodological framework to design and analyze distributed algorithms for optimization and games over networks. Starting from a centralized method, we identify an aggregation function involving all the decision variables (e.g., a global cost gradient or constraint) and introduce a distributed consensus-oriented scheme to asymptotically approximate the unavailable information at each agent. Then, we delineate the proper methodology for intertwining the identified building blocks, i.e., the optimization-oriented method and the consensus-oriented one. The key intuition is to interpret the obtained interconnection as a singularly perturbed system. We rely on this interpretation to provide sufficient conditions for the building blocks to be successfully connected into a distributed scheme exhibiting the convergence guarantees of the centralized algorithm. Finally, we show the potential of our approach by developing a new distributed scheme for constraint-coupled problems with a linear convergence rate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.12623v3</guid>
      <category>math.OC</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Guido Carnevale, Nicola Mimmo, Giuseppe Notarstefano</dc:creator>
    </item>
    <item>
      <title>Analytic Formulas for Alternating Projection Sequences for the Positive Semidefinite Cone and an Application to Convergence Analysis</title>
      <link>https://arxiv.org/abs/2401.15276</link>
      <description>arXiv:2401.15276v2 Announce Type: replace 
Abstract: We derive analytic formulas for the alternating projection method applied to the cone $\mathbb{S}^n_+$ of positive semidefinite matrices and an affine subspace. More precisely, we find recursive relations on parameters representing a sequence constructed by the alternating projection method. By applying these formulas, we analyze the alternating projection method in detail and show that the upper bound given by the singularity degree is actually tight when the alternating projection method is applied to $\mathbb{S}^3_+$ and a $3$-plane whose intersection is a singleton with singularity degree $2$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.15276v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.jmaa.2024.129070</arxiv:DOI>
      <arxiv:journal_reference>Journal of Mathematical Analysis and Applications 544 (2025), no. 1, Paper No. 129070</arxiv:journal_reference>
      <dc:creator>Hiroyuki Ochiai, Yoshiyuki Sekiguchi, Hayato Waki</dc:creator>
    </item>
    <item>
      <title>An Overview of Convergence Rates for Sum of Squares Hierarchies in Polynomial Optimization</title>
      <link>https://arxiv.org/abs/2408.04417</link>
      <description>arXiv:2408.04417v2 Announce Type: replace 
Abstract: In this survey we consider polynomial optimization problems, asking to minimize a polynomial function over a compact semialgebraic set, defined by polynomial inequalities. This models a great variety of (in general, nonlinear nonconvex) optimization problems. Various hierarchies of (lower and upper) bounds have been introduced, having the remarkable property that they converge asymptotically to the global minimum. These bounds exploit algebraic representations of positive polynomials in terms of sums of squares and can be computed using semidefinite optimization. Our focus lies in the performance analysis of these hierarchies of bounds, namely, in how far the bounds are from the global minimum as the degrees of the sums of squares they involve tend to infinity. We present the main state-of-the-art results and offer a gentle introductory overview over the various techniques that have been recently developed to establish them, stemming from the theory of orthogonal polynomials, approximation theory, Fourier analysis, and more.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04417v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Monique Laurent, Lucas Slot</dc:creator>
    </item>
    <item>
      <title>Multi-Objective LQR with Linear Scalarization</title>
      <link>https://arxiv.org/abs/2408.04488</link>
      <description>arXiv:2408.04488v2 Announce Type: replace 
Abstract: The framework of decision-making, modeled as a Markov Decision Process (MDP), typically assumes a single objective. However, practical scenarios often involve tradeoffs between multiple objectives. We address this in the Linear Quadratic Regulator (LQR), a canonical continuous, infinite horizon MDP. First, we establish that the Pareto front for LQR is characterized by linear scalarization: a convex combination of objectives recovers all tradeoff points, making multi-objective LQR reducible to single-objective problems. This highlights an important instance where linear scalarization suffices for a non-convex problem. Second, we show the Pareto front is smooth, in that an $\epsilon$ perturbation of a scalarization parameter yields an $\epsilon$ approximation to the objective. These results inspire a simple algorithm to approximate the Pareto front via grid search over scalarization parameters, where each optimization problem retains the computational efficiency of single-objective LQR. Lastly, we extend the analysis to certainty equivalence, where unknown dynamics are replaced with estimates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04488v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ali Jadbabaie, Devavrat Shah, Sean R. Sinclair</dc:creator>
    </item>
    <item>
      <title>An accelerated gradient method with adaptive restart for convex multiobjective optimization problems</title>
      <link>https://arxiv.org/abs/2501.07863</link>
      <description>arXiv:2501.07863v2 Announce Type: replace 
Abstract: In this work, based on the continuous time approach, we propose an accelerated gradient method with adaptive residual restart for convex multiobjective optimization problems. For the first, we derive rigorously the continuous limit of the multiobjective accelerated proximal gradient method by Tanabe et al. [Comput. Optim. Appl., 2023]. It is a second-order ordinary differential equation (ODE) that involves a special projection operator and can be viewed as an extension of the ODE by Su et al. [J. Mach. Learn. Res., 2016] for Nesterov's accelerated gradient method. Then, we introduce a novel accelerated multiobjective gradient (AMG) flow with tailored time scaling that adapts automatically to the convex case and the strongly convex case, and the exponential decay rate of a merit function along with the solution trajectory of AMG flow is established via the Lyapunov analysis. After that, we consider an implicit-explicit time discretization and obtain an accelerated multiobjective gradient method with a convex quadratic programming subproblem. The fast sublinear rate and linear rate are proved respectively for convex and strongly convex problems. In addition, we present an efficient residual based adaptive restart technique to overcome the oscillation issue and improve the convergence significantly. Numerical results are provided to validate the practical performance of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.07863v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hao Luo, Liping Tang, Xinmin Yang</dc:creator>
    </item>
    <item>
      <title>Dynamic Sensor Selection for Biomarker Discovery</title>
      <link>https://arxiv.org/abs/2405.09809</link>
      <description>arXiv:2405.09809v4 Announce Type: replace-cross 
Abstract: Advances in methods of biological data collection are driving the rapid growth of comprehensive datasets across clinical and research settings. These datasets provide the opportunity to monitor biological systems in greater depth and at finer time steps than was achievable in the past. Classically, biomarkers are used to represent and track key aspects of a biological system. Biomarkers retain utility even with the availability of large datasets, since monitoring and interpreting changes in a vast number of molecules remains impractical. However, given the large number of molecules in these datasets, a major challenge is identifying the best biomarkers for a particular setting Here, we apply principles of observability theory to establish a general methodology for biomarker selection. We demonstrate that observability measures effectively identify biologically meaningful sensors in a range of time series transcriptomics data. Motivated by the practical considerations of biological systems, we introduce the method of dynamic sensor selection (DSS) to maximize observability over time, thus enabling observability over regimes where system dynamics themselves are subject to change. This observability framework is flexible, capable of modeling gene expression dynamics and using auxiliary data, including chromosome conformation, to select biomarkers. Additionally, we demonstrate the applicability of this approach beyond genomics by evaluating the observability of neural activity These applications demonstrate the utility of observability-guided biomarker selection for across a wide range of biological systems, from agriculture and biomanufacturing to neural applications and beyond.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.09809v4</guid>
      <category>q-bio.MN</category>
      <category>math.OC</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joshua Pickard, Cooper Stansbury, Amit Surana, Lindsey Muir, Anthony Bloch, Indika Rajapakse</dc:creator>
    </item>
    <item>
      <title>Performance-Barrier Event-Triggered Control of a Class of Reaction-Diffusion PDEs</title>
      <link>https://arxiv.org/abs/2407.08178</link>
      <description>arXiv:2407.08178v2 Announce Type: replace-cross 
Abstract: We employ the recent performance-barrier event-triggered control (P-ETC) for achieving global exponential convergence of a class of reaction-diffusion PDEs via PDE backstepping control. Rather than insisting on a strictly monotonic decrease of the Lyapunov function for the closed-loop system, P-ETC allows the Lyapunov function to increase as long as it remains below an acceptable performance-barrier. This approach integrates a performance residual, the difference between the value of the performance-barrier and the Lyapunov function, into the triggering mechanism. The integration adds flexibility and results in fewer control updates than with regular ETC (R-ETC) that demands a monotonic decrease of the Lyapunov function. Our P-ETC PDE backstepping design ensures global exponential convergence of the closed-loop system in the spatial L^2 norm, without encountering Zeno phenomenon. To avoid continuous monitoring of the triggering function that generates events, we develop periodic event-triggered and self-triggered variants (P-PETC and P-STC, respectively) of the P-ETC. The P-PETC only requires periodic evaluation of the triggering function whereas the P-STC preemptively computes the time of the next event at the current event time using the system model and continuously available system states. The P-PETC and P-STC also ensure a Zeno-free behavior and deliver performance equivalent to that of the continuous-time P-ETC which requires continuous evaluation of the triggering function, in addition to the continuous sensing of the state. We provide numerical simulations to illustrate the proposed technique and to compare it with R-ETC associated with strictly decreasing Lyapunov functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.08178v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bhathiya Rathnayake, Mamadou Diagne, Jorge Cortes, Miroslav Krstic</dc:creator>
    </item>
    <item>
      <title>Dual Cone Gradient Descent for Training Physics-Informed Neural Networks</title>
      <link>https://arxiv.org/abs/2409.18426</link>
      <description>arXiv:2409.18426v2 Announce Type: replace-cross 
Abstract: Physics-informed neural networks (PINNs) have emerged as a prominent approach for solving partial differential equations (PDEs) by minimizing a combined loss function that incorporates both boundary loss and PDE residual loss. Despite their remarkable empirical performance in various scientific computing tasks, PINNs often fail to generate reasonable solutions, and such pathological behaviors remain difficult to explain and resolve. In this paper, we identify that PINNs can be adversely trained when gradients of each loss function exhibit a significant imbalance in their magnitudes and present a negative inner product value. To address these issues, we propose a novel optimization framework, Dual Cone Gradient Descent (DCGD), which adjusts the direction of the updated gradient to ensure it falls within a dual cone region. This region is defined as a set of vectors where the inner products with both the gradients of the PDE residual loss and the boundary loss are non-negative. Theoretically, we analyze the convergence properties of DCGD algorithms in a non-convex setting. On a variety of benchmark equations, we demonstrate that DCGD outperforms other optimization algorithms in terms of various evaluation metrics. In particular, DCGD achieves superior predictive accuracy and enhances the stability of training for failure modes of PINNs and complex PDEs, compared to existing optimally tuned models. Moreover, DCGD can be further improved by combining it with popular strategies for PINNs, including learning rate annealing and the Neural Tangent Kernel (NTK).</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.18426v2</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Youngsik Hwang, Dong-Young Lim</dc:creator>
    </item>
    <item>
      <title>An Accelerated Algorithm for Stochastic Bilevel Optimization under Unbounded Smoothness</title>
      <link>https://arxiv.org/abs/2409.19212</link>
      <description>arXiv:2409.19212v5 Announce Type: replace-cross 
Abstract: This paper investigates a class of stochastic bilevel optimization problems where the upper-level function is nonconvex with potentially unbounded smoothness and the lower-level problem is strongly convex. These problems have significant applications in sequential data learning, such as text classification using recurrent neural networks. The unbounded smoothness is characterized by the smoothness constant of the upper-level function scaling linearly with the gradient norm, lacking a uniform upper bound. Existing state-of-the-art algorithms require $\widetilde{O}(1/\epsilon^4)$ oracle calls of stochastic gradient or Hessian/Jacobian-vector product to find an $\epsilon$-stationary point. However, it remains unclear if we can further improve the convergence rate when the assumptions for the function in the population level also hold for each random realization almost surely. To address this issue, we propose a new Accelerated Bilevel Optimization algorithm named AccBO. The algorithm updates the upper-level variable by normalized stochastic gradient descent with recursive momentum and the lower-level variable by the stochastic Nesterov accelerated gradient descent algorithm with averaging. We prove that our algorithm achieves an oracle complexity of $\widetilde{O}(1/\epsilon^3)$ to find an $\epsilon$-stationary point, when the lower-level stochastic gradient's variance is $O(\epsilon)$. Our proof relies on a novel lemma characterizing the dynamics of stochastic Nesterov accelerated gradient descent algorithm under distribution drift with high probability for the lower-level variable, which is of independent interest and also plays a crucial role in analyzing the hypergradient estimation error over time. Experimental results on various tasks confirm that our proposed algorithm achieves the predicted theoretical acceleration and significantly outperforms baselines in bilevel optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19212v5</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaochuan Gong, Jie Hao, Mingrui Liu</dc:creator>
    </item>
    <item>
      <title>Extended convexity and smoothness and their applications in deep learning</title>
      <link>https://arxiv.org/abs/2410.05807</link>
      <description>arXiv:2410.05807v2 Announce Type: replace-cross 
Abstract: This paper introduces an optimization framework aimed at providing a theoretical foundation for a class of composite optimization problems, particularly those encountered in deep learning. In this framework, we introduce $\mathcal{H}(\phi)$-convexity and $\mathcal{H}(\Phi)$-smoothness to generalize the existing concepts of Lipschitz smoothness and strong convexity. Furthermore, we analyze and establish the convergence of both gradient descent and stochastic gradient descent methods for objective functions that are $\mathcal{H}(\Phi)$-smooth. We prove that the optimal convergence rates of these methods depend solely on the homogeneous degree of $\Phi$. Based on these findings, we construct two types of non-convex and non-smooth optimization problems: deterministic composite and stochastic composite optimization problems, which encompass the majority of optimization problems in deep learning. To address these problems, we develop the gradient structure control algorithm and prove that it can locate approximate global optima. This marks a significant departure from traditional non-convex analysis framework, which typically settle for stationary points. Therefore, with the introduction of $\mathcal{H}(\phi)$-convexity and $\mathcal{H}(\Phi)$-smoothness, along with the GSC algorithm, the non-convex optimization mechanisms in deep learning can be theoretically explained and supported. Finally, the effectiveness of the proposed framework is substantiated through empirical experimentation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05807v2</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Binchuan Qi, Wei Gong, Li Li</dc:creator>
    </item>
    <item>
      <title>Quadratic-form Optimal Transport</title>
      <link>https://arxiv.org/abs/2501.04658</link>
      <description>arXiv:2501.04658v2 Announce Type: replace-cross 
Abstract: We introduce the framework of quadratic-form optimal transport (QOT), whose transport cost has the form $\iint c\,\mathrm{d}\pi \otimes\mathrm{d}\pi$ for some coupling $\pi$ between two marginals. Interesting examples of quadratic-form transport cost and their optimization include inequality measurement, the variance of a bivariate function, covariance, Kendall's tau, the Gromov--Wasserstein distance, quadratic assignment problems, and quadratic regularization of classic optimal transport. QOT leads to substantially different mathematical structures compared to classic transport problems and many technical challenges. We illustrate the fundamental properties of QOT, provide several cases where explicit solutions are obtained, and give general lower bounds of the optimal transport costs. For a wide class of cost functions, including the rectangular cost functions, the QOT problem is solved by a new coupling called the diamond transport, whose copula is supported on a diamond in the unit square.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.04658v2</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruodu Wang, Zhenyuan Zhang</dc:creator>
    </item>
    <item>
      <title>Stable Set Polytopes with Rank $|V(G)|/3$ for the Lov\'{a}sz--Schrijver SDP Operator</title>
      <link>https://arxiv.org/abs/2501.07413</link>
      <description>arXiv:2501.07413v2 Announce Type: replace-cross 
Abstract: We study the lift-and-project rank of the stable set polytope of graphs with respect to the Lov\'{a}sz--Schrijver SDP operator $\text{LS}_+$ applied to the fractional stable set polytope. In particular, we show that for every positive integer $\ell$, the smallest possible graph with $\text{LS}_+$-rank $\ell$ contains $3\ell$ vertices. This result is sharp and settles a conjecture posed by Lipt\'{a}k and the second author in 2003, as well as answers a generalization of a problem posed by Knuth in 1994. We also show that for every positive integer $\ell$ there exists a vertex-transitive graph on $4\ell+12$ vertices with $\text{LS}_+$-rank at least $\ell$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.07413v2</guid>
      <category>math.CO</category>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>math.OC</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yu Hin Au, Levent Tun\c{c}el</dc:creator>
    </item>
  </channel>
</rss>
