<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 04 Nov 2025 03:49:06 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 03 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Limited Memory LRSGA Optimizer to competitive optimization</title>
      <link>https://arxiv.org/abs/2510.26983</link>
      <description>arXiv:2510.26983v1 Announce Type: new 
Abstract: We introduce LM-LRSGA, a limited-memory variant of Low-Rank Symplectic Gradient Adjustment (LRSGA) for differentiable games. It is an iterative scheme for approximating Nash equilibria at first-order cost while preserving the stabilizing benefits of second-order information. By storing only a limited history of curvature pairs, LM-LRSGA is well suited to high-parameter competitive models such as GANs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.26983v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 03 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Katherine Rossella Foglia, Francesco Sergio Pisani, Vittorio Colao</dc:creator>
    </item>
    <item>
      <title>GFORS: GPU-Accelerated First-Order Method with Randomized Sampling for Binary Integer Programs</title>
      <link>https://arxiv.org/abs/2510.27117</link>
      <description>arXiv:2510.27117v1 Announce Type: new 
Abstract: We present GFORS, a GPU-accelerated framework for large binary integer programs. It couples a first-order (PDHG-style) routine that guides the search in the continuous relaxation with a randomized, feasibility-aware sampling module that generates batched binary candidates. Both components are designed to run end-to-end on GPUs with minimal CPU-GPU synchronization. The framework establishes near-stationary-point guarantees for the first-order routine and probabilistic bounds on the feasibility and quality of sampled solutions, while not providing global optimality certificates. To improve sampling effectiveness, we introduce techniques such as total-unimodular reformulation, customized sampling design, and monotone relaxation. On classic benchmarks (set cover, knapsack, max cut, 3D assignment, facility location), baseline state-of-the-art exact solvers remain stronger on small-medium instances, while GFORS attains high-quality incumbents within seconds; on large instances, GFORS yields substantially shorter runtimes, with solution quality often comparable to -- or better than -- the baseline under the same time limit. These results suggest that GFORS can complement exact solvers by delivering scalable, GPU-native search when problem size and response time are the primary constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.27117v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 03 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ningji Wei, Jiaming Liang</dc:creator>
    </item>
    <item>
      <title>Gradient Flows as Optimal Controlled Evolutions: From Rn to Wasserstein product spaces</title>
      <link>https://arxiv.org/abs/2510.27120</link>
      <description>arXiv:2510.27120v1 Announce Type: new 
Abstract: We show that the continuous-time gradient descent in Rn can be viewed as an optimal controlled evolution for a suitable action functional; a similar result holds for stochastic gradient descent. We then provide an analogous characterization for the Wasserstein gradient flow of the (relative) entropy, with an action that mirrors the classical case where the Euclidean gradient is replaced by the Wasserstein gradient of the relative entropy. In the small-step limit, these continuous-time actions align with the Jordan Kinderlehrer Otto scheme. Next, we consider gradient flows for the relative entropy over a Wasserstein product space-a study motivated by the stochastic-control formulation of Schrodinger bridges. We characterize the product-space steepest descent as the solution to a variational problem with two control velocities and a product-space Wasserstein gradient, and we show that the induced fluxes in the two components are equal and opposite. This framework suggests applications to the optimal control evolution of microrobotic swarms that can communicate their present distribution to the other swarm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.27120v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 03 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yongxin Chen, Tryphon Georgiou, Michele Pavon</dc:creator>
    </item>
    <item>
      <title>Variable Smoothing Alternating Proximal Gradient Algorithm for Coupled Composite Optimization</title>
      <link>https://arxiv.org/abs/2510.27156</link>
      <description>arXiv:2510.27156v1 Announce Type: new 
Abstract: In this paper, we consider a broad class of nonconvex and nonsmooth optimization problems, where one objective component is a nonsmooth weakly convex function composed with a linear operator. By integrating variable smoothing techniques with first-order methods, we propose a variable smoothing alternating proximal gradient algorithm that features flexible parameter choices for step sizes and smoothing levels. Under mild assumptions, we establish that the iteration complexity to reach an $\varepsilon$-approximate stationary point is $\mathcal{O}(\varepsilon^{-3})$. The proposed algorithm is evaluated on sparse signal recovery and image denoising problems. Numerical experiments demonstrate its effectiveness and superiority over existing algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.27156v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 03 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xian-Jun Long, Kang Zeng, Gao-Xi Li, Minh N. Dao, Zai-Yun Peng</dc:creator>
    </item>
    <item>
      <title>Inexact subgradient algorithm with a non-asymptotic convergence guarantee for copositive programming problems</title>
      <link>https://arxiv.org/abs/2510.27160</link>
      <description>arXiv:2510.27160v1 Announce Type: new 
Abstract: In this paper, we propose a subgradient algorithm with a non-asymptotic convergence guarantee to solve copositive programming problems. The subproblem to be solved at each iteration is a standard quadratic programming problem, which is NP-hard in general. However, the proposed algorithm allows this subproblem to be solved inexactly. For a prescribed accuracy $\epsilon &gt; 0$ for both the objective function and the constraint arising from the copositivity condition, the proposed algorithm yields an approximate solution after $O(\epsilon^{-2})$ iterations, even when the subproblems are solved inexactly. We also discuss exact and inexact approaches for solving standard quadratic programming problems and compare their performance through numerical experiments. In addition, we apply the proposed algorithm to the problem of testing complete positivity of a matrix and derive a sufficient condition for certifying that a matrix is not completely positive. Experimental results demonstrate that we can detect the lack of complete positivity in various doubly nonnegative matrices that are not completely positive.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.27160v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 03 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mitsuhiro Nishijima, Pierre-Louis Poirion, Akiko Takeda</dc:creator>
    </item>
    <item>
      <title>Nonasymptotic Convergence Rates for Plug-and-Play Methods With MMSE Denoisers</title>
      <link>https://arxiv.org/abs/2510.27211</link>
      <description>arXiv:2510.27211v1 Announce Type: new 
Abstract: It is known that the minimum-mean-squared-error (MMSE) denoiser under Gaussian noise can be written as a proximal operator, which suffices for asymptotic convergence of plug-and-play (PnP) methods but does not reveal the structure of the induced regularizer or give convergence rates. We show that the MMSE denoiser corresponds to a regularizer that can be written explicitly as an upper Moreau envelope of the negative log-marginal density, which in turn implies that the regularizer is 1-weakly convex. Using this property, we derive (to the best of our knowledge) the first sublinear convergence guarantee for PnP proximal gradient descent with an MMSE denoiser. We validate the theory with a one-dimensional synthetic study that recovers the implicit regularizer. We also validate the theory with imaging experiments (deblurring and computed tomography), which exhibit the predicted sublinear behavior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.27211v1</guid>
      <category>math.OC</category>
      <category>eess.SP</category>
      <category>stat.ML</category>
      <pubDate>Mon, 03 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Henry Pritchard, Rahul Parhi</dc:creator>
    </item>
    <item>
      <title>Value of Multi-pursuer Single-evader Pursuit-evasion Game with Terminal Cost of Evader's Position: Relaxation of Convexity Condition</title>
      <link>https://arxiv.org/abs/2510.27271</link>
      <description>arXiv:2510.27271v1 Announce Type: new 
Abstract: In this study, we consider a multi-pursuer single-evader quantitative pursuit-evasion game with payoff function that includes only the terminal cost. The terminal cost is a function related only to the terminal position of the evader. This problem has been extensively studied in target defense games. Here, we prove that a candidate for the value function generated by geometric method is the viscosity solution of the corresponding Hamilton-Jacobi-Isaacs partial differential equation (HJI PDE) Dirichlet problem. Therefore, the value function of the game at each point can be computed by a mathematical program. In our work, the convexity of the terminal cost or the target is not required. The terminal cost only needs to be locally Lipschitz continuous. The cases in which the terminal costs or the targets are not convex are covered. Therefore, our result is more universal than those of previous studies, and the complexity of the proof is improved. We also discuss the optimal strategies in this game and present an intuitive explanation of this value function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.27271v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 03 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weiwen Huang, Li Liang, Ningsheng Xu, Fang Deng</dc:creator>
    </item>
    <item>
      <title>Flatness of Two-Input Discrete-Time Systems and their Linearization</title>
      <link>https://arxiv.org/abs/2510.27380</link>
      <description>arXiv:2510.27380v1 Announce Type: new 
Abstract: In this contribution we discuss flat discrete-time nonlinear systems in a general setting including two special subclasses, namely, forward- and backward-flat systems. We relate rank conditions for certain submatrices of the Jacobian of the flat parameterization to the mentioned subclasses. Motivated by these rank conditions, for the case of two-input systems that possess an (x,u)-flat output, we derive a simple type of dynamic extension for the purpose of an exact linearization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.27380v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 03 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Johannes Schrotshamer, Bernd Kolar, Markus Sch\"oberl</dc:creator>
    </item>
    <item>
      <title>Distributed Derivative-Free Optimization Using Inexact ADMM and Trust-Region Methods</title>
      <link>https://arxiv.org/abs/2510.27396</link>
      <description>arXiv:2510.27396v1 Announce Type: new 
Abstract: To reduce complexity and achieve scalable performance in high-dimensional black-box settings, we propose a distributed method for nonconvex derivative-free optimization of continuous variables with an additively separable objective, subject to linear equality constraints. The approach is built upon the alternating direction method of multipliers (ADMM) as the distributed optimization framework. To handle general, potentially complicating linear equality constraints beyond the standard ADMM formulation, we employ a two-level ADMM structure: an inner layer that performs sequential ADMM updates, and an outer layer that drives an introduced slack variable to zero via the method of multipliers. In addition, each subproblem is solved inexactly using a derivative-free trust-region solver, ensuring suboptimality within a decreasing, theoretically controlled error tolerance. This inexactness is critical for both computational efficiency and practical applicability in black-box settings, where exact solutions are impractical or overly expensive. We establish theoretical convergence of the proposed approach to an approximate solution, and demonstrate improved computational efficiency over monolithic derivative-free optimization approaches on challenging high-dimensional benchmarks, as well as effective performance on a distributed learning problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.27396v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 03 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Damilola Fasiku, Wentao Tang</dc:creator>
    </item>
    <item>
      <title>Linear control systems on a 4D solvable Lie group used to model primary visual cortex $V1$</title>
      <link>https://arxiv.org/abs/2510.27445</link>
      <description>arXiv:2510.27445v1 Announce Type: new 
Abstract: In this article, we study linear control systems on a 4-dimensional solvable Lie group. Our motivation stems from the model introduced in \cite{baspinar}, which presents a precise geometric framework in which the primary visual cortex $V1$ is interpreted as a fiber bundle over the retinal plane $M$ (identified with $\mathbb{R}^{2}$), with orientation $\theta \in S^{1}$, spatial frequency $\omega \in \mathbb{R}^{+}$, and phase $\phi \in S^{1}$ as intrinsic parameters. For each fixed frequency $\omega$, this model defines a Lie group $G(\omega) = \mathbb{R}^{2} \times S^{1} \times S^{1}$, which we adopt in this work as the state space group $G$ of our linear control system. We also present new results concerning controllability and characterize the control sets associated with this class of systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.27445v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 03 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Adriano Da Silva, Ey\"up Kizil, Victor Ayala</dc:creator>
    </item>
    <item>
      <title>Rigidity Theory of Graphs with Heterogeneous Vertices</title>
      <link>https://arxiv.org/abs/2510.27515</link>
      <description>arXiv:2510.27515v1 Announce Type: new 
Abstract: Graph rigidity theory answers the question of whether a set of local constraints can uniquely determine the shape of a graph embedded in a Euclidean space, and has been recognized as a useful tool of examining solvability of sensor network localization (SNL) problems. In recent years, constraints involving signed angle (SA) and ratio of distance (RoD) have been adopted in SNL due to their ease of measurements and independence of the global coordinate. However, most prior works consider homogeneous nodes, i.e., all the sensors have the same perceptual abilities. Although mixed constraints have been considered recently, little is known about how the bipartition of nodes based on perceptual abilities affects the rigidity property of the network.
  In this paper, we propose a novel SA-RoD rigidity theory for graphs with heterogeneous vertices, where each vertex corresponds to a sensor node capturing either SA or RoD measurements. Unlike existing rigidity theory, the SA-RoD rigidity is shown to be strongly dependent on bipartitions of nodes, and exhibits a duality. Moreover, the shape of an SA-RoD constrained network can be uniquely determined up to uniform rotations, translations, and scalings (global SA-RoD rigidity) even if it is neither globally RoD rigid nor globally SA rigid. A scalable approach to construction of globally SA-RoD rigid frameworks is proposed. Localizability analysis and localization algorithm synthesis are both conducted based on weaker network topology conditions, compared with SAor RoD-based SNL. Numerical simulations are worked out to validate the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.27515v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 03 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yongjie Liu, Gangshan Jing, Long Wang</dc:creator>
    </item>
    <item>
      <title>Risk-constrained stochastic scheduling of multi-market energy storage systems</title>
      <link>https://arxiv.org/abs/2510.27528</link>
      <description>arXiv:2510.27528v1 Announce Type: new 
Abstract: Energy storage can promote the integration of renewables by operating with charge and discharge policies that balance an intermittent power supply. This study investigates the scheduling of energy storage assets under energy price uncertainty, with a focus on electricity markets. A two-stage stochastic risk-constrained approach is employed, whereby electricity price trajectories or specific power markets are observed, allowing for recourse in the schedule. Conditional value-at-risk is used to quantify tail risk in the optimization problems; this allows for the explicit specification of a probabilistic risk limit. The proposed approach is tested in an integrated hydrogen system (IHS) and a battery energy storage system (BESS). In the joint design and operation context for the IHS, the risk constraint results in larger installed unit capacities, increasing capital cost but enabling more energy inventory to buffer price uncertainty. As shown in both case studies, there is an operational trade-off between risk and expected reward; this is reflected in higher expected costs (or lower expected profits) with increasing levels of risk aversion. Despite the decrease in expected reward, both systems exhibit substantial benefits of increasing risk aversion. This work provides a general method to address uncertainties in energy storage scheduling, allowing operators to input their level of risk tolerance on asset decisions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.27528v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>q-fin.RM</category>
      <pubDate>Mon, 03 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gabriel D. Patr\'on, Di Zhang, Lavinia M. P. Ghilardi, Evelin Blom, Maldon Goodridge, Erik Solis, Hamidreza Jahangir, Jorge Angarita, Nandhini Ganesan, Kevin West, Nilay Shah, Calvin Tsay</dc:creator>
    </item>
    <item>
      <title>Linear Convergence and Error Bounds for Optimization Without Strong Convexity</title>
      <link>https://arxiv.org/abs/2510.27540</link>
      <description>arXiv:2510.27540v1 Announce Type: new 
Abstract: Many optimization algorithms$\unicode{x2013}$including gradient descent, proximal methods, and operator splitting techniques$\unicode{x2013}$can be formulated as fixed-point iterations (FPI) of continuous operators. When these operators are averaged, convergence to a fixed point is guaranteed when one exists, but the convergence is generally sublinear. Recent results establish linear convergence of FPI for averaged operators under certain conditions. However, such conditions do not apply to common classes of operators, such as those arising in piecewise linear and quadratic optimization problems. In this work, we prove that a local error-bound condition is both necessary and sufficient for the linear convergence of FPI applied to averaged operators. We provide explicit bounds on the convergence rate and show how these relate to the constants in the error-bound condition. Our main result demonstrates that piecewise linear operators satisfy local error bounds, ensuring linear convergence of the associated optimization algorithms. This leads to a general and practical framework for analyzing convergence behavior in algorithms such as ADMM and Douglas-Rachford in the absence of strong convexity. In particular, we obtain convergence rates that are independent of problem data for linear optimization, and depend only on the condition number of the objective for quadratic optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.27540v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 03 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kira van Treek, Javier F. Pe\~na, Juan C. Vera, Luis F. Zuluaga</dc:creator>
    </item>
    <item>
      <title>Convergence Analysis of Distributed Optimization: A Dissipativity Framework</title>
      <link>https://arxiv.org/abs/2510.27645</link>
      <description>arXiv:2510.27645v1 Announce Type: new 
Abstract: We develop a system-theoretic framework for the structured analysis of distributed optimization algorithms. We model such algorithms as a network of interacting dynamical systems and derive tests for convergence based on incremental dissipativity and contraction theory. This approach yields a step-by-step analysis pipeline independent of the network structure, with conditions expressed as linear matrix inequalities. In addition, a numerical comparison with traditional analysis methods is presented, in the context of distributed gradient descent.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.27645v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 03 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aron Karakai, Jaap Eising, Andrea Martinelli, Florian D\"orfler</dc:creator>
    </item>
    <item>
      <title>Cooperative Integrated Estimation-Guidance for Simultaneous Interception of Moving Targets</title>
      <link>https://arxiv.org/abs/2510.26948</link>
      <description>arXiv:2510.26948v1 Announce Type: cross 
Abstract: This paper proposes a cooperative integrated estimation-guidance framework for simultaneous interception of a non-maneuvering target using a team of unmanned autonomous vehicles, assuming only a subset of vehicles are equipped with dedicated sensors to measure the target's states. Unlike earlier approaches that focus solely on either estimation or guidance design, the proposed framework unifies both within a cooperative architecture. To circumvent the limitation posed by heterogeneity in target observability, sensorless vehicles estimate the target's state by leveraging information exchanged with neighboring agents over a directed communication topology through a prescribed-time observer. The proposed approach employs true proportional navigation guidance (TPNG), which uses an exact time-to-go formulation and is applicable across a wide spectrum of target motions. Furthermore, prescribed-time observer and controller are employed to achieve convergence to true target's state and consensus in time-to-go within set predefined times, respectively. Simulations demonstrate the effectiveness of the proposed framework under various engagement scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.26948v1</guid>
      <category>eess.SY</category>
      <category>cs.MA</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 03 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Lohitvel Gopikannan, Shashi Ranjan Kumar, Abhinav Sinha</dc:creator>
    </item>
    <item>
      <title>Inconsistency thresholds revisited: The effect of the graph associated with incomplete pairwise comparisons</title>
      <link>https://arxiv.org/abs/2510.27011</link>
      <description>arXiv:2510.27011v1 Announce Type: cross 
Abstract: The inconsistency of pairwise comparisons remains difficult to interpret in the absence of acceptability thresholds. The popular 10% cut-off rule proposed by Saaty has recently been applied to incomplete pairwise comparison matrices, which contain some unknown comparisons. This paper revises these inconsistency thresholds: we uncover that they depend not only on the size of the matrix and the number of missing entries, but also on the undirected graph whose edges represent the known pairwise comparisons. Therefore, using our exact thresholds is especially important if the filling in patterns coincide for a large number of matrices, as has been recommended in the literature. The strong association between the new threshold values and the spectral radius of the representing graph is also demonstrated. Our results can be integrated into software to continuously monitor inconsistency during the collection of pairwise comparisons and immediately detect potential errors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.27011v1</guid>
      <category>stat.ME</category>
      <category>math.OC</category>
      <pubDate>Mon, 03 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kolos Csaba \'Agoston, L\'aszl\'o Csat\'o</dc:creator>
    </item>
    <item>
      <title>Exploring Landscapes for Better Minima along Valleys</title>
      <link>https://arxiv.org/abs/2510.27153</link>
      <description>arXiv:2510.27153v1 Announce Type: cross 
Abstract: Finding lower and better-generalizing minima is crucial for deep learning. However, most existing optimizers stop searching the parameter space once they reach a local minimum. Given the complex geometric properties of the loss landscape, it is difficult to guarantee that such a point is the lowest or provides the best generalization. To address this, we propose an adaptor "E" for gradient-based optimizers. The adapted optimizer tends to continue exploring along landscape valleys (areas with low and nearly identical losses) in order to search for potentially better local minima even after reaching a local minimum. This approach increases the likelihood of finding a lower and flatter local minimum, which is often associated with better generalization. We also provide a proof of convergence for the adapted optimizers in both convex and non-convex scenarios for completeness. Finally, we demonstrate their effectiveness in an important but notoriously difficult training scenario, large-batch training, where Lamb is the benchmark optimizer. Our testing results show that the adapted Lamb, ALTO, increases the test accuracy (generalization) of the current state-of-the-art optimizer by an average of 2.5% across a variety of large-batch training tasks. This work potentially opens a new research direction in the design of optimization algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.27153v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Mon, 03 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tong Zhao, Jiacheng Li, Yuanchang Zhou, Guangming Tan, Weile Jia</dc:creator>
    </item>
    <item>
      <title>Numerical solution of elliptic distributed optimal control problems with boundary value tracking</title>
      <link>https://arxiv.org/abs/2510.27336</link>
      <description>arXiv:2510.27336v1 Announce Type: cross 
Abstract: We consider some boundary value tracking optimal control problem constrained by a Neumann boundary value problem for some elliptic partial differential equation where the control acts as right-hand side. This optimal control problem can be reformulated asa state-based variational problem that is the starting point for the finite element discretizion. In this paper, we only consider atensor-product finite element discretizion for which optimal discretization error estimates and fast solvers can be derived.Numerical experiments illustrate the theoretical results quantitatively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.27336v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Mon, 03 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ulrich Langer, Richard L\"oscher, Olaf Steinbach, Huidong Yang</dc:creator>
    </item>
    <item>
      <title>Bi-martingale optimal transport and its applications</title>
      <link>https://arxiv.org/abs/2510.27451</link>
      <description>arXiv:2510.27451v1 Announce Type: cross 
Abstract: We introduce a new non-linear optimal transport formulation for a pair of probability measures on $\mathbb{R}^d$ sharing a common barycentre, in which admissible transference plans satisfy two martingale-type constraints. This bi-martingale framework underlies and interconnects several variational problems on the space of probability measures. For the quadratic cost, it provides an optimal transport interpretation of the second Zolotarev distance on $\mathrm{P}_2(\mathbb{R}^d)$. For a broader class of convex costs, it leads to optimization problems under convex order constraints, encompassing in particular the Zolotarev projection onto the cone of dominating probability measures. As a main application, we construct a $\Gamma$-convergent bi-martingale approximation of the classical martingale optimal transport problem. This scheme robustly accommodates deviations from convex order between the marginal distributions and overcomes the well-known instability of MOT with respect to variations of the marginals in higher dimensions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.27451v1</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <pubDate>Mon, 03 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Karol Bo{\l}botowski</dc:creator>
    </item>
    <item>
      <title>Context-Aware Stochastic Modeling of Consumer Energy Resource Aggregators in Electricity Markets</title>
      <link>https://arxiv.org/abs/2510.27478</link>
      <description>arXiv:2510.27478v1 Announce Type: cross 
Abstract: Aggregators of consumer energy resources (CERs) like rooftop solar and battery energy storage (BES) face challenges due to their inherent uncertainties. A sensible approach is to use stochastic optimization to handle such uncertainties, which can lead to infeasible problems or loss in revenues if not chosen appropriately. This paper presents three efficient two-stage stochastic optimization methods: risk-neutral, robust, and chance-constrained, to address the impact of CER uncertainties for aggregators who participate in energy and regulation services markets in the Australian National Electricity Market. Furthermore, these methods utilize the flexibility of BES, considering precise state-of-charge dynamics and complementarity constraints, aiming for scalable performance while managing uncertainty. The problems are formed as two-stage stochastic mixed-integer linear programs, with relaxations adopted for large scenario sets. The solution approach employs scenario-based methodologies and affine recourse policies to obtain tractable reformulations. These methods are evaluated across use cases reflecting diverse operational and market settings, uncertainty characteristics, and decision-making preferences, demonstrating their ability to mitigate uncertainty, enhance profitability, and provide context-aware guidance for aggregators in choosing the most appropriate stochastic optimization method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.27478v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 03 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chatum Sankalpa, Ghulam Mohy-ud-din, Erik Weyer, Maria Vrakopoulou</dc:creator>
    </item>
    <item>
      <title>Bayesian Optimization on Networks</title>
      <link>https://arxiv.org/abs/2510.27643</link>
      <description>arXiv:2510.27643v1 Announce Type: cross 
Abstract: This paper studies optimization on networks modeled as metric graphs. Motivated by applications where the objective function is expensive to evaluate or only available as a black box, we develop Bayesian optimization algorithms that sequentially update a Gaussian process surrogate model of the objective to guide the acquisition of query points. To ensure that the surrogates are tailored to the network's geometry, we adopt Whittle-Mat\'ern Gaussian process prior models defined via stochastic partial differential equations on metric graphs. In addition to establishing regret bounds for optimizing sufficiently smooth objective functions, we analyze the practical case in which the smoothness of the objective is unknown and the Whittle-Mat\'ern prior is represented using finite elements. Numerical results demonstrate the effectiveness of our algorithms for optimizing benchmark objective functions on a synthetic metric graph and for Bayesian inversion via maximum a posteriori estimation on a telecommunication network.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.27643v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <category>stat.CO</category>
      <pubDate>Mon, 03 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenwen Li, Daniel Sanz-Alonso, Ruiyi Yang</dc:creator>
    </item>
    <item>
      <title>A Primal-dual Forward-backward Splitting Method for Cross-diffusion Gradient Flows with General Mobility Matrices</title>
      <link>https://arxiv.org/abs/2510.27660</link>
      <description>arXiv:2510.27660v1 Announce Type: cross 
Abstract: In this work, we construct a primal-dual forward-backward (PDFB) splitting method for computing a class of cross-diffusion systems that can be formulated as gradient flows under transport distances induced by matrix mobilities. By leveraging their gradient flow structure, we use minimizing movements as the variational formulation and compute these cross-diffusion systems by solving the minimizing movements as optimization problems at the fully discrete level. Our strategy to solve the optimization problems is the PDFB splitting method outlined in our previous work \cite{PDFB2024}. The efficiency of the proposed PDFB splitting method is demonstrated on several challenging cross-diffusion equations from the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.27660v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Mon, 03 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yunhong Deng, Chaozhen Wei</dc:creator>
    </item>
    <item>
      <title>Exploiting Agent Symmetries for Performance Analysis of Distributed Optimization Methods</title>
      <link>https://arxiv.org/abs/2403.11724</link>
      <description>arXiv:2403.11724v2 Announce Type: replace 
Abstract: We show that, in many settings, the worst-case performance of a distributed optimization algorithm is independent of the number of agents in the system, and can thus be computed in the fundamental case with just two agents. This result relies on a novel approach that systematically exploits symmetries in worst-case performance computation, framed as Semidefinite Programming (SDP) via the Performance Estimation Problem (PEP) framework. Harnessing agent symmetries in the PEP yields compact problems whose size is independent of the number of agents in the system. When all agents are equivalent in the problem, we establish the explicit conditions under which the resulting worst-case performance is independent of the number of agents and is therefore equivalent to the basic case with two agents. Our compact PEP formulation also allows the consideration of multiple equivalence classes of agents, and its size only depends on the number of equivalence classes. This enables practical and automated performance analysis of distributed algorithms in numerous complex and realistic settings, such as the analysis of the worst agent performance. We leverage this new tool to analyze the performance of the EXTRA algorithm in advanced settings and its scalability with the number of agents, providing a tighter analysis and deeper understanding of the algorithm performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11724v2</guid>
      <category>math.OC</category>
      <category>cs.MA</category>
      <pubDate>Mon, 03 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sebastien Colla, Julien M. Hendrickx</dc:creator>
    </item>
    <item>
      <title>Gradient descent for unbounded convex functions on Hadamard manifolds and its applications to scaling problems</title>
      <link>https://arxiv.org/abs/2404.09746</link>
      <description>arXiv:2404.09746v3 Announce Type: replace 
Abstract: In this paper, we study the asymptotic behavior of continuous- and discrete-time gradient flows of a ``lower-unbounded" convex function $f$ on a Hadamard manifold $M$, particularly, their convergence properties to the boundary $M^{\infty}$ at infinity of $M$. We establish a duality theorem that the infimum of the gradient-norm $\|\nabla f(x)\|$ of $f$ over $M$ is equal to the supremum of the negative of the recession function $f^{\infty}$ of $f$ over the boundary $M^{\infty}$, provided the infimum is positive. Further, the infimum and the supremum are obtained by the limit of the gradient flow of $f$. Our results feature convex-optimization ingredients of the moment-weight inequality for reductive group actions by Georgoulas, Robbin, and Salamon, and are applied to noncommutative optimization by B\"urgisser et al. FOCS 2019. We show that gradient descent of the Kempf-Ness function for an unstable orbit converges to a destabilizing 1-parameter subgroup in the Hilbert-Mumford criterion, and the associated moment-map sequence converges to the minimum-norm point of the moment polytope. We show further refinements for operator scaling -- the left-right action on a matrix tuple $A= (A_1,A_2,\ldots,A_N)$. We characterize the gradient-flow limit of operator scaling by a vector-space generalization of the classical Dulmage-Mendelsohn decomposition of a bipartite graph. For a special case of $N = 2$, we reveal that the limit determines the Kronecker canonical form of a matrix pencil $s A_1+A_2$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.09746v3</guid>
      <category>math.OC</category>
      <category>math.DG</category>
      <pubDate>Mon, 03 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hiroshi Hirai, Keiya Sakabe</dc:creator>
    </item>
    <item>
      <title>Data-Driven Stochastic Optimal Control in Reproducing Kernel Hilbert Spaces</title>
      <link>https://arxiv.org/abs/2407.16407</link>
      <description>arXiv:2407.16407v2 Announce Type: replace 
Abstract: This paper proposes a fully data-driven approach for optimal control of nonlinear control-affine systems represented by a stochastic diffusion. The focus is on the scenario where both the nonlinear dynamics and stage cost functions are unknown, while only a control penalty function and constraints are provided. To this end, we embed state probability densities into a reproducing kernel Hilbert space (RKHS) to leverage recent advances in operator regression, thereby identifying Markov transition operators associated with controlled diffusion processes. This operator learning approach integrates naturally with convex operator-theoretic Hamilton-Jacobi-Bellman recursions that scale linearly with state dimensionality, effectively solving a wide range of nonlinear optimal control problems. Numerical results demonstrate its ability to address diverse nonlinear control tasks, including the depth regulation of an autonomous underwater vehicle.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.16407v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>stat.ML</category>
      <pubDate>Mon, 03 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicolas Hoischen, Petar Bevanda, Stefan Sosnowski, Sandra Hirche, Boris Houska</dc:creator>
    </item>
    <item>
      <title>A Regularized Newton Method for Nonconvex Optimization with Global and Local Complexity Guarantees</title>
      <link>https://arxiv.org/abs/2502.04799</link>
      <description>arXiv:2502.04799v3 Announce Type: replace 
Abstract: Finding an $\epsilon$-stationary point of a nonconvex function with a Lipschitz continuous Hessian is a central problem in optimization. Regularized Newton methods are a classical tool and have been studied extensively, yet they still face a trade-off between global and local convergence. Whether a parameter-free algorithm of this type can simultaneously achieve optimal global complexity and quadratic local convergence remains an open question. To bridge this long-standing gap, we propose a new class of regularizers constructed from the current and previous gradients, and leverage the conjugate gradient approach with a negative curvature monitor to solve the regularized Newton equation. The proposed algorithm is adaptive, requiring no prior knowledge of the Hessian Lipschitz constant, and achieves a global complexity of $O(\epsilon^{-3/2})$ in terms of the second-order oracle calls, and $\tilde{O}(\epsilon^{-7/4})$ for Hessian-vector products, respectively. When the iterates converge to a point where the Hessian is positive definite, the method exhibits quadratic local convergence. Preliminary numerical results, including training the physics-informed neural networks, illustrate the competitiveness of our algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04799v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Mon, 03 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuhao Zhou, Jintao Xu, Bingrui Li, Chenglong Bao, Chao Ding, Jun Zhu</dc:creator>
    </item>
    <item>
      <title>On exactness of SDP relaxation for the maximum cut problem</title>
      <link>https://arxiv.org/abs/2505.05200</link>
      <description>arXiv:2505.05200v5 Announce Type: replace 
Abstract: Semidefinite programming (SDP) provides a powerful relaxation for the maximum cut problem. For a graph with rational weights, the decision problem of whether the SDP relaxation for the maximum cut problem is exact is known to be NP-hard; however its complexity was unresolved for unweighted graphs. In this work, we extend the NP-hardness result to unweighted graphs. We characterize a few classes of graphs for which the SDP relaxation is exact. For each of these graph classes, we establish conditions for uniqueness of the SDP optimum. We complement these findings by identifying two graph operations that preserve the solution rank, and in turn exactness. These results reveal how the SDP relaxation for the maximum cut problem can remain exact in arbitrarily large graphs, owing to the presence of a small structural core that governs exactness. We further address two open problems posed by Mirka and Williamson (2024), by demonstrating that uniqueness of the maximum cut partition in exact relaxation does not imply uniqueness of the SDP optimum, and that exact relaxation with multiple optimal partitions may admit optimal SDP solutions lying outside the convex hull of rank-1 reference solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.05200v5</guid>
      <category>math.OC</category>
      <pubDate>Mon, 03 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Avinash Bhardwaj, Hritiz Gogoi, Vishnu Narayanan, Abhishek Pathapati</dc:creator>
    </item>
    <item>
      <title>Any-Dimensional Polynomial Optimization via de Finetti Theorems</title>
      <link>https://arxiv.org/abs/2507.15632</link>
      <description>arXiv:2507.15632v2 Announce Type: replace 
Abstract: Polynomial optimization problems often arise in sequences indexed by dimension, and it is of interest to compute bounds on the optimal values of all problems in the sequence. Examples include certifying inequalities between symmetric functions or graph homomorphism densities that hold over vectors and graphs of all sizes, and computing the value of mean-field games viewed as limits of games with a growing number of players. In this paper, we study such any-dimensional polynomial problems using the theory of representation stability, and we develop a systematic framework to produce hierarchies of bounds for their limiting optimal values in terms of finite-dimensional polynomial optimization problems. In this paper, we study such any-dimensional polynomial problems using the theory of representation stability, and we develop a systematic framework to produce sequences of improving bounds on their limiting optimal values. Our bounds are obtained by solving finite-dimensional polynomial optimization problems (or their relaxations). These bounds converge at explicit rates, and they follow as a consequence of new de Finetti-type theorems pertaining to sequences of random arrays projecting onto each other in different ways. The proofs of these theorems are based on applying results from probability to representations of certain categories. We apply our framework to produce new bounds on problems arising in a number of application domains such as mean-field games, extremal graph theory, and symmetric function theory, and we illustrate our methods via numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.15632v2</guid>
      <category>math.OC</category>
      <category>math.RT</category>
      <pubDate>Mon, 03 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eitan Levin, Venkat Chandrasekaran</dc:creator>
    </item>
    <item>
      <title>Two-Person Additively-Separable Sum Games</title>
      <link>https://arxiv.org/abs/2507.19325</link>
      <description>arXiv:2507.19325v4 Announce Type: replace 
Abstract: We consider a sub-class of bi-matrix games which we refer to as two-person (hereafter referred to as two-player) additively-separable sum (TPASS) games, where the sum of the pay-offs of the two players is additively separable. The row player's pay-off at each pair of pure strategies, is the sum of two numbers, the first of which may be dependent on the pure strategy chosen by the column player and the second being independent of the pure strategy chosen by the column player. The column player's pay-off at each pair of pure strategies, is also the sum of two numbers, the first of which may be dependent on the pure strategy chosen by the row player and the second being independent of the pure strategy chosen by the row player. The sum of the inter-dependent components of the pay-offs of the two players is assumed to be zero. We prove the existence of equilibrium for such games and show that the set of equilibria for such games is the projection on the set of strategy pairs of the solutions of a pair of linear programming problems that are dual to each other. This result is a generalization of the corresponding and well-known result for two-person zero-sum games. We also show that a (randomized or mixed) strategy pair is an equilibrium of the game if and only if there exist two other real numbers such that the three together solve a certain linear programming problem. In order to prove this result, we need to appeal to the existence of an equilibrium for the TPASS game. The technology we use to prove our results, consists of the duality theorems and the complementary slackness theorem of linear programming.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.19325v4</guid>
      <category>math.OC</category>
      <category>cs.GT</category>
      <pubDate>Mon, 03 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Somdeb Lahiri</dc:creator>
    </item>
    <item>
      <title>A note on the c-monotonicity in optimal transport with capacity constraints</title>
      <link>https://arxiv.org/abs/2508.20428</link>
      <description>arXiv:2508.20428v2 Announce Type: replace 
Abstract: This paper studies the geometry of the optimizer for the optimal transport problem with capacity constraints. We introduce the concept of c-capacity monotonicity, which is a generalization of c-cyclical monotonicity in optimal transport. We show that the optimizer of the optimal transport problem with capacity constraints is c-capacity monotone.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.20428v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 03 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dongwei Chen</dc:creator>
    </item>
    <item>
      <title>Tensor Completion via Monotone Inclusion: Generalized Low-Rank Priors Meet Deep Denoisers</title>
      <link>https://arxiv.org/abs/2510.12425</link>
      <description>arXiv:2510.12425v2 Announce Type: replace 
Abstract: Missing entries in multi dimensional data pose significant challenges for downstream analysis across diverse real world applications. These data are naturally represented as tensors, and recent completion methods integrating global low rank priors with plug and play denoisers have demonstrated strong empirical performance. However, these approaches often rely on empirical convergence alone or unrealistic assumptions, such as deep denoisers acting as proximal operators of implicit regularizers, which generally does not hold. To address these limitations, we propose a novel tensor completion framework grounded in the monotone inclusion paradigm. Within this framework, deep denoisers are treated as general operators that require far fewer restrictions than in classical optimization based formulations. To better capture holistic structure, we further incorporate generalized low rank priors with weakly convex penalties. Building upon the Davis Yin splitting scheme, we develop the GTCTV DPC algorithm and rigorously establish its global convergence. Extensive experiments demonstrate that GTCTV DPC consistently outperforms existing methods in both quantitative metrics and visual quality, particularly at low sampling rates. For instance, at a sampling rate of 0.05 for multi dimensional image completion, GTCTV DPC achieves an average mean peak signal to noise ratio (MPSNR) that surpasses the second best method by 0.717 dB, and 0.649 dB for multi spectral images, and color videos, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.12425v2</guid>
      <category>math.OC</category>
      <category>cs.CV</category>
      <pubDate>Mon, 03 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Peng Chen, Deliang Wei, Jiale Yao, Fang Li</dc:creator>
    </item>
    <item>
      <title>Towards Optimal Control and Algorithmic Structure of Decompression Schedules</title>
      <link>https://arxiv.org/abs/2510.17551</link>
      <description>arXiv:2510.17551v2 Announce Type: replace 
Abstract: We formalise decompression planning as an optimal control problem with gas feasibility windows (ppO$_2$, END), affine ceilings, and convex penalties in normalised oversaturation. We prove existence, a monotone no re-descent structure and bang-bang ascents under a mild monotonicity assumption on inert fraction, and establish dwell time KKT conditions. We give pseudo-polynomial DP and label-setting algorithms with a priori error bounds, derive Lipschitz regularity of the online value function, and discuss multi-species extensions. The efficient frontier is continuous and generally nonconvex. We provide the first formal existence and bang-bang structure proof under mixed gas feasibility windows.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.17551v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 03 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Benjamin Marsh</dc:creator>
    </item>
    <item>
      <title>Analysis and Synthesis of Switched Optimization Algorithms</title>
      <link>https://arxiv.org/abs/2510.21490</link>
      <description>arXiv:2510.21490v2 Announce Type: replace 
Abstract: Deployment of optimization algorithms on networked systems face challenges associated with time delays and corruptions. One particular instance is the presence of time-varying delays arising from factors such as packet drops and irregular sampling. Fixed time delays can destabilize gradient descent algorithms, and this degradation is exacerbated by time-varying delays. This work concentrates on the analysis and creation of discrete-time optimization algorithms with certified exponential convergence rates that are robust against switched uncertainties between the optimizer and the gradient oracle. These optimization algorithms are implemented by a switch-scheduled output feedback controllers. Rate variation and sawtooth behavior (packet drops) in time-varying delays can be imposed through constraining switching sequences. Analysis is accomplished by bisection in the convergence rate to find Zames-Falb filter coefficents. Synthesis is performed by alternating between a filter coefficient search for a fixed controller, and a controller search for fixed multipliers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21490v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 03 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jared Miller, Fabian Jakob, Carsten Scherer, Andrea Iannelli</dc:creator>
    </item>
    <item>
      <title>Model-Free Optimization and Control of Rigid Body Dynamics: An Extremum Seeking for Vibrational Stabilization Approach</title>
      <link>https://arxiv.org/abs/2510.22402</link>
      <description>arXiv:2510.22402v3 Announce Type: replace 
Abstract: In this paper, we introduce a model-free, real-time, dynamic optimization and control method for a class of rigid body dynamics. Our method is based on a recent extremum seeking control for vibrational stabilization (ESC-VS) approach that is applicable to a class of second-order mechanical systems. The new ESC-VS method is able to stabilize a rigid body dynamic system about the optimal state of an objective function that can be unknown expression-wise, but assessable through measurements; the ESC-VS is operable by using only one perturbation/vibrational signal. We demonstrate the effectiveness and the applicability of our ESC-VS approach via three rigid-body systems: (1) satellite attitude dynamics, (2) quadcopter attitude dynamics, and (3) acceleration-controlled unicycle dynamics. The results, including simulations, illustrate the ability of our ESC-VS to operate successfully as means of optimization and control for rigid body dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22402v3</guid>
      <category>math.OC</category>
      <pubDate>Mon, 03 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rohan Palanikumar, Ahmed A. Elgohary, Simone Martini, Sameh A. Eisa</dc:creator>
    </item>
    <item>
      <title>The Iterates of Nesterov's Accelerated Algorithm Converge in The Critical Regimes</title>
      <link>https://arxiv.org/abs/2510.22715</link>
      <description>arXiv:2510.22715v2 Announce Type: replace 
Abstract: In this paper, we prove that the iterates of the accelerated Nesterov's algorithm in the critical regime do converge in the weak topology to a global minimizer of an $L$-smooth function in a real Hilbert space, hence answering positively a conjecture posed by H. Attouch and co-authors a decade ago. This result is the algorithmic case of a very recent result on the continuous-time system posted by E. Ryu on X, with assistance from ChatGPT.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22715v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 03 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Radu Ioan Bot, Jalal Fadili, Dang-Khoa Nguyen</dc:creator>
    </item>
    <item>
      <title>Accelerated Rates between Stochastic and Adversarial Online Convex Optimization</title>
      <link>https://arxiv.org/abs/2303.03272</link>
      <description>arXiv:2303.03272v2 Announce Type: replace-cross 
Abstract: Stochastic and adversarial data are two widely studied settings in online learning. But many optimization tasks are neither i.i.d. nor fully adversarial, which makes it of fundamental interest to get a better theoretical understanding of the world between these extremes. In this work we establish novel regret bounds for online convex optimization in a setting that interpolates between stochastic i.i.d. and fully adversarial losses. By exploiting smoothness of the expected losses, these bounds replace a dependence on the maximum gradient length by the variance of the gradients, which was previously known only for linear losses. In addition, they weaken the i.i.d. assumption by allowing, for example, adversarially poisoned rounds, which were previously considered in the related expert and bandit settings. In the fully i.i.d. case, our regret bounds match the rates one would expect from results in stochastic acceleration, and we also recover the optimal stochastically accelerated rates via online-to-batch conversion. In the fully adversarial case our bounds gracefully deteriorate to match the minimax regret. We further provide lower bounds showing that our regret upper bounds are tight for all intermediate regimes in terms of the stochastic variance and the adversarial variation of the loss gradients.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.03272v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Mon, 03 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sarah Sachs, Hedi Hadiji, Tim van Erven, Cristobal Guzman</dc:creator>
    </item>
    <item>
      <title>Reevaluating Theoretical Analysis Methods for Optimization in Deep Learning</title>
      <link>https://arxiv.org/abs/2407.01825</link>
      <description>arXiv:2407.01825v2 Announce Type: replace-cross 
Abstract: There is a significant gap between our theoretical understanding of optimization algorithms used in deep learning and their practical performance. Theoretical development usually focuses on proving convergence guarantees under a variety of different assumptions, which are themselves often chosen based on a rough combination of intuitive match to practice and analytical convenience. In this paper, we carefully measure the degree to which the standard optimization analyses are capable of explaining modern algorithms. To do this, we develop new empirical metrics that compare real optimization behavior with analytically predicted behavior. Our investigation is notable for its tight integration with modern optimization analysis: rather than simply checking high-level assumptions made in the analysis (e.g. smoothness), we also verify key low-level identities used by the analysis to explain optimization behavior that might hold even if the high-level motivating assumptions do not. Notably, we find that smoothness-based analyses fail in practice under most scenarios, but the key identities commonly used in convex-optimization analyses often hold in practice despite the objective's global non-convexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.01825v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 03 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hoang Tran, Qinzi Zhang, Ashok Cutkosky</dc:creator>
    </item>
    <item>
      <title>A variational formulation of a Multi-Population Mean Field Games with non-local interactions</title>
      <link>https://arxiv.org/abs/2408.03118</link>
      <description>arXiv:2408.03118v3 Announce Type: replace-cross 
Abstract: We propose a MFG model with quadratic Hamiltonian involving $N$ populations. This results in a system of $N$ Hamilton-Jacobi-Bellman and $N$ Fokker-Planck equations with non-local interactions. As in the classical case we introduce an Eulerian variational formulation which, despite the non convexity of the interaction, still gives a weak solution to the MFG model. The problem can be reformulated in Lagrangian terms and solved numerically by a Sinkhorn-like scheme. We present numerical results based on this approach, these simulations exhibit different behaviours depending on the nature (repulsive or attractive) of the non-local interaction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.03118v3</guid>
      <category>math.AP</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Mon, 03 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luigi De Pascale, Luca Nenna</dc:creator>
    </item>
    <item>
      <title>Convergence of continuous-time stochastic gradient descent with applications to deep neural networks</title>
      <link>https://arxiv.org/abs/2409.07401</link>
      <description>arXiv:2409.07401v2 Announce Type: replace-cross 
Abstract: We study a continuous-time approximation of the stochastic gradient descent process for minimizing the population expected loss in learning problems. The main results establish general sufficient conditions for the convergence, extending the results of Chatterjee (2022) established for (nonstochastic) gradient descent. We show how the main result can be applied to the case of overparametrized neural network training.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.07401v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Mon, 03 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gabor Lugosi, Eulalia Nualart</dc:creator>
    </item>
    <item>
      <title>A universal example for quantitative semi-uniform stability</title>
      <link>https://arxiv.org/abs/2410.02357</link>
      <description>arXiv:2410.02357v2 Announce Type: replace-cross 
Abstract: We characterise quantitative semi-uniform stability for $C_0$-semigroups arising from port-Hamiltonian systems, complementing recent works on exponential and strong stability. With the result, we present a simple universal example class of port-Hamiltonian $C_0$-semigroups exhibiting arbitrary decay rates slower than $t^{-1/2}$.
  The latter is based on results from the theory of Diophantine approximation, as the decay rates will be strongly related to the approximation properties of irrational numbers by rationals obtained from cut-offs of continued fraction expansions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02357v2</guid>
      <category>math.AP</category>
      <category>math.FA</category>
      <category>math.NT</category>
      <category>math.OC</category>
      <pubDate>Mon, 03 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sahiba Arora, Felix Schwenninger, Ingrid Vukusic, Marcus Waurick</dc:creator>
    </item>
    <item>
      <title>Gradient flow structure for some nonlocal diffusion equations</title>
      <link>https://arxiv.org/abs/2412.20969</link>
      <description>arXiv:2412.20969v3 Announce Type: replace-cross 
Abstract: We study ``nonlocal diffusion equations'' of the form \[ \partial_{t}\frac{d\rho_{t}}{d\pi}(x)+\int_{X}\left(\frac{d\rho_{t}}{d\pi}(x)-\frac{d\rho_{t}}{d\pi}(y)\right)\eta(x,y)d\pi(y)=0\qquad(\dagger) \] where $X$ is either $\mathbb{R}^{d}$ or $\mathbb{T}^{d}$, $\pi$ is a probability distribution on $X$, and $\eta(x,y)$ is a ``transition kernel'' which may be singular as $x\rightarrow y$. For a suitable notion of weak solutions which we discuss below, we show that solutions to these nonlocal diffusion equations can be interpreted as gradient flows of the relative entropy with respect to a certain nonlocal Wasserstein-type metric defined in terms of $\eta$ and $\pi$. These ``nonlocal Wasserstein metrics'' endow the space of probability measures on $X$ with a formal Riemannian structure, thereby providing for us a nonlocal analogue of the \emph{Otto calculus} originally developed in the context of the 2-Wasserstein metric. The class of equations $(\dagger)$ includes a family of ``nonlocal Fokker-Planck equations'', which are thus identified as nonlocal Wasserstein gradient flows of the relative entropy, analogously with the usual Fokker-Planck equation and the $W_{2}$ metric.
  The gradient flow structure we provide allows us to deduce: existence and uniqueness of solutions to ($\dagger$) in a suitable class of weak solutions; stability of solutions in the sense of evolutionary $\Gamma$-convergence, with respect to perturbations of initial condition, reference measure $\pi$, and transition kernel $\eta$; sufficient conditions for exponential convergence to equilibrium, in terms of a nonlocal analogue of the log-Sobolev inequality; as well as the consistency of a finite-volume-type spatial discretization scheme in the $\mathbb{T}^{d}$ case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.20969v3</guid>
      <category>math.AP</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Mon, 03 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrew Warren</dc:creator>
    </item>
    <item>
      <title>Markovian Search with Ex-Ante Constraints: Theory and Applications to Socially Aware Algorithmic Hiring</title>
      <link>https://arxiv.org/abs/2501.13346</link>
      <description>arXiv:2501.13346v2 Announce Type: replace-cross 
Abstract: We develop an algorithmic framework to incorporate "ex-ante" constraints on outcomes (that hold only on average) into stateful sequential search with costly inspection. Our framework encompasses the classical Weitzman's Pandora's box [Weitzman, 1979] as well as its extensions to joint Markovian scheduling [Dumitriu et al., 2003; Gittins, 1979], modeling richer processes such as multistage search with multiple layers of inspection. Ex-ante constraints in search are particularly motivated by social considerations in algorithmic hiring, where they adjust outcome distributions to promote equity and access. Building on the optimality of index-based policies in the unconstrained problems, we show that optimal policies under a single ex-ante constraint (e.g., demographic parity) retain an index-based structure but require (i) dual-based adjustments of the indices and (ii) randomization between two such adjustments via a "tie-breaking rule," both easy to compute and economically interpretable. We then extend our results to handle multiple affine constraints by reduction to a variant of the exact Carath\'eodory problem and providing a polynomial-time algorithm to construct an optimal randomized dual-adjusted index-based policy that satisfies all constraints simultaneously. For general affine and convex constraints, we develop a primal-dual algorithm that randomizes over a polynomial number of dual-based adjustments, yielding a near-feasible, near-optimal policy. All these results rely on the key observation that a suitable relaxation of the Lagrange dual function for these constrained problems admits index-based policies akin to those in the unconstrained setting. Finally, through a numerical study, we investigate the implications of various socially aware ex-ante constraints on the utilitarian loss (price of fairness), and examine whether they achieve their intended socially desirable outcomes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13346v2</guid>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <category>math.OC</category>
      <pubDate>Mon, 03 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohammad Reza Aminian, Vahideh Manshadi, Rad Niazadeh</dc:creator>
    </item>
    <item>
      <title>Kernel Mean Embedding Topology: Weak and Strong Forms for Stochastic Kernels and Implications for Model Learning</title>
      <link>https://arxiv.org/abs/2502.13486</link>
      <description>arXiv:2502.13486v2 Announce Type: replace-cross 
Abstract: We introduce a novel topology, called Kernel Mean Embedding Topology, for stochastic kernels, in a weak and strong form. This topology, defined on the spaces of Bochner integrable functions from a signal space to a space of probability measures endowed with a Hilbert space structure, allows for a versatile formulation. This construction allows one to obtain both a strong and weak formulation. (i) For its weak formulation, we highlight the utility on relaxed policy spaces, and investigate connections with the Young narrow topology and Borkar (or \( w^* \))-topology, and establish equivalence properties. We report that, while both the \( w^* \)-topology and kernel mean embedding topology are relatively compact, they are not closed. Conversely, while the Young narrow topology is closed, it lacks relative compactness. (ii) We show that the strong form provides an appropriate formulation for placing topologies on spaces of models characterized by stochastic kernels with explicit robustness and learning theoretic implications on optimal stochastic control under discounted or average cost criteria. (iii) We thus show that this topology possesses several properties making it ideal to study optimality and approximations (under the weak formulation) and robustness (under the strong formulation) for many applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13486v2</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 03 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Naci Saldi, Serdar Yuksel</dc:creator>
    </item>
    <item>
      <title>Lexicographic Preferences over Random Availability Functions</title>
      <link>https://arxiv.org/abs/2505.12997</link>
      <description>arXiv:2505.12997v2 Announce Type: replace-cross 
Abstract: We provide an axiomatic characterization of lexicographic preferences over the set of all random availability functions using two assumptions. The first assumption is strong monotonicity, which in our framework is equivalent to the strong dominance property in microeconomics. The second assumption is independence of worse alternatives and we show that a weaker version of the same suffices for our purpose.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12997v2</guid>
      <category>econ.TH</category>
      <category>math.OC</category>
      <pubDate>Mon, 03 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Somdeb Lahiri</dc:creator>
    </item>
    <item>
      <title>PoLAR: Polar-Decomposed Low-Rank Adapter Representation</title>
      <link>https://arxiv.org/abs/2506.03133</link>
      <description>arXiv:2506.03133v2 Announce Type: replace-cross 
Abstract: We show that low-rank adaptation of large-scale models suffers from a low stable rank that is well below the linear algebraic rank of the subspace, degrading fine-tuning performance. To mitigate the underutilization of the allocated subspace, we propose PoLAR, a parameterization inspired by the polar decomposition that factorizes the low-rank update into two direction matrices constrained to Stiefel manifolds and an unconstrained scale matrix. Our theory shows that PoLAR yields an exponentially faster convergence rate on a canonical low-rank adaptation problem. Pairing the parameterization with Riemannian optimization leads to consistent gains on three different benchmarks testing general language understanding, commonsense reasoning, and mathematical problem solving with base model sizes ranging from 350M to 27B.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.03133v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>eess.SP</category>
      <category>math.OC</category>
      <pubDate>Mon, 03 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kai Lion, Liang Zhang, Bingcong Li, Niao He</dc:creator>
    </item>
    <item>
      <title>On-Manifold Low-Thrust Rephasing of Quasi-Periodic Orbits</title>
      <link>https://arxiv.org/abs/2507.07940</link>
      <description>arXiv:2507.07940v2 Announce Type: replace-cross 
Abstract: A bi-level optimal control framework is introduced to solve the low-thrust re-phasing problem on quasi-periodic invariant tori in multi-body environments where deviations away from the torus during maneuver are considered unsafe or irresponsible. It is shown for a large class of mechanical systems that conformity to the torus manifold during periods of non-zero control input is infeasible. The most feasible trajectories on the torus surface are generated through the minimization of fictitious control input in the torus space using phase space control variables mapped via the torus function. These reference trajectories are then transitioned to the phase space both through a minimum tracking error homotopy and minimum time patched solutions. Results are compared to torus agnostic low-thrust transfers using measures of fuel consumption, cumulative torus error, and coast time spent on the torus during maneuver. Modifications to the framework are made for the inclusion of quasi-periodically forced dynamical systems. Lastly, minimum time recovery trajectories with free final torus conditions expose the disparity between the proposed framework and torus agnostic approaches. Examples are drawn from the circular and elliptical restricted three-body problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.07940v2</guid>
      <category>nlin.CD</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Mon, 03 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ian M. Down, Manoranjan Majji, Kathleen C. Howell</dc:creator>
    </item>
  </channel>
</rss>
