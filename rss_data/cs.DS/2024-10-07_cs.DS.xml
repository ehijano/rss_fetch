<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 08 Oct 2024 04:00:28 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Pseudo-Deterministic Construction of Irreducible Polynomials over Finite Fields</title>
      <link>https://arxiv.org/abs/2410.04071</link>
      <description>arXiv:2410.04071v1 Announce Type: new 
Abstract: We present a polynomial-time pseudo-deterministic algorithm for constructing irreducible polynomial of degree $d$ over finite field $\mathbb{F}_q$. A pseudo-deterministic algorithm is allowed to use randomness, but with high probability it must output a canonical irreducible polynomial. Our construction runs in time $\tilde{O}(d^4 \log^4{q})$.
  Our construction extends Shoup's deterministic algorithm (FOCS 1988) for the same problem, which runs in time $\tilde{O}(d^4 p^{\frac{1}{2}} \log^4{q})$ (where $p$ is the characteristic of the field $\mathbb{F}_q$). Shoup had shown a reduction from constructing irreducible polynomials to factoring polynomials over finite fields. We show that by using a fast randomized factoring algorithm, the above reduction yields an efficient pseudo-deterministic algorithm for constructing irreducible polynomials over finite fields.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04071v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>math.NT</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shanthanu S Rai</dc:creator>
    </item>
    <item>
      <title>A branch-&amp;-price approach to the unrooted maximum agreement forest problem</title>
      <link>https://arxiv.org/abs/2410.04122</link>
      <description>arXiv:2410.04122v1 Announce Type: new 
Abstract: We propose the first branch-&amp;-price algorithm for the maximum agreement forest problem on unrooted binary trees: given two unrooted X-labelled binary trees we seek to partition X into a minimum number of blocks such that the induced subtrees are disjoint and have the same topologies in both trees. We provide a dynamic programming algorithm for the weighted maximum agreement subtree problem to solve the pricing problem. When combined with rigorous polynomial-time pre-processing our branch-&amp;-price algorithm exhibits (beyond) state-of-the-art performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04122v1</guid>
      <category>cs.DS</category>
      <category>math.OC</category>
      <category>q-bio.PE</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Martin Frohn, Steven Kelk, Simona Vychytilova</dc:creator>
    </item>
    <item>
      <title>Vizing's Theorem in Near-Linear Time</title>
      <link>https://arxiv.org/abs/2410.05240</link>
      <description>arXiv:2410.05240v1 Announce Type: new 
Abstract: Vizing's theorem states that any $n$-vertex $m$-edge graph of maximum degree $\Delta$ can be \emph{edge colored} using at most $\Delta + 1$ different colors [Vizing, 1964]. Vizing's original proof is algorithmic and shows that such an edge coloring can be found in $O(mn)$ time. This was subsequently improved to $\tilde O(m\sqrt{n})$ time, independently by [Arjomandi, 1982] and by [Gabow et al., 1985]. Very recently, independently and concurrently, using randomization, this runtime bound was further improved to $\tilde{O}(n^2)$ by [Assadi, 2024] and $\tilde O(mn^{1/3})$ by [Bhattacharya, Carmon, Costa, Solomon and Zhang, 2024] (and subsequently to $\tilde O(mn^{1/4})$ time by [Bhattacharya, Costa, Solomon and Zhang, 2024]). We present an algorithm that computes a $(\Delta+1)$-edge coloring in $\tilde O(m)$ time -- in fact, even $O(m\log{\Delta})$ time -- with high probability, \emph{giving a near-optimal algorithm for this fundamental problem}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05240v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sepehr Assadi, Soheil Behnezhad, Sayan Bhattacharya, Mart\'in Costa, Shay Solomon, Tianyi Zhang</dc:creator>
    </item>
    <item>
      <title>Enabling Asymptotic Truth Learning in a Social Network</title>
      <link>https://arxiv.org/abs/2410.04317</link>
      <description>arXiv:2410.04317v1 Announce Type: cross 
Abstract: Consider a network of agents that all want to guess the correct value of some ground truth state. In a sequential order, each agent makes its decision using a single private signal which has a constant probability of error, as well as observations of actions from its network neighbors earlier in the order. We are interested in enabling \emph{network-wide asymptotic truth learning} -- that in a network of $n$ agents, almost all agents make a correct prediction with probability approaching one as $n$ goes to infinity. In this paper we study both random orderings and carefully crafted decision orders with respect to the graph topology as well as sufficient or necessary conditions for a graph to support such a good ordering. We first show that on a sparse graph of average constant degree with a random ordering asymptotic truth learning does not happen. We then show a rather modest sufficient condition to enable asymptotic truth learning. With the help of this condition we characterize graphs generated from the Erd\"os R\'enyi model and preferential attachment model. In an Erd\"os R\'enyi graph, unless the graph is super sparse (with $O(n)$ edges) or super dense (nearly a complete graph), there exists a decision ordering that supports asymptotic truth learning. Similarly, any preferential attachment network with a constant number of edges per node can achieve asymptotic truth learning under a carefully designed ordering but not under either a random ordering nor the arrival order. We also evaluated a variant of the decision ordering on different network topologies and demonstrated clear effectiveness in improving truth learning over random orderings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04317v1</guid>
      <category>cs.SI</category>
      <category>cs.DS</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kevin Lu, Jordan Chong, Matt Lu, Jie Gao</dc:creator>
    </item>
    <item>
      <title>Quantum Approximate Optimization Algorithms for Maxmimum Cut on Low-Girth Graphs</title>
      <link>https://arxiv.org/abs/2410.04409</link>
      <description>arXiv:2410.04409v1 Announce Type: cross 
Abstract: Maximum cut (MaxCut) on graphs is a classic NP-hard problem. In quantum computing, Farhi, Gutmann, and Goldstone proposed the Quantum Approximate Optimization Algorithm (QAOA) for solving the MaxCut problem. Its guarantee on cut fraction (the fraction of edges in the output cut over all edges) was mainly studied for high-girth graphs, i.e., graphs with only long cycles. On the other hand, low-girth graphs are ubiquitous in theoretical computer science, including expander graphs being outstanding examples with wide applications in theory and beyond. In this paper, we apply QAOA to MaxCut on a set of expander graphs proposed by Mohanty and O'Donnell known as additive product graphs. Additionally, we apply multi-angle QAOA (ma-QAOA) to better utilize the graph structure of additive product graphs in ansatz design. In theory, we derive an iterative formula to calculate the expected cut fraction of such graphs. On the other hand, we conduct numerical experiments to compare between best-known classical local algorithms and QAOA with constant depth. Our results demonstrate that QAOA outperforms the best-known classical algorithms by 0.3% to 5.2% on several additive product graphs, while ma-QAOA further enhances this advantage by an additional 0.6% to 2.5%. In particular, we observe cases that ma-QAOA exhibits superiority over best-known classical algorithms but QAOA does not. Furthermore, we extend our experiments to planar graphs such as tiling grid graphs, where QAOA also demonstrates an advantage.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04409v1</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tongyang Li, Yuexin Su, Ziyi Yang, Shengyu Zhang</dc:creator>
    </item>
    <item>
      <title>The $Z$-Curve as an $n$-Dimensional Hypersphere: Properties and Analysis</title>
      <link>https://arxiv.org/abs/2410.04611</link>
      <description>arXiv:2410.04611v1 Announce Type: cross 
Abstract: In this research, we introduce what seems to be a new mathematical object resulting from projecting the $n$-dimensional $Z$-curve onto an $n$-dimensional sphere. The first part presents the algorithm that enables this transition, and the second part focuses on studying the properties of the resulting object.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04611v1</guid>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>math.GR</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Diego Vazquez Gonzalez, Hsing-Kuo Pao</dc:creator>
    </item>
    <item>
      <title>Gibbs state preparation for commuting Hamiltonian: Mapping to classical Gibbs sampling</title>
      <link>https://arxiv.org/abs/2410.04909</link>
      <description>arXiv:2410.04909v1 Announce Type: cross 
Abstract: Gibbs state reparation, or Gibbs sampling, is a key computational technique extensively used in physics, statistics, and other scientific fields. Recent efforts for designing fast mixing Gibbs samplers for quantum Hamiltonians have largely focused on commuting local Hamiltonians (CLHs), a non-trivial subclass of Hamiltonians which include highly entangled systems such as the Toric code and quantum double model. Most previous Gibbs samplers relied on simulating the Davies generator, which is a Lindbladian associated with the thermalization process in nature.
  Instead of using the Davies generator, we design a different Gibbs sampler for various CLHs by giving a reduction to classical Hamiltonians, in the sense that one can efficiently prepare the Gibbs state for some CLH $H$ on a quantum computer as long as one can efficiently do classical Gibbs sampling for the corresponding classical Hamiltonian $H^{(c)}$. We demonstrate that our Gibbs sampler is able to replicate state-of-the-art results as well as prepare the Gibbs state in regimes which were previously unknown, such as the low temperature region, as long as there exists fast mixing Gibbs samplers for the corresponding classical Hamiltonians. Our reductions are as follows.
  - If $H$ is a 2-local qudit CLH, then $H^{(c)}$ is a 2-local qudit classical Hamiltonian.
  - If $H$ is a 4-local qubit CLH on 2D lattice and there are no classical qubits, then $H^{(c)}$ is a 2-local qudit classical Hamiltonian on a planar graph. As an example, our algorithm can prepare the Gibbs state for the (defected) Toric code at any non-zero temperature in $\mathcal O(n^2)$ time.
  - If $H$ is a 4-local qubit CLH on 2D lattice and there are classical qubits, assuming that quantum terms are uniformly correctable, then $H^{(c)}$ is a constant-local classical Hamiltonian.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04909v1</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yeongwoo Hwang, Jiaqing Jiang</dc:creator>
    </item>
    <item>
      <title>Quantum property testing in sparse directed graphs</title>
      <link>https://arxiv.org/abs/2410.05001</link>
      <description>arXiv:2410.05001v1 Announce Type: cross 
Abstract: We initiate the study of quantum property testing in sparse directed graphs, and more particularly in the unidirectional model, where the algorithm is allowed to query only the outgoing edges of a vertex.
  In the classical unidirectional model the problem of testing $k$-star-freeness, and more generally $k$-source-subgraph-freeness, is almost maximally hard for large $k$. We prove that this problem has almost quadratic advantage in the quantum setting. Moreover, we prove that this advantage is nearly tight, by showing a quantum lower bound using the method of dual polynomials on an intermediate problem for a new, property testing version of the $k$-collision problem that was not studied before.
  To illustrate that not all problems in graph property testing admit such a quantum speedup, we consider the problem of $3$-colorability in the related undirected bounded-degree model, when graphs are now undirected. This problem is maximally hard to test classically, and we show that also quantumly it requires a linear number of queries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05001v1</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Simon Apers, Fr\'ed\'eric Magniez, Sayantan Sen, D\'aniel Szab\'o</dc:creator>
    </item>
    <item>
      <title>Tight Space Lower Bound for Pseudo-Deterministic Approximate Counting</title>
      <link>https://arxiv.org/abs/2304.01438</link>
      <description>arXiv:2304.01438v3 Announce Type: replace 
Abstract: We investigate one of the most basic problems in streaming algorithms: approximating the number of elements in the stream. In 1978, Morris famously gave a randomized algorithm achieving a constant-factor approximation error for streams of length at most N in space $O(\log \log N)$. We investigate the pseudo-deterministic complexity of the problem and prove a tight $\Omega(\log N)$ lower bound, thus resolving a problem of Goldwasser-Grossman-Mohanty-Woodruff.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.01438v3</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/FOCS57990.2023.00091</arxiv:DOI>
      <dc:creator>Ofer Grossman, Meghal Gupta, Mark Sellke</dc:creator>
    </item>
    <item>
      <title>Weighted Reservoir Sampling with Replacement from Multiple Data Streams</title>
      <link>https://arxiv.org/abs/2403.20256</link>
      <description>arXiv:2403.20256v3 Announce Type: replace 
Abstract: Reservoir sampling techniques can be used to extract a sample from a population of unknown size, where units are observed sequentially. Most of attention has been placed to sampling without replacement, with only a small number of studies focusing on sampling with replacement. Specifically, to the author's knowledge, no one has explored in detail how to deal with the weighted case. In this work, we demonstrate that the results shown in Park et al. (2004) can be further generalized using similar techniques to develop a fast skip-based algorithm for weighted reservoir sampling with replacement. It is also shown that the algorithm can be adapted to be executed on multiple streams in parallel. Furthermore, we found that the algorithm is faster than standard methods when used to extract a single sample from the population in a non-streaming scenario.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.20256v3</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Adriano Meligrana</dc:creator>
    </item>
    <item>
      <title>Knapsack with Vertex Cover, Set Cover, and Hitting Set</title>
      <link>https://arxiv.org/abs/2406.01057</link>
      <description>arXiv:2406.01057v4 Announce Type: replace 
Abstract: Given an undirected graph $\mathcal{G}=(\mathcal{V},\mathcal{E})$, with vertex weights $(w(u))_{u\in\mathcal{V}}$, vertex values $(\alpha(u))_{u\in\mathcal{V}}$, a knapsack size $s$, and a target value $d$, the \vcknapsack problem is to determine if there exists a subset $\mathcal{U}\subseteq\mathcal{V}$ of vertices such that $\mathcal{U}$ forms a vertex cover, $w(\mathcal{U})=\sum_{u\in\mathcal{U}} w(u) \le s$, and $\alpha(\mathcal{U})=\sum_{u\in\mathcal{U}} \alpha(u) \ge d$. In this paper, we closely study the \vcknapsack problem and its variations, such as \vcknapsackbudget, \minimalvcknapsack, and \minimumvcknapsack, for both general graphs and trees. We first prove that the \vcknapsack problem belongs to the complexity class \NPC and then study the complexity of the other variations. We generalize the problem to \setc and \hs versions and design polynomial time $H_g$-factor approximation algorithm for the \setckp problem and d-factor approximation algorithm for \hstp using primal dual method. We further show that \setcks and \hsmb are hard to approximate in polynomial time. Additionally, we develop a fixed parameter tractable algorithm running in time $8^{\mathcal{O}({\rm tw})}\cdot n\cdot {\sf min}\{s,d\}$ where ${\rm tw},s,d,n$ are respectively treewidth of the graph, the size of the knapsack, the target value of the knapsack, and the number of items for the \minimalvcknapsack problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01057v4</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Palash Dey, Ashlesha Hota, Sudeshna Kolay, Sipra Singh</dc:creator>
    </item>
    <item>
      <title>Preprocessing to Reduce the Search Space for Odd Cycle Transversal</title>
      <link>https://arxiv.org/abs/2409.00245</link>
      <description>arXiv:2409.00245v2 Announce Type: replace 
Abstract: The NP-hard Odd Cycle Transversal problem asks for a minimum vertex set whose removal from an undirected input graph $G$ breaks all odd cycles, and thereby yields a bipartite graph. The problem is well-known to be fixed-parameter tractable when parameterized by the size $k$ of the desired solution. It also admits a randomized kernelization of polynomial size, using the celebrated matroid toolkit by Kratsch and Wahlstr\"{o}m. The kernelization guarantees a reduction in the total $\textit{size}$ of an input graph, but does not guarantee any decrease in the size of the solution to be sought; the latter governs the size of the search space for FPT algorithms parameterized by $k$. We investigate under which conditions an efficient algorithm can detect one or more vertices that belong to an optimal solution to Odd Cycle Transversal. By drawing inspiration from the popular $\textit{crown reduction}$ rule for Vertex Cover, and the notion of $\textit{antler decompositions}$ that was recently proposed for Feedback Vertex Set, we introduce a graph decomposition called $\textit{tight odd cycle cut}$ that can be used to certify that a vertex set is part of an optimal odd cycle transversal. While it is NP-hard to compute such a graph decomposition, we develop parameterized algorithms to find a set of at least $k$ vertices that belong to an optimal odd cycle transversal when the input contains a tight odd cycle cut certifying the membership of $k$ vertices in an optimal solution. The resulting algorithm formalizes when the search space for the solution-size parameterization of Odd Cycle Transversal can be reduced by preprocessing. To obtain our results, we develop a graph reduction step that can be used to simplify the graph to the point that the odd cycle cut can be detected via color coding.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.00245v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bart M. P. Jansen, Yosuke Mizutani, Blair D. Sullivan, Ruben F. A. Verhaegh</dc:creator>
    </item>
    <item>
      <title>Revisiting Weighted Information Extraction: A Simpler and Faster Algorithm for Ranked Enumeration</title>
      <link>https://arxiv.org/abs/2409.18563</link>
      <description>arXiv:2409.18563v2 Announce Type: replace 
Abstract: Information extraction from textual data, where the query is represented by a finite transducer and the task is to enumerate all results without repetition, and its extension to the weighted case, where each output element has a weight and the output elements are to be enumerated sorted by their weights, are important and well studied problems in database theory. On the one hand, the first framework already covers the well-known case of regular document spanners, while the latter setting covers several practically relevant tasks that cannot be described in the unweighted setting.
  It is known that in the unweighted case this problem can be solved with linear time preprocessing $O(|D|)$ and output-linear delay $O(|s|)$ in data complexity, where $D$ is the input data and $s$ is the current output element. For the weighted case, Bourhis, Grez, Jachiet, and Riveros [ICDT 2021] recently designed an algorithm with linear time preprocessing, but the delay of $O(|s| \cdot \log|\mathsf{D}|)$ depends on the size of the data.
  We first show how to leverage the existing results on enumerating shortest paths to obtain a simple alternative algorithm with linear preprocessing and a delay of $O(|s_i| + \min\{ \log i, \log|\mathsf{D}|\})$ for the $i^{\text{th}}$ output element $s_i$ (in data complexity); thus, substantially improving the previous algorithm. Next, we develop a technically involved rounding technique that allows us to devise an algorithm with linear time preprocessing and output-linear delay $O(|s|)$ with high probability. To this end, we combine tools from algebra, high-dimensional geometry, and linear programming.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.18563v2</guid>
      <category>cs.DS</category>
      <category>cs.DB</category>
      <category>cs.FL</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pawel Gawrychowski, Florin Manea, Markus L. Schmid</dc:creator>
    </item>
    <item>
      <title>Implementing any Linear Combination of Unitaries on Intermediate-term Quantum Computers</title>
      <link>https://arxiv.org/abs/2302.13555</link>
      <description>arXiv:2302.13555v4 Announce Type: replace-cross 
Abstract: We develop three new methods to implement any Linear Combination of Unitaries (LCU), a powerful quantum algorithmic tool with diverse applications. While the standard LCU procedure requires several ancilla qubits and sophisticated multi-qubit controlled operations, our methods consume significantly fewer quantum resources. The first method (Single-Ancilla LCU) estimates expectation values of observables with respect to any quantum state prepared by an LCU procedure while requiring only a single ancilla qubit, and no multi-qubit controlled operations. The second approach (Analog LCU) is a simple, physically motivated, continuous-time analogue of LCU, tailored to hybrid qubit-qumode systems. The third method (Ancilla-free LCU) requires no ancilla qubit at all and is useful when we are interested in the projection of a quantum state (prepared by the LCU procedure) in some subspace of interest. We apply the first two techniques to develop new quantum algorithms for a wide range of practical problems, ranging from Hamiltonian simulation, ground state preparation and property estimation, and quantum linear systems. Remarkably, despite consuming fewer quantum resources they retain a provable quantum advantage. The third technique allows us to connect discrete and continuous-time quantum walks with their classical counterparts. It also unifies the recently developed optimal quantum spatial search algorithms in both these frameworks, and leads to the development of new ones that require fewer ancilla qubits. Overall, our results are quite generic and can be readily applied to other problems, even beyond those considered here.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.13555v4</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shantanav Chakraborty</dc:creator>
    </item>
    <item>
      <title>On the Constant-Depth Circuit Complexity of Generating Quasigroups</title>
      <link>https://arxiv.org/abs/2402.00133</link>
      <description>arXiv:2402.00133v4 Announce Type: replace-cross 
Abstract: We investigate the constant-depth circuit complexity of the Isomorphism Problem, Minimum Generating Set Problem (MGS), and Sub(quasi)group Membership Problem (Membership) for groups and quasigroups (=Latin squares), given as input in terms of their multiplication (Cayley) tables. Despite decades of research on these problems, lower bounds for these problems even against depth-$2$ AC circuits remain unknown. Perhaps surprisingly, Chattopadhyay, Tor\'an, and Wagner (FSTTCS 2010; ACM Trans. Comput. Theory, 2013) showed that Quasigroup Isomorphism could be solved by AC circuits of depth $O(\log \log n)$ using $O(\log^2 n)$ nondeterministic bits, a class we denote $\exists^{\log^2(n)}FOLL$. We narrow this gap by improving the upper bound for many of these problems to $quasiAC^0$, thus decreasing the depth to constant.
  In particular, we show:
  - MGS for quasigroups is in $\exists^{\log^2(n)}\forall^{\log n}NTIME(\mathrm{polylog}(n))\subseteq quasiAC^0$. Papadimitriou and Yannakakis (J. Comput. Syst. Sci., 1996) conjectured that this problem was $\exists^{\log^2(n)}P$-complete; our results refute a version of that conjecture for completeness under $quasiAC^0$ reductions unconditionally, and under polylog-space reductions assuming EXP $\neq$ PSPACE.
  - MGS for groups is in $AC^{1}(L)$, improving on the previous upper bound of $P$ (Lucchini &amp; Thakkar, J. Algebra, 2024).
  - Quasigroup Isomorphism belongs to $\exists^{\log^2(n)}AC^0(DTISP(\mathrm{polylog},\log)\subseteq quasiAC^0$, improving on the previous bound of $\exists^{\log^2(n)}L\cap\exists^{\log^2(n)}FOLL\subseteq quasiFOLL$ (Chattopadhyay, Tor\'an, &amp; Wagner, ibid.; Levet, Australas. J. Combin., 2023).
  Our results suggest that understanding the constant-depth circuit complexity may be key to resolving the complexity of problems concerning (quasi)groups in the multiplication table model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.00133v4</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <category>math.GR</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nathaniel A. Collins, Joshua A. Grochow, Michael Levet, Armin Wei{\ss}</dc:creator>
    </item>
    <item>
      <title>An Elementary Predictor Obtaining $2\sqrt{T}+1$ Distance to Calibration</title>
      <link>https://arxiv.org/abs/2402.11410</link>
      <description>arXiv:2402.11410v2 Announce Type: replace-cross 
Abstract: Blasiok et al. [2023] proposed distance to calibration as a natural measure of calibration error that unlike expected calibration error (ECE) is continuous. Recently, Qiao and Zheng [2024] gave a non-constructive argument establishing the existence of an online predictor that can obtain $O(\sqrt{T})$ distance to calibration in the adversarial setting, which is known to be impossible for ECE. They leave as an open problem finding an explicit, efficient algorithm. We resolve this problem and give an extremely simple, efficient, deterministic algorithm that obtains distance to calibration error at most $2\sqrt{T}+1$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.11410v2</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>stat.ML</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eshwar Ram Arunachaleswaran, Natalie Collina, Aaron Roth, Mirah Shi</dc:creator>
    </item>
    <item>
      <title>The Primal Pathwidth SETH</title>
      <link>https://arxiv.org/abs/2403.07239</link>
      <description>arXiv:2403.07239v2 Announce Type: replace-cross 
Abstract: Motivated by the importance of dynamic programming (DP) in parameterized complexity, we consider several fine-grained questions, such as the following examples: (i) can Dominating Set be solved in time $(3-\epsilon)^{pw}n^{O(1)}$? (where $pw$ is the pathwidth) (ii) can Coloring be solved in time $pw^{(1-\epsilon)pw}n^{O(1)}$? (iii) can a short reconfiguration between two size-$k$ independent sets be found in time $n^{(1-\epsilon)k}$? Such questions are well-studied: in some cases the answer is No under the SETH, while in others coarse-grained lower bounds are known under the ETH. Even though questions such as the above seem "morally equivalent" as they all ask if a simple DP can be improved, the problems concerned have wildly varying time complexities, ranging from single-exponential FPT to XNLP-complete.
  This paper's main contribution is to show that, despite their varying complexities, these questions are not just morally equivalent, but in fact they are the same question in disguise. We achieve this by putting forth a natural complexity assumption which we call the Primal Pathwidth-Strong Exponential Time Hypothesis (pw-SETH) and which states that 3-SAT cannot be solved in time $(2-\epsilon)^{pw}n^{O(1)}$, for any $\epsilon&gt;0$, where $pw$ is the pathwidth of the primal graph of the input. We then show that numerous fine-grained questions in parameterized complexity, including the ones above, are equivalent to the pw-SETH, and hence to each other. This allows us to obtain sharp fine-grained lower bounds for problems for which previous lower bounds left a constant in the exponent undetermined, but also to increase our confidence in bounds which were previously known under the SETH, because we show that breaking any one such bound requires breaking all (old and new) bounds; and because we show that the pw-SETH is more plausible than the SETH.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07239v2</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael Lampis</dc:creator>
    </item>
    <item>
      <title>Controlling Delegations in Liquid Democracy</title>
      <link>https://arxiv.org/abs/2403.07558</link>
      <description>arXiv:2403.07558v2 Announce Type: replace-cross 
Abstract: In liquid democracy, agents can either vote directly or delegate their vote to a different agent of their choice. This results in a power structure in which certain agents possess more voting weight than others. As a result, it opens up certain possibilities of vote manipulation, including control and bribery, that do not exist in standard voting scenarios of direct democracy. Here we formalize a certain kind of election control -- in which an external agent may change certain delegation arcs -- and study the computational complexity of the corresponding combinatorial problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07558v2</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shiri Alouf-Heffetz, Tanmay Inamdar, Pallavi Jain, Yash More, Nimrod Talmon</dc:creator>
    </item>
    <item>
      <title>Agnostic Private Density Estimation for GMMs via List Global Stability</title>
      <link>https://arxiv.org/abs/2407.04783</link>
      <description>arXiv:2407.04783v2 Announce Type: replace-cross 
Abstract: We consider the problem of private density estimation for mixtures of unrestricted high dimensional Gaussians in the agnostic setting. We prove the first upper bound on the sample complexity of this problem. Previously, private learnability of high dimensional GMMs was only known in the realizable setting [Afzali et al., 2024].
  To prove our result, we exploit the notion of $\textit{list global stability}$ [Ghazi et al., 2021b,a] that was originally introduced in the context of private supervised learning. We define an agnostic variant of this definition, showing that its existence is sufficient for agnostic private density estimation. We then construct an agnostic list globally stable learner for GMMs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04783v2</guid>
      <category>stat.ML</category>
      <category>cs.CR</category>
      <category>cs.DS</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammad Afzali, Hassan Ashtiani, Christopher Liaw</dc:creator>
    </item>
    <item>
      <title>Accurate and Fast Estimation of Temporal Motifs using Path Sampling</title>
      <link>https://arxiv.org/abs/2409.08975</link>
      <description>arXiv:2409.08975v2 Announce Type: replace-cross 
Abstract: Counting the number of small subgraphs, called motifs, is a fundamental problem in social network analysis and graph mining. Many real-world networks are directed and temporal, where edges have timestamps. Motif counting in directed, temporal graphs is especially challenging because there are a plethora of different kinds of patterns. Temporal motif counts reveal much richer information and there is a need for scalable algorithms for motif counting.
  A major challenge in counting is that there can be trillions of temporal motif matches even with a graph with only millions of vertices. Both the motifs and the input graphs can have multiple edges between two vertices, leading to a combinatorial explosion problem. Counting temporal motifs involving just four vertices is not feasible with current state-of-the-art algorithms.
  We design an algorithm, TEACUPS, that addresses this problem using a novel technique of temporal path sampling. We combine a path sampling method with carefully designed temporal data structures, to propose an efficient approximate algorithm for temporal motif counting. TEACUPS is an unbiased estimator with provable concentration behavior, which can be used to bound the estimation error. For a Bitcoin graph with hundreds of millions of edges, TEACUPS runs in less than 1 minute, while the exact counting algorithm takes more than a day. We empirically demonstrate the accuracy of TEACUPS on large datasets, showing an average of 30$\times$ speedup (up to 2000$\times$ speedup) compared to existing GPU-based exact counting methods while preserving high count estimation accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08975v2</guid>
      <category>cs.SI</category>
      <category>cs.DB</category>
      <category>cs.DS</category>
      <category>cs.IR</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yunjie Pan, Omkar Bhalerao, C. Seshadhri, Nishil Talati</dc:creator>
    </item>
    <item>
      <title>Quantum Channel Testing in Average-Case Distance</title>
      <link>https://arxiv.org/abs/2409.12566</link>
      <description>arXiv:2409.12566v3 Announce Type: replace-cross 
Abstract: We study the complexity of testing properties of quantum channels. First, we show that testing identity to any channel $\mathcal N: \mathbb C^{d_{\mathrm{in}} \times d_{\mathrm{in}}} \to \mathbb C^{d_{\mathrm{out}} \times d_{\mathrm{out}}}$ in diamond norm distance requires $\Omega(\sqrt{d_{\mathrm{in}}} / \varepsilon)$ queries, even in the strongest algorithmic model that admits ancillae, coherence, and adaptivity. This is due to the worst-case nature of the distance induced by the diamond norm.
  Motivated by this limitation and other theoretical and practical applications, we introduce an average-case analogue of the diamond norm, which we call the average-case imitation diamond (ACID) norm. In the weakest algorithmic model without ancillae, coherence, or adaptivity, we prove that testing identity to certain types of channels in ACID distance can be done with complexity independent of the dimensions of the channel, while for other types of channels the complexity depends on both the input and output dimensions. Building on previous work, we also show that identity to any fixed channel can be tested with $\tilde O(d_{\mathrm{in}} d_{\mathrm{out}}^{3/2} / \varepsilon^2)$ queries in ACID distance and $\tilde O(d_{\mathrm{in}}^2 d_{\mathrm{out}}^{3/2} / \varepsilon^2)$ queries in diamond distance in this model. Finally, we prove tight bounds on the complexity of channel tomography in ACID distance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.12566v3</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Tue, 08 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gregory Rosenthal, Hugo Aaronson, Sathyawageeswar Subramanian, Animesh Datta, Tom Gur</dc:creator>
    </item>
  </channel>
</rss>
