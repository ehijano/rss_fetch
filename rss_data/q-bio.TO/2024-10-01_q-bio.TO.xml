<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.TO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.TO</link>
    <description>q-bio.TO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.TO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 01 Oct 2024 20:52:55 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Sonic Entanglements with Electromyography: Between Bodies, Signals, and Representations</title>
      <link>https://arxiv.org/abs/2409.20037</link>
      <description>arXiv:2409.20037v1 Announce Type: new 
Abstract: This paper investigates sound and music interactions arising from the use of electromyography (EMG) to instrumentalise signals from muscle exertion of the human body. We situate EMG within a family of embodied interaction modalities, where it occupies a middle ground, considered as a ''signal from the inside'' compared with external observations of the body (e.g., motion capture), but also seen as more volitional than neurological states recorded by brain electroencephalogram (EEG). To understand the messiness of gestural interaction afforded by EMG, we revisit the phenomenological turn in HCI, reading Paul Dourish's work on the transparency of ''ready-to-hand'' technologies against the grain of recent posthumanist theories, which offer a performative interpretation of musical entanglements between bodies, signals, and representations. We take music performance as a use case, reporting on the opportunities and constraints posed by EMG in workshop-based studies of vocal, instrumental, and electronic practices. We observe that across our diverse range of musical subjects, they consistently challenged notions of EMG as a transparent tool that directly registered the state of the body, reporting instead that it took on ''present-at-hand'' qualities, defamiliarising the performer's own sense of themselves and reconfiguring their embodied practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.20037v1</guid>
      <category>q-bio.TO</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3643834.3661572</arxiv:DOI>
      <arxiv:journal_reference>DIS '24: Designing Interactive Systems Conference, ACM Conference on Designing Interactive Systems, Jul 2024, IT University of Copenhagen Denmark, Denmark. pp.2691 - 2707.</arxiv:journal_reference>
      <dc:creator>Courtney N Reed (CICM), Landon Morrison (CICM), Andrew P Mcpherson (CICM), David Fierro (CICM), Atau Tanaka (Goldsmiths College)</dc:creator>
    </item>
    <item>
      <title>Open-Source Periorbital Segmentation Dataset for Ophthalmic Applications</title>
      <link>https://arxiv.org/abs/2409.20407</link>
      <description>arXiv:2409.20407v1 Announce Type: cross 
Abstract: Periorbital segmentation and distance prediction using deep learning allows for the objective quantification of disease state, treatment monitoring, and remote medicine. However, there are currently no reports of segmentation datasets for the purposes of training deep learning models with sub mm accuracy on the regions around the eyes. All images (n=2842) had the iris, sclera, lid, caruncle, and brow segmented by five trained annotators. Here, we validate this dataset through intra and intergrader reliability tests and show the utility of the data in training periorbital segmentation networks. All the annotations are publicly available for free download. Having access to segmentation datasets designed specifically for oculoplastic surgery will permit more rapid development of clinically useful segmentation networks which can be leveraged for periorbital distance prediction and disease classification. In addition to the annotations, we also provide an open-source toolkit for periorbital distance prediction from segmentation masks. The weights of all models have also been open-sourced and are publicly available for use by the community.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.20407v1</guid>
      <category>cs.CV</category>
      <category>q-bio.TO</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>George R. Nahass, Emma Koehler, Nicholas Tomaras, Danny Lopez, Madison Cheung, Alexander Palacios, Jefferey Peterson, Sacha Hubschman, Kelsey Green, Chad A. Purnell, Pete Setabutr, Ann Q. Tran, Darvin Yi</dc:creator>
    </item>
  </channel>
</rss>
