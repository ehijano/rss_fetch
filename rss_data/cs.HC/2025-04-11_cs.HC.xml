<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.HC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.HC</link>
    <description>cs.HC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.HC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 11 Apr 2025 04:00:03 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 11 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Youth as Advisors in Participatory Design: Situating Teens' Expertise in Everyday Algorithm Auditing with Teachers and Researchers</title>
      <link>https://arxiv.org/abs/2504.07202</link>
      <description>arXiv:2504.07202v1 Announce Type: new 
Abstract: Research on children and youth's participation in different roles in the design of technologies is one of the core contributions in child-computer interaction studies. Building on this work, we situate youth as advisors to a group of high school computer science teacher- and researcher-designers creating learning activities in the context of emerging technologies. Specifically, we explore algorithm auditing as a potential entry point for youth and adults to critically evaluate generative AI algorithmic systems, with the goal of designing classroom lessons. Through a two-hour session where three teenagers (16-18 years) served as advisors, we (1) examine the types of expertise the teens shared and (2) identify back stage design elements that fostered their agency and voice in this advisory role. Our discussion considers opportunities and challenges in situating youth as advisors, providing recommendations for actions that researchers, facilitators, and teachers can take to make this unusual arrangement feasible and productive.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.07202v1</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <pubDate>Fri, 11 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3713043.3728849</arxiv:DOI>
      <dc:creator>Daniel J. Noh, Deborah A. Fields, Luis Morales-Navarro, Alexis Cabrera-Sutch, Yasmin B. Kafai, Dana\'e Metaxa</dc:creator>
    </item>
    <item>
      <title>Conducting VR User Studies with People with Vision/Hearing Impairments: Challenges and Mitigation Strategies</title>
      <link>https://arxiv.org/abs/2504.07256</link>
      <description>arXiv:2504.07256v1 Announce Type: new 
Abstract: There is a lack of virtual reality (VR) user studies that have been conducted involving people with vision/hearing impairments. This is due to the difficulty of recruiting participants and the accessibility barriers of VR devices. Based on the authors' experience conducting VR user studies with participants with vision/hearing impairments, this position paper identifies 5 key challenges (1. Recruitment, 2. Language Familiarity, 3. Technology Limitations and Barriers, 4. Access to Audio Cue, and 5. Travelling to the Experiment Location) and proposes strategic approaches to mitigate these challenges. In addition, we also presented three key considerations regarding understanding participants' lived experiences that could help the user study become accessible.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.07256v1</guid>
      <category>cs.HC</category>
      <category>cs.ET</category>
      <pubDate>Fri, 11 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wenge Xu, Craig Anderton, Kurtis Weir, Arthur Theil</dc:creator>
    </item>
    <item>
      <title>A Scalable Approach to Clustering Embedding Projections</title>
      <link>https://arxiv.org/abs/2504.07285</link>
      <description>arXiv:2504.07285v1 Announce Type: new 
Abstract: Interactive visualization of embedding projections is a useful technique for understanding data and evaluating machine learning models. Labeling data within these visualizations is critical for interpretation, as labels provide an overview of the projection and guide user navigation. However, most methods for producing labels require clustering the points, which can be computationally expensive as the number of points grows. In this paper, we describe an efficient clustering approach using kernel density estimation in the projected 2D space instead of points. This algorithm can produce high-quality cluster regions from a 2D density map in a few hundred milliseconds, orders of magnitude faster than current approaches. We contribute the design of the algorithm, benchmarks, and applications that demonstrate the utility of the algorithm, including labeling and summarization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.07285v1</guid>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 11 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Donghao Ren, Fred Hohman, Dominik Moritz</dc:creator>
    </item>
    <item>
      <title>Over-Relying on Reliance: Towards Realistic Evaluations of AI-Based Clinical Decision Support</title>
      <link>https://arxiv.org/abs/2504.07423</link>
      <description>arXiv:2504.07423v1 Announce Type: new 
Abstract: As AI-based clinical decision support (AI-CDS) is introduced in more and more aspects of healthcare services, HCI research plays an increasingly important role in designing for complementarity between AI and clinicians. However, current evaluations of AI-CDS often fail to capture when AI is and is not useful to clinicians. This position paper reflects on our work and influential AI-CDS literature to advocate for moving beyond evaluation metrics like Trust, Reliance, Acceptance, and Performance on the AI's task (what we term the "trap" of human-AI collaboration). Although these metrics can be meaningful in some simple scenarios, we argue that optimizing for them ignores important ways that AI falls short of clinical benefit, as well as ways that clinicians successfully use AI. As the fields of HCI and AI in healthcare develop new ways to design and evaluate CDS tools, we call on the community to prioritize ecologically valid, domain-appropriate study setups that measure the emergent forms of value that AI can bring to healthcare professionals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.07423v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>q-bio.OT</category>
      <pubDate>Fri, 11 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Venkatesh Sivaraman, Katelyn Morrison, Will Epperson, Adam Perer</dc:creator>
    </item>
    <item>
      <title>Proceedings of the Purposeful XR Workshop for CHI 2025</title>
      <link>https://arxiv.org/abs/2504.07475</link>
      <description>arXiv:2504.07475v1 Announce Type: new 
Abstract: This volume represents the proceedings of Workshop 27 on Purposeful XR: Affordances, Challenges, and Speculations for an Ethical Future, held together with the CHI conference on Human Factors in Computing Systems on MY 26th, 2025 in Yokohama, Japan.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.07475v1</guid>
      <category>cs.HC</category>
      <pubDate>Fri, 11 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Elizabeth Childs, Samir Ghosh, Sebastian Cmentowski, Andrea Cuadra, Rabindra Ratan</dc:creator>
    </item>
    <item>
      <title>Automating the Path: An R&amp;D Agenda for Human-Centered AI and Visualization</title>
      <link>https://arxiv.org/abs/2504.07529</link>
      <description>arXiv:2504.07529v1 Announce Type: new 
Abstract: The emergence of generative AI, large language models (LLMs), and foundation models is fundamentally reshaping computer science, and visualization and visual analytics are no exception. We present a systematic framework for understanding how human-centered AI (HCAI) can transform the visualization discipline. Our framework maps four key HCAI tool capabilities -- amplify, augment, empower, and enhance -- onto the four phases of visual sensemaking: view, explore, schematize, and report. For each combination, we review existing tools, envision future possibilities, identify challenges and pitfalls, and examine ethical considerations. This design space can serve as an R\&amp;D agenda for both visualization researchers and practitioners to integrate AI into their work as well as understanding how visualization can support HCAI research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.07529v1</guid>
      <category>cs.HC</category>
      <pubDate>Fri, 11 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Niklas Elmqvist, Clemens Nylandsted Klokmose</dc:creator>
    </item>
    <item>
      <title>Understanding Learner-LLM Chatbot Interactions and the Impact of Prompting Guidelines</title>
      <link>https://arxiv.org/abs/2504.07840</link>
      <description>arXiv:2504.07840v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have transformed human-computer interaction by enabling natural language-based communication with AI-powered chatbots. These models are designed to be intuitive and user-friendly, allowing users to articulate requests with minimal effort. However, despite their accessibility, studies reveal that users often struggle with effective prompting, resulting in inefficient responses. Existing research has highlighted both the limitations of LLMs in interpreting vague or poorly structured prompts and the difficulties users face in crafting precise queries. This study investigates learner-AI interactions through an educational experiment in which participants receive structured guidance on effective prompting. We introduce and compare three types of prompting guidelines: a task-specific framework developed through a structured methodology and two baseline approaches. To assess user behavior and prompting efficacy, we analyze a dataset of 642 interactions from 107 users. Using Von NeuMidas, an extended pragmatic annotation schema for LLM interaction analysis, we categorize common prompting errors and identify recurring behavioral patterns. We then evaluate the impact of different guidelines by examining changes in user behavior, adherence to prompting strategies, and the overall quality of AI-generated responses. Our findings provide a deeper understanding of how users engage with LLMs and the role of structured prompting guidance in enhancing AI-assisted communication. By comparing different instructional frameworks, we offer insights into more effective approaches for improving user competency in AI interactions, with implications for AI literacy, chatbot usability, and the design of more responsive AI systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.07840v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <pubDate>Fri, 11 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Cansu Koyuturk, Emily Theophilou, Sabrina Patania, Gregor Donabauer, Andrea Martinenghi, Chiara Antico, Alessia Telari, Alessia Testa, Sathya Bursic, Franca Garzotto, Davinia Hernandez-Leo, Udo Kruschwitz, Davide Taibi, Simona Amenta, Martin Ruskov, Dimitri Ognibene</dc:creator>
    </item>
    <item>
      <title>Open Datasets for Grid Modeling and Visualization: An Alberta Power Network Case</title>
      <link>https://arxiv.org/abs/2504.07870</link>
      <description>arXiv:2504.07870v1 Announce Type: new 
Abstract: In the power and energy industry, multiple entities in grid operational logs are frequently recorded and updated. Thanks to recent advances in IT facilities and smart metering services, a variety of datasets such as system load, generation mix, and grid connection are often publicly available. While these resources are valuable in evaluating power grid's operational conditions and system resilience, the lack of fine-grained, accurate locational information constrain the usage of current data, which further hinders the development of smart grid and renewables integration. For instance, electricity end users are not aware of nodal generation mix or carbon emissions, while the general public have limited understanding about the effect of demand response or renewables integration if only the whole system's demands and generations are available. In this work, we focus on recovering power grid topology and line flow directions from open public dataset. Taking the Alberta grid as a working example, we start from mapping multi-modal power system datasets to the grid topology integrated with geographical information. By designing a novel optimization-based scheme to recover line flow directions, we are able to analyze and visualize the interactions between generations and demand vectors in an efficient manner. Proposed research is fully open-sourced and highly generalizable, which can help model and visualize grid information, create synthetic dataset, and facilitate analytics and decision-making framework for clean energy transition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.07870v1</guid>
      <category>cs.HC</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>eess.SY</category>
      <pubDate>Fri, 11 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ben Cheng, Yize Chen</dc:creator>
    </item>
    <item>
      <title>Towards Sustainable Creativity Support: An Exploratory Study on Prompt Based Image Generation</title>
      <link>https://arxiv.org/abs/2504.07879</link>
      <description>arXiv:2504.07879v1 Announce Type: new 
Abstract: Creativity is a valuable human skill that has long been augmented through both analog and digital tools. Recent progress in generative AI, such as image generation, provides a disruptive technological solution to supporting human creativity further and helping humans generate solutions faster. While AI image generators can help to rapidly visualize ideas based on user prompts, the use of such AI systems has also been critiqued due to their considerable energy usage. In this paper, we report on a user study (N = 24) to understand whether energy consumption can be reduced without impeding on the tool's perceived creativity support. Our results highlight that, for example, a main effect of (image generation) condition on energy consumption, and index of creativity support per prompt but not per task, which seem mainly attributed to image quantity per prompt. We provide details of our analysis on the relation between energy usage, creativity support, and prompting behavior, including attitudes towards designing with AI and its environmental impact.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.07879v1</guid>
      <category>cs.HC</category>
      <pubDate>Fri, 11 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel Hove Paludan, Julie Fredsg{\aa}rd, Kasper Patrick B\"ahrentz, Ilhan Aslan, Niels van Berkel</dc:creator>
    </item>
    <item>
      <title>OKRA: an Explainable, Heterogeneous, Multi-Stakeholder Job Recommender System</title>
      <link>https://arxiv.org/abs/2504.07108</link>
      <description>arXiv:2504.07108v1 Announce Type: cross 
Abstract: The use of recommender systems in the recruitment domain has been labeled as 'high-risk' in recent legislation. As a result, strict requirements regarding explainability and fairness have been put in place to ensure proper treatment of all involved stakeholders. To allow for stakeholder-specific explainability, while also handling highly heterogeneous recruitment data, we propose a novel explainable multi-stakeholder job recommender system using graph neural networks: the Occupational Knowledge-based Recommender using Attention (OKRA). The proposed method is capable of providing both candidate- and company-side recommendations and explanations. We find that OKRA performs substantially better than six baselines in terms of nDCG for two datasets. Furthermore, we find that the tested models show a bias toward candidates and vacancies located in urban areas. Overall, our findings suggest that OKRA provides a balance between accuracy, explainability, and fairness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.07108v1</guid>
      <category>cs.IR</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <pubDate>Fri, 11 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Roan Schellingerhout, Francesco Barile, Nava Tintarev</dc:creator>
    </item>
    <item>
      <title>ChatBench: From Static Benchmarks to Human-AI Evaluation</title>
      <link>https://arxiv.org/abs/2504.07114</link>
      <description>arXiv:2504.07114v1 Announce Type: cross 
Abstract: With the rapid adoption of LLM-based chatbots, there is a pressing need to evaluate what humans and LLMs can achieve together. However, standard benchmarks, such as MMLU, measure LLM capabilities in isolation (i.e., "AI-alone"). Here, we design and conduct a user study to convert MMLU questions into user-AI conversations, by seeding the user with the question and having them carry out a conversation with the LLM to answer their question. We release ChatBench, a new dataset with AI-alone, user-alone, and user-AI data for 396 questions and two LLMs, including 144K answers and 7,336 user-AI conversations. We find that AI-alone accuracy fails to predict user-AI accuracy, with significant differences across multiple subjects (math, physics, and moral reasoning), and we analyze the user-AI conversations to provide insight into how they diverge from AI-alone benchmarks. Finally, we show that fine-tuning a user simulator on a subset of ChatBench improves its ability to estimate user-AI accuracies, increasing correlation on held-out questions by more than 20 points, creating possibilities for scaling interactive evaluation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.07114v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <pubDate>Fri, 11 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Serina Chang, Ashton Anderson, Jake M. Hofman</dc:creator>
    </item>
    <item>
      <title>Face-LLaVA: Facial Expression and Attribute Understanding through Instruction Tuning</title>
      <link>https://arxiv.org/abs/2504.07198</link>
      <description>arXiv:2504.07198v1 Announce Type: cross 
Abstract: The human face plays a central role in social communication, necessitating the use of performant computer vision tools for human-centered applications. We propose Face-LLaVA, a multimodal large language model for face-centered, in-context learning, including facial expression and attribute recognition. Additionally, Face-LLaVA is able to generate natural language descriptions that can be used for reasoning. Leveraging existing visual databases, we first developed FaceInstruct-1M, a face-centered database for instruction tuning MLLMs for face processing. We then developed a novel face-specific visual encoder powered by Face-Region Guided Cross-Attention that integrates face geometry with local visual features. We evaluated the proposed method across nine different datasets and five different face processing tasks, including facial expression recognition, action unit detection, facial attribute detection, age estimation and deepfake detection. Face-LLaVA achieves superior results compared to existing open-source MLLMs and competitive performance compared to commercial solutions. Our model output also receives a higher reasoning rating by GPT under a zero-shot setting across all the tasks. Both our dataset and model wil be released at https://face-llava.github.io to support future advancements in social AI and foundational vision-language research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.07198v1</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <pubDate>Fri, 11 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ashutosh Chaubey, Xulang Guan, Mohammad Soleymani</dc:creator>
    </item>
    <item>
      <title>Enhancements for Developing a Comprehensive AI Fairness Assessment Standard</title>
      <link>https://arxiv.org/abs/2504.07516</link>
      <description>arXiv:2504.07516v1 Announce Type: cross 
Abstract: As AI systems increasingly influence critical sectors like telecommunications, finance, healthcare, and public services, ensuring fairness in decision-making is essential to prevent biased or unjust outcomes that disproportionately affect vulnerable entities or result in adverse impacts. This need is particularly pressing as the industry approaches the 6G era, where AI will drive complex functions like autonomous network management and hyper-personalized services. The TEC Standard for Fairness Assessment and Rating of AI Systems provides guidelines for evaluating fairness in AI, focusing primarily on tabular data and supervised learning models. However, as AI applications diversify, this standard requires enhancement to strengthen its impact and broaden its applicability. This paper proposes an expansion of the TEC Standard to include fairness assessments for images, unstructured text, and generative AI, including large language models, ensuring a more comprehensive approach that keeps pace with evolving AI technologies. By incorporating these dimensions, the enhanced framework will promote responsible and trustworthy AI deployment across various sectors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.07516v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <pubDate>Fri, 11 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/COMSNETS63942.2025.10885551</arxiv:DOI>
      <arxiv:journal_reference>2025 17th International Conference on COMmunication Systems and NETworks (COMSNETS), Bengaluru, India, 2025, pp. 1216-1220</arxiv:journal_reference>
      <dc:creator>Avinash Agarwal, Mayashankar Kumar, Manisha J. Nene</dc:creator>
    </item>
    <item>
      <title>Context-Aware Monolingual Human Evaluation of Machine Translation</title>
      <link>https://arxiv.org/abs/2504.07685</link>
      <description>arXiv:2504.07685v1 Announce Type: cross 
Abstract: This paper explores the potential of context-aware monolingual human evaluation for assessing machine translation (MT) when no source is given for reference. To this end, we compare monolingual with bilingual evaluations (with source text), under two scenarios: the evaluation of a single MT system, and the comparative evaluation of pairwise MT systems. Four professional translators performed both monolingual and bilingual evaluations by assigning ratings and annotating errors, and providing feedback on their experience. Our findings suggest that context-aware monolingual human evaluation achieves comparable outcomes to human bilingual evaluations, and suggest the feasibility and potential of monolingual evaluation as an efficient approach to assessing MT.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.07685v1</guid>
      <category>cs.CL</category>
      <category>cs.HC</category>
      <pubDate>Fri, 11 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Silvio Picinini, Sheila Castilho</dc:creator>
    </item>
    <item>
      <title>Data over dialogue: Why artificial intelligence is unlikely to humanise medicine</title>
      <link>https://arxiv.org/abs/2504.07763</link>
      <description>arXiv:2504.07763v1 Announce Type: cross 
Abstract: Recently, a growing number of experts in artificial intelligence (AI) and medicine have be-gun to suggest that the use of AI systems, particularly machine learning (ML) systems, is likely to humanise the practice of medicine by substantially improving the quality of clinician-patient relationships. In this thesis, however, I argue that medical ML systems are more likely to negatively impact these relationships than to improve them. In particular, I argue that the use of medical ML systems is likely to comprise the quality of trust, care, empathy, understanding, and communication between clinicians and patients.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.07763v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 11 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.26180/24955371.v1</arxiv:DOI>
      <arxiv:journal_reference>Monash University, 2024</arxiv:journal_reference>
      <dc:creator>Joshua Hatherley</dc:creator>
    </item>
    <item>
      <title>FairEval: Evaluating Fairness in LLM-Based Recommendations with Personality Awareness</title>
      <link>https://arxiv.org/abs/2504.07801</link>
      <description>arXiv:2504.07801v1 Announce Type: cross 
Abstract: Recent advances in Large Language Models (LLMs) have enabled their application to recommender systems (RecLLMs), yet concerns remain regarding fairness across demographic and psychological user dimensions. We introduce FairEval, a novel evaluation framework to systematically assess fairness in LLM-based recommendations. FairEval integrates personality traits with eight sensitive demographic attributes,including gender, race, and age, enabling a comprehensive assessment of user-level bias. We evaluate models, including ChatGPT 4o and Gemini 1.5 Flash, on music and movie recommendations. FairEval's fairness metric, PAFS, achieves scores up to 0.9969 for ChatGPT 4o and 0.9997 for Gemini 1.5 Flash, with disparities reaching 34.79 percent. These results highlight the importance of robustness in prompt sensitivity and support more inclusive recommendation systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.07801v1</guid>
      <category>cs.IR</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <pubDate>Fri, 11 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Chandan Kumar Sah, Xiaoli Lian, Tony Xu, Li Zhang</dc:creator>
    </item>
    <item>
      <title>ReorderBench: A Benchmark for Matrix Reordering</title>
      <link>https://arxiv.org/abs/2408.12169</link>
      <description>arXiv:2408.12169v2 Announce Type: replace 
Abstract: Matrix reordering permutes the rows and columns of a matrix to reveal meaningful visual patterns, such as blocks that represent clusters. A comprehensive collection of matrices, along with a scoring method for measuring the quality of visual patterns in these matrices, contributes to building a benchmark. This benchmark is essential for selecting or designing suitable reordering algorithms for specific tasks. In this paper, we build a matrix reordering benchmark, ReorderBench, with the goal of evaluating and improving matrix reordering techniques. This is achieved by generating a large set of representative and diverse matrices and scoring these matrices with a convolution- and entropy-based method. Our benchmark contains 2,835,000 binary matrices and 5,670,000 continuous matrices, each featuring one of four visual patterns: block, off-diagonal block, star, or band. We demonstrate the usefulness of ReorderBench through three main applications in matrix reordering: 1) evaluating different reordering algorithms, 2) creating a unified scoring model to measure the visual patterns in any matrix, and 3) developing a deep learning model for matrix reordering.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.12169v2</guid>
      <category>cs.HC</category>
      <pubDate>Fri, 11 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiangning Zhu, Zheng Wang, Zhiyang Shen, Lai Wei, Fengyuan Tian, Mengchen Liu, Shixia Liu</dc:creator>
    </item>
    <item>
      <title>Towards softerware: Enabling personalization of interactive data representations for users with disabilities</title>
      <link>https://arxiv.org/abs/2502.18348</link>
      <description>arXiv:2502.18348v2 Announce Type: replace 
Abstract: Accessible design for some may still produce barriers for others. This tension, called access friction, creates challenges for both designers and end-users with disabilities. To address this, we present the concept of softerware, a system design approach that provides end users with agency to meaningfully customize and adapt interfaces to their needs. To apply softerware to visualization, we assembled 195 data visualization customization options centered on the barriers we expect users with disabilities will experience. We built a prototype that applies a subset of these options and interviewed practitioners for feedback. Lastly, we conducted a design probe study with blind and low vision accessibility professionals to learn more about their challenges and visions for softerware. We observed access frictions between our participant's designs and they expressed that for softerware's success, current and future systems must be designed with accessible defaults, interoperability, persistence, and respect for a user's perceived effort-to-outcome ratio.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.18348v2</guid>
      <category>cs.HC</category>
      <pubDate>Fri, 11 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Frank Elavsky, Marita Vindedal, Ted Gies, Patrick Carrington, Dominik Moritz, {\O}ystein Moseng</dc:creator>
    </item>
    <item>
      <title>Immersive Virtual Reality Assessments of Working Memory and Psychomotor Skills: A Comparison between Immersive and Non-Immersive Assessments</title>
      <link>https://arxiv.org/abs/2503.06333</link>
      <description>arXiv:2503.06333v2 Announce Type: replace 
Abstract: Objective: Immersive virtual reality (VR) enhances ecologically validity and facilitates intuitive and ergonomic hand interactions for performing neuropsychological assessments. However, its comparability to traditional computerized methods remains unclear. This study investigates the convergent validity, user experience, and usability of VR-based versus PC-based assessments of short-term and working memory, and psychomotor skills, while also examining how demographic and IT-related skills influence performance in both modalities. Methods: Sixty-six participants performed the Digit Span Task (DST), Corsi Block Task (CBT), and Deary-Liewald Reaction Time Task (DLRTT) in both VR- and PC-based formats. Participants' experience in using computers and smartphones, and playing videogames, was considered. User experience and system usability of the formats were also evaluated. Results: While performance on DST was similar across modalities, PC assessments enabled better performance on CBT and faster reaction times in DLRTT. Moderate-to-strong correlations between VR and PC versions supported convergent validity. Regression analyses revealed that performance on PC versions was influenced by age, computing, and gaming experience, whereas performance on VR versions was largely independent of these factors, except for gaming experience predicting performance on CBT backward recall. Moreover, VR assessments received higher ratings for user experience and usability than PC-based assessments. Conclusion: Immersive VR assessments provide an engaging alternative to traditional computerized methods, with minimal reliance on prior IT experience and demographic factors. This resilience to individual differences suggests that VR may offer a more equitable and accessible platform for cognitive assessment. Future research should explore the long-term reliability of VR-based assessments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.06333v2</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <pubDate>Fri, 11 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Panagiotis Kourtesis, Andrea Lizarraga, Sarah E. MacPherson</dc:creator>
    </item>
    <item>
      <title>Enhancing Human-Robot Interaction in Healthcare: A Study on Nonverbal Communication Cues and Trust Dynamics with NAO Robot Caregivers</title>
      <link>https://arxiv.org/abs/2503.16469</link>
      <description>arXiv:2503.16469v2 Announce Type: replace 
Abstract: As the population of older adults increases, so will the need for both human and robot care providers. While traditional practices involve hiring human caregivers to serve meals and attend to basic needs, older adults often require continuous companionship and health monitoring. However, hiring human caregivers for this job costs a lot of money. However, using a robot like Nao could be cheaper and still helpful. This study explores the integration of humanoid robots, particularly Nao, in health monitoring and caregiving for older adults. Using a mixed-methods approach with a within-subject factorial design, we investigated the effectiveness of nonverbal communication modalities, including touch, gestures, and LED patterns, in enhancing human-robot interactions. Our results indicate that Nao's touch-based health monitoring was well-received by participants, with positive ratings across various dimensions. LED patterns were perceived as more effective and accurate compared to hand and head gestures. Moreover, longer interactions were associated with higher trust levels and perceived empathy, highlighting the importance of prolonged engagement in fostering trust in human-robot interactions. Despite limitations, our study contributes valuable insights into the potential of humanoid robots to improve health monitoring and caregiving for older adults.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16469v2</guid>
      <category>cs.HC</category>
      <category>cs.RO</category>
      <pubDate>Fri, 11 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>S M Taslim Uddin Raju</dc:creator>
    </item>
    <item>
      <title>Quantifying Personality in Human-Drone Interactions for Building Heat Loss Inspection with Virtual Reality Training</title>
      <link>https://arxiv.org/abs/2504.03014</link>
      <description>arXiv:2504.03014v2 Announce Type: replace 
Abstract: Reliable building energy audits are crucial for efficiency through heat loss detection. While drones assist inspections, they overlook the interplay between personality traits, stress management, and operational strategies expert engineers employ. This gap, combined with workforce shortages, necessitates effective knowledge transfer. This study proposes a VR-based training system for human-drone interaction in building heat loss inspection. Participants piloted a virtual drone with a thermographic monitor to identify defects. By analyzing flight patterns, stress adaptation, and inspection performance across diverse trainees, we found: (1) Flight Trajectories - Extraverts, Intuitives, Feelers, and Perceivers explored larger areas but showed higher misclassification rates, while Introverts, Sensors, Thinkers, and Judgers demonstrated methodical approaches. (2) Stress Adaptation - Heart rate variability revealed broader stress fluctuations among Extraverts, Intuitives, Feelers, and Perceivers, whereas Introverts, Sensors, Thinkers, and Judgers maintained steadier responses. Task complexity magnified these differences. (3) Inspection Performance - Extraverts, Intuitives, and Feelers achieved higher recall but over-identified defects. Introverts, Sensors, Thinkers, and Judgers made fewer random errors but risked overlooking subtle heat losses. These insights highlight the interplay among personality traits, stress management, and operational strategies in VR training for drone-assisted audits. The framework shows potential for addressing workforce shortages by facilitating knowledge transfer and optimizing human-drone collaboration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03014v2</guid>
      <category>cs.HC</category>
      <pubDate>Fri, 11 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Pengkun Liu, Pingbo Tang, Jiepeng Liu, Yu Hou</dc:creator>
    </item>
    <item>
      <title>Conversational Medical AI: Ready for Practice</title>
      <link>https://arxiv.org/abs/2411.12808</link>
      <description>arXiv:2411.12808v2 Announce Type: replace-cross 
Abstract: The shortage of doctors is creating a critical squeeze in access to medical expertise. While conversational Artificial Intelligence (AI) holds promise in addressing this problem, its safe deployment in patient-facing roles remains largely unexplored in real-world medical settings. We present the first large-scale evaluation of a physician-supervised LLM-based conversational agent in a real-world medical setting.
  Our agent, Mo, was integrated into an existing medical advice chat service. Over a three-week period, we conducted a randomized controlled experiment with 926 cases to evaluate patient experience and satisfaction. Among these, Mo handled 298 complete patient interactions, for which we report physician-assessed measures of safety and medical accuracy.
  Patients reported higher clarity of information (3.73 vs 3.62 out of 4, p &lt; 0.05) and overall satisfaction (4.58 vs 4.42 out of 5, p &lt; 0.05) with AI-assisted conversations compared to standard care, while showing equivalent levels of trust and perceived empathy. The high opt-in rate (81% among respondents) exceeded previous benchmarks for AI acceptance in healthcare. Physician oversight ensured safety, with 95% of conversations rated as "good" or "excellent" by general practitioners experienced in operating a medical advice chat service.
  Our findings demonstrate that carefully implemented AI medical assistants can enhance patient experience while maintaining safety standards through physician supervision. This work provides empirical evidence for the feasibility of AI deployment in healthcare communication and insights into the requirements for successful integration into existing healthcare services.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.12808v2</guid>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <pubDate>Fri, 11 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Antoine Liz\'ee, Pierre-Auguste Beaucot\'e, James Whitbeck, Marion Doumeingts, Ana\"el Beaugnon, Isabelle Feldhaus</dc:creator>
    </item>
    <item>
      <title>Not someone, but something: Rethinking trust in the age of medical AI</title>
      <link>https://arxiv.org/abs/2504.05331</link>
      <description>arXiv:2504.05331v2 Announce Type: replace-cross 
Abstract: As artificial intelligence (AI) becomes embedded in healthcare, trust in medical decision-making is changing fast. This opinion paper argues that trust in AI isn't a simple transfer from humans to machines - it's a dynamic, evolving relationship that must be built and maintained. Rather than debating whether AI belongs in medicine, this paper asks: what kind of trust must AI earn, and how? Drawing from philosophy, bioethics, and system design, it explores the key differences between human trust and machine reliability - emphasizing transparency, accountability, and alignment with the values of good care. It argues that trust in AI shouldn't be built on mimicking empathy or intuition, but on thoughtful design, responsible deployment, and clear moral responsibility. The goal is a balanced view - one that avoids blind optimism and reflexive fear. Trust in AI must be treated not as a given, but as something to be earned over time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.05331v2</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <pubDate>Fri, 11 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jan Beger</dc:creator>
    </item>
    <item>
      <title>A Multimedia Analytics Model for the Foundation Model Era</title>
      <link>https://arxiv.org/abs/2504.06138</link>
      <description>arXiv:2504.06138v2 Announce Type: replace-cross 
Abstract: The rapid advances in Foundation Models and agentic Artificial Intelligence are transforming multimedia analytics by enabling richer, more sophisticated interactions between humans and analytical systems. Existing conceptual models for visual and multimedia analytics, however, do not adequately capture the complexity introduced by these powerful AI paradigms. To bridge this gap, we propose a comprehensive multimedia analytics model specifically designed for the foundation model era. Building upon established frameworks from visual analytics, multimedia analytics, knowledge generation, analytic task definition, mixed-initiative guidance, and human-in-the-loop reinforcement learning, our model emphasizes integrated human-AI teaming based on visual analytics agents from both technical and conceptual perspectives. Central to the model is a seamless, yet explicitly separable, interaction channel between expert users and semi-autonomous analytical processes, ensuring continuous alignment between user intent and AI behavior. The model addresses practical challenges in sensitive domains such as intelligence analysis, investigative journalism, and other fields handling complex, high-stakes data. We illustrate through detailed case studies how our model facilitates deeper understanding and targeted improvement of multimedia analytics solutions. By explicitly capturing how expert users can optimally interact with and guide AI-powered multimedia analytics systems, our conceptual framework sets a clear direction for system design, comparison, and future research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.06138v2</guid>
      <category>cs.MM</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <pubDate>Fri, 11 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marcel Worring, Jan Zah\'alka, Stef van den Elzen, Maximilian T. Fischer, Daniel A. Keim</dc:creator>
    </item>
  </channel>
</rss>
