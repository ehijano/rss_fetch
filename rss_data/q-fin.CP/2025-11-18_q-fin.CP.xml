<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-fin.CP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-fin.CP</link>
    <description>q-fin.CP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-fin.CP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 19 Nov 2025 02:46:56 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Statistical and economic evaluation of forecasts in electricity markets: beyond RMSE and MAE</title>
      <link>https://arxiv.org/abs/2511.13616</link>
      <description>arXiv:2511.13616v1 Announce Type: new 
Abstract: In recent years, a rapid development of forecasting methods has led to an increase in the accuracy of predictions. In the literature, forecasts are typically evaluated using metrics such as Root Mean Squared Error (RMSE) and Mean Absolute Error (MAE). While appropriate for statistical assessment, these measures do not adequately reflect the economic value of forecasts. This study addresses the decision-making problem faced by a battery energy storage system, which must determine optimal charging and discharging times based on day-ahead electricity price forecasts. To explore the relationship between forecast accuracy and economic value, we generate a pool of 192 forecasts. These are evaluated using seven statistical metrics that go beyond RMSE and MAE, capturing various characteristics of the predictions and associated errors. We calculate the dynamic correlation between the statistical measures and gained profits to reveal that both RMSE and MAE are only weakly correlated with revenue. In contrast, measures that assess the alignment between predicted and actual daily price curves have a stronger relationship with profitability and are thus more effective for selecting optimal forecasts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.13616v1</guid>
      <category>q-fin.CP</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Katarzyna Maciejowska, Arkadiusz Lipiecki, Bartosz Uniejewski</dc:creator>
    </item>
    <item>
      <title>Deep Reinforcement Learning for Automated Stock Trading: An Ensemble Strategy</title>
      <link>https://arxiv.org/abs/2511.12120</link>
      <description>arXiv:2511.12120v1 Announce Type: cross 
Abstract: Stock trading strategies play a critical role in investment. However, it is challenging to design a profitable strategy in a complex and dynamic stock market. In this paper, we propose an ensemble strategy that employs deep reinforcement schemes to learn a stock trading strategy by maximizing investment return. We train a deep reinforcement learning agent and obtain an ensemble trading strategy using three actor-critic based algorithms: Proximal Policy Optimization (PPO), Advantage Actor Critic (A2C), and Deep Deterministic Policy Gradient (DDPG). The ensemble strategy inherits and integrates the best features of the three algorithms, thereby robustly adjusting to different market situations. In order to avoid the large memory consumption in training networks with continuous action space, we employ a load-on-demand technique for processing very large data. We test our algorithms on the 30 Dow Jones stocks that have adequate liquidity. The performance of the trading agent with different reinforcement learning algorithms is evaluated and compared with both the Dow Jones Industrial Average index and the traditional min-variance portfolio allocation strategy. The proposed deep ensemble strategy is shown to outperform the three individual algorithms and two baselines in terms of the risk-adjusted return measured by the Sharpe ratio. This work is fully open-sourced at \href{https://github.com/AI4Finance-Foundation/Deep-Reinforcement-Learning-for-Automated-Stock-Trading-Ensemble-Strategy-ICAIF-2020}{GitHub}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.12120v1</guid>
      <category>q-fin.TR</category>
      <category>q-fin.CP</category>
      <category>q-fin.PM</category>
      <category>stat.ML</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongyang Yang, Xiao-Yang Liu, Shan Zhong, Anwar Walid</dc:creator>
    </item>
    <item>
      <title>A Practical Machine Learning Approach for Dynamic Stock Recommendation</title>
      <link>https://arxiv.org/abs/2511.12129</link>
      <description>arXiv:2511.12129v1 Announce Type: cross 
Abstract: Stock recommendation is vital to investment companies and investors. However, no single stock selection strategy will always win while analysts may not have enough time to check all S&amp;P 500 stocks (the Standard &amp; Poor's 500). In this paper, we propose a practical scheme that recommends stocks from S&amp;P 500 using machine learning. Our basic idea is to buy and hold the top 20% stocks dynamically. First, we select representative stock indicators with good explanatory power. Secondly, we take five frequently used machine learning methods, including linear regression, ridge regression, stepwise regression, random forest and generalized boosted regression, to model stock indicators and quarterly log-return in a rolling window. Thirdly, we choose the model with the lowest Mean Square Error in each period to rank stocks. Finally, we test the selected stocks by conducting portfolio allocation methods such as equally weighted, mean-variance, and minimum-variance. Our empirical results show that the proposed scheme outperforms the long-only strategy on the S&amp;P 500 index in terms of Sharpe ratio and cumulative returns. This work is fully open-sourced at \href{https://github.com/AI4Finance-Foundation/Dynamic-Stock-Recommendation-Machine_Learning-Published-Paper-IEEE}{GitHub}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.12129v1</guid>
      <category>q-fin.TR</category>
      <category>q-fin.CP</category>
      <category>q-fin.PM</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongyang Yang, Xiao-Yang Liu, Qingwei Wu</dc:creator>
    </item>
    <item>
      <title>Sharpening Shapley Allocation: from Basel 2.5 to FRTB</title>
      <link>https://arxiv.org/abs/2511.12391</link>
      <description>arXiv:2511.12391v1 Announce Type: cross 
Abstract: Risk allocation, the decomposition of a portfolio-wide risk measure into component contributions, is a fundamental problem in financial risk management due to the non-additive nature of risk measures, the layered organizational structures of financial institutions and the range of possible allocation strategies characterized by different rationales and properties.
  In this work, we conduct a systematic review of the major risk allocation strategies typically used in finance, comparing their theoretical properties, practical advantages, and limitations. To this scope we set up a specific testing framework, including both simplified settings, designed to highlight basic intrinsic behaviours, and realistic financial portfolios under different risk regulations, i.e. Basel 2.5 and FRTB. Furthermore, we develop and test novel practical solutions to manage the issue of negative risk allocations and of multi-level risk allocation in the layered organizational structure of financial institutions, while preserving the additivity property. Finally, we devote particular attention to the computational aspects of risk allocation.
  Our results show that, in this context, the Shapley allocation strategy offers the best compromise between simplicity, mathematical properties, risk representation and computational cost. The latter is still acceptable even in the challenging case of many business units, provided that an efficient Monte Carlo simulation is employed, which offers excellent scaling and convergence properties. While our empirical applications focus on market risk, our methodological framework is fully general and applicable to other financial context such as valuation risk, liquidity risk, credit risk, and counterparty credit risk.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.12391v1</guid>
      <category>q-fin.RM</category>
      <category>q-fin.CP</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marco Scaringi, Marco Bianchetti</dc:creator>
    </item>
    <item>
      <title>CBDC Stress Test in a Dual-Currency Setting</title>
      <link>https://arxiv.org/abs/2511.13384</link>
      <description>arXiv:2511.13384v2 Announce Type: cross 
Abstract: This study explores the potential impact of introducing a Central Bank Digital Currency (CBDC) on financial stability in an emerging dual-currency economy (Romania), where the domestic currency (RON) coexists with the euro. It develops an integrated analytical framework combining econometrics, machine learning, and behavioural modelling. CBDC adoption probabilities are estimated using XGBoost and logistic regression models trained on behavioural and macro-financial indicators rather than survey data. Liquidity stress simulations assess how banks would respond to deposit withdrawals resulting from CBDC adoption, while VAR, MSVAR, and SVAR models capture the macro-financial transmission of liquidity shocks into credit contraction and changes in monetary conditions. The findings indicate that CBDC uptake (co-circulating Digital RON and Digital EUR) would be moderate at issuance, amounting to around EUR 1 billion, primarily driven by digital readiness and trust in the central bank. The study concludes that a non-remunerated, capped CBDC, designed primarily as a means of payment rather than a store of value, can be introduced without compromising financial stability. In dual currency economies, differentiated holding limits for domestic and foreign digital currencies (e.g., Digital RON versus Digital Euro) are crucial to prevent uncontrolled euroisation and preserve monetary sovereignty. A prudent design with moderate caps, non remuneration, and macroprudential coordination can transform CBDC into a digital liquidity buffer and a complementary monetary policy instrument that enhances resilience and inclusion rather than destabilising the financial system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.13384v2</guid>
      <category>q-fin.GN</category>
      <category>q-fin.CP</category>
      <category>q-fin.ST</category>
      <category>stat.OT</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Catalin Dumitrescu</dc:creator>
    </item>
    <item>
      <title>Market-Dependent Communication in Multi-Agent Alpha Generation</title>
      <link>https://arxiv.org/abs/2511.13614</link>
      <description>arXiv:2511.13614v1 Announce Type: cross 
Abstract: Multi-strategy hedge funds face a fundamental organizational choice: should analysts generating trading strategies communicate, and if so, how? We investigate this using 5-agent LLM-based trading systems across 450 experiments spanning 21 months, comparing five organizational structures from isolated baseline to collaborative and competitive conversation. We show that communication improves performance, but optimal communication design depends on market characteristics. Competitive conversation excels in volatile technology stocks, while collaborative conversation dominates stable general stocks. Finance stocks resist all communication interventions. Surprisingly, all structures, including isolated agents, converge to similar strategy alignments, challenging assumptions that transparency causes harmful diversity loss. Performance differences stem from behavioral mechanisms: competitive agents focus on stock-level allocation while collaborative agents develop technical frameworks. Conversation quality scores show zero correlation with returns. These findings demonstrate that optimal communication design must match market volatility characteristics, and sophisticated discussions don't guarantee better performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.13614v1</guid>
      <category>cs.MA</category>
      <category>cs.CE</category>
      <category>q-fin.CP</category>
      <category>q-fin.TR</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jerick Shi, Burton Hollifield</dc:creator>
    </item>
    <item>
      <title>Complex discontinuities of the square root of Fredholm determinants in the Volterra Stein-Stein model</title>
      <link>https://arxiv.org/abs/2503.02965</link>
      <description>arXiv:2503.02965v2 Announce Type: replace-cross 
Abstract: Fourier-based methods are central to option pricing and hedging when the Fourier-Laplace transform of the log-price and integrated variance is available semi-explicitly. This is the case for the Volterra Stein-Stein stochastic volatility model, where the characteristic function is known analytically. However, naive evaluation of this formula can produce discontinuities due to the complex square root of a Fredholm determinant, particularly when the determinant crosses the negative real axis, leading to severe numerical instabilities. We analyze this phenomenon by characterizing the determinant's crossing behavior for the joint Fourier-Laplace transform of integrated variance and log-price. We then derive an expression for the transform to account for such crossings and develop efficient algorithms to detect and handle them. Applied to Fourier-based pricing in the rough Stein-Stein model, our approach significantly improves accuracy while drastically reducing computational cost relative to existing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.02965v2</guid>
      <category>q-fin.MF</category>
      <category>q-fin.CP</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eduardo Abi Jaber, Maxime Guellil</dc:creator>
    </item>
    <item>
      <title>Towards Causal Market Simulators</title>
      <link>https://arxiv.org/abs/2511.04469</link>
      <description>arXiv:2511.04469v2 Announce Type: replace-cross 
Abstract: Market generators using deep generative models have shown promise for synthetic financial data generation, but existing approaches lack causal reasoning capabilities essential for counterfactual analysis and risk assessment. We propose a Time-series Neural Causal Model VAE (TNCM-VAE) that combines variational autoencoders with structural causal models to generate counterfactual financial time series while preserving both temporal dependencies and causal relationships. Our approach enforces causal constraints through directed acyclic graphs in the decoder architecture and employs the causal Wasserstein distance for training. We validate our method on synthetic autoregressive models inspired by the Ornstein-Uhlenbeck process, demonstrating superior performance in counterfactual probability estimation with L1 distances as low as 0.03-0.10 compared to ground truth. The model enables financial stress testing, scenario analysis, and enhanced backtesting by generating plausible counterfactual market trajectories that respect underlying causal mechanisms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.04469v2</guid>
      <category>cs.LG</category>
      <category>q-fin.CP</category>
      <category>stat.OT</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dennis Thumm, Luis Ontaneda Mijares</dc:creator>
    </item>
  </channel>
</rss>
