<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 30 Aug 2024 04:01:15 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 30 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Unlocking Global Optimality in Bilevel Optimization: A Pilot Study</title>
      <link>https://arxiv.org/abs/2408.16087</link>
      <description>arXiv:2408.16087v1 Announce Type: new 
Abstract: Bilevel optimization has witnessed a resurgence of interest, driven by its critical role in trustworthy and efficient machine learning applications. Recent research has focused on proposing efficient methods with provable convergence guarantees. However, while many prior works have established convergence to stationary points or local minima, obtaining the global optimum of bilevel optimization remains an important yet open problem. The difficulty lies in the fact that unlike many prior non-convex single-level problems, this bilevel problem does not admit a ``benign" landscape, and may indeed have multiple spurious local solutions. Nevertheless, attaining the global optimality is indispensable for ensuring reliability, safety, and cost-effectiveness, particularly in high-stakes engineering applications that rely on bilevel optimization. In this paper, we first explore the challenges of establishing a global convergence theory for bilevel optimization, and present two sufficient conditions for global convergence. We provide algorithm-specific proofs to rigorously substantiate these sufficient conditions along the optimization trajectory, focusing on two specific bilevel learning scenarios: representation learning and data hypercleaning (a.k.a. reweighting). Experiments corroborate the theoretical findings, demonstrating convergence to global minimum in both cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.16087v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 30 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Quan Xiao, Tianyi Chen</dc:creator>
    </item>
    <item>
      <title>A Minibatch-SGD-Based Learning Meta-Policy for Inventory Systems with Myopic Optimal Policy</title>
      <link>https://arxiv.org/abs/2408.16181</link>
      <description>arXiv:2408.16181v1 Announce Type: new 
Abstract: Stochastic gradient descent (SGD) has proven effective in solving many inventory control problems with demand learning. However, it often faces the pitfall of an infeasible target inventory level that is lower than the current inventory level. Several recent works (e.g., Huh and Rusmevichientong (2009), Shi et al.(2016)) are successful to resolve this issue in various inventory systems. However, their techniques are rather sophisticated and difficult to be applied to more complicated scenarios such as multi-product and multi-constraint inventory systems.
  In this paper, we address the infeasible-target-inventory-level issue from a new technical perspective -- we propose a novel minibatch-SGD-based meta-policy. Our meta-policy is flexible enough to be applied to a general inventory systems framework covering a wide range of inventory management problems with myopic clairvoyant optimal policy. By devising the optimal minibatch scheme, our meta-policy achieves a regret bound of $\mathcal{O}(\sqrt{T})$ for the general convex case and $\mathcal{O}(\log T)$ for the strongly convex case. To demonstrate the power and flexibility of our meta-policy, we apply it to three important inventory control problems: multi-product and multi-constraint systems, multi-echelon serial systems, and one-warehouse and multi-store systems by carefully designing application-specific subroutines.We also conduct extensive numerical experiments to demonstrate that our meta-policy enjoys competitive regret performance, high computational efficiency, and low variances among a wide range of applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.16181v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 30 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jiameng Lyu, Jinxing Xie, Shilin Yuan, Yuan Zhou</dc:creator>
    </item>
    <item>
      <title>Single-Loop Deterministic and Stochastic Interior-Point Algorithms for Nonlinearly Constrained Optimization</title>
      <link>https://arxiv.org/abs/2408.16186</link>
      <description>arXiv:2408.16186v1 Announce Type: new 
Abstract: An interior-point algorithm framework is proposed, analyzed, and tested for solving nonlinearly constrained continuous optimization problems. The main setting of interest is when the objective and constraint functions may be nonlinear and/or nonconvex, and when constraint values and derivatives are tractable to compute, but objective function values and derivatives can only be estimated. The algorithm is intended primarily for a setting that is similar for stochastic-gradient methods for unconstrained optimization, namely, the setting when stochastic-gradient estimates are available and employed in place of gradients of the objective, and when no objective function values (nor estimates of them) are employed. This is achieved by the interior-point framework having a single-loop structure rather than the nested-loop structure that is typical of contemporary interior-point methods. For completeness, convergence guarantees for the framework are provided both for deterministic and stochastic settings. Numerical experiments show that the algorithm yields good performance on a large set of test problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.16186v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 30 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Frank E. Curtis, Xin Jiang, Qi Wang</dc:creator>
    </item>
    <item>
      <title>Adversarial Network Optimization under Bandit Feedback: Maximizing Utility in Non-Stationary Multi-Hop Networks</title>
      <link>https://arxiv.org/abs/2408.16215</link>
      <description>arXiv:2408.16215v1 Announce Type: new 
Abstract: Stochastic Network Optimization (SNO) concerns scheduling in stochastic queueing systems. It has been widely studied in network theory. Classical SNO algorithms require network conditions to be stationary with time, which fails to capture the non-stationary components in many real-world scenarios. Many existing algorithms also assume knowledge of network conditions before decision, which rules out applications where unpredictability presents.
  Motivated by these issues, we consider Adversarial Network Optimization (ANO) under bandit feedback. Specifically, we consider the task of *i)* maximizing some unknown and time-varying utility function associated to scheduler's actions, where *ii)* the underlying network is a non-stationary multi-hop one whose conditions change arbitrarily with time, and *iii)* only bandit feedback (effect of actually deployed actions) is revealed after decisions. Our proposed `UMO2` algorithm ensures network stability and also matches the utility maximization performance of any "mildly varying" reference policy up to a polynomially decaying gap. To our knowledge, no previous ANO algorithm handled multi-hop networks or achieved utility guarantees under bandit feedback, whereas ours can do both.
  Technically, our method builds upon a novel integration of online learning into Lyapunov analyses: To handle complex inter-dependencies among queues in multi-hop networks, we propose meticulous techniques to balance online learning and Lyapunov arguments. To tackle the learning obstacles due to potentially unbounded queue sizes, we design a new online linear optimization algorithm that automatically adapts to loss magnitudes. To maximize utility, we propose a bandit convex optimization algorithm with novel queue-dependent learning rate scheduling that suites drastically varying queue lengths. Our new insights in online learning can be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.16215v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.PF</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 30 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yan Dai, Longbo Huang</dc:creator>
    </item>
    <item>
      <title>Parametrization and convergence of a primal-dual block-coordinate approach to linearly-constrained nonsmooth optimization</title>
      <link>https://arxiv.org/abs/2408.16424</link>
      <description>arXiv:2408.16424v1 Announce Type: new 
Abstract: This note is concerned with the problem of minimizing a separable, convex, composite (smooth and nonsmooth) function subject to linear constraints. We study a randomized block-coordinate interpretation of the Chambolle-Pock primal-dual algorithm, based on inexact proximal gradient steps. A specificity of the considered algorithm is its robustness, as it converges even in the absence of strong duality or when the linear program is inconsistent. Using matrix preconditiong, we derive tight sublinear convergence rates with and without duality assumptions and for both the convex and the strongly convex settings. Our developments are extensions and particularizations of original algorithms proposed by Malitsky (2019) and Luke and Malitsky (2018). Numerical experiments are provided for an optimal transport problem of service pricing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.16424v1</guid>
      <category>math.OC</category>
      <category>cs.DC</category>
      <category>cs.MA</category>
      <pubDate>Fri, 30 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Olivier Bilenne</dc:creator>
    </item>
    <item>
      <title>Consensus Planning with Primal, Dual, and Proximal Agents</title>
      <link>https://arxiv.org/abs/2408.16462</link>
      <description>arXiv:2408.16462v1 Announce Type: new 
Abstract: Consensus planning is a method for coordinating decision making across complex systems and organizations, including complex supply chain optimization pipelines. It arises when large interdependent distributed agents (systems) share common resources and must act in order to achieve a joint goal. In this paper, we introduce a generic Consensus Planning Protocol (CPP) to solve such problems. Our protocol allows for different agents to interact with the coordinating algorithm in different ways (e.g., as a primal or dual or proximal agent). In prior consensus planning work, all agents have been assumed to have the same interaction pattern (e.g., all dual agents or all primal agents or all proximal agents), most commonly using the Alternating Direction Method of Multipliers (ADMM) as proximal agents. However, this is often not a valid assumption in practice, where agents consist of large complex systems, and where we might not have the luxury of modifying these large complex systems at will. Our generic CPP allows for any mix of agents by combining ADMM-like updates for the proximal agents, dual ascent updates for the dual agents, and linearized ADMM updates for the primal agents. We prove convergence results for the generic CPP, namely a sublinear O(1/k) convergence rate under mild assumptions, and two-step linear convergence under stronger assumptions. We also discuss enhancements to the basic method and provide illustrative empirical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.16462v1</guid>
      <category>math.OC</category>
      <category>cs.MA</category>
      <pubDate>Fri, 30 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alvaro Maggiar, Lee Dicker, Michael Mahoney</dc:creator>
    </item>
    <item>
      <title>A Two Stepsize SQP Method for Nonlinear Equality Constrained Stochastic Optimization</title>
      <link>https://arxiv.org/abs/2408.16656</link>
      <description>arXiv:2408.16656v1 Announce Type: new 
Abstract: We develop a Sequential Quadratic Optimization (SQP) algorithm for minimizing a stochastic objective function subject to deterministic equality constraints. The method utilizes two different stepsizes, one which exclusively scales the component of the step corrupted by the variance of the stochastic gradient estimates and a second which scales the entire step. We prove that this stepsize splitting scheme has a worst-case complexity result which improves over the best known result for this class of problems. In terms of approximately satisfying the constraint violation, this complexity result matches that of deterministic SQP methods, up to constant factors, while matching the known optimal rate for stochastic SQP methods to approximately minimize the norm of the gradient of the Lagrangian. We also propose and analyze multiple variants of our algorithm. One of these variants is based upon popular adaptive gradient methods for unconstrained stochastic optimization while another incorporates a safeguarded line search along the constraint violation. Preliminary numerical experiments show competitive performance against a state of the art stochastic SQP method. In addition, in these experiments, we observe an improved rate of convergence in terms of the constraint violation, as predicted by the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.16656v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 30 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael J. O'Neill</dc:creator>
    </item>
    <item>
      <title>Optimization Models for the Quadratic Traveling Salesperson Problem</title>
      <link>https://arxiv.org/abs/2408.16680</link>
      <description>arXiv:2408.16680v1 Announce Type: new 
Abstract: The quadratic traveling salesperson problem (QTSP) is a generalization of the traveling salesperson problem, in which all triples of consecutive customers in a tour determine the travel cost. We propose compact optimization models for QTSP in mixed-integer quadratic programming (MIQP), mixed-integer linear programming (MILP), constraint programming (CP), and domain-independent dynamic programming (DIDP). Our experimental results demonstrate that the DIDP model performs better than other approaches in optimality gap and solution quality when the problem size is large enough.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.16680v1</guid>
      <category>math.OC</category>
      <category>math.CO</category>
      <pubDate>Fri, 30 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yuxiao Chen, Nivetha Sathish, Anubhav Singh, Ryo Kuroiwa, J. Christopher Beck</dc:creator>
    </item>
    <item>
      <title>Path planning for autonomous vehicles with minimal collision severity</title>
      <link>https://arxiv.org/abs/2408.16076</link>
      <description>arXiv:2408.16076v1 Announce Type: cross 
Abstract: This paper proposes a path planning algorithm for autonomous vehicles, evaluating collision severity with respect to both static and dynamic obstacles. A collision severity map is generated from ratings, quantifying the severity of collisions. A two-level optimal control problem is designed. At the first level, the objective is to identify paths with the lowest collision severity. Subsequently, at the second level, among the paths with lowest collision severity, the one requiring the minimum steering effort is determined. Finally, numerical simulations were conducted using the optimal control software OCPID-DAE1. The study focuses on scenarios where collisions are unavoidable. Results demonstrate the effectiveness and significance of this approach in finding a path with minimum collision severity for autonomous vehicles. Furthermore, this paper illustrates how the ratings for collision severity influence the behaviour of the automated vehicle.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.16076v1</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <pubDate>Fri, 30 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Qiannan Wang, Matthias Gerdts</dc:creator>
    </item>
    <item>
      <title>Negative Binomial Matrix Completion</title>
      <link>https://arxiv.org/abs/2408.16113</link>
      <description>arXiv:2408.16113v1 Announce Type: cross 
Abstract: Matrix completion focuses on recovering missing or incomplete information in matrices. This problem arises in various applications, including image processing and network analysis. Previous research proposed Poisson matrix completion for count data with noise that follows a Poisson distribution, which assumes that the mean and variance are equal. Since overdispersed count data, whose variance is greater than the mean, is more likely to occur in realistic settings, we assume that the noise follows the negative binomial (NB) distribution, which can be more general than the Poisson distribution. In this paper, we introduce NB matrix completion by proposing a nuclear-norm regularized model that can be solved by proximal gradient descent. In our experiments, we demonstrate that the NB model outperforms Poisson matrix completion in various noise and missing data settings on real data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.16113v1</guid>
      <category>cs.LG</category>
      <category>cs.CV</category>
      <category>eess.IV</category>
      <category>eess.SP</category>
      <category>math.OC</category>
      <pubDate>Fri, 30 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yu Lu, Kevin Bui, Roummel F. Marcia</dc:creator>
    </item>
    <item>
      <title>Alternating Direction Method of Multipliers for Negative Binomial Model with The Weighted Difference of Anisotropic and Isotropic Total Variation</title>
      <link>https://arxiv.org/abs/2408.16117</link>
      <description>arXiv:2408.16117v1 Announce Type: cross 
Abstract: In many applications such as medical imaging, the measurement data represent counts of photons hitting a detector. Such counts in low-photon settings are often modeled using a Poisson distribution. However, this model assumes that the mean and variance of the signal's noise distribution are equal. For overdispersed data where the variance is greater than the mean, the negative binomial distribution is a more appropriate statistical model. In this paper, we propose an optimization approach for recovering images corrupted by overdispersed Poisson noise. In particular, we incorporate a weighted anisotropic-isotropic total variation regularizer, which avoids staircasing artifacts that are introduced by a regular total variation penalty. We use an alternating direction method of multipliers, where each subproblem has a closed-form solution. Numerical experiments demonstrate the effectiveness of our proposed approach, especially in very photon-limited settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.16117v1</guid>
      <category>eess.IV</category>
      <category>cs.CV</category>
      <category>math.OC</category>
      <pubDate>Fri, 30 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yu Lu, Kevin Bui, Roummel F. Marcia</dc:creator>
    </item>
    <item>
      <title>Free Lunch in the Forest: Functionally-Identical Pruning of Boosted Tree Ensembles</title>
      <link>https://arxiv.org/abs/2408.16167</link>
      <description>arXiv:2408.16167v1 Announce Type: cross 
Abstract: Tree ensembles, including boosting methods, are highly effective and widely used for tabular data. However, large ensembles lack interpretability and require longer inference times. We introduce a method to prune a tree ensemble into a reduced version that is "functionally identical" to the original model. In other words, our method guarantees that the prediction function stays unchanged for any possible input. As a consequence, this pruning algorithm is lossless for any aggregated metric. We formalize the problem of functionally identical pruning on ensembles, introduce an exact optimization model, and provide a fast yet highly effective method to prune large ensembles. Our algorithm iteratively prunes considering a finite set of points, which is incrementally augmented using an adversarial model. In multiple computational experiments, we show that our approach is a "free lunch", significantly reducing the ensemble size without altering the model's behavior. Thus, we can preserve state-of-the-art performance at a fraction of the original model's size.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.16167v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 30 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Youssouf Emine, Alexandre Forel, Idriss Malek, Thibaut Vidal</dc:creator>
    </item>
    <item>
      <title>On Convergence of Average-Reward Q-Learning in Weakly Communicating Markov Decision Processes</title>
      <link>https://arxiv.org/abs/2408.16262</link>
      <description>arXiv:2408.16262v1 Announce Type: cross 
Abstract: This paper analyzes reinforcement learning (RL) algorithms for Markov decision processes (MDPs) under the average-reward criterion. We focus on Q-learning algorithms based on relative value iteration (RVI), which are model-free stochastic analogues of the classical RVI method for average-reward MDPs. These algorithms have low per-iteration complexity, making them well-suited for large state space problems. We extend the almost-sure convergence analysis of RVI Q-learning algorithms developed by Abounadi, Bertsekas, and Borkar (2001) from unichain to weakly communicating MDPs. This extension is important both practically and theoretically: weakly communicating MDPs cover a much broader range of applications compared to unichain MDPs, and their optimality equations have a richer solution structure (with multiple degrees of freedom), introducing additional complexity in proving algorithmic convergence. We also characterize the sets to which RVI Q-learning algorithms converge, showing that they are compact, connected, potentially nonconvex, and comprised of solutions to the average-reward optimality equation, with exactly one less degree of freedom than the general solution set of this equation. Furthermore, we extend our analysis to two RVI-based hierarchical average-reward RL algorithms using the options framework, proving their almost-sure convergence and characterizing their sets of convergence under the assumption that the underlying semi-Markov decision process is weakly communicating.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.16262v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 30 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yi Wan, Huizhen Yu, Richard S. Sutton</dc:creator>
    </item>
    <item>
      <title>Near-Optimal Policy Identification in Robust Constrained Markov Decision Processes via Epigraph Form</title>
      <link>https://arxiv.org/abs/2408.16286</link>
      <description>arXiv:2408.16286v1 Announce Type: cross 
Abstract: Designing a safe policy for uncertain environments is crucial in real-world control applications. However, this challenge remains inadequately addressed within the Markov decision process (MDP) framework. This paper presents the first algorithm capable of identifying a near-optimal policy in a robust constrained MDP (RCMDP), where an optimal policy minimizes cumulative cost while satisfying constraints in the worst-case scenario across a set of environments. We first prove that the conventional Lagrangian max-min formulation with policy gradient methods can become trapped in suboptimal solutions by encountering a sum of conflicting gradients from the objective and constraint functions during its inner minimization problem. To address this, we leverage the epigraph form of the RCMDP problem, which resolves the conflict by selecting a single gradient from either the objective or the constraints. Building on the epigraph form, we propose a binary search algorithm with a policy gradient subroutine and prove that it identifies an $\varepsilon$-optimal policy in an RCMDP with $\tilde{\mathcal{O}}(\varepsilon^{-4})$ policy evaluations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.16286v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 30 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Toshinori Kitamura, Tadashi Kozuno, Wataru Kumagai, Kenta Hoshino, Yohei Hosoe, Kazumi Kasaura, Masashi Hamaya, Paavo Parmas, Yutaka Matsuo</dc:creator>
    </item>
    <item>
      <title>A Distance Similarity-based Genetic Optimization Algorithm for Satellite Ground Network Planning Considering Feeding Mode</title>
      <link>https://arxiv.org/abs/2408.16300</link>
      <description>arXiv:2408.16300v1 Announce Type: cross 
Abstract: With the rapid development of the satellite industry, the information transmission network based on communication satellites has gradually become a major and important part of the future satellite ground integration network. However, the low transmission efficiency of the satellite data relay back mission has become a problem that is currently constraining the construction of the system and needs to be solved urgently. Effectively planning the task of satellite ground networking by reasonably scheduling resources is crucial for the efficient transmission of task data. In this paper, we hope to provide a task execution scheme that maximizes the profit of the networking task for satellite ground network planning considering feeding mode (SGNPFM). To solve the SGNPFM problem, a mixed-integer planning model with the objective of maximizing the gain of the link-building task is constructed, which considers various constraints of the satellite in the feed-switching mode. Based on the problem characteristics, we propose a distance similarity-based genetic optimization algorithm (DSGA), which considers the state characteristics between the tasks and introduces a weighted Euclidean distance method to determine the similarity between the tasks. To obtain more high-quality solutions, different similarity evaluation methods are designed to assist the algorithm in intelligently screening individuals. The DSGA also uses an adaptive crossover strategy based on similarity mechanism, which guides the algorithm to achieve efficient population search. In addition, a task scheduling algorithm considering the feed-switching mode is designed for decoding the algorithm to generate a high-quality scheme. The results of simulation experiments show that the DSGA can effectively solve the SGNPFM problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.16300v1</guid>
      <category>cs.NE</category>
      <category>math.OC</category>
      <pubDate>Fri, 30 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yingying Ren, Qiuli Li, Yangyang Guo, Witold Pedrycz, Lining Xing, Anfeng Liu, Yanjie Song</dc:creator>
    </item>
    <item>
      <title>Stochastic optimal control of L\'evy tax processes with bailouts</title>
      <link>https://arxiv.org/abs/2408.16385</link>
      <description>arXiv:2408.16385v1 Announce Type: cross 
Abstract: We consider controlling the paths of a spectrally negative L\'evy process by two means: the subtraction of `taxes' when the process is at an all-time maximum, and the addition of `bailouts' which keep the value of the process above zero. We solve the corresponding stochastic optimal control problem of maximising the expected present value of the difference between taxes received and cost of bailouts given. Our class of taxation controls is larger than has been considered up till now in the literature and makes the problem truly two-dimensional rather than one-dimensional. Along the way, we define and characterise a large class of controlled L\'evy processes to which the optimal solution belongs, which extends a known result for perturbed Brownian motions to the case of a general L\'evy process with no positive jumps.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.16385v1</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <pubDate>Fri, 30 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dalal Al Ghanim, Ronnie Loeffen, Alexander R. Watson</dc:creator>
    </item>
    <item>
      <title>Constructive approaches to concentration inequalities with independent random variables</title>
      <link>https://arxiv.org/abs/2408.16480</link>
      <description>arXiv:2408.16480v1 Announce Type: cross 
Abstract: Concentration inequalities, a major tool in probability theory, quantify how much a random variable deviates from a certain quantity. This paper proposes a systematic convex optimization approach to studying and generating concentration inequalities with independent random variables. Specifically, we extend the generalized problem of moments to independent random variables.
  We first introduce a variational approach that extends classical moment-generating functions, focusing particularly on first-order moment conditions. Second, we develop a polynomial approach, based on a hierarchy of sum-of-square approximations, to extend these techniques to higher-moment conditions. Building on these advancements, we refine Hoeffding's, Bennett's and Bernstein's inequalities, providing improved worst-case guarantees compared to existing results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.16480v1</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <pubDate>Fri, 30 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Celine Moucer, Adrien Taylor, Francis Bach</dc:creator>
    </item>
    <item>
      <title>Statistical and Geometrical properties of regularized Kernel Kullback-Leibler divergence</title>
      <link>https://arxiv.org/abs/2408.16543</link>
      <description>arXiv:2408.16543v1 Announce Type: cross 
Abstract: In this paper, we study the statistical and geometrical properties of the Kullback-Leibler divergence with kernel covariance operators (KKL) introduced by Bach [2022]. Unlike the classical Kullback-Leibler (KL) divergence that involves density ratios, the KKL compares probability distributions through covariance operators (embeddings) in a reproducible kernel Hilbert space (RKHS), and compute the Kullback-Leibler quantum divergence. This novel divergence hence shares parallel but different aspects with both the standard Kullback-Leibler between probability distributions and kernel embeddings metrics such as the maximum mean discrepancy. A limitation faced with the original KKL divergence is its inability to be defined for distributions with disjoint supports. To solve this problem, we propose in this paper a regularised variant that guarantees that the divergence is well defined for all distributions. We derive bounds that quantify the deviation of the regularised KKL to the original one, as well as finite-sample bounds. In addition, we provide a closed-form expression for the regularised KKL, specifically applicable when the distributions consist of finite sets of points, which makes it implementable. Furthermore, we derive a Wasserstein gradient descent scheme of the KKL divergence in the case of discrete distributions, and study empirically its properties to transport a set of points to a target distribution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.16543v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.FA</category>
      <category>math.OC</category>
      <pubDate>Fri, 30 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Cl\'ementine Chazal, Anna Korba, Francis Bach</dc:creator>
    </item>
    <item>
      <title>Sparse Signal Reconstruction for Overdispersed Low-photon Count Biomedical Imaging Using $\ell_p$ Total Variation</title>
      <link>https://arxiv.org/abs/2408.16622</link>
      <description>arXiv:2408.16622v1 Announce Type: cross 
Abstract: The negative binomial model, which generalizes the Poisson distribution model, can be found in applications involving low-photon signal recovery, including medical imaging. Recent studies have explored several regularization terms for the negative binomial model, such as the $\ell_p$ quasi-norm with $0 &lt; p &lt; 1$, $\ell_1$ norm, and the total variation (TV) quasi-seminorm for promoting sparsity in signal recovery. These penalty terms have been shown to improve image reconstruction outcomes. In this paper, we investigate the $\ell_p$ quasi-seminorm, both isotropic and anisotropic $\ell_p$ TV quasi-seminorms, within the framework of the negative binomial statistical model. This problem can be formulated as an optimization problem, which we solve using a gradient-based approach. We present comparisons between the negative binomial and Poisson statistical models using the $\ell_p$ TV quasi-seminorm as well as common penalty terms. Our experimental results highlight the efficacy of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.16622v1</guid>
      <category>eess.IV</category>
      <category>cs.CV</category>
      <category>eess.SP</category>
      <category>math.OC</category>
      <pubDate>Fri, 30 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/ISBI56570.2024.10635788</arxiv:DOI>
      <dc:creator>Yu Lu, Roummel F. Marcia</dc:creator>
    </item>
    <item>
      <title>Modelling sand ripples in mine countermeasure simulations by means of stochastic optimal control</title>
      <link>https://arxiv.org/abs/2408.16624</link>
      <description>arXiv:2408.16624v1 Announce Type: cross 
Abstract: Modelling and simulating mine countermeasures (MCM) search missions performed by autonomous vehicles equipped with a sensor capable of detecting mines at sea is a challenging endeavour. In this work, we present a novel way to model and account for sand ripples present on the bottom of the ocean while calculating trajectories for the autonomous vehicles by means of a stochastic optimal control framework. It is known from the scientific literature that these ripples impact the sea mine detection capabilities of the autonomous vehicles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.16624v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Fri, 30 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Philippe Blondeel, Filip Van Utterbeeck, Ben Lauwens</dc:creator>
    </item>
    <item>
      <title>A Score-based Generative Solver for PDE-constrained Inverse Problems with Complex Priors</title>
      <link>https://arxiv.org/abs/2408.16626</link>
      <description>arXiv:2408.16626v1 Announce Type: cross 
Abstract: In the field of inverse estimation for systems modeled by partial differential equations (PDEs), challenges arise when estimating high- (or even infinite-) dimensional parameters. Typically, the ill-posed nature of such problems necessitates leveraging prior information to achieve well-posedness. In most existing inverse solvers, the prior distribution is assumed to be of either Gaussian or Laplace form which, in many practical scenarios, is an oversimplification. In case the prior is complex and the likelihood model is computationally expensive (e.g., due to expensive forward models), drawing the sample from such posteriors can be computationally intractable, especially when the unknown parameter is high-dimensional. In this work, to sample efficiently, we propose a score-based diffusion model, which combines a score-based generative sampling tool with a noising and denoising process driven by stochastic differential equations. This tool is used for iterative sample generation in accordance with the posterior distribution, while simultaneously learning and leveraging the underlying information and constraints inherent in the given complex prior. A time-varying time schedule is proposed to adapt the method for posterior sampling. To expedite the simulation of non-parameterized PDEs and enhance the generalization capacity, we introduce a physics-informed convolutional neural network (CNN) surrogate for the forward model. Finally, numerical experiments, including a hyper-elastic problem and a multi-scale mechanics problem, demonstrate the efficacy of the proposed approach. In particular, the score-based diffusion model, coupled with the physics-informed CNN surrogate, effectively learns geometrical features from provided prior samples, yielding better inverse estimation results compared to the state-of-the-art techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.16626v1</guid>
      <category>cs.CE</category>
      <category>math.OC</category>
      <pubDate>Fri, 30 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yankun Hong, Harshit Bansal, Karen Veroy</dc:creator>
    </item>
    <item>
      <title>Rank-one convexity implies quasiconvexity for two-component maps</title>
      <link>https://arxiv.org/abs/1905.06571</link>
      <description>arXiv:1905.06571v3 Announce Type: replace 
Abstract: We prove that, for two-component maps, rank-one convexity is equivalent to quasiconvexity. The essential tool for the proof is a fixed-point argument for a suitable set-valued map going from one component to the other and preserving decomposition directions in the $(H_n)$-condition formalism; the existence of a fixed point ensures that, in addition to keeping decomposition directions, joint volume fractions are preserved as well. When maps have more than two components, then fixed points exist for every combination of two components, but they do not match in general.</description>
      <guid isPermaLink="false">oai:arXiv.org:1905.06571v3</guid>
      <category>math.OC</category>
      <pubDate>Fri, 30 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pablo Pedregal</dc:creator>
    </item>
    <item>
      <title>Convergence and sample complexity of natural policy gradient primal-dual methods for constrained MDPs</title>
      <link>https://arxiv.org/abs/2206.02346</link>
      <description>arXiv:2206.02346v3 Announce Type: replace 
Abstract: We study sequential decision making problems aimed at maximizing the expected total reward while satisfying a constraint on the expected total utility. We employ the natural policy gradient method to solve the discounted infinite-horizon optimal control problem for Constrained Markov Decision Processes (constrained MDPs). Specifically, we propose a new Natural Policy Gradient Primal-Dual (NPG-PD) method that updates the primal variable via natural policy gradient ascent and the dual variable via projected sub-gradient descent. Although the underlying maximization involves a nonconcave objective function and a nonconvex constraint set, under the softmax policy parametrization we prove that our method achieves global convergence with sublinear rates regarding both the optimality gap and the constraint violation. Such convergence is independent of the size of the state-action space, i.e., it is~dimension-free. Furthermore, for log-linear and general smooth policy parametrizations, we establish sublinear convergence rates up to a function approximation error caused by restricted policy parametrization. We also provide convergence and finite-sample complexity guarantees for two sample-based NPG-PD algorithms. Finally, we use computational experiments to showcase the merits and the effectiveness of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2206.02346v3</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 30 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dongsheng Ding, Kaiqing Zhang, Jiali Duan, Tamer Ba\c{s}ar, Mihailo R. Jovanovi\'c</dc:creator>
    </item>
    <item>
      <title>Unified Convergence Theory of Stochastic and Variance-Reduced Cubic Newton Methods</title>
      <link>https://arxiv.org/abs/2302.11962</link>
      <description>arXiv:2302.11962v3 Announce Type: replace 
Abstract: We study stochastic Cubic Newton methods for solving general possibly non-convex minimization problems. We propose a new framework, which we call the helper framework, that provides a unified view of the stochastic and variance-reduced second-order algorithms equipped with global complexity guarantees. It can also be applied to learning with auxiliary information. Our helper framework offers the algorithm designer high flexibility for constructing and analyzing the stochastic Cubic Newton methods, allowing arbitrary size batches, and the use of noisy and possibly biased estimates of the gradients and Hessians, incorporating both the variance reduction and the lazy Hessian updates. We recover the best-known complexities for the stochastic and variance-reduced Cubic Newton, under weak assumptions on the noise. A direct consequence of our theory is the new lazy stochastic second-order method, which significantly improves the arithmetic complexity for large dimension problems. We also establish complexity bounds for the classes of gradient-dominated objectives, that include convex and strongly convex problems. For Auxiliary Learning, we show that using a helper (auxiliary function) can outperform training alone if a given similarity measure is small.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.11962v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 30 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>El Mahdi Chayti, Nikita Doikov, Martin Jaggi</dc:creator>
    </item>
    <item>
      <title>Solving influence diagrams via efficient mixed-integer programming formulations and heuristics</title>
      <link>https://arxiv.org/abs/2307.13299</link>
      <description>arXiv:2307.13299v4 Announce Type: replace 
Abstract: In this paper, we propose novel mixed-integer linear programming (MIP) formulations to model decision problems posed as influence diagrams. We also present a novel heuristic that can be employed to warm start the MIP solver, as well as provide heuristic solutions to more computationally challenging problems. We provide computational results showcasing the superior performance of these improved formulations as well as the performance of the proposed heuristic. Lastly, we describe a novel case study showcasing decision programming as an alternative framework for modelling multi-stage stochastic dynamic programming problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.13299v4</guid>
      <category>math.OC</category>
      <pubDate>Fri, 30 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Helmi Hankimaa, Olli Herrala, Fabricio Oliveira, Jaan Tollander de Balsch</dc:creator>
    </item>
    <item>
      <title>A Machine Learning Approach to Boost the Vehicle-2-Grid Scheduling</title>
      <link>https://arxiv.org/abs/2407.20802</link>
      <description>arXiv:2407.20802v2 Announce Type: replace 
Abstract: Electric Vehicles (EVs) are emerging as battery energy storage systems (BESSs) of increasing importance for different power grid services. However, the unique characteristics of EVs makes them more difficult to operate than dedicated BESSs. In this work, we apply a data-driven learning approach to leverage EVs as a BESS to provide capacity-related services to the grid. The approach uses machine learning to predict how to charge and discharge EVs while satisfying their operational constraints. As a paradigm application, we use flexible energy commercialization in the wholesale markets, but the approach can be applied to a broader range of capacity-related grid services. We evaluate the proposed approach numerically and show that when the number of EVs is large, we can obtain comparable objective values to CPLEX and approximate dynamic programming, but with shorter run times. These reduced run times are important because they allow us to (re)optimize frequently to adapt to the time-varying system conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.20802v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 30 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gabriele Agliardi, Giorgio Cortiana, Anton Dekusar, Kumar Ghosh, Naeimeh Mohseni, Corey O'Meara, V\'ictor Valls, Kavitha Yogaraj, Sergiy Zhuk</dc:creator>
    </item>
    <item>
      <title>A Deterministic Algorithm of Quasi-Polynomial Complexity for Clipped Cubes Volume Approximation</title>
      <link>https://arxiv.org/abs/2407.21365</link>
      <description>arXiv:2407.21365v3 Announce Type: replace 
Abstract: We give a deterministic method of quasi-polynomial complexity to approximate the volume of the intersection of the unit hypercube with two specific sets. The method can actually be applied (without losing the quasi-polynomial complexity) to compute the volume of the hypercube intersected with a fixed number of sets, described by equations of the form $\sum_{q=1}^n a_q(x_q) \leq b$, where $a_q : \mathbb{R} \to \mathbb{R}$ are polynomial functions and $b \in \mathbb{R}$. Note that the resulting sets are not necessarily convex. This type of equations describe, among others, half-spaces, balls and ellipsoids. We give detailed convergence and complexity analysis for the case in which the unit hypercube is clipped by balls of arbitrary radius but with centers whom distance to the unit hypercube is greater than $1$ (one).</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.21365v3</guid>
      <category>math.OC</category>
      <pubDate>Fri, 30 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marius Costandin</dc:creator>
    </item>
    <item>
      <title>Heat Death of Generative Models in Closed-Loop Learning</title>
      <link>https://arxiv.org/abs/2404.02325</link>
      <description>arXiv:2404.02325v2 Announce Type: replace-cross 
Abstract: Improvement and adoption of generative machine learning models is rapidly accelerating, as exemplified by the popularity of LLMs (Large Language Models) for text, and diffusion models for image generation. As generative models become widespread, data they generate is incorporated into shared content through the public web. This opens the question of what happens when data generated by a model is fed back to the model in subsequent training campaigns. This is a question about the stability of the training process, whether the distribution of publicly accessible content, which we refer to as "knowledge", remains stable or collapses.
  Small scale empirical experiments reported in the literature show that this closed-loop training process is prone to degenerating. Models may start producing gibberish data, or sample from only a small subset of the desired data distribution (a phenomenon referred to as mode collapse). So far there has been only limited theoretical understanding of this process, in part due to the complexity of the deep networks underlying these generative models.
  The aim of this paper is to provide insights into this process (that we refer to as "generative closed-loop learning") by studying the learning dynamics of generative models that are fed back their own produced content in addition to their original training dataset. The sampling of many of these models can be controlled via a "temperature" parameter. Using dynamical systems tools, we show that, unless a sufficient amount of external data is introduced at each iteration, any non-trivial temperature leads the model to asymptotically degenerate. In fact, either the generative distribution collapses to a small set of outputs or becomes uniform over a large set of outputs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02325v2</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 30 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matteo Marchi, Stefano Soatto, Pratik Chaudhari, Paulo Tabuada</dc:creator>
    </item>
    <item>
      <title>Quantifying the degree of risk aversion of spectral risk measures</title>
      <link>https://arxiv.org/abs/2408.15675</link>
      <description>arXiv:2408.15675v2 Announce Type: replace-cross 
Abstract: I propose a functional on the space of spectral risk measures that quantifies their ``degree of risk aversion''. This quantification formalizes the idea that some risk measures are ``more risk-averse'' than others. I construct the functional using two axioms: a normalization on the space of CVaRs and a linearity axiom. I present two formulas for the functional and discuss several properties and interpretations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.15675v2</guid>
      <category>q-fin.RM</category>
      <category>math.OC</category>
      <pubDate>Fri, 30 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>E. Ruben van Beesten</dc:creator>
    </item>
  </channel>
</rss>
