<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CY updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CY</link>
    <description>cs.CY updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CY" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 27 Aug 2025 04:03:26 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 27 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Praxis of Influence: Framing the Observation and Measurement of Information Power</title>
      <link>https://arxiv.org/abs/2508.18482</link>
      <description>arXiv:2508.18482v1 Announce Type: new 
Abstract: Information power is the capacity to convert data flows into durable shifts in attention, belief, and behavior. We argue that this power has migrated from broadcast persuasion to platform-ized, data-driven operations that fuse computational delivery with cognitive effects. In this context, we define and bound information power within international relations and the information environment while demonstrating why observing and measuring it demands an integrated lens that combines politics (goals and governance), computing (data movement and algorithmic delivery), and psychology (attention, affect, memory, and belief). The article contributes three elements: (1) a triadic analytical framework that specifies the minimum variables and instrumentation needed for study; (2) two crosswalks that map common objectives (persuade, disrupt, shape) and target classes (leaders, elites, publics) to political, computational, and psychological tactics, yielding practical coding heuristics and testable hypotheses; and (3) a McCumber-style cube for information influence that integrates targets, operations, as well as machines (automation and AI) into a single space. The space provides for comparative analysis, data fusion, and effect measurement. Using recent cases across state and commercial platforms, we illustrate how virality, stickiness, and denial of logic exploit fast cognition, why conventional reach metrics understate impact, and where instrumentation should focus. We conclude with a mixed-methods research program coupling computational sensing including large-language-model text mining with experiments and polling. The intention is to move from detecting activity to estimating belief change and decision effects.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.18482v1</guid>
      <category>cs.CY</category>
      <pubDate>Wed, 27 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Chris Bronk, Jason Pittman, Carolyn Semmler</dc:creator>
    </item>
    <item>
      <title>The Accessibility Paradox: How Blind and Low Vision Employees Experience and Negotiate Accessibility in the Technology Industry</title>
      <link>https://arxiv.org/abs/2508.18492</link>
      <description>arXiv:2508.18492v1 Announce Type: new 
Abstract: Many technology companies aim to improve access and inclusion not only by making their products accessible but also by bringing people with disabilities into the tech workforce. We know less about how accessibility is experienced and negotiated by disabled workers within these organizations. Through interviews with 20 BLV workers across various tech companies, we uncover a persistent misalignment between organizational attempts at accessibility and the current realities of these employees. We introduce the concept of the accessibility paradox, which we define as the inherent tension between the productivity- and profit-driven nature of tech companies and their desire to hire and retain disabled workers. Focusing on the experiences of BLV workers, we show how the accessibility paradox manifests in their everyday workplace interactions, including digital infrastructure, accommodations processes and policies, ability assumptions, and competing priorities. We offer recommendations for future research and practice to understand and improve workplace accessibility and inclusion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.18492v1</guid>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <pubDate>Wed, 27 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3757666</arxiv:DOI>
      <dc:creator>Aparajita Marathe, Anne Marie Piper</dc:creator>
    </item>
    <item>
      <title>Supporting Intervention Design for Suicide Prevention with Language Model Assistants</title>
      <link>https://arxiv.org/abs/2508.18541</link>
      <description>arXiv:2508.18541v1 Announce Type: new 
Abstract: Warning: This paper discusses topics of suicide and suicidal ideation, which may be distressing to some readers.
  The National Violent Death Reporting System (NVDRS) documents information about suicides in the United States, including free text narratives (e.g., circumstances surrounding a suicide). In a demanding public health data pipeline, annotators manually extract structured information from death investigation records following extensive guidelines developed painstakingly by experts. In this work, we facilitate data-driven insights from the NVDRS data to support the development of novel suicide interventions by investigating the value of language models (LMs) as efficient assistants to these (a) data annotators and (b) experts. We find that LM predictions match existing data annotations about 85% of the time across 50 NVDRS variables. In the cases where the LM disagrees with existing annotations, expert review reveals that LM assistants can surface annotation discrepancies 38% of the time. Finally, we introduce a human-in-the-loop algorithm to assist experts in efficiently building and refining guidelines for annotating new variables by allowing them to focus only on providing feedback for incorrect LM predictions. We apply our algorithm to a real-world case study for a new variable that characterizes victim interactions with lawyers and demonstrate that it achieves comparable annotation quality with a laborious manual approach. Our findings provide evidence that LMs can serve as effective assistants to public health researchers who handle sensitive data in high-stakes scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.18541v1</guid>
      <category>cs.CY</category>
      <pubDate>Wed, 27 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jaspreet Ranjit, Hyundong J. Cho, Claire J. Smerdon, Yoonsoo Nam, Myles Phung, Jonathan May, John R. Blosnich, Swabha Swayamdipta</dc:creator>
    </item>
    <item>
      <title>The Quasi-Creature and the Uncanny Valley of Agency: A Synthesis of Theory and Evidence on User Interaction with Inconsistent Generative AI</title>
      <link>https://arxiv.org/abs/2508.18563</link>
      <description>arXiv:2508.18563v1 Announce Type: new 
Abstract: The user experience with large-scale generative AI is paradoxical: superhuman fluency meets absurd failures in common sense and consistency. This paper argues that the resulting potent frustration is an ontological problem, stemming from the "Quasi-Creature"-an entity simulating intelligence without embodiment or genuine understanding. Interaction with this entity precipitates the "Uncanny Valley of Agency," a framework where user comfort drops when highly agentic AI proves erratically unreliable. Its failures are perceived as cognitive breaches, causing profound cognitive dissonance. Synthesizing HCI, cognitive science, and philosophy of technology, this paper defines the Quasi-Creature and details the Uncanny Valley of Agency. An illustrative mixed-methods study ("Move 78," N=37) of a collaborative creative task reveals a powerful negative correlation between perceived AI efficiency and user frustration, central to the negative experience. This framework robustly explains user frustration with generative AI and has significant implications for the design, ethics, and societal integration of these powerful, alien technologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.18563v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <pubDate>Wed, 27 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mauricio Manhaes, Christine Miller, Nicholas Schroeder</dc:creator>
    </item>
    <item>
      <title>The Hands-Up Problem and How to Deal With It: Secondary School Teachers' Experiences of Debugging in the Classroom</title>
      <link>https://arxiv.org/abs/2508.18861</link>
      <description>arXiv:2508.18861v1 Announce Type: new 
Abstract: Debugging is a vital but challenging skill for beginner programmers to learn. It is also a difficult skill to teach. For secondary school teachers, who may lack time or relevant knowledge, honing students' understanding of debugging can be a daunting task. Despite this, little research has explored their perspectives of debugging. To this end, we investigated secondary teachers' experiences of debugging in the classroom, with a focus on text-based programming. Through thematic analysis of nine semi-structured interviews, we identified a common reliance on the teacher for debugging support, often embodied by many raised hands. We call this phenomenon the `hands-up problem'. While more experienced and confident teachers discussed strategies they use for dealing with this, less confident teachers discussed the generally negative consequences of this problem. We recommend further research into debugging-specific pedagogical content knowledge and professional development to help less confident teachers develop counters to the hands-up problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.18861v1</guid>
      <category>cs.CY</category>
      <pubDate>Wed, 27 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Laurie Gale, Sue Sentance</dc:creator>
    </item>
    <item>
      <title>Of the People, By the Algorithm: How AI Transforms Democratic Representation</title>
      <link>https://arxiv.org/abs/2508.19036</link>
      <description>arXiv:2508.19036v1 Announce Type: new 
Abstract: This review examines how AI technologies are transforming democratic representation, focusing on citizen participation and algorithmic decision-making. The analysis reveals that AI technologies are reshaping democratic processes in fundamental ways: enabling mass-scale deliberation, changing how citizens access and engage with political information, and transforming how representatives make and implement decisions. While AI offers unprecedented opportunities for enhancing democratic participation and governance efficiency, it also presents significant challenges to democratic legitimacy and accountability. Social media platforms' AI-driven algorithms currently mediate much political discourse, creating concerns about information manipulation and privacy. Large Language Models introduce both epistemic challenges and potential tools for improving democratic dialogue. The emergence of Mass Online Deliberation platforms suggests possibilities for scaling up meaningful citizen participation, while Algorithmic Decision-Making systems promise more efficient policy implementation but face limitations in handling complex political trade-offs. As these systems become prevalent, representatives may assume the role of architects of automated decision frameworks, responsible for guiding the translation of politically contested concepts into technical parameters and metrics. Advanced deliberation platforms offering real-time insights into citizen preferences will challenge traditional representative independence and discretion to interpret public will. The institutional integration of these participation mechanisms requires frameworks that balance the benefits with democratic stability through hybrid systems weighting different forms of democratic expression.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.19036v1</guid>
      <category>cs.CY</category>
      <pubDate>Wed, 27 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yuval Rymon</dc:creator>
    </item>
    <item>
      <title>The Adaptive Communication Framework (ACF) for Extraterrestrial Intelligence Discovery</title>
      <link>https://arxiv.org/abs/2508.18287</link>
      <description>arXiv:2508.18287v1 Announce Type: cross 
Abstract: The Vera C. Rubin Observatory's Legacy Survey of Space and Time will increase interstellar object detection rates to one every few months, substantially elevating the probability of identifying objects with characteristics suggesting artificial origin. Despite this imminent capability, no evidence-based crisis communication framework exists for managing potential technosignature discoveries. We present the Adaptive Communication Framework (ACF), a theoretically grounded protocol that integrates crisis communication theories with the SPECtrum of Rhetoric Intelligences model to address diverse cognitive, social and emotional processing styles. Through analysis of communication failures during COVID-19, Fukushima, and asteroid 99942 Apophis (2004 MN4), we identify critical gaps in managing scientific uncertainty under public scrutiny. The ACF provides graduated protocols calibrated to the Loeb Scale for Interstellar Object Significance, offering specific messaging strategies across four rhetoric intelligence channels (Systematic, Practical, Emotional, Creative) for each evidential level group. Recognizing that Artificial Intelligence (AI) systems will mediate public understanding, the framework incorporates safeguards against synthetic media manipulation and algorithmic misinformation through pre-positioned content seeding and deepfake detection protocols. Our theoretical framework reveals that successful communication of paradigm-shifting discoveries requires simultaneous activation of multiple cognitive channels, with messages adapted to cultural contexts and uncertainty levels. This framework provides essential theoretical groundwork for ensuring humanity's potentially most transformative discovery unfolds through understanding rather than chaos.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.18287v1</guid>
      <category>physics.soc-ph</category>
      <category>astro-ph.IM</category>
      <category>cs.CY</category>
      <pubDate>Wed, 27 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Omer Eldadi, Gershon Tenenbaum, Abraham Loeb</dc:creator>
    </item>
    <item>
      <title>A Fast and Minimal System to Identify Depression Using Smartphones: Explainable Machine Learning-Based Approach</title>
      <link>https://arxiv.org/abs/2508.18301</link>
      <description>arXiv:2508.18301v1 Announce Type: cross 
Abstract: Background: Existing robust, pervasive device-based systems developed in recent years to detect depression require data collected over a long period and may not be effective in cases where early detection is crucial.
  Objective: Our main objective was to develop a minimalistic system to identify depression using data retrieved in the fastest possible time.
  Methods: We developed a fast tool that retrieves the past 7 days' app usage data in 1 second (mean 0.31, SD 1.10 seconds). A total of 100 students from Bangladesh participated in our study, and our tool collected their app usage data. To identify depressed and nondepressed students, we developed a diverse set of ML models. We selected important features using the stable approach, along with 3 main types of feature selection (FS) approaches.
  Results: Leveraging only the app usage data retrieved in 1 second, our light gradient boosting machine model used the important features selected by the stable FS approach and correctly identified 82.4% (n=42) of depressed students (precision=75%, F1-score=78.5%). Moreover, after comprehensive exploration, we presented a parsimonious stacking model where around 5 features selected by the all-relevant FS approach Boruta were used in each iteration of validation and showed a maximum precision of 77.4% (balanced accuracy=77.9%). A SHAP analysis of our best models presented behavioral markers that were related to depression.
  Conclusions: Due to our system's fast and minimalistic nature, it may make a worthwhile contribution to identifying depression in underdeveloped and developing regions. In addition, our detailed discussion about the implication of our findings can facilitate the development of less resource-intensive systems to better understand students who are depressed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.18301v1</guid>
      <category>cs.LG</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <pubDate>Wed, 27 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.2196/28848</arxiv:DOI>
      <dc:creator>Md Sabbir Ahmed, Nova Ahmed</dc:creator>
    </item>
    <item>
      <title>Evaluating Federated Learning for At-Risk Student Prediction: A Comparative Analysis of Model Complexity and Data Balancing</title>
      <link>https://arxiv.org/abs/2508.18316</link>
      <description>arXiv:2508.18316v1 Announce Type: cross 
Abstract: High dropout and failure rates in distance education pose a significant challenge for academic institutions, making the proactive identification of at-risk students crucial for providing timely support. This study develops and evaluates a machine learning model based on early academic performance and digital engagement patterns from the large-scale OULAD dataset to predict student risk at a UK university. To address the practical challenges of data privacy and institutional silos that often hinder such initiatives, we implement the model using a Federated Learning (FL) framework. We compare model complexity (Logistic Regression vs. a Deep Neural Network) and data balancing. The final federated model demonstrates strong predictive capability, achieving an ROC AUC score of approximately 85% in identifying at-risk students. Our findings show that this federated approach provides a practical and scalable solution for institutions to build effective early-warning systems, enabling proactive student support while inherently respecting data privacy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.18316v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <pubDate>Wed, 27 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rodrigo Tertulino</dc:creator>
    </item>
    <item>
      <title>Not All Visitors are Bilingual: A Measurement Study of the Multilingual Web from an Accessibility Perspective</title>
      <link>https://arxiv.org/abs/2508.18328</link>
      <description>arXiv:2508.18328v1 Announce Type: cross 
Abstract: English is the predominant language on the web, powering nearly half of the world's top ten million websites. Support for multilingual content is nevertheless growing, with many websites increasingly combining English with regional or native languages in both visible content and hidden metadata. This multilingualism introduces significant barriers for users with visual impairments, as assistive technologies like screen readers frequently lack robust support for non-Latin scripts and misrender or mispronounce non-English text, compounding accessibility challenges across diverse linguistic contexts. Yet, large-scale studies of this issue have been limited by the lack of comprehensive datasets on multilingual web content. To address this gap, we introduce LangCrUX, the first large-scale dataset of 120,000 popular websites across 12 languages that primarily use non-Latin scripts. Leveraging this dataset, we conduct a systematic analysis of multilingual web accessibility and uncover widespread neglect of accessibility hints. We find that these hints often fail to reflect the language diversity of visible content, reducing the effectiveness of screen readers and limiting web accessibility. We finally propose Kizuki, a language-aware automated accessibility testing extension to account for the limited utility of language-inconsistent accessibility hints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.18328v1</guid>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <category>cs.NI</category>
      <pubDate>Wed, 27 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Masudul Hasan Masud Bhuiyan, Matteo Varvello, Yasir Zaki, Cristian-Alexandru Staicu</dc:creator>
    </item>
    <item>
      <title>Development of the Measure of Assessment Self-Efficacy (MASE) for Quizzes and Exams</title>
      <link>https://arxiv.org/abs/2508.18631</link>
      <description>arXiv:2508.18631v1 Announce Type: cross 
Abstract: Self-efficacy is a significant construct in education due to its predictive relationship with achievement. Existing measures of assessment-related self-efficacy concentrate on students' beliefs about content-specific tasks but omit beliefs around assessment-taking. This research aimed to develop and test the Measure of Assessment Self-Efficacy (MASE), designed to assess two types of efficacy beliefs related to assessment (i.e., 'comprehension and execution' and 'emotional regulation') in two scenarios (i.e., a low-stakes online quiz and a high-stakes final exam). Results from confirmatory factor analysis in Study 1 (N = 301) supported the hypothesised two-factor measurement models for both assessment scenarios. In Study 2, results from MGCFA (N = 277) confirmed these models were invariant over time and provided evidence for the scales' validity. Study 3 demonstrated the exam-related MASE was invariant across cohorts of students (Ns = 277; 329). Potential uses of the developed scales in educational research are discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.18631v1</guid>
      <category>math.HO</category>
      <category>cs.CY</category>
      <pubDate>Wed, 27 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1080/0969594X.2022.2162481</arxiv:DOI>
      <dc:creator>Kaitlin Riegel, Tanya Evans, Jason M. Stephens</dc:creator>
    </item>
    <item>
      <title>How digital will the future be? Analysis of prospective scenarios</title>
      <link>https://arxiv.org/abs/2312.15948</link>
      <description>arXiv:2312.15948v3 Announce Type: replace 
Abstract: With the climate change context, many prospective studies, generally encompassing all areas of society, imagine possible futures to expand the range of options. The role of digital technologies within these possible futures is rarely specifically targeted. Which digital technologies and methodologies do these studies envision in a world that has mitigated and adapted to climate change? In this paper, we propose a typology for scenarios to survey digital technologies and their applications in 14 prospective studies and their corresponding 35 future scenarios. Our finding is that all the scenarios consider digital technology to be present in the future. We observe that only a few of them question our relationship with digital technology and all aspects related to its materiality, and none of the general studies envision breakthroughs concerning technologies used today. Our result demonstrates the lack of a systemic view of information and communication technologies. We therefore argue for new prospective studies to envision the future of ICT.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.15948v3</guid>
      <category>cs.CY</category>
      <pubDate>Wed, 27 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Workshop on Computing within Limits, 2024</arxiv:journal_reference>
      <dc:creator>Aur\'elie Bugeau (IUF, LaBRI, UB), Anne-Laure Ligozat (ENSIIE, LISN, STL)</dc:creator>
    </item>
    <item>
      <title>From Principles to Rules: A Regulatory Approach for Frontier AI</title>
      <link>https://arxiv.org/abs/2407.07300</link>
      <description>arXiv:2407.07300v2 Announce Type: replace 
Abstract: Several jurisdictions are starting to regulate frontier artificial intelligence (AI) systems, i.e. general-purpose AI systems that match or exceed the capabilities present in the most advanced systems. To reduce risks from these systems, regulators may require frontier AI developers to adopt safety measures. The requirements could be formulated as high-level principles (e.g. 'AI systems should be safe and secure') or specific rules (e.g. 'AI systems must be evaluated for dangerous model capabilities following the protocol set forth in...'). These regulatory approaches, known as 'principle-based' and 'rule-based' regulation, have complementary strengths and weaknesses. While specific rules provide more certainty and are easier to enforce, they can quickly become outdated and lead to box-ticking. Conversely, while high-level principles provide less certainty and are more costly to enforce, they are more adaptable and more appropriate in situations where the regulator is unsure exactly what behavior would best advance a given regulatory objective. However, rule-based and principle-based regulation are not binary options. Policymakers must choose a point on the spectrum between them, recognizing that the right level of specificity may vary between requirements and change over time. We recommend that policymakers should initially (1) mandate adherence to high-level principles for safe frontier AI development and deployment, (2) ensure that regulators closely oversee how developers comply with these principles, and (3) urgently build up regulatory capacity. Over time, the approach should likely become more rule-based. Our recommendations are based on a number of assumptions, including (A) risks from frontier AI systems are poorly understood and rapidly evolving, (B) many safety practices are still nascent, and (C) frontier AI developers are best placed to innovate on safety practices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.07300v2</guid>
      <category>cs.CY</category>
      <pubDate>Wed, 27 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1093/oxfordhb/9780198940272.013.0014</arxiv:DOI>
      <dc:creator>Jonas Schuett, Markus Anderljung, Alexis Carlier, Leonie Koessler, Ben Garfinkel</dc:creator>
    </item>
    <item>
      <title>Perception Gaps in Risk, Benefit, and Value Between Experts and Public Challenge Socially Accepted AI</title>
      <link>https://arxiv.org/abs/2412.01459</link>
      <description>arXiv:2412.01459v2 Announce Type: replace 
Abstract: Artificial Intelligence (AI) is reshaping many societal domains, raising critical questions about its risks, benefits, and the potential misalignment between public and academic perspectives. This study examines how the general public (N=1110) -- individuals who interact with or are impacted by AI technologies -- and academic AI experts (N=119) -- those elites shaping AI development -- perceive AI's capabilities and impact across 71 scenarios. These scenarios span domains such as sustainability, healthcare, job performance, societal inequality, art, and warfare. Participants evaluated these scenarios across four dimensions using the psychometric model: likelihood, perceived risk and benefit, and overall value (or sentiment). The results suggest significant differences: experts consistently anticipate higher probabilities, perceive lower risks, report greater benefits, and express more positive sentiment toward AI compared to the non-experts. Moreover, both groups apply different weighting schemes: experts discount risk more heavily relative to benefit than non-experts. Visual mappings of these evaluations uncover areas convergent evaluations (e.g., AI performing medical diagnoses or criminal use) as well as tension points (e.g., decision of legal cases, political decision making), highlighting areas where communication and policy interventions may be needed. These findings underscore a critical translational challenge: if AI research and deployment are to align with societal priorities, the perception gap between developers and the public must be better understood and addressed. Our results provide an empirical foundation for value-sensitive AI governance and trust-building strategies across stakeholder groups.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01459v2</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <pubDate>Wed, 27 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Philipp Brauner, Felix Glawe, Gian Luca Liehner, Luisa Vervier, Martina Ziefle</dc:creator>
    </item>
    <item>
      <title>Cultural Dimensions of AI Perception: Charting Expectations, Risks, Benefits, Tradeoffs, and Value in Germany and China</title>
      <link>https://arxiv.org/abs/2412.13841</link>
      <description>arXiv:2412.13841v2 Announce Type: replace 
Abstract: As artificial intelligence (AI) continues to advance, understanding public perceptions -- including biases, risks, and benefits -- is essential for guiding research priorities and AI alignment, shaping public discourse, and informing policy. This exploratory study investigates cultural differences in mental models of AI using 71 imaginaries of AI's potential futures. Drawing on cross-cultural convenience samples from Germany (N=52) and China (N=60), we identify significant differences in expectations, evaluations, and risk-benefit tradeoffs. Participants from Germany generally provided more cautious assessments, whereas participants from China expressed greater optimism regarding AI's societal benefits. Chinese participants exhibited relatively balanced risk-benefit tradeoffs ($\beta=-0.463$ for risk and $\beta=+0.484$ for benefit, $r^2=.630$). In contrast, German participants placed greater emphasis on AI's benefits and comparatively less on risks ($\beta=-0.337$ for risk and $\beta=+0.715$ for benefit, $r^2=.839$). Visual cognitive maps illustrate these contrasts, offering new perspectives on how cultural contexts shape AI acceptance. Our findings highlight key factors influencing public perception and provide insights for aligning AI with societal values and promoting equitable and culturally sensitive integration of AI technologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13841v2</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <pubDate>Wed, 27 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Philipp Brauner, Felix Glawe, Gian Luca Liehner, Luisa Vervier, Martina Ziefle</dc:creator>
    </item>
    <item>
      <title>Exploring Economic Sectoral Dynamics Through High-resolution Mobility Data</title>
      <link>https://arxiv.org/abs/2506.13985</link>
      <description>arXiv:2506.13985v2 Announce Type: replace 
Abstract: We present a comprehensive dataset capturing patterns of human mobility across the United States from January 2019 to January 2023, based on anonymized mobile device data. Aggregated weekly, the dataset reports visits, travel distances, and time spent at public locations organized by economic sector for approximately 12 million Points of Interest (POIs). This resource enables the study of how mobility and economic activity changed over time, particularly during major events such as the COVID-19 pandemic. By disaggregating patterns across different types of businesses, it provides valuable insights for researchers in economics, urban studies, and public health. To protect privacy, all data have been aggregated and anonymized. This dataset offers an opportunity to explore the dynamics of human behavior across sectors over an extended time period, supporting studies of mobility, resilience, and recovery.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.13985v2</guid>
      <category>cs.CY</category>
      <pubDate>Wed, 27 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Timothy F Leslie, Hossein Amiri, Andreas Z\"ufle</dc:creator>
    </item>
    <item>
      <title>When Algorithms Infer Gender: Revisiting Computational Phenotyping with Electronic Health Records Data</title>
      <link>https://arxiv.org/abs/2508.14150</link>
      <description>arXiv:2508.14150v2 Announce Type: replace 
Abstract: Computational phenotyping has emerged as a practical solution to the incomplete collection of data on gender in electronic health records (EHRs). This approach relies on algorithms to infer a patient's gender using the available data in their health record, such as diagnosis codes, medication histories, and information in clinical notes. Although intended to improve the visibility of trans and gender-expansive populations in EHR-based biomedical research, computational phenotyping raises significant methodological and ethical concerns related to the potential misuse of algorithm outputs. In this paper, we review current practices for computational phenotyping of gender and examine its challenges through a critical lens. We also highlight existing recommendations for biomedical researchers and propose priorities for future work in this domain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.14150v2</guid>
      <category>cs.CY</category>
      <pubDate>Wed, 27 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jessica Gronsbell, Hilary Thurston, Lillian Dong, Vanessa Ferguson, Diksha Sen Chaudhury, Braden O'Neill, Katrina S. Sha, Rebecca Bonneville</dc:creator>
    </item>
    <item>
      <title>Generative Artificial Intelligence and Agents in Research and Teaching</title>
      <link>https://arxiv.org/abs/2508.16701</link>
      <description>arXiv:2508.16701v2 Announce Type: replace 
Abstract: This study provides a comprehensive analysis of the development, functioning, and application of generative artificial intelligence (GenAI) and large language models (LLMs), with an emphasis on their implications for research and education. It traces the conceptual evolution from artificial intelligence (AI) through machine learning (ML) and deep learning (DL) to transformer architectures, which constitute the foundation of contemporary generative systems. Technical aspects, including prompting strategies, word embeddings, and probabilistic sampling methods (temperature, top-k, and top-p), are examined alongside the emergence of autonomous agents. These elements are considered in relation to both the opportunities they create and the limitations and risks they entail.
  The work critically evaluates the integration of GenAI across the research process, from ideation and literature review to research design, data collection, analysis, interpretation, and dissemination. While particular attention is given to geographical research, the discussion extends to wider academic contexts. A parallel strand addresses the pedagogical applications of GenAI, encompassing course and lesson design, teaching delivery, assessment, and feedback, with geography education serving as a case example.
  Central to the analysis are the ethical, social, and environmental challenges posed by GenAI. Issues of bias, intellectual property, governance, and accountability are assessed, alongside the ecological footprint of LLMs and emerging technological strategies for mitigation. The concluding section considers near- and long-term futures of GenAI, including scenarios of sustained adoption, regulation, and potential decline. By situating GenAI within both scholarly practice and educational contexts, the study contributes to critical debates on its transformative potential and societal responsibilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.16701v2</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <pubDate>Wed, 27 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jussi S. Jauhiainen, Aurora Toppari</dc:creator>
    </item>
    <item>
      <title>Global Geolocated Realtime Data of Interfleet Urban Transit Bus Idling</title>
      <link>https://arxiv.org/abs/2403.03489</link>
      <description>arXiv:2403.03489v5 Announce Type: replace-cross 
Abstract: Urban transit bus idling is a contributor to ecological stress, economic inefficiency, and medically hazardous health outcomes due to emissions. The global accumulation of this frequent pattern of undesirable driving behavior is enormous. In order to measure its scale, we propose GRD-TRT-BUF-4I (Ground Truth Buffer for Idling) an extensible, realtime detection system that records the geolocation and idling duration of urban transit bus fleets internationally. Using live vehicle locations from General Transit Feed Specification (GTFS) Realtime, the system detects approximately 200,000 idling events per day from over 50 cities across North America, Europe, Oceania, and Asia. This realtime data was created dynamically to serve operational decision-making and fleet management to reduce the frequency and duration of idling events as they occur, as well as to capture its accumulative effects. Civil and Transportation Engineers, Urban Planners, Epidemiologists, Policymakers, and other stakeholders might find this useful for emissions modeling, traffic management, route planning, and other urban sustainability efforts at a variety of geographic and temporal scales.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.03489v5</guid>
      <category>eess.SY</category>
      <category>cs.CY</category>
      <category>cs.SY</category>
      <pubDate>Wed, 27 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicholas Kunz, H. Oliver Gao</dc:creator>
    </item>
    <item>
      <title>A Taxonomy of Questions for Critical Reflection in Machine-Assisted Decision-Making</title>
      <link>https://arxiv.org/abs/2504.12830</link>
      <description>arXiv:2504.12830v3 Announce Type: replace-cross 
Abstract: Decision-makers run the risk of relying too much on machine recommendations, which is associated with lower cognitive engagement. Reflection has been shown to increase cognitive engagement and improve critical thinking and therefore decision-making. Questions are a means to stimulate reflection, but there is a research gap regarding the systematic creation and use of relevant questions for machine-assisted decision-making. We therefore present a taxonomy of questions aimed at promoting reflection and cognitive engagement in order to stimulate a deliberate decision-making process. Our taxonomy builds on the Socratic questioning method and a question bank for explainable AI. As a starting point, we focus on clinical decision-making. Brief discussions with two medical and three educational researchers provide feedback on the relevance and expected benefits of our taxonomy. Our work contributes to research on mitigating overreliance in human-AI interactions and aims to support effective human oversight as required by the European AI Act.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.12830v3</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <pubDate>Wed, 27 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Simon W. S. Fischer, Hanna Schraffenberger, Serge Thill, Pim Haselager</dc:creator>
    </item>
    <item>
      <title>YuLan-OneSim: Towards the Next Generation of Social Simulator with Large Language Models</title>
      <link>https://arxiv.org/abs/2505.07581</link>
      <description>arXiv:2505.07581v3 Announce Type: replace-cross 
Abstract: Leveraging large language model (LLM) based agents to simulate human social behaviors has recently gained significant attention. In this paper, we introduce a novel social simulator called YuLan-OneSim. Compared to previous works, YuLan-OneSim distinguishes itself in five key aspects: (1) Code-free scenario construction: Users can simply describe and refine their simulation scenarios through natural language interactions with our simulator. All simulation code is automatically generated, significantly reducing the need for programming expertise. (2) Comprehensive default scenarios: We implement 50 default simulation scenarios spanning 8 domains, including economics, sociology, politics, psychology, organization, demographics, law, and communication, broadening access for a diverse range of social researchers. (3) Evolvable simulation: Our simulator is capable of receiving external feedback and automatically fine-tuning the backbone LLMs, significantly enhancing the simulation quality. (4) Large-scale simulation: By developing a fully responsive agent framework and a distributed simulation architecture, our simulator can handle up to 100,000 agents, ensuring more stable and reliable simulation results. (5) AI social researcher: Leveraging the above features, we develop an AI social researcher. Users only need to propose a research topic, and the AI researcher will automatically analyze the input, construct simulation environments, summarize results, generate technical reports, review and refine the reports--completing the social science research loop. To demonstrate the advantages of YuLan-OneSim, we conduct experiments to evaluate the quality of the automatically generated scenarios, the reliability, efficiency, and scalability of the simulation process, as well as the performance of the AI social researcher.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07581v3</guid>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <pubDate>Wed, 27 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lei Wang, Heyang Gao, Xiaohe Bo, Xu Chen, Ji-Rong Wen</dc:creator>
    </item>
    <item>
      <title>A Comparison of Precinct and District Voting Data Using Persistent Homology to Identify Gerrymandering in North Carolina</title>
      <link>https://arxiv.org/abs/2506.13997</link>
      <description>arXiv:2506.13997v3 Announce Type: replace-cross 
Abstract: We present an extension of Feng and Porter's 2019 paper on the use of the level-set method for the construction of a filtered simplicial complex from geospatial election data. Precincts are regarded to be too small to be gerrymandered, allowing us to identify discrepancies between precinct and district level voting data to quantify gerrymandering in the United States. Comparing the persistent homologies of Democratic voting areas on the precinct and district level shows when areas have been 'cracked' or 'packed' for partisan gain. This analysis was done for North Carolina House of Representatives elections (2012 to 2024). North Carolina has been redistricted 4 times in the past 10 years, whereas most states redistrict decennially, allowing us to understand how and when redistricted maps deviate from precinct-level voting data, and when gerrymandering occurs. Comparing persistence barcodes at the precinct and district levels (using the bottleneck distance) shows that precinct-level voting patterns do not significantly fluctuate biannually, while district level patterns do, suggesting that shifts are likely a result of redistricting rather than voter behavior, providing strong evidence of gerrymandering. North Carolina election data was collected from the public domain. Composite shapefiles were created using QGIS and R, and rasterized using Python. The level-set method was employed to generate filtered simplicial complexes. Persistence barcodes were produced using GUDHI and PHAT libraries. Additionally, we compare our results with traditional measures such as Polsby-Popper and Reock scores (gerrymandering identification measures). This research presents a novel application of topological data analysis in evaluating gerrymandering.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.13997v3</guid>
      <category>cs.SI</category>
      <category>cs.CY</category>
      <pubDate>Wed, 27 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ananya Shah</dc:creator>
    </item>
    <item>
      <title>Multi-Agent LLMs as Ethics Advocates for AI-Based Systems</title>
      <link>https://arxiv.org/abs/2507.08392</link>
      <description>arXiv:2507.08392v3 Announce Type: replace-cross 
Abstract: Incorporating ethics into the requirement elicitation process is essential for creating ethically aligned systems. Although eliciting manual ethics requirements is effective, it requires diverse input from multiple stakeholders, which can be challenging due to time and resource constraints. Moreover, it is often given a low priority in the requirements elicitation process. This study proposes a framework for generating ethics requirements drafts by introducing an ethics advocate agent in a multi-agent LLM setting. This agent critiques and provides input on ethical issues based on the system description. The proposed framework is evaluated through two case studies from different contexts, demonstrating that it captures the majority of ethics requirements identified by researchers during 30-minute interviews and introduces several additional relevant requirements. However, it also highlights reliability issues in generating ethics requirements, emphasizing the need for human feedback in this sensitive domain. We believe this work can facilitate the broader adoption of ethics in the requirements engineering process, ultimately leading to more ethically aligned products.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.08392v3</guid>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <pubDate>Wed, 27 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Asma Yamani, Malak Baslyman, Moataz Ahmed</dc:creator>
    </item>
  </channel>
</rss>
