<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.SI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.SI</link>
    <description>cs.SI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.SI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 02 Dec 2025 05:00:15 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Concentration Within Distribution: Unmasking Bitcoin's Structural Centralization Through Network Science</title>
      <link>https://arxiv.org/abs/2512.00437</link>
      <description>arXiv:2512.00437v1 Announce Type: new 
Abstract: We construct the Bitcoin User Network (BUN) directly from raw blockchain data up to late 2025, which allows us to explore its mesoscopic properties and trace its temporal evolution. In particular, we analyze the structure of connected components and directed assortativity through the four variants of Newman's coefficient, implemented via custom algorithms and a dedicated database. Building on this, to characterize the distribution of structural influence, we introduce direction-sensitive centrality measures based on PageRank and HITS, which provide a complementary global analysis of the BUN and reveal a persistently unequal and increasingly core-periphery structure. In addition, we complement the structural analysis with a study of Bitcoin's price volatility using high-frequency market data. Overall, our results reveal a clear pattern of concentration within distribution: although the protocol is decentralized by design, the emergent user network evolves toward an asymmetric mesoscopic structure that indicates the existence of a few large-scale connected components that function as the critical backbone of the system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.00437v1</guid>
      <category>cs.SI</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Myriam Nonaka, F. Javier Mar\'in-Rodr\'iguez, Alexander Jiricny, Miguel Romance, Regino Criado, Sergio Iglesias-P\'erez, Alberto Partida</dc:creator>
    </item>
    <item>
      <title>Social Media Data Mining of Human Behaviour during Bushfire Evacuation</title>
      <link>https://arxiv.org/abs/2512.01262</link>
      <description>arXiv:2512.01262v1 Announce Type: new 
Abstract: Traditional data sources on bushfire evacuation behaviour, such as quantitative surveys and manual observations have severe limitations. Mining social media data related to bushfire evacuations promises to close this gap by allowing the collection and processing of a large amount of behavioural data, which are low-cost, accurate, possibly including location information and rich contextual information. However, social media data have many limitations, such as being scattered, incomplete, informal, etc. Together, these limitations represent several challenges to their usefulness to better understand bushfire evacuation. To overcome these challenges and provide guidance on which and how social media data can be used, this scoping review of the literature reports on recent advances in relevant data mining techniques. In addition, future applications and open problems are discussed. We envision future applications such as evacuation model calibration and validation, emergency communication, personalised evacuation training, and resource allocation for evacuation preparedness. We identify open problems such as data quality, bias and representativeness, geolocation accuracy, contextual understanding, crisis-specific lexicon and semantics, and multimodal data interpretation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.01262v1</guid>
      <category>cs.SI</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Junfeng Wu, Xiangmin Zhou, Erica Kuligowski, Dhirendra Singh, Enrico Ronchi, Max Kinateder</dc:creator>
    </item>
    <item>
      <title>A Survey on Centrality and Importance Measures in Hypergraphs: Categorization and Empirical Insights</title>
      <link>https://arxiv.org/abs/2512.00107</link>
      <description>arXiv:2512.00107v1 Announce Type: cross 
Abstract: Identifying central entities and interactions is a fundamental problem in network science. While well-studied for graphs (pairwise relations), many biological and social systems exhibit higher-order interactions best modeled by hypergraphs. This has led to a proliferation of specialized hypergraph centrality measures, but the field remains fragmented and lacks a unifying framework. This paper addresses this gap by providing the first systematic survey of 39 distinct measures. We introduce a novel taxonomy classifying them as: (1) structural (topology-based), (2) functional (impact on system dynamics), or (3) contextual (incorporating external features). We also present an experimental assessment comparing their empirical similarity and computation time. Finally, we discuss applications, establishing a coherent roadmap for future research in this area.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.00107v1</guid>
      <category>physics.soc-ph</category>
      <category>cs.SI</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jaewan Chun, Fanchen Bu, Yeongho Kim, Atsushi Miyauchi, Francesco Bonchi, Kijung Shin</dc:creator>
    </item>
    <item>
      <title>DQ4FairIM: Fairness-aware Influence Maximization using Deep Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2512.00545</link>
      <description>arXiv:2512.00545v1 Announce Type: cross 
Abstract: The Influence Maximization (IM) problem aims to select a set of seed nodes within a given budget to maximize the spread of influence in a social network. However, real-world social networks have several structural inequalities, such as dominant majority groups and underrepresented minority groups. If these inequalities are not considered while designing IM algorithms, the outcomes might be biased, disproportionately benefiting majority groups while marginalizing minorities. In this work, we address this gap by designing a fairness-aware IM method using Reinforcement Learning (RL) that ensures equitable influence outreach across all communities, regardless of protected attributes. Fairness is incorporated using a maximin fairness objective, which prioritizes improving the outreach of the least-influenced group, pushing the solution toward an equitable influence distribution. We propose a novel fairness-aware deep RL method, called DQ4FairIM, that maximizes the expected number of influenced nodes by learning an RL policy. The learnt policy ensures that minority groups formulate the IM problem as a Markov Decision Process (MDP) and use deep Q-learning, combined with the Structure2Vec network embedding, earning together with Structure2Vec network embedding to solve the MDP. We perform extensive experiments on synthetic benchmarks and real-world networks to compare our method with fairness-agnostic and fairness-aware baselines. The results show that our method achieves a higher level of fairness while maintaining a better fairness-performance trade-off than baselines. Additionally, our approach learns effective seeding policies that generalize across problem instances without retraining, such as varying the network size or the number of seed nodes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.00545v1</guid>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <category>stat.ML</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Akrati Saxena, Harshith Kumar Yadav, Bart Rutten, Shashi Shekhar Jha</dc:creator>
    </item>
    <item>
      <title>Measuring the disruptiveness of conceptual papers in the field of marketing</title>
      <link>https://arxiv.org/abs/2308.14724</link>
      <description>arXiv:2308.14724v3 Announce Type: replace 
Abstract: Marketing scholars have underscored the importance of conceptual articles in providing theoretical foundations and new perspectives to the field. This paper supports the argument by employing two network-based measures -- the number of citations and the disruption score -- and comparing them for conceptual and empirical research. With the aid of a large language model, we classify conceptual and empirical articles published in a substantial set of marketing journals. The findings reveal that conceptual research is not only more frequently cited but also has a greater disruptive impact on the field of marketing than empirical research. Our paper contributes to the understanding of how marketing articles advance knowledge through developmental approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.14724v3</guid>
      <category>cs.SI</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jennifer JooYeon Lee, Hyunuk Kim</dc:creator>
    </item>
    <item>
      <title>A Reinforcement Learning Method to Factual and Counterfactual Explanations for Session-based Recommendation</title>
      <link>https://arxiv.org/abs/2504.13632</link>
      <description>arXiv:2504.13632v2 Announce Type: replace 
Abstract: Session-based Recommendation (SR) systems have recently achieved considerable success, yet their complex, "black box" nature often obscures why certain recommendations are made. Existing explanation methods struggle to pinpoint truly influential factors, as they frequently depend on static user profiles or fail to grasp the intricate dynamics within user sessions. In response, we introduce FCESR (Factual and Counterfactual Explanations for Session-based Recommendation), a novel framework designed to illuminate SR model predictions by emphasizing both the sufficiency (factual) and necessity (counterfactual) of recommended items. By recasting explanation generation as a combinatorial optimization challenge and leveraging reinforcement learning, our method uncovers the minimal yet critical sequence of items influencing recommendations. Moreover, recognizing the intrinsic value of robust explanations, we innovatively utilize these factual and counterfactual insights within a contrastive learning paradigm, employing them as high-quality positive and negative samples to fine-tune and significantly enhance SR accuracy. Extensive qualitative and quantitative evaluations across diverse datasets and multiple SR architectures confirm that our framework not only boosts recommendation accuracy but also markedly elevates the quality and interpretability of explanations, thereby paving the way for more transparent and trustworthy recommendation systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.13632v2</guid>
      <category>cs.SI</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Han Zhou, Hui Fang, Zhu Sun, Wentao Hu</dc:creator>
    </item>
    <item>
      <title>The Artificial Benchmark for Community Detection with Outliers and Overlapping Communities (ABCD+$o^2$)</title>
      <link>https://arxiv.org/abs/2506.05486</link>
      <description>arXiv:2506.05486v2 Announce Type: replace 
Abstract: The Artificial Benchmark for Community Detection (ABCD) graph is a random graph model with community structure and power-law distribution for both degrees and community sizes. The model generates graphs similar to the well-known LFR model but it is faster, more interpretable, and can be investigated analytically. In this paper, we use the underlying ingredients of the ABCD model, and its generalization to include outliers (ABCD+$o$), and introduce another variant that allows for overlapping communities, ABCD+$o^2$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.05486v2</guid>
      <category>cs.SI</category>
      <category>math.CO</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jordan Barrett, Ryan DeWolfe, Bogumi{\l} Kami\'nski, Pawe{\l} Pra{\l}at, Aaron Smith, Fran\c{c}ois Th\'eberge</dc:creator>
    </item>
    <item>
      <title>HoWDe: a validated algorithm for Home and Work location Detection</title>
      <link>https://arxiv.org/abs/2506.20679</link>
      <description>arXiv:2506.20679v2 Announce Type: replace 
Abstract: Smartphone location data have become a key resource for understanding urban mobility, yet extracting actionable insights requires robust and reproducible preprocessing pipelines. A central step is the identification of individuals' home and work locations, which underpins analyses of commuting, employment, accessibility, and socioeconomic patterns. However, existing approaches are often ad hoc, data-specific, and difficult to reproduce, limiting comparability across studies and datasets. We introduce HoWDe, an open-source software library for detecting home and work locations from large-scale mobility data. HoWDe implements a transparent, modular pipeline explicitly designed to handle missing data, heterogeneous sampling rates, and differences in data sparsity across individuals. The code allows users to tune a small set of interpretable parameters, enabling to adapt the algorithm to diverse applications and datasets. Using two unique ground truth datasets comprising 5,099 individuals across 68 countries, we show that HoWDe achieves home and work detection accuracies of up to 97% and 88%, respectively, with consistent performance across demographic groups and geographic contexts. We further demonstrate how parameter settings propagate to downstream metrics such as employment estimates and commuting flows, highlighting the importance of transparent methodological choices. By providing a validated, documented, and easily deployable pipeline, HoWDe supports scalable in-house preprocessing and facilitates the sharing of privacy-preserving mobility datasets. Our software and evaluation benchmarks establish methodological standards that enhance the robustness and reproducibility of human mobility research at urban and national scales.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.20679v2</guid>
      <category>cs.SI</category>
      <category>cs.CY</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>S\'ilvia De Sojo, Lorenzo Lucchini, Ollin D. Langle-Chimal, Samuel P. Fraiberger, Laura Alessandretti</dc:creator>
    </item>
    <item>
      <title>Past-aware game-theoretic centrality in complex contagion dynamics</title>
      <link>https://arxiv.org/abs/2511.07157</link>
      <description>arXiv:2511.07157v2 Announce Type: replace 
Abstract: In this paper, we introduce past-aware game-theoretic centrality, a class of centrality measures that captures the collaborative contribution of nodes in a network, accounting for both uncertain and certain collaborators. A general framework for computing standard game-theoretic centrality is extended to the past-aware case. As an application, we develop a new heuristic for different versions of the influence maximization problem in complex contagion, which models processes requiring reinforcement from multiple neighbors to spread. A computationally efficient explicit formula for the corresponding past-aware centrality score is derived, leading to scalable algorithms for identifying the most influential nodes, which in most cases outperform the standard greedy approach in both efficiency and solution quality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.07157v2</guid>
      <category>cs.SI</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Francesco Zigliotto</dc:creator>
    </item>
    <item>
      <title>Conformal Prediction for Multi-Source Detection on a Network</title>
      <link>https://arxiv.org/abs/2511.08867</link>
      <description>arXiv:2511.08867v2 Announce Type: replace 
Abstract: Detecting the origin of information or infection spread in networks is a fundamental challenge with applications in misinformation tracking, epidemiology, and beyond. We study the multi-source detection problem: given snapshot observations of node infection status on a graph, estimate the set of source nodes that initiated the propagation. Existing methods either lack statistical guarantees or are limited to specific diffusion models and assumptions. We propose a novel conformal prediction framework that provides statistically valid recall guarantees for source set detection, independent of the underlying diffusion process or data distribution. Our approach introduces principled score functions to quantify the alignment between predicted probabilities and true sources, and leverages a calibration set to construct prediction sets with user-specified recall and coverage levels. The method is applicable to both single- and multi-source scenarios, supports general network diffusion dynamics, and is computationally efficient for large graphs. Empirical results demonstrate that our method achieves rigorous coverage with competitive accuracy, outperforming existing baselines in both reliability and scalability.The code is available online.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.08867v2</guid>
      <category>cs.SI</category>
      <category>cs.AI</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xingchao Jian, Purui Zhang, Lan Tian, Feng Ji, Wenfei Liang, Wee Peng Tay, Bihan Wen, Felix Krahmer</dc:creator>
    </item>
    <item>
      <title>Lossy communication constrains iterated learning</title>
      <link>https://arxiv.org/abs/2511.18220</link>
      <description>arXiv:2511.18220v2 Announce Type: replace 
Abstract: Humans' distinctive role in the world can largely be attributed to our capacity for iterated learning, a process by which knowledge is expanded and refined over generations. A range of theories seek to explain why humans are so adept at iterated learning, many positing substantial evolutionary discontinuities in communication or cognition. Is it necessary to posit large differences in abilities between humans and other species, or could small differences in communication ability produce large differences in what a species can learn over generations? We investigate this question through a formal model based on information theory. We manipulate how much information individual learners can send each other and observe the effect on iterated learning performance. Incremental changes to the channel rate can lead to dramatic, non-linear changes to the eventual performance of the population. We complement this model with a theoretical result that describes how individual lossy communications constrain the global performance of iterated learning. Our results demonstrate that incremental, quantitative changes to communication abilities could be sufficient to explain large differences in what can be learned over many generations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.18220v2</guid>
      <category>cs.SI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ben Prystawski, Dilip Arumugam, Noah D. Goodman</dc:creator>
    </item>
    <item>
      <title>Multiple Randomization Designs: Estimation and Inference with Interference</title>
      <link>https://arxiv.org/abs/2112.13495</link>
      <description>arXiv:2112.13495v4 Announce Type: replace-cross 
Abstract: Completely randomized experiments, originally developed by Fisher and Neyman in the 1930s, are still widely used in practice, even in online experimentation. However, such designs are of limited value for answering standard questions in marketplaces, where multiple populations of agents interact strategically, leading to complex patterns of spillover effects. In this paper, we derive the finite-sample properties of tractable estimators for "Simple Multiple Randomization Designs" (SMRDs), a new class of experimental designs which account for complex spillover effects in randomized experiments. Our derivations are obtained under a natural and general form of cross-unit interference, which we call "local interference". We discuss the estimation of main effects, direct effects, and spillovers, and present associated central limit theorems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2112.13495v4</guid>
      <category>stat.ME</category>
      <category>cs.SI</category>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1093/jrsssb/qkaf073</arxiv:DOI>
      <dc:creator>Lorenzo Masoero, Suhas Vijaykumar, Thomas Richardson, James McQueen, Ido Rosen, Brian Burdick, Pat Bajari, Guido Imbens</dc:creator>
    </item>
    <item>
      <title>Endogenous Network Structures with Precision and Dimension Choices</title>
      <link>https://arxiv.org/abs/2507.00249</link>
      <description>arXiv:2507.00249v2 Announce Type: replace-cross 
Abstract: This paper presents a social learning model where the network structure is endogenously determined by signal precision and dimension choices. Agents not only choose the precision of their signals and what dimension of the state to learn about, but these decisions directly determine the underlying network structure on which social learning occurs. We show that under a fixed network structure, the optimal precision choice is sublinear in the agent's stationary influence in the network, and this individually optimal choice is worse than the socially optimal choice by a factor of $n^{1/3}$. Under a dynamic network structure, we specify the network by defining a kernel distance between agents, which then determines how much weight agents place on one another. Agents choose dimensions to learn about such that their choice minimizes the squared sum of influences of all agents: a network with equally distributed influence across agents is ideal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.00249v2</guid>
      <category>econ.TH</category>
      <category>cs.SI</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nikhil Kumar</dc:creator>
    </item>
    <item>
      <title>Using Generative AI to Uncover What Drives Player Enjoyment in PC and VR Games</title>
      <link>https://arxiv.org/abs/2508.16596</link>
      <description>arXiv:2508.16596v5 Announce Type: replace-cross 
Abstract: As video games continue to evolve, understanding what drives player enjoyment remains a key challenge. Player reviews provide valuable insights, but their unstructured nature makes large-scale analysis difficult. This study applies generative AI and machine learning, leveraging Microsoft Phi-4 small language model (SLM) and Google Cloud, to quantify and analyze game reviews from Steam and Meta Quest stores. The approach converts qualitative feedback into structured data, enabling comprehensive evaluation of key game design elements, monetization models, and platform-specific trends. The findings reveal distinct patterns in player preferences across PC and VR games, highlighting factors that contribute to higher player enjoyment. By using Google Cloud for large-scale data storage and processing, this study establishes a scalable framework for game review analysis. The study's insights offer actionable guidance for game developers, helping optimize game mechanics, pricing strategies, and player engagement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.16596v5</guid>
      <category>cs.HC</category>
      <category>cs.SI</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hisham Abdelqader</dc:creator>
    </item>
    <item>
      <title>HiFIRec Towards High-Frequency yet Low-Intention Behaviors for Multi-Behavior Recommendation</title>
      <link>https://arxiv.org/abs/2509.25755</link>
      <description>arXiv:2509.25755v2 Announce Type: replace-cross 
Abstract: Multi behavior recommendation leverages multiple types of user-item interactions to address data sparsity and cold-start issues,providing personalized services in domains such as healthcare and ecommerce.Most existing methods utilize graph neural networks to model user intention in a unified manner,which inadequately considers the heterogeneity across different behaviors.Especially,high frequency yet low intention behaviors may implicitly contain noisy signals,and frequent patterns that are plausible while misleading,thereby hindering the learning of user intentions.To this end,this paper proposes a novel multi-behavior recommendation method,HiFIRec,that corrects the effect of high-frequency yet low-intention behaviors by differential behavior modeling.To revise the noisy signals,we hierarchically suppress it across layers by extracting neighborhood information through layer-wise neighborhood aggregation and further capturing user intentions through adaptive cross layer feature fusion.To correct plausible frequent patterns,we propose an intensity-aware non-sampling strategy that dynamically adjusts the weights of negative samples.Extensive experiments on two benchmarks show that HiFIRec relatively improves HR@10 by 4.21%-6.81% over several state-of-the-art methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.25755v2</guid>
      <category>cs.IR</category>
      <category>cs.SI</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ruiqi Luo, Ran Jin, Kaixi Hu, Xiaohui Tao, Lin Li</dc:creator>
    </item>
    <item>
      <title>How Similar Are Grokipedia and Wikipedia? A Multi-Dimensional Textual and Structural Comparison</title>
      <link>https://arxiv.org/abs/2510.26899</link>
      <description>arXiv:2510.26899v3 Announce Type: replace-cross 
Abstract: The launch of Grokipedia - an AI-generated encyclopedia developed by Elon Musk's xAI - was presented as a response to perceived ideological and structural biases in Wikipedia, aiming to produce "truthful" entries using the Grok large language model. Yet whether an AI-driven alternative can escape the biases and limitations of human-edited platforms remains unclear. This study conducts a large-scale computational comparison of more than 17,000 matched article pairs from the 20,000 most-edited English Wikipedia pages. Using metrics spanning lexical richness, readability, reference density, structural features, and semantic similarity, we assess how closely the two platforms align in form and substance. We find that Grokipedia articles are substantially longer and contain significantly fewer references per word. Moreover, Grokipedia's content divides into two distinct groups: one that remains semantically and stylistically aligned with Wikipedia, and another that diverges sharply. Among the dissimilar articles, we observe a systematic rightward shift in the political bias of cited news sources, concentrated primarily in entries related to politics, history, and religion. These findings suggest that AI-generated encyclopedic content diverges from established editorial norms-favouring narrative expansion over citation-based verification. The implications highlight emerging tensions around transparency, provenance, and the governance of knowledge in an era of automated text generation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.26899v3</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.SI</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Taha Yasseri, Saeedeh Mohammadi</dc:creator>
    </item>
    <item>
      <title>A Machine Learning Approach for Detection of Mental Health Conditions and Cyberbullying from Social Media</title>
      <link>https://arxiv.org/abs/2511.20001</link>
      <description>arXiv:2511.20001v2 Announce Type: replace-cross 
Abstract: Mental health challenges and cyberbullying are increasingly prevalent in digital spaces, necessitating scalable and interpretable detection systems. This paper introduces a unified multiclass classification framework for detecting ten distinct mental health and cyberbullying categories from social media data. We curate datasets from Twitter and Reddit, implementing a rigorous "split-then-balance" pipeline to train on balanced data while evaluating on a realistic, held-out imbalanced test set. We conducted a comprehensive evaluation comparing traditional lexical models, hybrid approaches, and several end-to-end fine-tuned transformers. Our results demonstrate that end-to-end fine-tuning is critical for performance, with the domain-adapted MentalBERT emerging as the top model, achieving an accuracy of 0.92 and a Macro F1 score of 0.76, surpassing both its generic counterpart and a zero-shot LLM baseline. Grounded in a comprehensive ethical analysis, we frame the system as a human-in-the-loop screening aid, not a diagnostic tool. To support this, we introduce a hybrid SHAPLLM explainability framework and present a prototype dashboard ("Social Media Screener") designed to integrate model predictions and their explanations into a practical workflow for moderators. Our work provides a robust baseline, highlighting future needs for multi-label, clinically-validated datasets at the critical intersection of online safety and computational mental health.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.20001v2</guid>
      <category>cs.CL</category>
      <category>cs.SI</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Edward Ajayi, Martha Kachweka, Mawuli Deku, Emily Aiken</dc:creator>
    </item>
  </channel>
</rss>
