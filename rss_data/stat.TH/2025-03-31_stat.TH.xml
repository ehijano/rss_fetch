<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.TH updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.TH</link>
    <description>stat.TH updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.TH" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 31 Mar 2025 04:00:23 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 31 Mar 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Rolled Gaussian process models for curves on manifolds</title>
      <link>https://arxiv.org/abs/2503.21980</link>
      <description>arXiv:2503.21980v1 Announce Type: new 
Abstract: Given a planar curve, imagine rolling a sphere along that curve without slipping or twisting, and by this means tracing out a curve on the sphere. It is well known that such a rolling operation induces a local isometry between the sphere and the plane so that the two curves uniquely determine each other, and moreover, the operation extends to a general class of manifolds in any dimension. We use rolling to construct an analogue of a Gaussian process on a manifold starting from a Euclidean Gaussian process. The resulting model is generative, and is amenable to statistical inference given data as curves on a manifold. We illustrate with examples on the unit sphere, symmetric positive-definite matrices, and with a robotics application involving 3D orientations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.21980v1</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Mon, 31 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Simon Preston, Karthik Bharath, Pablo Lopez-Custodio, Alfred Kume</dc:creator>
    </item>
    <item>
      <title>Asymptotic Behavior of Principal Component Projections for Multivariate Extremes</title>
      <link>https://arxiv.org/abs/2503.22296</link>
      <description>arXiv:2503.22296v1 Announce Type: new 
Abstract: The extremal dependence structure of a regularly varying $d$-dimensional random vector can be described by its angular measure. The standard nonparametric estimator of this measure is the empirical measure of the observed angles of the $k$ random vectors with largest norm, for a suitably chosen number $k$. Due to the curse of dimensionality, for moderate or large $d$, this estimator is often inaccurate. If the angular measure is concentrated on a vicinity of a lower dimensional subspace, then first projecting the data on a lower dimensional subspace obtained by a principal component analysis of the angles of extreme observations can substantially improve the performance of the estimator.
  We derive the asymptotic behavior of such PCA projections and the resulting excess risk. In particular, it is shown that, under mild conditions, the excess risk (as a function of $k$) decreases much faster than it was suggested by empirical risk bounds obtained in \cite{DS21}. Moreover, functional limit theorems for local empirical processes of the (empirical) reconstruction error of projections uniformly over neighborhoods of the true optimal projection are established. Based on these asymptotic results, we propose a data-driven method to select the dimension of the projection space. Finally, the finite sample performance of resulting estimators is examined in a simulation study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.22296v1</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Mon, 31 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Holger Drees</dc:creator>
    </item>
    <item>
      <title>Conditional Extreme Value Estimation for Dependent Time Series</title>
      <link>https://arxiv.org/abs/2503.22366</link>
      <description>arXiv:2503.22366v1 Announce Type: new 
Abstract: We study the consistency and weak convergence of the conditional tail function and conditional Hill estimators under broad dependence assumptions for a heavy-tailed response sequence and a covariate sequence. Consistency is established under $\alpha$-mixing, while asymptotic normality follows from $\beta$-mixing and second-order conditions. A key aspect of our approach is its versatile functional formulation in terms of the conditional tail process. Simulations demonstrate its performance across dependence scenarios. We apply our method to extreme event modeling in the oil industry, revealing distinct tail behaviors under varying conditioning values.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.22366v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 31 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Martin Bladt, Laurits Glargaard, Theodor Henningsen</dc:creator>
    </item>
    <item>
      <title>An Improved Satterthwaite Effective Degrees of Freedom Correction for Weighted Syntheses of Variance</title>
      <link>https://arxiv.org/abs/2503.22080</link>
      <description>arXiv:2503.22080v1 Announce Type: cross 
Abstract: This article presents an improved approximation for the effective degrees of freedom in the Satterthwaite (1941, 1946) method which estimates the distribution of a weighted combination of variance components The standard Satterthwaite approximation assumes a scaled chisquare distribution for the composite variance estimator but is known to be biased downward when component degrees of freedom are small. Building on recent work by von Davier (2025) we propose an adjusted estimator that corrects this bias by modifying both the numerator and denominator of the traditional formula. The new approximation incorporates a weighted average of component degrees of freedom and a scaling factor that ensures consistency as the number of components or their degrees of freedom increases. We demonstrate the utility of this adjustment in practical settings including Rubins (1987) total variance estimation in multiple imputations where weighted variance combinations are common. The proposed estimator generalizes von Daviers (2025) unweighted case and more accurately approximates synthetic variance estimators with arbitrary weights.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.22080v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 31 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Matthias von Davier</dc:creator>
    </item>
    <item>
      <title>Inference on effect size after multiple hypothesis testing</title>
      <link>https://arxiv.org/abs/2503.22369</link>
      <description>arXiv:2503.22369v1 Announce Type: cross 
Abstract: Significant treatment effects are often emphasized when interpreting and summarizing empirical findings in studies that estimate multiple, possibly many, treatment effects. Under this kind of selective reporting, conventional treatment effect estimates may be biased and their corresponding confidence intervals may undercover the true effect sizes. We propose new estimators and confidence intervals that provide valid inferences on the effect sizes of the significant effects after multiple hypothesis testing. Our methods are based on the principle of selective conditional inference and complement a wide range of tests, including step-up tests and bootstrap-based step-down tests. Our approach is scalable, allowing us to study an application with over 370 estimated effects. We justify our procedure for asymptotically normal treatment effect estimators. We provide two empirical examples that demonstrate bias correction and confidence interval adjustments for significant effects. The magnitude and direction of the bias correction depend on the correlation structure of the estimated effects and whether the interpretation of the significant effects depends on the (in)significance of other effects.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.22369v1</guid>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 31 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Andreas Dzemski, Ryo Okui, Wenjie Wang</dc:creator>
    </item>
    <item>
      <title>Optimal treatment regimes for the net benefit of a treatment</title>
      <link>https://arxiv.org/abs/2503.22580</link>
      <description>arXiv:2503.22580v1 Announce Type: cross 
Abstract: We developed a mathematical setup inspired by Buyse's generalized pairwise comparisons to define a notion of optimal individualized treatment rule (ITR) in the presence of prioritized outcomes in a randomized controlled trial, terming such an ITR pairwise optimal. We present two approaches to estimate pairwise optimal ITRs. The first is a variant of the k-nearest neighbors algorithm. The second is a meta-learner based on a randomized bagging scheme, allowing the use of any classification algorithm for constructing an ITR. We study the behavior of these estimation schemes from a theoretical standpoint and through Monte Carlo simulations and illustrate their use on trial data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.22580v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.TH</category>
      <pubDate>Mon, 31 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fran\c{c}ois Petit, G\'erard Biau, Rapha\"el Porcher</dc:creator>
    </item>
    <item>
      <title>Adversarially Robust Topological Inference</title>
      <link>https://arxiv.org/abs/2206.01795</link>
      <description>arXiv:2206.01795v2 Announce Type: replace 
Abstract: The distance function to a compact set plays a crucial role in the paradigm of topological data analysis. In particular, the sublevel sets of the distance function are used in the computation of persistent homology -- a backbone of the topological data analysis pipeline. Despite its stability to perturbations in the Hausdorff distance, persistent homology is highly sensitive to outliers. In this work, we develop a framework of statistical inference for persistent homology in the presence of outliers. Drawing inspiration from recent developments in robust statistics, we propose a \textit{median-of-means} variant of the distance function (\textsf{MoM Dist}) and establish its statistical properties. In particular, we show that, even in the presence of outliers, the sublevel filtrations and weighted filtrations induced by \textsf{MoM Dist} are both consistent estimators of the true underlying population counterpart and exhibit near minimax-optimal performance in adversarial settings. Finally, we demonstrate the advantages of the proposed methodology through simulations and applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2206.01795v2</guid>
      <category>math.ST</category>
      <category>cs.CG</category>
      <category>cs.LG</category>
      <category>math.AT</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Mon, 31 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Siddharth Vishwanath, Bharath K. Sriperumbudur, Kenji Fukumizu, Satoshi Kuriki</dc:creator>
    </item>
    <item>
      <title>Regression graphs and sparsity-inducing reparametrizations</title>
      <link>https://arxiv.org/abs/2402.09112</link>
      <description>arXiv:2402.09112v3 Announce Type: replace 
Abstract: That parametrization and sparsity are inherently linked raises the possibility that relevant models, not obviously sparse in their natural formulation, exhibit a population-level sparsity after reparametrization. In covariance models, positive-definiteness enforces additional constraints on how sparsity can legitimately manifest. It is therefore natural to consider reparametrization maps in which sparsity respects positive definiteness. The main purpose of this paper is to provide insight into structures on the physically-natural scale that induce and are induced by sparsity after reparametrization. The richest of the four structures initially uncovered is, under a causal ordering, a constrained version of the joint-response graphs studied by Cox and Wermuth (2004), while the most restrictive is that induced by sparsity on the scale of the matrix logarithm, studied by Battey (2017). This points to a class of reparametrizations for the chain-graph models Andersson et al. (2001), with undirected and directed acyclic graphs as special cases. While much of the paper is focused on exact zeros, the scope is considerably broadened through the possibility of approximate zeros. An important insight is the interpretation of these approximate zeros, explaining the modelling implications of enforcing sparsity after reparameterization: in effect, the relation between two variables would be declared null if relatively direct regression effects were negligible and other effects manifested through long paths. The insights have some conceptual implications; they also have a bearing on methodology, some aspects of which are developed in the supplementary material.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.09112v3</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 31 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jakub Rybak, Heather Battey, Karthik Bharath</dc:creator>
    </item>
    <item>
      <title>The maximum likelihood type estimator of SDEs with fractional Brownian motion under small noise asymptotics in the rough case</title>
      <link>https://arxiv.org/abs/2406.07804</link>
      <description>arXiv:2406.07804v3 Announce Type: replace 
Abstract: We study the problem of parametric estimation for continuously observed stochastic differential equation driven by fractional Brownian motion. Under some assumptions on drift and diffusion coefficients, we construct maximum likelihood estimator and establish its the asymptotic normality and moment convergence of the drift parameter when a small dispersion coefficient vanishes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.07804v3</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Mon, 31 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shohei Nakajima</dc:creator>
    </item>
    <item>
      <title>On the supremum of the sets of copulas with given curvilinear section</title>
      <link>https://arxiv.org/abs/2412.20629</link>
      <description>arXiv:2412.20629v2 Announce Type: replace 
Abstract: Making use of the total variation of particular functions, we give an explicit formula for the pointwise supremum of the set of all copulas with a given curvilinear section. When the pointwise supremum is a copula is characterized. We also characterize the coincidence of the pointwise supremum and the greatest quasi-copula with the same curvilinear section.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.20629v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 31 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yao Ouyang, Yonghui Sun, Hua-Peng Zhang</dc:creator>
    </item>
    <item>
      <title>Compress Then Test: Powerful Kernel Testing in Near-linear Time</title>
      <link>https://arxiv.org/abs/2301.05974</link>
      <description>arXiv:2301.05974v3 Announce Type: replace-cross 
Abstract: Kernel two-sample testing provides a powerful framework for distinguishing any pair of distributions based on $n$ sample points. However, existing kernel tests either run in $n^2$ time or sacrifice undue power to improve runtime. To address these shortcomings, we introduce Compress Then Test (CTT), a new framework for high-powered kernel testing based on sample compression. CTT cheaply approximates an expensive test by compressing each $n$ point sample into a small but provably high-fidelity coreset. For standard kernels and subexponential distributions, CTT inherits the statistical behavior of a quadratic-time test -- recovering the same optimal detection boundary -- while running in near-linear time. We couple these advances with cheaper permutation testing, justified by new power analyses; improved time-vs.-quality guarantees for low-rank approximation; and a fast aggregation procedure for identifying especially discriminating kernels. In our experiments with real and simulated data, CTT and its extensions provide 20--200x speed-ups over state-of-the-art approximate MMD tests with no loss of power.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.05974v3</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Mon, 31 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Carles Domingo-Enrich, Raaz Dwivedi, Lester Mackey</dc:creator>
    </item>
    <item>
      <title>Personalised Decision-Making without Counterfactuals</title>
      <link>https://arxiv.org/abs/2301.11976</link>
      <description>arXiv:2301.11976v2 Announce Type: replace-cross 
Abstract: This article is a response to recent proposals by Pearl and others for a new approach to personalised treatment decisions, in contrast to the traditional one based on statistical decision theory. We argue that this approach is dangerously misguided and should not be used in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.11976v2</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 31 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>A. Philip Dawid, Stephen Senn</dc:creator>
    </item>
    <item>
      <title>A Parameter-Efficient Quantum Anomaly Detection Method on a Superconducting Quantum Processor</title>
      <link>https://arxiv.org/abs/2412.16867</link>
      <description>arXiv:2412.16867v3 Announce Type: replace-cross 
Abstract: Quantum machine learning has gained attention for its potential to address computational challenges. However, whether those algorithms can effectively solve practical problems and outperform their classical counterparts, especially on current quantum hardware, remains a critical question. In this work, we propose a novel quantum machine learning method, called Parameter-Efficient Quantum Anomaly Detection (PEQAD), for practical image anomaly detection, which aims to achieve both parameter efficiency and superior accuracy compared to classical models. Emulation results indicate that PEQAD demonstrates favourable recognition capabilities compared to classical baselines, achieving an average accuracy of over 90% on benchmarks with significantly fewer trainable parameters. Theoretical analysis confirms that PEQAD has a comparable expressivity to classical counterparts while requiring only a fraction of the parameters. Furthermore, we demonstrate the first implementation of a quantum anomaly detection method for general image datasets on a superconducting quantum processor. Specifically, we achieve an accuracy of over 80% with only 16 parameters on the device, providing initial evidence of PEQAD's practical viability in the noisy intermediate-scale quantum era and highlighting its significant reduction in parameter requirements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16867v3</guid>
      <category>quant-ph</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 31 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maida Wang, Jinyang Jiang, Peter V. Coveney</dc:creator>
    </item>
  </channel>
</rss>
