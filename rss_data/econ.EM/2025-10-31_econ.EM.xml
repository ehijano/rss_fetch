<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.EM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.EM</link>
    <description>econ.EM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.EM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 31 Oct 2025 04:00:45 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Estimation and Inference in Boundary Discontinuity Designs: Distance-Based Methods</title>
      <link>https://arxiv.org/abs/2510.26051</link>
      <description>arXiv:2510.26051v1 Announce Type: new 
Abstract: We study the statistical properties of nonparametric distance-based (isotropic) local polynomial regression estimators of the boundary average treatment effect curve, a key causal functional parameter capturing heterogeneous treatment effects in boundary discontinuity designs. We present necessary and/or sufficient conditions for identification, estimation, and inference in large samples, both pointwise and uniformly along the boundary. Our theoretical results highlight the crucial role played by the ``regularity'' of the boundary (a one-dimensional manifold) over which identification, estimation, and inference are conducted. Our methods are illustrated with simulated data. Companion general-purpose software is provided.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.26051v1</guid>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matias D. Cattaneo (Rae), Rocio Titiunik (Rae),  Ruiqi (Rae),  Yu</dc:creator>
    </item>
    <item>
      <title>Causal Inference with Groupwise Matching</title>
      <link>https://arxiv.org/abs/2510.26106</link>
      <description>arXiv:2510.26106v1 Announce Type: new 
Abstract: This paper examines methods of causal inference based on groupwise matching when we observe multiple large groups of individuals over several periods. We formulate causal inference validity through a generalized matching condition, generalizing the parallel trend assumption in difference-in-differences designs. We show that difference-in-differences, synthetic control, and synthetic difference-in-differences designs are distinguished by the specific matching conditions that they invoke. Through regret analysis, we demonstrate that difference-in-differences and synthetic control with differencing are complementary; the former dominates the latter if and only if the latter's extrapolation error exceeds the former's matching error up to a term vanishing at the parametric rate. The analysis also reveals that synthetic control with differencing is equivalent to difference-in-differences when the parallel trend assumption holds for both the pre-treatment and post-treatment periods. We develop a statistical inference procedure based on synthetic control with differencing and present an empirical application demonstrating its usefulness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.26106v1</guid>
      <category>econ.EM</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ratzanyel Rinc\'on, Kyungchul Song</dc:creator>
    </item>
    <item>
      <title>Tests of exogeneity in duration models with censored data</title>
      <link>https://arxiv.org/abs/2510.26613</link>
      <description>arXiv:2510.26613v1 Announce Type: new 
Abstract: Consider the setting in which a researcher is interested in the causal effect of a treatment $Z$ on a duration time $T$, which is subject to right censoring. We assume that $T=\varphi(X,Z,U)$, where $X$ is a vector of baseline covariates, $\varphi(X,Z,U)$ is strictly increasing in the error term $U$ for each $(X,Z)$ and $U\sim \mathcal{U}[0,1]$. Therefore, the model is nonparametric and nonseparable. We propose nonparametric tests for the hypothesis that $Z$ is exogenous, meaning that $Z$ is independent of $U$ given $X$. The test statistics rely on an instrumental variable $W$ that is independent of $U$ given $X$. We assume that $X,W$ and $Z$ are all categorical. Test statistics are constructed for the hypothesis that the conditional rank $V_T= F_{T \mid X,Z}(T \mid X,Z)$ is independent of $(X,W)$ jointly. Under an identifiability condition on $\varphi$, this hypothesis is equivalent to $Z$ being exogenous. However, note that $V_T$ is censored by $V_C =F_{T \mid X,Z}(C \mid X,Z)$, which complicates the construction of the test statistics significantly. We derive the limiting distributions of the proposed tests and prove that our estimator of the distribution of $V_T$ converges to the uniform distribution at a rate faster than the usual parametric $n^{-1/2}$-rate. We demonstrate that the test statistics and bootstrap approximations for the critical values have a good finite sample performance in various Monte Carlo settings. Finally, we illustrate the tests with an empirical application to the National Job Training Partnership Act (JTPA) Study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.26613v1</guid>
      <category>econ.EM</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gilles Crommen, Ingrid Van Keilegom, Jean-Pierre Florens</dc:creator>
    </item>
    <item>
      <title>In Defense of the Pre-Test: Valid Inference when Testing Violations of Parallel Trends for Difference-in-Differences</title>
      <link>https://arxiv.org/abs/2510.26470</link>
      <description>arXiv:2510.26470v1 Announce Type: cross 
Abstract: The difference-in-differences (DID) research design is a key identification strategy which allows researchers to estimate causal effects under the parallel trends assumption. While the parallel trends assumption is counterfactual and cannot be tested directly, researchers often examine pre-treatment periods to check whether the time trends are parallel before treatment is administered. Recently, researchers have been cautioned against using preliminary tests which aim to detect violations of parallel trends in the pre-treatment period. In this paper, we argue that preliminary testing can -- and should -- play an important role within the DID research design. We propose a new and more substantively appropriate conditional extrapolation assumption, which requires an analyst to conduct a preliminary test to determine whether the severity of pre-treatment parallel trend violations falls below an acceptable level before extrapolation to the post-treatment period is justified. This stands in contrast to prior work which can be interpreted as either setting the acceptable level to be exactly zero (in which case preliminary tests lack power) or assuming that extrapolation is always justified (in which case preliminary tests are not required). Under mild assumptions on how close the actual violation is to the acceptable level, we provide a consistent preliminary test as well confidence intervals which are valid when conditioned on the result of the test. The conditional coverage of these intervals overcomes a common critique made against the use of preliminary testing within the DID research design. We use real data as well as numerical simulations to illustrate the performance of the proposed methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.26470v1</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jonas M. Mikhaeil, Christopher Harshaw</dc:creator>
    </item>
    <item>
      <title>Bridging the Gap between Empirical Welfare Maximization and Conditional Average Treatment Effect Estimation in Policy Learning</title>
      <link>https://arxiv.org/abs/2510.26723</link>
      <description>arXiv:2510.26723v1 Announce Type: cross 
Abstract: The goal of policy learning is to train a policy function that recommends a treatment given covariates to maximize population welfare. There are two major approaches in policy learning: the empirical welfare maximization (EWM) approach and the plug-in approach. The EWM approach is analogous to a classification problem, where one first builds an estimator of the population welfare, which is a functional of policy functions, and then trains a policy by maximizing the estimated welfare. In contrast, the plug-in approach is based on regression, where one first estimates the conditional average treatment effect (CATE) and then recommends the treatment with the highest estimated outcome. This study bridges the gap between the two approaches by showing that both are based on essentially the same optimization problem. In particular, we prove an exact equivalence between EWM and least squares over a reparameterization of the policy class. As a consequence, the two approaches are interchangeable in several respects and share the same theoretical guarantees under common conditions. Leveraging this equivalence, we propose a novel regularization method for policy learning. Our findings yield a convex and computationally efficient training procedure that avoids the NP-hard combinatorial step typically required in EWM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.26723v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Masahiro Kato</dc:creator>
    </item>
    <item>
      <title>A Unified Theory for Causal Inference: Direct Debiased Machine Learning via Bregman-Riesz Regression</title>
      <link>https://arxiv.org/abs/2510.26783</link>
      <description>arXiv:2510.26783v1 Announce Type: cross 
Abstract: This note introduces a unified theory for causal inference that integrates Riesz regression, covariate balancing, density-ratio estimation (DRE), targeted maximum likelihood estimation (TMLE), and the matching estimator in average treatment effect (ATE) estimation. In ATE estimation, the balancing weights and the regression functions of the outcome play important roles, where the balancing weights are referred to as the Riesz representer, bias-correction term, and clever covariates, depending on the context. Riesz regression, covariate balancing, DRE, and the matching estimator are methods for estimating the balancing weights, where Riesz regression is essentially equivalent to DRE in the ATE context, the matching estimator is a special case of DRE, and DRE is in a dual relationship with covariate balancing. TMLE is a method for constructing regression function estimators such that the leading bias term becomes zero. Nearest Neighbor Matching is equivalent to Least Squares Density Ratio Estimation and Riesz Regression.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.26783v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Masahiro Kato</dc:creator>
    </item>
    <item>
      <title>Estimation and Inference in Boundary Discontinuity Designs: Location-Based Methods</title>
      <link>https://arxiv.org/abs/2505.05670</link>
      <description>arXiv:2505.05670v2 Announce Type: replace 
Abstract: Boundary discontinuity designs are used to learn about causal treatment effects along a continuous assignment boundary that splits units into control and treatment groups according to a bivariate location score. We analyze the statistical properties of local polynomial treatment effect estimators employing location information for each unit. We develop pointwise and uniform estimation and inference methods for both the conditional treatment effect function at the assignment boundary as well as for transformations thereof, which aggregate information along the boundary. We illustrate our methods with an empirical application. Companion general-purpose software is provided.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.05670v2</guid>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matias D. Cattaneo, Rocio Titiunik, Ruiqi Rae Yu</dc:creator>
    </item>
    <item>
      <title>Semiparametric Learning of Integral Functionals on Submanifolds</title>
      <link>https://arxiv.org/abs/2507.12673</link>
      <description>arXiv:2507.12673v2 Announce Type: replace 
Abstract: This paper studies the semiparametric estimation and inference of integral functionals on submanifolds, which arise naturally in a variety of econometric settings. For linear integral functionals on a regular submanifold, we show that the semiparametric plug-in estimatorattains the minimax-optimal convergence rate $n^{-\frac{s}{2s+d-m}}$, where $s$ is the H\"{o}lder smoothness order of the underlying nonparametric function, $d$ is the dimension of the first-stage nonparametric estimation, $m$ is the dimension of the submanifold over which the integral is taken. This rate coincides with the standard minimax-optimal rate for a $(d-m)$-dimensional nonparametric estimation problem, illustrating that integration over the $m$-dimensional manifold effectively reduces the problem's dimensionality. We then provide a general asymptotic normality theorem for linear/nonlinear submanifold integrals, along with a consistent variance estimator. We provide simulation evidence in support of our theoretical results. In a companion paper, Chen, Chen &amp; Gao (2025), we apply the main results of this paper to the inference problem on the welfare and value of a policy treatment under first-best treatment assignment, and conduct an empirical illustration using the JTPA data set.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.12673v2</guid>
      <category>econ.EM</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaohong Chen, Wayne Yuan Gao</dc:creator>
    </item>
    <item>
      <title>Direct Debiased Machine Learning via Bregman Divergence Minimization</title>
      <link>https://arxiv.org/abs/2510.23534</link>
      <description>arXiv:2510.23534v2 Announce Type: replace 
Abstract: We develop a direct debiased machine learning framework comprising Neyman targeted estimation and generalized Riesz regression. Our framework unifies Riesz regression for automatic debiased machine learning, covariate balancing, targeted maximum likelihood estimation (TMLE), and density-ratio estimation. In many problems involving causal effects or structural models, the parameters of interest depend on regression functions. Plugging regression functions estimated by machine learning methods into the identifying equations can yield poor performance because of first-stage bias. To reduce such bias, debiased machine learning employs Neyman orthogonal estimating equations. Debiased machine learning typically requires estimation of the Riesz representer and the regression function. For this problem, we develop a direct debiased machine learning framework with an end-to-end algorithm. We formulate estimation of the nuisance parameters, the regression function and the Riesz representer, as minimizing the discrepancy between Neyman orthogonal scores computed with known and unknown nuisance parameters, which we refer to as Neyman targeted estimation. Neyman targeted estimation includes Riesz representer estimation, and we measure discrepancies using the Bregman divergence. The Bregman divergence encompasses various loss functions as special cases, where the squared loss yields Riesz regression and the Kullback-Leibler divergence yields entropy balancing. We refer to this Riesz representer estimation as generalized Riesz regression. Neyman targeted estimation also yields TMLE as a special case for regression function estimation. Furthermore, for specific pairs of models and Riesz representer estimation methods, we can automatically obtain the covariate balancing property without explicitly solving the covariate balancing objective.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.23534v2</guid>
      <category>econ.EM</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Masahiro Kato</dc:creator>
    </item>
    <item>
      <title>Structured Lasso for convex nonparametric least squares: An application to Swedish electricity distribution networks</title>
      <link>https://arxiv.org/abs/2409.01911</link>
      <description>arXiv:2409.01911v4 Announce Type: replace-cross 
Abstract: We study the problem of variable selection in convex nonparametric least squares (CNLS). Whereas the least absolute shrinkage and selection operator (Lasso) is a popular technique for least squares, its variable selection performance is unknown in CNLS problems. In this work, we investigate the performance of the Lasso estimator and find out it is usually unable to select variables efficiently. Exploiting the unique structure of the subgradients in CNLS, we develop a structured Lasso method by combining $\ell_1$-norm and $\ell_{\infty}$-norm. The relaxed version of the structured Lasso is proposed for achieving model sparsity and predictive performance simultaneously, where we can control the two effects--variable selection and model shrinkage--using separate tuning parameters. A Monte Carlo study is implemented to verify the finite sample performance of the proposed approaches. We also use real data from Swedish electricity distribution networks to illustrate the effects of the proposed variable selection techniques. The results from the simulation and application confirm that the proposed structured Lasso performs favorably, generally leading to sparser and more accurate predictive models, relative to the conventional Lasso methods in the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.01911v4</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <pubDate>Fri, 31 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhiqiang Liao, Zhaonan Qu</dc:creator>
    </item>
  </channel>
</rss>
