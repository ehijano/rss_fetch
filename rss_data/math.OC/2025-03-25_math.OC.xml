<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 26 Mar 2025 02:15:08 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A nonlocal degenerate macroscopic model of traffic dynamics with saturated diffusion: modeling and calibration theory</title>
      <link>https://arxiv.org/abs/2503.17413</link>
      <description>arXiv:2503.17413v1 Announce Type: new 
Abstract: In this work, we introduce a novel first-order nonlocal partial differential equation with saturated diffusion to describe the macroscopic behavior of traffic dynamics. We show how the proposed model is better in comparison with existing models in explaining the underlying driver behavior in real traffic data. In doing so, we introduce a methodology for adjusting the parameters of the proposed PDE with respect to the distribution of real datasets. In particular, we conceptually and analytically elaborate on how such calibration connects the solution of the PDE to the probability transition kernel proposed by the datasets.
  The performance of the model is thoroughly investigated with respect to several metrics. More precisely, we study the capability of the model in capturing the probability distribution realized by the datasets in the form of the fundamental diagram. We show that the model is capable of approximating the dynamics of the evolution of the probability distribution. To this end, we evaluate the performance of the model with regard to the congestion formation and dissipation scenarios from various datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.17413v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Dawson Do, Hossein Nick Zinat Matin, Masuma Mollika Mitti, Maria Laura Delle Monache</dc:creator>
    </item>
    <item>
      <title>Distributed Stochastic Zeroth-Order Optimization with Compressed Communication</title>
      <link>https://arxiv.org/abs/2503.17429</link>
      <description>arXiv:2503.17429v2 Announce Type: new 
Abstract: The dual challenges of prohibitive communication overhead and the impracticality of gradient computation due to data privacy or black-box constraints in distributed systems motivate this work on communication-constrained gradient-free optimization. We propose a stochastic distributed zeroth-order algorithm (Com-DSZO) requiring only two function evaluations per iteration, integrated with general compression operators. Rigorous analysis establishes its sublinear convergence rate for both smooth and nonsmooth objectives, while explicitly elucidating the compression-convergence trade-off. Furthermore, we develop a variance-reduced variant (VR-Com-DSZO) under stochastic mini-batch feedback. The empirical algorithm performance are illustrated with numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.17429v2</guid>
      <category>math.OC</category>
      <category>cs.MA</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Youqing Hua, Shuai Liu, Yiguang Hong, Wei Ren</dc:creator>
    </item>
    <item>
      <title>Adjoint Sensitivities for the Optimization of Nonlinear Structural Dynamics via Spectral Submanifolds</title>
      <link>https://arxiv.org/abs/2503.17431</link>
      <description>arXiv:2503.17431v1 Announce Type: new 
Abstract: This work presents an optimization framework for tailoring the nonlinear dynamic response of lightly damped mechanical systems using Spectral Submanifold (SSM) reduction. We derive the SSM-based backbone curve and its sensitivity with respect to parameters up to arbitrary polynomial orders, enabling efficient and accurate optimization of the nonlinear frequency-amplitude relation. We use the adjoint method to derive sensitivity expressions, which drastically reduces the computational cost compared to direct differentiation as the number of parameters increases. An important feature of this framework is the automatic adjustment of the expansion order of SSM-based ROMs using user-defined error tolerances during the optimization process. We demonstrate the effectiveness of the approach in optimizing the nonlinear response over several numerical examples of mechanical systems. Hence, the proposed framework extends the applicability of SSM-based optimization methods to practical engineering problems, offering a robust tool for the design and optimization of nonlinear mechanical structures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.17431v1</guid>
      <category>math.OC</category>
      <category>cs.CE</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matteo Pozzi, Jacopo Marconi, Shobhit Jain, Mingwu Li, Francesco Braghin</dc:creator>
    </item>
    <item>
      <title>Optimization over Trained Neural Networks: Difference-of-Convex Algorithm and Application to Data Center Scheduling</title>
      <link>https://arxiv.org/abs/2503.17506</link>
      <description>arXiv:2503.17506v1 Announce Type: new 
Abstract: When solving decision-making problems with mathematical optimization, some constraints or objectives may lack analytic expressions but can be approximated from data. When an approximation is made by neural networks, the underlying problem becomes optimization over trained neural networks. Despite recent improvements with cutting planes, relaxations, and heuristics, the problem remains difficult to solve in practice. We propose a new solution based on a bilinear problem reformulation that penalizes ReLU constraints in the objective function. This reformulation makes the problem amenable to efficient difference-of-convex algorithms (DCA), for which we propose a principled approach to penalty selection that facilitates convergence to stationary points of the original problem. We apply the DCA to the problem of the least-cost allocation of data center electricity demand in a power grid, reporting significant savings in congested cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.17506v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Xinwei Liu, Vladimir Dvorkin</dc:creator>
    </item>
    <item>
      <title>A Two-Stage Stochastic Model for Road-Rail Intermodal Freight Transportation Under Demand and Capacity Uncertainty</title>
      <link>https://arxiv.org/abs/2503.17510</link>
      <description>arXiv:2503.17510v1 Announce Type: new 
Abstract: With the steady increase in global logistics and freight transport demand, the need for efficient and sustainable intermodal transport systems becomes increasingly important. This study addresses the optimization of container movement by intermodal transport with fixed train schedules. We emphasize the integration of road-rail intermodal transport amid uncertain demand and train (spot) capacities. A two-stage stochastic optimization model is developed to strategically manage the transportation of containers from multiple origins to designated intermodal hubs. By leveraging spot capacities at train stations and addressing uncertainties in demand and train capacity, the model integrates Conditional Value-at-Risk (CVaR) to balance cost efficiency and risk management, enabling robust decision-making under uncertainty. The model's objectives encompass minimizing transportation costs, mitigating carbon emissions, and enhancing the reliability of containerized freight movement across the network. A comprehensive case study using real-world data demonstrates the practical applicability of the model, highlighting its effectiveness in reducing operational costs, minimizing environmental impacts, and providing actionable insights for stakeholders to navigate the trade-offs between expected costs and risk management in dynamic intermodal transport settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.17510v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jeremiah Gbadegoye, Mustafa C. Camur, Xueping Li</dc:creator>
    </item>
    <item>
      <title>A Relaxed Primal-Dual Hybrid Gradient Method with Line Search</title>
      <link>https://arxiv.org/abs/2503.17575</link>
      <description>arXiv:2503.17575v1 Announce Type: new 
Abstract: The primal-dual hybrid gradient method (PDHG) is useful for optimization problems that commonly appear in image reconstruction. A downside of PDHG is that there are typically three user-set parameters and performance of the algorithm is sensitive to their values. Toward a parameter-free algorithm, we combine two existing line searches. The first, by Malitsky et al., is over two of the step sizes in the PDHG iterations. We then use the connection between PDHG and the primal-dual form of Douglas-Rachford splitting to construct a line search over the relaxation parameter. We demonstrate the efficacy of the combined line search on multiple problems, including a novel inverse problem in magnetic resonance image reconstruction. The method presented in this manuscript is the first parameter-free variant of PDHG (across all numerical experiments, there were no changes to line search hyperparameters).</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.17575v1</guid>
      <category>math.OC</category>
      <category>eess.IV</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alex McManus, Stephen Becker, Nicholas Dwork</dc:creator>
    </item>
    <item>
      <title>Time-optimal neural feedback control of nilpotent systems as a binary classification problem</title>
      <link>https://arxiv.org/abs/2503.17581</link>
      <description>arXiv:2503.17581v1 Announce Type: new 
Abstract: A computational method for the synthesis of time-optimal feedback control laws for linear nilpotent systems is proposed. The method is based on the use of the bang-bang theorem, which leads to a characterization of the time-optimal trajectory as a parameter-dependent polynomial system for the control switching sequence. A deflated Newton's method is then applied to exhaust all the real roots of the polynomial system. The root-finding procedure is informed by the Hermite quadratic form, which provides a sharp estimate on the number of real roots to be found. In the second part of the paper, the polynomial systems are sampled and solved to generate a synthetic dataset for the construction of a time-optimal deep neural network -- interpreted as a binary classifier -- via supervised learning. Numerical tests in integrators of increasing dimension assess the accuracy, robustness, and real-time-control capabilities of the approximate control law.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.17581v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sara Bicego, Samuel Gue, Dante Kalise, Nelly Villamizar</dc:creator>
    </item>
    <item>
      <title>Infinite Horizon Mean-Field Linear-Quadratic Optimal Control Problems with Switching and Indefinite-Weighted Costs</title>
      <link>https://arxiv.org/abs/2503.17622</link>
      <description>arXiv:2503.17622v1 Announce Type: new 
Abstract: This paper is concerned with an infinite horizon stochastic linear quadratic (LQ, for short) optimal control problems with conditional mean-field terms in a switching environment. Different from [17], the cost functionals do not have positive-definite weights here. When the problems are merely finite, we construct a sequence of asymptotic optimal controls and derive their closed-loop representations. For the solvability, an equivalence result between the open-loop and closed-loop cases is established through algebraic Riccati equations and infinite horizon backward stochastic differential equations. It can be seen that the research in [17] with positive-definite weights is a special case of the current paper.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.17622v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongwei Mei, Rui Wang, Qingmeng Wei, Jiongmin Yong</dc:creator>
    </item>
    <item>
      <title>On the Hopf-Cole Transform for Control-affine Schr\"{o}dinger Bridge</title>
      <link>https://arxiv.org/abs/2503.17640</link>
      <description>arXiv:2503.17640v1 Announce Type: new 
Abstract: The purpose of this note is to clarify the importance of the relation $\boldsymbol{gg}^{\top}\propto \boldsymbol{\sigma\sigma}^{\top}$ in solving control-affine Schr\"{o}dinger bridge problems via the Hopf-Cole transform, where $\boldsymbol{g},\boldsymbol{\sigma}$ are the control and noise coefficients, respectively. We show that the Hopf-Cole transform applied to the conditions of optimality for generic control-affine Schr\"{o}dinger bridge problems, i.e., without the assumption $\boldsymbol{gg}^{\top}\propto\boldsymbol{\sigma\sigma}^{\top}$, gives a pair of forward-backward PDEs that are neither linear nor equation-level decoupled. We explain how the resulting PDEs can be interpreted as nonlinear forward-backward advection-diffusion-reaction equations, where the nonlinearity stem from additional drift and reaction terms involving the gradient of the log-likelihood a.k.a. the score. These additional drift and reaction vanish when $\boldsymbol{gg}^{\top}\propto\boldsymbol{\sigma\sigma}^{\top}$, and the resulting boundary-coupled system of linear PDEs can then be solved by dynamic Sinkhorn recursions. A key takeaway of our work is that the numerical solution of the generic control-affine Schr\"{o}dinger bridge requires further algorithmic development, possibly generalizing the dynamic Sinkhorn recursion or otherwise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.17640v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>stat.ML</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexis Teter, Abhishek Halder</dc:creator>
    </item>
    <item>
      <title>Directional differentiability for solution operators of sweeping processes with convex polyhedral admissible sets</title>
      <link>https://arxiv.org/abs/2503.17740</link>
      <description>arXiv:2503.17740v1 Announce Type: new 
Abstract: We study directional differentiability properties of solution operators of rate-independent evolution variational inequalities with full-dimensional convex polyhedral admissible sets. It is shown that, if the space of continuous functions of bounded variation is used as the domain of definition, then the most prototypical examples of such solution operators - the vector play and stop - are Hadamard directionally differentiable in a pointwise manner if and only if the admissible set is non-obtuse. We further prove that, in those cases where they exist, the directional derivatives of the vector play and stop are uniquely characterized by a system of projection identities and variational inequalities and that directional differentiability cannot be expected in the obtuse case even if the solution operator is restricted to the space of Lipschitz continuous functions. Our results can be used, for example, to formulate Bouligand stationarity conditions for optimal control problems involving sweeping processes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.17740v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Martin Brokate, Constantin Christof</dc:creator>
    </item>
    <item>
      <title>Solving Schr\"{o}dinger bridge problem via continuous normalizing flow</title>
      <link>https://arxiv.org/abs/2503.17829</link>
      <description>arXiv:2503.17829v1 Announce Type: new 
Abstract: The Schr\"{o}dinger Bridge Problem (SBP), which can be understood as an entropy-regularized optimal transport, seeks to compute stochastic dynamic mappings connecting two given distributions. SBP has shown significant theoretical importance and broad practical potential, with applications spanning a wide range of interdisciplinary fields. While theoretical aspects of the SBP are well-understood, practical computational solutions for general cases have remained challenging. This work introduces a computational framework that leverages continuous normalizing flows and score matching methods to approximate the drift in the dynamic formulation of the SBP. The learned drift term can be used for building generative models, opening new possibilities for applications in probability flow-based methods. We also provide a rigorous $\Gamma-$convergence analysis for our algorithm, demonstrating that the neuron network solutions converge to the theoretical ones as the regularization parameter tends to infinity. Lastly, we validate our algorithm through numerical experiments on fundamental cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.17829v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yang Jing, Lei Li, Jingtong Zhang</dc:creator>
    </item>
    <item>
      <title>Adaptive Robust Optimization Models for DER Planning in Distribution Networks under Long- and Short-Term Uncertainties</title>
      <link>https://arxiv.org/abs/2503.17839</link>
      <description>arXiv:2503.17839v1 Announce Type: new 
Abstract: This study introduces adaptive robust optimization (ARO) and adaptive robust stochastic optimization (ARSO) approaches to address long- and short-term uncertainties in the optimal sizing and placement of distributed energy resources in distribution networks. ARO models uncertainty using a Budget of Uncertainty (BoU), while ARSO distinguishes long-term (LT) demand (via BoU) and short-term (ST) photovoltaics generation (via scenarios). Adapted Benders cutting plane algorithms are presented to tackle the tri-level optimization challenges. The experiments consider a modified version of the IEEE 33 bus system to test these two approaches and also compare them with traditional robust and stochastic optimization models. The results indicate that distinguishing between LT and ST uncertainties using a hybrid formulation such ARSO yields a solution closer to the optimal solution under perfect information than ARO.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.17839v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fernando Garc\'ia-Mu\~noz, Cristian Duran-Mateluna</dc:creator>
    </item>
    <item>
      <title>Learning algorithms for mean field optimal control</title>
      <link>https://arxiv.org/abs/2503.17869</link>
      <description>arXiv:2503.17869v1 Announce Type: new 
Abstract: We analyze an algorithm to numerically solve the mean-field optimal control problems by approximating the optimal feedback controls using neural networks with problem specific architectures. We approximate the model by an $N$-particle system and leverage the exchangeability of the particles to obtain substantial computational efficiency. In addition to several numerical examples, a convergence analysis is provided. We also developed a universal approximation theorem on Wasserstein spaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.17869v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>H. Mete Soner, Josef Teichmann, Qinxin Yan</dc:creator>
    </item>
    <item>
      <title>On classical solutions in the stabilization problem for nonholonomic control systems with time-varying feedback laws</title>
      <link>https://arxiv.org/abs/2503.18006</link>
      <description>arXiv:2503.18006v1 Announce Type: new 
Abstract: We consider the stabilization problem for driftless control-affine systems under the bracket-generating condition. In our previous works, a class of time-varying feedback laws has been constructed to stabilize the equilibrium of a nonholonomic system under rather general controllability assumptions. This stabilization scheme is based on the sampling concept, which is not equivalent to the classical definition of solutions for the corresponding nonautonomous closed-loop system. In the present paper, we refine the previous results by presenting sufficient conditions for the convergence of classical solutions of the closed-loop system to the equilibrium. Our theoretical findings are applied to a multidimensional driftless control-affine system and illustrated through numerical simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.18006v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexander Zuyev, Victoria Grushkovskaya</dc:creator>
    </item>
    <item>
      <title>Variational formulation of planar linearized elasticity with incompatible kinematics</title>
      <link>https://arxiv.org/abs/2503.18053</link>
      <description>arXiv:2503.18053v1 Announce Type: new 
Abstract: We present a variational characterization of mechanical equilibrium in the planar strain regime for systems with incompatible kinematics. For non-simply connected domains, we show that the equilibrium problem for a non-liftable strain-stress pair can be reformulated as a well-posed minimization problem for the Airy potential of the system. We characterize kinematic incompatibilities on internal boundaries as rotational or translational mismatches, in agreement with Volterra's modeling of disclinations and dislocations. Finally, we establish that the minimization problem for the Airy potential can be reduced to a finite-dimensional optimization involving cell formulas.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.18053v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pierluigi Cesana, Edoardo Fabbrini, Marco Morandotti</dc:creator>
    </item>
    <item>
      <title>Linear, nested, and quadratic ordered measures: Computation and incorporation into optimization problems</title>
      <link>https://arxiv.org/abs/2503.18097</link>
      <description>arXiv:2503.18097v1 Announce Type: new 
Abstract: In this paper we address a unified mathematical optimization framework to compute a wide range of measures used in most operations research and data science contexts. The goal is to embed such metrics within general optimization models allowing their efficient computation. We assess the usefulness of this approach applying it to three different families of measures, namely linear, nested, and quadratic ordered measures. Computational results are reported showing the efficiency and accuracy of our methods as compared with standard implementations in numerical software packages. Finally, we illustrate this methodology by computing a number of optimal solutions with respect to different metrics on three well-known linear and combinatorial optimization problems: scenario analysis in linear programming, the traveling salesman and the weighted multicover set problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.18097v1</guid>
      <category>math.OC</category>
      <category>cs.DM</category>
      <category>stat.CO</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Victor Blanco, Miguel A. Pozo, Justo Puerto, Alberto Torrejon</dc:creator>
    </item>
    <item>
      <title>Forward-backward splitting under the light of generalized convexity</title>
      <link>https://arxiv.org/abs/2503.18098</link>
      <description>arXiv:2503.18098v1 Announce Type: new 
Abstract: In this paper we present a unifying framework for continuous optimization methods grounded in the concept of generalized convexity. Utilizing the powerful theory of $\Phi$-convexity, we propose a conceptual algorithm that extends the classical difference-of-convex method, encompassing a broad spectrum of optimization algorithms. Relying exclusively on the tools of generalized convexity we develop a gap function analysis that strictly characterizes the decrease of the function values, leading to simplified and unified convergence results. As an outcome of this analysis, we naturally obtain a generalized PL inequality which ensures $q$-linear convergence rates of the proposed method, incorporating various well-established conditions from the existing literature. Moreover we propose a $\Phi$-Bregman proximal point interpretation of the scheme that allows us to capture conditions that lead to sublinear rates under convexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.18098v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Konstantinos Oikonomidis, Emanuel Laude, Panagiotis Patrinos</dc:creator>
    </item>
    <item>
      <title>Active Inference for Energy Control and Planning in Smart Buildings and Communities</title>
      <link>https://arxiv.org/abs/2503.18161</link>
      <description>arXiv:2503.18161v1 Announce Type: new 
Abstract: Active Inference (AIF) is emerging as a powerful framework for decision-making under uncertainty, yet its potential in engineering applications remains largely unexplored. In this work, we propose a novel dual-layer AIF architecture that addresses both building-level and community-level energy management. By leveraging the free energy principle, each layer adapts to evolving conditions and handles partial observability without extensive sensor information and respecting data privacy. We validate the continuous AIF model against both a perfect optimization baseline and a reinforcement learning-based approach. We also test the community AIF framework under extreme pricing scenarios. The results highlight the model's robustness in handling abrupt changes. This study is the first to show how a distributed AIF works in engineering. It also highlights new opportunities for privacy-preserving and uncertainty-aware control strategies in engineering applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.18161v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Seyyed Danial Nazemi, Mohsen A. Jafari, Andrea Matta</dc:creator>
    </item>
    <item>
      <title>Closest univariate convex linear-quadratic function approximation with minimal number of Pieces</title>
      <link>https://arxiv.org/abs/2503.18164</link>
      <description>arXiv:2503.18164v1 Announce Type: new 
Abstract: We compute the closest convex piecewise linear-quadratic (PLQ) function with minimal number of pieces to a given univariate piecewise linear-quadratic function. The Euclidean norm is used to measure the distance between functions. First, we assume that the number and positions of the breakpoints of the output function are fixed, and solve a convex optimization problem. Next, we assume the number of breakpoints is fixed, but not their position, and solve a nonconvex optimization problem to determine optimal breakpoints placement. Finally, we propose an algorithm composed of a greedy search preprocessing and a dichotomic search that solves a logarithmic number of optimization problems to obtain an approximation of any PLQ function with minimal number of pieces thereby obtaining in two steps the closest convex function with minimal number of pieces.
  We illustrate our algorithms with multiple examples, compare our approach with a previous globally optimal univariate spline approximation algorithm, and apply our method to simplify vertical alignment curves in road design optimization. CPLEX, Gurobi, and BARON are used with the YALMIP library in MATLAB to effectively select the most efficient solver.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.18164v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:journal_reference>Journal of Convex Analysis 32 (2025), No. 2, 467--486</arxiv:journal_reference>
      <dc:creator>Namrata Kundu, Yves Lucet</dc:creator>
    </item>
    <item>
      <title>Ordering and refining path-complete Lyapunov functions through composition lifts</title>
      <link>https://arxiv.org/abs/2503.18189</link>
      <description>arXiv:2503.18189v1 Announce Type: new 
Abstract: A fruitful approach to study stability of switched systems is to look for multiple Lyapunov functions. However, in general, we do not yet understand the interplay between the desired stability certificate, the template of the Lyapunov functions and their mutual relationships to accommodate switching. In this work we elaborate on path-complete Lyapunov functions: a graphical framework that aims to elucidate this interplay. In particular, previously, several preorders were introduced to compare multiple Lyapunov functions. These preorders are initially algorithmically intractable due to the algebraic nature of Lyapunov inequalities, yet, lifting techniques were proposed to turn some preorders purely combinatorial and thereby eventually tractable. In this note we show that a conjecture in this area regarding the so-called composition lift, that was believed to be true, is false. This refutal, however, points us to a beneficial structural feature of the composition lift that we exploit to iteratively refine path-complete graphs, plus, it points us to a favourable adaptation of the composition lift.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.18189v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wouter Jongeneel, Rapha\"el M. Jungers</dc:creator>
    </item>
    <item>
      <title>Optimal consumption under adjustment costs with respect to multiple reference levels</title>
      <link>https://arxiv.org/abs/2503.18443</link>
      <description>arXiv:2503.18443v1 Announce Type: new 
Abstract: This paper studies a type of consumption preference where some adjustment costs are incured whenever the past spending maximum and the past spending minimum records are updated. This preference can capture the adverse effects of the historical consumption high and low values on the agent's consumption performance, thereby matching with some empirically observed smooth consumption patterns. By employing the dual transform, the smooth-fit conditions and the super-contact conditions, we obtain the closed-form solution of the dual PDE problem, and can characterize the optimal investment and consumption controls in the piecewise feedback form. We provide the rigorous proof of the verification theorem and compensate the theoretical findings with some numerical examples and financial implications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.18443v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yijie Huang, Kaixin Yan, Qinyi Zhang</dc:creator>
    </item>
    <item>
      <title>Feasibility of multiple robust control barrier functions for bounding box constraints</title>
      <link>https://arxiv.org/abs/2503.18524</link>
      <description>arXiv:2503.18524v1 Announce Type: new 
Abstract: Enforcing multiple constraints based on the concept of control barrier functions (CBFs) is a remaining challenge because each of the CBFs requires a condition on the control inputs to be satisfied which may easily lead to infeasibility problems. The problem becomes even more challenging with input constraints and disturbances. In this paper, we consider enforcement of bounding box constraints for a second order system under limited control authority and input disturbances. To solve the constrained control problem, we apply multiple robust control barrier functions (RCBFs) which, in general, do not provide a feasible solution to the problem. However, we derive conditions on how to select the RCBF parameters to guarantee that a feasible solution always exists.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.18524v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mark Spiller, Emilia Isbono, Philipp Schitz</dc:creator>
    </item>
    <item>
      <title>Optimization under uncertainty</title>
      <link>https://arxiv.org/abs/2503.18561</link>
      <description>arXiv:2503.18561v1 Announce Type: new 
Abstract: One of the most ubiquitous problems in optimization is that of finding all the elements of a finite set at which a function $f$ attains its minimum (or maximum) on that set. When the codomain of $f$ is equipped with a reflexive, anti-symmetric and transitive relation, it is easy to specify, implement and verify generic solutions for this problem. But what if $f$ is affected by uncertainties? What if one seeks values that minimize more than one $f$ or if $f$ does not return a single result but a set of ``possible results'' or perhaps a probability distribution on possible results? This situation is very common in integrated assessment and optimal design and developing trustable solution methods for optimization under uncertainty requires one to formulate the above questions rigorously. We show how functional programming can help formulating such questions and apply it to specify and test solution methods for the case in which optimization is affected by two conceptually different kinds of uncertainty: \it{value} and \it{functorial} uncertainty.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.18561v1</guid>
      <category>math.OC</category>
      <category>cs.SE</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicola Botta, Patrik Jansson, Tim Richter</dc:creator>
    </item>
    <item>
      <title>A linear Convergence result for the Jacobi-Proximal Alternating Direction Method of Multipliers</title>
      <link>https://arxiv.org/abs/2503.18601</link>
      <description>arXiv:2503.18601v1 Announce Type: new 
Abstract: In this paper, we analyze the convergence rate of the Jacobi-Proximal Alternating Direction Method of Multipliers (ADMM), a method initially introduced by Deng et al. for the block-structured optimization problem with linear constraint. We establish the linear convergence of the algorithm when the cost functions are strongly convex and smooth.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.18601v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hyelin Choi, Woocheol Choi</dc:creator>
    </item>
    <item>
      <title>AttenMfg: An Attention Network Based Optimization Framework for Sensor-Driven Operations &amp; Maintenance in Manufacturing Systems</title>
      <link>https://arxiv.org/abs/2503.18780</link>
      <description>arXiv:2503.18780v1 Announce Type: new 
Abstract: Operations and maintenance (O&amp;M) scheduling is a critical problem in leased manufacturing systems, with significant implications for operational efficiency, cost optimization, and machine reliability. Solving this problem involves navigating complex trade-offs between machine-level degradation risks, production throughput, and maintenance team logistics across multi-site manufacturing networks. Conventional approaches rely on large-scale Mixed Integer Programming (MIP) models, which, while capable of yielding optimal solutions, suffer from prolonged computational times and scalability limitations. To overcome these challenges, we propose AttenMfg, a novel decision-making framework that leverages multi-head attention (MHA), tailored for complex optimization problems. The proposed framework incorporates several key innovations, including constraint-aware masking procedures and novel reward functions that explicitly embed mathematical programming formulations into the MHA structure. The resulting attention-based model (i) reduces solution times from hours to seconds, (ii) ensures feasibility of the generated schedules under operational and logistical constraints, (iii) achieves solution quality on par with exact MIP formulations, and (iv) demonstrates strong generalizability across diverse problem settings. These results highlight the potential of attention-based learning to revolutionize O&amp;M scheduling in leased manufacturing systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.18780v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Iman Kazemian, Murat Yildirim, Paritosh Ramanan</dc:creator>
    </item>
    <item>
      <title>Benign landscapes for synchronization on spheres via normalized Laplacian matrices</title>
      <link>https://arxiv.org/abs/2503.18801</link>
      <description>arXiv:2503.18801v1 Announce Type: new 
Abstract: We study the nonconvex optimization landscapes of synchronization problems on spheres. First, we present new results for the statistical problem of synchronization over the two-element group $\mathbf{Z}_2$. We consider the nonconvex least-squares problem with $\mathbf{Z}_2 = \{\pm 1\}$ relaxed to the unit sphere in $\mathbf{R}^r$ for $r \geq 2$; for several popular models, including graph clustering under the binary stochastic block model, we show that, for any $r \geq 2$, every second-order critical point recovers the ground truth in the asymptotic regimes where exact recovery is information-theoretically possible. Such statistical optimality via spherical relaxations had previously only been shown for (potentially arbitrarily) larger relaxation dimension $r$. Second, we consider the global synchronization of networks of coupled oscillators under the (homogeneous) Kuramoto model. We prove new and optimal asymptotic results for random signed networks on an Erd\H{o}s--R\'enyi graph, and we give new and simple proofs for several existing state-of-the-art results. Our key tool is a deterministic landscape condition that extends a recent result of Rakoto Endor and Waldspurger. This result says that, if a certain problem-dependent Laplacian matrix has small enough condition number, the nonconvex landscape is benign. Our extension allows the condition number to include an arbitrary diagonal preconditioner, which gives tighter results for many problems. We show that, for the synchronization of Kuramoto oscillator networks on nearest-neighbor circulant graphs as studied by Wiley, Strogatz, and Girvan, this condition is optimal. We also prove a natural complex extension that may be of interest for synchronization on the special orthogonal group $\operatorname{SO}(2)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.18801v1</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrew D. McRae</dc:creator>
    </item>
    <item>
      <title>Formalization of Algorithms for Optimization with Block Structures</title>
      <link>https://arxiv.org/abs/2503.18806</link>
      <description>arXiv:2503.18806v1 Announce Type: new 
Abstract: Block-structured problems are central to advances in numerical optimization and machine learning. This paper provides the formalization of convergence analysis for two pivotal algorithms in such settings: the block coordinate descent (BCD) method and the alternating direction method of multipliers (ADMM). Utilizing the type-theory-based proof assistant Lean4, we develop a rigorous framework to formally represent these algorithms. Essential concepts in nonsmooth and nonconvex optimization are formalized, notably subdifferentials, which extend the classical differentiability to handle nonsmooth scenarios, and the Kurdyka-Lojasiewicz (KL) property, which provides essential tools to analyze convergence in nonconvex settings. Such definitions and properties are crucial for the corresponding convergence analyses. We formalize the convergence proofs of these algorithms, demonstrating that our definitions and structures are coherent and robust. These formalizations lay a basis for analyzing the convergence of more general optimization algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.18806v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chenyi Li, Zichen Wang, Yifan Bai, Yunxi Duan, Yuqing Gao, Pengfei Hao, Zaiwen Wen</dc:creator>
    </item>
    <item>
      <title>Formalization of Optimality Conditions for Smooth Constrained Optimization Problems</title>
      <link>https://arxiv.org/abs/2503.18821</link>
      <description>arXiv:2503.18821v1 Announce Type: new 
Abstract: Optimality conditions are central to analysis of optimization problems, characterizing necessary criteria for local minima. Formalizing the optimality conditions within the type-theory-based proof assistant Lean4 provides a precise, robust, and reusable framework essential for rigorous verification in optimization theory. In this paper, we introduce a formalization of the first-order optimality conditions (also known as the Karush-Kuhn-Tucker (KKT) conditions) for smooth constrained optimization problems by beginning with concepts such as the Lagrangian function and constraint qualifications. The geometric optimality conditions are then formalized, offering insights into local minima through tangent cones. We also establish the critical equivalence between the tangent cone and linearized feasible directions under appropriate constraint qualifications. Building on these key elements, the formalization concludes the KKT conditions through the proof of the Farkas lemma. Additionally, this study provides a formalization of the dual problem and the weak duality property.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.18821v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chenyi Li, Shengyang Xu, Chumin Sun, Li Zhou, Zaiwen Wen</dc:creator>
    </item>
    <item>
      <title>The Graph Geometric Control Condition</title>
      <link>https://arxiv.org/abs/2503.18864</link>
      <description>arXiv:2503.18864v1 Announce Type: new 
Abstract: In this paper, we introduce a novel concept called the Graph Geometric Control Condition (GGCC). It turns out to be a simple, geometric rewriting of many of the frameworks in which the controllability of PDEs on graphs has been studied. We prove that (GGCC) is a necessary and sufficient condition for the exact controllability of the wave equation on metric graphs with internal controls and Dirichlet boundary conditions. We then investigate the internal exact controllability of the wave equation with mixed boundary conditions and the one of the Schr\"odinger equation, as well as the internal null-controllability of the heat equation. We show that (GGCC) provides a sufficient condition for the controllability of these equations and we provide explicit examples proving that (GGCC) is not necessary in these cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.18864v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Ka\"is Ammari, Alessandro Duca, Romain Joly, K\'evin Le Balc'h</dc:creator>
    </item>
    <item>
      <title>Characterization of Local Maximal Monotonicity through Graphical Derivatives</title>
      <link>https://arxiv.org/abs/2503.18867</link>
      <description>arXiv:2503.18867v1 Announce Type: new 
Abstract: This paper is devoted to study a characterization of (strong) local maximal monotonicity in terms of a property involving the graphical derivative of a set-valued mapping defined on a Hilbert space. As a consequence, a second-order characterization of variational convexity is provided without the assumption of subdifferential continuity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.18867v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Juan Guillermo Garrido</dc:creator>
    </item>
    <item>
      <title>Availability of Perfect Decomposition in Statistical Linkage Learning for Unitation-based Function Concatenations</title>
      <link>https://arxiv.org/abs/2503.17397</link>
      <description>arXiv:2503.17397v1 Announce Type: cross 
Abstract: Statistical Linkage Learning (SLL) is a part of many state-of-the-art optimizers. The purpose of SLL is to discover variable interdependencies. It has been shown that the effectiveness of SLL-using optimizers is highly dependent on the quality of SLL-based problem decomposition. Thus, understanding what kind of problems are hard or easy to decompose by SLL is important for practice. In this work, we analytically estimate the size of a population sufficient for obtaining a perfect decomposition in case of concatenations of certain unitation-based functions. The experimental study confirms the accuracy of the proposed estimate. Finally, using the proposed estimate, we identify those problem types that may be considered hard for SLL-using optimizers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.17397v1</guid>
      <category>cs.NE</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Michal Prusik, Bartosz Frej, Michal W. Przewozniczek</dc:creator>
    </item>
    <item>
      <title>Sharp Hybrid Zonotopes: Set Operations and the Reformulation-linearization Technique</title>
      <link>https://arxiv.org/abs/2503.17483</link>
      <description>arXiv:2503.17483v1 Announce Type: cross 
Abstract: Mixed integer set representations, and specifically hybrid zonotopes, have enabled new techniques for reachability and verification of nonlinear and hybrid systems. Mixed-integer sets which have the property that their convex relaxation is equal to their convex hull are said to be sharp. This property allows the convex hull to be computed with minimal overhead, and is known to be important for improving the convergence rates of mixed-integer optimization algorithms that rely on convex relaxations. This paper examines methods for formulating sharp hybrid zonotopes and provides sharpness-preserving methods for performing several key set operations. The paper then shows how the reformulation-linearization technique can be applied to create a sharp realization of a hybrid zonotope that is initially not sharp. A numerical example applies this technique to find the convex hull of a level set of a feedforward ReLU neural network.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.17483v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jonah J. Glunt, Joshua A. Robbins, Daniel Silvestre, Herschel C. Pangborn</dc:creator>
    </item>
    <item>
      <title>Dual Block Gradient Ascent for Entropically Regularised Quantum Optimal Transport</title>
      <link>https://arxiv.org/abs/2503.17590</link>
      <description>arXiv:2503.17590v1 Announce Type: cross 
Abstract: We present a block gradient ascent method for solving the quantum optimal transport problem with entropic regularisation similar to the algorithm proposed in [D. Feliciangeli, A. Gerolin, L. Portinale: J. Funct. Anal. 285 (2023), no. 4, 109963] and [E. Caputo, A. Gerolin, N. Monina, L. Portinale: arXiv:2409.03698]. We prove a linear convergence rate based on strong concavity of the dual functional and present some results of numerical experiments of an implementation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.17590v1</guid>
      <category>math-ph</category>
      <category>cs.NA</category>
      <category>math.MP</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marvin Randig, Max von Renesse</dc:creator>
    </item>
    <item>
      <title>Planning and Learning in Average Risk-aware MDPs</title>
      <link>https://arxiv.org/abs/2503.17629</link>
      <description>arXiv:2503.17629v1 Announce Type: cross 
Abstract: For continuing tasks, average cost Markov decision processes have well-documented value and can be solved using efficient algorithms. However, it explicitly assumes that the agent is risk-neutral. In this work, we extend risk-neutral algorithms to accommodate the more general class of dynamic risk measures. Specifically, we propose a relative value iteration (RVI) algorithm for planning and design two model-free Q-learning algorithms, namely a generic algorithm based on the multi-level Monte Carlo method, and an off-policy algorithm dedicated to utility-base shortfall risk measures. Both the RVI and MLMC-based Q-learning algorithms are proven to converge to optimality. Numerical experiments validate our analysis, confirms empirically the convergence of the off-policy algorithm, and demonstrate that our approach enables the identification of policies that are finely tuned to the intricate risk-awareness of the agent that they serve.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.17629v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Weikai Wang, Erick Delage</dc:creator>
    </item>
    <item>
      <title>Bayesian Optimization for CVaR-based portfolio optimization</title>
      <link>https://arxiv.org/abs/2503.17737</link>
      <description>arXiv:2503.17737v1 Announce Type: cross 
Abstract: Optimal portfolio allocation is often formulated as a constrained risk problem, where one aims to minimize a risk measure subject to some performance constraints. This paper presents new Bayesian Optimization algorithms for such constrained minimization problems, seeking to minimize the conditional value-at-risk (a computationally intensive risk measure) under a minimum expected return constraint. The proposed algorithms utilize a new acquisition function, which drives sampling towards the optimal region. Additionally, a new two-stage procedure is developed, which significantly reduces the number of evaluations of the expensive-to-evaluate objective function. The proposed algorithm's competitive performance is demonstrated through practical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.17737v1</guid>
      <category>q-fin.PM</category>
      <category>math.OC</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Robert Millar, Jinglai Li</dc:creator>
    </item>
    <item>
      <title>Tensor-based homogeneous polynomial dynamical system analysis from data</title>
      <link>https://arxiv.org/abs/2503.17774</link>
      <description>arXiv:2503.17774v1 Announce Type: cross 
Abstract: Numerous complex real-world systems, such as those in biological, ecological, and social networks, exhibit higher-order interactions that are often modeled using polynomial dynamical systems or homogeneous polynomial dynamical systems (HPDSs). However, identifying system parameters and analyzing key system-theoretic properties remain challenging due to their inherent nonlinearity and complexity, particularly for large-scale systems. To address these challenges, we develop an innovative computational framework in this article that leverages advanced tensor decomposition techniques, namely tensor train and hierarchical Tucker decompositions, to facilitate efficient identification and analysis of HPDSs that can be equivalently represented by tensors. Specifically, we introduce memory-efficient system identification techniques for directly estimating system parameters represented through tensor decompositions from time-series data. Additionally, we develop necessary and sufficient conditions for determining controllability and observability using the tensor decomposition-based representations of HPDSs, accompanied by detailed complexity analyses that demonstrate significant reductions in computational demands. The effectiveness and efficiency of our framework are validated through numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.17774v1</guid>
      <category>math.DS</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xin Mao, Anqi Dong, Ziqin He, Yidan Mei, Shenghan Mei, Can Chen</dc:creator>
    </item>
    <item>
      <title>Finite-Time Bounds for Two-Time-Scale Stochastic Approximation with Arbitrary Norm Contractions and Markovian Noise</title>
      <link>https://arxiv.org/abs/2503.18391</link>
      <description>arXiv:2503.18391v1 Announce Type: cross 
Abstract: Two-time-scale Stochastic Approximation (SA) is an iterative algorithm with applications in reinforcement learning and optimization. Prior finite time analysis of such algorithms has focused on fixed point iterations with mappings contractive under Euclidean norm. Motivated by applications in reinforcement learning, we give the first mean square bound on non linear two-time-scale SA where the iterations have arbitrary norm contractive mappings and Markovian noise. We show that the mean square error decays at a rate of $O(1/n^{2/3})$ in the general case, and at a rate of $O(1/n)$ in a special case where the slower timescale is noiseless. Our analysis uses the generalized Moreau envelope to handle the arbitrary norm contractions and solutions of Poisson equation to deal with the Markovian noise. By analyzing the SSP Q-Learning algorithm, we give the first $O(1/n)$ bound for an algorithm for asynchronous control of MDPs under the average reward criterion. We also obtain a rate of $O(1/n)$ for Q-Learning with Polyak-averaging and provide an algorithm for learning Generalized Nash Equilibrium (GNE) for strongly monotone games which converges at a rate of $O(1/n^{2/3})$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.18391v1</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Siddharth Chandak, Shaan Ul Haque, Nicholas Bambos</dc:creator>
    </item>
    <item>
      <title>Constraint Horizon in Model Predictive Control</title>
      <link>https://arxiv.org/abs/2503.18521</link>
      <description>arXiv:2503.18521v1 Announce Type: cross 
Abstract: In this work, we propose a Model Predictive Control (MPC) formulation incorporating two distinct horizons: a prediction horizon and a constraint horizon. This approach enables a deeper understanding of how constraints influence key system properties such as suboptimality, without compromising recursive feasibility and constraint satisfaction. In this direction, our contributions are twofold. First, we provide a framework to estimate closed-loop optimality as a function of the number of enforced constraints. This is a generalization of existing results by considering partial constraint enforcement over the prediction horizon. Second, when adopting this general framework under the lens of safety-critical applications, our method improves conventional Control Barrier Function (CBF) based approaches. It mitigates myopic behaviour in Quadratic Programming (QP)-CBF schemes, and resolves compatibility issues between Control Lyapunov Function (CLF) and CBF constraints via the prediction horizon used in the optimization. We show the efficacy of the method via numerical simulations for a safety critical application.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.18521v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Allan Andre Do Nascimento, Han Wang, Antonis Papachristodoulou, Kostas Margellos</dc:creator>
    </item>
    <item>
      <title>Asymptotics of the quantization problem on metric measure spaces</title>
      <link>https://arxiv.org/abs/2503.18779</link>
      <description>arXiv:2503.18779v1 Announce Type: cross 
Abstract: The problem of quantization of measures looks for best approximations of probability measures on a metric space by discrete measures supported on $N$ points, where the error of approximation is measured with respect to the Wasserstein distance. Zador's theorem states that, for measures on $\mathbb{R}^d$ or $d$-dimensional Riemannian manifolds satisfying appropriate integrability conditions, the quantization error decays to zero as $N \to \infty$ at the rate $N^{-1/d}$.
  In this paper, we provide a general treatment of the asymptotics of quantization on metric measure spaces $(X, \nu)$. We show that a weaker version of Zador's theorem involving the Hausdorff densities of $\nu$ holds also in this general setting. We also prove Zador's theorem in full for appropriate $m$-rectifiable measures on Euclidean space, answering a conjecture by Graf and Luschgy in the affirmative. For both results, the higher integrability conditions of Zador's theorem are replaced with a general notion of $(p,s)$-quantizability, which follows from Pierce-type (non-asymptotic) upper bounds on the quantization error, and we also prove multiple such bounds at the level of metric measure spaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.18779v1</guid>
      <category>math.MG</category>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ata Deniz Aydin</dc:creator>
    </item>
    <item>
      <title>Sample-Efficient Reinforcement Learning of Koopman eNMPC</title>
      <link>https://arxiv.org/abs/2503.18787</link>
      <description>arXiv:2503.18787v1 Announce Type: cross 
Abstract: Reinforcement learning (RL) can be used to tune data-driven (economic) nonlinear model predictive controllers ((e)NMPCs) for optimal performance in a specific control task by optimizing the dynamic model or parameters in the policy's objective function or constraints, such as state bounds. However, the sample efficiency of RL is crucial, and to improve it, we combine a model-based RL algorithm with our published method that turns Koopman (e)NMPCs into automatically differentiable policies. We apply our approach to an eNMPC case study of a continuous stirred-tank reactor (CSTR) model from the literature. The approach outperforms benchmark methods, i.e., data-driven eNMPCs using models based on system identification without further RL tuning of the resulting policy, and neural network controllers trained with model-based RL, by achieving superior control performance and higher sample efficiency. Furthermore, utilizing partial prior knowledge about the system dynamics via physics-informed learning further increases sample efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.18787v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel Mayfrank, Mehmet Velioglu, Alexander Mitsos, Manuel Dahmen</dc:creator>
    </item>
    <item>
      <title>Admission Control for A Single Server Waiting Time Process in Heavy Traffic</title>
      <link>https://arxiv.org/abs/2212.05674</link>
      <description>arXiv:2212.05674v2 Announce Type: replace 
Abstract: We address a single server queue control problem (QCP) in heavy traffic originating from Lee and Weerasinghe (2011). The state process represents the offered waiting time, the customer arrival has a state-dependent intensity, and the customers' service and patience times are i.i.d with general distributions. We introduce an infinite-horizon discounted cost functional consisting of a control cost generated from the use of control and a penalty for idleness cost. Our primary goal is to tackle the QCP, taking into account a non-trivial control cost and a non-increasing cost function resulting from the control mechanisms in the waiting time. Under mild assumptions, the heavy traffic limit of the QCP yields a stochastic control problem described by a diffusion process, which we call a diffusion control problem (DCP). We find the optimal control of the associated DCP by incorporating the Legendre-Fenchel transform and a formal Hamilton-Jacobi-Bellman (HJB) equation. Then, we ``translate'' this optimal strategy to the QCP, of which we obtain an asymptotically optimal policy. Apart from theoretical results, we also examine the REINFORCE algorithm, a Reinforcement learning (RL) approach, for solving stochastic controls motivated by recent literature. We highlight the advantages and limitations of simulation from theoretical results and data-driven algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.05674v2</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bowen Xie, Haoyu Yin</dc:creator>
    </item>
    <item>
      <title>Maximum Principle of Stochastic Optimal Control Problems with Model Uncertainty</title>
      <link>https://arxiv.org/abs/2309.10454</link>
      <description>arXiv:2309.10454v4 Announce Type: replace 
Abstract: This paper is concerned with the maximum principle of stochastic optimal control problems, where the coefficients of the state equation and the cost functional are uncertain, and the system is generally under Markovian regime switching. Firstly, the $ L^\beta$-solutions of forward-backward stochastic differential equations with regime switching are given. Secondly, we obtain the variational inequality by making use of the continuity of solutions to variational equations with respect to the uncertainty parameter $\theta$. Thirdly, utilizing the linearization and weak convergence techniques, we prove the necessary stochastic maximum principle and provide sufficient conditions for the stochastic optimal control. Finally, as an application, a risk-minimizing portfolio selection problem is studied.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.10454v4</guid>
      <category>math.OC</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tao Hao, Jiaqiang Wen, Jie Xiong</dc:creator>
    </item>
    <item>
      <title>Iterative approximations of periodic trajectories for nonlinear systems with discontinuous inputs</title>
      <link>https://arxiv.org/abs/2401.00310</link>
      <description>arXiv:2401.00310v3 Announce Type: replace 
Abstract: Nonlinear control-affine systems described by ordinary differential equations with bounded measurable input functions are considered. The problem of the existence of periodic trajectories for these systems is formulated in the sense of Carath\'eodory solutions. It is shown that, under the dominant linearization assumption, the periodic boundary value problem admits a unique solution for any admissible control. This solution can be obtained as the limit of the proposed simple iterative scheme and Newton-type methods. Under additional technical assumptions, sufficient contraction conditions of the corresponding generating operators are derived analytically. The proposed iterative approach is applied for the computation of periodic solutions of a realistic chemical reaction model with discontinuous control inputs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.00310v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexander Zuyev, Peter Benner</dc:creator>
    </item>
    <item>
      <title>Multimodal urban transportation network equilibrium including intermodality and shared mobility services</title>
      <link>https://arxiv.org/abs/2402.00735</link>
      <description>arXiv:2402.00735v4 Announce Type: replace 
Abstract: Shared Mobility Services (SMSs) are reshaping urban transportation systems by providing flexible mobility options. With their ability to decrease the number of cars on the roads, these services can potentially improve the transportation system's performance in terms of travel times and emissions. This emphasizes the importance of analyzing and understanding their impacts on the system and users' choices, especially when integrated into a complex multi-modal system, including public transport (PT). Many studies overlook the synergies between SMSs and PT, leading to inaccurate traffic estimations and planning. This research offers an extensive review of multi-modal transportation system models involving SMSs. We then introduce a traffic assignment analytical model valid in both continuous and integer settings, leading to a Mixed-Integer Bilinear Programming (MIBLP) formulation. This model comprises diverse travel possibilities, including SMSs, and handles intermodality by allowing commuters to combine modes to optimize time and monetary expense. An in-depth examination of commuters' mode and path choices on two test cases and an analysis of the price of anarchy highlights the disparities between user equilibrium and system optimum in such intricate systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.00735v4</guid>
      <category>math.OC</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Khadidja Kadem, Mostafa Ameli, Mahdi Zargayouna, Latifa Oukhellou</dc:creator>
    </item>
    <item>
      <title>Adaptive generalized conditional gradient method for multiobjective optimization</title>
      <link>https://arxiv.org/abs/2404.04174</link>
      <description>arXiv:2404.04174v3 Announce Type: replace 
Abstract: In this paper, we propose a generalized conditional gradient method for multiobjective optimization, which can be viewed as an improved extension of the classical Frank-Wolfe (conditional gradient) method for single-objective optimization. The proposed method works for both constrained and unconstrained benchmark multiobjective optimization problems, where the objective function is the summation of a smooth function and a possibly nonsmooth convex function. The method combines the so-called normalized descent direction as an adaptive procedure and the line search technique. We prove the convergence of the algorithm with respect to Pareto optimality under mild assumptions. The iteration complexity for obtaining an approximate Pareto critical point and the convergence rate in terms of a merit function is also analyzed. Finally, we report some numerical results, which demonstrate the feasibility and competitiveness of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.04174v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anteneh Getachew Gebrie, Ellen Hidemi Fukuda</dc:creator>
    </item>
    <item>
      <title>Asymptotic Nash Equilibria of Finite-State Ergodic Markovian Mean Field Games</title>
      <link>https://arxiv.org/abs/2404.11695</link>
      <description>arXiv:2404.11695v2 Announce Type: replace 
Abstract: Mean field games (MFGs) model equilibria in games with a continuum of weakly interacting players as limiting systems of symmetric $n$-player games. We consider the finite-state, infinite-horizon problem with ergodic cost. Assuming Markovian strategies, we first prove that any solution to the MFG system gives rise to a $(C/\sqrt{n})$-Nash equilibrium in the $n$-player game. We follow this result by proving the same is true for the strategy profile derived from the master equation. We conclude the main theoretical portion of the paper by establishing a large deviation principle for empirical measures associated with the asymptotic Nash equilibria. Then, we contrast the asymptotic Nash equilibria using an example. We solve the MFG system directly and numerically solve the ergodic master equation by adapting the deep Galerkin method of Sirignano and Spiliopoulos. We use these results to derive the strategies of the asymptotic Nash equilibria and compare them. Finally, we derive an explicit form for the rate functions in dimension two.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11695v2</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Asaf Cohen, Ethan Zell</dc:creator>
    </item>
    <item>
      <title>Linear-Quadratic Mean Field Stackelberg Stochastic Differential Game with Partial Information and Common Noise</title>
      <link>https://arxiv.org/abs/2405.03102</link>
      <description>arXiv:2405.03102v2 Announce Type: replace 
Abstract: This paper is concerned with a linear-quadratic mean field Stackelberg stochastic differential game with partial information and common noise, which contains a leader and a large number of followers. To be specific, the followers face a large population Nash game after the leader first announces his strategy, while the leader will then optimize his own cost functional on consideration of the followers' reactions. The state equation of the leader and followers are both general stochastic differential equations, where the diffusion terms contain both the control and state variables. However, the followers' average state terms enter into the drift term of the leader's state equation, reflecting that the leader's state is influenced by the followers' states. By virtue of stochastic maximum principle with partial information and optimal filter technique, we deduce the open-loop adapted decentralized strategies and feedback decentralized strategies of this leader-followers system, and demonstrate that the decentralized strategies are the corresponding $\varepsilon$-Stackelberg-Nash equilibrium.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03102v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Yu Si, Jingtao Shi</dc:creator>
    </item>
    <item>
      <title>A Riemannian Proximal Newton-CG Method</title>
      <link>https://arxiv.org/abs/2405.08365</link>
      <description>arXiv:2405.08365v2 Announce Type: replace 
Abstract: Recently, a Riemannian proximal Newton method has been developed for optimizing problems in the form of $\min_{x\in\mathcal{M}} f(x) + \mu \|x\|_1$, where $\mathcal{M}$ is a compact embedded submanifold and $f(x)$ is smooth. Although this method converges superlinearly locally, global convergence is not guaranteed. The existing remedy relies on a hybrid approach: running a Riemannian proximal gradient method until the iterate is sufficiently accurate and switching to the Riemannian proximal Newton method. This existing approach is sensitive to the switching parameter. This paper proposes a Riemannian proximal Newton-CG method that merges the truncated conjugate gradient method with the Riemannian proximal Newton method. The global convergence and local superlinear convergence are proven. Numerical experiments show that the proposed method outperforms other state-of-the-art methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.08365v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wen Huang, Wutao Si</dc:creator>
    </item>
    <item>
      <title>Entropy annealing for policy mirror descent in continuous time and space</title>
      <link>https://arxiv.org/abs/2405.20250</link>
      <description>arXiv:2405.20250v3 Announce Type: replace 
Abstract: Entropy regularization has been widely used in policy optimization algorithms to enhance exploration and the robustness of the optimal control; however it also introduces an additional regularization bias. This work quantifies the impact of entropy regularization on the convergence of policy gradient methods for stochastic exit time control problems. We analyze a continuous-time policy mirror descent dynamics, which updates the policy based on the gradient of an entropy-regularized value function and adjusts the strength of entropy regularization as the algorithm progresses. We prove that with a fixed entropy level, the mirror descent dynamics converges exponentially to the optimal solution of the regularized problem. We further show that when the entropy level decays at suitable polynomial rates, the annealed flow converges to the solution of the unregularized problem at a rate of $\mathcal O(1/S)$ for discrete action spaces and, under suitable conditions, at a rate of $\mathcal O(1/\sqrt{S})$ for general action spaces, with $S$ being the gradient flow running time. The technical challenge lies in analyzing the gradient flow in the infinite-dimensional space of Markov kernels for nonconvex objectives. This paper explains how entropy regularization improves policy optimization, even with the true gradient, from the perspective of convergence rate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20250v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Deven Sethi, David \v{S}i\v{s}ka, Yufei Zhang</dc:creator>
    </item>
    <item>
      <title>Mean-field stochastic linear quadratic control problem with random coefficients</title>
      <link>https://arxiv.org/abs/2406.04621</link>
      <description>arXiv:2406.04621v4 Announce Type: replace 
Abstract: In this paper, we first prove that the mean-field stochastic linear quadratic (MFSLQ for short) control problem with random coefficients has a unique optimal control and derive a preliminary stochastic maximum principle to characterize this optimal control by an optimality system. However, because of the term of the form $\mathbb{E}[A_1(\cdot)^\top Y(\cdot)] $ in the adjoint equation, which cannot be represented in the form $\mathbb{E}[A_1(\cdot)^\top]\mathbb{E} [Y(\cdot)] $, we cannot solve this optimality system explicitly. To this end, we decompose the MFSLQ control problem into two problems without the mean-field terms, and one of them is a constrained problem. The constrained SLQ control problem is solved explicitly by an extended LaGrange multiplier method developed in this article.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04621v4</guid>
      <category>math.OC</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jie Xiong, Wen Xu</dc:creator>
    </item>
    <item>
      <title>Non-overshooting continuous in convergence sliding mode control of second-order systems</title>
      <link>https://arxiv.org/abs/2406.14000</link>
      <description>arXiv:2406.14000v3 Announce Type: replace 
Abstract: This paper proposes a novel nonlinear sliding mode state feedback controller for perturbed second-order systems. In analogy to a linear proportional-derivative (PD) feedback control, the proposed nonlinear scheme uses the output of interest and its time derivative. The control has only one free design parameter, and the closed-loop system is shown to possess uniform boundedness and finite-time convergence of trajectories in the presence of matched disturbances. We derive a strict Lyapunov function for the closed-loop control system with a bounded exogenous perturbation, and use it for both, the control parameter tuning and analysis of the finite-time convergence. The essential features of the proposed new control law is non-overshooting despite the unknown dynamic disturbances and the continuous control action during the convergence to zero equilibrium. Apart from the numerical results, a revealing experimental example is also shown in favor of the proposed control and in comparison with PD and sub-optimal nonlinear damping regulators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.14000v3</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Ruderman, Denis Efimov</dc:creator>
    </item>
    <item>
      <title>Improving Convergence Guarantees of Random Subspace Second-order Algorithm for Nonconvex Optimization</title>
      <link>https://arxiv.org/abs/2406.14337</link>
      <description>arXiv:2406.14337v2 Announce Type: replace 
Abstract: In recent years, random subspace methods have been actively studied for large-dimensional nonconvex problems. Recent subspace methods have improved theoretical guarantees such as iteration complexity and local convergence rate while reducing computational costs by deriving descent directions in randomly selected low-dimensional subspaces. This paper proposes the Random Subspace Homogenized Trust Region (RSHTR) method with the best theoretical guarantees among random subspace algorithms for nonconvex optimization. RSHTR achieves an $\varepsilon$-approximate first-order stationary point in $O(\varepsilon^{-3/2})$ iterations, converging locally at a linear rate. Furthermore, under rank-deficient conditions, RSHTR satisfies $\varepsilon$-approximate second-order necessary conditions in $O(\varepsilon^{-3/2})$ iterations and exhibits a local quadratic convergence. Experiments on real-world datasets verify the benefits of RSHTR.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.14337v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rei Higuchi, Pierre-Louis Poirion, Akiko Takeda</dc:creator>
    </item>
    <item>
      <title>Hedging Hydrogen: Planning and Contracting Under Uncertainty for a Green Hydrogen Producer</title>
      <link>https://arxiv.org/abs/2407.21574</link>
      <description>arXiv:2407.21574v2 Announce Type: replace 
Abstract: Green hydrogen production by water electrolysis using renewable electricity is considered essential for decarbonisation of certain sectors of the global economy, however development of the industry is lagging behind expectations due to the perceived financial risk for individual projects. This risk stems from a number of uncertainties, including future hydrogen demand, variable renewable energy sources, and volatile energy market prices. The interaction of these uncertainties is complex, yet the analysis of hydrogen projects is often carried out using simplified modelling. In this study, we define a set of planning methods (planning policies) in order to compare the effectiveness of different modelling approaches. We propose a 2-stage market-focused stochastic program to represent a hydrogen producer supplying an industrial customer through a hydrogen offtake contract (a Hydrogen Purchase Agreement, or HPA). The model can be used to obtain equipment sizing decisions, as well as energy hedging decisions using Power Purchase Agreements (PPA's) and power futures. We find that for some HPA contract types, failure to use stochastic modelling can result in planning decisions that will perform 30% worse during scenario stress-testing for the same project. This could lead to some projects being incorrectly discarded. The results also show the importance of negotiating demand-side uncertainty in HPA contract negotiations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.21574v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Owen Palmer, Hugo Radet, Simon Camal, Jalal Kazempour, Robin Girard</dc:creator>
    </item>
    <item>
      <title>A Linear Complexity Algorithm for Optimal Transport Problem with Log-type Cost</title>
      <link>https://arxiv.org/abs/2501.06578</link>
      <description>arXiv:2501.06578v2 Announce Type: replace 
Abstract: In [Q. Liao et al., Commun. Math. Sci., 20(2022)], a linear-time Sinkhorn algorithm is developed based on dynamic programming, which significantly reduces the computational complexity involved in solving optimal transport problems. However, this algorithm is specifically designed for the Wasserstein-1 metric. We are curious whether the preceding dynamic programming framework can be extended to tackle optimal transport problems with different transport costs. Notably, two special kinds of optimal transport problems, the Sinkhorn ranking and the far-field reflector and refractor problems, are closely associated with the log-type transport costs. Interestingly, by employing series rearrangement and dynamic programming techniques, it is feasible to perform the matrix-vector multiplication within the Sinkhorn iteration in linear time for this type of cost. This paper provides a detailed exposition of its implementation and applications, with numerical simulations demonstrating the effectiveness and efficiency of our methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.06578v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ziyuan Lyu, Zihao Wang, Hao Wu, Shuai Yang</dc:creator>
    </item>
    <item>
      <title>On the Almost Sure Convergence of the Stochastic Three Points Algorithm</title>
      <link>https://arxiv.org/abs/2501.13886</link>
      <description>arXiv:2501.13886v3 Announce Type: replace 
Abstract: The stochastic three points (STP) algorithm is a derivative-free optimization technique designed for unconstrained optimization problems in $\mathbb{R}^d$. In this paper, we analyze this algorithm for three classes of functions: smooth functions that may lack convexity, smooth convex functions, and smooth functions that are strongly convex. Our work provides the first almost sure convergence results of the STP algorithm, alongside some convergence results in expectation. For the class of smooth functions, we establish that the best gradient iterate of the STP algorithm converges almost surely to zero at a rate arbitrarily close to $o(\frac{1}{\sqrt{T}})$, where $T$ is the number of iterations. Furthermore, within the same class of functions, we establish both almost sure convergence and convergence in expectation of the final gradient iterate towards zero. For the class of smooth convex functions, we establish that $f(\theta^T)$ converges to $\inf_{\theta \in \mathbb{R}^d} f(\theta)$ almost surely at a rate arbitrarily close to $o(\frac{1}{T})$, and in expectation at a rate of $O(\frac{d}{T})$ where $d$ is the dimension of the space. Finally, for the class of smooth functions that are strongly convex, we establish that when step sizes are obtained by approximating the directional derivatives of the function, $f(\theta^T)$ converges to $\inf_{\theta \in \mathbb{R}^d} f(\theta)$ in expectation at a rate of $O((1-\frac{\mu}{dL})^T)$, and almost surely at a rate arbitrarily close to $o((1-\frac{\mu}{dL})^T)$, where $\mu$ and $L$ are the strong convexity and smoothness parameters of the function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13886v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Taha El Bakkali, Omar Saadi</dc:creator>
    </item>
    <item>
      <title>Safe Gradient Flow for Bilevel Optimization</title>
      <link>https://arxiv.org/abs/2501.16520</link>
      <description>arXiv:2501.16520v2 Announce Type: replace 
Abstract: Bilevel optimization is a key framework in hierarchical decision-making, where one problem is embedded within the constraints of another. In this work, we propose a control-theoretic approach to solving bilevel optimization problems. Our method consists of two components: a gradient flow mechanism to minimize the upper-level objective and a safety filter to enforce the constraints imposed by the lower-level problem. Together, these components form a safe gradient flow that solves the bilevel problem in a single loop. To improve scalability with respect to the lower-level problem's dimensions, we introduce a relaxed formulation and design a compact variant of the safe gradient flow. This variant minimizes the upper-level objective while ensuring the lower-level decision variable remains within a user-defined suboptimality. Using Lyapunov analysis, we establish convergence guarantees for the dynamics, proving that they converge to a neighborhood of the optimal solution. Numerical experiments further validate the effectiveness of the proposed approaches. Our contributions provide both theoretical insights and practical tools for efficiently solving bilevel optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.16520v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sina Sharifi, Nazanin Abolfazli, Erfan Yazdandoost Hamedani, Mahyar Fazlyab</dc:creator>
    </item>
    <item>
      <title>The Effectiveness of the Operator Splitting Method versus the Implicit Euler Method in Autonomous and Non-Autonomous Systems</title>
      <link>https://arxiv.org/abs/2502.05483</link>
      <description>arXiv:2502.05483v2 Announce Type: replace 
Abstract: We have transformed specific Delay Differential Equations (DDEs) into suitable operator equations within the appropriate function space. Our findings show that both the Implicit Euler method and the Lie-Trotter operator splitting technique effectively approximate the exact solutions of the DDEs in the strong topology. Furthermore, we have established that these operators generate a $ C_0 $-semigroup in the autonomous case, utilizing the Miyadera Perturbation Theorem. In the non-autonomous case, they produce an evolution family using the Chernoff Theorem.
  Instead of directly demonstrating that the Lie-Trotter splitting operator approximates the generator of a $ C_0 $-semigroup or an evolution family, we showed that the Lie-Trotter splitting operator generates the exact solutions of the delay differential equations. We achieved this by proving that the Lie-Trotter splitting operator approximates the Implicit Euler operator, which, in turn, approximates the generator of a $C_0$-semigroup or evolution family. Additionally, we evaluated the discrepancies between the Implicit Euler operator and the Lie-Trotter splitting operator, demonstrating that both operators are controllable and accurate within a specified error range.
  Using numerical computation, we evaluated the Operator Splitting Method's accuracy, stability, convergence, and efficiency by contrasting it with the Implicit Euler method in the autonomous and non-autonomous cases. We will discuss its effectiveness while considering both theory and calculation results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05483v2</guid>
      <category>math.OC</category>
      <category>math.FA</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hideki Kawahara</dc:creator>
    </item>
    <item>
      <title>Lyapunov-like Stability Inequality with an Asymmetric Matrix and Application to Suboptimal LQ Control Design</title>
      <link>https://arxiv.org/abs/2502.11556</link>
      <description>arXiv:2502.11556v4 Announce Type: replace 
Abstract: The Lyapunov inequality is an indispensable tool for stability analysis in the linear control theory. This work proposes a new variant of this inequality where-in the constituent matrix is allowed to be asymmetric. After developing the stability conditions based on the proposed inequality for a class of linear systems, we utilize these conditions to derive new results for the suboptimal linear quadratic control problem where we characterize the cost of the stabilizing controllers. We also demonstrate, by a numerical example, that the proposed results can be easily molded for the structured suboptimal consensus protocol design for multi-agent system where we also see that the asymmetry condition of the design matrix turns up inherently.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.11556v4</guid>
      <category>math.OC</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Avinash Kumar</dc:creator>
    </item>
    <item>
      <title>Quadratic obstructions to Small-Time Local Controllability for the multi-input bilinear Schr\"odinger equation</title>
      <link>https://arxiv.org/abs/2502.14999</link>
      <description>arXiv:2502.14999v2 Announce Type: replace 
Abstract: We investigate the small-time local controllability (STLC) near the ground state of a bilinear Schr\"odinger equation when the linearized system is not controllable. It is well known that, for single-input systems, quadratic terms in the state expansion can then lead to obstructions to the STLC of the nonlinear system. In this work, we extend this phenomenon to the multi-input setting, presenting the first example of multi-input quadratic obstructions for PDEs. Our results build upon our previous study of such obstructions for ODEs and provide a functional framework for analyzing them in the bilinear Schr\"odinger equation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.14999v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Th\'eo Gherdaoui</dc:creator>
    </item>
    <item>
      <title>A Deterministic and Linear Model of Dynamic Optimization</title>
      <link>https://arxiv.org/abs/2502.17012</link>
      <description>arXiv:2502.17012v3 Announce Type: replace 
Abstract: We introduce a model of infinite horizon linear dynamic optimization and obtain results concerning existence of solution and satisfaction of the competitive condition and transversality condition being unconditionally sufficient for optimality of a trajectory. We also show that under some mild restrictions the optimal trajectory satisfies the Euler condition and a related transversality condition. We show that the optimal value function is concave and continuous and the optimal trajectory satisfies the functional equation of dynamic programming. Linearity bites when it comes to the definition of optimal decision rules which can no longer be guaranteed to be single-valued. We show that the optimal decision rule is an upper semi-continuous correspondence. For linear cake-eating problems, we obtain monotonicity results for the optimal value function and a conditional monotonicity result for optimal decision rules. We also introduce the concept of a two-phase linear cake eating problem and obtain a necessary condition that must be satisfied by all solutions of such problems. We show that for a class of linear dynamic optimization problems, known as interlinked linear dynamic optimization problems, a slightly modified version of the functional equation of dynamic programming is satisfied.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.17012v3</guid>
      <category>math.OC</category>
      <category>econ.TH</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Somdeb Lahiri</dc:creator>
    </item>
    <item>
      <title>A Tutorial on Multi-time Scale Optimization Models and Algorithms</title>
      <link>https://arxiv.org/abs/2502.20568</link>
      <description>arXiv:2502.20568v2 Announce Type: replace 
Abstract: Systems across different industries consist of interrelated processes and decisions in different time scales including long-time decisions and short-term decisions. To optimize such systems, the most effective approach is to formulate and solve multi-time scale optimization models that integrate various decision layers. In this tutorial, we provide an overview of multi-time scale optimization models and review the algorithms used to solve them. We also discuss the metric Value of the Multi-scale Model (VMM) introduced to quantify the benefits of using multi-time scale optimization models as opposed to sequentially solving optimization models from high-level to low-level. Finally, we present an illustrative example of a multi-time scale capacity expansion planning model and showcase how it can be solved using some of the algorithms (https://github.com/li-group/MultiScaleOpt-Tutorial.git). This tutorial serves as both an introductory guide for beginners with no prior experience and a high-level overview of current algorithms for solving multi-time scale optimization models, catering to experts in process systems engineering.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.20568v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Asha Ramanujam, Can Li</dc:creator>
    </item>
    <item>
      <title>Kantorovich duality for optimal transport on completely regular Hausdorff spaces</title>
      <link>https://arxiv.org/abs/2503.03929</link>
      <description>arXiv:2503.03929v2 Announce Type: replace 
Abstract: We introduce a new intermediate optimization problem situated between Kantorovich's primal and dual formulations. This new problem extends Kantorovich's duality to separable Baire measures, which are strictly more general than tight (or Radon) measures in completely regular Hausdorff spaces. In the special case where the measures are Radon, our intermediate problem aligns with the classical Kantorovich's primal problem. Existence of solutions for all three formulations are also provided within this comprehensive framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.03929v2</guid>
      <category>math.OC</category>
      <category>math.FA</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohammed Bachir</dc:creator>
    </item>
    <item>
      <title>Choosing Augmentation Parameters in OSQP- A New Approach based on Conjugate Directions</title>
      <link>https://arxiv.org/abs/2503.05941</link>
      <description>arXiv:2503.05941v2 Announce Type: replace 
Abstract: This work proposes a new method to select the augmentation parameters in the operator splitting quadratic program (OSQP) algorithm so as to reduce the computation time of overall algorithm. The selection is based upon the information of conjugate directions of the coefficient matrix of a linear system of equations present in the algorithm. This selection makes it possible to cache these conjugate directions, instead of computing them at each iteration, resulting in faster computation of the solution of the linear system thus reducing the overall computation time. This reduction is demonstrated by a numerical example.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.05941v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Avinash Kumar</dc:creator>
    </item>
    <item>
      <title>Well-posedness and stability of boundary delay equations</title>
      <link>https://arxiv.org/abs/2503.11156</link>
      <description>arXiv:2503.11156v2 Announce Type: replace 
Abstract: In this paper, we introduce the notion of boundary delay equations, establishing a unified framework for analyzing systems with time-delayed boundary conditions. We establish sufficient conditions for the existence, uniqueness, and positivity of solutions. Furthermore, we derive spectral conditions for exponential stability, applicable to a broad class of perturbed boundary value problems. The conditions on the perturbations generalize well-known criteria for the generation of domain perturbations of positive semigroups generators. As an application, we present necessary and sufficient conditions for the exponential stability of positive linear hyperbolic systems with time-delayed boundary conditions, demonstrating the practical relevance of our findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.11156v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yassine El Gantouh, Yang Liu</dc:creator>
    </item>
    <item>
      <title>Fast MLE and MAPE-Based Device Activity Detection for Grant-Free Access via PSCA and PSCA-Net</title>
      <link>https://arxiv.org/abs/2503.15259</link>
      <description>arXiv:2503.15259v2 Announce Type: replace 
Abstract: Fast and accurate device activity detection is the critical challenge in grant-free access for supporting massive machine-type communications (mMTC) and ultra-reliable low-latency communications (URLLC) in 5G and beyond. The state-of-the-art methods have unsatisfactory error rates or computation times. To address these outstanding issues, we propose new maximum likelihood estimation (MLE) and maximum a posterior estimation (MAPE) based device activity detection methods for known and unknown pathloss that achieve superior error rate and computation time tradeoffs using optimization and deep learning techniques. Specifically, we investigate four non-convex optimization problems for MLE and MAPE in the two pathloss cases, with one MAPE problem being formulated for the first time. For each non-convex problem, we develop an innovative parallel iterative algorithm using the parallel successive convex approximation (PSCA) method. Each PSCA-based algorithm allows parallel computations, uses up to the objective function's second-order information, converges to the problem's stationary points, and has a low per-iteration computational complexity compared to the state-of-the-art algorithms. Then, for each PSCA-based iterative algorithm, we present a deep unrolling neural network implementation, called PSCA-Net, to further reduce the computation time. Each PSCA-Net elegantly marries the underlying PSCA-based algorithm's parallel computation mechanism with the parallelizable neural network architecture and effectively optimizes its step sizes based on vast data samples to speed up the convergence. Numerical results demonstrate that the proposed methods can significantly reduce the error rate and computation time compared to the state-of-the-art methods, revealing their significant values for grant-free access.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.15259v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TWC.2025.3545649</arxiv:DOI>
      <dc:creator>Bowen Tan, Ying Cui</dc:creator>
    </item>
    <item>
      <title>Stability of Schr\"odinger bridges and Sinkhorn semigroups for log-concave models</title>
      <link>https://arxiv.org/abs/2503.15963</link>
      <description>arXiv:2503.15963v2 Announce Type: replace 
Abstract: In this article we obtain several new results and developments in the study of entropic optimal transport problems (a.k.a. Schr\"odinger problems) with general reference distributions and log-concave target marginal measures. Our approach combines transportation cost inequalities
  with the theory of Riccati matrix difference equations arising in filtering and optimal control theory. This methodology is partly based on a novel entropic stability of Schr\"odinger bridges and closed form expressions of a class of discrete time algebraic Riccati equations. In the context of regularized entropic transport these techniques provide new sharp entropic map estimates. When applied to the stability of Sinkhorn semigroups, they also yield
  a series of novel contraction estimates in terms of the fixed point of Riccati equations.
  The strength of our approach is that it is applicable to a large class of models arising in machine learning and artificial intelligence algorithms. We illustrate the impact of our results in the context of regularized entropic transport, proximal samplers and diffusion generative models as well as diffusion flow matching models</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.15963v2</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pierre Del Moral</dc:creator>
    </item>
    <item>
      <title>Asymptotics of Proximity Operator for Squared Loss and Performance Prediction of Nonconvex Sparse Signal Recovery</title>
      <link>https://arxiv.org/abs/2103.10300</link>
      <description>arXiv:2103.10300v4 Announce Type: replace-cross 
Abstract: Proximal splitting-based convex optimization is a promising approach to linear inverse problems because we can use some prior knowledge of the unknown variables explicitly. An understanding of the behavior of the optimization algorithms would be important for the tuning of the parameters and the development of new algorithms. In this paper, we first analyze the asymptotic property of the proximity operator for the squared loss function, which appears in the update equations of some proximal splitting methods for linear inverse problems. Our analysis shows that the output of the proximity operator can be characterized with a scalar random variable in the large system limit. Moreover, we apply the asymptotic result to the prediction of optimization algorithms for compressed sensing. Simulation results demonstrate that the MSE performance of the Douglas-Rachford algorithm can be well predicted in compressed sensing with the $\ell_{1}$ optimization. We also examine the behavior of the prediction for the case with nonconvex smoothly clipped absolute deviation (SCAD) and minimax concave penalty (MCP) regularization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2103.10300v4</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ryo Hayakawa</dc:creator>
    </item>
    <item>
      <title>KOALA: A Kalman Optimization Algorithm with Loss Adaptivity</title>
      <link>https://arxiv.org/abs/2107.03331</link>
      <description>arXiv:2107.03331v3 Announce Type: replace-cross 
Abstract: Optimization is often cast as a deterministic problem, where the solution is found through some iterative procedure such as gradient descent. However, when training neural networks the loss function changes over (iteration) time due to the randomized selection of a subset of the samples. This randomization turns the optimization problem into a stochastic one. We propose to consider the loss as a noisy observation with respect to some reference optimum. This interpretation of the loss allows us to adopt Kalman filtering as an optimizer, as its recursive formulation is designed to estimate unknown parameters from noisy measurements. Moreover, we show that the Kalman Filter dynamical model for the evolution of the unknown parameters can be used to capture the gradient dynamics of advanced methods such as Momentum and Adam. We call this stochastic optimization method KOALA, which is short for Kalman Optimization Algorithm with Loss Adaptivity. KOALA is an easy to implement, scalable, and efficient method to train neural networks. We provide convergence analysis and show experimentally that it yields parameter estimates that are on par with or better than existing state of the art optimization algorithms across several neural network architectures and machine learning tasks, such as computer vision and language modeling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2107.03331v3</guid>
      <category>cs.LG</category>
      <category>cs.CV</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aram Davtyan, Sepehr Sameni, Llukman Cerkezi, Givi Meishvilli, Adam Bielski, Paolo Favaro</dc:creator>
    </item>
    <item>
      <title>On the Global Convergence of Risk-Averse Policy Gradient Methods with Expected Conditional Risk Measures</title>
      <link>https://arxiv.org/abs/2301.10932</link>
      <description>arXiv:2301.10932v4 Announce Type: replace-cross 
Abstract: Risk-sensitive reinforcement learning (RL) has become a popular tool for controlling the risk of uncertain outcomes and ensuring reliable performance in highly stochastic sequential decision-making problems. While Policy Gradient (PG) methods have been developed for risk-sensitive RL, it remains unclear if these methods enjoy the same global convergence guarantees as in the risk-neutral case \citep{mei2020global,agarwal2021theory,cen2022fast,bhandari2024global}. In this paper, we consider a class of dynamic time-consistent risk measures, named Expected Conditional Risk Measures (ECRMs), and derive PG and Natural Policy Gradient (NPG) updates for ECRMs-based RL problems. We provide global optimality {and iteration complexities} of the proposed algorithms under the following four settings: (i) PG with constrained direct parameterization, (ii) PG with softmax parameterization and log barrier regularization, (iii) NPG with softmax parameterization and entropy regularization, and (iv) approximate NPG with inexact policy evaluation. Furthermore, we test a risk-averse REINFORCE algorithm \citep{williams1992simple} and a risk-averse NPG algorithm \citep{kakade2001natural} on a stochastic Cliffwalk environment to demonstrate the efficacy of our methods and the importance of risk control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.10932v4</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xian Yu, Lei Ying</dc:creator>
    </item>
    <item>
      <title>Distributed Safe Control Design and Probabilistic Safety Verification for Multi-Agent Systems</title>
      <link>https://arxiv.org/abs/2303.12610</link>
      <description>arXiv:2303.12610v3 Announce Type: replace-cross 
Abstract: We propose distributed iterative algorithms for safe control design and safety verification for networked multi-agent systems. These algorithms rely on distributing a control barrier function (CBF) related quadratic programming (QP) problem assuming the existence of CBFs. The proposed distributed algorithm addresses infeasibility issues of existing schemes via a cooperation mechanism between agents. The resulting control input is guaranteed to be optimal, and satisfies CBF constraints of all agents. Furthermore, a truncated algorithm is proposed to facilitate computational implementation. The performance of the truncated algorithm is evaluated using a distributed safety verification algorithm. The algorithm quantifies safety for multi-agent systems probabilistically by means of CBFs. Both upper and lower bounds on the probability of safety are obtained using the so called scenario approach. Both the scenario sampling and safety verification procedures are fully distributed. The efficacy of our algorithms is demonstrated by an example on multi-robot collision avoidance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.12610v3</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Han Wang, Antonis Papachristodoulou, Kostas Margellos</dc:creator>
    </item>
    <item>
      <title>Minimum-norm solutions of the non-symmetric semidefinite Procrustes problem</title>
      <link>https://arxiv.org/abs/2406.02203</link>
      <description>arXiv:2406.02203v2 Announce Type: replace-cross 
Abstract: Given two matrices $X,B\in \mathbb{R}^{n\times m}$ and a set $\mathcal{A}\subseteq \mathbb{R}^{n\times n}$, a Procrustes problem consists in finding a matrix $A \in \mathcal{A}$ such that the Frobenius norm of $AX-B$ is minimized. When $\mathcal{A}$ is the set of the matrices whose symmetric part is positive semidefinite, we obtain the so-called non-symmetric positive semidefinite Procrustes (NSPDSP) problem. The NSPDSP problem arises in the estimation of compliance or stiffness matrix in solid and elastic structures. If $X$ has rank $r$, Baghel et al. (Lin. Alg. Appl., 2022) proposed a three-step semi-analytical approach: (1) construct a reduced NSPDSP problem in dimension $r\times r$, (2) solve the reduced problem by means of a fast gradient method with a linear rate of convergence, and (3) post-process the solution of the reduced problem to construct a solution of the larger original NSPDSP problem. In this paper, we revisit this approach of Baghel et al. and identify an unnecessary assumption used by the authors leading to cases where their algorithm cannot attain a minimum and produces solutions with unbounded norm. In fact, revising the post-processing phase of their semi-analytical approach, we show that the infimum of the NSPDSP problem is always attained, and we show how to compute a minimum-norm solution. We also prove that the symmetric part of the computed solution has minimum rank bounded by $r$, and that the skew-symmetric part has rank bounded by $2r$. Several numerical examples show the efficiency of this algorithm, both in terms of computational speed and of finding optimal minimum-norm solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.02203v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicolas Gillis, Stefano Sicilia</dc:creator>
    </item>
    <item>
      <title>Large Deviation Upper Bounds and Improved MSE Rates of Nonlinear SGD: Heavy-tailed Noise and Power of Symmetry</title>
      <link>https://arxiv.org/abs/2410.15637</link>
      <description>arXiv:2410.15637v2 Announce Type: replace-cross 
Abstract: We study large deviation upper bounds and mean-squared error (MSE) guarantees of a general framework of nonlinear stochastic gradient methods in the online setting, in the presence of heavy-tailed noise. Unlike existing works that rely on the closed form of a nonlinearity (typically clipping), our framework treats the nonlinearity in a black-box manner, allowing us to provide unified guarantees for a broad class of bounded nonlinearities, including many popular ones, like sign, quantization, normalization, as well as component-wise and joint clipping. We provide several strong results for a broad range of step-sizes in the presence of heavy-tailed noise with symmetric probability density function, positive in a neighbourhood of zero and potentially unbounded moments. In particular, for non-convex costs we provide a large deviation upper bound for the minimum norm-squared of gradients, showing an asymptotic tail decay on an exponential scale, at a rate $\sqrt{t} / \log(t)$. We establish the accompanying rate function, showing an explicit dependence on the choice of step-size, nonlinearity, noise and problem parameters. Next, for non-convex costs and the minimum norm-squared of gradients, we derive the optimal MSE rate $\widetilde{\mathcal{O}}(t^{-1/2})$. Moreover, for strongly convex costs and the last iterate, we provide an MSE rate that can be made arbitrarily close to the optimal rate $\mathcal{O}(t^{-1})$, improving on the state-of-the-art results in the presence of heavy-tailed noise. Finally, we establish almost sure convergence of the minimum norm-squared of gradients, providing an explicit rate, which can be made arbitrarily close to $o(t^{-1/4})$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15637v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aleksandar Armacki, Shuhua Yu, Dragana Bajovic, Dusan Jakovetic, Soummya Kar</dc:creator>
    </item>
    <item>
      <title>Linear Partial Gromov-Wasserstein Embedding</title>
      <link>https://arxiv.org/abs/2410.16669</link>
      <description>arXiv:2410.16669v3 Announce Type: replace-cross 
Abstract: The Gromov-Wasserstein (GW) problem, a variant of the classical optimal transport (OT) problem, has attracted growing interest in the machine learning and data science communities due to its ability to quantify similarity between measures in different metric spaces. However, like the classical OT problem, GW imposes an equal mass constraint between measures, which restricts its application in many machine learning tasks. To address this limitation, the partial Gromov-Wasserstein (PGW) problem has been introduced. It relaxes the equal mass constraint, allowing the comparison of general positive Radon measures. Despite this, both GW and PGW face significant computational challenges due to their non-convex nature. To overcome these challenges, we propose the linear partial Gromov-Wasserstein (LPGW) embedding, a linearized embedding technique for the PGW problem. For $K$ different metric measure spaces, the pairwise computation of the PGW distance requires solving the PGW problem ${O}(K^2)$ times. In contrast, the proposed linearization technique reduces this to ${O}(K)$ times. Similar to the linearization technique for the classical OT problem, we prove that LPGW defines a valid metric for metric measure spaces. Finally, we demonstrate the effectiveness of LPGW in practical applications such as shape retrieval and learning with transport-based embeddings, showing that LPGW preserves the advantages of PGW in partial matching while significantly enhancing computational efficiency. The code is available at https://github.com/mint-vu/Linearized_Partial_Gromov_Wasserstein.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.16669v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yikun Bai, Abihith Kothapalli, Hengrong Du, Rocio Diaz Martin, Soheil Kolouri</dc:creator>
    </item>
    <item>
      <title>A uniform rate of convergence for the entropic potentials in the quadratic Euclidean setting</title>
      <link>https://arxiv.org/abs/2502.00084</link>
      <description>arXiv:2502.00084v2 Announce Type: replace-cross 
Abstract: We bound the rate of uniform convergence in compact sets for both entropic potentials and their gradients towards the Brenier potential and its gradient, respectively. Both results hold in the quadratic Euclidean setting for absolutely continuous measures satisfying some convexity assumptions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.00084v2</guid>
      <category>math.CA</category>
      <category>math.AP</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pablo L\'opez-Rivera</dc:creator>
    </item>
    <item>
      <title>Convergence of Policy Mirror Descent Beyond Compatible Function Approximation</title>
      <link>https://arxiv.org/abs/2502.11033</link>
      <description>arXiv:2502.11033v2 Announce Type: replace-cross 
Abstract: Modern policy optimization methods roughly follow the policy mirror descent (PMD) algorithmic template, for which there are by now numerous theoretical convergence results. However, most of these either target tabular environments, or can be applied effectively only when the class of policies being optimized over satisfies strong closure conditions, which is typically not the case when working with parametric policy classes in large-scale environments. In this work, we develop a theoretical framework for PMD for general policy classes where we replace the closure conditions with a strictly weaker variational gradient dominance assumption, and obtain upper bounds on the rate of convergence to the best-in-class policy. Our main result leverages a novel notion of smoothness with respect to a local norm induced by the occupancy measure of the current policy, and casts PMD as a particular instance of smooth non-convex optimization in non-Euclidean space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.11033v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Uri Sherman, Tomer Koren, Yishay Mansour</dc:creator>
    </item>
  </channel>
</rss>
