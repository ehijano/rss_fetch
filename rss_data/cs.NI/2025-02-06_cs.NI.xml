<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 07 Feb 2025 02:42:56 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Study on 5G Network Slice Isolation Based on Native Cloud and Edge Computing Tools</title>
      <link>https://arxiv.org/abs/2502.02842</link>
      <description>arXiv:2502.02842v1 Announce Type: new 
Abstract: 5G networks support various advanced applications through network slicing, network function virtualization (NFV), and edge computing, ensuring low latency and service isolation. However, private 5G networks relying on open-source tools still face challenges in maturity and integration with edge/cloud platforms, compromising proper slice isolation. This study investigates resource allocation mechanisms to address this issue, conducting experiments in a hospital scenario with medical video conferencing. The results show that CPU limitations improve the performance of prioritized slices, while memory restrictions have minimal impact. The generated data and scripts have been made publicly available for future research and machine learning applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02842v1</guid>
      <category>cs.NI</category>
      <category>cs.DC</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Maiko Andrade, Juliano Araujo Wickboldt</dc:creator>
    </item>
    <item>
      <title>Vertical Federated Learning for Failure-Cause Identification in Disaggregated Microwave Networks</title>
      <link>https://arxiv.org/abs/2502.02874</link>
      <description>arXiv:2502.02874v1 Announce Type: new 
Abstract: Machine Learning (ML) has proven to be a promising solution to provide novel scalable and efficient fault management solutions in modern 5G-and-beyond communication networks. In the context of microwave networks, ML-based solutions have received significant attention. However, current solutions can only be applied to monolithic scenarios in which a single entity (e.g., an operator) manages the entire network. As current network architectures move towards disaggregated communication platforms in which multiple operators and vendors collaborate to achieve cost-efficient and reliable network management, new ML-based approaches for fault management must tackle the challenges of sharing business-critical information due to potential conflicts of interest. In this study, we explore the application of Federated Learning in disaggregated microwave networks for failure-cause identification using a real microwave hardware failure dataset. In particular, we investigate the application of two Vertical Federated Learning (VFL), namely using Split Neural Networks (SplitNNs) and Federated Learning based on Gradient Boosting Decision Trees (FedTree), on different multi-vendor deployment scenarios, and we compare them to a centralized scenario where data is managed by a single entity. Our experimental results show that VFL-based scenarios can achieve F1-Scores consistently within at most a 1% gap with respect to a centralized scenario, regardless of the deployment strategies or model types, while also ensuring minimal leakage of sensitive-data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02874v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fatih Temiz, Memedhe Ibrahimi, Francesco Musumeci, Claudio Passera, Massimo Tornatore</dc:creator>
    </item>
    <item>
      <title>Differentially-Private Multi-Tier Federated Learning: A Formal Analysis and Evaluation</title>
      <link>https://arxiv.org/abs/2502.02877</link>
      <description>arXiv:2502.02877v1 Announce Type: new 
Abstract: While federated learning (FL) eliminates the transmission of raw data over a network, it is still vulnerable to privacy breaches from the communicated model parameters. Differential privacy (DP) is often employed to address such issues. However, the impact of DP on FL in multi-tier networks -- where hierarchical aggregations couple noise injection decisions at different tiers, and trust models are heterogeneous across subnetworks -- is not well understood. To fill this gap, we develop \underline{M}ulti-Tier \underline{F}ederated Learning with \underline{M}ulti-Tier \underline{D}ifferential \underline{P}rivacy ({\tt M$^2$FDP}), a DP-enhanced FL methodology for jointly optimizing privacy and performance over such networks. One of the key principles of {\tt M$^2$FDP} is to adapt DP noise injection across the established edge/fog computing hierarchy (e.g., edge devices, intermediate nodes, and other tiers up to cloud servers) according to the trust models in different subnetworks. We conduct a comprehensive analysis of the convergence behavior of {\tt M$^2$FDP} under non-convex problem settings, revealing conditions on parameter tuning under which the training process converges sublinearly to a finite stationarity gap that depends on the network hierarchy, trust model, and target privacy level. We show how these relationships can be employed to develop an adaptive control algorithm for {\tt M$^2$FDP} that tunes properties of local model training to minimize energy, latency, and the stationarity gap while meeting desired convergence and privacy criterion. Subsequent numerical evaluations demonstrate that {\tt M$^2$FDP} obtains substantial improvements in these metrics over baselines for different privacy budgets and system configurations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02877v1</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Evan Chen, Frank Po-Chen Lin, Dong-Jun Han, Christopher G. Brinton</dc:creator>
    </item>
    <item>
      <title>Advancements in Mobile Edge Computing and Open RAN: Leveraging Artificial Intelligence and Machine Learning for Wireless Systems</title>
      <link>https://arxiv.org/abs/2502.02886</link>
      <description>arXiv:2502.02886v1 Announce Type: new 
Abstract: Mobile Edge Computing (MEC) and Open Radio Access Networks (ORAN) are transformative technologies in the development of next-generation wireless communication systems. MEC pushes computational resources closer to end-users, enabling low latency and efficient processing, while ORAN promotes interoperability and openness in radio networks, thereby fostering innovation. This paper explores recent advancements in these two domains, with a particular focus on how Artificial Intelligence (AI) and Machine Learning (ML) techniques are being utilized to solve complex wireless challenges. In MEC, Deep Reinforcement Learning (DRL) is leveraged for optimizing computation offloading, ensuring energy-efficient solutions, and meeting Quality of Service (QoS) requirements. In ORAN, AI/ML is used to develop intelligent xApps for network slicing, scheduling, and online training to enhance network adaptability. This reading report provides an in-depth analysis of multiple key papers, discusses the methodologies employed, and highlights the impact of these technologies in improving network efficiency and scalability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02886v1</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ryan Barker</dc:creator>
    </item>
    <item>
      <title>From DeepSense to Open RAN: AI/ML Advancements in Dynamic Spectrum Sensing and Their Applications</title>
      <link>https://arxiv.org/abs/2502.02889</link>
      <description>arXiv:2502.02889v1 Announce Type: new 
Abstract: The integration of Artificial Intelligence (AI) and Machine Learning (ML) in next-generation wireless communication systems has become a cornerstone for advancing intelligent, adaptive, and scalable networks. This reading report examines key innovations in dynamic spectrum sensing (DSS), beginning with the foundational DeepSense framework, which uses convolutional neural networks (CNNs) and spectrogram-based analysis for real-time wideband spectrum monitoring. Building on this groundwork, it highlights advancements such as DeepSweep and Wideband Signal Stitching, which address the challenges of scalability, latency, and dataset diversity through parallel processing, semantic segmentation, and robust data augmentation strategies. The report then explores Open Radio Access Networks (ORAN), focusing on AI/ML-driven enhancements for UAV experimentation, digital twin-based optimization, network slicing, and self-healing xApp development. By bridging AI-based DSS methodologies with ORAN's open, vendor-neutral architecture, these studies underscore the potential of software-defined, intelligent infrastructures in enabling efficient, resilient, and self-optimizing networks for 5G/6G ecosystems. Through this synthesis, the report highlights AI's transformative role in shaping the future of wireless communication and autonomous systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02889v1</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ryan Barker</dc:creator>
    </item>
    <item>
      <title>A Framework for IoT-Enabled Smart Manufacturing for Energy and Resource Optimization</title>
      <link>https://arxiv.org/abs/2502.03040</link>
      <description>arXiv:2502.03040v1 Announce Type: new 
Abstract: The increasing demands for sustainable and efficient manufacturing systems have driven the integration of Internet of Things (IoT) technologies into smart manufacturing. This study investigates IoT-enabled systems designed to enhance energy efficiency and resource optimization in the manufacturing sector, focusing on a multi-layered architecture integrating sensors, edge computing, and cloud platforms. MATLAB Simulink was utilized for modeling and simulation, replicating typical manufacturing conditions to evaluate energy consumption, machine uptime, and resource usage. The results demonstrate an 18% reduction in energy consumption, a 22% decrease in machine downtime, and a 15% improvement in resource utilization. Comparative analyses highlight the superiority of the proposed framework in addressing operational inefficiencies and aligning with sustainability goals. The study underscores the potential of IoT in transforming traditional manufacturing into interconnected, intelligent systems, offering practical implications for industrial stakeholders aiming to optimize operations while adhering to global sustainability standards. Future work will focus on addressing identified challenges such as high deployment costs and data security concerns, aiming to facilitate the broader adoption of IoT in industrial applications.
  Keywords: IoT (Internet of Things), Smart Manufacturing, Energy Efficiency, Resource Optimization, Manufacturing</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03040v1</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bazigu Alex, Mwebaze Johnson</dc:creator>
    </item>
    <item>
      <title>Solar Synergy: Innovative Strategies for Data Centers Energy Efficiency and Sustainability</title>
      <link>https://arxiv.org/abs/2502.03130</link>
      <description>arXiv:2502.03130v1 Announce Type: new 
Abstract: One of the current trends related to data centers is providing it with renewable energy sources. This paper suggests an analysis technique for a model uses solar panels energy to power a data center consists of 100 traditional servers, physical infrastructures, 5 backup batteries. The analysis passes through three phases: Initially, the power consumption model of the data center is proposed to show the variation in traffic and total energy consumed. Then, a solar system model is designed according to the power needed. At the last phase, the desired battery capacity is chosen as (10000Ah-48V) to accommodate the solar energy production.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03130v1</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alnawar J. Mohammed, Qutaiba I. Ali</dc:creator>
    </item>
    <item>
      <title>SkyOctopus: Enabling Low-Latency Mobile Satellite Network through Multiple Anchors</title>
      <link>https://arxiv.org/abs/2502.03250</link>
      <description>arXiv:2502.03250v1 Announce Type: new 
Abstract: The rapid deployment of low earth orbit (LEO) satellite constellations has drawn attention to the potential of nonterrestrial networks (NTN) in providing global communication services. Telecom operators are attempting to collaborate with satellite network providers to develop mobile satellite networks, which serve as an effective supplement to terrestrial networks. However, current mobile satellite network architectures still employ the single-anchor design of terrestrial mobile networks, leading to severely circuitous routing for users and significantly impacting their service experience. To reduce unnecessary latency caused by circuitous routing and provide users with low-latency global internet services, this paper presents SkyOctopus, an advanced multi-anchor mobile satellite network architecture. SkyOctopus innovatively deploys traffic classifiers on satellites to enable connections between users and multiple anchor points distributed globally. It guarantees optimal anchor point selection for each user's target server by monitoring multiple end-to-end paths. We build a prototype of SkyOctopus using enhanced Open5GS and UERANSIM, which is driven by actual LEO satellite constellations such as Starlink, Kuiper, and OneWeb. We conducted extensive experiments, and the results demonstrate that, compared to standard 5G NTN and two other existing schemes, SkyOctopus can reduce end-to-end latency by up to 53\%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03250v1</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shaojie Su, Jiasheng Wu, Zijie Ying, Zhiyuan Zhao, Xiangyu Jia, Wenjun Zhu, Yue Gao</dc:creator>
    </item>
    <item>
      <title>Energy-Efficient Flying LoRa Gateways: A Multi-Agent Reinforcement Learning Approach</title>
      <link>https://arxiv.org/abs/2502.03377</link>
      <description>arXiv:2502.03377v1 Announce Type: new 
Abstract: With the rapid development of next-generation Internet of Things (NG-IoT) networks, the increasing number of connected devices has led to a surge in power consumption. This rise in energy demand poses significant challenges to resource availability and raises sustainability concerns for large-scale IoT deployments. Efficient energy utilization in communication networks, particularly for power-constrained IoT devices, has thus become a critical area of research. In this paper, we deployed flying LoRa gateways (GWs) mounted on unmanned aerial vehicles (UAVs) to collect data from LoRa end devices (EDs) and transmit it to a central server. Our primary objective is to maximize the global system energy efficiency (EE) of wireless LoRa networks by joint optimization of transmission power (TP), spreading factor (SF), bandwidth (W), and ED association. To solve this challenging problem, we model the problem as a partially observable Markov decision process (POMDP), where each flying LoRa GW acts as a learning agent using a cooperative Multi-Agent Reinforcement Learning (MARL) approach under centralized training and decentralized execution (CTDE). Simulation results demonstrate that our proposed method, based on the multi-agent proximal policy optimization (MAPPO) algorithm, significantly improves the global system EE and surpasses the conventional MARL schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03377v1</guid>
      <category>cs.NI</category>
      <category>cs.LG</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Abdullahi Isa Ahmed, El Mehdi Amhoud</dc:creator>
    </item>
    <item>
      <title>Performance Analysis of 5G FR2 (mmWave) Downlink 256QAM on Commercial 5G Networks</title>
      <link>https://arxiv.org/abs/2502.03416</link>
      <description>arXiv:2502.03416v1 Announce Type: new 
Abstract: The 5G New Radio (NR) standard introduces new frequency bands allocated in Frequency Range 2 (FR2) to support enhanced Mobile Broadband (eMBB) in congested environments and enables new use cases such as Ultra-Reliable Low Latency Communication (URLLC). The 3GPP introduced 256QAM support for FR2 frequency bands to further enhance downlink capacity. However, sustaining 256QAM on FR2 in practical environments is challenging due to strong path loss and susceptibility to distortion. While 256QAM can improve theoretical throughput by 33%, compared to 64QAM, and is widely adopted in FR1, its real-world impact when utilized in FR2 is questionable, given the significant path loss and distortions experienced in the FR2 range. Additionally, using higher modulation correlates to higher BLER, increased instability, and retransmission. Moreover, 256QAM also utilizes a different MCS table defining the modulation and code rate at different Channel Quality Indexes (CQI), affecting the UE's link adaptation behavior. This paper investigates the real-world performance of 256QAM utilization on FR2 bands in two countries, across three RAN manufacturers, and in both NSA (EN-DC) and SA (NR-DC) configurations, under various scenarios, including open-air plazas, city centers, footbridges, train station platforms, and stationary environments. The results show that 256QAM provides a reasonable throughput gain when stationary but marginal improvements when there is UE mobility while increasing the probability of NACK responses, increasing BLER, and the number of retransmissions. Finally, MATLAB simulations are run to validate the findings as well as explore the effect of the recently introduced 1024QAM on FR2.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03416v1</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kasidis Arunruangsirilert, Pasapong Wongprasert, Jiro Katto</dc:creator>
    </item>
    <item>
      <title>Building a Smart, Secured and Sustainable Campus: A Self-Powered Wireless Network for Environmental Monitoring</title>
      <link>https://arxiv.org/abs/2502.03441</link>
      <description>arXiv:2502.03441v1 Announce Type: new 
Abstract: The objective of this study is to propose a self-powered wireless network solution that utilizes strategically deployed wireless sensor nodes within buildings for environmental data collection, while integrating advanced security measures and sustainable power management strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03441v1</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qutaiba I. Ali</dc:creator>
    </item>
    <item>
      <title>CARROT: A Cost Aware Rate Optimal Router</title>
      <link>https://arxiv.org/abs/2502.03261</link>
      <description>arXiv:2502.03261v1 Announce Type: cross 
Abstract: With the rapid growth in the number of Large Language Models (LLMs), there has been a recent interest in LLM routing, or directing queries to the cheapest LLM that can deliver a suitable response. Following this line of work, we introduce CARROT, a Cost AwaRe Rate Optimal rouTer that can select models based on any desired trade-off between performance and cost. Given a query, CARROT selects a model based on estimates of models' cost and performance. Its simplicity lends CARROT computational efficiency, while our theoretical analysis demonstrates minimax rate-optimality in its routing performance. Alongside CARROT, we also introduce the Smart Price-aware Routing (SPROUT) dataset to facilitate routing on a wide spectrum of queries with the latest state-of-the-art LLMs. Using SPROUT and prior benchmarks such as Routerbench and open-LLM-leaderboard-v2 we empirically validate CARROT's performance against several alternative routers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03261v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Seamus Somerstep, Felipe Maia Polo, Allysson Flavio Melo de Oliveira, Prattyush Mangal, M\'irian Silva, Onkar Bhardwaj, Mikhail Yurochkin, Subha Maity</dc:creator>
    </item>
    <item>
      <title>The Adoption of Artificial Intelligence in Different Network Security Concepts</title>
      <link>https://arxiv.org/abs/2502.03398</link>
      <description>arXiv:2502.03398v1 Announce Type: cross 
Abstract: The obstacles of each security system combined with the increase of cyber-attacks, negatively affect the effectiveness of network security management and rise the activities to be taken by the security staff and network administrators. So, there is a growing need for the automated auditing and intelligent reporting strategies for reliable network security with as less model complexity as possible. Newly, artificial intelligence has been effectively applied to various network security issues, and numerous studies have been conducted that utilize various artificial intelligence techniques for the purposes of encryption and secure communication, in addition to using artificial intelligence to perform a large number of data encryption operations in record time. The aim of the study is to present and discuss the most prominent methods of artificial intelligence recently used in the field of network security including user authentication, Key exchanging, encryption/decryption, data integrity and intrusion detection system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03398v1</guid>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mamoon A. Al Jbaar, Adel Jalal Yousif, Qutaiba I. Ali</dc:creator>
    </item>
    <item>
      <title>Cryptocurrency Network Analysis</title>
      <link>https://arxiv.org/abs/2502.03411</link>
      <description>arXiv:2502.03411v1 Announce Type: cross 
Abstract: Cryptocurrency network analysis consists of applying the tools and methods of social network analysis to transactional data issued from cryptocurrencies. The main difference with most online social networks is that users do not exchange textual content but instead value -- in systems designed mainly as cryptocurrency, such as Bitcoin -- or digital items and services in more permissive systems based on smart contracts such as Ethereum.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03411v1</guid>
      <category>cs.SI</category>
      <category>cs.CY</category>
      <category>cs.NI</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Natkamon Tovanich, C\'elestin Coquid\'e, R\'emy Cazabet</dc:creator>
    </item>
    <item>
      <title>Compact Data Structures for Network Telemetry</title>
      <link>https://arxiv.org/abs/2311.02636</link>
      <description>arXiv:2311.02636v2 Announce Type: replace 
Abstract: Collecting and analyzing of network traffic data (network telemetry) plays a critical role in managing modern networks. Network administrators analyze their traffic to troubleshoot performance and reliability problems, and to detect and block cyberattacks. However, conventional traffic-measurement techniques offer limited visibility into network conditions and rely on offline analysis. Fortunately, network devices -- such as switches and network interface cards -- are increasingly programmable at the packet level, enabling flexible analysis of the traffic in place, as the packets fly by. However, to operate at high speed, these devices have limited memory and computational resources, leading to trade-offs between accuracy and overhead. In response, an exciting research area emerged, bringing ideas from compact data structures and streaming algorithms to bear on important networking telemetry applications and the unique characteristics of high-speed network devices. In this paper, we review the research on compact data structures for network telemetry and discuss promising directions for future research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.02636v2</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shir Landau Feibish, Zaoxing Liu, Jennifer Rexford</dc:creator>
    </item>
    <item>
      <title>Managing O-RAN Networks: xApp Development from Zero to Hero</title>
      <link>https://arxiv.org/abs/2407.09619</link>
      <description>arXiv:2407.09619v3 Announce Type: replace 
Abstract: The Open Radio Access Network (O-RAN) Alliance proposes an open architecture that disaggregates the RAN and supports executing custom control logic in near-real time from third-party applications, the xApps. Despite O-RAN's efforts, the creation of xApps remains a complex and time-consuming endeavor, aggravated by the sometimes fragmented, outdated, or deprecated documentation from the O-RAN Software Community (OSC). These challenges hinder academia and industry from developing and validating solutions and algorithms on O-RAN networks. This tutorial addresses this gap by providing the first comprehensive guide for developing xApps to manage the O-RAN ecosystem from theory to practice. We provide a thorough theoretical foundation of the O-RAN architecture and detail the functionality offered by Near Real-Time RAN Intelligent Controller (Near-RT RIC) components. We examine the xApp design and configuration. We explore the xApp lifecycle and demonstrate how to deploy and manage xApps on a Near-RT RIC. We address the xApps' interfaces and capabilities, accompanied by practical examples. We provide comprehensive details on how xApps can control the RAN. We discuss debugging strategies and good practices to aid the xApp developers in testing their xApps. Finally, we review the current landscape and open challenges for creating xApps.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09619v3</guid>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/COMST.2025.3539687 10.1109/COMST.2025.3539687 10.1109/COMST.2025.3539687</arxiv:DOI>
      <dc:creator>Joao F. Santos, Alexandre Huff, Daniel Campos, Kleber V. Cardoso, Cristiano B. Both, Luiz A. DaSilva</dc:creator>
    </item>
    <item>
      <title>An Exposition of Pathfinding Strategies Within Lightning Network Clients</title>
      <link>https://arxiv.org/abs/2410.13784</link>
      <description>arXiv:2410.13784v2 Announce Type: replace 
Abstract: The Lightning Network is a peer-to-peer network designed to address Bitcoin's scalability challenges, facilitating rapid, cost-effective, and instantaneous transactions through bidirectional, blockchain-backed payment channels among network peers. Due to a source-based routing of payments, different pathfinding strategies are used in practice, trading off different objectives for each other such as payment reliability and routing fees. This paper explores differences within pathfinding strategies used by prominent Lightning Network node implementations, which include different underlying cost functions and different constraints, as well as different greedy algorithms of shortest path-type. Surprisingly, we observe that the pathfinding problems that most LN node implementations attempt to solve are NP-complete, and cannot be guaranteed to be optimally solved by the variants of Dijkstra's algorithm currently deployed in production. Through comparative analysis and simulations, we evaluate efficacy of different pathfinding strategies across metrics such as success rate, fees, path length, and timelock. Our experiments indicate that the strategies used by Eclair are advantageous in terms of payment reliability and result in paths with low fees. LND exhibits moderate success rates, while LDK results in paths with higher fee levels for smaller payment amounts; furthermore, CLN stands out for its minimal timelock paths. Additionally, we investigate the impact of Lightning node connectivity levels on routing efficiency. The findings of our analysis provide insights towards future improvements of pathfinding strategies and algorithms used within the Lightning Network.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.13784v2</guid>
      <category>cs.NI</category>
      <category>cs.CE</category>
      <category>cs.CR</category>
      <category>cs.SI</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Sindura Saraswathi, Christian K\"ummerle</dc:creator>
    </item>
    <item>
      <title>Spatial Network Calculus: Toward Deterministic Wireless Networking</title>
      <link>https://arxiv.org/abs/2501.02556</link>
      <description>arXiv:2501.02556v3 Announce Type: replace 
Abstract: This paper extends the classical network calculus to spatial scenarios, focusing on wireless networks with heterogeneous traffic and varying transmit power levels. Building on spatial network calculus, a prior extension of network calculus to spatial settings, we propose a generalized framework by introducing spatial regulations for stationary marked point processes. The regulations correspond to two key constraints: the total transmit power within a spatial region and the cumulative received power at a receiver. Then we prove the equivalence of ball regulation and shot-noise regulation for stationary marked point processes and establish a universal lower bound on the performance of all network links under these constraints. This framework is applicable to diverse network scenarios, as demonstrated by the analysis of performance guarantees for networks with multi-class users. In addition, we propose an SINR-based power control scheme adapted to user traffic, which ensures differentiated quality of service (QoS) for different user classes. We derive deterministic performance guarantees for all links in complex and heterogeneous wireless networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.02556v3</guid>
      <category>cs.NI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yi Zhong, Xiaohang Zhou, Ke Feng</dc:creator>
    </item>
    <item>
      <title>Hybrid LLM-DDQN based Joint Optimization of V2I Communication and Autonomous Driving</title>
      <link>https://arxiv.org/abs/2410.08854</link>
      <description>arXiv:2410.08854v3 Announce Type: replace-cross 
Abstract: Large language models (LLMs) have received considerable interest recently due to their outstanding reasoning and comprehension capabilities. This work explores applying LLMs to vehicular networks, aiming to jointly optimize vehicle-to-infrastructure (V2I) communications and autonomous driving (AD) policies. We deploy LLMs for AD decision-making to maximize traffic flow and avoid collisions for road safety, and a double deep Q-learning algorithm (DDQN) is used for V2I optimization to maximize the received data rate and reduce frequent handovers. In particular, for LLM-enabled AD, we employ the Euclidean distance to identify previously explored AD experiences, and then LLMs can learn from past good and bad decisions for further improvement. Then, LLM-based AD decisions will become part of states in V2I problems, and DDQN will optimize the V2I decisions accordingly. After that, the AD and V2I decisions are iteratively optimized until convergence. Such an iterative optimization approach can better explore the interactions between LLMs and conventional reinforcement learning techniques, revealing the potential of using LLMs for network optimization and management. Finally, the simulations demonstrate that our proposed hybrid LLM-DDQN approach outperforms the conventional DDQN algorithm, showing faster convergence and higher average rewards.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08854v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Zijiang Yan, Hao Zhou, Hina Tabassum, Xue Liu</dc:creator>
    </item>
    <item>
      <title>CVaR-Based Variational Quantum Optimization for User Association in Handoff-Aware Vehicular Networks</title>
      <link>https://arxiv.org/abs/2501.08418</link>
      <description>arXiv:2501.08418v2 Announce Type: replace-cross 
Abstract: Efficient resource allocation is essential for optimizing various tasks in wireless networks, which are usually formulated as generalized assignment problems (GAP). GAP, as a generalized version of the linear sum assignment problem, involves both equality and inequality constraints that add computational challenges. In this work, we present a novel Conditional Value at Risk (CVaR)-based Variational Quantum Eigensolver (VQE) framework to address GAP in vehicular networks (VNets). Our approach leverages a hybrid quantum-classical structure, integrating a tailored cost function that balances both objective and constraint-specific penalties to improve solution quality and stability. Using the CVaR-VQE model, we handle the GAP efficiently by focusing optimization on the lower tail of the solution space, enhancing both convergence and resilience on noisy intermediate-scale quantum (NISQ) devices. We apply this framework to a user-association problem in VNets, where our method achieves 23.5% improvement compared to the deep neural network (DNN) approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08418v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Zijiang Yan, Hao Zhou, Jianhua Pei, Aryan Kaushik, Hina Tabassum, Ping Wang</dc:creator>
    </item>
  </channel>
</rss>
