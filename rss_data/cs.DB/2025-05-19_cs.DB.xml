<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DB updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DB</link>
    <description>cs.DB updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DB" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 19 May 2025 04:00:14 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 19 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>TAIJI: MCP-based Multi-Modal Data Analytics on Data Lakes</title>
      <link>https://arxiv.org/abs/2505.11270</link>
      <description>arXiv:2505.11270v1 Announce Type: new 
Abstract: The variety of data in data lakes presents significant challenges for data analytics, as data scientists must simultaneously analyze multi-modal data, including structured, semi-structured, and unstructured data. While Large Language Models (LLMs) have demonstrated promising capabilities, they still remain inadequate for multi-modal data analytics in terms of accuracy, efficiency, and freshness. First, current natural language (NL) or SQL-like query languages may struggle to precisely and comprehensively capture users' analytical intent. Second, relying on a single unified LLM to process diverse data modalities often leads to substantial inference overhead. Third, data stored in data lakes may be incomplete or outdated, making it essential to integrate external open-domain knowledge to generate timely and relevant analytics results.
  In this paper, we envision a new multi-modal data analytics system. Specifically, we propose a novel architecture built upon the Model Context Protocol (MCP), an emerging paradigm that enables LLMs to collaborate with knowledgeable agents. First, we define a semantic operator hierarchy tailored for querying multi-modal data in data lakes and develop an AI-agent-powered NL2Operator translator to bridge user intent and analytical execution. Next, we introduce an MCP-based execution framework, in which each MCP server hosts specialized foundation models optimized for specific data modalities. This design enhances both accuracy and efficiency, while supporting high scalability through modular deployment. Finally, we propose a updating mechanism by harnessing the deep research and machine unlearning techniques to refresh the data lakes and LLM knowledges, with the goal of balancing the data freshness and inference efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.11270v1</guid>
      <category>cs.DB</category>
      <category>cs.AI</category>
      <pubDate>Mon, 19 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chao Zhang, Shaolei Zhang, Quehuan Liu, Sibei Chen, Tong Li, Ju Fan</dc:creator>
    </item>
    <item>
      <title>MatTools: Benchmarking Large Language Models for Materials Science Tools</title>
      <link>https://arxiv.org/abs/2505.10852</link>
      <description>arXiv:2505.10852v1 Announce Type: cross 
Abstract: Large language models (LLMs) are increasingly applied to materials science questions, including literature comprehension, property prediction, materials discovery and alloy design. At the same time, a wide range of physics-based computational approaches have been developed in which materials properties can be calculated. Here, we propose a benchmark application to evaluate the proficiency of LLMs to answer materials science questions through the generation and safe execution of codes based on such physics-based computational materials science packages. MatTools is built on two complementary components: a materials simulation tool question-answer (QA) benchmark and a real-world tool-usage benchmark. We designed an automated methodology to efficiently collect real-world materials science tool-use examples. The QA benchmark, derived from the pymatgen (Python Materials Genomics) codebase and documentation, comprises 69,225 QA pairs that assess the ability of an LLM to understand materials science tools. The real-world benchmark contains 49 tasks (138 subtasks) requiring the generation of functional Python code for materials property calculations. Our evaluation of diverse LLMs yields three key insights: (1)Generalists outshine specialists;(2)AI knows AI; and (3)Simpler is better. MatTools provides a standardized framework for assessing and improving LLM capabilities for materials science tool applications, facilitating the development of more effective AI systems for materials science and general scientific research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.10852v1</guid>
      <category>cond-mat.mtrl-sci</category>
      <category>cs.CL</category>
      <category>cs.DB</category>
      <pubDate>Mon, 19 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Siyu Liu, Jiamin Xu, Beilin Ye, Bo Hu, David J. Srolovitz, Tongqi Wen</dc:creator>
    </item>
    <item>
      <title>Relational Graph Transformer</title>
      <link>https://arxiv.org/abs/2505.10960</link>
      <description>arXiv:2505.10960v1 Announce Type: cross 
Abstract: Relational Deep Learning (RDL) is a promising approach for building state-of-the-art predictive models on multi-table relational data by representing it as a heterogeneous temporal graph. However, commonly used Graph Neural Network models suffer from fundamental limitations in capturing complex structural patterns and long-range dependencies that are inherent in relational data. While Graph Transformers have emerged as powerful alternatives to GNNs on general graphs, applying them to relational entity graphs presents unique challenges: (i) Traditional positional encodings fail to generalize to massive, heterogeneous graphs; (ii) existing architectures cannot model the temporal dynamics and schema constraints of relational data; (iii) existing tokenization schemes lose critical structural information. Here we introduce the Relational Graph Transformer (RelGT), the first graph transformer architecture designed specifically for relational tables. RelGT employs a novel multi-element tokenization strategy that decomposes each node into five components (features, type, hop distance, time, and local structure), enabling efficient encoding of heterogeneity, temporality, and topology without expensive precomputation. Our architecture combines local attention over sampled subgraphs with global attention to learnable centroids, incorporating both local and database-wide representations. Across 21 tasks from the RelBench benchmark, RelGT consistently matches or outperforms GNN baselines by up to 18%, establishing Graph Transformers as a powerful architecture for Relational Deep Learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.10960v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.DB</category>
      <pubDate>Mon, 19 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vijay Prakash Dwivedi, Sri Jaladi, Yangyi Shen, Federico L\'opez, Charilaos I. Kanatsoulis, Rishi Puri, Matthias Fey, Jure Leskovec</dc:creator>
    </item>
    <item>
      <title>Local consistency and axioms of functional dependence</title>
      <link>https://arxiv.org/abs/2505.11057</link>
      <description>arXiv:2505.11057v1 Announce Type: cross 
Abstract: Local consistency arises in diverse areas, including Bayesian statistics, relational databases, and quantum foundations. Likewise, the notion of functional dependence arises in all of these areas. We adopt a general approach to study logical inference in a setting that enables both global inconsistency and local consistency. Our approach builds upon pairwise consistent families of K-relations, i.e, relations with tuples annotated with elements of some positive commutative monoid. The framework covers, e.g., families of probability distributions arising from quantum experiments and their possibilistic counterparts. As a first step, we investigate the entailment problem for functional dependencies (FDs) in this setting. Notably, the transitivity rule for FDs is no longer sound, but can be replaced by two novel axiom schemes. We provide a complete axiomatisation and a PTIME algorithm for the entailment problem of unary FDs. In addition, we explore when contextual families over the Booleans have realisations as contextual families over various monoids.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.11057v1</guid>
      <category>quant-ph</category>
      <category>cs.DB</category>
      <pubDate>Mon, 19 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Timon Barlag, Miika Hannula, Juha Kontinen, Nina Pardal, Jonni Virtema</dc:creator>
    </item>
    <item>
      <title>Inferring the Most Similar Variable-length Subsequences between Multidimensional Time Series</title>
      <link>https://arxiv.org/abs/2505.11106</link>
      <description>arXiv:2505.11106v1 Announce Type: cross 
Abstract: Finding the most similar subsequences between two multidimensional time series has many applications: e.g. capturing dependency in stock market or discovering coordinated movement of baboons. Considering one pattern occurring in one time series, we might be wondering whether the same pattern occurs in another time series with some distortion that might have a different length. Nevertheless, to the best of our knowledge, there is no efficient framework that deals with this problem yet. In this work, we propose an algorithm that provides the exact solution of finding the most similar multidimensional subsequences between time series where there is a difference in length both between time series and between subsequences. The algorithm is built based on theoretical guarantee of correctness and efficiency. The result in simulation datasets illustrated that our approach not just only provided correct solution, but it also utilized running time only quarter of time compared against the baseline approaches. In real-world datasets, it extracted the most similar subsequences even faster (up to 20 times faster against baseline methods) and provided insights regarding the situation in stock market and following relations of multidimensional time series of baboon movement. Our approach can be used for any time series. The code and datasets of this work are provided for the public use.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.11106v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.DB</category>
      <category>stat.ME</category>
      <pubDate>Mon, 19 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thanadej Rattanakornphan, Piyanon Charoenpoonpanich, Chainarong Amornbunchornvej</dc:creator>
    </item>
    <item>
      <title>Finding Counterfactual Evidences for Node Classification</title>
      <link>https://arxiv.org/abs/2505.11396</link>
      <description>arXiv:2505.11396v1 Announce Type: cross 
Abstract: Counterfactual learning is emerging as an important paradigm, rooted in causality, which promises to alleviate common issues of graph neural networks (GNNs), such as fairness and interpretability. However, as in many real-world application domains where conducting randomized controlled trials is impractical, one has to rely on available observational (factual) data to detect counterfactuals. In this paper, we introduce and tackle the problem of searching for counterfactual evidences for the GNN-based node classification task. A counterfactual evidence is a pair of nodes such that, regardless they exhibit great similarity both in the features and in their neighborhood subgraph structures, they are classified differently by the GNN. We develop effective and efficient search algorithms and a novel indexing solution that leverages both node features and structural information to identify counterfactual evidences, and generalizes beyond any specific GNN. Through various downstream applications, we demonstrate the potential of counterfactual evidences to enhance fairness and accuracy of GNNs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.11396v1</guid>
      <category>cs.LG</category>
      <category>cs.DB</category>
      <pubDate>Mon, 19 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dazhuo Qiu, Jinwen Chen, Arijit Khan, Yan Zhao, Francesco Bonchi</dc:creator>
    </item>
    <item>
      <title>Evaluating Continuous Basic Graph Patterns over Dynamic Link Data Graphs</title>
      <link>https://arxiv.org/abs/2209.10272</link>
      <description>arXiv:2209.10272v2 Announce Type: replace 
Abstract: In this paper, we investigate the problem of evaluating Basic Graph Patterns (BGP, for short, a subclass of SPARQL queries) over dynamic Linked Data graphs; i.e., Linked Data graphs that are continuously updated. We consider a setting where the updates are continuously received through a stream of messages and support both insertions and deletions of triples (updates are straightforwardly handled as a combination of deletions and insertions). In this context, we propose a set of in-memory algorithms minimizing the cached data to efficiently and continuously answer BGP queries. The queries are typically submitted into a system and continuously result in the delta answers while the update messages are processed.
  To efficiently and continuously evaluate the submitted query over the streaming data, as well as to minimize the amount of cached data, we propose an approach where the submitted query is decomposed into simpler subqueries and the query evaluation is achieved by combining the intermediate answers of the subqueries. Using this approach, the proposed algorithms compute the delta answers of a BGP query in polynomial time and space. Note that for certain subclasses of BGP queries, we show that the evaluation can be achieved in constant or linear time and space. Consolidating all the historical delta answers, the algorithms ensure that the answer to each query is constructed at any given time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.10272v2</guid>
      <category>cs.DB</category>
      <pubDate>Mon, 19 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Manolis Gergatsoulis, Matthew Damigos</dc:creator>
    </item>
    <item>
      <title>TreeTracker Join: Simple, Optimal, Fast</title>
      <link>https://arxiv.org/abs/2403.01631</link>
      <description>arXiv:2403.01631v4 Announce Type: replace 
Abstract: We present a novel linear-time acyclic join algorithm, TreeTracker Join (TTJ). The algorithm can be understood as the pipelined binary hash join with a simple twist: upon a hash lookup failure, TTJ resets execution to the binding of the tuple causing the failure, and removes the offending tuple from its relation. Compared to the best known linear-time acyclic join algorithm, Yannakakis's algorithm, TTJ shares the same asymptotic complexity while imposing lower overhead. Further, we prove that when measuring query performance by counting the number of hash probes, TTJ will match or outperform binary hash join on the same plan. This property holds independently of the plan and independently of acyclicity. We are able to extend our theoretical results to cyclic queries by introducing a new hypergraph decomposition method called tree convolution. Tree convolution iteratively identifies and contracts acyclic subgraphs of the query hypergraph. The method avoids redundant calculations associated with tree decomposition and may be of independent interest. Empirical results on TPC-H, the Join Order Benchmark, and the Star Schema Benchmark demonstrate favorable results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.01631v4</guid>
      <category>cs.DB</category>
      <pubDate>Mon, 19 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zeyuan Hu, Yisu Remy Wang, Daniel P. Miranker</dc:creator>
    </item>
    <item>
      <title>Containment for Guarded Monotone Strict NP</title>
      <link>https://arxiv.org/abs/2310.01254</link>
      <description>arXiv:2310.01254v4 Announce Type: replace-cross 
Abstract: Guarded Monotone Strict NP (GMSNP) extends Monotone Monadic Strict NP (MMSNP) by guarded existentially quantified predicates of arbitrary arities. We prove that the containment problem for GMSNP is decidable, thereby settling an open question of Bienvenu, ten Cate, Lutz, and Wolter, later restated by Bourhis and Lutz. Our proof also comes with a 2NEXPTIME upper bound on the complexity of the problem, which matches the lower bound for containment of MMSNP due to Bourhis and Lutz. In order to obtain these results, we significantly improve the state of knowledge of the model-theoretic properties of GMSNP. Bodirsky, Kn\"{a}uer, and Starke previously showed that every GMSNP sentence defines a finite union of CSPs of $\omega$-categorical structures. We show that these structures can be used to obtain a reduction from the containment problem for GMSNP to the much simpler problem of testing the existence of a certain map called recolouring, albeit in a more general setting than GMSNP; a careful analysis of this yields said upper bound. As a secondary contribution, we refine the construction of Bodirsky, Kn\"{a}uer, and Starke by adding a restricted form of homogeneity to the properties of these structures, making the logic amenable to future complexity classifications for query evaluation using techniques developed for infinite-domain CSPs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.01254v4</guid>
      <category>cs.LO</category>
      <category>cs.DB</category>
      <category>math.LO</category>
      <pubDate>Mon, 19 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexey Barsukov, Michael Pinsker, Jakub Rydval</dc:creator>
    </item>
  </channel>
</rss>
