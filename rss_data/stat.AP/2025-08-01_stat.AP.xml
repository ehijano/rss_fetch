<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.AP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.AP</link>
    <description>stat.AP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.AP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 01 Aug 2025 04:02:04 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Efficient inference of dynamic gene regulatory networks using discrete penalty</title>
      <link>https://arxiv.org/abs/2507.23106</link>
      <description>arXiv:2507.23106v1 Announce Type: new 
Abstract: Gene regulatory networks (GRNs) orchestrate cellular decision making and survival strategies. Inferring the structure of these networks from high-dimensional transcriptomics data is a central challenge in systems biology. Traditional approaches to GRN inference, such as the graphical lasso and its joint extensions, rely on $\ell_1$ penalty to induce sparsity but can bias network recovery and require extensive hyperparameter tuning. Here, we present a scalable framework for the joint inference of dynamic GRNs using a discrete $\ell_0$ penalty, enabling direct and unbiased control over network sparsity. Leveraging recent algorithmic advances, we efficiently solve the resulting mixed-integer optimization problem for populations structured as arbitrary tree hypergraphs, accommodating both continuous and categorical distinctions among biological samples. After validating our method on synthetic benchmarks, we apply it to single-cell and spatial transcriptomics data from glioblastoma (GBM) patient tumors. Our approach reconstructs gene networks across tumor clusters, maps network rewiring along hypoxia gradients, and reveals niche-specific differences between primary and recurrent tumors. By providing a robust and interpretable tool for GRN inference in complex tissues, our work facilitates high-resolution dissection of tumor heterogeneity and adaptation, with broad applicability to emerging large-scale transcriptomic datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.23106v1</guid>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <category>stat.OT</category>
      <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Visweswaran Ravikumar, Aaresh Bhathena, Wajd N Al-Holou, Salar Fattahi, Arvind Rao</dc:creator>
    </item>
    <item>
      <title>Watermark in the Classroom: A Conformal Framework for Adaptive AI Usage Detection</title>
      <link>https://arxiv.org/abs/2507.23113</link>
      <description>arXiv:2507.23113v1 Announce Type: new 
Abstract: As artificial intelligence tools become ubiquitous in education, maintaining academic integrity while accommodating pedagogically beneficial AI assistance presents unprecedented challenges. Current AI detection systems fail to control false positive rates (FPR) and suffer from bias against minority student groups, prompting institutional suspensions of these technologies. Watermarking techniques offer statistical rigor through precise $p$-values but remain untested in educational contexts where students may use varying levels of permitted AI edits. We present the first adaptation of watermarking-based detection methods for classroom settings, introducing conformal methods that effectively control FPR across diverse classroom settings. Using essays from native and non-native English speakers, we simulate seven levels of AI editing interventions--from grammar correction to content expansion--across multiple language models and watermarking schemes, and evaluate our proposal under these different setups. Our findings provide educators with quantitative frameworks to enforce academic integrity standards while embracing AI integration in the classroom.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.23113v1</guid>
      <category>stat.AP</category>
      <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yangxinyu Xie, Xuyang Chen, Zhimei Ren, Weijie J. Su</dc:creator>
    </item>
    <item>
      <title>The effect of a new power interconnector on energy prices volatility: the case of Sicily</title>
      <link>https://arxiv.org/abs/2507.23505</link>
      <description>arXiv:2507.23505v1 Announce Type: new 
Abstract: The energy transition process requires the transformation of energy markets and substantial infrastructure investments. In electricity markets, in particular, infrastructure developments can significantly influence market performance. This study examines the impact of the introduction of the "Sorgente-Rizziconi" interconnector, which was integrated into the Italian electricity grid in May 2016 and enhanced power interconnection between Sicily and the mainland. The analysis focusses on the interconnector's effects on zonal price volatility within the Italian day-ahead electricity market. Prices and volatility are modelled using two distinct heteroscedastic approaches: a semi-parametric additive model and a fully non-parametric additive model. The results obtained from both modelling strategies indicate that: (i) the interconnector had a direct effect only on Sicily; (ii) it did not lead to a reduction in the price level; and (iii) it contributed to an increase in the baseline level of price volatility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.23505v1</guid>
      <category>stat.AP</category>
      <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Francesco Lisi, Pierdomenico Duttilo, Marina Bertolini</dc:creator>
    </item>
    <item>
      <title>Spatiodynamic inference using vision-based generative modelling</title>
      <link>https://arxiv.org/abs/2507.22256</link>
      <description>arXiv:2507.22256v1 Announce Type: cross 
Abstract: Biological systems commonly exhibit complex spatiotemporal patterns whose underlying generative mechanisms pose a significant analytical challenge. Traditional approaches to spatiodynamic inference rely on dimensionality reduction through summary statistics, which sacrifice complexity and interdependent structure intrinsic to these data in favor of parameter identifiability. This imposes a fundamental constraint on reliably extracting mechanistic insights from spatiotemporal data, highlighting the need for analytical frameworks that preserve the full richness of these dynamical systems. To address this, we developed a simulation-based inference framework that employs vision transformer-driven variational encoding to generate compact representations of the data, exploiting the inherent contextual dependencies. These representations are subsequently integrated into a likelihood-free Bayesian approach for parameter inference. The central idea is to construct a fine-grained, structured mesh of latent representations from simulated dynamics through systematic exploration of the parameter space. This encoded mesh of latent embeddings then serves as a reference map for retrieving parameter values that correspond to observed data. By integrating generative modeling with Bayesian principles, our approach provides a unified inference framework to identify both spatial and temporal patterns that manifest in multivariate dynamical systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.22256v1</guid>
      <category>q-bio.QM</category>
      <category>q-bio.PE</category>
      <category>stat.AP</category>
      <category>stat.ML</category>
      <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jun Won Park, Kangyu Zhao, Sanket Rane</dc:creator>
    </item>
    <item>
      <title>SigBERT: Combining Narrative Medical Reports and Rough Path Signature Theory for Survival Risk Estimation in Oncology</title>
      <link>https://arxiv.org/abs/2507.22941</link>
      <description>arXiv:2507.22941v1 Announce Type: cross 
Abstract: Electronic medical reports (EHR) contain a vast amount of information that can be leveraged for machine learning applications in healthcare. However, existing survival analysis methods often struggle to effectively handle the complexity of textual data, particularly in its sequential form. Here, we propose SigBERT, an innovative temporal survival analysis framework designed to efficiently process a large number of clinical reports per patient. SigBERT processes timestamped medical reports by extracting and averaging word embeddings into sentence embeddings. To capture temporal dynamics from the time series of sentence embedding coordinates, we apply signature extraction from rough path theory to derive geometric features for each patient, which significantly enhance survival model performance by capturing complex temporal dynamics. These features are then integrated into a LASSO-penalized Cox model to estimate patient-specific risk scores. The model was trained and evaluated on a real-world oncology dataset from the L\'eon B\'erard Center corpus, with a C-index score of 0.75 (sd 0.014) on the independent test cohort. SigBERT integrates sequential medical data to enhance risk estimation, advancing narrative-based survival analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.22941v1</guid>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Paul Minchella, Lo\"ic Verlingue, St\'ephane Chr\'etien, R\'emi Vaucher, Guillaume Metzler</dc:creator>
    </item>
    <item>
      <title>Stability Analysis and Local Influence Diagnostics for an Extreme-Value Regression Model of Anomalous Wind Gusts</title>
      <link>https://arxiv.org/abs/2507.22967</link>
      <description>arXiv:2507.22967v1 Announce Type: cross 
Abstract: Extreme events in complex physical systems, such as anomalous wind gusts, often cause significant material and human damage. Their modeling is crucial for risk assessment and understanding the underlying dynamics. In this work, we introduce a local influence analysis to assess the stability of a class of extreme-value Birnbaum-Saunders regression models, which are particularly suited for analyzing such data. The proposed approach uses the conformal normal curvature (CNC) of the log-likelihood function to diagnose the influence of individual observations on the postulated model. By examining the eigenvalues and eigenvectors associated with the CNC, we identify influential data points-physical events that disproportionately affect the model's parameters. We illustrate the methodology through a simulation study and apply it to a time series of wind gust data from Itajai, Brazil, where a severe event caused multiple damages and casualties. Our approach successfully pinpoints this specific event as a highly influential observation and quantifies its impact on the fitted model. This work provides a valuable diagnostic tool for physicists and data scientists working with extreme-value models of complex natural phenomena.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.22967v1</guid>
      <category>stat.ME</category>
      <category>physics.app-ph</category>
      <category>physics.data-an</category>
      <category>stat.AP</category>
      <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jos\'e I. C. Lima, Raydonal Ospina, Michelli Barros, Ant\^onio M. S. Mac\^edo</dc:creator>
    </item>
    <item>
      <title>Learning Smooth Populations of Parameters with Trial Heterogeneity</title>
      <link>https://arxiv.org/abs/2507.23140</link>
      <description>arXiv:2507.23140v1 Announce Type: cross 
Abstract: We consider the classical problem of estimating the mixing distribution of binomial mixtures, but under trial heterogeneity and smoothness. This problem has been studied extensively when the trial parameter is homogeneous, but not under the more general scenario of heterogeneous trials, and only within a low smoothness regime, where the resulting rates are slow. Under the assumption that the density is s-smooth, we derive fast error rates for the kernel density estimator under trial heterogeneity that depend on the harmonic mean of the trials. Importantly, even when reduced to the homogeneous case, our result improves on the state-of-the-art rate of Ye and Bickel (2021). We also study nonparametric estimation of the difference between two densities, which can be smoother than the individual densities, in both i.i.d. and binomial-mixture settings. Our work is motivated by an application in criminal justice: comparing conviction rates of indigent representation in Pennsylvania. We find that the estimated conviction rates for appointed counsel (court-appointed private attorneys) are generally higher than those for public defenders, potentially due to a confounding factor: appointed counsel are more likely to take on severe cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.23140v1</guid>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.TH</category>
      <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>JungHo Lee, Valerio Ba\'cak, Edward H. Kennedy</dc:creator>
    </item>
    <item>
      <title>Countering the Forgetting of Novel Health Information with 'Social Boosting'</title>
      <link>https://arxiv.org/abs/2507.23148</link>
      <description>arXiv:2507.23148v1 Announce Type: cross 
Abstract: To mitigate the adverse effects of low-quality or false information, studies have shown the effectiveness of various intervention techniques through debunking or so-called pre-bunking. However, the effectiveness of such interventions can decay. Here, we investigate the role of the detailed social structure of the local villages within which the intervened individuals live, which provides opportunities for the targeted individuals to discuss and internalize new knowledge. We evaluated this with respect to a critically important topic, information about maternal and child health care, delivered via a 22-month in-home intervention. Specifically, we examined the effect of having friendship ties on the retention of knowledge interventions among targeted individuals in 110 isolated Honduran villages. We hypothesize that individuals who receive specific knowledge can internalize and consolidate this information by engaging in social interactions where, for instance, they have an opportunity to discuss it with others in the process. The opportunity to explain information to others (knowledge sharing) promotes deeper cognitive processing and elaborative encoding, which ultimately enhances memory retention. We found that well-connected individuals within a social network experience an enhanced effectiveness of knowledge interventions. These individuals may be more likely to internalize and retain the information and reinforce it in others, due to increased opportunities for social interaction where they teach others or learn from them, a mechanism we refer to as "social boosting". These findings underscore the role of social interactions in reinforcing health knowledge interventions over the long term. We believe these findings would be of interest to the health policy, the global health workforce, and healthcare professionals focusing on disadvantaged populations and UN missions on infodemics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.23148v1</guid>
      <category>cs.SI</category>
      <category>stat.AP</category>
      <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vaibhav Krishna, Nicholas A. Christakis</dc:creator>
    </item>
    <item>
      <title>Bayesian reliability acceptance sampling plan sampling plans under adaptive accelerated type-II censored competing risk data</title>
      <link>https://arxiv.org/abs/2507.23293</link>
      <description>arXiv:2507.23293v1 Announce Type: cross 
Abstract: In recent times, products have become increasingly complex and highly reliable, so failures typically occur after long periods of operation under normal conditions and may arise from multiple causes. This paper employs simple step-stress partial accelerated life testing (SSSPALT) within the competing risks framework to determine the Bayesian reliability acceptance sampling plan (BRASP) under type-II censoring. Elevating the stress during the life test incurs an additional cost that increases the cost of the life test. In this context, an adaptive scenario is also considered in that sampling plan. The adaptive scenario is as follows: the stress is increased after a certain time if the number of failures up to that point is less than a pre-specified number of failures. The Bayes decision function and Bayes risk are derived for the general loss function. An optimal BRASP under that adaptive SSSPALT is obtained for the quadratic loss function by minimizing Bayes risk. An algorithm is provided to determine the optimal proposed BRASP. Further, comparative studies are conducted between the proposed BRASP, the conventional non-accelerated BRASP, and the conventional accelerated BRASP under type-II censoring to evaluate the effectiveness of the proposed approach. Finally, the methodology is illustrated using real data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.23293v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rathin Das, Soumya Roy, Biswabrata Pradhan</dc:creator>
    </item>
    <item>
      <title>Kilo-scale point-source inference using Parametric Cataloging</title>
      <link>https://arxiv.org/abs/2507.23472</link>
      <description>arXiv:2507.23472v1 Announce Type: cross 
Abstract: The estimation of the number of point-sources in the sky is one the oldest problems in astronomy, yet an easy and efficient method for estimating the uncertainty on these counts is still an open problem. Probabilistic cataloging solves the general point-source inference problem, but the trans-dimensional nature of the inference method requires a bespoke approach that is difficult to scale. Here it is shown that probabilistic cataloging can be performed in a fixed-dimensional framework called Parametric Cataloging under mild assumptions on some of the priors. The method requires only a simple reparameterization of the flux coordinates, yielding an accessible method that can be implemented in most probabilistic programming environments. As the parameter space is fixed-dimensional, off the shelf gradient based samplers can be employed which allows the method to scale to tens of thousands of sources.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.23472v1</guid>
      <category>astro-ph.IM</category>
      <category>hep-ex</category>
      <category>stat.AP</category>
      <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gabriel H. Collin</dc:creator>
    </item>
    <item>
      <title>The Missing Covariate Indicator Method is Nearly Valid Almost Always</title>
      <link>https://arxiv.org/abs/2111.00138</link>
      <description>arXiv:2111.00138v2 Announce Type: replace 
Abstract: Background: Although the missing covariate indicator method (MCIM) has been shown to be biased under extreme conditions, the degree and determinants of bias have not been formally assessed. We derived the formula for the relative bias in the MCIM and systematically investigated conditions under which bias arises. We found that the extent of bias is independent of both the disease rate and the exposure-outcome association, but it is a function of 5 parameters: exposure and covariate prevalences, covariate missingness proportion, and associations of covariate with exposure and outcome. The MCIM was unbiased when the missing covariate is a risk factor for the outcome but not a confounder. The average median relative bias was zero across each of the parameters over a wide range of values considered. Our simulation study demonstrated that the mean and median of relative bias of MCIM was comparable to that of the no missingness method, which used the full sample with complete information for all variables, as long as the missingness of covariate is independent of the outcome. When missingness was no greater than 50%, less than 5% of the scenarios considered had relative bias greater than 10%. In several analyses of the Harvard cohort studies, the MCIM produced materially the same results as the multiple imputation method. In conclusion, the MCIM is nearly valid almost always in settings typically encountered in epidemiology and its continued use is recommended, unless the covariate is missing in an extreme proportion or acts as a strong confounder.</description>
      <guid isPermaLink="false">oai:arXiv.org:2111.00138v2</guid>
      <category>stat.AP</category>
      <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gang Xu, Mingyang Song, Xin Zhou, Yilun Wu, Mathew Pazaris, Donna Spiegelman</dc:creator>
    </item>
    <item>
      <title>Compositional data analysis for modelling and forecasting mortality using the {\alpha}-transformation</title>
      <link>https://arxiv.org/abs/2501.01129</link>
      <description>arXiv:2501.01129v2 Announce Type: replace 
Abstract: Mortality forecasting is crucial for demographic planning and actuarial studies, especially for projecting population ageing and longevity risk. Classical approaches largely rely on extrapolative methods, such as the Lee-Carter (LC) model, which use mortality rates as the mortality measure. In recent years, compositional data analysis (CoDA), which respects summability and non-negativity constraints, has gained increasing attention for mortality forecasting. While the centred log-ratio (CLR) transformation is commonly used to map compositional data to real space, the {\alpha}-transformation, a generalisation of log-ratio transformations, offers greater flexibility and adaptability. This study contributes to mortality forecasting by introducing the {\alpha}-transformation as an alternative to the CLR transformation within a non-functional CoDA model that has not been previously investigated in existing literature. To fairly compare the impact of transformation choices on forecast accuracy, zero values in the data are imputed, although the {\alpha}-transformation can inherently handle them. Using age-specific life table death counts for males and females in 31 selected European countries/regions from 1983 to 2018, the proposed method demonstrates comparable performance to the CLR transformation in most cases, with improved forecast accuracy in some instances. These findings highlight the potential of the {\alpha}-transformation for enhancing mortality forecasting within the non-functional CoDA framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.01129v2</guid>
      <category>stat.AP</category>
      <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Han Ying Lim, Dharini Pathmanathan, Sophie Dabo-Niang</dc:creator>
    </item>
    <item>
      <title>Is Your Model Risk ALARP? Evaluating Prospective Safety-Critical Applications of Complex Models</title>
      <link>https://arxiv.org/abs/2507.10817</link>
      <description>arXiv:2507.10817v2 Announce Type: replace 
Abstract: The increasing availability of advanced computational modelling offers new opportunities to improve safety, efficacy, and emissions reductions. Application of complex models to support engineering decisions has been slow in comparison to other sectors, reflecting the higher consequence of unsafe applications. Adopting a complex model introduces a \emph{model risk}, namely the expected consequence of incorrect or otherwise unhelpful outputs. This should be weighed against the prospective benefits that the more sophisticated model can provide, also accounting for the non-zero risk of existing practice. Demonstrating when the model risk of a proposed machine learning application is As Low As Reasonably Practicable (ALARP) can help ensure that safety-critical industries benefit from complex models where appropriate while avoiding their misuse. An example of automated weld radiograph classification is presented to demonstrate how this can be achieved by combining statistical decision analysis, uncertainty quantification, and value of information.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.10817v2</guid>
      <category>stat.AP</category>
      <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Domenic Di Francesco, Alan Forrest, Fiona McGarry, Nicholas Hall, Adam Sobey</dc:creator>
    </item>
    <item>
      <title>Distribution of lowest eigenvalue in $k$-body bosonic random matrix ensembles</title>
      <link>https://arxiv.org/abs/2405.00190</link>
      <description>arXiv:2405.00190v4 Announce Type: replace-cross 
Abstract: We present numerical investigations demonstrating the result that the distribution of the lowest eigenvalue of finite many-boson systems (say we have $m$ number of bosons) with $k$-body interactions, modeled by Bosonic Embedded Gaussian Orthogonal [BEGOE($k$)] and Unitary [BEGUE($k$)] random matrix Ensembles of $k$-body interactions, exhibits a smooth transition from Gaussian like (for $k = 1$) to a modified Gumbel like (for intermediate values of $k$) to the well-known Tracy-Widom distribution (for $k = m$) form. We also provide ansatz for centroids and variances of the lowest eigenvalue distributions. In addition, we show that the distribution of normalized spacing between the lowest and the next lowest eigenvalues exhibits a transition from Wigner's surmise (for $k = 1$) to Poisson (for intermediate $k$ values with $k \le m/2$) to Wigner's surmise (starting from $k = m/2$ to $k = m$) form. We analyze these transitions as a function of $q$ parameter defining $q$-normal distribution for eigenvalue densities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00190v4</guid>
      <category>quant-ph</category>
      <category>physics.data-an</category>
      <category>stat.AP</category>
      <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>N. D. Chavda, Priyanka Rao, V. K. B. Kota, Manan Vyas</dc:creator>
    </item>
    <item>
      <title>Multi-view biclustering via non-negative matrix tri-factorisation</title>
      <link>https://arxiv.org/abs/2502.13698</link>
      <description>arXiv:2502.13698v2 Announce Type: replace-cross 
Abstract: Multi-view data is ever more apparent as methods for production, collection and storage of data become more feasible both practically and fiscally. However, not all features are relevant to describe the patterns for all individuals. Multi-view biclustering aims to simultaneously cluster both rows and columns, discovering clusters of rows as well as their view-specific identifying features. A novel multi-view biclustering approach based on non-negative matrix factorisation is proposed named ResNMTF. Demonstrated through extensive experiments on both synthetic and real datasets, ResNMTF successfully identifies both overlapping and non-exhaustive biclusters, without pre-existing knowledge of the number of biclusters present, and is able to incorporate any combination of shared dimensions across views. Further, to address the lack of a suitable bicluster-specific intrinsic measure, the popular silhouette score is extended to the bisilhouette score. The bisilhouette score is demonstrated to align well with known extrinsic measures, and proves useful as a tool for hyperparameter tuning as well as visualisation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13698v2</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ella S. C. Orme, Theodoulos Rodosthenous, Marina Evangelou</dc:creator>
    </item>
    <item>
      <title>Bayesian nonparametric copulas with tail dependence</title>
      <link>https://arxiv.org/abs/2504.00138</link>
      <description>arXiv:2504.00138v2 Announce Type: replace-cross 
Abstract: We introduce a novel bivariate copula model able to capture both the central and tail dependence of the joint probability distribution. Model that can capture the dependence structure within the joint tail have important implications in many application areas where the focus is risk management (e.g. macroeconomics and finance). We use a Bayesian nonparametric approach to introduce a random copula based on infinite partitions of unity. We define a hierarchical prior over an infinite partition of the unit hypercube which has a stick breaking representation leading to an infinite mixture of products of independent beta densities. Capitalising on the stick breaking representation we introduce a Gibbs sample to proceed to inference. For our empirical analysis we consider both simulated and real data (insurance claims and portfolio returns). We compare both our model's ability to capture tail dependence and its out of sample predictive performance to competitive models (e.g. Joe and Clayton copulas) and show that in both simulated and real examples our model outperforms the competitive models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.00138v2</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Maria Concepci\'on Aus\'in, Maria Kalli</dc:creator>
    </item>
    <item>
      <title>On Level Crossings and Fade Durations in von Mises-Fisher Scattering Channels</title>
      <link>https://arxiv.org/abs/2506.05898</link>
      <description>arXiv:2506.05898v2 Announce Type: replace-cross 
Abstract: This paper investigates the second-order statistics of multipath fading channels with von Mises-Fisher (vMF) distributed scatters. Simple closed-form expressions for the mean Doppler shift and Doppler spread are derived as the key spectral moments that capture the impact of mobility and scattering characteristics on level crossings and fade durations. These expressions are then used to analyze the influence of vMF parameters on the Level-Crossing Rate (LCR) and Average Fade Duration (AFD). The results show that isotropic scattering yields the highest LCR and the lowest AFD, while fading dynamics reduce with the decreasing angular spread of scatterers. Moreover, mobile antenna motion parallel to the mean scattering direction results in a lower LCR than the perpendicular motion, with the difference between the two cases increasing with the higher concentration of scatterers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.05898v2</guid>
      <category>eess.SP</category>
      <category>stat.AP</category>
      <pubDate>Fri, 01 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kenan Turbic, Slawomir Stanczak</dc:creator>
    </item>
  </channel>
</rss>
