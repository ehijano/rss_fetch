<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.ST updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.ST</link>
    <description>math.ST updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.ST" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 25 Aug 2025 04:01:12 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Bayesimax Theory: Selecting Priors by Minimizing Total Information</title>
      <link>https://arxiv.org/abs/2508.15976</link>
      <description>arXiv:2508.15976v1 Announce Type: new 
Abstract: We introduce Bayesimax theory, a paradigm for objective Bayesian analysis which selects priors by applying minimax theory to prior disclosure games. In these games, the uniquely optimal strategy for a Bayesian agent upon observing the data is to reveal their prior. As such, the prior chosen by minimax theory is, in effect, the implicit prior of minimax agents. Since minimax analysis disregards prior information, this prior is arguably noninformative. We refer to minimax solutions of certain prior disclosure games as Bayesimax priors, and we classify a statistical procedure as Bayesimax if it is a Bayes rule with respect to a Bayesimax prior. Under regular conditions, minimax decision rules maximize the minimum Bayes risk. We study games leveraging strictly proper scoring rules to induce posterior (and thereby prior) revelation. In such games, the minimum Bayes risk equals the conditional (generalized) entropy of the parameter given the data. In particular, for the logarithmic score a Bayesimax prior maximizes the conditional Shannon entropy. As conditional entropy equals marginal entropy (prior uninformativeness) minus mutual information (data informativeness), Bayesimax priors effectively minimize total information. We give a measure-theoretic formulation of these ideas, outline sufficient conditions for existence and minimax characterization, and investigate asymptotics and conjugate-family examples. We next describe a generic Monte Carlo algorithm for estimating conditional entropy under a given prior. Finally, we compare and contrast Bayesimax theory with various related proposals from the objective Bayes and decision theory literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.15976v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sitaram Vangala</dc:creator>
    </item>
    <item>
      <title>General M-estimators of location on Riemannian manifolds: existence and uniqueness</title>
      <link>https://arxiv.org/abs/2508.16149</link>
      <description>arXiv:2508.16149v1 Announce Type: new 
Abstract: We study general M-estimators of location on Riemannian manifolds, extending classical notions such as the Frechet mean by replacing the squared loss with a broad class of loss functions. Under minimal regularity conditions on the loss function and the underlying probability distribution, we establish theoretical guarantees for the existence and uniqueness of such estimators. In particular, we provide sufficient conditions under which the population and sample M-estimators exist and are uniquely defined. Our results offer a general framework for robust location estimation in non-Euclidean geometric spaces and unify prior uniqueness results under a broad class of convex losses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.16149v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jongmin Lee, Sungkyu Jung</dc:creator>
    </item>
    <item>
      <title>Data Gluttony: Epistemic Risks, Dependent Testing and Data Reuse in Large Datasets</title>
      <link>https://arxiv.org/abs/2508.16552</link>
      <description>arXiv:2508.16552v1 Announce Type: new 
Abstract: Large-scale registries have collected vast amounts of data which has enabled investigators to efficiently conduct studies of observational data. Common practice is for investigators to use all data meeting the inclusion criteria of their study to perform their analysis. We term this common practice data gluttony. It has apparent formal justification insofar as this approach maximizes per-study power. But this comes at a cost: data reuse affects the shape of the tail distribution of inferential errors. Using the theory of risk orderings we demonstrate how positively dependent testing procedures result in strictly riskier distributions of inferential error.
  We identify two remedies to this state of affairs: research portfolio optimization and what we term data temperance. Research portfolio optimization requires that we formulate the enterprise of inference in a utility theoretic framework: associated to each hypothesis to be evaluated is some utility dependent on its truth as well as the impact of the statistical decision rendered on the basis of the data. Under certain models of data governance, this approach can be used to optimally allocate data usage across multiple inferential tasks. On the other hand, data temperance is a more flexible strategy for managing the distribution of inferential errors. Data temperance is the principle that an investigator use only as much data as is necessary to perform the task at hand. This is possible due to the diminishing marginal returns in power and precision in sample size. We analyze the effectiveness of data temperance at reducing the dependence across testing and develop a theory of the capacity of a static database to sustain large numbers of inferential tasks with low probability of inducing pairwise dependent testing procedures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.16552v1</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Reid Dale, Jordan Rodu, Maria E. Currie, Mike Baiocchi</dc:creator>
    </item>
    <item>
      <title>On a multivariate extension for Copula-based Conditional Value at Risk</title>
      <link>https://arxiv.org/abs/2508.16132</link>
      <description>arXiv:2508.16132v1 Announce Type: cross 
Abstract: Copula-based Conditional Value at Risk (CCVaR) is defined as an alternative version of the classical Conditional Value at Risk (CVaR) for multivariate random vectors intended to be real-valued. We aim to generalize CCVaR to several dimensions (d&gt;=2) when the dependence structure is given by an Archimedean copula. While previous research focused on the bivariate case, leaving the multivariate version unexplored, an almost closed-form expression for CCVaR under an Archimedean copula is derived. The conditions under which this risk measure satisfies coherence are then examined. Finally, numerical experiments based on real data are conducted to estimate CCVaR, and the results are compared with classical measures of Value at Risk (VaR) and Conditional Value at Risk (CVaR).</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.16132v1</guid>
      <category>q-fin.PM</category>
      <category>math.ST</category>
      <category>q-fin.RM</category>
      <category>stat.TH</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andres Mauricio Molina Barreto</dc:creator>
    </item>
    <item>
      <title>A Sharp KL-Convergence Analysis for Diffusion Models under Minimal Assumptions</title>
      <link>https://arxiv.org/abs/2508.16306</link>
      <description>arXiv:2508.16306v1 Announce Type: cross 
Abstract: Diffusion-based generative models have emerged as highly effective methods for synthesizing high-quality samples. Recent works have focused on analyzing the convergence of their generation process with minimal assumptions, either through reverse SDEs or Probability Flow ODEs. The best known guarantees, without any smoothness assumptions, for the KL divergence so far achieve a linear dependence on the data dimension $d$ and an inverse quadratic dependence on $\varepsilon$. In this work, we present a refined analysis that improves the dependence on $\varepsilon$. We model the generation process as a composition of two steps: a reverse ODE step, followed by a smaller noising step along the forward process. This design leverages the fact that the ODE step enables control in Wasserstein-type error, which can then be converted into a KL divergence bound via noise addition, leading to a better dependence on the discretization step size. We further provide a novel analysis to achieve the linear $d$-dependence for the error due to discretizing this Probability Flow ODE in absence of any smoothness assumptions. We show that $\tilde{O}\left(\tfrac{d\log^{3/2}(\frac{1}{\delta})}{\varepsilon}\right)$ steps suffice to approximate the target distribution corrupted with Gaussian noise of variance $\delta$ within $O(\varepsilon^2)$ in KL divergence, improving upon the previous best result, requiring $\tilde{O}\left(\tfrac{d\log^2(\frac{1}{\delta})}{\varepsilon^2}\right)$ steps.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.16306v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.AP</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nishant Jain, Tong Zhang</dc:creator>
    </item>
    <item>
      <title>Underdamped Langevin MCMC with third order convergence</title>
      <link>https://arxiv.org/abs/2508.16485</link>
      <description>arXiv:2508.16485v1 Announce Type: cross 
Abstract: In this paper, we propose a new numerical method for the underdamped Langevin diffusion (ULD) and present a non-asymptotic analysis of its sampling error in the 2-Wasserstein distance when the $d$-dimensional target distribution $p(x)\propto e^{-f(x)}$ is strongly log-concave and has varying degrees of smoothness. Precisely, under the assumptions that the gradient and Hessian of $f$ are Lipschitz continuous, our algorithm achieves a 2-Wasserstein error of $\varepsilon$ in $\mathcal{O}(\sqrt{d}/\varepsilon)$ and $\mathcal{O}(\sqrt{d}/\sqrt{\varepsilon})$ steps respectively. Therefore, our algorithm has a similar complexity as other popular Langevin MCMC algorithms under matching assumptions. However, if we additionally assume that the third derivative of $f$ is Lipschitz continuous, then our algorithm achieves a 2-Wasserstein error of $\varepsilon$ in $\mathcal{O}(\sqrt{d}/\varepsilon^{\frac{1}{3}})$ steps. To the best of our knowledge, this is the first gradient-only method for ULD with third order convergence. To support our theory, we perform Bayesian logistic regression across a range of real-world datasets, where our algorithm achieves competitive performance compared to an existing underdamped Langevin MCMC algorithm and the popular No U-Turn Sampler (NUTS).</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.16485v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maximilian Scott, D\'aire O'Kane, Andra\v{z} Jelin\v{c}i\v{c}, James Foster</dc:creator>
    </item>
    <item>
      <title>FraPPE: Fast and Efficient Preference-based Pure Exploration</title>
      <link>https://arxiv.org/abs/2508.16487</link>
      <description>arXiv:2508.16487v1 Announce Type: cross 
Abstract: Preference-based Pure Exploration (PrePEx) aims to identify with a given confidence level the set of Pareto optimal arms in a vector-valued (aka multi-objective) bandit, where the reward vectors are ordered via a (given) preference cone $\mathcal{C}$. Though PrePEx and its variants are well-studied, there does not exist a computationally efficient algorithm that can optimally track the existing lower bound for arbitrary preference cones. We successfully fill this gap by efficiently solving the minimisation and maximisation problems in the lower bound. First, we derive three structural properties of the lower bound that yield a computationally tractable reduction of the minimisation problem. Then, we deploy a Frank-Wolfe optimiser to accelerate the maximisation problem in the lower bound. Together, these techniques solve the maxmin optimisation problem in $\mathcal{O}(KL^{2})$ time for a bandit instance with $K$ arms and $L$ dimensional reward, which is a significant acceleration over the literature. We further prove that our proposed PrePEx algorithm, FraPPE, asymptotically achieves the optimal sample complexity. Finally, we perform numerical experiments across synthetic and real datasets demonstrating that FraPPE achieves the lowest sample complexities to identify the exact Pareto set among the existing algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.16487v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Udvas Das, Apurv Shukla, Debabrota Basu</dc:creator>
    </item>
    <item>
      <title>Stabilized Cross-Validation of Smoothness in Density Deconvolution</title>
      <link>https://arxiv.org/abs/2401.01478</link>
      <description>arXiv:2401.01478v2 Announce Type: replace 
Abstract: We consider density estimation under measurement error with the Smoothness-Penalized Deconvolution (SPeD) estimator. The estimator has a tuning parameter regulating the smoothness of the estimate, and proper choice of this parameter is critical for forming good estimates. We derive the cross-validation choice of tuning parameter for the SPeD estimator, but it performs very poorly. We introduce a stabilized cross-validation (SCV) criterion which unbiasedly estimates the mean integrated squared error (MISE) for a smaller sample size, and use asymptotic arguments to obtain an appropriate tuning parameter from this stabilized criterion. We show that the SCV is a strongly consistent estimator of the MISE, and that it is the minimum variance unbiased estimator of the MISE. In a simulation study, we show that the SCV approach outperforms the previously recommended choice of tuning parameter in nearly all settings, and in a majority of the settings, SPeD with the SCV outperforms the classic deconvoluting kernel estimator with its recommended choice of tuning parameter.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.01478v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David Kent</dc:creator>
    </item>
    <item>
      <title>Asymptotic Theory for Linear Functionals of Kernel Ridge Regression</title>
      <link>https://arxiv.org/abs/2403.04248</link>
      <description>arXiv:2403.04248v3 Announce Type: replace 
Abstract: An asymptotic theory is established for linear functionals of the predictive function given by kernel ridge regression, when the reproducing kernel Hilbert space is equivalent to a Sobolev space. The theory covers a wide variety of linear functionals, including point evaluations, evaluation of derivatives, $L_2$ inner products, etc. We establish the upper and lower bounds of the estimates and their asymptotic normality. It is shown that $\lambda\sim n^{-1}$ is the universal optimal order of magnitude for the smoothing parameter to balance the variance and the worst-case bias. The theory also implies that the optimal $L_\infty$ error of kernel ridge regression can be attained under the optimal smoothing parameter $\lambda\sim n^{-1}\log n$. These optimal rates for the smoothing parameter differ from the known optimal rate $\lambda\sim n^{-\frac{2m}{2m+d}}$ that minimizes the $L_2$ error of the kernel ridge regression.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.04248v3</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rui Tuo, Lu Zou</dc:creator>
    </item>
    <item>
      <title>Online jump and kink detection in segmented linear regression: Statistical optimality meets computational efficiency</title>
      <link>https://arxiv.org/abs/2503.05270</link>
      <description>arXiv:2503.05270v2 Announce Type: replace 
Abstract: We consider the problem of sequential (online) estimation of a single change point in a piecewise linear regression model under a Gaussian setup. We demonstrate that certain CUSUM-type statistics attain the minimax optimal rates for localizing the change point. Our minimax analysis unveils an interesting phase transition from a jump (discontinuity in function values) to a kink (a change in slope). Specifically, for a jump, the minimax rate is of order $\log (n) / n$ , whereas for a kink it scales as $(\log (n) / n)^{1/3}$, given that the sampling rate is of order $1/n$. We further introduce an online algorithm based on these detectors, which optimally identifies both a jump and a kink, and is able to distinguish between them. Notably, the algorithm operates with constant computational complexity and requires only constant memory per incoming sample. Finally, we evaluate the empirical performance of our method on both simulated and real-world data sets. An implementation is available in the R package FLOC on GitHub.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.05270v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Annika H\"uselitz, Housen Li, Axel Munk</dc:creator>
    </item>
    <item>
      <title>Smooth and rough paths in mean derivative estimation for functional data</title>
      <link>https://arxiv.org/abs/2503.24066</link>
      <description>arXiv:2503.24066v2 Announce Type: replace 
Abstract: In this paper, in a multivariate setting we derive near optimal rates of convergence in the minimax sense for estimating partial derivatives of the mean function for functional data observed under a fixed synchronous design over H\"older smoothness classes. We focus on the supremum norm since it corresponds to the visualisation of the estimation error, and is closely related to the construction of uniform confidence bands. In contrast to mean function estimation, for derivative estimation the smoothness of the paths of the processes is crucial for the rates of convergence. On the one hand, if the paths have higher-order smoothness than the order of the partial derivative to be estimated, the parametric $\sqrt n$ rate can be achieved under sufficiently dense design. On the other hand, for processes with rough paths of lower-order smoothness, we show that the rates of convergence are necessarily slower than the parametric rate, and determine a near-optimal rate at which estimation is still possible. We implement a multivariate local polynomial derivative estimator and illustrate its finite-sample performance in a simulation as well as for two real-data sets. To assess the smoothness of the sample paths in the applications we further discuss a method based on comparing restricted estimates of the partial derivatives of the covariance kernel.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.24066v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Max Berger, Hajo Holzmann</dc:creator>
    </item>
    <item>
      <title>Statistical methods: Basic concepts, interpretations, and cautions</title>
      <link>https://arxiv.org/abs/2508.10168</link>
      <description>arXiv:2508.10168v2 Announce Type: replace-cross 
Abstract: The study of associations and their causal explanations is a central research activity whose methodology varies tremendously across fields. Even within specialized subfields, comparisons across textbooks and journals reveals that the basics are subject to considerable variation and controversy. This variation is often obscured by the singular viewpoints presented within textbooks and journal guidelines, which may be deceptively written as if the norms they adopt are unchallenged. Furthermore, human limitations and the vastness within fields imply that no one can have expertise across all subfields and that interpretations will be severely constrained by the limitations of studies of human populations.
  The present chapter outlines an approach to statistical methods that attempts to recognize these problems from the start, rather than assume they are absent as in the claims of 'statistical significance' and 'confidence' ordinarily attached to statistical tests and interval estimates. It does so by grounding models and statistics in data description, and treating inferences from them as speculations based on assumptions that cannot be fully validated or checked using the analysis data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10168v2</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Sander Greenland</dc:creator>
    </item>
    <item>
      <title>Factor Models of Matrix-Valued Time Series: Nonstationarity and Cointegration</title>
      <link>https://arxiv.org/abs/2508.11358</link>
      <description>arXiv:2508.11358v2 Announce Type: replace-cross 
Abstract: In this paper, we consider the nonstationary matrix-valued time series with common stochastic trends. Unlike the traditional factor analysis which flattens matrix observations into vectors, we adopt a matrix factor model in order to fully explore the intrinsic matrix structure in the data, allowing interaction between the row and column stochastic trends, and subsequently improving the estimation convergence. It also reduces the computation complexity in estimation. The main estimation methodology is built on the eigenanalysis of sample row and column covariance matrices when the nonstationary matrix factors are of full rank and the idiosyncratic components are temporally stationary, and is further extended to tackle a more flexible setting when the matrix factors are cointegrated and the idiosyncratic components may be nonstationary. Under some mild conditions which allow the existence of weak factors, we derive the convergence theory for the estimated factor loading matrices and nonstationary factor matrices. In particular, the developed methodology and theory are applicable to the general case of heterogeneous strengths over weak factors. An easy-to-implement ratio criterion is adopted to consistently estimate the size of latent factor matrix. Both simulation and empirical studies are conducted to examine the numerical performance of the developed model and methodology in finite samples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.11358v2</guid>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Degui Li, Yayi Yan, Qiwei Yao</dc:creator>
    </item>
  </channel>
</rss>
