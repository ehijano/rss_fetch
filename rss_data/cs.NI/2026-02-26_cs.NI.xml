<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 27 Feb 2026 02:44:38 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>UnlinkableDFL: a Practical Mixnet Protocol for Churn-Tolerant Decentralized FL Model Sharing</title>
      <link>https://arxiv.org/abs/2602.21343</link>
      <description>arXiv:2602.21343v1 Announce Type: new 
Abstract: Decentralized Federated Learning (DFL) eliminates the need for a central aggregator, but it can expose communication patterns that reveal participant identities. This work presents UnlinkableDFL, a DFL framework that combines a peer-based mixnet with fragment-based model aggregation to ensure unlinkability in fully decentralized settings. Model updates are divided into encrypted fragments, sent over separate multi-hop paths, and aggregated without using any identity information. A theoretical analysis indicates that relay and end-to-end unlinkability improve with larger mixing sets and longer paths, while convergence remains similar to standard FedAvg. A prototype implementation evaluates learning performance, latency, unlinkability, and resource usage. The results show that UnlinkableDFL converges reliably and adapts to node churn. Communication latency emerges as the main overhead, while memory and CPU usage stay moderate. These findings illustrate the balance between anonymity and system efficiency, demonstrating that strong unlinkability can be maintained in decentralized learning workflows.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.21343v1</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chao Feng, Thomas Grubl, Jan von der Assen, Sandrin Raphael Hunkeler, Linn Anna Spitz, Gerome Bovet, Burkhard Stiller</dc:creator>
    </item>
    <item>
      <title>Compensating the Packet Delay Variation for 6G Integrated with IEEE Time-Sensitive Networking</title>
      <link>https://arxiv.org/abs/2602.21444</link>
      <description>arXiv:2602.21444v1 Announce Type: new 
Abstract: 6G is deemed as a key technology to support emerging applications with stringent requirements for highly dependable and timecritical communication. In this paper, we investigate 6G networks integrated with TSN and how to compensate for wireless stochastic behavior which involves a large intrinsic packet delay variation. We evaluate a 6G solution to reduce packet delay variation that is based on de-jittering. For this, we propose to use virtual timeslots for providing the required time-awareness. We discuss the benefits of the proposed solution while evaluating the impact of the timeslot size on the number of schedulable TSN streams.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.21444v1</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Marilet De Andrade, Joachim Sachs, Lucas Haug, Simon Egger, Frank D\"urr, Bal\'azs Varga, Janos Farkas, Gy\"orgy Mikl\'os</dc:creator>
    </item>
    <item>
      <title>Lossy Compression of Network Feature Data: When Less Is Enough</title>
      <link>https://arxiv.org/abs/2602.21891</link>
      <description>arXiv:2602.21891v1 Announce Type: new 
Abstract: Network traffic analysis increasingly relies on feature-based representations to support monitoring and security in the presence of pervasive encryption. Although features are more compact than raw packet traces, their storage has become a scalability bottleneck from large-scale core networks to resource-constrained Internet of Things (IoT) environments. This article investigates task-aware lossy compression strategies that reduce the storage footprint of traffic features while preserving analytics accuracy. Using website classification in core networks and device identification in IoT environments as representative use cases, we show that simple, semantics-preserving compression techniques expose stable operating regions that balance storage efficiency and task performance. These results highlight compression as a first-class design dimension in scalable network monitoring systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.21891v1</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fabio Palmese, Gabriele Merlach, Damiano Ravalico, Martino Trevisan, Alessandro E. C. Redondi</dc:creator>
    </item>
    <item>
      <title>The Instability of all Backoff Protocols</title>
      <link>https://arxiv.org/abs/2602.21315</link>
      <description>arXiv:2602.21315v1 Announce Type: cross 
Abstract: In this paper we prove Aldous's conjecture from 1987 that there is no backoff protocol that is stable for any positive arrival rate. The setting is a communication channel for coordinating requests for a shared resource. Each user who wants to access the resource makes a request by sending a message to the channel. The users don't have any way to communicate with each other, except by sending messages to the channel. The operation of the channel proceeds in discrete time steps. If exactly one message is sent to the channel during a time step then this message succeeds (and leaves the system). If multiple messages are sent during a time step then these messages collide. Each of the users that sent these messages therefore waits a random amount of time before re-sending. A backoff protocol is a randomised algorithm for determining how long to wait -- the waiting time is a function of how many collisions a message has had. Specifically, a backoff protocol is described by a send sequence $\overline{p} = (p_0,p_1,p_2,\ldots)$. If a message has had $k$ collisions before a time step then, with probability $p_k$, it sends during that time step, whereas with probability $1-p_k$ it is silent (waiting for later). The most famous backoff protocol is binary exponential backoff, where $p_k = 2^{-k}$. Under Kelly's model, in which the number of new messages that arrive in the system at each time step is given by a Poisson random variable with mean $\lambda$, Aldous proved that binary exponential backoff is unstable for any positive $\lambda$. He conjectured that the same is true for any backoff protocol. We prove this conjecture.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.21315v1</guid>
      <category>math.PR</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>cs.IT</category>
      <category>cs.NI</category>
      <category>math.IT</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Leslie Ann Goldberg, John Lapinskas</dc:creator>
    </item>
    <item>
      <title>Implementation and transition to post-quantum cryptography of the Minimal IKE protocol</title>
      <link>https://arxiv.org/abs/2602.21737</link>
      <description>arXiv:2602.21737v1 Announce Type: cross 
Abstract: This paper concerns the Minimal Internet Key Exchange (IKE) protocol, which has received little attention to date, despite its potential to make the best-known IKE protocol sufficiently lightweight to be also applied in contexts where it is currently prohibitive, due to its large footprint. First, we introduce and describe Colibri, an efficient, open-source implementation of the Minimal IKE protocol, which allows us to quantitatively assess its real advantages in terms of lightness. Then we introduce a post-quantum variant of the Minimal IKE protocol, which is essential to make it contemporary, and assess it through Colibri. We demonstrate that the protocol performance remains excellent even in such a more challenging context, making it suitable for deploying pervasive and quantum-resistant virtual private networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.21737v1</guid>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Davide De Zuane, Paolo Santini, Marco Baldi</dc:creator>
    </item>
    <item>
      <title>Dual-Hop Joint Visible Light and Backscatter Communication Relaying under Finite Blocklength</title>
      <link>https://arxiv.org/abs/2602.21744</link>
      <description>arXiv:2602.21744v1 Announce Type: cross 
Abstract: This paper investigates a dual-hop joint visible light communication (VLC) and backscatter communication (BC) relaying framework under the finite blocklength (FBL) constraint, aiming at energy-neutral Ambient Internet of Things (A-IoT) deployments. In the proposed system, indoor LED access points are used to simultaneously provide illumination and transmit information over light to a backscatter device (BD), which harvests optical energy and backscatters the received messages to user equipments (UEs) equipped with radio frequency (RF) front ends. This forwarding of the information from VLC to RF channels is implemented without the need for carrier synthesizers and power amplifiers at the IoT node. By modeling the end-to-end communication link with short-packet IoT traffic and realistic levels of interference between adjacent VLC coverage areas, we analyze the outage performance and achievable data rate of the proposed system. Simulation results demonstrate that key factors, such as placement and orientation of the BD, as well as the selected code rate of the system affect reliability and data rate that can be achieved for communication purposes. The insights gained from this study pave the way for ambient power-enabled IoT solutions and future hybrid VLC/RF network designs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.21744v1</guid>
      <category>eess.SP</category>
      <category>cs.NI</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Boxuan Xie, Lauri Mela, Alexis A. Dowhuszko, Jiacheng Wang, Kalle Ruttik, Riku J\"antti</dc:creator>
    </item>
    <item>
      <title>Enhancing Cellular-enabled Collaborative Robots Planning through GNSS data for SAR Scenarios</title>
      <link>https://arxiv.org/abs/2602.21899</link>
      <description>arXiv:2602.21899v1 Announce Type: cross 
Abstract: Cellular-enabled collaborative robots are becoming paramount in Search-and-Rescue (SAR) and emergency response. Crucially dependent on resilient mobile network connectivity, they serve as invaluable assets for tasks like rapid victim localization and the exploration of hazardous, otherwise unreachable areas. However, their reliance on battery power and the need for persistent, low-latency communication limit operational time and mobility. To address this, and considering the evolving capabilities of 5G/6G networks, we propose a novel SAR framework that includes Mission Planning and Mission Execution phases and that optimizes robot deployment. By considering parameters such as the exploration area size, terrain elevation, robot fleet size, communication-influenced energy profiles, desired exploration rate, and target response time, our framework determines the minimum number of robots required and their optimal paths to ensure effective coverage and timely data backhaul over mobile networks. Our results demonstrate the trade-offs between number of robots, explored area, and response time for wheeled and quadruped robots. Further, we quantify the impact of terrain elevation data on mission time and energy consumption, showing the benefits of incorporating real-world environmental factors that might also affect mobile signal propagation and connectivity into SAR planning. This framework provides critical insights for leveraging next-generation mobile networks to enhance autonomous SAR operations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.21899v1</guid>
      <category>cs.RO</category>
      <category>cs.NI</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.comcom.2025.108376</arxiv:DOI>
      <dc:creator>Arnau Romero, Carmen Delgado, Jana Baguer, Ra\'ul Su\'arez, Xavier Costa-P\'erez</dc:creator>
    </item>
    <item>
      <title>A Generic Web Component for WebRTC Pub-Sub</title>
      <link>https://arxiv.org/abs/2602.22011</link>
      <description>arXiv:2602.22011v1 Announce Type: cross 
Abstract: We present video-io, a generic web component to publish or subscribe to a media stream in WebRTC (web real-time communication) applications. Unlike a call or conference room abstraction of existing video conferencing services, it uses a named stream abstraction, which is useful in many scenarios beyond just a call or conference. It keeps most of the application logic in the endpoint using the extensive application interface of this component, and keeps any vendor specific access control or signaling negotiation in a service-specific connector implementation. This allows an app developer to write once, and be able to run the web app on different servers or services. We also demonstrate its flexibility by implementing the connector for ten different existing systems and services. Decoupling the app from the hosted vendor service promotes innovation in the endpoint beyond what a single vendor locked client app can offer.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.22011v1</guid>
      <category>cs.MM</category>
      <category>cs.NI</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kundan Singh</dc:creator>
    </item>
    <item>
      <title>MSADM: Large Language Model (LLM) Assisted End-to-End Network Health Management Based on Multi-Scale Semanticization</title>
      <link>https://arxiv.org/abs/2406.08305</link>
      <description>arXiv:2406.08305v3 Announce Type: replace 
Abstract: Network device and system health management is the foundation of modern network operations and maintenance. Traditional health management methods, relying on expert identification or simple rule-based algorithms, struggle to cope with the heterogeneous networks (HNs) environment. Moreover, current state-of-the-art distributed fault diagnosis methods, which utilize specific machine learning techniques, lack multi-scale adaptivity for heterogeneous device information, resulting in unsatisfactory diagnostic accuracy for HNs. In this paper, we develop an LLM-assisted end-to-end intelligent network health management framework. The framework first proposes a multi-scale data scaling method based on unsupervised learning to address the multi-scale data problem in HNs. Secondly, we combine the semantic rule tree with the attention mechanism to propose a Multi-Scale Semanticized Anomaly Detection Model (MSADM) that generates network semantic information while detecting anomalies. Finally, we embed a chain-of-thought-based large-scale language model downstream to adaptively analyze the fault diagnosis results and create an analysis report containing detailed fault information and optimization strategies. We compare our scheme with other fault diagnosis models and demonstrate that it performs well on several metrics of network fault diagnosis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.08305v3</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fengxiao Tang, Xiaonan Wang, Xun Yuan, Linfeng Luo, Ming Zhao, Tianchi Huang, Nei Kato</dc:creator>
    </item>
    <item>
      <title>Nexus: Efficient and Scalable Multi-Cell mmWave Baseband Processing with Heterogeneous Compute</title>
      <link>https://arxiv.org/abs/2509.04625</link>
      <description>arXiv:2509.04625v2 Announce Type: replace 
Abstract: The rapid adoption of 5G New Radio (NR), particularly in the millimeter-wave (mmWave) spectrum, imposes stringent demands on the flexibility, scalability, and efficiency of baseband processing. While virtualized Radio Access Networks (vRANs) enable dynamic spectrum sharing across cells, compute resource allocation for baseband processing, especially in multi-cell deployments with heterogeneous workloads, remains underexplored. In this paper, we present NEXUS, the first system to realize real-time, virtualized multi-cell mmWave baseband processing on a single server with heterogeneous compute resources. NEXUS integrates software-based digital signal processing pipelines with hardware-accelerated LDPC decoding, and introduces a novel framework for sharing Intel's ACC100 eASIC across multiple CPU cores via virtual functions (VFs). For single-cell operation, NEXUS employs a random forest (RAF)-based model that predicts the most energy-efficient resource allocation for the given cell configuration with microsecond-level inference latency and high accuracy. For multi-cell scenarios, NEXUS introduces a power-aware scheduler that incorporates a lightweight contention model to adjust resource allocation strategies under concurrent execution. Through extensive evaluation across various Frequency Range 2 (FR2) cell configurations, we show that NEXUS supports up to 16 concurrent cells under full load, achieving 5.37Gbps aggregate throughput, while reducing the multi-cell scheduling search space by orders of magnitude. These results demonstrate that virtualized, resource-aware baseband processing is both practical and efficient for next-generation vRAN systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.04625v2</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Zhenzhou Qi, Chung-Hsuan Tung, Zhihui Gao, Tingjun Chen</dc:creator>
    </item>
    <item>
      <title>Wi-Fi Radar via Over-the-Air Referencing: Bridging Wi-Fi Sensing and Bistatic Radar</title>
      <link>https://arxiv.org/abs/2602.05344</link>
      <description>arXiv:2602.05344v2 Announce Type: replace 
Abstract: Wi-Fi channel state information (CSI), which is originally acquired for communication purposes, has recently been reused for sensing and radar-like functionalities. However, in practical Wi-Fi systems with independent clocks at the transmitter and receiver, the lack of a common delay and phase reference fundamentally precludes phase-coherent radar-like delay--Doppler analysis. By exploiting the line-of-sight (LoS) path component, i.e., the earliest-arriving direct path, as an over-the-air (OTA) reference for delay and phase, we propose an OTA LoS-path referencing scheme, termed LoSRef, that enables delay calibration and phase alignment under this practical constraint. Unlike conventional Wi-Fi bistatic radar systems that rely on wired reference signals or dedicated reference antennas, the proposed LoSRef-based framework enables phase-coherent bistatic radar-like operation that can be integrated into typically deployed Wi-Fi systems. Through human gait and respiration experiments in indoor environments, we demonstrate that phase-coherent channel impulse responses and corresponding delay--Doppler responses can be obtained using only commodity Wi-Fi devices. This enables physically interpretable human motion sensing, including gait-induced range variation and respiration-induced sub-wavelength displacement, as well as the extraction of target-induced dynamics up to 20 dB weaker than dominant static multipath components.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.05344v2</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Koji Yamamoto</dc:creator>
    </item>
    <item>
      <title>A Uniqueness Theorem for Distributed Computation under Physical Constraint</title>
      <link>https://arxiv.org/abs/2509.11754</link>
      <description>arXiv:2509.11754v2 Announce Type: replace-cross 
Abstract: Foundational models of computation often abstract away physical hardware limitations. However, in extreme environments like In-Network Computing (INC), these limitations become inviolable laws, creating an acute trilemma among communication efficiency, bounded memory, and robust scalability. Prevailing distributed paradigms, while powerful in their intended domains, were not designed for this stringent regime and thus face fundamental challenges. This paper demonstrates that resolving this trilemma requires a shift in perspective - from seeking engineering trade-offs to deriving solutions from logical necessity. We establish a rigorous axiomatic system that formalizes these physical constraints and prove that for the broad class of computations admitting an idempotent merge operator, there exists a unique, optimal paradigm. Any system satisfying these axioms must converge to a single normal form: Self-Describing Parallel Flows (SDPF), a purely data-centric model where stateless executors process flows that carry their own control logic. We further prove this unique paradigm is convergent, Turing-complete, and minimal. In the same way that the CAP theorem established a boundary for what is impossible in distributed state management, our work provides a constructive dual: a uniqueness theorem that reveals what is \textit{inevitable} for distributed computation flows under physical law.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11754v2</guid>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhiyuan Ren, Mingxuan Lu, Wenchi Cheng</dc:creator>
    </item>
    <item>
      <title>How segmented is my network?</title>
      <link>https://arxiv.org/abs/2602.10125</link>
      <description>arXiv:2602.10125v3 Announce Type: replace-cross 
Abstract: Network segmentation is a popular security practice for limiting lateral movement, yet practitioners lack a metric to measure how segmented a network actually is. We introduce the first statistically principled metric for network segmentedness based on global edge density, enabling practitioners to quantify what has previously been assessed only qualitatively. Then, we derive a normalized estimator for segmentedness and evaluate its uncertainty using confidence intervals. For a 95\% confidence interval with a margin-of-error of $\pm 0.1$, we show that a minimum of $M=97$ sampled node pairs is sufficient. This result is independent of the total number of nodes in the network, provided that node pairs are sampled uniformly at random. We evaluate the estimator through Monte Carlo simulations on Erd\H{o}s--R\'enyi, stochastic block models, and real-world enterprise network datasets, demonstrating accurate estimation and well-behaved coverage. Finally, we discuss applications of the estimator, such as baseline tracking, zero trust assessment, and merger integration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10125v3</guid>
      <category>cs.SI</category>
      <category>cs.NI</category>
      <category>stat.AP</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rohit Dube</dc:creator>
    </item>
    <item>
      <title>Instruction-Set Architecture for Programmable NV-Center Quantum Repeater Nodes</title>
      <link>https://arxiv.org/abs/2602.14995</link>
      <description>arXiv:2602.14995v2 Announce Type: replace-cross 
Abstract: Programmability is increasingly central in emerging quantum network software stacks, yet the node-internal controller-to-hardware interface for quantum repeater devices remains under-specified. We introduce the idea of an instruction-set architecture (ISA) for controller-driven programmability of nitrogen-vacancy (NV) center quantum repeater nodes. Each node consists of an optically interfaced electron spin acting as a data qubit and a long-lived nuclear-spin register acting as a control program. We formalize two modes of programmability: (i) deterministic register control, where the nuclear register is initialized in a basis state to select a specific operation on the data qubit; and (ii) coherent register control, where the register is prepared in superposition, enabling coherent combinations of operations beyond classical programmability. Network protocols are expressed as controller-issued instruction vectors, which we illustrate through a compact realization of the BBPSSW purification protocol. We further show that coherent register control enables interferometric diagnostics such as fidelity witnessing and calibration, providing tools unavailable in classical programmability. Finally, we discuss scalability to multi-electron and multi-nuclear spin architectures and connection to Linear combination of unitaries (LCU) and Kraus formulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14995v2</guid>
      <category>quant-ph</category>
      <category>cs.NI</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vinay Kumar, Claudio Cicconetti, Riccardo Bassoli, Marco Conti, Andrea Passarella</dc:creator>
    </item>
  </channel>
</rss>
