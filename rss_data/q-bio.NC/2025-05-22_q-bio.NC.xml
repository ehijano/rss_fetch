<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 23 May 2025 01:45:14 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 22 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Place Cells as Position Embeddings of Multi-Time Random Walk Transition Kernels for Path Planning</title>
      <link>https://arxiv.org/abs/2505.14806</link>
      <description>arXiv:2505.14806v2 Announce Type: new 
Abstract: The hippocampus orchestrates spatial navigation through collective place cell encodings that form cognitive maps. We reconceptualize the population of place cells as position embeddings approximating multi-scale symmetric random walk transition kernels: the inner product $\langle h(x, t), h(y, t) \rangle = q(y|x, t)$ represents normalized transition probabilities, where $h(x, t)$ is the embedding at location $ x $, and $q(y|x, t)$ is the normalized symmetric transition probability over time $t$. The time parameter $\sqrt{t}$ defines a spatial scale hierarchy, mirroring the hippocampal dorsoventral axis. $q(y|x, t)$ defines spatial adjacency between $x$ and $y$ at scale or resolution $\sqrt{t}$, and the pairwise adjacency relationships $(q(y|x, t), \forall x, y)$ are reduced into individual embeddings $(h(x, t), \forall x)$ that collectively form a map of the environment at sale $\sqrt{t}$. Our framework employs gradient ascent on $q(y|x, t) = \langle h(x, t), h(y, t)\rangle$ with adaptive scale selection, choosing the time scale with maximal gradient at each step for trap-free, smooth trajectories. Efficient matrix squaring $P_{2t} = P_t^2$ builds global representations from local transitions $P_1$ without memorizing past trajectories, enabling hippocampal preplay-like path planning. This produces robust navigation through complex environments, aligning with hippocampal navigation. Experimental results show that our model captures place cell properties -- field size distribution, adaptability, and remapping -- while achieving computational efficiency. By modeling collective transition probabilities rather than individual place fields, we offer a biologically plausible, scalable framework for spatial navigation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.14806v2</guid>
      <category>q-bio.NC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Thu, 22 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Minglu Zhao, Dehong Xu, Deqian Kong, Wen-Hao Zhang, Ying Nian Wu</dc:creator>
    </item>
    <item>
      <title>Neural Heterogeneity Enables Adaptive Encoding of Time Sequences</title>
      <link>https://arxiv.org/abs/2505.14855</link>
      <description>arXiv:2505.14855v1 Announce Type: new 
Abstract: Biological systems represent time from microseconds to years. An important gap in our knowledge concerns the mechanisms for encoding time intervals of hundreds of milliseconds to minutes that matter for tasks like navigation, communication, storage, recall, and prediction of stimulus patterns. A recently identified mechanism in fish thalamic neurons addresses this gap. Representation of intervals between events uses the ubiquitous property of neural fatigue, where firing adaptation sets in quickly during an event. The recovery from fatigue by the next stimulus is a monotonous function of time elapsed. Here we develop a full theory for the representation of intervals, allowing for recovery time scales and sensitivity to past stimuli to vary across cells. Our Bayesian framework combines parametrically heterogeneous stochastic dynamical modeling with interval priors to predict available timing information independent of actual decoding mechanism. A compromise is found between optimally encoding the latest time interval and previous ones, crucial for spatial navigation. Cellular heterogeneity is actually necessary to represent interval sequences, a novel computational role for experimentally observed heterogeneity. This biophysical adaptation-based timing memory shapes spatiotemporal information for efficient storage and recall in target recurrent networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.14855v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Thu, 22 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rapha\"el Lafond-Mercier, Leonard Maler, Avner Wallach, Andr\'e Longtin</dc:creator>
    </item>
    <item>
      <title>A dynamical memory with only one spiking neuron</title>
      <link>https://arxiv.org/abs/2505.15453</link>
      <description>arXiv:2505.15453v1 Announce Type: new 
Abstract: Common wisdom indicates that to implement a Dynamical Memory with spiking neurons two ingredients are necessary: recurrence and a neuron population. Here we shall show that the second requirement is not needed. We shall demonstrate that under very general assumptions a single recursive spiking neuron can realize a robust model of a dynamical memory. We demonstrate the implementation of a dynamical memory in both, software and hardware. In the former case, we introduce trivial extensions of the popular aQIF and AdEx models. In the latter, we show traces obtained in a circuit model with a recently proposed memristive spiking neuron. We show that the bistability of the theoretical models can be understood in terms of a self-consistent problem that can be represented geometrically. Our minimal dynamical memory model provides a simplest implementation of an important neuro-computational primitive, which can be useful in navigation system models based on purely spiking dynamics. A one neuron dynamical memory may also provides a natural explanation to the surprising recent observation that the excitation bump in Drosophila's ellipsoidal body is made by just a handful of neurons.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.15453v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Thu, 22 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Damien Depannemaecker, Adrien d'Hollande, Jiaming Wu, Marcelo J. Rozenberg</dc:creator>
    </item>
    <item>
      <title>Brain volume predicts survival of colliding-spreading messages on mammal brain networks</title>
      <link>https://arxiv.org/abs/2505.15477</link>
      <description>arXiv:2505.15477v1 Announce Type: new 
Abstract: White matter in mammal brains forms a densely interconnected communication network. Due to high edge density, along with continuous generation and spread of messages, brain networks must contend with congestion, which may limit polysynaptic message survival in complex ways. Here we study congestion with a colliding-spreading model, a synchronous Markovian process where messages arriving coincidentally at a node are deleted, while surviving messages spread to all nearest neighbors. Numerical simulations on a large sample of mammal connectomes demonstrate that message survival follows a positively skewed lognormal-like distribution for all connectomes tested. This distribution mirrors empirical distributions of interareal distances and edge weights. However, the distribution of message survival is an emergent property of system dynamics and graph topology alone; it does not require interareal distances or edge weights. We then show that message survival is well predicted by log brain volume (r = -0.64) across species. Thus, messages survive longer in small compared to large mammals, in accordance with the notion that larger brains become more modular. Chimpanzee showed the lowest message survival among the animals tested. We describe structural properties that may play a role in generating these dynamics and we discuss implications of our results for brain function and evolution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.15477v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Thu, 22 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yan Hao, Tate Tower, Hannah Lax, Marc-Thorsten H\"utt, Daniel J. Graham</dc:creator>
    </item>
    <item>
      <title>Meta-Learning an In-Context Transformer Model of Human Higher Visual Cortex</title>
      <link>https://arxiv.org/abs/2505.15813</link>
      <description>arXiv:2505.15813v1 Announce Type: cross 
Abstract: Understanding functional representations within higher visual cortex is a fundamental question in computational neuroscience. While artificial neural networks pretrained on large-scale datasets exhibit striking representational alignment with human neural responses, learning image-computable models of visual cortex relies on individual-level, large-scale fMRI datasets. The necessity for expensive, time-intensive, and often impractical data acquisition limits the generalizability of encoders to new subjects and stimuli. BraInCoRL uses in-context learning to predict voxelwise neural responses from few-shot examples without any additional finetuning for novel subjects and stimuli. We leverage a transformer architecture that can flexibly condition on a variable number of in-context image stimuli, learning an inductive bias over multiple subjects. During training, we explicitly optimize the model for in-context learning. By jointly conditioning on image features and voxel activations, our model learns to directly generate better performing voxelwise models of higher visual cortex. We demonstrate that BraInCoRL consistently outperforms existing voxelwise encoder designs in a low-data regime when evaluated on entirely novel images, while also exhibiting strong test-time scaling behavior. The model also generalizes to an entirely new visual fMRI dataset, which uses different subjects and fMRI data acquisition parameters. Further, BraInCoRL facilitates better interpretability of neural signals in higher visual cortex by attending to semantically relevant stimuli. Finally, we show that our framework enables interpretable mappings from natural language queries to voxel selectivity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.15813v1</guid>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <pubDate>Thu, 22 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Muquan Yu, Mu Nan, Hossein Adeli, Jacob S. Prince, John A. Pyles, Leila Wehbe, Margaret M. Henderson, Michael J. Tarr, Andrew F. Luo</dc:creator>
    </item>
    <item>
      <title>Uncovering potential effects of spontaneous waves on synaptic development: the visual system as a model</title>
      <link>https://arxiv.org/abs/2504.18991</link>
      <description>arXiv:2504.18991v2 Announce Type: replace 
Abstract: Spontaneous waves are ubiquitous during early brain development and are hypothesized to drive the development of receptive fields (RFs). Different stages of spontaneous waves in the retina have been observed to coincide with the development of the retinotopic map, ON-OFF segregation, and orientation selectivity in the early visual pathway of mammals, and can be characterized by different activity patterns in the retina and downstream areas. Stage II waves, which occur in rodents right after birth, have been implicated in a possible synaptic pruning process, relating these stage II retinal waves to the refinement of the retinotopic map. However, the mechanisms underlying the activity-dependent effects of retinal waves on synapses into the primary visual cortex (V1) are poorly understood. In this work, we build a biologically-constrained model of the development of thalamocortical synapses of V1 cells driven by stage II retinal waves using a spike-timing dependent triplet learning rule. Using this model, together with a reduced rate-based model, we propose mechanisms underlying such a pruning process and predict how characteristics of the retinal waves may lead to different RF structures, including periodic RFs. We introduce gap junctions into the V1 network and show that such a coupling can serve to promote precise local retinotopy. Finally, we discuss how the spatial distribution of synaptic weights at the end of stage II may affect the emergence of orientation selectivity of V1 neurons during stage III waves. The mechanisms uncovered in this work may be useful in understanding synaptic structures that emerge across cortical regions during development.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.18991v2</guid>
      <category>q-bio.NC</category>
      <pubDate>Thu, 22 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jennifer Crodelle, Wei P. Dai</dc:creator>
    </item>
  </channel>
</rss>
