<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.EM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.EM</link>
    <description>econ.EM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.EM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 25 Nov 2025 05:03:10 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Limit Theorems for Network Data without Metric Structure</title>
      <link>https://arxiv.org/abs/2511.17928</link>
      <description>arXiv:2511.17928v1 Announce Type: new 
Abstract: This paper develops limit theorems for random variables with network dependence, without requiring that individuals in the network to be located in a Euclidean or metric space. This distinguishes our approach from most existing limit theorems in network econometrics, which are based on weak dependence concepts such as strong mixing, near-epoch dependence, and $\psi$-dependence. By relaxing the assumption of an underlying metric space, our theorems can be applied to a broader range of network data, including financial and social networks. To derive the limit theorems, we generalize the concept of functional dependence (also known as physical dependence) from time series to random variables with network dependence. Using this framework, we establish several inequalities, a law of large numbers, and central limit theorems. Furthermore, we verify the conditions for these limit theorems based on primitive assumptions for spatial autoregressive models, which are widely used in network data analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.17928v1</guid>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wen Jiang, Yachen Wang, Zeqi Wu, Xingbai Xu</dc:creator>
    </item>
    <item>
      <title>Robust Inference Methods for Latent Group Panel Models under Possible Group Non-Separation</title>
      <link>https://arxiv.org/abs/2511.18550</link>
      <description>arXiv:2511.18550v1 Announce Type: new 
Abstract: This paper presents robust inference methods for general linear hypotheses in linear panel data models with latent group structure in the coefficients. We employ a selective conditional inference approach, deriving the conditional distribution of coefficient estimates given the group structure estimated from the data. Our procedure provides valid inference under possible violations of group separation, where distributional properties of group-specific coefficients remain unestablished. Furthermore, even when group separation does hold, our method demonstrates superior finite-sample properties compared to traditional asymptotic approaches. This improvement stems from our procedure's ability to account for statistical uncertainty in the estimation of group structure. We demonstrate the effectiveness of our approach through Monte Carlo simulations and apply the methods to two datasets on: (i) the relationship between income and democracy, and (ii) the cyclicality of firm-level R&amp;D investment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.18550v1</guid>
      <category>econ.EM</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Oguzhan Akgun, Ryo Okui</dc:creator>
    </item>
    <item>
      <title>ReLU-Based and DNN-Based Generalized Maximum Score Estimators</title>
      <link>https://arxiv.org/abs/2511.19121</link>
      <description>arXiv:2511.19121v1 Announce Type: new 
Abstract: We propose a new formulation of the maximum score estimator that uses compositions of rectified linear unit (ReLU) functions, instead of indicator functions as in Manski (1975,1985), to encode the sign alignment restrictions. Since the ReLU function is Lipschitz, our new ReLU-based maximum score criterion function is substantially easier to optimize using standard gradient-based optimization pacakges. We also show that our ReLU-based maximum score (RMS) estimator can be generalized to an umbrella framework defined by multi-index single-crossing (MISC) conditions, while the original maximum score estimator cannot be applied. We establish the $n^{-s/(2s+1)}$ convergence rate and asymptotic normality for the RMS estimator under order-$s$ Holder smoothness. In addition, we propose an alternative estimator using a further reformulation of RMS as a special layer in a deep neural network (DNN) architecture, which allows the estimation procedure to be implemented via state-of-the-art software and hardware for DNN.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.19121v1</guid>
      <category>econ.EM</category>
      <category>stat.ML</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaohong Chen, Wayne Yuan Gao, Likang Wen</dc:creator>
    </item>
    <item>
      <title>Identification, estimation and inference in Panel Vector Autoregressions using external instruments</title>
      <link>https://arxiv.org/abs/2511.19372</link>
      <description>arXiv:2511.19372v1 Announce Type: new 
Abstract: This paper proposes an identification inspired from the SVAR-IV literature that uses external instruments to identify PVARs, and discusses associated issues of identification, estimation, and inference.
  I introduce a form of local average treatment effect - the $\mu$-LATE - which arises when a continuous instrument targets a binary treatment. Under standard assumptions of independence, exclusion, and monotonicity, I show that externally instrumented PVARs estimate the $\mu$-LATE. Monte Carlo simulations illustrate that confidence sets based on the Anderson-Rubin statistics deliver reliable convergence for impulse responses.
  As an application, I instrument state-level military spending with the state's share of national spending to estimate the dynamic fiscal multiplier. I find multipliers above unity, with effects concentrated in the contemporaneous year and persisting into the following year.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.19372v1</guid>
      <category>econ.EM</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Raimondo Pala</dc:creator>
    </item>
    <item>
      <title>Estimation of High-dimensional Nonlinear Vector Autoregressive Models</title>
      <link>https://arxiv.org/abs/2511.18641</link>
      <description>arXiv:2511.18641v1 Announce Type: cross 
Abstract: High-dimensional vector autoregressive (VAR) models have numerous applications in fields such as econometrics, biology, climatology, among others. While prior research has mainly focused on linear VAR models, these approaches can be restrictive in practice. To address this, we introduce a high-dimensional non-parametric sparse additive model, providing a more flexible framework. Our method employs basis expansions to construct high-dimensional nonlinear VAR models. We derive convergence rates and model selection consistency for least squared estimators, considering dependence measures of the processes, error moment conditions, sparsity, and basis expansions. Our theory significantly extends prior linear VAR models by incorporating both non-Gaussianity and non-linearity. As a key contribution, we derive sharp Bernstein-type inequalities for tail probabilities in both non-sub-Gaussian linear and nonlinear VAR processes, which match the classical Bernstein inequality for independent random variables. Additionally, we present numerical experiments that support our theoretical findings and demonstrate the advantages of the nonlinear VAR model for a gene expression time series dataset.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.18641v1</guid>
      <category>math.ST</category>
      <category>econ.EM</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yuefeng Han, Likai Chen, Wei Biao Wu</dc:creator>
    </item>
    <item>
      <title>Prior-Free Information Design</title>
      <link>https://arxiv.org/abs/2511.18647</link>
      <description>arXiv:2511.18647v1 Announce Type: cross 
Abstract: This paper introduces a prior-free framework for information design based on partial identification and applies it to robust causal inference. The decision maker observes the distribution of signals generated by an information structure and ranks alternatives by their worst-case payoff over the state distributions consistent with those signals. We characterize the set of robustly implementable actions and show that each can be implemented by an information structure that withholds at most one dimension of information from the decision maker. In the potential outcomes model, every treatment is implementable via an experiment that is almost fully informative.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.18647v1</guid>
      <category>econ.TH</category>
      <category>econ.EM</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maxwell Rosenthal</dc:creator>
    </item>
    <item>
      <title>Experimental Design under Network Interference</title>
      <link>https://arxiv.org/abs/2003.08421</link>
      <description>arXiv:2003.08421v5 Announce Type: replace 
Abstract: This paper studies how to design two-wave experiments in the presence of spillovers for precise inference on treatment effects. We consider units connected through a single network, local dependence among individuals, and a general class of estimands encompassing average treatment and average spillover effects. We introduce a statistical framework for designing two-wave experiments with networks, where the researcher optimizes over participants and treatment assignments to minimize the variance of the estimators of interest, using a first-wave (pilot) experiment to estimate the variance. We derive guarantees for inference on treatment effects and regret guarantees on the variance obtained from the proposed design mechanism. Our results illustrate the existence of a trade-off in the choice of the pilot study and formally characterize the pilot's size relative to the main experiment.
  Simulations using simulated and real-world networks illustrate the advantages of the method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2003.08421v5</guid>
      <category>econ.EM</category>
      <category>stat.ME</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Davide Viviano</dc:creator>
    </item>
    <item>
      <title>Evaluating the Impact of Regulatory Policies on Social Welfare in Difference-in-Difference Settings</title>
      <link>https://arxiv.org/abs/2306.04494</link>
      <description>arXiv:2306.04494v3 Announce Type: replace 
Abstract: Quantifying the impact of regulatory policies on social welfare generally requires the identification of counterfactual distributions. Many of these policies (e.g. minimum wages or minimum working time) generate mass points and/or discontinuities in the outcome distribution. Existing approaches in the difference-in-difference literature cannot accommodate these discontinuities while accounting for selection on unobservables and non-stationary outcome distributions. We provide a unifying partial identification result that can account for these features. Our main identifying assumption is the stability of the dependence (copula) between the distribution of the untreated potential outcome and group membership (treatment assignment) across time. Exploiting this copula stability assumption allows us to provide an identification result that is invariant to monotonic transformations. We provide sharp bounds on the counterfactual distribution of the treatment group suitable for any outcome, whether discrete, continuous, or mixed. Our bounds collapse to the point-identification result in Athey and Imbens (2006) for continuous outcomes with strictly increasing distribution functions. We illustrate our approach and the informativeness of our bounds by analyzing the impact of an increase in the legal minimum wage using data from a recent minimum wage study (Cengiz et al 2019).</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.04494v3</guid>
      <category>econ.EM</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dalia Ghanem, D\'esir\'e K\'edagni, Ismael Mourifi\'e</dc:creator>
    </item>
    <item>
      <title>Heterogeneous Treatment Effects and Causal Mechanisms</title>
      <link>https://arxiv.org/abs/2404.01566</link>
      <description>arXiv:2404.01566v4 Announce Type: replace 
Abstract: The credibility revolution advances the use of research designs that permit identification and estimation of causal effects. However, understanding which mechanisms produce measured causal effects remains a challenge. The dominant current approach to the quantitative evaluation of mechanisms relies on the detection of heterogeneous treatment effects (HTEs) with respect to pre-treatment covariates. This paper develops a framework to understand when the existence of such heterogeneous treatment effects can support inferences about the activation of a mechanism. We show first that this design cannot provide evidence of mechanism activation without additional, generally implicit, exclusion assumptions. Further, even when these assumptions are satisfied, the presence of HTEs supports the inference that mechanism is active but the absence of HTEs is generally uninformative about mechanism activation. We provide novel guidance for interpretation and research design in light of these findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.01566v4</guid>
      <category>econ.EM</category>
      <category>stat.ME</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiawei Fu, Tara Slough</dc:creator>
    </item>
    <item>
      <title>A Sharp Test for the Judge Leniency Design</title>
      <link>https://arxiv.org/abs/2405.06156</link>
      <description>arXiv:2405.06156v2 Announce Type: replace 
Abstract: We propose sharp testable implications and tests to jointly assess the random assignment, exclusion, and monotonicity assumptions in judge leniency designs. Our procedures accommodate various data scenarios in which the number of defendants handled by a judge may be either small or large, and allow for discrete or continuous instrumental variables. When the validity of the design is rejected, a variant of the marginal treatment effect can be identified under weaker assumptions. We apply our test to the Philadelphia court data studied by Stevenson (2018) and demonstrate that it outperforms non-sharp joint tests by significant margins in simulation studies</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.06156v2</guid>
      <category>econ.EM</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohamed Coulibaly, Yu-Chin Hsu, Ismael Mourifi\'e, Yuanyuan Wan</dc:creator>
    </item>
    <item>
      <title>Count Data Models with Heterogeneous Peer Effects under Rational Expectations</title>
      <link>https://arxiv.org/abs/2405.17290</link>
      <description>arXiv:2405.17290v3 Announce Type: replace 
Abstract: This paper develops a peer effect model for count responses under rational expectations. The model accounts for heterogeneity in peer effects through groups based on observed characteristics. Identification is based on the linear model condition requiring friends' friends who are not direct friends, which I show extends to a broad class of nonlinear models. Parameters are estimated using a nested pseudo-likelihood approach. An empirical application on students' extracurricular participation reveals that females are more responsive to peers than males. An easy-to-use R package, CDatanet, is available for implementing the model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.17290v3</guid>
      <category>econ.EM</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aristide Houndetoungan</dc:creator>
    </item>
    <item>
      <title>Estimating Variances for Causal Panel Data Estimators</title>
      <link>https://arxiv.org/abs/2510.11841</link>
      <description>arXiv:2510.11841v2 Announce Type: replace 
Abstract: There has been a recent surge in research on causal panel data models, leading to many new estimators for average causal effects. However, researchers have paid less attention to quantifying the precision of these estimators. This paper addresses that gap by studying the problem of variance estimation in causal panel settings. We develop a unified framework for comparing the three main variance estimators used in these settings: regression-based, Unit-Placebo, and Time-Placebo estimators. We show that each relies on a distinct exchangeability assumption and, correspondingly, each targets a different conditional variance. We find that, under some assumptions, all three estimators are all valid, but that their statistical power differs substantially depending on the heteroskedasticity present in the data. Building on these insights, we propose a new variance estimator that flexibly accounts for heteroskedasticity across the unit and time dimensions, and delivers superior statistical power in realistic panel data settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.11841v2</guid>
      <category>econ.EM</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Almeida, Susan Athey, Guido Imbens, Eva Lestant, Alexia Olaizola</dc:creator>
    </item>
    <item>
      <title>Heterogeneity in peer effects for binary outcomes</title>
      <link>https://arxiv.org/abs/2511.15891</link>
      <description>arXiv:2511.15891v2 Announce Type: replace 
Abstract: I introduce heterogeneity into the analysis of peer effects that arise from conformity, allowing the strength of the taste for conformity to vary across agents' actions. Using a structural model based on a simultaneous network game with incomplete information, I derive conditions for equilibrium uniqueness and for the identification of heterogeneous peer-effect parameters. I also propose specification tests to determine whether the conformity model or the spillover model is consistent with the observed data in the presence of heterogeneous peer effects. Applying the model to data on smoking and alcohol consumption among secondary school students, I show that assuming a homogeneous preference for conformity leads to biased estimates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15891v2</guid>
      <category>econ.EM</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mathieu Lambotte</dc:creator>
    </item>
    <item>
      <title>The Challenge of Using LLMs to Simulate Human Behavior: A Causal Inference Perspective</title>
      <link>https://arxiv.org/abs/2312.15524</link>
      <description>arXiv:2312.15524v3 Announce Type: replace-cross 
Abstract: Large Language Models (LLMs) have shown impressive potential to simulate human behavior. We identify a fundamental challenge in using them to simulate experiments: when LLM-simulated subjects are blind to the experimental design (as is standard practice with human subjects), variations in treatment systematically affect unspecified variables that should remain constant, violating the unconfoundedness assumption. Using demand estimation as a context and an actual experiment with 40 different products as a benchmark, we show this can lead to implausible results. While confounding may in principle be addressed by controlling for covariates, this can compromise ecological validity in the context of LLM simulations: controlled covariates become artificially salient in the simulated decision process. We show formally that confoundness stems from ambiguous prompting strategies. Therefore, it can be addressed by developing unambiguous prompting strategies through unblinding, i.e., revealing the experiment design in LLM simulations. Our empirical results show that this strategy consistently enhances model performance across all tested models, including both out-of-box reasoning and non-reasoning models. We also show that it is a technique that complements fine-tuning: while fine-tuning can improve simulation performance, an unambiguous prompting strategy makes the predictions robust to the inclusion of irrelevant data in the fine-tuning process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.15524v3</guid>
      <category>cs.AI</category>
      <category>cs.IR</category>
      <category>econ.EM</category>
      <category>stat.AP</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.2139/ssrn.4650172</arxiv:DOI>
      <dc:creator>George Gui, Olivier Toubia</dc:creator>
    </item>
  </channel>
</rss>
