<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.data-an updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.data-an</link>
    <description>physics.data-an updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.data-an" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 09 Apr 2025 01:52:34 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Dimensionless learning based on information</title>
      <link>https://arxiv.org/abs/2504.03927</link>
      <description>arXiv:2504.03927v1 Announce Type: cross 
Abstract: Dimensional analysis is one of the most fundamental tools for understanding physical systems. However, the construction of dimensionless variables, as guided by the Buckingham-$\pi$ theorem, is not uniquely determined. Here, we introduce IT-$\pi$, a model-free method that combines dimensionless learning with the principles of information theory. Grounded in the irreducible error theorem, IT-$\pi$ identifies dimensionless variables with the highest predictive power by measuring their shared information content. The approach is able to rank variables by predictability, identify distinct physical regimes, uncover self-similar variables, determine the characteristic scales of the problem, and extract its dimensionless parameters. IT-$\pi$ also provides a bound of the minimum predictive error achievable across all possible models, from simple linear regression to advanced deep learning techniques, naturally enabling a definition of model efficiency. We benchmark IT-$\pi$ across different cases and demonstrate that it offers superior performance and capabilities compared to existing tools. The method is also applied to conduct dimensionless learning for supersonic turbulence, aerodynamic drag on both smooth and irregular surfaces, magnetohydrodynamic power generation, and laser-metal interaction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03927v1</guid>
      <category>physics.flu-dyn</category>
      <category>physics.comp-ph</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuan Yuan, Adri\'an Lozano-Dur\'an</dc:creator>
    </item>
    <item>
      <title>DeepOHeat-v1: Efficient Operator Learning for Fast and Trustworthy Thermal Simulation and Optimization in 3D-IC Design</title>
      <link>https://arxiv.org/abs/2504.03955</link>
      <description>arXiv:2504.03955v1 Announce Type: cross 
Abstract: Thermal analysis is crucial in three-dimensional integrated circuit (3D-IC) design due to increased power density and complex heat dissipation paths. Although operator learning frameworks such as DeepOHeat have demonstrated promising preliminary results in accelerating thermal simulation, they face critical limitations in prediction capability for multi-scale thermal patterns, training efficiency, and trustworthiness of results during design optimization. This paper presents DeepOHeat-v1, an enhanced physics-informed operator learning framework that addresses these challenges through three key innovations. First, we integrate Kolmogorov-Arnold Networks with learnable activation functions as trunk networks, enabling an adaptive representation of multi-scale thermal patterns. This approach achieves a $1.25\times$ and $6.29\times$ reduction in error in two representative test cases. Second, we introduce a separable training method that decomposes the basis function along the coordinate axes, achieving $62\times$ training speedup and $31\times$ GPU memory reduction in our baseline case, and enabling thermal analysis at resolutions previously infeasible due to GPU memory constraints. Third, we propose a confidence score to evaluate the trustworthiness of the predicted results, and further develop a hybrid optimization workflow that combines operator learning with finite difference (FD) using Generalized Minimal Residual (GMRES) method for incremental solution refinement, enabling efficient and trustworthy thermal optimization. Experimental results demonstrate that DeepOHeat-v1 achieves accuracy comparable to optimization using high-fidelity finite difference solvers, while speeding up the entire optimization process by $70.6\times$ in our test cases, effectively minimizing the peak temperature through optimal placement of heat-generating components.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03955v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Xinling Yu, Ziyue Liu, Hai Li, Yixing Li, Xin Ai, Zhiyu Zeng, Ian Young, Zheng Zhang</dc:creator>
    </item>
    <item>
      <title>Maximum entropy for dynamic processes on networks</title>
      <link>https://arxiv.org/abs/2504.04240</link>
      <description>arXiv:2504.04240v1 Announce Type: cross 
Abstract: Dynamic processes on networks are fundamental to understand modern day phenomena such as information diffusion and opinion polarization on the internet or epidemic spreading. However, they are notoriously difficult to study broadly as small changes in initial conditions, the process or the network can lead to very different evolution trajectories. Here we apply the information-theoretic framework of maximum caliber to study the statistics of such systems analytically in a general way. We verify the dynamics deduced from maximum caliber by using simulations of different processes on different networks, introduce an approximation of the dynamics which significantly simplifies the problem and show that the approximation can be used to recover well-established models of population dynamics that are typically not thought of as taking place on a network. This provides a theoretical tool that allows to study dynamic processes on networks broadly without loosing sight of known results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.04240v1</guid>
      <category>physics.soc-ph</category>
      <category>cond-mat.stat-mech</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Noam Abadi, Franco Ruzzenenti</dc:creator>
    </item>
    <item>
      <title>Improve the estimate of the b-value in regional catalogs by means of the the b-more positive method</title>
      <link>https://arxiv.org/abs/2504.04663</link>
      <description>arXiv:2504.04663v1 Announce Type: cross 
Abstract: The b-value, which controls the slope of the frequency-magnitude distribution of earthquakes, is a critical parameter in seismic forecasting. However, accurately measuring the true b-value is challenging due to the temporal and spatial variations in the completeness of instrumental seismic catalogs. In this study, we systematically compare traditional methods for estimating the b-value with newer approaches, specifically focusing on the b-more-positive estimator based on positive magnitude difference statistics. We conduct this comparison using both synthetic ETAS catalogs, with artificially introduced incompleteness, and instrumental catalogs from five regions: Japan, Italy, Southern California, Northern California, and New Zealand. Our results from synthetic ETAS catalogs reveal that traditional estimators tend to underestimate the b-value, while the b-more-positive estimator provides a more accurate measurement. Similar patterns are observed in instrumental catalogs, suggesting that traditional methods may also underestimate the true b-value in real datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.04663v1</guid>
      <category>physics.geo-ph</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eugenio Lippiello, Cataldo Godano, Giuseppe Petrillo</dc:creator>
    </item>
    <item>
      <title>Dynamic hysteresis model of grain-oriented ferromagnetic material using neural operators</title>
      <link>https://arxiv.org/abs/2504.04863</link>
      <description>arXiv:2504.04863v1 Announce Type: cross 
Abstract: Accurately capturing the behavior of grain-oriented (GO) ferromagnetic materials is crucial for modeling the electromagnetic devices. In this paper, neural operator models, including Fourier neural operator (FNO), U-net combined FNO (U-FNO) and Deep operator network (DeepONet) are used to approximate the dynamic hysteresis models of GO steel. Furthermore, two types of data augmentation strategies including cyclic rolling augmentation and Gaussian data augmentation (GDA) are implemented to enhance the learning ability of models. With the inclusion of these augmentation techniques, the optimized models account for not only the peak values of the magnetic flux density but also the effects of different frequencies and phase shifts. The accuracy of all models is assessed using the L2-norm of the test data and the mean relative error (MRE) of calculated core losses. Each model performs well in different scenarios, but FNO consistently achieves the best performance across all cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.04863v1</guid>
      <category>eess.SY</category>
      <category>cond-mat.mtrl-sci</category>
      <category>cs.SY</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ziqing Guo, Binh H. Nguyen, Hamed Hamzehbahmani, Ruth V. Sabariego</dc:creator>
    </item>
    <item>
      <title>Phase transitions in swarm optimization algorithms</title>
      <link>https://arxiv.org/abs/2504.04947</link>
      <description>arXiv:2504.04947v1 Announce Type: cross 
Abstract: Natural systems often exhibit chaotic behavior in their space-time evolution. Systems transiting between chaos and order manifest a potential to compute, as shown with cellular automata and artificial neural networks. We demonstrate that swarms optimisation algorithms also exhibit transitions from chaos, analogous to motion of gas molecules, when particles explore solution space disorderly, to order, when particles follow a leader, similar to molecules propagating along diffusion gradients in liquid solutions of reagents. We analyse these `phase-like' transitions in swarm optimization algorithms using recurrence quantification analysis and Lempel-Ziv complexity estimation. We demonstrate that converging and non-converging iterations of the optimization algorithms are statistically different in a view of applied chaos, complexity and predictability estimating indicators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.04947v1</guid>
      <category>physics.comp-ph</category>
      <category>nlin.CD</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1007/978-3-319-92435-9_15</arxiv:DOI>
      <arxiv:journal_reference>Lecture Notes in Computer Science, 10867, 204-216 (2018)</arxiv:journal_reference>
      <dc:creator>Tom\'a\v{s} Vantuch, Ivan Zelinka, Andrew Adamatzky, Norbert Marwan</dc:creator>
    </item>
    <item>
      <title>Parameter estimation of structural dynamics with neural operators enabled surrogate modeling</title>
      <link>https://arxiv.org/abs/2410.11712</link>
      <description>arXiv:2410.11712v2 Announce Type: replace-cross 
Abstract: Parameter estimation in structural dynamics generally involves inferring the values of physical, geometric, or even customized parameters based on first principles or expert knowledge, which is challenging for complex structural systems. In this work, we present a unified deep learning-based framework for parameterization, forward modeling, and inverse modeling of structural dynamics. The parameterization is flexible and can be user-defined, including physical and/or non-physical (customized) parameters. In the forward modeling, we train a neural operator for response prediction -- forming a surrogate model, which leverages the defined system parameters and excitation forces as inputs to the model. The inverse modeling focuses on estimating system parameters. In particular, the learned forward surrogate model (which is differentiable) is utilized for preliminary parameter estimation via gradient-based optimization; to further boost the parameter estimation, we introduce a neural refinement method to mitigate ill-posed problems, which often occur in the former. The framework's effectiveness is verified numerically and experimentally, in both interpolation and extrapolation cases, indicating its capability to capture intrinsic dynamics of structural systems from both forward and inverse perspectives. Moreover, the framework's flexibility is expected to support a wide range of applications, including surrogate modeling, structural identification, damage detection, and inverse design of structural systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11712v2</guid>
      <category>cs.CE</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mingyuan Zhou, Haoze Song, Wenjing Ye, Wei Wang, Zhilu Lai</dc:creator>
    </item>
    <item>
      <title>SIGMA: Single Interpolated Generative Model for Anomalies</title>
      <link>https://arxiv.org/abs/2410.20537</link>
      <description>arXiv:2410.20537v2 Announce Type: replace-cross 
Abstract: A key step in any resonant anomaly detection search is accurate modeling of the background distribution in each signal region. Data-driven methods like CATHODE accomplish this by training separate generative models on the complement of each signal region, and interpolating them into their corresponding signal regions. Having to re-train the generative model on essentially the entire dataset for each signal region is a major computational cost in a typical sliding window search with many signal regions. Here, we present SIGMA, a new, fully data-driven, computationally-efficient method for estimating background distributions. The idea is to train a single generative model on all of the data and interpolate its parameters in sideband regions in order to obtain a model for the background in the signal region. The SIGMA method significantly reduces the computational cost compared to previous approaches, while retaining a similar high quality of background modeling and sensitivity to anomalous signals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.20537v2</guid>
      <category>hep-ph</category>
      <category>cs.LG</category>
      <category>hep-ex</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ranit Das, David Shih</dc:creator>
    </item>
    <item>
      <title>Physical meaning of principal component analysis for classical lattice systems with translational invariance</title>
      <link>https://arxiv.org/abs/2410.22682</link>
      <description>arXiv:2410.22682v4 Announce Type: replace-cross 
Abstract: We explore the physical implications of applying principal component analysis (PCA) to translationally invariant classical systems defined on a $d$-dimensional hypercubic lattice. Using Rayleigh-Schr\"odinger perturbation theory, we demonstrate that the principal components are related to the reciprocal lattice vectors of the hypercubic lattice, and the corresponding eigenvalues are connected to the discrete Fourier transform of the sampled configurations. From a different perspective, we show that the PCA in question can be viewed as a numerical method for computing the ensemble average of the squared moduli of the Fourier transform of physical quantities. Our results also provide a way to determine approximately the principal components of a classical system with translational invariance without the need for matrix diagonalization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.22682v4</guid>
      <category>cond-mat.stat-mech</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1103/PhysRevE.111.045301</arxiv:DOI>
      <arxiv:journal_reference>Phys. Rev. E 111, 045301 (2025)</arxiv:journal_reference>
      <dc:creator>Su-Chan Park</dc:creator>
    </item>
  </channel>
</rss>
