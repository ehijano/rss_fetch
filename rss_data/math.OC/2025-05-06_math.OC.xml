<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 07 May 2025 01:46:29 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Supervisory Control of a Flexible Manufacturing Unit for the Production of Two Products</title>
      <link>https://arxiv.org/abs/2505.01434</link>
      <description>arXiv:2505.01434v1 Announce Type: new 
Abstract: In this diploma thesis, the mathematical model of a multi-product manufacturing unit will be presented. The unit consists of a set of three conveyors, a robot, a lathe, a milling machine, an assembly machine, and a painting machine. Finally, the connection of the above elements is carried out via one slot buffer. The products can be divided into two distinct sets according to the route they will follow through the machines of the unit. The mathematical models of the individual subsystems of the plant using finite deterministic automata will be presented. The two different routes that the products can follow will be presented. The desired product flow will be presented in the form of desired regular languages. The properties of the desired languages with respect the overall automaton of the system will be investigated. A supervisory architecture will be designed based on the desired regular languages.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01434v1</guid>
      <category>math.OC</category>
      <category>cs.FL</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kyriakos Giagiakos</dc:creator>
    </item>
    <item>
      <title>Parametric vibrations of a damaged orthotropic geometrical shell stiffened with an inhomogeneous rod and rings on viscoelastic medium</title>
      <link>https://arxiv.org/abs/2505.01443</link>
      <description>arXiv:2505.01443v1 Announce Type: new 
Abstract: The structural element considered in the presented article consists, according to the geometric structure, of a coating and reinforcement elements, according to the mechanical characteristics of heterogeneous coatings along the length, having damage inside due to their physical structure and, finally, a system in contact with a viscoelastic medium. Taking into account one of the existing models (Winkler or Pasternak), the contact conditions between the coating and the reinforcement elements and the influence of the medium on the coating, the frequency equation of oscillation was solved, the results were analyzed. Theory of hereditary type damage under the action of external force is often used for taking into account the damages in the structure of a cylindrical shell forced to vibration. The Hamilton-Ostrogradsky variational principle is used for solving the problem. The results obtained can be used in the foundations of bridges built across mountain rivers. Such support is cost-effective. It should be noted that reinforcement and concrete mortar are also used in the internal parts of the cylindrical supports used. The article proposes to fill the inside of the cylindrical lid under study with clay.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01443v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>International Journal on Technical and Physical Problems of Engineering, Iss. 60, Vol. 16, No. 3, Sep. 2024</arxiv:journal_reference>
      <dc:creator>I. G. Aliyev, F. S. Latifov, A. M. Guliyeva</dc:creator>
    </item>
    <item>
      <title>Data Informativity under Data Perturbation</title>
      <link>https://arxiv.org/abs/2505.01641</link>
      <description>arXiv:2505.01641v1 Announce Type: new 
Abstract: Data informativity provides a theoretical foundation for determining whether collected data are sufficiently informative to achieve specific control objectives in data-driven control frameworks. In this study, we investigate the data informativity subject to noise characterized by quadratic matrix inequalities (QMIs), which describe constraints through matrix-valued quadratic functions. We introduce a generalized noise model, referred to as data perturbation, under which we derive necessary and sufficient conditions formulated as tractable linear matrix inequalities for data informativity with respect to stabilization and performance guarantees via state feedback, as well as stabilization via output feedback. Our proposed framework encompasses and extends existing analyses that consider exogenous disturbances and measurement noise, while also relaxing several restrictive assumptions commonly made in prior work. A central challenge in the data perturbation setting arises from the non-convexity of the set of systems consistent with the data, which renders standard matrix S-procedure techniques inapplicable. To resolve this issue, we develop a novel matrix S-procedure that does not rely on convexity of the system set by exploiting geometric properties of QMI solution sets. Furthermore, we derive sufficient conditions for data informativity in the presence of multiple noise sources by approximating the combined noise effect through the QMI framework. The proposed results are broadly applicable to a wide class of noise models and subsume several existing methodologies as special cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01641v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Taira Kaminaga, Hampei Sasahara</dc:creator>
    </item>
    <item>
      <title>A dynamic view of the double descent</title>
      <link>https://arxiv.org/abs/2505.01751</link>
      <description>arXiv:2505.01751v1 Announce Type: new 
Abstract: It has been observed by Belkin et al.\ that overparametrized neural networks exhibit a `double descent' phenomenon. That is, as the model complexity, as reflected in the number of features, increases, the training error initially decreases, then increases, and then decreases again. A counterpart of this phenomenon in the time domain has been noted in the context of epoch-wise training, viz., that the training error decreases with time, then increases, then decreases again. This note presents a plausible explanation for this phenomenon by using the theory of two time scale stochastic approximation and singularly perturbed differential equations, applied to the continuous time limit of the gradient dynamics. This adds a `dynamic' angle to an already well studied theme.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01751v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vivek Shripad Borkar</dc:creator>
    </item>
    <item>
      <title>On a robust approach to "split" feasibility problems: solvability and global error bound conditions</title>
      <link>https://arxiv.org/abs/2505.01787</link>
      <description>arXiv:2505.01787v1 Announce Type: new 
Abstract: In the present paper, a robust approach to a special class of convex feasibility problems is considered. By techniques of convex and variational analysis, conditions for the existence of robust feasible solutions and related error bounds are investigated. This is done by reformulating the robust counterpart of a split feasibility problem as a set-valued inclusion, a problem for which one can take profit from the solvability and stability theory that has been recently developed. As a result, a sufficient condition for solution existence and error bounds is established in terms of problem data and discussed through several examples. A specific focus is devoted to error bound conditions in the case of the robust counterpart of polyhedral split feasibility problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01787v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amos Uderzo</dc:creator>
    </item>
    <item>
      <title>Switched Systems Control via Discreteness-Promoting Regularization</title>
      <link>https://arxiv.org/abs/2505.01803</link>
      <description>arXiv:2505.01803v1 Announce Type: new 
Abstract: This paper proposes a novel method for designing finite-horizon discrete-valued switching signals in linear switched systems based on discreteness-promoting regularization. The inherent combinatorial optimization problem is reformulated as a continuous optimization problem with a non-convex regularization term that promotes discreteness of the control. We prove that any solution obtained from the relaxed problem is also a solution to the original problem. The resulting non-convex optimization problem is efficiently solved through time discretization. Numerical examples demonstrate the effectiveness of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01803v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Masaaki Nagahara, Takuya Ikeda, Ritsuki Hoshimoto</dc:creator>
    </item>
    <item>
      <title>Integrated optimization of operations and capacity planning under uncertainty for drayage procurement in container logistics</title>
      <link>https://arxiv.org/abs/2505.01808</link>
      <description>arXiv:2505.01808v1 Announce Type: new 
Abstract: We present an integrated framework for truckload procurement in container logistics, bridging strategic and operational aspects that are often treated independently in existing research. Drayage, the short-haul trucking of containers, plays a critical role in intermodal container logistics. Using dynamic programming, we identify optimal operational policies for allocating drayage volumes among capacitated carriers under uncertain container flows and spot rates. The computational complexity of optimization under uncertainty is mitigated through sample average approximation. These optimal policies serve as the basis for evaluating specific capacity arrangements. To optimize capacity reservations with strategic and spot carriers, we employ an efficient quasi-Newton method. Numerical experiments demonstrate significant cost-efficiency improvements, including a 21.2% cost reduction in a four-period scenario. Monte Carlo simulations further highlight the strong generalization capabilities of the proposed joint optimization method across out-of-sample scenarios. These findings underscore the importance of integrating strategic and operational decisions to enhance cost efficiency in truckload procurement under uncertainty.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01808v1</guid>
      <category>math.OC</category>
      <category>stat.AP</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Georgios Vassos, Richard Lusby, Pierre Pinson</dc:creator>
    </item>
    <item>
      <title>Multistage stochastic optimization for drayage procurement in container logistics using stochastic dual dynamic programming</title>
      <link>https://arxiv.org/abs/2505.01813</link>
      <description>arXiv:2505.01813v1 Announce Type: new 
Abstract: Truckload procurement plays a vital role in integrated container logistics, particularly under the uncertainties of container flow and market conditions. We formulate the operational volume allocation problem in drayage procurement as a multistage stochastic transportation problem and solve it using stochastic dual dynamic programming (SDDP). We employ a multivariate count time series approach from the literature to model cargo flow dynamics, relaxing independence assumptions and capturing complex correlations. Our numerical experiments demonstrate the scalability of SDDP and its effectiveness in approximating high-quality policies across realistic problem instances. Sensitivity analyses highlight the significant impact of inflow uncertainties on costs, while spot market variability has a comparatively minor effect. Additionally, we propose an alternative stopping rule for SDDP iterations, balancing computational efficiency and solution fidelity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01813v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Georgios Vassos, Richard Lusby, Pierre Pinson</dc:creator>
    </item>
    <item>
      <title>Robust Frequency Domain Full-Waveform Inversion via HV-Geometry</title>
      <link>https://arxiv.org/abs/2505.01817</link>
      <description>arXiv:2505.01817v1 Announce Type: new 
Abstract: Conventional frequency-domain full-waveform inversion (FWI) is typically implemented with an $L^2$ misfit function, which suffers from challenges such as cycle skipping and sensitivity to noise. While the Wasserstein metric has proven effective in addressing these issues in time-domain FWI, its applicability in frequency-domain FWI is limited due to the complex-valued nature of the data and reduced transport-like dependency on wave speed. To mitigate these challenges, we introduce the HV metric ($d_{\text{HV}}$), inspired by optimal transport theory, which compares signals based on horizontal and vertical changes without requiring the normalization of data. We implement $d_{\text{HV}}$ as the misfit function in frequency-domain FWI and evaluate its performance on synthetic and real-world datasets from seismic imaging and ultrasound computed tomography (USCT). Numerical experiments demonstrate that $d_{\text{HV}}$ outperforms the $L^2$ and Wasserstein metrics in scenarios with limited prior model information and high noise while robustly improving inversion results on clinical USCT data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01817v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhijun Zeng, Matej Neumann, Yunan Yang</dc:creator>
    </item>
    <item>
      <title>Smoothness of the Augmented Lagrangian Dual in Convex Optimization</title>
      <link>https://arxiv.org/abs/2505.01824</link>
      <description>arXiv:2505.01824v1 Announce Type: new 
Abstract: This paper investigates the general linearly constrained optimization problem: $\min_{x \in \R^d} f(x) \ \st \ A x = b$, where $f: \R^n \rightarrow \exs$ is a closed proper convex function, $A \in \R^{p \times d}$, and $b \in \R^p$. We establish the following results without requiring additional regularity conditions: (1) the augmented Lagrangian dual function $\phi_{\rho}(\lambda) = \inf_x \cL_{\rho}(x, \lambda)$ is $\frac{1}{\rho}$-smooth everywhere; and (2) the solution to $\min_{x \in \R^d} \cL_{\rho}(x, \lambda)$ exists for any dual variable $\lambda \in \R^p$, where $\rho &gt; 0$ is the augmented parameter and $\cL_{\rho}(x, \lambda) = f(x) + \dotprod{\lambda, A x - b} + \frac{\rho}{2}\norm{A x - b}^2$ is the augmented Lagrangian. These findings significantly relax the strong assumptions commonly imposed in existing literature to guarantee similar properties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01824v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jingwang Li, Vincent Lau</dc:creator>
    </item>
    <item>
      <title>Rank-One Modified Value Iteration</title>
      <link>https://arxiv.org/abs/2505.01828</link>
      <description>arXiv:2505.01828v1 Announce Type: new 
Abstract: In this paper, we provide a novel algorithm for solving planning and learning problems of Markov decision processes. The proposed algorithm follows a policy iteration-type update by using a rank-one approximation of the transition probability matrix in the policy evaluation step. This rank-one approximation is closely related to the stationary distribution of the corresponding transition probability matrix, which is approximated using the power method. We provide theoretical guarantees for the convergence of the proposed algorithm to optimal (action-)value function with the same rate and computational complexity as the value iteration algorithm in the planning problem and as the Q-learning algorithm in the learning problem. Through our extensive numerical simulations, however, we show that the proposed algorithm consistently outperforms first-order algorithms and their accelerated versions for both planning and learning problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01828v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Arman Sharifi Kolarijani, Tolga Ok, Peyman Mohajerin Esfahani, Mohamad Amin Sharif Kolarijani</dc:creator>
    </item>
    <item>
      <title>Mean Field Game of Optimal Tracking Portfolio</title>
      <link>https://arxiv.org/abs/2505.01858</link>
      <description>arXiv:2505.01858v1 Announce Type: new 
Abstract: This paper studies the mean field game (MFG) problem arising from a large population competition in fund management, featuring a new type of relative performance via the benchmark tracking constraint. In the n-agent model, each agent can strategically inject capital to ensure that the total wealth outperforms the benchmark process, which is modeled as a linear combination of the population's average wealth process and an exogenous market index process. That is, each agent is concerned about the performance of her competitors captured by the floor constraint. With a continuum of agents, we formulate the constrained MFG problem and transform it into an equivalent unconstrained MFG problem with a reflected state process. We establish the existence of the mean field equilibrium (MFE) using the PDE approach. Firstly, by applying the dual transform, the best response control of the representative agent can be characterized in analytical form in terms of a dual reflected diffusion process. As a novel contribution, we verify the consistency condition of the MFE in separated domains with the help of the duality relationship and properties of the dual process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01858v1</guid>
      <category>math.OC</category>
      <category>q-fin.PM</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lijun Bo, Yijie Huang, Xiang Yu</dc:creator>
    </item>
    <item>
      <title>Ergodic Non-zero Sum Differential Game with McKean-Vlasov Dynamics</title>
      <link>https://arxiv.org/abs/2505.01972</link>
      <description>arXiv:2505.01972v1 Announce Type: new 
Abstract: We investigate a two-player ergodic game problem under McKean-Vlasov dynamics. Due to the ergodicity of the controlled process, the associated system of Hamiltonian-Jacobi-Bellman (HJB) equations exhibits non-uniqueness in its solutions. We establish a two-stage verification theorem that connects the differential game problem with the HJB equations. The first stage involves the characterization of the Nash equilibrium and ergodic constants. The second stage focuses on the non-unique solutions of the HJB equations, which are linked to the value function of an auxiliary control problem. At the end, we analyze the linear-quadratic-Gaussian (LQG) case, leading to an intriguing set of measure-dependent algebraic Riccati equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01972v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qingshuo Song, Gu Wang, Zuo Quan Xu, Chao Zhu</dc:creator>
    </item>
    <item>
      <title>Collective steering: Tracer-informed dynamics</title>
      <link>https://arxiv.org/abs/2505.01975</link>
      <description>arXiv:2505.01975v1 Announce Type: new 
Abstract: We consider control and inference problems where control protocols and internal dynamics are informed by two types of constraints. Our data consist of i) statistics on the ensemble and ii) trajectories or final disposition of selected tracer particles embedded in the flow. Our aim is i') to specify a control protocol to realize a flow that meets such constraints or ii') to recover the internal dynamics that are consistent with such a data set. We analyze these problems in the setting of linear flows and Gaussian distributions. The control cost is taken to be a suitable action integral constrained by either the trajectories of tracer particles or their terminal placements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01975v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Asmaa Eldesoukey, Mahmoud Abdelgalil, Tryphon T. Georgiou</dc:creator>
    </item>
    <item>
      <title>Optimization over Trained (and Sparse) Neural Networks: A Surrogate within a Surrogate</title>
      <link>https://arxiv.org/abs/2505.01985</link>
      <description>arXiv:2505.01985v1 Announce Type: new 
Abstract: We can approximate a constraint or an objective function that is uncertain or nonlinear with a neural network that we embed in the optimization model. This approach, which is known as constraint learning, faces the challenge that optimization models with neural network surrogates are harder to solve. Such difficulties have motivated studies on model reformulation, specialized optimization algorithms, and - to a lesser extent - pruning of the embedded networks. In this work, we double down on the use of surrogates by applying network pruning to produce a surrogate of the neural network itself. In the context of using a Mixed-Integer Linear Programming (MILP) solver to verify neural networks, we obtained faster adversarial perturbations for dense neural networks by using sparse surrogates, especially - and surprisingly - if not taking the time to finetune the sparse network to make up for the loss in accuracy. In other words, we show that a pruned network with bad classification performance can still be a good - and more efficient - surrogate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01985v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hung Pham, Aiden Ren, Ibrahim Tahir, Jiatai Tong, Thiago Serra</dc:creator>
    </item>
    <item>
      <title>Sharp bounds in perturbed smooth optimization</title>
      <link>https://arxiv.org/abs/2505.02002</link>
      <description>arXiv:2505.02002v1 Announce Type: new 
Abstract: This paper studies the problem of perturbed convex and smooth optimization. The main results describe how the solution and the value of the problem change if the objective function is perturbed. Examples include linear, quadratic, and smooth additive perturbations. Such problems naturally arise in statistics and machine learning, stochastic optimization, stability and robustness analysis, inverse problems, optimal control, etc. The results provide accurate expansions for the difference between the solution of the original problem and its perturbed counterpart with an explicit error term.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02002v1</guid>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vladimir Spokoiny</dc:creator>
    </item>
    <item>
      <title>Efficient Curvature-Aware Hypergradient Approximation for Bilevel Optimization</title>
      <link>https://arxiv.org/abs/2505.02101</link>
      <description>arXiv:2505.02101v1 Announce Type: new 
Abstract: Bilevel optimization is a powerful tool for many machine learning problems, such as hyperparameter optimization and meta-learning. Estimating hypergradients (also known as implicit gradients) is crucial for developing gradient-based methods for bilevel optimization. In this work, we propose a computationally efficient technique for incorporating curvature information into the approximation of hypergradients and present a novel algorithmic framework based on the resulting enhanced hypergradient computation. We provide convergence rate guarantees for the proposed framework in both deterministic and stochastic scenarios, particularly showing improved computational complexity over popular gradient-based methods in the deterministic setting. This improvement in complexity arises from a careful exploitation of the hypergradient structure and the inexact Newton method. In addition to the theoretical speedup, numerical experiments demonstrate the significant practical performance benefits of incorporating curvature information.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02101v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Youran Dong, Junfeng Yang, Wei Yao, Jin Zhang</dc:creator>
    </item>
    <item>
      <title>Dual Acceleration for Minimax Optimization: Linear Convergence Under Relaxed Assumptions</title>
      <link>https://arxiv.org/abs/2505.02115</link>
      <description>arXiv:2505.02115v1 Announce Type: new 
Abstract: This paper addresses the bilinearly coupled minimax optimization problem: $\min_{x \in \R^{d_x}}\max_{y \in \R^{d_y}} \ f_1(x) + f_2(x) + y\T Bx - g_1(y) - g_2(y)$, where $f_1$ and $g_1$ are smooth convex functions, $f_2$ and $g_2$ are potentially nonsmooth convex functions, and $B$ is a coupling matrix. Existing algorithms for solving this problem achieve linear convergence only under stronger conditions, which may not be met in many scenarios. We first introduce the Primal-Dual Proximal Gradient (PDPG) method and demonstrate that it converges linearly under an assumption where existing algorithms fail to achieve linear convergence. Building on insights gained from analyzing the convergence conditions of existing algorithms and PDPG, we further propose the inexact Dual Accelerated Proximal Gradient (iDAPG) method. This method achieves linear convergence under weaker conditions than those required by existing approaches. Moreover, even in cases where existing methods guarantee linear convergence, iDAPG can still provide superior theoretical performance in certain scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02115v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jingwang Li, Xiao Li</dc:creator>
    </item>
    <item>
      <title>Proximal Gradient Descent Ascent Methods for Nonsmooth Nonconvex-Concave Minimax Problems on Riemannian Manifolds</title>
      <link>https://arxiv.org/abs/2505.02140</link>
      <description>arXiv:2505.02140v1 Announce Type: new 
Abstract: Nonsmooth nonconvex-concave minimax problems have attracted significant attention due to their wide applications in many fields. In this paper, we consider a class of nonsmooth nonconvex-concave minimax problems on Riemannian manifolds. Owing to the nonsmoothness of the objective function, existing minimax manifold optimization methods cannot be directly applied to solve this problem. We propose a manifold proximal gradient descent ascent (MPGDA) algorithm for solving the problem. At each iteration, the proposed algorithm alternately performs one or multiple manifold proximal gradient descent steps and a proximal ascent step. We prove that the MPGDA algorithm can find an $\varepsilon$-game-stationary point and an $\varepsilon$-optimization-stationary point of the considered problem within $\mathcal{O}(\varepsilon^{-3})$ iterations. Numerical experiments on fair sparse PCA and sparse spectral clustering are conducted to demonstrate the advantages of the MPGDA algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02140v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiyuan Xie, Qia Li</dc:creator>
    </item>
    <item>
      <title>Pickup &amp; Delivery with Time Windows and Transfers: combining decomposition with metaheuristics</title>
      <link>https://arxiv.org/abs/2505.02158</link>
      <description>arXiv:2505.02158v1 Announce Type: new 
Abstract: This paper examines the generalisation of the Pickup and Delivery Problem that allows mid-route load exchanges among vehicles and obeys strict time-windows at all locations. We propose a novel Logic-Based Benders Decomposition (LBBD) that improves optimality gaps for all benchmarks in the literature and scales up to handle larger ones. To tackle even larger instances, we introduce a refined Large Neighborhood Search (LNS) algorithm that improves the adaptability of LNS beyond case-specific configurations appearing in related literature.
  To bridge the gap in benchmark availability, we develop an instance generator that allows for extensive experimentation. For moderate datasets (25 and 50 requests), we evaluate the performance of both LBBD and LNS, the former being able to close the gap and the latter capable of providing near-optimal solutions. For larger instances (75 and 100 requests), we recreate indicative state-of-the-art metaheuristics to highlight the improvements introduced by our LNS refinements, while establishing its scalability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02158v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ioannis Avgerinos, Ioannis Mourtos, Nikolaos Tsompanidis, Georgios Zois</dc:creator>
    </item>
    <item>
      <title>Smooth Integer Encoding via Integral Balance</title>
      <link>https://arxiv.org/abs/2505.02259</link>
      <description>arXiv:2505.02259v1 Announce Type: new 
Abstract: We introduce a novel method for encoding integers using smooth real-valued functions whose integral properties implicitly reflect discrete quantities. In contrast to classical representations, where the integer appears as an explicit parameter, our approach encodes the number N in the set of natural numbers through the cumulative balance of a smooth function f_N(t), constructed from localized Gaussian bumps with alternating and decaying coefficients. The total integral I(N) converges to zero as N tends to infinity, and the integer can be recovered as the minimal point of near-cancellation.
  This method enables continuous and differentiable representations of discrete states, supports recovery through spline-based or analytical inversion, and extends naturally to multidimensional tuples (N1, N2, ...). We analyze the structure and convergence of the encoding series, demonstrate numerical construction of the integral map I(N), and develop procedures for integer recovery via numerical inversion. The resulting framework opens a path toward embedding discrete logic within continuous optimization pipelines, machine learning architectures, and smooth symbolic computation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02259v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Stanislav Semenov</dc:creator>
    </item>
    <item>
      <title>Theoretical analysis of a derivative free control based continuation algorithm with path following capability for autonomous systems</title>
      <link>https://arxiv.org/abs/2505.02262</link>
      <description>arXiv:2505.02262v1 Announce Type: new 
Abstract: We present a minimal control-based continuation algorithm designed to track branches of limit cycles in autonomous systems. The controller can be viewed as three sub-controllers: (i) a derivative feedback controller that is used to stabilize the limit cycle, (ii) an integral phase controller, used to synthesize the unknown phase of the limit cycle and (iii) an integral arclength controller, used to track branches of limit cycles. The controlled system is analyzed theoretically, using the averaging method, allowing us to express tuning rules for the different parameters of the controller. Remarkably, theses tuning rules are independent of the studied system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02262v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Etienne Gourc (LMA), Romain Caron (LMA), Fabrice Silva (LMA), Christophe Vergez (LMA), Bruno Cochelin (LMA)</dc:creator>
    </item>
    <item>
      <title>Minimisation of Quasar-Convex Functions Using Random Zeroth-Order Oracles</title>
      <link>https://arxiv.org/abs/2505.02281</link>
      <description>arXiv:2505.02281v1 Announce Type: new 
Abstract: This study explores the performance of a random Gaussian smoothing zeroth-order (ZO) scheme for minimising quasar-convex (QC) and strongly quasar-convex (SQC) functions in both unconstrained and constrained settings. For the unconstrained problem, we establish the ZO algorithm's convergence to a global minimum along with its complexity when applied to both QC and SQC functions. For the constrained problem, we introduce the new notion of proximal-quasar-convexity and prove analogous results to the unconstrained case. Specifically, we show the complexity bounds and the convergence of the algorithm to a neighbourhood of a global minimum whose size can be controlled under a variance reduction scheme. Theoretical findings are illustrated through investigating the performance of the algorithm applied to a range of problems in machine learning and optimisation. Specifically, we observe scenarios where the ZO method outperforms gradient descent. We provide a possible explanation for this phenomenon.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02281v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Amir Ali Farzin, Yuen-Man Pun, Iman Shames</dc:creator>
    </item>
    <item>
      <title>Temporal Robustness in Discrete Time Linear Dynamical Systems</title>
      <link>https://arxiv.org/abs/2505.02347</link>
      <description>arXiv:2505.02347v1 Announce Type: new 
Abstract: Discrete time linear dynamical systems, including Markov chains, have found many applications. However, in some problems, there is uncertainty about the time horizon for which the system runs. This creates uncertainty about the cost (or reward) incurred based on the state distribution when the system stops. Given past data samples of how long a system ran, we propose to theoretically analyze a distributional robust cost estimation task in a Wasserstein ambiguity set, instead of learning a probability distribution from a few samples. Towards this, we show an equivalence between a discrete time Markov Chain on a probability simplex and a global asymptotic stable (GAS) discrete time linear dynamical system, allowing us to base our study on a GAS system only. Then, we provide various polynomial time algorithms and hardness results for different cases in our theoretical study, including a fundamental result about Wasserstein distance based polytope.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02347v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Nilava Metya, Arunesh Sinha</dc:creator>
    </item>
    <item>
      <title>A short introduction to the control theory in finite-dimensional spaces</title>
      <link>https://arxiv.org/abs/2505.02423</link>
      <description>arXiv:2505.02423v1 Announce Type: new 
Abstract: This is a brief introduction to control theory in finite-dimensional spaces. The material is partly based on my lectures for the Master 1 program in Math\'ematiques et applications at Sorbonne University, delivered over the past few years. The aim is to provide a concise overview of the subject, primarily focusing on the linear setting. Proofs are presented in detail and are selected to allow for extensions to the infinite-dimensional case in many situations. Topics covered include the Kalman rank condition, the Hautus test, observability, stability, detectability and dynamic observers, the Pole Shifting Theorem, the linear test for controllability, linear-quadratic optimal control over finite and infinite horizons, and stabilization via Gramians.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02423v1</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Hoai-Minh Nguyen</dc:creator>
    </item>
    <item>
      <title>Integrating Column Generation and Large Neighborhood Search for Bus Driver Scheduling with Complex Break Constraints</title>
      <link>https://arxiv.org/abs/2505.02485</link>
      <description>arXiv:2505.02485v1 Announce Type: new 
Abstract: The Bus Driver Scheduling Problem (BDSP) is a combinatorial optimization problem with the goal to design shifts to cover prearranged bus tours. The objective takes into account the operational cost as well as the satisfaction of drivers. This problem is heavily constrained due to strict legal rules and collective agreements. The objective of this article is to provide state-of-the-art exact and hybrid solution methods that can provide high-quality solutions for instances of different sizes. This work presents a comprehensive study of both an exact method, Branch and Price (B&amp;P), as well as a Large Neighborhood Search (LNS) framework which uses B&amp;P or Column Generation (CG) for the repair phase to solve the BDSP. It further proposes and evaluates a novel deeper integration of B&amp;P and LNS, storing the generated columns from the LNS subproblems and reusing them for other subproblems, or to find better global solutions. The article presents a detailed analysis of several components of the solution methods and their impact, including general improvements for the B&amp;P subproblem, which is a high-dimensional Resource Constrained Shortest Path Problem (RCSPP), and the components of the LNS. The evaluation shows that our approach provides new state-of-the-art results for instances of all sizes, including exact solutions for small instances, and low gaps to a known lower bound for mid-sized instances. Conclusions: We observe that B&amp;P provides the best results for small instances, while the tight integration of LNS and CG can provide high-quality solutions for larger instances, further improving over LNS which just uses CG as a black box. The proposed methods are general and can also be applied to other rule sets and related optimization problems</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02485v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lucas Kletzander, Tommaso Mannelli Mazzoli, Nysret Musliu, Pascal Van Hentenryck</dc:creator>
    </item>
    <item>
      <title>An Exact Penalty Approach for Equality Constrained Optimization over a Convex Set</title>
      <link>https://arxiv.org/abs/2505.02495</link>
      <description>arXiv:2505.02495v1 Announce Type: new 
Abstract: In this paper, we consider the nonlinear constrained optimization problem (NCP) with constraint set $\{x \in \mathcal{X}: c(x) = 0\}$, where $\mathcal{X}$ is a closed convex subset of $\mathbb{R}^n$. We propose an exact penalty approach, named constraint dissolving approach, that transforms (NCP) into its corresponding constraint dissolving problem (CDP). The transformed problem (CDP) admits $\mathcal{X}$ as its feasible region with a locally Lipschitz smooth objective function. We prove that (NCP) and (CDP) share the same first-order stationary points, second-order stationary points, second-order sufficient condition (SOSC) points, and strong SOSC points, in a neighborhood of the feasible region. Moreover, we prove that these equivalences extend globally under a particular error bound condition. Therefore, our proposed constraint dissolving approach enables direct implementations of optimization approaches over $\mathcal{X}$ and inherits their convergence properties to solve problems that take the form of (NCP). Preliminary numerical experiments illustrate the high efficiency of directly applying existing solvers for optimization over $\mathcal{X}$ to solve (NCP) through (CDP). These numerical results further demonstrate the practical potential of our proposed constraint dissolving approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02495v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nachuan Xiao, Tianyun Tang, Shiwei Wang, Kim-Chuan Toh</dc:creator>
    </item>
    <item>
      <title>Marginal minimization and sup-norm expansions in perturbed optimization</title>
      <link>https://arxiv.org/abs/2505.02562</link>
      <description>arXiv:2505.02562v1 Announce Type: new 
Abstract: Let the objective unction \( f \) depends on the target variable \( x \) along with a nuisance variable \( s \): \( f(v) = f(x,s) \). The goal is to identify the marginal solution \( x^{*} = \arg\min_{x} \min_{s} f(x,s) \). This paper discusses three related problems. The plugin approach widely used e.g. in inverse problems suggests to use a preliminary guess (pilot) \( \hat{s} \) and apply the solution of the partial optimization \( \hat{x} = \arg\min_{x} f(x,\hat{s}) \). The main question to address within this approach is the required quality of the pilot ensuring the prescribed accuracy of \( \hat{x} \). The popular \emph{alternating optimization} approach suggests the following procedure: given a starting guess \( x_{0} \), for \( t \geq 1 \), define \( s_{t} = \arg\min_{s} f(x_{t-1},s) \), and then \( x_{t} = \arg\min_{x} f(x,s_{t}) \). The main question here is the set of conditions ensuring a convergence of \( x_{t} \) to \( x^{*} \). Finally, the paper discusses an interesting connection between marginal optimization and sup-norm estimation. The basic idea is to consider one component of the variable \( v \) as a target and the rest as nuisance. In all cases, we provide accurate closed form results under realistic assumptions. The results are illustrated by one numerical example for the BTL model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02562v1</guid>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vladimir Spokoiny</dc:creator>
    </item>
    <item>
      <title>Lipschitz upper semicontinuity of linear inequality systems under full perturbations</title>
      <link>https://arxiv.org/abs/2505.02575</link>
      <description>arXiv:2505.02575v1 Announce Type: new 
Abstract: The present paper is focused on the computation of the Lipschitz upper semicontinuity modulus of the feasible set mapping in the context of fully perturbed linear inequality systems; i.e., where all coefficients are allowed to be perturbed. The direct antecedent comes from the framework of right-hand side (RHS, for short) perturbations. The difference between both parametric contexts, full vs RHS perturbations, is emphasized. In particular, the polyhedral structure of the graph of the feasible set mapping in the latter framework enables us to apply classical results as those of Hoffman [A. J. HOFFMAN, J. Res. Natl. Bur. Stand. 49 (1952), pp. 263--265] and Robinson [S. M. ROBINSON, Math. Progr. Study 14 (1981), pp. 206--214]. In contrast, the graph of the feasible set mapping under full perturbations is no longer polyhedral (not even convex). This fact requires ad hoc techniques to analyze the Lipschitz upper semicontinuity property and its corresponding modulus.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02575v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jes\'us Camacho, Mar\'ia Josefa C\'anovas, Helmut Gfrerer, Juan Parra</dc:creator>
    </item>
    <item>
      <title>A full splitting algorithm for structured difference-of-convex programs</title>
      <link>https://arxiv.org/abs/2505.02588</link>
      <description>arXiv:2505.02588v1 Announce Type: new 
Abstract: In this paper, we study a class of nonconvex and nonsmooth structured difference-of-convex (DC) programs, which contain in the convex part the sum of a nonsmooth linearly composed convex function and a differentiable function, and in the concave part another nonsmooth linearly composed convex function. Among the various areas in which such problems occur, we would like to mention in particular the recovery of sparse signals. We propose an adaptive double-proximal, full-splitting algorithm with a moving center approach in the final subproblem, which addresses the challenge of evaluating compositions by decoupling the linear operator from the nonsmooth component. We establish the subsequential convergence of the generated sequence of iterates to an approximate stationary point and prove its global convergence under the Kurdyka-\L ojasiewicz property. We also discuss the tightness of the convergence results and provide insights into the rationale for seeking an approximate KKT point. This is illustrated by constructing a counterexample showing that the algorithm can diverge when seeking exact solutions. Finally, we present a practical version of the algorithm that incorporates a nonmonotone line search, which significantly improves the convergence performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02588v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Radu Ioan Bot, Rossen Nenov, Min Tao</dc:creator>
    </item>
    <item>
      <title>Entropic Mirror Descent for Linear Systems: Polyak's Stepsize and Implicit Bias</title>
      <link>https://arxiv.org/abs/2505.02614</link>
      <description>arXiv:2505.02614v1 Announce Type: new 
Abstract: This paper focuses on applying entropic mirror descent to solve linear systems, where the main challenge for the convergence analysis stems from the unboundedness of the domain. To overcome this without imposing restrictive assumptions, we introduce a variant of Polyak-type stepsizes. Along the way, we strengthen the bound for $\ell_1$-norm implicit bias, obtain sublinear and linear convergence results, and generalize the convergence result to arbitrary convex $L$-smooth functions. We also propose an alternative method that avoids exponentiation, resembling the original Hadamard descent, but with provable convergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02614v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yura Malitsky, Alexander Posch</dc:creator>
    </item>
    <item>
      <title>Nonconvex landscapes in phase retrieval and semidefinite low-rank matrix sensing with overparametrization</title>
      <link>https://arxiv.org/abs/2505.02636</link>
      <description>arXiv:2505.02636v1 Announce Type: new 
Abstract: We study a nonconvex algorithmic approach to phase retrieval and the more general problem of semidefinite low-rank matrix sensing. Specifically, we analyze the nonconvex landscape of a quartic Burer-Monteiro factorized least-squares optimization problem. We develop a new analysis framework, taking advantage of the semidefinite problem structure, to understand the properties of second-order critical points -- specifically, whether they (approximately) recover the ground truth matrix. We show that it can be helpful to overparametrize the problem, that is, to optimize over matrices of higher rank than the ground truth. We then apply this framework to several example problems: in addition to recovering existing state-of-the-art phase retrieval landscape guarantees (without overparametrization), we show that overparametrizing by a factor at most logarithmic in the dimension allows recovery with optimal statistical sample complexity for the well-known problems of (1) phase retrieval with sub-Gaussian measurements and (2) more general semidefinite matrix sensing with rank-1 Gaussian measurements. More generally, our analysis (optionally) uses the popular method of convex dual certificates, suggesting that our analysis could be applied to a much wider class of problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02636v1</guid>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrew D. McRae</dc:creator>
    </item>
    <item>
      <title>Batch Sample-wise Stochastic Optimal Control via Stochastic Maximum Principle</title>
      <link>https://arxiv.org/abs/2505.02688</link>
      <description>arXiv:2505.02688v1 Announce Type: new 
Abstract: In this work, we study the stochastic optimal control problem (SOC) mainly from the probabilistic view point, i.e. via the Stochastic Maximum principle (SMP) \cite{Peng4}. We adopt the sample-wise backpropagation scheme proposed in \cite{Hui1} to solve the SOC problem under the strong convexity assumption. Importantly, in the Stochastic Gradient Descent (SGD) procedure, we use batch samples with higher order scheme in the forward SDE to improve the convergence rate in \cite{Hui1} from $\sim \mathcal{O}(\sqrt{\frac{N}{K} + \frac{1}{N}})$ to $\sim \mathcal{O}(\sqrt{\frac{1}{K} + \frac{1}{N^2}})$ and note that the main source of uncertainty originates from the scheme for the simulation of $Z$ term in the BSDE. In the meantime, we note the SGD procedure uses only the necessary condition of the SMP, while the batch simulation of the approximating solution of BSDEs allows one to obtain a more accurate estimate of the control $u$ that minimizes the Hamiltonian. We then propose a damped contraction algorithm to solve the SOC problem whose proof of convergence for a special case is attained under some appropriate assumption. We then show numerical results to check the first order convergence rate of the projection algorithm and analyze the convergence behavior of the damped contraction algorithm. Lastly, we briefly discuss how to incorporate the proposed scheme in solving practical problems especially when the Randomized Neural Networks are used. We note that in this special case, the error backward propagation can be avoided and parameter update can be achieved via purely algebraic computation (vector algebra) which will potentially improve the efficiency of the whole training procedure. Such idea will require further exploration and we will leave it as our future work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02688v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hui Sun, Feng Bao</dc:creator>
    </item>
    <item>
      <title>Computing the Congestion Phases of Dynamical Systems with Priorities and Application to Emergency Departments</title>
      <link>https://arxiv.org/abs/2505.02729</link>
      <description>arXiv:2505.02729v1 Announce Type: new 
Abstract: Medical emergency departments are complex systems in which patients must be treated according to priority rules based on the severity of their condition. We develop a model of emergency departments using Petri nets with priorities, described by nonmonotone piecewise linear dynamical systems. The collection of stationary solutions of such systems forms a "phase diagram", in which each phase corresponds to a subset of bottleneck resources (like senior doctors, interns, nurses, consultation rooms, etc.). Since the number of phases is generally exponential in the number of resources, developing automated methods is essential to tackle realistic models. We develop a general method to compute congestion diagrams. A key ingredient is a polynomial time algorithm to test whether a given "policy" (configuration of bottleneck tasks) is achievable by a choice of resources. This is done by reduction to a feasibility problem for an unusual class of lexicographic polyhedra. Furthermore, we show that each policy uniquely determines the system's throughput. We apply our approach to a case study, analyzing a simplified model of an emergency department from Assistance Publique - H\^opitaux de Paris.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02729v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xavier Allamigeon, Pascal Capetillo, St\'ephane Gaubert</dc:creator>
    </item>
    <item>
      <title>A note on the diameter of small sub-Riemannian balls</title>
      <link>https://arxiv.org/abs/2505.02790</link>
      <description>arXiv:2505.02790v1 Announce Type: new 
Abstract: We observe that the diameter of small (in a locally uniform sense) balls in $C^{1,1}$ sub-Riemannian manifolds equals twice the radius. We also prove that, when the regularity of the structure is further lowered to $C^0$, the diameter is arbitrarily close to twice the radius. Both results hold independently of the bracket-generating condition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02790v1</guid>
      <category>math.OC</category>
      <category>math.DG</category>
      <category>math.MG</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marco Di Marco, Gianluca Somma, Davide Vittone</dc:creator>
    </item>
    <item>
      <title>On inequalities between norms of partial derivatives on convex domains</title>
      <link>https://arxiv.org/abs/2505.01611</link>
      <description>arXiv:2505.01611v1 Announce Type: cross 
Abstract: We consider inequalities between $L_p$-norms of partial derivatives, $p\in [1,+\infty]$, for bivariate concave functions on a convex domain that vanish on the boundary. Can the ratio between those norms be arbitrarily large? If not, what is the upper bound? We show that for $p=1$, the ratio is always bounded and find sharp estimates, while for $p&gt;1$, the answer depends on the geometry of the domain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01611v1</guid>
      <category>math.CA</category>
      <category>math.FA</category>
      <category>math.OC</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexander Plakhov, Vladimir Protasov</dc:creator>
    </item>
    <item>
      <title>On the Design of Resilient Distributed Single Time-Scale Estimators: A Graph-Theoretic Approach</title>
      <link>https://arxiv.org/abs/2505.01757</link>
      <description>arXiv:2505.01757v1 Announce Type: cross 
Abstract: Distributed estimation in interconnected systems has gained increasing attention due to its relevance in diverse applications such as sensor networks, autonomous vehicles, and cloud computing. In real practice, the sensor network may suffer from communication and/or sensor failures. This might be due to cyber-attacks, faults, or environmental conditions. Distributed estimation resilient to such conditions is the topic of this paper. By representing the sensor network as a graph and exploiting its inherent structural properties, we introduce novel techniques that enhance the robustness of distributed estimators. As compared to the literature, the proposed estimator (i) relaxes the network connectivity of most existing single time-scale estimators and (ii) reduces the communication load of the existing double time-scale estimators by avoiding the inner consensus loop.
  On the other hand, the sensors might be subject to faults or attacks, resulting in biased measurements. Removing these sensor data may result in observability loss. Therefore, we propose resilient design on the definitions of $q$-node-connectivity and $q$-link-connectivity, which capture robust strong-connectivity under link or sensor node failure. By proper design of the sensor network, we prove Schur stability of the proposed distributed estimation protocol under failure of up to $q$ sensors or $q$ communication links.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01757v1</guid>
      <category>eess.SY</category>
      <category>cs.DC</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>math.OC</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammadreza Doostmohammadian, Mohammad Pirani</dc:creator>
    </item>
    <item>
      <title>Pinching Antenna-enabled ISAC Systems: Exploiting Look-Angle Dependence of RCS for Target Diversity</title>
      <link>https://arxiv.org/abs/2505.01777</link>
      <description>arXiv:2505.01777v1 Announce Type: cross 
Abstract: We investigate a novel integrated sensing and communication (ISAC) system supported by pinching antennas (PAs), which can be dynamically activated along a dielectric waveguide to collect spatially diverse observations. This capability allows different PAs to view the same target from different angles across time, thereby introducing target diversity, which is a key advantage over conventional fixed antenna arrays. To quantify the sensing reliability, we adopt the outage probability as a performance metric, capturing the likelihood that the accumulated radar echo signal power falls below a detection threshold. In contrast to traditional ISAC models that assume deterministic sensing channels, we explicitly account for the look-angle dependence of radar cross-section (RCS) by modeling it as a random variable. We ensure the long-term quality-of-service (QoS) for communication users by enforcing an accumulated data rate constraint over time. We derive an exact closed-form expression for the sensing outage probability based on the distribution of weighted sums of exponentially distributed random variables. Since the resulting expression is highly non-convex and intractable for optimization, we use a tractable upper bound based on the Chernoff inequality and formulate a PA activation optimization problem. A successive convex approximation (SCA) framework is proposed to efficiently solve the formulated problem. Numerical results show that dynamically activating different PAs across time slots significantly enhances sensing reliability compared to repeatedly activating the same PA at a fixed position and conventional antenna selection schemes, respectively. These findings highlight the benefits of integrating outage-based reliability metrics and target diversity into ISAC systems using PAs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01777v1</guid>
      <category>eess.SP</category>
      <category>math.OC</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ata Khalili, Brikena Kaziu, Vasilis K. Papanikolaou, Robert Schober</dc:creator>
    </item>
    <item>
      <title>Pathfinders in the Sky: Formal Decision-Making Models for Collaborative Air Traffic Control in Convective Weather</title>
      <link>https://arxiv.org/abs/2505.01804</link>
      <description>arXiv:2505.01804v1 Announce Type: cross 
Abstract: Air traffic can be significantly disrupted by weather. Pathfinder operations involve assigning a designated aircraft to assess whether airspace that was previously impacted by weather can be safely traversed through. Despite relatively routine use in air traffic control, there is little research on the underlying multi-agent decision-making problem. We seek to address this gap herein by formulating decision models to capture the operational dynamics and implications of pathfinders. Specifically, we construct a Markov chain to represent the stochastic transitions between key operational states (e.g., pathfinder selection). We then analyze its steady-state behavior to understand long-term system dynamics. We also propose models to characterize flight-specific acceptance behaviors (based on utility trade-offs) and pathfinder selection strategies (based on sequential offer allocations). We then conduct a worst-case scenario analysis that highlights risks from collective rejection and explores how selfless behavior and uncertainty affect system resilience. Empirical analysis of data from the US Federal Aviation Administration demonstrates the real-world significance of pathfinder operations and informs future model calibration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01804v1</guid>
      <category>cs.MA</category>
      <category>math.OC</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jimin Choi, Kartikeya Anand, Husni R. Idris, Huy T. Tran, Max Z. Li</dc:creator>
    </item>
    <item>
      <title>Data-Driven Team Selection in Fantasy Premier League Using Integer Programming and Predictive Modeling Approach</title>
      <link>https://arxiv.org/abs/2505.02170</link>
      <description>arXiv:2505.02170v1 Announce Type: cross 
Abstract: Fantasy football is a billion-dollar industry with millions of participants. Constrained by a fixed budget, decision-makers draft a squad whose players are expected to perform well in the upcoming weeks to maximize total points. This paper proposes novel deterministic and robust integer programming models that select the optimal starting eleven and the captain. A new hybrid scoring metric is constructed using an interpretable artificial intelligence framework and underlying match performance data. Several objective functions and estimation techniques are introduced for the programming model. To the best of my knowledge, this is the first study to approach fantasy football through this lens. The models' performance is evaluated using data from the 2023/24 Premier League season. Results indicate that the proposed hybrid method achieved the highest score while maintaining consistent performance. Utilizing the Monte Carlo simulation, the strategic choice of averaging techniques for estimating cost vectors, and the proposed hybrid approach are shown to be effective during the out-of-sample period. This paper also provides a thorough analysis of the optimal formations and players selected by the models, offering valuable insights into effective fantasy football strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02170v1</guid>
      <category>cs.CE</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Danial Ramezani</dc:creator>
    </item>
    <item>
      <title>Mirror Mean-Field Langevin Dynamics</title>
      <link>https://arxiv.org/abs/2505.02621</link>
      <description>arXiv:2505.02621v1 Announce Type: cross 
Abstract: The mean-field Langevin dynamics (MFLD) minimizes an entropy-regularized nonlinear convex functional on the Wasserstein space over $\mathbb{R}^d$, and has gained attention recently as a model for the gradient descent dynamics of interacting particle systems such as infinite-width two-layer neural networks. However, many problems of interest have constrained domains, which are not solved by existing mean-field algorithms due to the global diffusion term. We study the optimization of probability measures constrained to a convex subset of $\mathbb{R}^d$ by proposing the \emph{mirror mean-field Langevin dynamics} (MMFLD), an extension of MFLD to the mirror Langevin framework. We obtain linear convergence guarantees for the continuous MMFLD via a uniform log-Sobolev inequality, and uniform-in-time propagation of chaos results for its time- and particle-discretized counterpart.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02621v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anming Gu, Juno Kim</dc:creator>
    </item>
    <item>
      <title>Stochastic Games with Limited Public Memory</title>
      <link>https://arxiv.org/abs/2505.02623</link>
      <description>arXiv:2505.02623v1 Announce Type: cross 
Abstract: We study the memory resources required for near-optimal play in two-player zero-sum stochastic games with the long-run average payoff. Although optimal strategies may not exist in such games, near-optimal strategies always do.
  Mertens and Neyman (1981) proved that in any stochastic game, for any $\varepsilon&gt;0$, there exist uniform $\varepsilon$-optimal memory-based strategies -- i.e., strategies that are $\varepsilon$-optimal in all sufficiently long $n$-stage games -- that use at most $O(n)$ memory states within the first $n$ stages. We improve this bound on the number of memory states by proving that in any stochastic game, for any $\varepsilon&gt;0$, there exist uniform $\varepsilon$-optimal memory-based strategies that use at most $O(\log n)$ memory states in the first $n$ stages. Moreover, we establish the existence of uniform $\varepsilon$-optimal memory-based strategies whose memory updating and action selection are time-independent and such that, with probability close to 1, for all $n$, the number of memory states used up to stage $n$ is at most $O(\log n)$.
  This result cannot be extended to strategies with bounded public memory -- even if time-dependent memory updating and action selection are allowed. This impossibility is illustrated in the Big Match -- a well-known stochastic game where the stage payoffs to Player 1 are 0 or 1. Although for any $\varepsilon &gt; 0$, there exist strategies of Player 1 that guarantee a payoff {exceeding} $1/2 - \varepsilon$ in all sufficiently long $n$-stage games, we show that any strategy of Player 1 that uses a finite public memory fails to guarantee a payoff greater than $\varepsilon$ in any sufficiently long $n$-stage game.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02623v1</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kristoffer Arnsfelt Hansen, Rasmus Ibsen-Jensen, Abraham Neyman</dc:creator>
    </item>
    <item>
      <title>Towards Quantifying the Hessian Structure of Neural Networks</title>
      <link>https://arxiv.org/abs/2505.02809</link>
      <description>arXiv:2505.02809v1 Announce Type: cross 
Abstract: Empirical studies reported that the Hessian matrix of neural networks (NNs) exhibits a near-block-diagonal structure, yet its theoretical foundation remains unclear. In this work, we reveal two forces that shape the Hessian structure: a ``static force'' rooted in the architecture design, and a ``dynamic force'' arisen from training. We then provide a rigorous theoretical analysis of ``static force'' at random initialization. We study linear models and 1-hidden-layer networks with the mean-square (MSE) loss and the Cross-Entropy (CE) loss for classification tasks. By leveraging random matrix theory, we compare the limit distributions of the diagonal and off-diagonal Hessian blocks and find that the block-diagonal structure arises as $C \rightarrow \infty$, where $C$ denotes the number of classes. Our findings reveal that $C$ is a primary driver of the near-block-diagonal structure. These results may shed new light on the Hessian structure of large language models (LLMs), which typically operate with a large $C$ exceeding $10^4$ or $10^5$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02809v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhaorui Dong, Yushun Zhang, Zhi-Quan Luo, Jianfeng Yao, Ruoyu Sun</dc:creator>
    </item>
    <item>
      <title>Gauss-Southwell type descent methods for low-rank matrix optimization</title>
      <link>https://arxiv.org/abs/2306.00897</link>
      <description>arXiv:2306.00897v3 Announce Type: replace 
Abstract: We consider gradient-related methods for low-rank matrix optimization with a smooth cost function. The methods operate on single factors of the low-rank factorization and share aspects of both alternating and Riemannian optimization. Two possible choices for the search directions based on Gauss-Southwell type selection rules are compared: one using the gradient of a factorized non-convex formulation, the other using the Riemannian gradient. While both methods provide gradient convergence guarantees that are similar to the unconstrained case, numerical experiments on a quadratic cost function indicate that the version based on the Riemannian gradient is significantly more robust with respect to small singular values and the condition number of the cost function. As a side result of our approach, we also obtain new convergence results for the alternating least squares method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.00897v3</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guillaume Olikier, Andr\'e Uschmajew, Bart Vandereycken</dc:creator>
    </item>
    <item>
      <title>On reachability of Markov decision processes: a novel state-classification-based PI approach</title>
      <link>https://arxiv.org/abs/2308.06298</link>
      <description>arXiv:2308.06298v2 Announce Type: replace 
Abstract: This paper concentrates on the reliability of a discrete-time controlled Markov system with finite states and actions, and aims to give an efficient algorithm for obtaining an optimal (control) policy that makes the system have the maximal reliability for every initial state. After establishing the existence of an optimal policy, for the computation of optimal policies, we introduce the concept of an absorbing set of a stationary policy, and find some characterization and a computational method of the absorbing sets. Using the largest absorbing set, we build a novel optimality equation (OE), and prove the uniqueness of a solution of the OE. Furthermore, we provide a policy iteration algorithm of optimal policies, and prove that an optimal policy and the maximal reliability can be obtained in a finite number of iterations. Finally, an example in reliability and maintenance problems is given to illustrate our results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.06298v2</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yanyun Li, Xin Guo, Xianping Guo</dc:creator>
    </item>
    <item>
      <title>Adaptive Softassign via Hadamard-Equipped Sinkhorn</title>
      <link>https://arxiv.org/abs/2309.13855</link>
      <description>arXiv:2309.13855v4 Announce Type: replace 
Abstract: Softassign is a pivotal method in graph matching and other learning tasks. Many softassign-based algorithms exhibit performance sensitivity to a parameter in the softassign. However, tuning the parameter is challenging and almost done empirically. This paper proposes an adaptive softassign method for graph matching by analyzing the relationship between the objective score and the parameter. This method can automatically tune the parameter based on a given error bound to guarantee accuracy. The Hadamard-Equipped Sinkhorn formulas introduced in this study significantly enhance the efficiency and stability of the adaptive softassign. Moreover, these formulas can also be used in optimal transport problems. The resulting adaptive softassign graph matching algorithm enjoys significantly higher accuracy than previous state-of-the-art large graph matching algorithms while maintaining comparable efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.13855v4</guid>
      <category>math.OC</category>
      <category>math.CO</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Binrui Shen, Qiang Niu, Shengxin Zhu</dc:creator>
    </item>
    <item>
      <title>Joint Problems in Learning Multiple Dynamical Systems</title>
      <link>https://arxiv.org/abs/2311.02181</link>
      <description>arXiv:2311.02181v3 Announce Type: replace 
Abstract: Clustering of time series is a well-studied problem, with applications ranging from quantitative, personalized models of metabolism obtained from metabolite concentrations to state discrimination in quantum information theory. We consider a variant, where given a set of trajectories and a number of parts, we jointly partition the set of trajectories and learn linear dynamical system (LDS) models for each part, so as to minimize the maximum error across all the models. We present globally convergent methods and EM heuristics, accompanied by promising computational results. The key highlight of this method is that it does not require a predefined hidden state dimension but instead provides an upper bound. Additionally, it offers guidance for determining regularization in the system identification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.02181v3</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mengjia Niu, Xiaoyu He, Petr Ry\v{s}av\'y, Quan Zhou, Jakub Marecek</dc:creator>
    </item>
    <item>
      <title>Almost-Surely Convergent Randomly Activated Monotone Operator Splitting Methods</title>
      <link>https://arxiv.org/abs/2403.10673</link>
      <description>arXiv:2403.10673v3 Announce Type: replace 
Abstract: We propose stochastic splitting algorithms for solving large-scale composite inclusion problems involving monotone and linear operators. They activate at each iteration blocks of randomly selected resolvents of monotone operators and, unlike existing methods, achieve almost sure convergence of the iterates to a solution without any regularity assumptions or knowledge of the norms of the linear operators. Applications to image recovery and machine learning are provided.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.10673v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Patrick L. Combettes, Javier I. Madariaga</dc:creator>
    </item>
    <item>
      <title>Non-concave stochastic optimal control in finite discrete time under model uncertainty</title>
      <link>https://arxiv.org/abs/2404.05230</link>
      <description>arXiv:2404.05230v2 Announce Type: replace 
Abstract: In this article we present a general framework for non-concave robust stochastic control problems under model uncertainty in a discrete time finite horizon setting. Our framework allows to consider a variety of different path-dependent ambiguity sets of probability measures comprising, as a natural example, the ambiguity set defined via Wasserstein-balls around path-dependent reference measures with path-dependent radii, as well as parametric classes of probability distributions. We establish a dynamic programming principle which allows to derive both optimal control and worst-case measure by solving recursively a sequence of one-step optimization problems. Moreover, we derive upper bounds for the difference of the values of the robust and non-robust stochastic control problem in the Wasserstein uncertainty and parameter uncertainty case. As a concrete application, we study the robust hedging problem of financial derivatives under an asymmetric (and non-convex) loss function accounting for different preferences of sell- and buy side when it comes to the hedging of financial derivatives. As our entirely data-driven ambiguity set of probability measures, we consider Wasserstein-balls around the empirical measure derived from real financial data. We demonstrate that during adverse scenarios such as a financial crisis, our robust approach outperforms typical model-based hedging strategies such as the classical Delta-hedging strategy as well as the hedging strategy obtained in the non-robust setting with respect to the empirical measure and therefore overcomes the problem of model misspecification in such critical periods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.05230v2</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>q-fin.MF</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ariel Neufeld, Julian Sester</dc:creator>
    </item>
    <item>
      <title>A Characterization for Tightness of the Sparse Moment-SOS Hierarchy</title>
      <link>https://arxiv.org/abs/2406.06882</link>
      <description>arXiv:2406.06882v3 Announce Type: replace 
Abstract: This paper studies the sparse Moment-SOS hierarchy of relaxations for solving sparse polynomial optimization problems. We show that this sparse hierarchy is tight if and only if the objective can be written as a sum of sparse nonnegative polynomials, each of which belongs to the sum of the ideal and quadratic module generated by the corresponding sparse constraints. Based on this characterization, we give several sufficient conditions for the sparse Moment-SOS hierarchy to be tight. In particular, we show that this sparse hierarchy is tight under some assumptions such as convexity, optimality conditions or finiteness of constraining sets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06882v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiawang Nie, Zheng Qu, Xindong Tang, Linghao Zhang</dc:creator>
    </item>
    <item>
      <title>Metric extrapolation in the Wasserstein space</title>
      <link>https://arxiv.org/abs/2407.10516</link>
      <description>arXiv:2407.10516v3 Announce Type: replace 
Abstract: In this article we study a variational problem providing a way to extend for all times minimizing geodesics connecting two given probability measures, in the Wasserstein space. This is simply obtained by allowing for negative coefficients in the classical variational characterization of Wasserstein barycenters. We show that this problem admits two equivalent convex formulations: the first can be seen as a particular instance of Toland duality and the second is a barycentric optimal transport problem. We propose an efficient numerical scheme to solve the latter formulation based on entropic regularization and a variant of Sinkhorn algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10516v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas O. Gallou\"et (PARMA, LMO), Andrea Natale (RAPSODI, LPP), Gabriele Todeschi</dc:creator>
    </item>
    <item>
      <title>On the growth of nonconvex functionals at strict local minimizers</title>
      <link>https://arxiv.org/abs/2409.01833</link>
      <description>arXiv:2409.01833v4 Announce Type: replace 
Abstract: We give new characterizations of growth conditions at strict local minimizers. The main characterizations are a variant of the so-called tilt stability property and an analog of the classical Polyak--\L{}ojasiewicz condition, where the gradient is replaced by linear perturbations. As a consequence, we derive a tilting principle that relates the stability of minimizers under linear perturbations to their stability under nonlinear ones.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.01833v4</guid>
      <category>math.OC</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alberto Dom\'inguez Corella, Tr\'i Minh L\^e</dc:creator>
    </item>
    <item>
      <title>On time-inconsistent extended mean-field control problems with common noise</title>
      <link>https://arxiv.org/abs/2409.07219</link>
      <description>arXiv:2409.07219v2 Announce Type: replace 
Abstract: This paper studies a class of time-inconsistent mean field control (MFC) problems in the presence of common noise under non-exponential discount and joint law dependence of both state and control. We investigate the closed-loop time-consistent equilibrium strategies for these extended MFC problems and characterize them through an equilibrium Hamilton-Jacobi-Bellman (HJB) equation defined on the Wasserstein space. We first apply the results to the linear-quadratic (LQ) time-inconsistent MFC problems and obtain the existence of time-consistent equilibria via a comprehensive study of a nonlocal Riccati system. To illustrate the theoretical findings, two financial applications are presented. We then examine a class of non-LQ time-inconsistent MFC problems, for which we contribute the existence of time-consistent equilibria by analyzing a nonlocal nonlinear partial differential equation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.07219v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zongxia Liang, Xiang Yu, Keyu Zhang</dc:creator>
    </item>
    <item>
      <title>From Gradient Clipping to Normalization for Heavy Tailed SGD</title>
      <link>https://arxiv.org/abs/2410.13849</link>
      <description>arXiv:2410.13849v2 Announce Type: replace 
Abstract: Recent empirical evidence indicates that many machine learning applications involve heavy-tailed gradient noise, which challenges the standard assumptions of bounded variance in stochastic optimization. Gradient clipping has emerged as a popular tool to handle this heavy-tailed noise, as it achieves good performance in this setting both theoretically and practically. However, our current theoretical understanding of non-convex gradient clipping has three main shortcomings. First, the theory hinges on large, increasing clipping thresholds, which are in stark contrast to the small constant clipping thresholds employed in practice. Second, clipping thresholds require knowledge of problem-dependent parameters to guarantee convergence. Lastly, even with this knowledge, current sampling complexity upper bounds for the method are sub-optimal in nearly all parameters. To address these issues, we study convergence of Normalized SGD (NSGD). First, we establish a parameter-free sample complexity for NSGD of $\mathcal{O}\left(\varepsilon^{-\frac{2p}{p-1}}\right)$ to find an $\varepsilon$-stationary point. Furthermore, we prove tightness of this result, by providing a matching algorithm-specific lower bound. In the setting where all problem parameters are known, we show this complexity is improved to $\mathcal{O}\left(\varepsilon^{-\frac{3p-2}{p-1}}\right)$, matching the previously known lower bound for all first-order methods in all problem dependent parameters. Finally, we establish high-probability convergence of NSGD with a mild logarithmic dependence on the failure probability. Our work complements the studies of gradient clipping under heavy tailed noise improving the sample complexities of existing algorithms and offering an alternative mechanism to achieve high probability convergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.13849v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Florian H\"ubler, Ilyas Fatkhullin, Niao He</dc:creator>
    </item>
    <item>
      <title>The monotonicity of the Cheeger constant for parallel bodies</title>
      <link>https://arxiv.org/abs/2412.20917</link>
      <description>arXiv:2412.20917v2 Announce Type: replace 
Abstract: We prove that for every planar convex set $\Omega$, the function $t\in (-r(\Omega),+\infty)\longmapsto \sqrt{|\Omega_t|}h(\Omega_t)$ is monotonically decreasing, where $r$, $|\cdot|$ and $h$ stand for the inradius, the measure and the Cheeger constant and $(\Omega_t)$ for parallel bodies of $\Omega$. The result is shown to not hold when the convexity assumption is dropped. We also prove the differentiability of the map $t\longmapsto h(\Omega_t)$ in any dimension and without any regularity assumption on $\Omega$, obtaining an explicit formula for the derivative. Those results are then combined to obtain estimates on the contact surface of the Cheeger sets of convex bodies. Finally, potential generalizations to other functionals such as the first eigenvalue of the Dirichlet Laplacian are explored.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.20917v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ilias Ftouhi</dc:creator>
    </item>
    <item>
      <title>Numerical Approximation of Delay Differential Equations via Operator Splitting in Fractional Domains</title>
      <link>https://arxiv.org/abs/2502.05483</link>
      <description>arXiv:2502.05483v3 Announce Type: replace 
Abstract: This paper develops a rigorous framework for the numerical approximation of both autonomous and non-autonomous delay differential equations (DDEs), with a focus on the implicit Euler method and sequential operator splitting.
  To overcome the difficulty that the delay operator does not generate an analytic semigroup in the standard space \( L^1[\tau, 0] \), we embed the problem into the interpolation space \( \left(L^1[\tau, 0], W^{1,1}_0[\tau, 0]\right)_{\theta, 1} \) for \( 0 &lt; \theta &lt; 1 \), where the differential operator becomes sectorial. This allows the full operator \( L = A + B \) to generate an analytic semigroup \( T_L(t) \), enabling the use of semigroup theory to derive sharp error estimates.
  We prove that the implicit Euler method achieves a global error of order \( \mathcal{O}(h) \), while the Lie--Trotter splitting method yields an error of order \( \mathcal{O}(h^{2\theta - 1}) \) in the interpolation norm. These theoretical rates are confirmed by numerical experiments, including comparisons with exact solutions obtained via semi-analytical Fourier-based methods in the non-autonomous setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05483v3</guid>
      <category>math.OC</category>
      <category>math.FA</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hideki Kawahara</dc:creator>
    </item>
    <item>
      <title>A Parameter-Free and Near-Optimal Zeroth-Order Algorithm for Stochastic Convex Optimization</title>
      <link>https://arxiv.org/abs/2502.05600</link>
      <description>arXiv:2502.05600v2 Announce Type: replace 
Abstract: This paper considers zeroth-order optimization for stochastic convex minimization problem. We propose a parameter-free stochastic zeroth-order method (POEM) by introducing a step-size scheme based on the distance over finite difference and an adaptive smoothing parameter. We provide the theoretical analysis to show that POEM achieves the near-optimal stochastic zeroth-order oracle complexity. We further conduct the numerical experiments to demonstrate POEM outperforms existing zeroth-order methods in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05600v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kunjie Ren, Luo Luo</dc:creator>
    </item>
    <item>
      <title>Local controllability of a free-boundary problem for 1D degenerate parabolic equations</title>
      <link>https://arxiv.org/abs/2503.11929</link>
      <description>arXiv:2503.11929v2 Announce Type: replace 
Abstract: This paper deals with the local controllability of a free-boundary problem for the 1D boundary-degenerate parabolic equation with distributed controls, locally supported in space. We prove that, if the final time T is fixed and the initial state is sufficiently small, there exist controls that drive the state exactly to rest at time t = T. The proof is based on Schauder's fixed point theorem, combined with appropriate estimates for solutions to degenerate parabolic equations and for the control function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.11929v2</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lingyang Liu, Hang Gao</dc:creator>
    </item>
    <item>
      <title>Dual Averaging With Non-Strongly-Convex Prox-Functions: New Analysis and Algorithm</title>
      <link>https://arxiv.org/abs/2504.03613</link>
      <description>arXiv:2504.03613v2 Announce Type: replace 
Abstract: We present new analysis and algorithm of the dual-averaging-type (DA-type) methods for solving the composite convex optimization problem ${\min}_{x\in\mathbb{R}^n} \, f(\mathsf{A} x) + h(x)$, where $f$ is a convex and globally Lipschitz function, $\mathsf{A}$ is a linear operator, and $h$ is a ``simple'' and convex function that is used as the prox-function in the DA-type methods. We open new avenues of analyzing and developing DA-type methods, by going beyond the canonical setting where the prox-function $h$ is assumed to be strongly convex (on its domain). To that end, we identify two new sets of assumptions on $h$ (and also $f$ and $\mathsf{A}$) and show that they hold broadly for many important classes of non-strongly-convex functions. Under the first set of assumptions, we show that the original DA method still has a $O(1/k)$ primal-dual convergence rate. Moreover, we analyze the affine invariance of this method and its convergence rate. Under the second set of assumptions, we develop a new DA-type method with dual monotonicity, and show that it has a $O(1/k)$ primal-dual convergence rate. Finally, we consider the case where $f$ is only convex and Lipschitz on $\mathcal{C}:=\mathsf{A}(\mathsf{dom} h)$, and construct its globally convex and Lipschitz extension based on the Pasch-Hausdorff envelope. Furthermore, we characterize the sub-differential and Fenchel conjugate of this extension using the convex analytic objects associated with $f$ and $\mathcal{C}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03613v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Renbo Zhao</dc:creator>
    </item>
    <item>
      <title>Distributed Online Randomized Gradient-Free optimization with Compressed Communication</title>
      <link>https://arxiv.org/abs/2504.21693</link>
      <description>arXiv:2504.21693v2 Announce Type: replace 
Abstract: This paper addresses two fundamental challenges in distributed online convex optimization: communication efficiency and optimization under limited feedback. We propose Online Compressed Gradient Tracking with one-point Bandit Feedback (OCGT-BF), a novel algorithm that harness data compression and gradient-free optimization techniques in distributed networks. Our algorithm incorporates a compression scheme with error compensation mechanisms to reduce communication overhead while maintaining convergence guarantees. Unlike traditional approaches that assume perfect communication and full gradient access, OCGT-BF operates effectively under practical constraints by combining gradient-like tracking with one-point feedback estimation. We provide theoretical analysis demonstrating the dynamic regret bounds under both bandit feedback and stochastic gradient scenarios. Finally, extensive experiments validate that OCGT-BF achieves low dynamic regret while significantly reducing communication requirements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.21693v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Longkang Zhu, Xinli Shi, Xiangping Xu, Jinde Cao</dc:creator>
    </item>
    <item>
      <title>Generalized $\theta$-Parametric Metric Spaces: Fixed Point Theorems and Applications to Fractional Economic Models</title>
      <link>https://arxiv.org/abs/2505.00722</link>
      <description>arXiv:2505.00722v2 Announce Type: replace 
Abstract: The objective of this manuscript is to introduce and develop the concept of a generalized $\theta$-parametric metric space-a novel extension that enriches the modern metric fixed point theory. We study of its fundamental properties, including convergence and Cauchy sequences that establishes a solid theoretical foundation. A significant highlight of our work is the formulation of Suzuki-type fixed point theorem within this framework which extends classical results in a meaningful way. To demonstrate the depth and applicability of our findings, we construct non-trivial examples that illustrate the behavior of key concepts. Moreover, as a practical application, we apply our main theorem to analyze an economic growth model, demonstrating its utility in solving fractional differential equations that arise in dynamic economic systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00722v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Abhishikta Das, Hemanta Kalita, Mohammad Sajid, T. Bag</dc:creator>
    </item>
    <item>
      <title>Wasserstein Distributionally Robust Estimation in High Dimensions: Performance Analysis and Optimal Hyperparameter Tuning</title>
      <link>https://arxiv.org/abs/2206.13269</link>
      <description>arXiv:2206.13269v3 Announce Type: replace-cross 
Abstract: Distributionally robust optimization (DRO) has become a powerful framework for estimation under uncertainty, offering strong out-of-sample performance and principled regularization. In this paper, we propose a DRO-based method for linear regression and address a central question: how to optimally choose the robustness radius, which controls the trade-off between robustness and accuracy. Focusing on high-dimensional settings where the dimension and the number of samples are both large and comparable in size, we employ tools from high-dimensional asymptotic statistics to precisely characterize the estimation error of the resulting estimator. Remarkably, this error can be recovered by solving a simple convex-concave optimization problem involving only four scalar variables. This characterization enables efficient selection of the radius that minimizes the estimation error. In doing so, it achieves the same effect as cross-validation, but at a fraction of the computational cost. Numerical experiments confirm that our theoretical predictions closely match empirical performance and that the optimal radius selected through our method aligns with that chosen by cross-validation, highlighting both the accuracy and the practical benefits of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2206.13269v3</guid>
      <category>stat.ML</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Liviu Aolaritei, Soroosh Shafiee, Florian D\"orfler</dc:creator>
    </item>
    <item>
      <title>Conformal Predictive Programming for Chance Constrained Optimization</title>
      <link>https://arxiv.org/abs/2402.07407</link>
      <description>arXiv:2402.07407v2 Announce Type: replace-cross 
Abstract: We propose conformal predictive programming (CPP), a framework to solve chance constrained optimization problems, i.e., optimization problems with constraints that are functions of random variables. CPP utilizes samples from these random variables along with the quantile lemma - central to conformal prediction - to transform the chance constrained optimization problem into a deterministic problem with a quantile reformulation. CPP inherits a priori guarantees on constraint satisfaction from existing sample average approximation approaches for a class of chance constrained optimization problems, and it provides a posteriori guarantees that are of conditional and marginal nature otherwise. The strength of CPP is that it can easily support different variants of conformal prediction which have been (or will be) proposed within the conformal prediction community. To illustrate this, we present robust CPP to deal with distribution shifts in the random variables and Mondrian CPP to deal with class conditional chance constraints. To enable tractable solutions to the quantile reformulation, we present a mixed integer programming method (CPP-MIP) encoding, a bilevel optimization strategy (CPP-Bilevel), and a sampling-and-discarding optimization strategy (CPP-Discarding). We also extend CPP to deal with joint chance constrained optimization (JCCO). In a series of case studies, we show the validity of the aforementioned approaches, empirically compare CPP-MIP, CPP-Bilevel, as well as CPP-Discarding, and illustrate the advantage of CPP as compared to scenario approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.07407v2</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yiqi Zhao, Xinyi Yu, Matteo Sesia, Jyotirmoy V. Deshmukh, Lars Lindemann</dc:creator>
    </item>
    <item>
      <title>Boundary controllability for a fourth order degenerate parabolic equation with a singular potential</title>
      <link>https://arxiv.org/abs/2403.08745</link>
      <description>arXiv:2403.08745v3 Announce Type: replace-cross 
Abstract: In this paper, we prove the null controllability of a one-dimensional fourth-order degenerate parabolic equation with a singular potential. Here, we analyze cases where boundary control conditions are applied at the left endpoint. We utilize a spectral decomposition involving Bessel functions and their zeros in a convenient weighted Sobolev space for a degenerate parabolic operator with specific boundary conditions. We establish the well-posedness of the system using semigroup operator theory. Subsequently, we employ the moment method by Fattorini and Russell to obtain an upper estimate of the cost of controllability. Additionally, we derive a lower estimate of the cost of controllability using a representation theorem for analytic functions of exponential type.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.08745v3</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Leandro Galo-Mendoza</dc:creator>
    </item>
    <item>
      <title>Delta-modular ILP Problems of Bounded Codimension, Discrepancy, and Convolution (new version)</title>
      <link>https://arxiv.org/abs/2405.17001</link>
      <description>arXiv:2405.17001v4 Announce Type: replace-cross 
Abstract: For integers $k,n \geq 0$ and a cost vector $c \in Z^n$, we study two fundamental integer linear programming (ILP) problems: \[
  \text{(Standard Form)} \quad \max\bigl\{c^\top x \colon Ax = b,\ x \in Z^n_{\geq 0}\bigr\} \text{ with } A \in Z^{k \times n}, \text{rank}(A) = k, b \in Z^k, \] \[
  \text{(Canonical Form)} \quad \max\bigl\{c^\top x \colon Ax \leq b,\ x \in Z^n\bigr\} \text{ with } A \in Z^{(n+k) \times n}, \text{rank}(A) = n, b \in Z^{n+k}. \] We present improved algorithms for both problems and their feasibility versions, parameterized by $k$ and $\Delta$, where $\Delta$ denotes the maximum absolute value of $\text{rank}(A) \times \text{rank}(A)$ subdeterminants of $A$. Our main complexity results, stated in terms of required arithmetic operations, are: \[ \text{Optimization:}\quad O(\log k)^{2k} \cdot \Delta^2 / 2^{\Omega(\sqrt{\log \Delta})} + 2^{O(k)} \cdot \text{poly}(\varphi), \] \[ \text{Feasibility:} \quad O(\log k)^k \cdot \Delta \cdot (\log \Delta)^3 + 2^{O(k)} \cdot \text{poly}(\varphi), \] where $\varphi$ represents the input size measured by the bit-encoding length of $(A,b,c)$. We also examine several special cases when $k \in \{0,1\}$, which have important applications in: expected computational complexity of ILP with varying right-hand side $b$, ILP problems with generic constraint matrices, ILP problems on simplices. Our results yield improved complexity bounds for these specific scenarios.
  As independent contributions, we present: An $n^2/2^{\Omega(\sqrt{\log n})}$-time algorithm for the tropical convolution problem on sequences indexed by elements of a finite Abelian group of order $n$; A complete and self-contained error analysis of the generalized DFT over Abelian groups in the Word-RAM model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.17001v4</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>math.AC</category>
      <category>math.OC</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>M. Cherniavskii, D. Gribanov, D. Malyshev, P. M. Pardalos</dc:creator>
    </item>
    <item>
      <title>Which exceptional low-dimensional projections of a Gaussian point cloud can be found in polynomial time?</title>
      <link>https://arxiv.org/abs/2406.02970</link>
      <description>arXiv:2406.02970v2 Announce Type: replace-cross 
Abstract: Given $d$-dimensional standard Gaussian vectors $\boldsymbol{x}_1,\dots, \boldsymbol{x}_n$, we consider the set of all empirical distributions of its $m$-dimensional projections, for $m$ a fixed constant. Diaconis and Freedman (1984) proved that, if $n/d\to \infty$, all such distributions converge to the standard Gaussian distribution. In contrast, we study the proportional asymptotics, whereby $n,d\to \infty$ with $n/d\to \alpha \in (0, \infty)$. In this case, the projection of the data points along a typical random subspace is again Gaussian, but the set $\mathscr{F}_{m,\alpha}$ of all probability distributions that are asymptotically feasible as $m$-dimensional projections contains non-Gaussian distributions corresponding to exceptional subspaces.
  Non-rigorous methods from statistical physics yield an indirect characterization of $\mathscr{F}_{m,\alpha}$ in terms of a generalized Parisi formula. Motivated by the goal of putting this formula on a rigorous basis, and to understand whether these projections can be found efficiently, we study the subset $\mathscr{F}^{\rm alg}_{m,\alpha}\subseteq \mathscr{F}_{m,\alpha}$ of distributions that can be realized by a class of iterative algorithms. We prove that this set is characterized by a certain stochastic optimal control problem, and obtain a dual characterization of this problem in terms of a variational principle that extends Parisi's formula.
  As a byproduct, we obtain computationally achievable values for a class of random optimization problems including `generalized spherical perceptron' models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.02970v2</guid>
      <category>math.PR</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrea Montanari, Kangjie Zhou</dc:creator>
    </item>
    <item>
      <title>Learning stochastic dynamics from snapshots through regularized unbalanced optimal transport</title>
      <link>https://arxiv.org/abs/2410.00844</link>
      <description>arXiv:2410.00844v4 Announce Type: replace-cross 
Abstract: Reconstructing dynamics using samples from sparsely time-resolved snapshots is an important problem in both natural sciences and machine learning. Here, we introduce a new deep learning approach for solving regularized unbalanced optimal transport (RUOT) and inferring continuous unbalanced stochastic dynamics from observed snapshots. Based on the RUOT form, our method models these dynamics without requiring prior knowledge of growth and death processes or additional information, allowing them to be learned directly from data. Theoretically, we explore the connections between the RUOT and Schr\"odinger bridge problem and discuss the key challenges and potential solutions. The effectiveness of our method is demonstrated with a synthetic gene regulatory network, high-dimensional Gaussian Mixture Model, and single-cell RNA-seq data from blood development. Compared with other methods, our approach accurately identifies growth and transition patterns, eliminates false transitions, and constructs the Waddington developmental landscape. Our code is available at: https://github.com/zhenyiizhang/DeepRUOT.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00844v4</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>physics.comp-ph</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Zhenyi Zhang, Tiejun Li, Peijie Zhou</dc:creator>
    </item>
    <item>
      <title>Global Contact-Rich Planning with Sparsity-Rich Semidefinite Relaxations</title>
      <link>https://arxiv.org/abs/2502.02829</link>
      <description>arXiv:2502.02829v3 Announce Type: replace-cross 
Abstract: We show that contact-rich motion planning is also sparsity-rich when viewed as polynomial optimization (POP). We can exploit not only the correlative and term sparsity patterns that are general to all POPs, but also specialized sparsity patterns from the robot kinematic structure and the separability of contact modes. Such sparsity enables the design of high-order but sparse semidefinite programming (SDPs) relaxations--building upon Lasserre's moment and sums of squares hierarchy--that (i) can be solved in seconds by off-the-shelf SDP solvers, and (ii) compute near globally optimal solutions to the nonconvex contact-rich planning problems with small certified suboptimality. Through extensive experiments both in simulation (Push Bot, Push Box, Push Box with Obstacles, and Planar Hand) and real world (Push T), we demonstrate the power of using convex SDP relaxations to generate global contact-rich motion plans. As a contribution of independent interest, we release the Sparse Polynomial Optimization Toolbox (SPOT)--implemented in C++ with interfaces to both Python and Matlab--that automates sparsity exploitation for robotics and beyond.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02829v3</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shucheng Kang, Guorui Liu, Heng Yang</dc:creator>
    </item>
    <item>
      <title>Stability of optimal transport maps on Riemannian manifolds</title>
      <link>https://arxiv.org/abs/2504.05412</link>
      <description>arXiv:2504.05412v2 Announce Type: replace-cross 
Abstract: We prove quantitative bounds on the stability of optimal transport maps and Kantorovich potentials from a fixed source measure $\rho$ under variations of the target measure $\mu$, when the cost function is the squared Riemannian distance on a Riemannian manifold. Previous works were restricted to subsets of Euclidean spaces, or made specific assumptions either on the manifold, or on the regularity of the transport maps. Our proof techniques combine entropy-regularized optimal transport with spectral and integral-geometric techniques. As some of the arguments do not rely on the Riemannian structure, our work also paves the way towards understanding stability of optimal transport in more general geometric spaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.05412v2</guid>
      <category>math.MG</category>
      <category>math.OC</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jun Kitagawa, Cyril Letrouit, Quentin M\'erigot</dc:creator>
    </item>
    <item>
      <title>Observability conditions for neural state-space models with eigenvalues and their roots of unity</title>
      <link>https://arxiv.org/abs/2504.15758</link>
      <description>arXiv:2504.15758v2 Announce Type: replace-cross 
Abstract: We operate through the lens of ordinary differential equations and control theory to study the concept of observability in the context of neural state-space models and the Mamba architecture. We develop strategies to enforce observability, which are tailored to a learning context, specifically where the hidden states are learnable at initial time, in conjunction to over its continuum, and high-dimensional. We also highlight our methods emphasize eigenvalues, roots of unity, or both. Our methods effectuate computational efficiency when enforcing observability, sometimes at great scale. We formulate observability conditions in machine learning based on classical control theory and discuss their computational complexity. Our nontrivial results are fivefold. We discuss observability through the use of permutations in neural applications with learnable matrices without high precision. We present two results built upon the Fourier transform that effect observability with high probability up to the randomness in the learning. These results are worked with the interplay of representations in Fourier space and their eigenstructure, nonlinear mappings, and the observability matrix. We present a result for Mamba that is similar to a Hautus-type condition, but instead employs an argument using a Vandermonde matrix instead of eigenvectors. Our final result is a shared-parameter construction of the Mamba system, which is computationally efficient in high exponentiation. We develop a training algorithm with this coupling, showing it satisfies a Robbins-Monro condition under certain orthogonality, while a more classical training procedure fails to satisfy a contraction with high Lipschitz constant.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.15758v2</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrew Gracyk</dc:creator>
    </item>
    <item>
      <title>Numerical Representation of Preferences over Random Availability Functions</title>
      <link>https://arxiv.org/abs/2504.18863</link>
      <description>arXiv:2504.18863v2 Announce Type: replace-cross 
Abstract: We interpret a fuzzy set as a random availability function and provide sufficient conditions under which a preference relation over the set of all random availability functions can be represented by a utility function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.18863v2</guid>
      <category>econ.TH</category>
      <category>math.OC</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Somdeb Lahiri</dc:creator>
    </item>
  </channel>
</rss>
