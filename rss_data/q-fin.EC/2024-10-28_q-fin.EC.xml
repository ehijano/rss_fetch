<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-fin.EC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-fin.EC</link>
    <description>q-fin.EC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-fin.EC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 28 Oct 2024 04:01:24 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 28 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Prebunking Elections Rumors: Artificial Intelligence Assisted Interventions Increase Confidence in American Elections</title>
      <link>https://arxiv.org/abs/2410.19202</link>
      <description>arXiv:2410.19202v1 Announce Type: new 
Abstract: Large Language Models (LLMs) can assist in the prebunking of election misinformation. Using results from a preregistered two-wave experimental study of 4,293 U.S. registered voters conducted in August 2024, we show that LLM-assisted prebunking significantly reduced belief in specific election myths,with these effects persisting for at least one week. Confidence in election integrity was also increased post-treatment. Notably, the effect was consistent across partisan lines, even when controlling for demographic and attitudinal factors like conspiratorial thinking. LLM-assisted prebunking is a promising tool for rapidly responding to changing election misinformation narratives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.19202v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Mon, 28 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mitchell Linegar, Betsy Sinclair, Sander van der Linden, R. Michael Alvarez</dc:creator>
    </item>
    <item>
      <title>The Impact of Industry Agglomeration on Land Use Efficiency: Insights from China's Yangtze River Delta</title>
      <link>https://arxiv.org/abs/2410.19304</link>
      <description>arXiv:2410.19304v1 Announce Type: new 
Abstract: This study investigates the impact of industrial agglomeration on land use intensification in the Yangtze River Delta (YRD) urban agglomeration. Utilizing spatial econometric models, we conduct an empirical analysis of the clustering phenomena in manufacturing and producer services. By employing the Location Quotient (LQ) and the Relative Diversification Index (RDI), we assess the degree of industrial specialization and diversification in the YRD. Additionally, Global Moran's I and Local Moran's I scatter plots are used to reveal the spatial distribution characteristics of land use intensification. Our findings indicate that industrial agglomeration has complex effects on land use intensification, showing positive, negative, and inverted U-shaped impacts. These synergistic effects exhibit significant regional variations across the YRD. The study provides both theoretical foundations and empirical support for the formulation of land management and industrial development policies. In conclusion, we propose policy recommendations aimed at optimizing industrial structures and enhancing land use efficiency to foster sustainable development in the YRD region.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.19304v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Mon, 28 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hambur Wang</dc:creator>
    </item>
    <item>
      <title>Most Swiss-system tournaments are unfair: Evidence from chess</title>
      <link>https://arxiv.org/abs/2410.19333</link>
      <description>arXiv:2410.19333v1 Announce Type: new 
Abstract: Swiss-system is an increasingly popular tournament format as it provides an attractive trade-off between the number of matches and ranking accuracy. However, few empirical research consider the optimal design of the Swiss-system. We contribute to this issue by investigating the fairness of Swiss-system chess competitions with an odd number of rounds, where half of the players have an extra game with white pieces. They are proven to enjoy a significant advantage and to be overrepresented among both the highest-ranked and outperforming players. Therefore, Swiss-system tournaments should have an even number of rounds and use a pairing mechanism that guarantees a balanced colour assignment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.19333v1</guid>
      <category>econ.GN</category>
      <category>physics.soc-ph</category>
      <category>q-fin.EC</category>
      <category>stat.AP</category>
      <pubDate>Mon, 28 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>L\'aszl\'o Csat\'o</dc:creator>
    </item>
    <item>
      <title>Take Caution in Using LLMs as Human Surrogates: Scylla Ex Machina</title>
      <link>https://arxiv.org/abs/2410.19599</link>
      <description>arXiv:2410.19599v1 Announce Type: new 
Abstract: Recent studies suggest large language models (LLMs) can exhibit human-like reasoning, aligning with human behavior in economic experiments, surveys, and political discourse. This has led many to propose that LLMs can be used as surrogates for humans in social science research. However, LLMs differ fundamentally from humans, relying on probabilistic patterns, absent the embodied experiences or survival objectives that shape human cognition. We assess the reasoning depth of LLMs using the 11-20 money request game. Almost all advanced approaches fail to replicate human behavior distributions across many models, except in one case involving fine-tuning using a substantial amount of human behavior data. Causes of failure are diverse, relating to input language, roles, and safeguarding. These results caution against using LLMs to study human behaviors or as human surrogates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.19599v1</guid>
      <category>econ.GN</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <category>q-fin.EC</category>
      <pubDate>Mon, 28 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuan Gao, Dokyun Lee, Gordon Burtch, Sina Fazelpour</dc:creator>
    </item>
    <item>
      <title>Generating long-horizon stock "buy" signals with a neural language model</title>
      <link>https://arxiv.org/abs/2410.18988</link>
      <description>arXiv:2410.18988v1 Announce Type: cross 
Abstract: This paper describes experiments on fine-tuning a small language model to generate forecasts of long-horizon stock price movements. Inputs to the model are narrative text from 10-K reports of large market capitalization companies in the S&amp;P 500 index; the output is a forward-looking buy or sell decision. Price direction is predicted at discrete horizons up to 12 months after the report filing date. The results reported here demonstrate good out-of-sample statistical performance (F1-macro= 0.62) at medium to long investment horizons. In particular, the buy signals generated from 10-K text are found most precise at 6 and 9 months in the future. As measured by the F1 score, the buy signal provides between 4.8 and 9 percent improvement against a random stock selection model. In contrast, sell signals generated by the models do not perform well. This may be attributed to the highly imbalanced out-of-sample data, or perhaps due to management drafting annual reports with a bias toward positive language. Cross-sectional analysis of performance by economic sector suggests that idiosyncratic reporting styles within industries are correlated with varying degrees and time scales of price movement predictability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.18988v1</guid>
      <category>q-fin.ST</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Mon, 28 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joel R. Bock</dc:creator>
    </item>
  </channel>
</rss>
