<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.CO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.CO</link>
    <description>stat.CO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.CO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 26 Sep 2024 04:02:41 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 26 Sep 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Novel Framework for Analyzing Structural Transformation in Data-Constrained Economies Using Bayesian Modeling and Machine Learning</title>
      <link>https://arxiv.org/abs/2409.16738</link>
      <description>arXiv:2409.16738v1 Announce Type: cross 
Abstract: Structural transformation, the shift from agrarian economies to more diversified industrial and service-based systems, is a key driver of economic development. However, in low- and middle-income countries (LMICs), data scarcity and unreliability hinder accurate assessments of this process. This paper presents a novel statistical framework designed to address these challenges by integrating Bayesian hierarchical modeling, machine learning-based data imputation, and factor analysis. The framework is specifically tailored for conditions of data sparsity and is capable of providing robust insights into sectoral productivity and employment shifts across diverse economies. By utilizing Bayesian models, uncertainties in data are effectively managed, while machine learning techniques impute missing data points, ensuring the integrity of the analysis. Factor analysis reduces the dimensionality of complex datasets, distilling them into core economic structures. The proposed framework has been validated through extensive simulations, demonstrating its ability to predict structural changes even when up to 60\% of data is missing. This approach offers policymakers and researchers a valuable tool for making informed decisions in environments where data quality is limited, contributing to the broader understanding of economic development in LMICs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.16738v1</guid>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <pubDate>Thu, 26 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ronald Katende</dc:creator>
    </item>
    <item>
      <title>Variable Selection Using Nearest Neighbor Gaussian Processes</title>
      <link>https://arxiv.org/abs/2103.14315</link>
      <description>arXiv:2103.14315v2 Announce Type: replace 
Abstract: We introduce a novel Bayesian approach for variable selection using Gaussian process regression, which is crucial for enhancing interpretability and model regularization. Our method employs nearest neighbor Gaussian processes, serving as scalable approximations of classical Gaussian processes. Variable selection is achieved by conditioning the process mean and covariance function on a random set that represents the indices of contributing variables. A priori beliefs regarding this set control the variable selection, while reference priors are assigned to the remaining model parameters, ensuring numerical robustness in the process covariance matrix. We propose a Metropolis-Within-Gibbs algorithm for model inference. Evaluation using simulated data, a computer experiment approximation, and two real-world data sets demonstrate the effectiveness of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2103.14315v2</guid>
      <category>stat.CO</category>
      <pubDate>Thu, 26 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Konstantin Posch, Maximilian Arbeiter, Christian Truden, Martin Pleschberger, Juergen Pilz</dc:creator>
    </item>
    <item>
      <title>Tweedie Moment Projected Diffusions For Inverse Problems</title>
      <link>https://arxiv.org/abs/2310.06721</link>
      <description>arXiv:2310.06721v3 Announce Type: replace 
Abstract: Diffusion generative models unlock new possibilities for inverse problems as they allow for the incorporation of strong empirical priors in scientific inference. Recently, diffusion models are repurposed for solving inverse problems using Gaussian approximations to conditional densities of the reverse process via Tweedie's formula to parameterise the mean, complemented with various heuristics. To address various challenges arising from these approximations, we leverage higher order information using Tweedie's formula and obtain a statistically principled approximation. We further provide a theoretical guarantee specifically for posterior sampling which can lead to a better theoretical understanding of diffusion-based conditional sampling. Finally, we illustrate the empirical effectiveness of our approach for general linear inverse problems on toy synthetic examples as well as image restoration. We show that our method (i) removes any time-dependent step-size hyperparameters required by earlier methods, (ii) brings stability and better sample quality across multiple noise levels, (iii) is the only method that works in a stable way with variance exploding (VE) forward processes as opposed to earlier works.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.06721v3</guid>
      <category>stat.CO</category>
      <pubDate>Thu, 26 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Benjamin Boys, Mark Girolami, Jakiw Pidstrigach, Sebastian Reich, Alan Mosca, O. Deniz Akyildiz</dc:creator>
    </item>
    <item>
      <title>Best Linear Unbiased Estimate from Privatized Histograms</title>
      <link>https://arxiv.org/abs/2409.04387</link>
      <description>arXiv:2409.04387v2 Announce Type: replace 
Abstract: In differential privacy (DP) mechanisms, it can be beneficial to release "redundant" outputs, in the sense that a quantity can be estimated by combining different combinations of privatized values. Indeed, this structure is present in the DP 2020 Decennial Census products published by the U.S. Census Bureau. With this structure, the DP output can be improved by enforcing self-consistency (i.e., estimators obtained by combining different values result in the same estimate) and we show that the minimum variance processing is a linear projection. However, standard projection algorithms are too computationally expensive in terms of both memory and execution time for applications such as the Decennial Census. We propose the Scalable Efficient Algorithm for Best Linear Unbiased Estimate (SEA BLUE), based on a two step process of aggregation and differencing that 1) enforces self-consistency through a linear and unbiased procedure, 2) is computationally and memory efficient, 3) achieves the minimum variance solution under certain structural assumptions, and 4) is empirically shown to be robust to violations of these structural assumptions. We propose three methods of calculating confidence intervals from our estimates, under various assumptions. We apply SEA BLUE to two 2010 Census demonstration products, illustrating its scalability and validity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.04387v2</guid>
      <category>stat.CO</category>
      <category>cs.CR</category>
      <category>stat.AP</category>
      <pubDate>Thu, 26 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jordan Awan, Adam Edwards, Paul Bartholomew, Andrew Sillers</dc:creator>
    </item>
    <item>
      <title>Skew-symmetric schemes for stochastic differential equations with non-Lipschitz drift: an unadjusted Barker algorithm</title>
      <link>https://arxiv.org/abs/2405.14373</link>
      <description>arXiv:2405.14373v3 Announce Type: replace-cross 
Abstract: We propose a new simple and explicit numerical scheme for time-homogeneous stochastic differential equations. The scheme is based on sampling increments at each time step from a skew-symmetric probability distribution, with the level of skewness determined by the drift and volatility of the underlying process. We show that as the step-size decreases the scheme converges weakly to the diffusion of interest, and also prove path-wise accuracy in a particular setting. We then consider the problem of simulating from the limiting distribution of an ergodic diffusion process using the numerical scheme with a fixed step-size. We establish conditions under which the numerical scheme converges to equilibrium at a geometric rate, and quantify the bias between the equilibrium distributions of the scheme and of the true diffusion process. Notably, our results do not require a global Lipschitz assumption on the drift, in contrast to those required for the Euler--Maruyama scheme for long-time simulation at fixed step-sizes. Our weak convergence result relies on an extension of the theory of Milstein \&amp; Tretyakov to stochastic differential equations with non-Lipschitz drift, which could also be of independent interest. We support our theoretical results with numerical simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14373v3</guid>
      <category>math.PR</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.CO</category>
      <pubDate>Thu, 26 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Samuel Livingstone, Nikolas N\"usken, Giorgos Vasdekis, Rui-Yang Zhang</dc:creator>
    </item>
  </channel>
</rss>
