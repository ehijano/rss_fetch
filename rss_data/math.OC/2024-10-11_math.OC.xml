<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 11 Oct 2024 04:00:13 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Congestion and Penalization in Optimal Transport</title>
      <link>https://arxiv.org/abs/2410.07363</link>
      <description>arXiv:2410.07363v1 Announce Type: new 
Abstract: In this paper we introduce two novel models derived from the discrete optimal transport problem. The first model extends the traditional transport problem by adding a quadratic congestion factor directly into the cost function, while the second model replaces conventional constraints with weighted penalization terms. We present theoretical contributions, including the study and characterization of interior and corner solution for some specific cases, convergence to the optimal solutions, as well as smooth comparative statics analysis. Finally, we propose an $O((N+L)(NL)^2)$ algorithm for computing the optimal plan for the penalized model assuming interior solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07363v1</guid>
      <category>math.OC</category>
      <category>econ.TH</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marcelo Gallardo, Manuel Loaiza, Jorge Ch\'avez</dc:creator>
    </item>
    <item>
      <title>On the infimum of the upper envelope of certain families of functions</title>
      <link>https://arxiv.org/abs/2410.07450</link>
      <description>arXiv:2410.07450v1 Announce Type: new 
Abstract: In this paper, given a topological space $X$, an interval $I\subseteq {\bf R}$ and five continuous functions $\varphi, \psi, \omega :X\to {\bf R}$, $\alpha, \beta:I\to {\bf R}$, we are interested in the infimum of the function $\Phi:X\to ]-\infty,+\infty]$ defined by $$\Phi(x)=\sup_{\lambda\in I}(\alpha(\lambda)\varphi(x)+\beta(\lambda)\psi(x))+\omega(x)\ .$$ Using a recent minimax theorem ([5]), we build a general scheme which provides the exact value of $\inf_X\Phi$ for a large class of functions $\Phi$. When additional compactness conditions are satisfied, our scheme provides also the existence of (explicitly detected) functions $\gamma, \eta:X\to {\bf R}$ such that, for some $\tilde x\in X$, one has $$\gamma(\tilde x)\varphi(\tilde x)+\eta(\tilde x)\psi(\tilde x)+\omega(\tilde x)=\inf_{x\in X}(\gamma(\tilde x)\varphi(x)+\eta(\tilde x)\psi(x)+\omega(x))\ .$$</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07450v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Biagio Ricceri</dc:creator>
    </item>
    <item>
      <title>Adaptive Mesh Refinement and Error Estimation Method for Optimal Control Using Direct Collocation</title>
      <link>https://arxiv.org/abs/2410.07488</link>
      <description>arXiv:2410.07488v1 Announce Type: new 
Abstract: An adaptive mesh refinement and error estimation method for numerically solving optimal control problems is developed using Legendre-Gauss-Radau direct collocation. In regions of the solution where the desired accuracy tolerance has not been met, the mesh is refined by either increasing the degree of the approximating polynomial in a mesh interval or dividing a mesh interval into subintervals. In regions of the solution where the desired accuracy tolerance has been met, the mesh size may be reduced by either merging adjacent mesh intervals or decreasing the degree of the approximating polynomial in a mesh interval. Coupled with the mesh refinement method described in this paper is a newly developed relative error estimate that is based on the differences between solutions obtained from the collocation method and those obtained by solving initial-value and terminal-value problems in each mesh interval using an interpolated control obtained from the collocation method. Because the error estimate is based on explicit simulation, the solution obtained via collocation is in close agreement with the solution obtained via explicit simulation using the control on the final mesh, which ensures that the control is an accurate approximation of the true optimal control. The method is demonstrated on three examples from the open literature, and the results obtained show an improvement in final mesh size when compared against previously developed mesh refinement methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07488v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>George V. Haman III, Anil V. Rao</dc:creator>
    </item>
    <item>
      <title>R-Adaptive Mesh Optimization to Enhance Finite Element Basis Compression</title>
      <link>https://arxiv.org/abs/2410.07646</link>
      <description>arXiv:2410.07646v1 Announce Type: new 
Abstract: Modern computing systems are capable of exascale calculations, which are revolutionizing the development and application of high-fidelity numerical models in computational science and engineering. While these systems continue to grow in processing power, the available system memory has not increased commensurately, and electrical power consumption continues to grow. A predominant approach to limit the memory usage in large-scale applications is to exploit the abundant processing power and continually recompute many low-level simulation quantities, rather than storing them. However, this approach can adversely impact the throughput of the simulation and diminish the benefits of modern computing architectures. We present two novel contributions to reduce the memory burden while maintaining performance in simulations based on finite element discretizations. The first contribution develops dictionary-based data compression schemes that detect and exploit the structure of the discretization, due to redundancies across the finite element mesh. These schemes are shown to reduce memory requirements by more than 99 percent on meshes with large numbers of nearly identical mesh cells. For applications where this structure does not exist, our second contribution leverages a recently developed augmented Lagrangian sequential quadratic programming algorithm to enable r-adaptive mesh optimization, with the goal of enhancing redundancies in the mesh. Numerical results demonstrate the effectiveness of the proposed methods to detect, exploit and enhance mesh structure on examples inspired by large-scale applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07646v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Graham Harper, Denis Ridzal, Tim Wildey</dc:creator>
    </item>
    <item>
      <title>Meta-Learning from Learning Curves for Budget-Limited Algorithm Selection</title>
      <link>https://arxiv.org/abs/2410.07696</link>
      <description>arXiv:2410.07696v1 Announce Type: new 
Abstract: Training a large set of machine learning algorithms to convergence in order to select the best-performing algorithm for a dataset is computationally wasteful. Moreover, in a budget-limited scenario, it is crucial to carefully select an algorithm candidate and allocate a budget for training it, ensuring that the limited budget is optimally distributed to favor the most promising candidates. Casting this problem as a Markov Decision Process, we propose a novel framework in which an agent must select in the process of learning the most promising algorithm without waiting until it is fully trained. At each time step, given an observation of partial learning curves of algorithms, the agent must decide whether to allocate resources to further train the most promising algorithm (exploitation), to wake up another algorithm previously put to sleep, or to start training a new algorithm (exploration). In addition, our framework allows the agent to meta-learn from learning curves on past datasets along with dataset meta-features and algorithm hyperparameters. By incorporating meta-learning, we aim to avoid myopic decisions based solely on premature learning curves on the dataset at hand. We introduce two benchmarks of learning curves that served in international competitions at WCCI'22 and AutoML-conf'22, of which we analyze the results. Our findings show that both meta-learning and the progression of learning curves enhance the algorithm selection process, as evidenced by methods of winning teams and our DDQN baseline, compared to heuristic baselines or a random search. Interestingly, our cost-effective baseline, which selects the best-performing algorithm w.r.t. a small budget, can perform decently when learning curves do not intersect frequently.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07696v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>Pattern Recognition Letters, 2024, 185, pp.225-231</arxiv:journal_reference>
      <dc:creator>Manh Hung Nguyen (LISN), Lisheng Sun-Hosoya (LISN), Isabelle Guyon</dc:creator>
    </item>
    <item>
      <title>Continuous-time persuasion by filtering</title>
      <link>https://arxiv.org/abs/2410.07735</link>
      <description>arXiv:2410.07735v1 Announce Type: new 
Abstract: We frame dynamic persuasion in a partial observation stochastic control game with an ergodic criterion. The Receiver controls the dynamics of a multidimensional unobserved state process. Information is provided to the Receiver through a device designed by the Sender that generates the observation process. The commitment of the Sender is enforced. We develop this approach in the case where all dynamics are linear and the preferences of the Receiver are linear-quadratic. We prove a verification theorem for the existence and uniqueness of the solution of the HJB equation satisfied by the Receiver's value function. An extension to the case of persuasion of a mean field of interacting Receivers is also provided. We illustrate this approach in two applications: the provision of information to electricity consumers with a smart meter designed by an electricity producer; the information provided by carbon footprint accounting rules to companies engaged in a best-in-class emissions reduction effort. In the first application, we link the benefits of information provision to the mispricing of electricity production. In the latter, we show that when firms declare a high level of best-in-class target, the information provided by stringent accounting rules offsets the Nash equilibrium effect that leads firms to increase pollution to make their target easier to achieve.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07735v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ren\'e A\"id, Ofelia Bonesini, Giorgia Callegaro, Luciano Campi</dc:creator>
    </item>
    <item>
      <title>Gradient correlation is needed to accelerate SGD with momentum</title>
      <link>https://arxiv.org/abs/2410.07870</link>
      <description>arXiv:2410.07870v1 Announce Type: new 
Abstract: Empirically, it has been observed that adding momentum to Stochastic Gradient Descent (SGD) accelerates the convergence of the algorithm. However, the literature has been rather pessimistic, even in the case of convex functions, about the possibility of theoretically proving this observation. We investigate the possibility of obtaining accelerated convergence of the Stochastic Nesterov Accelerated Gradient (SNAG), a momentum-based version of SGD, when minimizing a sum of functions in a convex setting. We demonstrate that the average correlation between gradients allows to verify the strong growth condition, which is the key ingredient to obtain acceleration with SNAG. Numerical experiments, both in linear regression and deep neural network optimization, confirm in practice our theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07870v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Julien Hermant, Marien Renaud, Jean-Fran\c{c}ois Aujol, Charles Dossal, Aude Rondepierre</dc:creator>
    </item>
    <item>
      <title>Decision-Aware Predictive Model Selection for Workforce Allocation</title>
      <link>https://arxiv.org/abs/2410.07932</link>
      <description>arXiv:2410.07932v1 Announce Type: new 
Abstract: Many organizations depend on human decision-makers to make subjective decisions, especially in settings where information is scarce. Although workers are often viewed as interchangeable, the specific individual assigned to a task can significantly impact outcomes due to their unique decision-making processes and risk tolerance. In this paper, we introduce a novel framework that utilizes machine learning to predict worker behavior and employs integer optimization to strategically assign workers to tasks. Unlike traditional methods that treat machine learning predictions as static inputs for optimization, in our approach, the optimal predictive model used to represent a worker's behavior is determined by how that worker is allocated within the optimization process. We present a decision-aware optimization framework that integrates predictive model selection with worker allocation. Collaborating with an auto-insurance provider and using real-world data, we evaluate the effectiveness of our proposed method by applying three different techniques to predict worker behavior. Our findings show the proposed decision-aware framework outperforms traditional methods and offers context-sensitive and data-responsive strategies for workforce management.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07932v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eric G. Stratman, Justin J. Boutilier, Laura A. Albert</dc:creator>
    </item>
    <item>
      <title>Second-Order Optimization via Quiescence</title>
      <link>https://arxiv.org/abs/2410.08033</link>
      <description>arXiv:2410.08033v1 Announce Type: new 
Abstract: Second-order optimization methods exhibit fast convergence to critical points, however, in nonconvex optimization, these methods often require restrictive step-sizes to ensure a monotonically decreasing objective function. In the presence of highly nonlinear objective functions with large Lipschitz constants, increasingly small step-sizes become a bottleneck to fast convergence. We propose a second-order optimization method that utilizes a dynamic system model to represent the trajectory of optimization variables as an ODE. We then follow the quasi-steady state trajectory by forcing variables with the fastest rise time into a state known as quiescence. This optimization via quiescence allows us to adaptively select large step-sizes that sequentially follow each optimization variable to a quasi-steady state until all state variables reach the actual steady state, coinciding with the optimum. The result is a second-order method that utilizes large step-sizes and does not require a monotonically decreasing objective function to reach a critical point. Experimentally, we demonstrate the fast convergence of this approach for optimizing nonconvex problems in power systems and compare them to existing state-of-the-art second-order methods, including damped Newton-Raphson, BFGS, and SR1.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08033v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aayushya Agarwal, Larry Pileggi, Ronald Rohrer</dc:creator>
    </item>
    <item>
      <title>Optimal Transportation by Orthogonal Coupling Dynamics</title>
      <link>https://arxiv.org/abs/2410.08060</link>
      <description>arXiv:2410.08060v1 Announce Type: new 
Abstract: Many numerical algorithms and learning tasks rest on solution of the Monge-Kantorovich problem and corresponding Wasserstein distances. While the natural approach is to treat the problem as an infinite-dimensional linear programming, such a methodology severely limits the computational performance due to the polynomial scaling with respect to the sample size along with intensive memory requirements. We propose a novel alternative framework to address the Monge-Kantorovich problem based on a projection type gradient descent scheme. The micro-dynamics is built on the notion of the conditional expectation, where the connection with the opinion dynamics is explored and leveraged to build compact numerical schemes. We demonstrate that the devised dynamics recovers random maps with favourable computational performance. Along with the theoretical insight, the provided dynamics paves the way for innovative approaches to construct numerical schemes for computing optimal transport maps as well as Wasserstein distances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08060v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohsen Sadr, Peyman Mohajerin Esfehani, Hossein Gorji</dc:creator>
    </item>
    <item>
      <title>Representation of Zeros of a Copositive Matrix via Maximal Cliques of a Graph</title>
      <link>https://arxiv.org/abs/2410.08066</link>
      <description>arXiv:2410.08066v1 Announce Type: new 
Abstract: There is a profound connection between copositive matrices and graph theory. Copositive matrices provide a powerful tool for formulating and solving various challenging graph-related problems. Conversely, graph theory provides a rich set of concepts and techniques that can be applied to analyze key properties of copositive matrices, including their eigenvalues and spectra. In this paper, we present new aspects of the relationship between copositive matrices and graph theory. Focusing on the set of normalized zeros of a copositive matrix, we investigate its properties and demonstrate that this set can be expressed as a union of convex hulls of subsets of minimal zeros. We show that these subsets are connected with the set of maximal cliques of a special graph constructed on the basis of the set of minimal zeros of this matrix. We develop an algorithm for constructing both the set of normalized minimal zeros and the set of all normalized zeros of a copositive matrix.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08066v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>O. I. Kostyukova, T. V. Tchemisova</dc:creator>
    </item>
    <item>
      <title>Memory-augmented Transformers can implement Linear First-Order Optimization Methods</title>
      <link>https://arxiv.org/abs/2410.07263</link>
      <description>arXiv:2410.07263v1 Announce Type: cross 
Abstract: We show that memory-augmented Transformers (Memformers) can implement linear first-order optimization methods such as conjugate gradient descent, momentum methods, and more generally, methods that linearly combine past gradients. Building on prior work that demonstrates how Transformers can simulate preconditioned gradient descent, we provide theoretical and empirical evidence that Memformers can learn more advanced optimization algorithms. Specifically, we analyze how memory registers in Memformers store suitable intermediate attention values allowing them to implement algorithms such as conjugate gradient. Our results show that Memformers can efficiently learn these methods by training on random linear regression tasks, even learning methods that outperform conjugate gradient. This work extends our knowledge about the algorithmic capabilities of Transformers, showing how they can learn complex optimization methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07263v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sanchayan Dutta (UC Davis), Suvrit Sra (TU Munich)</dc:creator>
    </item>
    <item>
      <title>LLM Embeddings Improve Test-time Adaptation to Tabular $Y|X$-Shifts</title>
      <link>https://arxiv.org/abs/2410.07395</link>
      <description>arXiv:2410.07395v1 Announce Type: cross 
Abstract: For tabular datasets, the change in the relationship between the label and covariates ($Y|X$-shifts) is common due to missing variables (a.k.a. confounders). Since it is impossible to generalize to a completely new and unknown domain, we study models that are easy to adapt to the target domain even with few labeled examples. We focus on building more informative representations of tabular data that can mitigate $Y|X$-shifts, and propose to leverage the prior world knowledge in LLMs by serializing (write down) the tabular data to encode it. We find LLM embeddings alone provide inconsistent improvements in robustness, but models trained on them can be well adapted/finetuned to the target domain even using 32 labeled observations. Our finding is based on a comprehensive and systematic study consisting of 7650 source-target pairs and benchmark against 261,000 model configurations trained by 22 algorithms. Our observation holds when ablating the size of accessible target data and different adaptation strategies. The code is available at https://github.com/namkoong-lab/LLM-Tabular-Shifts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07395v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yibo Zeng, Jiashuo Liu, Henry Lam, Hongseok Namkoong</dc:creator>
    </item>
    <item>
      <title>The Plug-in Approach for Average-Reward and Discounted MDPs: Optimal Sample Complexity Analysis</title>
      <link>https://arxiv.org/abs/2410.07616</link>
      <description>arXiv:2410.07616v1 Announce Type: cross 
Abstract: We study the sample complexity of the plug-in approach for learning $\varepsilon$-optimal policies in average-reward Markov decision processes (MDPs) with a generative model. The plug-in approach constructs a model estimate then computes an average-reward optimal policy in the estimated model. Despite representing arguably the simplest algorithm for this problem, the plug-in approach has never been theoretically analyzed. Unlike the more well-studied discounted MDP reduction method, the plug-in approach requires no prior problem information or parameter tuning. Our results fill this gap and address the limitations of prior approaches, as we show that the plug-in approach is optimal in several well-studied settings without using prior knowledge. Specifically it achieves the optimal diameter- and mixing-based sample complexities of $\widetilde{O}\left(SA \frac{D}{\varepsilon^2}\right)$ and $\widetilde{O}\left(SA \frac{\tau_{\mathrm{unif}}}{\varepsilon^2}\right)$, respectively, without knowledge of the diameter $D$ or uniform mixing time $\tau_{\mathrm{unif}}$. We also obtain span-based bounds for the plug-in approach, and complement them with algorithm-specific lower bounds suggesting that they are unimprovable. Our results require novel techniques for analyzing long-horizon problems which may be broadly useful and which also improve results for the discounted plug-in approach, removing effective-horizon-related sample size restrictions and obtaining the first optimal complexity bounds for the full range of sample sizes without reward perturbation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07616v1</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matthew Zurek, Yudong Chen</dc:creator>
    </item>
    <item>
      <title>A Generalization Result for Convergence in Learning-to-Optimize</title>
      <link>https://arxiv.org/abs/2410.07704</link>
      <description>arXiv:2410.07704v1 Announce Type: cross 
Abstract: Convergence in learning-to-optimize is hardly studied, because conventional convergence guarantees in optimization are based on geometric arguments, which cannot be applied easily to learned algorithms. Thus, we develop a probabilistic framework that resembles deterministic optimization and allows for transferring geometric arguments into learning-to-optimize. Our main theorem is a generalization result for parametric classes of potentially non-smooth, non-convex loss functions and establishes the convergence of learned optimization algorithms to stationary points with high probability. This can be seen as a statistical counterpart to the use of geometric safeguards to ensure convergence. To the best of our knowledge, we are the first to prove convergence of optimization algorithms in such a probabilistic framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07704v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Sucker, Peter Ochs</dc:creator>
    </item>
    <item>
      <title>Offline Hierarchical Reinforcement Learning via Inverse Optimization</title>
      <link>https://arxiv.org/abs/2410.07933</link>
      <description>arXiv:2410.07933v1 Announce Type: cross 
Abstract: Hierarchical policies enable strong performance in many sequential decision-making problems, such as those with high-dimensional action spaces, those requiring long-horizon planning, and settings with sparse rewards. However, learning hierarchical policies from static offline datasets presents a significant challenge. Crucially, actions taken by higher-level policies may not be directly observable within hierarchical controllers, and the offline dataset might have been generated using a different policy structure, hindering the use of standard offline learning algorithms. In this work, we propose OHIO: a framework for offline reinforcement learning (RL) of hierarchical policies. Our framework leverages knowledge of the policy structure to solve the inverse problem, recovering the unobservable high-level actions that likely generated the observed data under our hierarchical policy. This approach constructs a dataset suitable for off-the-shelf offline training. We demonstrate our framework on robotic and network optimization problems and show that it substantially outperforms end-to-end RL methods and improves robustness. We investigate a variety of instantiations of our framework, both in direct deployment of policies trained offline and when online fine-tuning is performed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07933v1</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Carolin Schmidt, Daniele Gammelli, James Harrison, Marco Pavone, Filipe Rodrigues</dc:creator>
    </item>
    <item>
      <title>Eco-driving Incentive Mechanisms for Mitigating Emissions in Urban Transportation</title>
      <link>https://arxiv.org/abs/2410.07952</link>
      <description>arXiv:2410.07952v1 Announce Type: cross 
Abstract: This paper proposes incentive mechanisms that promote eco-driving in transportation networks with the over-arching objective of minimizing emissions. The transportation system operator provides the drivers with energy-efficient driving guidance throughout their trips, and their eco-driving levels are measured by how closely they follow this guidance via vehicle telematics. Drivers choose their eco-driving levels to optimize a combination of their travel times and their emissions. To obtain optimal budget allocation and recommendations for the incentive mechanism, the system operator gathers drivers' preferences, or types, to assess each driver's trip urgency and natural willingness to eco-drive. In a setting where drivers truthfully report their types, we introduce the first-best incentive mechanism and show that the obedience condition holds (i.e., drivers find it optimal to comply with the system operator's recommendations) when the recommended eco-driving profile constitutes a Nash equilibrium. Moreover, in a setting where drivers can strategically report their types, we introduce the second-best incentive mechanism and show that the proposed mechanism is incentive-compatible (i.e., drivers find it optimal to be truthful). Under this mechanism, we also show that all equilibrium outcomes are at least as good as the recommended eco-driving profile in terms of the system operator's objective. Overall, this work offers a framework for designing eco-driving incentive mechanisms while considering both the strategic behavior of individual drivers and the network effects of collective decision-making.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07952v1</guid>
      <category>cs.GT</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>M. Umar B. Niazi, Jung-Hoon Cho, Munther A. Dahleh, Roy Dong, Cathy Wu</dc:creator>
    </item>
    <item>
      <title>On the Convergence of (Stochastic) Gradient Descent for Kolmogorov--Arnold Networks</title>
      <link>https://arxiv.org/abs/2410.08041</link>
      <description>arXiv:2410.08041v1 Announce Type: cross 
Abstract: Kolmogorov--Arnold Networks (KANs), a recently proposed neural network architecture, have gained significant attention in the deep learning community, due to their potential as a viable alternative to multi-layer perceptrons (MLPs) and their broad applicability to various scientific tasks. Empirical investigations demonstrate that KANs optimized via stochastic gradient descent (SGD) are capable of achieving near-zero training loss in various machine learning (e.g., regression, classification, and time series forecasting, etc.) and scientific tasks (e.g., solving partial differential equations). In this paper, we provide a theoretical explanation for the empirical success by conducting a rigorous convergence analysis of gradient descent (GD) and SGD for two-layer KANs in solving both regression and physics-informed tasks. For regression problems, we establish using the neural tangent kernel perspective that GD achieves global linear convergence of the objective function when the hidden dimension of KANs is sufficiently large. We further extend these results to SGD, demonstrating a similar global convergence in expectation. Additionally, we analyze the global convergence of GD and SGD for physics-informed KANs, which unveils additional challenges due to the more complex loss structure. This is the first work establishing the global convergence guarantees for GD and SGD applied to optimize KANs and physics-informed KANs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08041v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yihang Gao, Vincent Y. F. Tan</dc:creator>
    </item>
    <item>
      <title>Gaussian Process Thompson Sampling via Rootfinding</title>
      <link>https://arxiv.org/abs/2410.08071</link>
      <description>arXiv:2410.08071v1 Announce Type: cross 
Abstract: Thompson sampling (TS) is a simple, effective stochastic policy in Bayesian decision making. It samples the posterior belief about the reward profile and optimizes the sample to obtain a candidate decision. In continuous optimization, the posterior of the objective function is often a Gaussian process (GP), whose sample paths have numerous local optima, making their global optimization challenging. In this work, we introduce an efficient global optimization strategy for GP-TS that carefully selects starting points for gradient-based multi-start optimizers. It identifies all local optima of the prior sample via univariate global rootfinding, and optimizes the posterior sample using a differentiable, decoupled representation. We demonstrate remarkable improvement in the global optimization of GP posterior samples, especially in high dimensions. This leads to dramatic improvements in the overall performance of Bayesian optimization using GP-TS acquisition functions, surprisingly outperforming alternatives like GP-UCB and EI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08071v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Taiwo A. Adebiyi, Bach Do, Ruda Zhang</dc:creator>
    </item>
    <item>
      <title>Special Orthogonal Group SO(3), Euler Angles, Angle-axis, Rodriguez Vector and Unit-Quaternion: Overview, Mapping and Challenges</title>
      <link>https://arxiv.org/abs/1909.06669</link>
      <description>arXiv:1909.06669v5 Announce Type: replace 
Abstract: The attitude of a rigid-body in the three dimensional space has a unique and global definition on the Special Orthogonal Group SO (3). This paper gives an overview of the rotation matrix, attitude kinematics and parameterization. The four most frequently used methods of attitude representations are discussed with detailed derivations, namely Euler angles, angle-axis parameterization, Rodriguez vector, and unit-quaternion. The mapping from one representation to others including SO (3) is given. Also, important results which could be useful for the process of filter and/or control design are given. The main weaknesses of attitude parameterization using Euler angles, angle-axis parameterization, Rodriguez vector, and unit-quaternion are illustrated. Keywords: Special Orthogonal Group 3, Euler angles, Angle-axis, Rodriguez Vector, Unit-quaternion, SO(3), Mapping, Parameterization, Attitude, Control, Filter, Observer, Estimator, Rotation, Rotational matrix, Transformation matrix, Orientation, Transformation, Roll, Pitch, Yaw, Quad-rotor, Unmanned aerial vehicle, Robot, spacecraft, satellite, UAV, Underwater vehicle, autonomous, system, Pose, literature review, survey, overview, comparison, comparative study, body frame, identity, origin, dynamics, kinematics, Lie group, inertial frame, zero, filter, control, estimate, observation, measurement, 3D, three dimensional space, advantage, disadvantage.</description>
      <guid isPermaLink="false">oai:arXiv.org:1909.06669v5</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hashim A. Hashim</dc:creator>
    </item>
    <item>
      <title>Approximation Algorithm for Generalized Budgeted Assignment Problems and Applications in Transportation Systems</title>
      <link>https://arxiv.org/abs/2208.11832</link>
      <description>arXiv:2208.11832v4 Announce Type: replace 
Abstract: Motivated by a transit line planning problem in transportation systems, we investigate the following capacitated assignment problem under a budget constraint. Our model involves $L$ bins and $P$ items. Each bin $l$ has a utilization cost $c_l$ and an $n_l$-dimensional capacity vector. Each item $p$ has an $n_l$-dimensional binary weight vector $r_{lp}$, where the $1$s in $r_{lp}$ (if any) appear in consecutive positions, and its assignment to bin $l$ yields a reward $v_{lp}$. The objective is to maximize total rewards through an assignment that satisfies three constraints: (i) the total weights of assigned items do not violate any bin's capacity; (ii) each item is assigned to at most one open bin; and (iii) the overall utilization costs remain within a total budget $B$.
  We propose the first randomized rounding algorithm with a constant approximation ratio for this problem. We then apply our framework to the motivating transit line planning problem, presenting corresponding models and conducting numerical experiments using real-world data. Our results demonstrate significant improvements over previous approaches in addressing this critical transportation challenge.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.11832v4</guid>
      <category>math.OC</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongyi Jiang, Samitha Samaranayake</dc:creator>
    </item>
    <item>
      <title>Variance Reduced Distributed Non-Convex Optimization Using Matrix Stepsizes</title>
      <link>https://arxiv.org/abs/2310.04614</link>
      <description>arXiv:2310.04614v3 Announce Type: replace 
Abstract: Matrix-stepsized gradient descent algorithms have been shown to have superior performance in non-convex optimization problems compared to their scalar counterparts. The det-CGD algorithm, as introduced by Li et al. (2023), leverages matrix stepsizes to perform compressed gradient descent for non-convex objectives and matrix-smooth problems in a federated manner. The authors establish the algorithm's convergence to a neighborhood of a weighted stationarity point under a convex condition for the symmetric and positive-definite matrix stepsize. In this paper, we propose two variance-reduced versions of the det-CGD algorithm, incorporating MARINA and DASHA methods. Notably, we establish theoretically and empirically, that det-MARINA and det-DASHA outperform MARINA, DASHA and the distributed det-CGD algorithms in terms of iteration and communication complexities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.04614v3</guid>
      <category>math.OC</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hanmin Li, Avetik Karagulyan, Peter Richt\'arik</dc:creator>
    </item>
    <item>
      <title>Distributed Optimization of Clique-Wise Coupled Problems via Three-Operator Splitting</title>
      <link>https://arxiv.org/abs/2310.18625</link>
      <description>arXiv:2310.18625v2 Announce Type: replace 
Abstract: This study explores distributed optimization problems with clique-wise coupling via operator splitting and how we can utilize this framework for performance analysis and enhancement. This framework extends beyond conventional pairwise coupled problems (e.g., consensus optimization) and is applicable to broader examples. To this end, we first introduce a new distributed optimization algorithm by leveraging a clique-based matrix and the Davis-Yin splitting (DYS), a versatile three-operator splitting method. We then demonstrate that this approach sheds new light on conventional algorithms in the following way: (i) Existing algorithms (NIDS, Exact diffusion, diffusion, and our previous work) can be derived from our proposed method; (ii) We present a new mixing matrix based on clique-wise coupling, which surfaces when deriving the NIDS. We prove its preferable distribution of eigenvalues, enabling fast consensus; (iii) These observations yield a new linear convergence rate for the NIDS with non-smooth objective functions. Remarkably our linear rate is first established for the general DYS with a projection for a subspace. This case is not covered by any prior results, to our knowledge. Finally, numerical examples showcase the efficacy of our proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.18625v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuto Watanabe, Kazunori Sakurama</dc:creator>
    </item>
    <item>
      <title>Approximation Theory, Computing, and Deep Learning on the Wasserstein Space</title>
      <link>https://arxiv.org/abs/2310.19548</link>
      <description>arXiv:2310.19548v4 Announce Type: replace 
Abstract: The challenge of approximating functions in infinite-dimensional spaces from finite samples is widely regarded as formidable. We delve into the challenging problem of the numerical approximation of Sobolev-smooth functions defined on probability spaces. Our particular focus centers on the Wasserstein distance function, which serves as a relevant example. In contrast to the existing body of literature focused on approximating efficiently pointwise evaluations, we chart a new course to define functional approximants by adopting three machine learning-based approaches: 1. Solving a finite number of optimal transport problems and computing the corresponding Wasserstein potentials. 2. Employing empirical risk minimization with Tikhonov regularization in Wasserstein Sobolev spaces. 3. Addressing the problem through the saddle point formulation that characterizes the weak form of the Tikhonov functional's Euler-Lagrange equation. We furnish explicit and quantitative bounds on generalization errors for each of these solutions. We leverage the theory of metric Sobolev spaces and we combine it with techniques of optimal transport, variational calculus, and large deviation bounds. In our numerical implementation, we harness appropriately designed neural networks to serve as basis functions. These networks undergo training using diverse methodologies. This approach allows us to obtain approximating functions that can be rapidly evaluated after training. Our constructive solutions significantly enhance at equal accuracy the evaluation speed, surpassing that of state-of-the-art methods by several orders of magnitude. This allows evaluations over large datasets several times faster, including training, than traditional optimal transport algorithms. Our analytically designed deep learning architecture slightly outperforms the test error of state-of-the-art CNN architectures on datasets of images.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.19548v4</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>math.FA</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Massimo Fornasier, Pascal Heid, Giacomo Enrico Sodini</dc:creator>
    </item>
    <item>
      <title>Splitting the Conditional Gradient Algorithm</title>
      <link>https://arxiv.org/abs/2311.05381</link>
      <description>arXiv:2311.05381v4 Announce Type: replace 
Abstract: We propose a novel generalization of the conditional gradient (CG / Frank-Wolfe) algorithm for minimizing a smooth function $f$ under an intersection of compact convex sets, using a first-order oracle for $\nabla f$ and linear minimization oracles (LMOs) for the individual sets. Although this computational framework presents many advantages, there are only a small number of algorithms which require one LMO evaluation per set per iteration; furthermore, these algorithms require $f$ to be convex. Our algorithm appears to be the first in this class which is proven to also converge in the nonconvex setting. Our approach combines a penalty method and a product-space relaxation. We show that one conditional gradient step is a sufficient subroutine for our penalty method to converge, and we provide several analytical results on the product-space relaxation's properties and connections to other problems in optimization. We prove that our average Frank-Wolfe gap converges at a rate of $\mathcal{O}(\ln t/\sqrt{t})$, -- only a log factor worse than the vanilla CG algorithm with one set.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.05381v4</guid>
      <category>math.OC</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zev Woodstock, Sebastian Pokutta</dc:creator>
    </item>
    <item>
      <title>Stochastic Extragradient with Random Reshuffling: Improved Convergence for Variational Inequalities</title>
      <link>https://arxiv.org/abs/2403.07148</link>
      <description>arXiv:2403.07148v2 Announce Type: replace 
Abstract: The Stochastic Extragradient (SEG) method is one of the most popular algorithms for solving finite-sum min-max optimization and variational inequality problems (VIPs) appearing in various machine learning tasks. However, existing convergence analyses of SEG focus on its with-replacement variants, while practical implementations of the method randomly reshuffle components and sequentially use them. Unlike the well-studied with-replacement variants, SEG with Random Reshuffling (SEG-RR) lacks established theoretical guarantees. In this work, we provide a convergence analysis of SEG-RR for three classes of VIPs: (i) strongly monotone, (ii) affine, and (iii) monotone. We derive conditions under which SEG-RR achieves a faster convergence rate than the uniform with-replacement sampling SEG. In the monotone setting, our analysis of SEG-RR guarantees convergence to an arbitrary accuracy without large batch sizes, a strong requirement needed in the classical with-replacement SEG. As a byproduct of our results, we provide convergence guarantees for Shuffle Once SEG (shuffles the data only at the beginning of the algorithm) and the Incremental Extragradient (does not shuffle the data). We supplement our analysis with experiments validating empirically the superior performance of SEG-RR over the classical with-replacement sampling SEG.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07148v2</guid>
      <category>math.OC</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Konstantinos Emmanouilidis, Ren\'e Vidal, Nicolas Loizou</dc:creator>
    </item>
    <item>
      <title>CFD-based Shape Optimization of Structured Packings for Enhancing Separation Efficiency in Distillation</title>
      <link>https://arxiv.org/abs/2407.11099</link>
      <description>arXiv:2407.11099v2 Announce Type: replace 
Abstract: Free-form shape optimization techniques are investigated to improve the separation efficiency of structured packings in laboratory-scale distillation columns. A simplified simulation model based on computational fluid dynamics (CFD) for the mass transfer in the distillation column is used and a corresponding shape optimization problem is formulated. The goal of the optimization is to increase the mass transfer in the column by changing the packing's shape, which has been previously used as criterion for increasing the separation efficiency of the column. The computational shape optimization yields promising results, with an increased mass transfer of nearly 20 %. For validation, the resulting optimized shape is additively manufactured using 3D-printing and investigated experimentally. The experimental results are in good agreement with the performance improvement predicted by the computational model, yielding an increase in separation efficiency of around 20 %.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.11099v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.ces.2024.120803</arxiv:DOI>
      <dc:creator>Sebastian Blauth, Dennis Stucke, Mohamed Adel Ashour, Johannes Schnebele, Thomas Gr\"utzner, Christian Leith\"auser</dc:creator>
    </item>
    <item>
      <title>A Course in Dynamic Optimization</title>
      <link>https://arxiv.org/abs/2408.03034</link>
      <description>arXiv:2408.03034v2 Announce Type: replace 
Abstract: These lecture notes are derived from a graduate-level course in dynamic optimization, offering an introduction to techniques and models extensively used in management science, economics, operations research, engineering, and computer science. The course emphasizes the theoretical underpinnings of discrete-time dynamic programming models and advanced algorithmic strategies for solving these models. Unlike typical treatments, it provides a proof for the principle of optimality for upper semi-continuous dynamic programming, a middle ground between the simpler countable state space case \cite{bertsekas2012dynamic}, and the involved universally measurable case \cite{bertsekas1996stochastic}. This approach is sufficiently rigorous to include important examples such as dynamic pricing, consumption-savings, and inventory management models. The course also delves into the properties of value and policy functions, leveraging classical results \cite{topkis1998supermodularity} and recent developments. Additionally, it offers an introduction to reinforcement learning, including a formal proof of the convergence of Q-learning algorithms. Furthermore, the notes delve into policy gradient methods for the average reward case, presenting a convergence result for the tabular case in this context. This result is simple and similar to the discounted case but appears to be new.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.03034v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>econ.TH</category>
      <category>eess.SY</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bar Light</dc:creator>
    </item>
    <item>
      <title>Beyond Price-Taker: Multiscale Optimization of Wind and Battery Integrated Energy Systems</title>
      <link>https://arxiv.org/abs/2409.08343</link>
      <description>arXiv:2409.08343v2 Announce Type: replace 
Abstract: Decarbonizing global energy systems requires extensive integration of renewable energy into the electric grid. However, the intermittency and variable nature of wind and other non-dispatchable renewable resources make integration a great challenge. Hybridizing renewables with energy storage to form integrated energy systems (IESs) helps mitigate these concerns by improving reliability and resiliency. This paper systematically studies the limitations of the prevailing price-taker assumption for techno-economic analysis (TEA) and optimization of hybrid energy systems. As an illustrative case study, we retrofit an existing wind farm in the RTS-GMLC test system (which loosely mimics the Southwest U.S.) with battery energy storage to form an IES. We show that the standard price-taker model overestimates the electricity revenue and the net present value (NPV) of the IES up to 178% and 50%, respectively, compared to our more rigorous multiscale optimization. These differences arise because introducing storage creates a more flexible resource that impacts the larger wholesale electricity market. Moreover, this work highlights the impact of the IES has on the market via various strategic bidding, and underscores the importance of moving beyond price-taker for optimal storage sizing and TEA of IESs. We conclude by discussing opportunities to generalize the proposed framework to other IESs, and highlight emerging research questions regarding the complex interactions between IESs and markets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08343v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xinhe Chen, Xian Gao, Darice Guittet, Radhakrishna Tumbalam-Gooty, Bernard Knueven, John D. Siirola, David C. Miller, Alexander W. Dowling</dc:creator>
    </item>
    <item>
      <title>Variance-reduced first-order methods for deterministically constrained stochastic nonconvex optimization with strong convergence guarantees</title>
      <link>https://arxiv.org/abs/2409.09906</link>
      <description>arXiv:2409.09906v3 Announce Type: replace 
Abstract: In this paper, we study a class of deterministically constrained stochastic optimization problems. Existing methods typically aim to find an $\epsilon$-stochastic stationary point, where the expected violations of both constraints and first-order stationarity are within a prescribed accuracy $\epsilon$. However, in many practical applications, it is crucial that the constraints be nearly satisfied with certainty, making such an $\epsilon$-stochastic stationary point potentially undesirable due to the risk of significant constraint violations. To address this issue, we propose single-loop variance-reduced stochastic first-order methods, where the stochastic gradient of the stochastic component is computed using either a truncated recursive momentum scheme or a truncated Polyak momentum scheme for variance reduction, while the gradient of the deterministic component is computed exactly. Under the error bound condition with a parameter $\theta \geq 1$ and other suitable assumptions, we establish that these methods respectively achieve a sample and first-order operation complexity of $\widetilde O(\epsilon^{-\max\{\theta+2, 2\theta\}})$ and $\widetilde O(\epsilon^{-\max\{4, 2\theta\}})$ for finding a stronger $\epsilon$-stochastic stationary point, where the constraint violation is within $\epsilon$ with certainty, and the expected violation of first-order stationarity is within $\epsilon$. For $\theta=1$, these complexities reduce to $\widetilde O(\epsilon^{-3})$ and $\widetilde O(\epsilon^{-4})$ respectively, which match, up to a logarithmic factor, the best-known complexities achieved by existing methods for finding an $\epsilon$-stochastic stationary point of unconstrained smooth stochastic optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.09906v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.ML</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhaosong Lu, Sanyou Mei, Yifeng Xiao</dc:creator>
    </item>
    <item>
      <title>Convex regularization and subdifferential calculus</title>
      <link>https://arxiv.org/abs/2410.01436</link>
      <description>arXiv:2410.01436v2 Announce Type: replace 
Abstract: This paper deals with the regularization of the sum of functions defined on a locally convex spaces through their closed-convex hulls in the bidual space. Different conditions guaranteeing that the closed-convex hull of the sum is the sum of the corresponding closed-convex hulls are provided. These conditions are expressed in terms of some epsilon-subdifferential calculus rules for the sum. The case of convex functions is also studied, and exact calculus rules are given under additional continuity/qualifications conditions. As an illustration, a variant of the proof of the classical Rockafellar theorem on convex integration is proposed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.01436v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rafael Correa, Abderrahim Hantoute, Marco A. L\'opez</dc:creator>
    </item>
    <item>
      <title>A Penalty-Based Method for Communication-Efficient Decentralized Bilevel Programming</title>
      <link>https://arxiv.org/abs/2211.04088</link>
      <description>arXiv:2211.04088v4 Announce Type: replace-cross 
Abstract: Bilevel programming has recently received attention in the literature due to its wide range of applications, including reinforcement learning and hyper-parameter optimization. However, it is widely assumed that the underlying bilevel optimization problem is solved either by a single machine or, in the case of multiple machines connected in a star-shaped network, i.e., in a federated learning setting. The latter approach suffers from a high communication cost on the central node (e.g., parameter server). Hence, there is an interest in developing methods that solve bilevel optimization problems in a communication-efficient, decentralized manner. To that end, this paper introduces a penalty function-based decentralized algorithm with theoretical guarantees for this class of optimization problems. Specifically, a distributed alternating gradient-type algorithm for solving consensus bilevel programming over a decentralized network is developed. A key feature of the proposed algorithm is the estimation of the hyper-gradient of the penalty function through decentralized computation of matrix-vector products and a few vector communications. The estimation is integrated into an alternating algorithm for solving the penalized reformulation of the bilevel optimization problem. Under appropriate step sizes and penalty parameters, our theoretical framework ensures non-asymptotic convergence to the optimal solution of the original problem under various convexity conditions. Our theoretical result highlights improvements in the iteration complexity of decentralized bilevel optimization, all while making efficient use of vector communication. Empirical results demonstrate that the proposed method performs well in real-world settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.04088v4</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>math.OC</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Parvin Nazari, Ahmad Mousavi, Davoud Ataee Tarzanagh, George Michailidis</dc:creator>
    </item>
    <item>
      <title>Convergence of Gradient Descent for Recurrent Neural Networks: A Nonasymptotic Analysis</title>
      <link>https://arxiv.org/abs/2402.12241</link>
      <description>arXiv:2402.12241v2 Announce Type: replace-cross 
Abstract: We analyze recurrent neural networks with diagonal hidden-to-hidden weight matrices, trained with gradient descent in the supervised learning setting, and prove that gradient descent can achieve optimality \emph{without} massive overparameterization. Our in-depth nonasymptotic analysis (i) provides improved bounds on the network size $m$ in terms of the sequence length $T$, sample size $n$ and ambient dimension $d$, and (ii) identifies the significant impact of long-term dependencies in the dynamical system on the convergence and network width bounds characterized by a cutoff point that depends on the Lipschitz continuity of the activation function. Remarkably, this analysis reveals that an appropriately-initialized recurrent neural network trained with $n$ samples can achieve optimality with a network size $m$ that scales only logarithmically with $n$. This sharply contrasts with the prior works that require high-order polynomial dependency of $m$ on $n$ to establish strong regularity conditions. Our results are based on an explicit characterization of the class of dynamical systems that can be approximated and learned by recurrent neural networks via norm-constrained transportation mappings, and establishing local smoothness properties of the hidden state with respect to the learnable parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.12241v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Semih Cayci, Atilla Eryilmaz</dc:creator>
    </item>
    <item>
      <title>MPC using mixed-integer programming for aquifer thermal energy storages</title>
      <link>https://arxiv.org/abs/2404.09786</link>
      <description>arXiv:2404.09786v2 Announce Type: replace-cross 
Abstract: Aquifer thermal energy storages (ATES) are used to temporally store thermal energy in groundwater saturated aquifers. Typically, two storages are combined, one for heat and one for cold, to support heating and cooling of buildings. This way, the use of classical fossil fuel-based heating, ventilation, and air conditioning can be significantly reduced. Exploiting the benefits of ATES beyond "seasonal" heating in winter and cooling in summer as well as meeting legislative restrictions requires sophisticated control. We propose a tailored model predictive control (MPC) scheme for the sustainable operation of ATES systems, which mainly builds on a novel model and objective function. The new approach leads to a mixed-integer quadratic program. Its performance is evaluated on real data from an ATES system in Belgium.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.09786v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.ifacol.2024.09.004</arxiv:DOI>
      <dc:creator>Johannes van Randenborgh, Moritz Schulze Darup</dc:creator>
    </item>
    <item>
      <title>On the shifts of orbits and periodic orbits under perturbation and the change of Poincar\'e map Jacobian of periodic orbits</title>
      <link>https://arxiv.org/abs/2407.08079</link>
      <description>arXiv:2407.08079v4 Announce Type: replace-cross 
Abstract: Periodic orbits and cycles, respectively, play a significant role in discrete- and continuous-time dynamical systems (i.e. maps and flows). To succinctly describe their shifts when the system is applied perturbation, the notions of functional and functional derivative are borrowed from functional analysis to consider the whole system as an argument of the geometric representation of the periodic orbit or cycle. The shifts of an orbit/trajectory and periodic orbit/cycle are analyzed and concluded as formulae for maps/flows, respectively. The theory shall be beneficial for analyzing sensitivity to perturbations, and optimizing and controlling various systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.08079v4</guid>
      <category>math.DS</category>
      <category>math.FA</category>
      <category>math.OC</category>
      <category>nlin.CD</category>
      <category>physics.plasm-ph</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenyin Wei, Alexander Knieps, Yunfeng Liang</dc:creator>
    </item>
    <item>
      <title>Differentiation Through Black-Box Quadratic Programming Solvers</title>
      <link>https://arxiv.org/abs/2410.06324</link>
      <description>arXiv:2410.06324v2 Announce Type: replace-cross 
Abstract: In recent years, many deep learning approaches have incorporated layers that solve optimization problems (e.g., linear, quadratic, and semidefinite programs). Integrating these optimization problems as differentiable layers requires computing the derivatives of the optimization problem's solution with respect to its objective and constraints. This has so far prevented the use of state-of-the-art black-box numerical solvers within neural networks, as they lack a differentiable interface. To address this issue for one of the most common convex optimization problems -- quadratic programming (QP) -- we introduce dQP, a modular framework that enables plug-and-play differentiation for any QP solver, allowing seamless integration into neural networks and bi-level optimization tasks. Our solution is based on the core theoretical insight that knowledge of the active constraint set at the QP optimum allows for explicit differentiation. This insight reveals a unique relationship between the computation of the solution and its derivative, enabling efficient differentiation of any solver, that only requires the primal solution. Our implementation, which will be made publicly available, interfaces with an existing framework that supports over 15 state-of-the-art QP solvers, providing each with a fully differentiable backbone for immediate use as a differentiable layer in learning setups. To demonstrate the scalability and effectiveness of dQP, we evaluate it on a large benchmark dataset of QPs with varying structures. We compare dQP with existing differentiable QP methods, demonstrating its advantages across a range of problems, from challenging small and dense problems to large-scale sparse ones, including a novel bi-level geometry optimization problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06324v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 11 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Connor W. Magoon, Fengyu Yang, Noam Aigerman, Shahar Z. Kovalsky</dc:creator>
    </item>
  </channel>
</rss>
