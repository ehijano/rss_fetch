<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.EM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.EM</link>
    <description>econ.EM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.EM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 06 Jun 2025 04:01:34 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Latent Variable Autoregression with Exogenous Inputs</title>
      <link>https://arxiv.org/abs/2506.04488</link>
      <description>arXiv:2506.04488v1 Announce Type: new 
Abstract: This paper introduces a new least squares regression methodology called (C)LARX: a (constrained) latent variable autoregressive model with exogenous inputs. Two additional contributions are made as a side effect: First, a new matrix operator is introduced for matrices and vectors with blocks along one dimension; Second, a new latent variable regression (LVR) framework is proposed for economics and finance. The empirical section examines how well the stock market predicts real economic activity in the United States. (C)LARX models outperform the baseline OLS specification in out-of-sample forecasts and offer novel analytical insights about the underlying functional relationship.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04488v1</guid>
      <category>econ.EM</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniil Bargman</dc:creator>
    </item>
    <item>
      <title>Power-boosting in Specification Tests using Kernel Directional Component</title>
      <link>https://arxiv.org/abs/2506.04900</link>
      <description>arXiv:2506.04900v1 Announce Type: new 
Abstract: We propose power-boosting strategies for kernel-based specification tests in conditional moment models, with a focus on the Kernel Conditional Moment (KCM) test. By decomposing the KCM statistic into spectral components, we demonstrate that truncating poorly estimated directions and selecting kernels based on a non-asymptotic signal-to-noise ratio significantly improves both test power and size control. Our theoretical and simulation results demonstrate that, while divergent component weights may offer higher asymptotic power, convergent component weights perform better in finite samples. The methods outperform existing tests across various settings and are illustrated in an empirical application.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04900v1</guid>
      <category>econ.EM</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Cui Rui, Li Yuhao, Song Xiaojun</dc:creator>
    </item>
    <item>
      <title>Enhancing the Merger Simulation Toolkit with ML/AI</title>
      <link>https://arxiv.org/abs/2506.05225</link>
      <description>arXiv:2506.05225v1 Announce Type: new 
Abstract: This paper develops a flexible approach to predict the price effects of horizontal mergers using ML/AI methods. While standard merger simulation techniques rely on restrictive assumptions about firm conduct, we propose a data-driven framework that relaxes these constraints when rich market data are available. We develop and identify a flexible nonparametric model of supply that nests a broad range of conduct models and cost functions. To overcome the curse of dimensionality, we adapt the Variational Method of Moments (VMM) (Bennett and Kallus, 2023) to estimate the model, allowing for various forms of strategic interaction. Monte Carlo simulations show that our method significantly outperforms an array of misspecified models and rivals the performance of the true model, both in predictive performance and counterfactual merger simulations. As a way to interpret the economics of the estimated function, we simulate pass-through and reveal that the model learns markup and cost functions that imply approximately correct pass-through behavior. Applied to the American Airlines-US Airways merger, our method produces more accurate post-merger price predictions than traditional approaches. The results demonstrate the potential for machine learning techniques to enhance merger analysis while maintaining economic structure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.05225v1</guid>
      <category>econ.EM</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Harold D. Chiang, Jack Collison, Lorenzo Magnolfi, Christopher Sullivan</dc:creator>
    </item>
    <item>
      <title>The Spurious Factor Dilemma: Robust Inference in Heavy-Tailed Elliptical Factor Models</title>
      <link>https://arxiv.org/abs/2506.05116</link>
      <description>arXiv:2506.05116v1 Announce Type: cross 
Abstract: Factor models are essential tools for analyzing high-dimensional data, particularly in economics and finance. However, standard methods for determining the number of factors often overestimate the true number when data exhibit heavy-tailed randomness, misinterpreting noise-induced outliers as genuine factors. This paper addresses this challenge within the framework of Elliptical Factor Models (EFM), which accommodate both heavy tails and potential non-linear dependencies common in real-world data. We demonstrate theoretically and empirically that heavy-tailed noise generates spurious eigenvalues that mimic true factor signals. To distinguish these, we propose a novel methodology based on a fluctuation magnification algorithm. We show that under magnifying perturbations, the eigenvalues associated with real factors exhibit significantly less fluctuation (stabilizing asymptotically) compared to spurious eigenvalues arising from heavy-tailed effects. This differential behavior allows the identification and detection of the true and spurious factors. We develop a formal testing procedure based on this principle and apply it to the problem of accurately selecting the number of common factors in heavy-tailed EFMs. Simulation studies and real data analysis confirm the effectiveness of our approach compared to existing methods, particularly in scenarios with pronounced heavy-tailedness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.05116v1</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiang Hu, Jiahui Xie, Yangchun Zhang, Wang Zhou</dc:creator>
    </item>
    <item>
      <title>Admissibility of Completely Randomized Trials: A Large-Deviation Approach</title>
      <link>https://arxiv.org/abs/2506.05329</link>
      <description>arXiv:2506.05329v1 Announce Type: cross 
Abstract: When an experimenter has the option of running an adaptive trial, is it admissible to ignore this option and run a non-adaptive trial instead? We provide a negative answer to this question in the best-arm identification problem, where the experimenter aims to allocate measurement efforts judiciously to confidently deploy the most effective treatment arm. We find that, whenever there are at least three treatment arms, there exist simple adaptive designs that universally and strictly dominate non-adaptive completely randomized trials. This dominance is characterized by a notion called efficiency exponent, which quantifies a design's statistical efficiency when the experimental sample is large. Our analysis focuses on the class of batched arm elimination designs, which progressively eliminate underperforming arms at pre-specified batch intervals. We characterize simple sufficient conditions under which these designs universally and strictly dominate completely randomized trials. These results resolve the second open problem posed in Qin [2022].</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.05329v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>econ.EM</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guido Imbens, Chao Qin, Stefan Wager</dc:creator>
    </item>
    <item>
      <title>Mining Causality: AI-Assisted Search for Instrumental Variables</title>
      <link>https://arxiv.org/abs/2409.14202</link>
      <description>arXiv:2409.14202v3 Announce Type: replace 
Abstract: The instrumental variables (IVs) method is a leading empirical strategy for causal inference. Finding IVs is a heuristic and creative process, and justifying its validity -- especially exclusion restrictions -- is largely rhetorical. We propose using large language models (LLMs) to search for new IVs through narratives and counterfactual reasoning, similar to how a human researcher would. The stark difference, however, is that LLMs can dramatically accelerate this process and explore an extremely large search space. We demonstrate how to construct prompts to search for potentially valid IVs. We contend that multi-step and role-playing prompting strategies are effective for simulating the endogenous decision-making processes of economic agents and for navigating language models through the realm of real-world scenarios, rather than anchoring them within the narrow realm of academic discourses on IVs. We apply our method to three well-known examples in economics: returns to schooling, supply and demand, and peer effects. We then extend our strategy to finding (i) control variables in regression and difference-in-differences and (ii) running variables in regression discontinuity designs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.14202v3</guid>
      <category>econ.EM</category>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sukjin Han</dc:creator>
    </item>
    <item>
      <title>Estimating Sequential Search Models Based on a Partial Ranking Representation</title>
      <link>https://arxiv.org/abs/2501.07514</link>
      <description>arXiv:2501.07514v3 Announce Type: replace 
Abstract: The rapid growth of online shopping has made consumer search data increasingly available, opening up new possibilities for empirical research. Sequential search models offer a structured approach for analyzing such data, but their estimation remains difficult. This is because consumers make optimal decisions based on private information revealed in search, which is not observed in typical data. As a result, the model's likelihood function involves high-dimensional integrals that require intensive simulation. This paper introduces a new representation that shows a consumer's optimal search decision-making can be recast as a partial ranking over all actions available throughout the consumer's search process. This reformulation yields the same choice probabilities as the original model but leads to a simpler likelihood function that relies less on simulation. Based on this insight, we provide identification arguments and propose a modified GHK-style simulator that improves both estimation performances and ease of implementation. The proposed approach also generalizes to a wide range of model variants, including those with incomplete search data and structural extensions such as search with product discovery. It enables a tractable and unified estimation strategy across different settings in sequential search models, offering both a new perspective on understanding sequential search and a practical tool for its application.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.07514v3</guid>
      <category>econ.EM</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Tinghan Zhang</dc:creator>
    </item>
    <item>
      <title>The continuous-time limit of quasi score-driven volatility models</title>
      <link>https://arxiv.org/abs/2409.14734</link>
      <description>arXiv:2409.14734v2 Announce Type: replace-cross 
Abstract: This paper explores the continuous-time limit of a class of Quasi Score-Driven (QSD) models that characterize volatility. As the sampling frequency increases and the time interval tends to zero, the model weakly converges to a continuous-time stochastic volatility model where the two Brownian motions are correlated, thereby capturing the leverage effect in the market. Subsequently, we identify that a necessary condition for non-degenerate correlation is that the distribution of driving innovations differs from that of computing score, and at least one being asymmetric. We then illustrate this with two typical examples. As an application, the QSD model is used as an approximation for correlated stochastic volatility diffusions and quasi maximum likelihood estimation is performed. Simulation results confirm the method's effectiveness, particularly in estimating the correlation coefficient.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.14734v2</guid>
      <category>math.PR</category>
      <category>econ.EM</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1111/jtsa.12848</arxiv:DOI>
      <dc:creator>Yinhao Wu, Ping He</dc:creator>
    </item>
  </channel>
</rss>
