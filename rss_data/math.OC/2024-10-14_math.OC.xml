<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 15 Oct 2024 03:30:53 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Bounding the Estimation Error Covariance for Nonlinear Systems</title>
      <link>https://arxiv.org/abs/2410.08298</link>
      <description>arXiv:2410.08298v1 Announce Type: new 
Abstract: This paper presents preliminary work on computing upper bounds on the estimation error covariance in the framework of the extended Kalman filter. The approach taken is using quadratic constraints to bound the dynamic nonlinearities and use of semidefinite programs to find the upper bound of each entry of the estimation error covariance matrix.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08298v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sze Kwan Cheah, Yingjie Hu</dc:creator>
    </item>
    <item>
      <title>Fej\'er* monotonicity in optimization algorithms</title>
      <link>https://arxiv.org/abs/2410.08331</link>
      <description>arXiv:2410.08331v1 Announce Type: new 
Abstract: Fej\'er monotonicity is a well-established property commonly observed in sequences generated by optimization algorithms. In this paper, we introduce an extension of this property, called Fej\'er* monotonicity, which was initially proposed in [SIAM J. Optim., 34(3), 2535-2556 (2024)]. We discuss and build upon the concept by exploring its behavior within Hilbert spaces, presenting an illustrative example and insightful results regarding weak and strong convergence. We also compare Fej\'er* monotonicity with other weak notions of Fej\'er-like monotonicity, to better establish the role of Fej\'er* monotonicity in optimization algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08331v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Roger Behling, Yunier Bello-Cruz, Alfredo Noel Iusem, Ademir Alves Ribeiro, Luiz-Rafael Santos</dc:creator>
    </item>
    <item>
      <title>Numerical approximations of the value of zero-sum stochastic differential impulse controls game in finite horizon</title>
      <link>https://arxiv.org/abs/2410.08354</link>
      <description>arXiv:2410.08354v1 Announce Type: new 
Abstract: In this paper, we consider a differential stochastic zero-sum game in which two players intervene by adopting impulse controls in a finite time horizon. We provide a numerical solution as an approximation of the value function, which turns out to be the same for both players. While one seeks to maximize the value function, the other seeks to minimize it. Thus we find a single numerical solution for the Nash equilibrium as well as the optimal impulse controls strategy pair for both player based on the classical Policy Iteration (PI) algorithm. Then, we perform a rigorous convergence analysis on the approximation scheme where we prove that it converges to its corresponding viscosity solution as the discretization step approaches zero, and under certain conditions. We showcase our algorithm by implementing a two-player almost analytically solvable game in which the players act through impulse control and compete over the exchange rate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08354v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Antoine Zolome, Brahim El Asri</dc:creator>
    </item>
    <item>
      <title>Nesterov acceleration in benignly non-convex landscapes</title>
      <link>https://arxiv.org/abs/2410.08395</link>
      <description>arXiv:2410.08395v1 Announce Type: new 
Abstract: While momentum-based optimization algorithms are commonly used in the notoriously non-convex optimization problems of deep learning, their analysis has historically been restricted to the convex and strongly convex setting. In this article, we partially close this gap between theory and practice and demonstrate that virtually identical guarantees can be obtained in optimization problems with a `benign' non-convexity. We show that these weaker geometric assumptions are well justified in overparametrized deep learning, at least locally. Variations of this result are obtained for a continuous time model of Nesterov's accelerated gradient descent algorithm (NAG), the classical discrete time version of NAG, and versions of NAG with stochastic gradient estimates with purely additive noise and with noise that exhibits both additive and multiplicative scaling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08395v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kanan Gupta, Stephan Wojtowytsch</dc:creator>
    </item>
    <item>
      <title>Noise Removal in One-Dimensional Signals using Iterative Shrinkage Total Variation Algorithm</title>
      <link>https://arxiv.org/abs/2410.08404</link>
      <description>arXiv:2410.08404v1 Announce Type: new 
Abstract: The total variation filtering technique emerges as a highly effective strategy for restoring signals with discontinuities in various parts of their structure. This study presents and implements a one-dimensional signal filtering algorithm based on total variation. The aim is to demonstrate the effectiveness of this algorithm through a series of synthetic filtering tests. The results presented in this paper were significant in demonstrating the proposed algorithm's effectiveness. Through a series of rigorously conducted experiments, the algorithm's ability to solve complex noise removal problems in various scenarios was evidenced.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08404v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joyce Oliveira dos Santos, Francisco M\'arcio Barboza</dc:creator>
    </item>
    <item>
      <title>An Integer Programming Formulation for the Maximally Diverse Grouping Problem</title>
      <link>https://arxiv.org/abs/2410.08482</link>
      <description>arXiv:2410.08482v1 Announce Type: new 
Abstract: The Maximally Diverse Grouping Problem (MDGP) is the problem of assigning a set of elements to mutually disjoint groups in order to maximise the overall diversity between the elements. Because the MDGP is NP-complete, most studies have focused on heuristic solution approaches, as compared to exact solution approaches, to the problem. On the one hand, heuristic solution approaches, although common in practice, do not guarantee a global optimal solution. On the other hand, studies that have reformulated the problem as an integer linear programme, which can be solved using exact solution approaches, are either restricted to groups of equal size or restricted to the use of the Manhattan distance. The present paper presents a new integer linear programming formulation that is not subjected to either of these restrictions, and can therefore be used to establish useful benchmarks for the performance of heuristics in a broader range of applications moving forward.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08482v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kevin Fu Yuan Lam, Jiang Qian</dc:creator>
    </item>
    <item>
      <title>Controllability of Quasi-linear Parabolic Equations by Hierarchic Controls</title>
      <link>https://arxiv.org/abs/2410.08532</link>
      <description>arXiv:2410.08532v1 Announce Type: new 
Abstract: This paper is devoted to studying a multi-objective control problem for a class of multi-dimensional quasi-linear parabolic equations. The considered system is driven by a leader control and two follower controls. For each leader control, a pair of follower controls is searched for as a Nash quasi-equilibrium (or Nash equilibrium) of cost functionals, while the aim for a leader control is to solve a controllability problem. This hierarchic control problem may be transformed into controllability of a strongly coupled system of quasi-linear parabolic equations through one control. Regarding controllability for quasi-linear parabolic equations of second order, the existing results usually require coefficients in principal parts to be independent of gradient of solutions, or spacial dimension to be limited. In this paper, the coefficients in principal parts for the controlled quasi-linear system contain not only the state itself but also its gradient with general spacial dimension.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08532v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yanming Dong, Xu Liu, Xu Zhang</dc:creator>
    </item>
    <item>
      <title>Optimization of microalgae biosynthesis via controlled algal-bacterial symbiosis</title>
      <link>https://arxiv.org/abs/2410.08575</link>
      <description>arXiv:2410.08575v1 Announce Type: new 
Abstract: We investigate optimization of an algal-bacterial consortium, where an exogenous control input modulates bacterial resource allocation between growth and synthesis of a resource that is limiting for algal growth. Maximization of algal biomass synthesis is pursued in a continuous bioreactor, with dilution rate as an additional control variable. We formulate optimal control in the two variants of static and dynamic control problems, and address them by theoretical and numerical tools. We explore convexity of the static problem and uniqueness of its solution, and show that the dynamic problem displays a solution with bang-bang control actions and singular arcs that result in cyclic control actions. We finally discuss the relation among the two solutions and show the extent to which dynamic control can outperform static optimal solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08575v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>Conference on Decision and Control, IEEE CSS, Dec 2024, Milan, Italy</arxiv:journal_reference>
      <dc:creator>Rand Asswad (MICROCOSME), Walid Djema (BIOCORE), Olivier Bernard (BIOCORE), Jean-Luc Gouz\'e (UniCA, MACBES), Eugenio Cinquemani (MICROCOSME)</dc:creator>
    </item>
    <item>
      <title>Nonexistence of finite-dimensional estimation algebras on closed smooth manifolds</title>
      <link>https://arxiv.org/abs/2410.08689</link>
      <description>arXiv:2410.08689v1 Announce Type: new 
Abstract: Estimation algebras have been extensively studied in Euclidean space, where finite-dimensional estimation algebras form the foundation of the Kalman and Benes filters, and have contributed to the discovery of many other finite-dimensional filters. This work extends the theory of estimation algebras to filtering problems on Riemannian manifolds in continuous time. Our main result demonstrates that, with non-constant observation functions, the estimation algebra associated with the system on closed Riemannian manifolds is infinite-dimensional.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08689v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiayi Kang, Andrew Salmon, Stephen Shing-Toung Yau</dc:creator>
    </item>
    <item>
      <title>Strict Copositivity for a Class of 3rd Order Symmetric Tensors</title>
      <link>https://arxiv.org/abs/2410.08750</link>
      <description>arXiv:2410.08750v1 Announce Type: new 
Abstract: In this article, we mainly give the strictly copositive conditions of a special class of third order three dimensional symmetric tensors. More specifically, by means of the polynomial decomposition method, the analytic sufficient and necessary conditions are established for checking the strict copositivity of a 3rd order 3-dimensional symmetric tensor with its entries in $\{-1,0,1\}$. Several strict inequalities of cubic ternary homogeneous polynomials are presented by applying these conclusions. Some criteria which ensure the strict copositivity of a general 3rd order 3-dimensional tensor are obtained</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08750v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Min Li, Yisheng Song</dc:creator>
    </item>
    <item>
      <title>Convexoid: A Minimal Theory of Conjugate Convexity</title>
      <link>https://arxiv.org/abs/2410.08775</link>
      <description>arXiv:2410.08775v1 Announce Type: new 
Abstract: A key idea in convex optimization theory is to use well-structured affine functions to approximate general functions, leading to impactful developments in conjugate functions and convex duality theory. This raises the question: what are the minimal requirements to establish these results? This paper aims to address this inquiry through a carefully crafted system called the convexoid. We demonstrate that fundamental constructs, such as conjugate functions and subdifferentials, along with their relationships, can be derived within this minimal system. Building on this, we define the associated duality systems and develop conditions for weak and strong duality, generalizing the classic results of conjugate duality theory. Due to its simplicity, our framework supports various approximation schemes, including approximating general functions using symmetric-conic, bilinear, or piecewise constant functions, and representing general structures such as graphs, set systems, fuzzy sets, or toposes using special membership functions. The associated duality results for these systems also open new opportunities for establishing bounds on objective values and verifying structural properties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08775v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ningji Wei</dc:creator>
    </item>
    <item>
      <title>Deep Learning Algorithms for Mean Field Optimal Stopping in Finite Space and Discrete Time</title>
      <link>https://arxiv.org/abs/2410.08850</link>
      <description>arXiv:2410.08850v1 Announce Type: new 
Abstract: Optimal stopping is a fundamental problem in optimization that has found applications in risk management, finance, economics, and recently in the fields of computer science. We extend the standard framework to a multi-agent setting, named multi-agent optimal stopping (MAOS), where a group of agents cooperatively solves finite-space, discrete-time optimal stopping problems. Solving the finite-agent case is computationally prohibitive when the number of agents is very large, so this work studies the mean field optimal stopping (MFOS) problem, obtained as the number of agents approaches infinity. We prove that MFOS provides a good approximate solution to MAOS. We also prove a dynamic programming principle (DPP), based on the theory of mean field control. We then propose two deep learning methods: one simulates full trajectories to learn optimal decisions, whereas the other leverages DPP with backward induction; both methods train neural networks for the optimal stopping decisions. We demonstrate the effectiveness of these approaches through numerical experiments on 6 different problems in spatial dimension up to 300. To the best of our knowledge, this is the first work to study MFOS in finite space and discrete time, and to propose efficient and scalable computational methods for this type of problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08850v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lorenzo Magnino, Yuchen Zhu, Mathieu Lauri\`ere</dc:creator>
    </item>
    <item>
      <title>Domain decomposition for entropic unbalanced optimal transport</title>
      <link>https://arxiv.org/abs/2410.08859</link>
      <description>arXiv:2410.08859v1 Announce Type: new 
Abstract: Solving large scale entropic optimal transport problems with the Sinkhorn algorithm remains challenging, and domain decomposition has been shown to be an efficient strategy for problems on large grids. Unbalanced optimal transport is a versatile variant of the balanced transport problem and its entropic regularization can be solved with an adapted Sinkhorn algorithm. However, it is a priori unclear how to apply domain decomposition to unbalanced problems since the independence of the cell problems is lost. In this article we show how this difficulty can be overcome at a theoretical and practical level and demonstrate with experiments that domain decomposition is also viable and efficient on large unbalanced entropic transport problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08859v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ismael Medina, The Sang Nguyen, Bernhard Schmitzer</dc:creator>
    </item>
    <item>
      <title>Problem-Driven Scenario Reduction and Scenario Approximation for Robust Optimization</title>
      <link>https://arxiv.org/abs/2410.08863</link>
      <description>arXiv:2410.08863v1 Announce Type: new 
Abstract: In robust optimization, we would like to find a solution that is immunized against all scenarios that are modeled in an uncertainty set. Which scenarios to include in such a set is therefore of central importance for the tractability of the robust model and practical usefulness of the resulting solution. We consider problems with a discrete uncertainty set affecting only the objective function. Our aim is reduce the size of the uncertainty set, while staying as true as possible to the original robust problem, measured by an approximation guarantee. Previous reduction approaches ignored the structure of the set of feasible solutions in this process. We show how to achieve better uncertainty sets by taking into account what solutions are possible, providing a theoretical framework and models to this end. In computational experiments, we note that our new framework achieves better uncertainty sets than previous methods or a simple K-means approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08863v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jamie Fairbrother, Marc Goerigk, Mohammad Khosravi</dc:creator>
    </item>
    <item>
      <title>Relaxed Proximal Point Algorithm: Tight Complexity Bounds and Acceleration without Momentum</title>
      <link>https://arxiv.org/abs/2410.08890</link>
      <description>arXiv:2410.08890v1 Announce Type: new 
Abstract: In this paper, we focus on the relaxed proximal point algorithm (RPPA) for solving convex (possibly nonsmooth) optimization problems. We conduct a comprehensive study on three types of relaxation schedules: (i) constant schedule with relaxation parameter $\alpha_k\equiv \alpha \in (0, \sqrt{2}]$, (ii) the dynamic schedule put forward by Teboulle and Vaisbourd [TV23], and (iii) the silver stepsize schedule proposed by Altschuler and Parrilo [AP23b]. The latter two schedules were initially investigated for the gradient descent (GD) method and are extended to the RPPA in this paper. For type (i), we establish tight non-ergodic $O(1/N)$ convergence rate results measured by function value residual and subgradient norm, where $N$ denotes the iteration counter. For type (ii), we establish a convergence rate that is tight and approximately $\sqrt{2}$ times better than the constant schedule of type (i). For type (iii), aside from the original silver stepsize schedule put forward by Altschuler and Parrilo, we propose two new modified silver stepsize schedules, and for all the three silver stepsize schedules, $O(1/N^{1.2716})$ accelerated convergence rate results with respect to three different performance metrics are established. Furthermore, our research affirms the conjecture in [LG24][Conjecture 3.2] on GD method with the original silver stepsize schedule.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08890v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bofan Wang, Shiqian Ma, Junfeng Yang, Danqing Zhou</dc:creator>
    </item>
    <item>
      <title>Gradient-adjusted underdamped Langevin dynamics for sampling</title>
      <link>https://arxiv.org/abs/2410.08987</link>
      <description>arXiv:2410.08987v1 Announce Type: new 
Abstract: Sampling from a target distribution is a fundamental problem. Traditional Markov chain Monte Carlo (MCMC) algorithms, such as the unadjusted Langevin algorithm (ULA), derived from the overdamped Langevin dynamics, have been extensively studied. From an optimization perspective, the Kolmogorov forward equation of the overdamped Langevin dynamics can be treated as the gradient flow of the relative entropy in the space of probability densities embedded with Wassrstein-2 metrics. Several efforts have also been devoted to including momentum-based methods, such as underdamped Langevin dynamics for faster convergence of sampling algorithms. Recent advances in optimizations have demonstrated the effectiveness of primal-dual damping and Hessian-driven damping dynamics for achieving faster convergence in solving optimization problems. Motivated by these developments, we introduce a class of stochastic differential equations (SDEs) called gradient-adjusted underdamped Langevin dynamics (GAUL), which add stochastic perturbations in primal-dual damping dynamics and Hessian-driven damping dynamics from optimization. We prove that GAUL admits the correct stationary distribution, whose marginal is the target distribution. The proposed method outperforms overdamped and underdamped Langevin dynamics regarding convergence speed in the total variation distance for Gaussian target distributions. Moreover, using the Euler-Maruyama discretization, we show that the mixing time towards a biased target distribution only depends on the square root of the condition number of the target covariance matrix. Numerical experiments for non-Gaussian target distributions, such as Bayesian regression problems and Bayesian neural networks, further illustrate the advantages of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08987v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xinzhe Zuo, Stanley Osher, Wuchen Li</dc:creator>
    </item>
    <item>
      <title>Randomized Asymmetric Chain of LoRA: The First Meaningful Theoretical Framework for Low-Rank Adaptation</title>
      <link>https://arxiv.org/abs/2410.08305</link>
      <description>arXiv:2410.08305v1 Announce Type: cross 
Abstract: Fine-tuning has become a popular approach to adapting large foundational models to specific tasks. As the size of models and datasets grows, parameter-efficient fine-tuning techniques are increasingly important. One of the most widely used methods is Low-Rank Adaptation (LoRA), with adaptation update expressed as the product of two low-rank matrices. While LoRA was shown to possess strong performance in fine-tuning, it often under-performs when compared to full-parameter fine-tuning (FPFT). Although many variants of LoRA have been extensively studied empirically, their theoretical optimization analysis is heavily under-explored. The starting point of our work is a demonstration that LoRA and its two extensions, Asymmetric LoRA and Chain of LoRA, indeed encounter convergence issues. To address these issues, we propose Randomized Asymmetric Chain of LoRA (RAC-LoRA) -- a general optimization framework that rigorously analyzes the convergence rates of LoRA-based methods. Our approach inherits the empirical benefits of LoRA-style heuristics, but introduces several small but important algorithmic modifications which turn it into a provably convergent method. Our framework serves as a bridge between FPFT and low-rank adaptation. We provide provable guarantees of convergence to the same solution as FPFT, along with the rate of convergence. Additionally, we present a convergence analysis for smooth, non-convex loss functions, covering gradient descent, stochastic gradient descent, and federated learning settings. Our theoretical findings are supported by experimental results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08305v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Grigory Malinovsky, Umberto Michieli, Hasan Abed Al Kader Hammoud, Taha Ceritli, Hayder Elesedy, Mete Ozay, Peter Richt\'arik</dc:creator>
    </item>
    <item>
      <title>HyperDPO: Hypernetwork-based Multi-Objective Fine-Tuning Framework</title>
      <link>https://arxiv.org/abs/2410.08316</link>
      <description>arXiv:2410.08316v1 Announce Type: cross 
Abstract: In LLM alignment and many other ML applications, one often faces the Multi-Objective Fine-Tuning (MOFT) problem, i.e. fine-tuning an existing model with datasets labeled w.r.t. different objectives simultaneously. To address the challenge, we propose the HyperDPO framework, a hypernetwork-based approach that extends the Direct Preference Optimization (DPO) technique, originally developed for efficient LLM alignment with preference data, to accommodate the MOFT settings. By substituting the Bradley-Terry-Luce model in DPO with the Plackett-Luce model, our framework is capable of handling a wide range of MOFT tasks that involve listwise ranking datasets. Compared with previous approaches, HyperDPO enjoys an efficient one-shot training process for profiling the Pareto front of auxiliary objectives, and offers flexible post-training control over trade-offs. Additionally, we propose a novel Hyper Prompt Tuning design, that conveys continuous weight across objectives to transformer-based models without altering their architecture. We demonstrate the effectiveness and efficiency of the HyperDPO framework through its applications to various tasks, including Learning-to-Rank (LTR) and LLM alignment, highlighting its viability for large-scale ML deployments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08316v1</guid>
      <category>cs.LG</category>
      <category>cs.CL</category>
      <category>math.OC</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yinuo Ren, Tesi Xiao, Michael Shavlovsky, Lexing Ying, Holakou Rahmanian</dc:creator>
    </item>
    <item>
      <title>Safe and Dynamically-Feasible Motion Planning using Control Lyapunov and Barrier Functions</title>
      <link>https://arxiv.org/abs/2410.08364</link>
      <description>arXiv:2410.08364v1 Announce Type: cross 
Abstract: This paper considers the problem of designing motion planning algorithms for control-affine systems that generate collision-free paths from an initial to a final destination and can be executed using safe and dynamically-feasible controllers. We introduce the C-CLF-CBF-RRT algorithm, which produces paths with such properties and leverages rapidly exploring random trees (RRTs), control Lyapunov functions (CLFs) and control barrier functions (CBFs). We show that C-CLF-CBF-RRT is computationally efficient for a variety of different dynamics and obstacles, and establish its probabilistic completeness. We showcase the performance of C-CLF-CBF-RRT in different simulation and hardware experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08364v1</guid>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pol Mestres, Carlos Nieto-Granda, Jorge Cort\'es</dc:creator>
    </item>
    <item>
      <title>Logarithmic Regret for Unconstrained Submodular Maximization Stochastic Bandit</title>
      <link>https://arxiv.org/abs/2410.08578</link>
      <description>arXiv:2410.08578v1 Announce Type: cross 
Abstract: We address the online unconstrained submodular maximization problem (Online USM), in a setting with stochastic bandit feedback. In this framework, a decision-maker receives noisy rewards from a nonmonotone submodular function, taking values in a known bounded interval. This paper proposes Double-Greedy - Explore-then-Commit (DG-ETC), adapting the Double-Greedy approach from the offline and online full-information settings. DG-ETC satisfies a O(d log(dT)) problemdependent upper bound for the 1/2-approximate pseudo-regret, as well as a O(dT^{2/3}log(dT)^{1/3}) problem-free one at the same time, outperforming existing approaches. To that end, we introduce a notion of hardness for submodular functions, characterizing how difficult it is to maximize them with this type of strategy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08578v1</guid>
      <category>cs.LG</category>
      <category>math.CO</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Julien Zhou (Thoth, STATIFY), Pierre Gaillard (Thoth), Thibaud Rahier (STATIFY), Julyan Arbel (STATIFY)</dc:creator>
    </item>
    <item>
      <title>From gymnastics to virtual nonholonomic constraints: energy injection, dissipation, and regulation for the acrobot</title>
      <link>https://arxiv.org/abs/2410.08653</link>
      <description>arXiv:2410.08653v1 Announce Type: cross 
Abstract: In this article we study virtual nonholonomic constraints, which are relations between the generalized coordinates and momenta of a mechanical system that can be enforced via feedback control. We design a constraint which emulates gymnastics giant motion in an acrobot, and prove that this constraint can inject or dissipate energy based on the sign of a design parameter. The proposed constraint is tested both in simulation and experimentally on a real-world acrobot, demonstrating highly effective energy regulation properties and robustness to a variety of disturbances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08653v1</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TCST.2023.3294065</arxiv:DOI>
      <arxiv:journal_reference>IEEE Transactions on Control Systems Technology, 32: 47-60, 2024</arxiv:journal_reference>
      <dc:creator>Adan Moran-MacDonald, Manfredi Maggiore, Xingbo Wang</dc:creator>
    </item>
    <item>
      <title>A generic Branch-and-Cut algorithm for bi-objective binary linear programs</title>
      <link>https://arxiv.org/abs/2410.08722</link>
      <description>arXiv:2410.08722v1 Announce Type: cross 
Abstract: This paper presents the first generic bi-objective binary linear branch-and-cut algorithm. Studying the impact of valid inequalities in solution and objective spaces, two cutting frameworks are proposed. The multi-point separation problem is introduced together with a cutting algorithm to efficiently generate valid inequalities violating multiple points simultaneously. The other main idea is to invoke state-of-the-art integer linear programming solver's internal advanced techniques such as cut separators. Aggregation techniques are proposed to use these frameworks with a trade-off among efficient cut separations, tight lower and upper bound sets and advanced branching strategies. Experiments on various types of instances in the literature exhibit the promising efficiency of the algorithm that solves instances with up to 2800 binary variables in less than one hour of CPU time. Our algorithms are easy to extend for more than two objectives and integer variables.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08722v1</guid>
      <category>cs.DM</category>
      <category>math.OC</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pierre Fouilhoux, Lucas L\'etocart, Yue Zhang</dc:creator>
    </item>
    <item>
      <title>Unlocking FedNL: Self-Contained Compute-Optimized Implementation</title>
      <link>https://arxiv.org/abs/2410.08760</link>
      <description>arXiv:2410.08760v1 Announce Type: cross 
Abstract: Federated Learning (FL) is an emerging paradigm that enables intelligent agents to collaboratively train Machine Learning (ML) models in a distributed manner, eliminating the need for sharing their local data. The recent work (arXiv:2106.02969) introduces a family of Federated Newton Learn (FedNL) algorithms, marking a significant step towards applying second-order methods to FL and large-scale optimization. However, the reference FedNL prototype exhibits three serious practical drawbacks: (i) It requires 4.8 hours to launch a single experiment in a sever-grade workstation; (ii) The prototype only simulates multi-node setting; (iii) Prototype integration into resource-constrained applications is challenging. To bridge the gap between theory and practice, we present a self-contained implementation of FedNL, FedNL-LS, FedNL-PP for single-node and multi-node settings. Our work resolves the aforementioned issues and reduces the wall clock time by x1000. With this FedNL outperforms alternatives for training logistic regression in a single-node -- CVXPY (arXiv:1603.00943), and in a multi-node -- Apache Spark (arXiv:1505.06807), Ray/Scikit-Learn (arXiv:1712.05889). Finally, we propose two practical-orientated compressors for FedNL - adaptive TopLEK and cache-aware RandSeqK, which fulfill the theory of FedNL.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08760v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.MS</category>
      <category>cs.PF</category>
      <category>math.OC</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Konstantin Burlachenko, Peter Richt\'arik</dc:creator>
    </item>
    <item>
      <title>Rapid Grassmannian Averaging with Chebyshev Polynomials</title>
      <link>https://arxiv.org/abs/2410.08956</link>
      <description>arXiv:2410.08956v1 Announce Type: cross 
Abstract: We propose new algorithms to efficiently average a collection of points on a Grassmannian manifold in both the centralized and decentralized settings. Grassmannian points are used ubiquitously in machine learning, computer vision, and signal processing to represent data through (often low-dimensional) subspaces. While averaging these points is crucial to many tasks (especially in the decentralized setting), existing methods unfortunately remain computationally expensive due to the non-Euclidean geometry of the manifold. Our proposed algorithms, Rapid Grassmannian Averaging (RGrAv) and Decentralized Rapid Grassmannian Averaging (DRGrAv), overcome this challenge by leveraging the spectral structure of the problem to rapidly compute an average using only small matrix multiplications and QR factorizations. We provide a theoretical guarantee of optimality and present numerical experiments which demonstrate that our algorithms outperform state-of-the-art methods in providing high accuracy solutions in minimal time. Additional experiments showcase the versatility of our algorithms to tasks such as K-means clustering on video motion data, establishing RGrAv and DRGrAv as powerful tools for generic Grassmannian averaging.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08956v1</guid>
      <category>math.NA</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Brighton Ancelin, Alex Saad-Falcon, Kason Ancelin, Justin Romberg</dc:creator>
    </item>
    <item>
      <title>A Randomized Block-Coordinate Primal-Dual Method for Large-scale Stochastic Saddle Point Problems</title>
      <link>https://arxiv.org/abs/1907.03886</link>
      <description>arXiv:1907.03886v5 Announce Type: replace 
Abstract: We consider (stochastic) convex-concave saddle point (SP) problems with high-dimensional decision variables, arising in various machine learning problems. To contend with the challenges in computing full gradients, we employ a randomized block-coordinate primal-dual scheme in which randomly selected primal and dual blocks of variables are updated. We consider both deterministic and stochastic settings, where deterministic partial gradients and their randomly sampled estimates are used, respectively, at each iteration. We investigate the convergence of the proposed method under different blocking strategies and provide the corresponding complexity results. While the best-known complexity result for deterministic primal-dual methods using full gradients is $\mathcal O(\max\{M,N\}^2/\varepsilon)$ where $M$ and $N$ denote the number of primal and dual blocks, respectively, we show that our proposed randomized block-coordinate method can achieve an improved convergence rate of $\mathcal O(MN/\varepsilon)$. Moreover, for the stochastic setting where a mini-batch sample gradient is utilized, we show an optimal oracle complexity of $\tilde{\mathcal{O}}(M^2N^2/\varepsilon^2)$ through acceleration. Finally, almost sure convergence of the iterate sequence to a saddle point is established.</description>
      <guid isPermaLink="false">oai:arXiv.org:1907.03886v5</guid>
      <category>math.OC</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Erfan Yazdandoost Hamedani, Afrooz Jalilzadeh, Necdet Serhat Aybat</dc:creator>
    </item>
    <item>
      <title>Coordinate-Update Algorithms can Efficiently Detect Infeasible Optimization Problems</title>
      <link>https://arxiv.org/abs/2305.12211</link>
      <description>arXiv:2305.12211v3 Announce Type: replace 
Abstract: Coordinate update/descent algorithms are widely used in large-scale optimization due to their low per-iteration cost and scalability, but their behavior on infeasible or misspecified problems has not been much studied compared to the algorithms that use full updates. For coordinate-update methods to be as widely adopted to the extent so that they can be used as engines of general-purpose solvers, it is necessary to also understand their behavior under pathological problem instances. In this work, we show that the normalized iterates of randomized coordinate-update fixed-point iterations (RC-FPI) converge to the infimal displacement vector and use this result to design an efficient infeasibility detection method. We then extend the analysis to the setup where the coordinates are defined by non-orthonormal basis using the Friedrichs angle and then apply the machinery to decentralized optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.12211v3</guid>
      <category>math.OC</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.jmaa.2024.128925</arxiv:DOI>
      <dc:creator>Jinhee Paeng, Jisun Park, Ernest K. Ryu</dc:creator>
    </item>
    <item>
      <title>Stochastic Optimal Control Matching</title>
      <link>https://arxiv.org/abs/2312.02027</link>
      <description>arXiv:2312.02027v5 Announce Type: replace 
Abstract: Stochastic optimal control, which has the goal of driving the behavior of noisy systems, is broadly applicable in science, engineering and artificial intelligence. Our work introduces Stochastic Optimal Control Matching (SOCM), a novel Iterative Diffusion Optimization (IDO) technique for stochastic optimal control that stems from the same philosophy as the conditional score matching loss for diffusion models. That is, the control is learned via a least squares problem by trying to fit a matching vector field. The training loss, which is closely connected to the cross-entropy loss, is optimized with respect to both the control function and a family of reparameterization matrices which appear in the matching vector field. The optimization with respect to the reparameterization matrices aims at minimizing the variance of the matching vector field. Experimentally, our algorithm achieves lower error than all the existing IDO techniques for stochastic optimal control for three out of four control problems, in some cases by an order of magnitude. The key idea underlying SOCM is the path-wise reparameterization trick, a novel technique that may be of independent interest. Code at https://github.com/facebookresearch/SOC-matching</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.02027v5</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Carles Domingo-Enrich, Jiequn Han, Brandon Amos, Joan Bruna, Ricky T. Q. Chen</dc:creator>
    </item>
    <item>
      <title>Existence and Density Theorems of Henig Global Proper Efficient Points</title>
      <link>https://arxiv.org/abs/2401.10103</link>
      <description>arXiv:2401.10103v2 Announce Type: replace 
Abstract: In this work, we provide some novel results that establish both the existence of Henig global proper efficient points and their density in the efficient set for vector optimization problems in arbitrary normed spaces. Our results do not require the assumption of convexity, and in certain cases, can be applied to unbounded sets. However, it is important to note that a weak compactness condition on the set (or on a section of it) and a separation property between the order cone and its conical neighborhoods remains necessary. The weak compactness condition ensures that certain convergence properties hold. The separation property enables the interpolation of a family of Bishop-Phelps cones between the order cone and each of its conic neighborhoods. This interpolation, combined with the proper handling of two distinct types of conic neighborhoods, plays a crucial role in the proofs of our results, which include as a particular case other results that have already been established under more restrictive conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.10103v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fernando Garc\'ia-Casta\~no, Miguel \'Angel Melguizo-Padial</dc:creator>
    </item>
    <item>
      <title>Data-Driven Stable Neural Feedback Loop Design</title>
      <link>https://arxiv.org/abs/2405.02100</link>
      <description>arXiv:2405.02100v2 Announce Type: replace 
Abstract: This paper proposes a data-driven approach to design a feedforward Neural Network (NN) controller with a stability guarantee for plants with unknown dynamics. We first introduce data-driven representations of stability conditions for Neural Feedback Loops (NFLs) with linear plants, which can be formulated into a semidefinite program (SDP). Subsequently, this SDP constraint is integrated into the NN training process to ensure stability of the feedback loop. The whole NN controller design problem can be solved by an iterative algorithm. Finally, we illustrate the effectiveness of the proposed method compared to model-based methods via numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.02100v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Zuxun Xiong, Han Wang, Liqun Zhao, Antonis Papachristodoulou</dc:creator>
    </item>
    <item>
      <title>Convergence Analysis of Adaptive Gradient Methods under Refined Smoothness and Noise Assumptions</title>
      <link>https://arxiv.org/abs/2406.04592</link>
      <description>arXiv:2406.04592v2 Announce Type: replace 
Abstract: Adaptive gradient methods, such as AdaGrad, are among the most successful optimization algorithms for neural network training. While these methods are known to achieve better dimensional dependence than stochastic gradient descent (SGD) under favorable geometry for stochastic convex optimization, the theoretical justification for their success in stochastic non-convex optimization remains elusive. In fact, under standard assumptions of Lipschitz gradients and bounded noise variance, it is known that SGD is worst-case optimal (up to absolute constants) in terms of finding a near-stationary point with respect to the $\ell_2$-norm, making further improvements impossible. Motivated by this limitation, we introduce refined assumptions on the smoothness structure of the objective and the gradient noise variance, which better suit the coordinate-wise nature of adaptive gradient methods. Moreover, we adopt the $\ell_1$-norm of the gradient as the stationarity measure, as opposed to the standard $\ell_2$-norm, to align with the coordinate-wise analysis and obtain tighter convergence guarantees for AdaGrad. Under these new assumptions and the $\ell_1$-norm stationarity measure, we establish an upper bound on the convergence rate of AdaGrad and a corresponding lower bound for SGD. In particular, for certain configurations of problem parameters, we show that the iteration complexity of AdaGrad outperforms SGD by a factor of $d$. To the best of our knowledge, this is the first result to demonstrate a provable gain of adaptive gradient methods over SGD in a non-convex setting. We also present supporting lower bounds, including one specific to AdaGrad and one applicable to general deterministic first-order methods, showing that our upper bound for AdaGrad is tight and unimprovable up to a logarithmic factor under certain conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04592v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruichen Jiang, Devyani Maladkar, Aryan Mokhtari</dc:creator>
    </item>
    <item>
      <title>Global convergence of a modified BFGS-type method based on function information for nonconvex multiobjective optimization problems</title>
      <link>https://arxiv.org/abs/2408.00543</link>
      <description>arXiv:2408.00543v2 Announce Type: replace 
Abstract: In this paper, based on function information, we propose a modified BFGS-type method for nonconvex multiobjective optimization problems (MFQNMO). In the multiobjective quasi-Newton method (QNMO), each iteration involves separately approximating the Hessian matrix for each component objective function, which results in significant storage and computational burdens. MFQNMO employs a common BFGS-type matrix to approximate the Hessian matrix of all objective functions in each iteration. This matrix is updated using function information from the previous step. This approach strikes a balance between efficacy and computational cost. We confirm the convergence of the method without relying on convexity assumptions, under mild conditions, we establish a local superlinear convergence rate for MFQNMO. Furthermore, we validate its effectiveness through experiments on both nonconvex and convex test problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.00543v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yingxue Yang</dc:creator>
    </item>
    <item>
      <title>Data-Scarce Identification of Game Dynamics via Sum-of-Squares Optimization</title>
      <link>https://arxiv.org/abs/2307.06640</link>
      <description>arXiv:2307.06640v2 Announce Type: replace-cross 
Abstract: Understanding how players adjust their strategies in games, based on their experience, is a crucial tool for policymakers. It enables them to forecast the system's eventual behavior, exert control over the system, and evaluate counterfactual scenarios. The task becomes increasingly difficult when only a limited number of observations are available or difficult to acquire. In this work, we introduce the Side-Information Assisted Regression (SIAR) framework, designed to identify game dynamics in multiplayer normal-form games only using data from a short run of a single system trajectory. To enhance system recovery in the face of scarce data, we integrate side-information constraints into SIAR, which restrict the set of feasible solutions to those satisfying game-theoretic properties and common assumptions about strategic interactions. SIAR is solved using sum-of-squares (SOS) optimization, resulting in a hierarchy of approximations that provably converge to the true dynamics of the system. We showcase that the SIAR framework accurately predicts player behavior across a spectrum of normal-form games, widely-known families of game dynamics, and strong benchmarks, even if the unknown system is chaotic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.06640v2</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Iosif Sakos, Antonios Varvitsiotis, Georgios Piliouras</dc:creator>
    </item>
    <item>
      <title>Certified Multi-Fidelity Zeroth-Order Optimization</title>
      <link>https://arxiv.org/abs/2308.00978</link>
      <description>arXiv:2308.00978v2 Announce Type: replace-cross 
Abstract: We consider the problem of multi-fidelity zeroth-order optimization, where one can evaluate a function $f$ at various approximation levels (of varying costs), and the goal is to optimize $f$ with the cheapest evaluations possible. In this paper, we study certified algorithms, which are additionally required to output a data-driven upper bound on the optimization error. We first formalize the problem in terms of a min-max game between an algorithm and an evaluation environment. We then propose a certified variant of the MFDOO algorithm and derive a bound on its cost complexity for any Lipschitz function $f$. We also prove an $f$-dependent lower bound showing that this algorithm has a near-optimal cost complexity. As a direct example, we close the paper by addressing the special case of noisy (stochastic) evaluations, which corresponds to $\eps$-best arm identification in Lipschitz bandits with continuously many arms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.00978v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1137/23M1591086</arxiv:DOI>
      <arxiv:journal_reference>SIAM/ASA Journal on Uncertainty Quantification, 2024, 12 (4), pp.1135-1164</arxiv:journal_reference>
      <dc:creator>\'Etienne de Montbrun (TSE-R), S\'ebastien Gerchinovitz (IMT)</dc:creator>
    </item>
    <item>
      <title>Adaptive Reduced Basis Trust Region Methods for Parameter Identification Problems</title>
      <link>https://arxiv.org/abs/2309.07627</link>
      <description>arXiv:2309.07627v3 Announce Type: replace-cross 
Abstract: In this contribution, we are concerned with model order reduction in the context of iterative regularization methods for the solution of inverse problems arising from parameter identification in elliptic partial differential equations. Such methods typically require a large number of forward solutions, which makes the use of the reduced basis method attractive to reduce computational complexity. However, the considered inverse problems are typically ill-posed due to their infinite-dimensional parameter space. Moreover, the infinite-dimensional parameter space makes it impossible to build and certify classical reduced-order models efficiently in a so-called "offline phase". We thus propose a new algorithm that adaptively builds a reduced parameter space in the online phase. The enrichment of the reduced parameter space is naturally inherited from the Tikhonov regularization within an iteratively regularized Gau{\ss}-Newton method. Finally, the adaptive parameter space reduction is combined with a certified reduced basis state space reduction within an adaptive error-aware trust region framework. Numerical experiments are presented to show the efficiency of the combined parameter and state space reduction for inverse parameter identification problems with distributed reaction or diffusion coefficients.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.07627v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Kartmann, Tim Keil, Mario Ohlberger, Stefan Volkwein, Barbara Kaltenbacher</dc:creator>
    </item>
    <item>
      <title>On the $p$-torsional rigidity of combinatorial graphs</title>
      <link>https://arxiv.org/abs/2312.14131</link>
      <description>arXiv:2312.14131v3 Announce Type: replace-cross 
Abstract: We study the $p$-\emph{torsion function} and the corresponding $p$-\emph{torsional rigidity} associated with $p$-Laplacians and, more generally, $p$-Schr\"odinger operators, for $1&lt;p&lt;\infty$, on possibly infinite combinatorial graphs. We present sufficient criteria for the existence of a summable $p$-torsion function and we derive several upper and lower bounds for the $p$-torsional rigidity. Our methods are mostly based on novel surgery principles. As an application, we also find some new estimates on the bottom of the spectrum of the $p$-Laplacian with Dirichlet conditions, thus complementing some results recently obtained in: Jos\'e M. Maz\'on, Julian Toledo, Torsional rigidity in random walk spaces, in a more general setting. Finally, we prove a Kohler-Jobin inequality for combinatorial graphs (for $p=2$): to the best of our knowledge, graphs thus become the third ambient where a Kohler-Jobin inequality is known to hold.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.14131v3</guid>
      <category>math.SP</category>
      <category>math.CO</category>
      <category>math.OC</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Patrizio Bifulco, Delio Mugnolo</dc:creator>
    </item>
    <item>
      <title>Task-optimal data-driven surrogate models for eNMPC via differentiable simulation and optimization</title>
      <link>https://arxiv.org/abs/2403.14425</link>
      <description>arXiv:2403.14425v2 Announce Type: replace-cross 
Abstract: We present a method for end-to-end learning of Koopman surrogate models for optimal performance in a specific control task. In contrast to previous contributions that employ standard reinforcement learning (RL) algorithms, we use a training algorithm that exploits the potential differentiability of environments based on mechanistic simulation models to aid the policy optimization. We evaluate the performance of our method by comparing it to that of other controller type and training algorithm combinations on an existing economic nonlinear model predictive control (eNMPC) case study of a continuous stirred-tank reactor (CSTR) model. Compared to the benchmark methods, our method produces similar economic performance but causes considerably fewer and less severe constraint violations. Thus, for this case study, our method outperforms the others and offers a promising path toward more performant controllers that employ dynamic surrogate models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.14425v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel Mayfrank, Na Young Ahn, Alexander Mitsos, Manuel Dahmen</dc:creator>
    </item>
    <item>
      <title>Two-Stage Robust Planning Model for Park-Level Integrated Energy System Considering Uncertain Equipment Contingency</title>
      <link>https://arxiv.org/abs/2404.19415</link>
      <description>arXiv:2404.19415v2 Announce Type: replace-cross 
Abstract: To enhance the reliability of Integrated Energy Systems (IESs) and address the research gap in reliability-based planning methods, this paper proposes a two-stage robust planning model specifically for park-level IESs. The proposed planning model considers uncertainties like load demand fluctuations and equipment contingencies, and provides a reliable scheme of equipment selection and sizing for IES investors. Inspired by the unit commitment problem, we formulate an equipment contingency uncertainty set to accurately describe the potential equipment contingencies which happen and can be repaired within a day. Then, a modified nested column-and-constraint generation algorithm is applied to solve this two-stage robust planning model with integer recourse efficiently. In the case study, the role of energy storage system for IES reliability enhancement is analyzed in detail. Computational results demonstrate the advantage of the proposed model over other planning models in terms of improving reliability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.19415v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Zuxun Xiong, Xinwei Shen, Hongbin Sun</dc:creator>
    </item>
    <item>
      <title>Robust Clustering on High-Dimensional Data with Stochastic Quantization</title>
      <link>https://arxiv.org/abs/2409.02066</link>
      <description>arXiv:2409.02066v3 Announce Type: replace-cross 
Abstract: This paper addresses the limitations of conventional vector quantization algorithms, particularly K-Means and its variant K-Means++, and investigates the Stochastic Quantization (SQ) algorithm as a scalable alternative for high-dimensional unsupervised and semi-supervised learning tasks. Traditional clustering algorithms often suffer from inefficient memory utilization during computation, necessitating the loading of all data samples into memory, which becomes impractical for large-scale datasets. While variants such as Mini-Batch K-Means partially mitigate this issue by reducing memory usage, they lack robust theoretical convergence guarantees due to the non-convex nature of clustering problems. In contrast, the Stochastic Quantization algorithm provides strong theoretical convergence guarantees, making it a robust alternative for clustering tasks. We demonstrate the computational efficiency and rapid convergence of the algorithm on an image classification problem with partially labeled data, comparing model accuracy across various ratios of labeled to unlabeled data. To address the challenge of high dimensionality, we employ a Triplet Network to encode images into low-dimensional representations in a latent space, which serve as a basis for comparing the efficiency of both the Stochastic Quantization algorithm and traditional quantization algorithms. Furthermore, we enhance the algorithm's convergence speed by introducing modifications with an adaptive learning rate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02066v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Anton Kozyriev, Vladimir Norkin</dc:creator>
    </item>
    <item>
      <title>LibMOON: A Gradient-based MultiObjective OptimizatioN Library in PyTorch</title>
      <link>https://arxiv.org/abs/2409.02969</link>
      <description>arXiv:2409.02969v3 Announce Type: replace-cross 
Abstract: Multiobjective optimization problems (MOPs) are prevalent in machine learning, with applications in multi-task learning, learning under fairness or robustness constraints, etc. Instead of reducing multiple objective functions into a scalar objective, MOPs aim to optimize for the so-called Pareto optimality or Pareto set learning, which involves optimizing more than one objective function simultaneously, over models with thousands / millions of parameters. Existing benchmark libraries for MOPs mainly focus on evolutionary algorithms, most of which are zeroth-order / meta-heuristic methods that do not effectively utilize higher-order information from objectives and cannot scale to large-scale models with thousands / millions of parameters. In light of the above gap, this paper introduces LibMOON, the first multiobjective optimization library that supports state-of-the-art gradient-based methods, provides a fair benchmark, and is open-sourced for the community.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02969v3</guid>
      <category>cs.MS</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 14 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaoyuan Zhang, Liang Zhao, Yingying Yu, Xi Lin, Yifan Chen, Han Zhao, Qingfu Zhang</dc:creator>
    </item>
  </channel>
</rss>
