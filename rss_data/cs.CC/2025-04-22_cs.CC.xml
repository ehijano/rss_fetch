<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CC</link>
    <description>cs.CC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 23 Apr 2025 01:47:51 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>On the redundancy of short and heterogeneous sequences of belief revisions</title>
      <link>https://arxiv.org/abs/2504.13986</link>
      <description>arXiv:2504.13986v1 Announce Type: new 
Abstract: Forgetting a specific belief revision episode may not erase information because the other revisions may provide the same information or allow to deduce it. Whether it does was proved coNP-hard for sequence of two arbitrary lexicographic revision or arbitrarily long lexicographic Horn revision. A polynomial algorithm is presented for the case of two Horn revision. Heterogeneous sequences of revisions were proved to belong in Delta2. Their previously proved coNP-hardness is enhanced by a proof of NP-hardness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.13986v1</guid>
      <category>cs.CC</category>
      <category>cs.AI</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Paolo Liberatore</dc:creator>
    </item>
    <item>
      <title>Holant* Dichotomy on Domain Size 3: A Geometric Perspective</title>
      <link>https://arxiv.org/abs/2504.14074</link>
      <description>arXiv:2504.14074v1 Announce Type: new 
Abstract: Holant problems are a general framework to study the computational complexity of counting problems. It is a more expressive framework than counting constraint satisfaction problems (CSP) which are in turn more expressive than counting graph homomorphisms (GH). In this paper, we prove the first complexity dichotomy of $\mathrm{Holant}_3(\mathcal{F})$ where $\mathcal{F}$ is an arbitrary set of symmetric, real valued constraint functions on domain size $3$. We give an explicit tractability criterion and prove that, if $\mathcal{F}$ satisfies this criterion then $\mathrm{Holant}_3(\mathcal{F})$ is polynomial time computable, and otherwise it is \#P-hard, with no intermediate cases. We show that the geometry of the tensor decomposition of the constraint functions plays a central role in the formulation as well as the structural internal logic of the dichotomy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14074v1</guid>
      <category>cs.CC</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jin-Yi Cai, Jin Soo Ihm</dc:creator>
    </item>
    <item>
      <title>A Note on the Complexity of Defensive Domination</title>
      <link>https://arxiv.org/abs/2504.14390</link>
      <description>arXiv:2504.14390v1 Announce Type: new 
Abstract: In a graph G, a k-attack A is any set of at most k vertices and l-defense D is a set of at most l vertices. We say that defense D counters attack A if each a in A can be matched to a distinct defender d in D with a equal to d or a adjacent to d in G. In the defensive domination problem, we are interested in deciding, for a graph G and positive integers k and l given on input, if there exists an l-defense that counters every possible k-attack on G. Defensive domination is a natural resource allocation problem and can be used to model network robustness and security, disaster response strategies, and redundancy designs.
  The defensive domination problem is naturally in the complexity class $\Sigma^P_2$. The problem was known to be NP-hard in general, and polynomial-time algorithms were found for some restricted graph classes. In this note we prove that the defensive domination problem is $\Sigma^P_2$-complete. We also introduce a natural variant of the defensive domination problem in which the defense is allowed to be a multiset of vertices. This variant is also $\Sigma^P_2$-complete, but we show that it admits a polynomial-time algorithm in the class of interval graphs. A similar result was known for the original setting in the class of proper interval graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14390v1</guid>
      <category>cs.CC</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Steven Chaplick, Grzegorz Gutowski, Tomasz Krawczyk</dc:creator>
    </item>
    <item>
      <title>Rank Bounds and PIT for $\Sigma^3 \Pi \Sigma \Pi^d$ circuits via a non-linear Edelstein-Kelly theorem</title>
      <link>https://arxiv.org/abs/2504.14729</link>
      <description>arXiv:2504.14729v2 Announce Type: new 
Abstract: We prove a non-linear Edelstein-Kelly theorem for polynomials of constant degree, fully settling a stronger form of Conjecture 30 in Gupta (2014), and generalizing the main result of Peleg and Shpilka (STOC 2021) from quadratic polynomials to polynomials of any constant degree.
  As a consequence of our result, we obtain constant rank bounds for depth-4 circuits with top fanin 3 and constant bottom fanin (denoted $\Sigma^{3}\Pi\Sigma\Pi^{d}$ circuits) which compute the zero polynomial. This settles a stronger form of Conjecture 1 in Gupta (2014) when $k=3$, for any constant degree bound; additionally this also makes progress on Conjecture 28 in Beecken, Mittmann, and Saxena (Information \&amp; Computation, 2013). Our rank bounds, when combined with Theorem 2 in Beecken, Mittmann, and Saxena (Information \&amp; Computation, 2013) yield the first deterministic, polynomial time PIT algorithm for $\Sigma^{3}\Pi\Sigma\Pi^{d}$ circuits.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14729v2</guid>
      <category>cs.CC</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Abhibhav Garg, Rafael Oliveira, Akash Kumar Sengupta</dc:creator>
    </item>
    <item>
      <title>Deterministic Depth-4 PIT and Normalization</title>
      <link>https://arxiv.org/abs/2504.15143</link>
      <description>arXiv:2504.15143v1 Announce Type: new 
Abstract: In this paper, we initiate the study of deterministic PIT for $\Sigma^{[k]}\Pi\Sigma\Pi^{[\delta]}$ circuits over fields of any characteristic, where $k$ and $\delta$ are bounded. Our main result is a deterministic polynomial-time black-box PIT algorithm for $\Sigma^{[3]}\Pi\Sigma\Pi^{[\delta]}$ circuits, under the additional condition that one of the summands at the top $\Sigma$ gate is squarefree.
  Our techniques are purely algebro-geometric: they do not rely on Sylvester--Gallai-type theorems, and our PIT result holds over arbitrary fields.
  The core of our proof is based on the normalization of algebraic varieties. Specifically, we carry out the analysis in the integral closure of a coordinate ring, which enjoys better algebraic properties than the original ring.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.15143v1</guid>
      <category>cs.CC</category>
      <category>math.AG</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zeyu Guo, Siki Wang</dc:creator>
    </item>
    <item>
      <title>Maker-Maker games of rank 4 are PSPACE-complete</title>
      <link>https://arxiv.org/abs/2504.14256</link>
      <description>arXiv:2504.14256v1 Announce Type: cross 
Abstract: The Maker-Maker convention of positional games is played on a hypergraph whose edges are interpreted as winning sets. Two players take turns picking a previously unpicked vertex, aiming at being first to pick all the vertices of some edge. Optimal play can only lead to a first player win or a draw, and deciding between the two is known to be PSPACE-complete even for 6-uniform hypergraphs. We establish PSPACE-completeness for hypergraphs of rank 4. As an intermediary, we use the recently introduced achievement positional games, a more general convention in which each player has their own winning sets (blue and red). We show that deciding whether the blue player has a winning strategy as the first player is PSPACE-complete even with blue edges of size 2 or 3 and pairwise disjoint red edges of size 2. The result for hypergraphs of rank 4 in the Maker-Maker convention follows as a simple corollary.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14256v1</guid>
      <category>cs.DM</category>
      <category>cs.CC</category>
      <category>math.CO</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Florian Galliot, Jonas S\'enizergues</dc:creator>
    </item>
    <item>
      <title>Approximate all-pairs Hamming distances and 0-1 matrix multiplication</title>
      <link>https://arxiv.org/abs/2504.14723</link>
      <description>arXiv:2504.14723v1 Announce Type: cross 
Abstract: Arslan showed that computing all-pairs Hamming distances is easily
  reducible to arithmetic 0-1 matrix multiplication (IPL 2018). We
  provide a reverse, linear-time reduction of arithmetic 0-1 matrix
  multiplication to computing all-pairs distances in a Hamming space.
  On the other hand, we present a fast randomized algorithm for
  approximate all-pairs distances in a Hamming space. By combining it
  with our reduction, we obtain also a fast randomized algorithm for
  approximate 0-1 matrix multiplication. Next, we present an
  output-sensitive randomized algorithm for a minimum spanning tree of
  a set of points in a generalized Hamming space, the lower is the
  cost of the minimum spanning tree the faster is our
  algorithm. Finally, we provide $(2+\epsilon)$- approximation
  algorithms for the $\ell$-center clustering and minimum-diameter
  $\ell$-clustering problems in a Hamming space $\{0,1\}^d$ that are
  substantially faster than the known $2$-approximation ones when both
  $\ell$ and $d$ are super-logarithmic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14723v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Miroslaw Kowaluk, Andrzej Lingas, Mia Persson</dc:creator>
    </item>
    <item>
      <title>(Sub)Exponential Quantum Speedup for Optimization</title>
      <link>https://arxiv.org/abs/2504.14841</link>
      <description>arXiv:2504.14841v1 Announce Type: cross 
Abstract: We demonstrate provable (sub)exponential quantum speedups in both discrete and continuous optimization, achieved through simple and natural quantum optimization algorithms, namely the quantum adiabatic algorithm for discrete optimization and quantum Hamiltonian descent for continuous optimization. Our result builds on the Gily\'en--Hastings--Vazirani (sub)exponential oracle separation for adiabatic quantum computing. With a sequence of perturbative reductions, we compile their construction into two standalone objective functions, whose oracles can be directly leveraged by the plain adiabatic evolution and Schr\"odinger operator evolution for discrete and continuous optimization, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14841v1</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>math.OC</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiaqi Leng, Kewen Wu, Xiaodi Wu, Yufan Zheng</dc:creator>
    </item>
    <item>
      <title>Parallel Kac's Walk Generates PRU</title>
      <link>https://arxiv.org/abs/2504.14957</link>
      <description>arXiv:2504.14957v1 Announce Type: cross 
Abstract: Ma and Huang recently proved that the PFC construction, introduced by Metger, Poremba, Sinha and Yuen [MPSY24], gives an adaptive-secure pseudorandom unitary family PRU. Their proof developed a new path recording technique [MH24].
  In this work, we show that a linear number of sequential repetitions of the parallel Kac's Walk, introduced by Lu, Qin, Song, Yao and Zhao [LQSY+24], also forms an adaptive-secure PRU, confirming a conjecture therein. Moreover, it additionally satisfies strong security against adversaries making inverse queries. This gives an alternative PRU construction, and provides another instance demonstrating the power of the path recording technique. We also discuss some further simplifications and implications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14957v1</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.CR</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chuhan Lu, Minglong Qin, Fang Song, Penghui Yao, Mingnan Zhao</dc:creator>
    </item>
    <item>
      <title>Explicit Lossless Vertex Expanders</title>
      <link>https://arxiv.org/abs/2504.15087</link>
      <description>arXiv:2504.15087v1 Announce Type: cross 
Abstract: We give the first construction of explicit constant-degree lossless vertex expanders. Specifically, for any $\varepsilon &gt; 0$ and sufficiently large $d$, we give an explicit construction of an infinite family of $d$-regular graphs where every small set $S$ of vertices has $(1-\varepsilon)d|S|$ neighbors (which implies $(1-2\varepsilon)d|S|$ unique-neighbors). Our results also extend naturally to construct biregular bipartite graphs of any constant imbalance, where small sets on each side have strong expansion guarantees. The graphs we construct admit a free group action, and hence realize new families of quantum LDPC codes of Lin and M. Hsieh with a linear time decoding algorithm.
  Our construction is based on taking an appropriate product of a constant-sized lossless expander with a base graph constructed from Ramanujan Cayley cubical complexes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.15087v1</guid>
      <category>math.CO</category>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>math.GR</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jun-Ting Hsieh, Alexander Lubotzky, Sidhanth Mohanty, Assaf Reiner, Rachel Yun Zhang</dc:creator>
    </item>
    <item>
      <title>How Global Calibration Strengthens Multiaccuracy</title>
      <link>https://arxiv.org/abs/2504.15206</link>
      <description>arXiv:2504.15206v1 Announce Type: cross 
Abstract: Multiaccuracy and multicalibration are multigroup fairness notions for prediction that have found numerous applications in learning and computational complexity. They can be achieved from a single learning primitive: weak agnostic learning. Here we investigate the power of multiaccuracy as a learning primitive, both with and without the additional assumption of calibration. We find that multiaccuracy in itself is rather weak, but that the addition of global calibration (this notion is called calibrated multiaccuracy) boosts its power substantially, enough to recover implications that were previously known only assuming the stronger notion of multicalibration.
  We give evidence that multiaccuracy might not be as powerful as standard weak agnostic learning, by showing that there is no way to post-process a multiaccurate predictor to get a weak learner, even assuming the best hypothesis has correlation $1/2$. Rather, we show that it yields a restricted form of weak agnostic learning, which requires some concept in the class to have correlation greater than $1/2$ with the labels. However, by also requiring the predictor to be calibrated, we recover not just weak, but strong agnostic learning.
  A similar picture emerges when we consider the derivation of hardcore measures from predictors satisfying multigroup fairness notions. On the one hand, while multiaccuracy only yields hardcore measures of density half the optimal, we show that (a weighted version of) calibrated multiaccuracy achieves optimal density.
  Our results yield new insights into the complementary roles played by multiaccuracy and calibration in each setting. They shed light on why multiaccuracy and global calibration, although not particularly powerful by themselves, together yield considerably stronger notions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.15206v1</guid>
      <category>cs.LG</category>
      <category>cs.CC</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>S\'ilvia Casacuberta, Parikshit Gopalan, Varun Kanade, Omer Reingold</dc:creator>
    </item>
    <item>
      <title>Tight Complexity Bounds for Counting Generalized Dominating Sets in Bounded-Treewidth Graphs Part I: Algorithmic Results</title>
      <link>https://arxiv.org/abs/2211.04278</link>
      <description>arXiv:2211.04278v3 Announce Type: replace 
Abstract: We investigate how efficiently a well-studied family of domination-type problems can be solved on bounded-treewidth graphs. For sets $\sigma,\rho$ of non-negative integers, a $(\sigma,\rho)$-set of a graph $G$ is a set $S$ of vertices such that $|N(u)\cap S|\in \sigma$ for every $u\in S$, and $|N(v)\cap S|\in \rho$ for every $v\not\in S$. The problem of finding a $(\sigma,\rho)$-set (of a certain size) unifies standard problems such as Independent Set, Dominating Set, Independent Dominating Set, and many others.
  For all pairs of finite or cofinite sets $(\sigma,\rho)$, we determine (under standard complexity assumptions) the best possible value $c_{\sigma,\rho}$ such that there is an algorithm that counts $(\sigma,\rho)$-sets in time $c_{\sigma,\rho}^{\sf tw}\cdot n^{O(1)}$ (if a tree decomposition of width ${\sf tw}$ is given in the input). For example, for the Exact Independent Dominating Set problem (also known as Perfect Code) corresponding to $\sigma=\{0\}$ and $\rho=\{1\}$, we improve the $3^{\sf tw}\cdot n^{O(1)}$ algorithm of [van Rooij, 2020] to $2^{\sf tw}\cdot n^{O(1)}$.
  Despite the unusually delicate definition of $c_{\sigma,\rho}$, an accompanying paper shows that our algorithms are most likely optimal, that is, for any pair $(\sigma, \rho)$ of finite or cofinite sets where the problem is non-trivial, and any $\varepsilon&gt;0$, a $(c_{\sigma,\rho}-\varepsilon)^{\sf tw}\cdot n^{O(1)}$-algorithm counting the number of $(\sigma,\rho)$-sets would violate the Counting Strong Exponential-Time Hypothesis (#SETH). For finite sets $\sigma$ and $\rho$, these lower bounds also extend to the decision version, and hence, our algorithms are optimal in this setting as well. In contrast, for many cofinite sets, we show that further significant improvements for the decision and optimization versions are possible using the technique of representative sets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.04278v3</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jacob Focke, D\'aniel Marx, Fionn Mc Inerney, Daniel Neuen, Govind S. Sankar, Philipp Schepper, Philip Wellnitz</dc:creator>
    </item>
    <item>
      <title>The complexity of convexity number and percolation time in the cycle convexity</title>
      <link>https://arxiv.org/abs/2404.09236</link>
      <description>arXiv:2404.09236v3 Announce Type: replace 
Abstract: The subject of graph convexity is well explored in the literature, the so-called interval convexities above all. In this work, we explore the cycle convexity, an interval convexity whose interval function is $I(S) = S \cup \{u \mid G[S \cup \{u\}]$ has a cycle containing $u\}$. In this convexity, we prove that determine whether the convexity number of a graph $G$ is at least $k$ is \NP-complete and \W[1]-hard when parameterized by the size of the solution when $G$ is a thick spider, but polynomial when $G$ is an extended $P_4$-laden graph. We also prove that determining whether the percolation time of a graph is at least $k$ is \NP-complete even for fixed $k \geq 9$, but polynomial for cacti or for fixed $k\leq2$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.09236v3</guid>
      <category>cs.CC</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Carlos V. G. C. Lima, Thiago Marcilon, Pedro Paulo de Medeiros</dc:creator>
    </item>
    <item>
      <title>Low-Degree Polynomials Are Good Extractors</title>
      <link>https://arxiv.org/abs/2405.10297</link>
      <description>arXiv:2405.10297v2 Announce Type: replace 
Abstract: We prove that random low-degree polynomials (over $\mathbb{F}_2$) are unbiased, in an extremely general sense. That is, we show that random low-degree polynomials are good randomness extractors for a wide class of distributions. Prior to our work, such results were only known for the small families of (1) uniform sources, (2) affine sources, and (3) local sources. We significantly generalize these results, and prove the following.
  1. Low-degree polynomials extract from small families. We show that a random low-degree polynomial is a good low-error extractor for any small family of sources. In particular, we improve the positive result of Alrabiah, Chattopadhyay, Goodman, Li, and Ribeiro (ICALP 2022) for local sources, and give new results for polynomial and variety sources via a single unified approach.
  2. Low-degree polynomials extract from sumset sources. We show that a random low-degree polynomial is a good extractor for sumset sources, which are the most general large family of sources (capturing independent sources, interleaved sources, small-space sources, and more). Formally, for any even $d$, we show that a random degree $d$ polynomial is an $\varepsilon$-error extractor for $n$-bit sumset sources with min-entropy $k=O(d(n/\varepsilon^2)^{2/d})$. This is nearly tight in the polynomial error regime.
  Our results on sumset extractors imply new complexity separations for linear ROBPs, and the tools that go into its proof may be of independent interest. The two main tools we use are a new structural result on sumset-punctured Reed-Muller codes, paired with a novel type of reduction between extractors. Using the new structural result, we obtain new limits on the power of sumset extractors, strengthening and generalizing the impossibility results of Chattopadhyay, Goodman, and Gurumukhani (ITCS 2024).</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10297v2</guid>
      <category>cs.CC</category>
      <category>math.CO</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Omar Alrabiah, Jesse Goodman, Jonathan Mosheiff, Jo\~ao Ribeiro</dc:creator>
    </item>
    <item>
      <title>On the Complexity of Neural Computation in Superposition</title>
      <link>https://arxiv.org/abs/2409.15318</link>
      <description>arXiv:2409.15318v2 Announce Type: replace 
Abstract: Superposition, the ability of neural networks to represent more features than neurons, is increasingly seen as key to the efficiency of large models. This paper investigates the theoretical foundations of computing in superposition, establishing complexity bounds for explicit, provably correct algorithms.
  We present the first lower bounds for a neural network computing in superposition, showing that for a broad class of problems, including permutations and pairwise logical operations, computing $m'$ features in superposition requires at least $\Omega(\sqrt{m' \log m'})$ neurons and $\Omega(m' \log m')$ parameters. This implies the first subexponential upper bound on superposition capacity: a network with $n$ neurons can compute at most $O(n^2 / \log n)$ features. Conversely, we provide a nearly tight constructive upper bound: logical operations like pairwise AND can be computed using $O(\sqrt{m'} \log m')$ neurons and $O(m' \log^2 m')$ parameters. There is thus an exponential gap between the complexity of computing in superposition (the subject of this work) versus merely representing features, which can require as little as $O(\log m')$ neurons based on the Johnson-Lindenstrauss Lemma.
  Our hope is that our results open a path for using complexity theoretic techniques in neural network interpretability research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.15318v2</guid>
      <category>cs.CC</category>
      <category>cs.AI</category>
      <category>cs.DS</category>
      <category>cs.NE</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Micah Adler, Nir Shavit</dc:creator>
    </item>
    <item>
      <title>Efficient Algorithm for Sparse Fourier Transform of Generalized $q$-ary Functions</title>
      <link>https://arxiv.org/abs/2501.12365</link>
      <description>arXiv:2501.12365v2 Announce Type: replace 
Abstract: Computing the Fourier transform of a $q$-ary function $f:\mathbb{Z}_{q}^n\rightarrow \mathbb{R}$, which maps $q$-ary sequences to real numbers, is an important problem in mathematics with wide-ranging applications in biology, signal processing, and machine learning. Previous studies have shown that, under the sparsity assumption, the Fourier transform can be computed efficiently using fast and sample-efficient algorithms. However, in most practical settings, the function is defined over a more general space -- the space of generalized $q$-ary sequences $\mathbb{Z}_{q_1} \times \mathbb{Z}_{q_2} \times \cdots \times \mathbb{Z}_{q_n}$ -- where each $\mathbb{Z}_{q_i}$ corresponds to integers modulo $q_i$. Herein, we develop GFast, a coding theoretic algorithm that computes the $S$-sparse Fourier transform of $f$ with a sample complexity of $O(Sn)$, computational complexity of $O(Sn \log N)$, and a failure probability that approaches zero as $N=\prod_{i=1}^n q_i \rightarrow \infty$ with $S = N^\delta$ for some $0 \leq \delta &lt; 1$. We show that a noise-robust version of GFast computes the transform with a sample complexity of $O(Sn^2)$ and computational complexity of $O(Sn^2 \log N)$ under the same high probability guarantees. Additionally, we demonstrate that GFast computes the sparse Fourier transform of generalized $q$-ary functions $8\times$ faster using $16\times$ fewer samples on synthetic experiments, and enables explaining real-world heart disease diagnosis and protein fitness models using up to $13\times$ fewer samples compared to existing Fourier algorithms applied to the most efficient parameterization of the models as $q$-ary functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12365v2</guid>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Darin Tsui, Kunal Talreja, Amirali Aghazadeh</dc:creator>
    </item>
    <item>
      <title>A Pseudorandom Generator for Functions of Low-Degree Polynomial Threshold Functions</title>
      <link>https://arxiv.org/abs/2504.10904</link>
      <description>arXiv:2504.10904v2 Announce Type: replace 
Abstract: Developing explicit pseudorandom generators (PRGs) for prominent categories of Boolean functions is a key focus in computational complexity theory. In this paper, we investigate the PRGs against the functions of degree-$d$ polynomial threshold functions (PTFs) over Gaussian space. Our main result is an explicit construction of PRG with seed length $\mathrm{poly}(k,d,1/\epsilon)\cdot\log n$ that can fool any function of $k$ degree-$d$ PTFs with probability at least $1-\varepsilon$. More specifically, we show that the summation of $L$ independent $R$-moment-matching Gaussian vectors $\epsilon$-fools functions of $k$ degree-$d$ PTFs, where $L=\mathrm{poly}( k, d, \frac{1}{\epsilon})$ and $R = O({\log \frac{kd}{\epsilon}})$. The PRG is then obtained by applying an appropriate discretization to Gaussian vectors with bounded independence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.10904v2</guid>
      <category>cs.CC</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Penghui Yao, Mingnan Zhao</dc:creator>
    </item>
    <item>
      <title>Complexity of approximate conflict-free, linearly-ordered, and nonmonochromatic hypergraph colourings</title>
      <link>https://arxiv.org/abs/2501.12062</link>
      <description>arXiv:2501.12062v2 Announce Type: replace-cross 
Abstract: Using the algebraic approach to promise constraint satisfaction problems, we establish complexity classifications of three natural variants of hypergraph colourings: standard nonmonochromatic colourings, conflict-free colourings, and linearly-ordered colourings.
  Firstly, we show that finding an $\ell$-colouring of a $k$-colourable $r$-uniform hypergraph is NP-hard for all constant $2\leq k\leq \ell$ and $r\geq 3$. This provides a shorter proof of a celebrated result by Dinur et al. [FOCS'02/Combinatorica'05].
  Secondly, we show that finding an $\ell$-conflict-free colouring of an $r$-uniform hypergraph that admits a $k$-conflict-free colouring is NP-hard for all constant $3\leq k\leq\ell$ and $r\geq 4$, except for $r=4$ and $k=2$ (and any $\ell$); this case is solvable in polynomial time. The case of $r=3$ is the standard nonmonochromatic colouring, and the case of $r=2$ is the notoriously difficult open problem of approximate graph colouring.
  Thirdly, we show that finding an $\ell$-linearly-ordered colouring of an $r$-uniform hypergraph that admits a $k$-linearly-ordered colouring is NP-hard for all constant $3\leq k\leq\ell$ and $r\geq 4$, thus improving on the results of Nakajima and \v{Z}ivn\'y [ICALP'22/ACM TocT'23].</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12062v2</guid>
      <category>cs.DM</category>
      <category>cs.CC</category>
      <category>math.CO</category>
      <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tamio-Vesa Nakajima, Zephyr Verwimp, Marcin Wrochna, Stanislav \v{Z}ivn\'y</dc:creator>
    </item>
  </channel>
</rss>
