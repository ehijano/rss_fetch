<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 27 Jun 2024 01:32:21 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 26 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Computing User Equilibria for Schedule-Based Transit Networks with Hard Vehicle Capacities</title>
      <link>https://arxiv.org/abs/2406.17153</link>
      <description>arXiv:2406.17153v1 Announce Type: new 
Abstract: Modelling passenger assignments in public transport networks is a fundamental task for city planners, especially when deliberating network infrastructure decisions. A key aspect of a realistic model for passenger assignments is to integrate selfish routing behaviour of passengers on the one hand, and the limited vehicle capacities on the other hand. We formulate a side-constrained user equilibrium model in a schedule-based time-expanded transit network, where passengers are modelled via a continuum of non-atomic agents that want to travel with a fixed start time from a user-specific origin to a destination. An agent's route may comprise several rides along given lines, each using vehicles with hard loading capacities. We give a characterization of (side-constrained) user equilibria via a quasi-variational inequality and prove their existence by generalizing a well-known existence result of Bernstein and Smith (Transp. Sci., 1994). We further derive a polynomial time algorithm for single-commodity instances and an exact finite time algorithm for the multi-commodity case. Based on our quasi-variational characterization, we finally devise a fast heuristic computing user equilibria, which is tested on real-world instances based on data gained from the Hamburg S-Bahn system and the Swiss long-distance train network. It turns out that w.r.t. the total travel time, the computed user-equilibria are quite efficient compared to a system optimum, which neglects equilibrium constraints and only minimizes total travel time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.17153v1</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tobias Harks, Sven J\"ager, Michael Markl, Philine Schiewe</dc:creator>
    </item>
    <item>
      <title>The Power of Counting Steps in Quantitative Games</title>
      <link>https://arxiv.org/abs/2406.17482</link>
      <description>arXiv:2406.17482v1 Announce Type: new 
Abstract: We study deterministic games of infinite duration played on graphs and focus on the strategy complexity of quantitative objectives. Such games are known to admit optimal memoryless strategies over finite graphs, but require infinite-memory strategies in general over infinite graphs.
  We provide new lower and upper bounds for the strategy complexity of mean-payoff and total-payoff objectives over infinite graphs, focusing on whether step-counter strategies (sometimes called Markov strategies) suffice to implement winning strategies. In particular, we show that over finitely branching arenas, three variants of limsup mean-payoff and total-payoff objectives admit winning strategies that are based either on a step counter or on a step counter and an additional bit of memory. Conversely, we show that for certain liminf total-payoff objectives, strategies resorting to a step counter and finite memory are not sufficient. For step-counter strategies, this settles the case of all classical quantitative objectives up to the second level of the Borel hierarchy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.17482v1</guid>
      <category>cs.GT</category>
      <category>cs.FL</category>
      <category>cs.LO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sougata Bose, Rasmus Ibsen-Jensen, David Purser, Patrick Totzke, Pierre Vandenhove</dc:creator>
    </item>
    <item>
      <title>Splitting Guarantees for Prophet Inequalities via Nonlinear Systems</title>
      <link>https://arxiv.org/abs/2406.17767</link>
      <description>arXiv:2406.17767v1 Announce Type: new 
Abstract: The prophet inequality is one of the cornerstone problems in optimal stopping theory and has become a crucial tool for designing sequential algorithms in Bayesian settings. In the i.i.d. $k$-selection prophet inequality problem, we sequentially observe $n$ non-negative random values sampled from a known distribution. Each time, a decision is made to accept or reject the value, and under the constraint of accepting at most $k$. For $k=1$, Hill and Kertz [Ann. Probab. 1982] provided an upper bound on the worst-case approximation ratio that was later matched by an algorithm of Correa et al. [Math. Oper. Res. 2021]. The worst-case tight approximation ratio for $k=1$ is computed by studying a differential equation that naturally appears when analyzing the optimal dynamic programming policy. A similar result for $k&gt;1$ has remained elusive.
  In this work, we introduce a nonlinear system of differential equations for the i.i.d. $k$-selection prophet inequality that generalizes Hill and Kertz's equation when $k=1$. Our nonlinear system is defined by $k$ constants that determine its functional structure, and their summation provides a lower bound on the optimal policy's asymptotic approximation ratio for the i.i.d. $k$-selection prophet inequality. To obtain this result, we introduce for every $k$ an infinite-dimensional linear programming formulation that fully characterizes the worst-case tight approximation ratio of the $k$-selection prophet inequality problem for every $n$, and then we follow a dual-fitting approach to link with our nonlinear system for sufficiently large values of $n$. As a corollary, we use our provable lower bounds to establish a tight approximation ratio for the stochastic sequential assignment problem in the i.i.d. non-negative regime.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.17767v1</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Johannes Brustle, Sebastian Perez-Salazar, Victor Verdugo</dc:creator>
    </item>
    <item>
      <title>Inception: Efficiently Computable Misinformation Attacks on Markov Games</title>
      <link>https://arxiv.org/abs/2406.17114</link>
      <description>arXiv:2406.17114v1 Announce Type: cross 
Abstract: We study security threats to Markov games due to information asymmetry and misinformation. We consider an attacker player who can spread misinformation about its reward function to influence the robust victim player's behavior. Given a fixed fake reward function, we derive the victim's policy under worst-case rationality and present polynomial-time algorithms to compute the attacker's optimal worst-case policy based on linear programming and backward induction. Then, we provide an efficient inception ("planting an idea in someone's mind") attack algorithm to find the optimal fake reward function within a restricted set of reward functions with dominant strategies. Importantly, our methods exploit the universal assumption of rationality to compute attacks efficiently. Thus, our work exposes a security vulnerability arising from standard game assumptions under misinformation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.17114v1</guid>
      <category>cs.LG</category>
      <category>cs.CR</category>
      <category>cs.GT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jeremy McMahan, Young Wu, Yudong Chen, Xiaojin Zhu, Qiaomin Xie</dc:creator>
    </item>
    <item>
      <title>Truthful Aggregation of LLMs with an Application to Online Advertising</title>
      <link>https://arxiv.org/abs/2405.05905</link>
      <description>arXiv:2405.05905v3 Announce Type: replace 
Abstract: Online platforms generate hundreds of billions of dollars in revenue per year by showing advertisements alongside their own content. Currently, these platforms are integrating Large Language Models (LLMs) into their services. This makes revenue generation from LLM-generated content the next major challenge in online advertising. We consider a scenario where advertisers aim to influence the responses of an LLM to align with their interests, while platforms seek to maximize advertiser value and ensure user satisfaction. We introduce an auction mechanism for this problem that operates without LLM fine-tuning or access to model weights and provably converges to the output of the optimally fine-tuned LLM for the platform's objective as computational resources increase. Our mechanism ensures that truthful reporting is a dominant strategy for advertisers and it aligns each advertiser's utility with their contribution to social welfare - an essential feature for long-term viability. Additionally, it can incorporate contextual information about the advertisers, significantly accelerating convergence. Via experiments with a publicly available LLM, we show that our mechanism significantly boosts advertiser value and platform revenue, with low computational overhead. While our motivating application is online advertising, our mechanism can be applied in any setting with monetary transfers, making it a general-purpose solution for truthfully aggregating the preferences of self-interested agents over LLM-generated replies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.05905v3</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ermis Soumalias, Michael J. Curry, Sven Seuken</dc:creator>
    </item>
    <item>
      <title>Fast, optimal, and dynamic electoral campaign budgeting by a generalized Colonel Blotto game</title>
      <link>https://arxiv.org/abs/2406.15714</link>
      <description>arXiv:2406.15714v2 Announce Type: replace 
Abstract: The Colonel Blotto game is a deeply studied theoretical model for competitive allocation environments including elections, advertising, and ecology. However, the original formulation of Colonel Blotto has had few practical implications due to the lack of fast algorithms to compute its optimal strategies and the limited applicability of its winner-take-all reward distribution. We demonstrate that the Colonel Blotto game can be a practical model for competitive allocation environments by implementing the multiplicative weights update algorithm from Beaglehole et al. (2023). In particular, using that this algorithm allows for arbitrary winning-rules, we study strategies for a more realistic model of political campaigning we term Electoral Colonel Blotto. Contrary to existing theory and the implemented allocation strategies from U.S. presidential elections, we find that the optimal response to Democratic and Republican strategies in the 2008 and 2020 presidential elections was to focus allocations on a subset of states and sacrifice winning probability on others. We also found that campaigners should compete for undecided voters even in states where the opponent has significantly many more decided voters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15714v2</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Thomas Valles, Daniel Beaglehole</dc:creator>
    </item>
    <item>
      <title>Fundamental Bounds on Online Strategic Classification</title>
      <link>https://arxiv.org/abs/2302.12355</link>
      <description>arXiv:2302.12355v2 Announce Type: replace-cross 
Abstract: We study the problem of online binary classification where strategic agents can manipulate their observable features in predefined ways, modeled by a manipulation graph, in order to receive a positive classification. We show this setting differs in fundamental ways from non-strategic online classification. For instance, whereas in the non-strategic case, a mistake bound of $\ln|H|$ is achievable via the halving algorithm when the target function belongs to a known class $H$, we show that no deterministic algorithm can achieve a mistake bound $o(\Delta)$ in the strategic setting, where $\Delta$ is the maximum degree of the manipulation graph (even when $|H|=O(\Delta)$). We obtain an algorithm achieving mistake bound $O(\Delta\ln|H|)$. We also extend this to the agnostic setting and obtain an algorithm with a $\Delta$ multiplicative regret, and we show no deterministic algorithm can achieve $o(\Delta)$ multiplicative regret.
  Next, we study two randomized models based on whether the random choices are made before or after agents respond, and show they exhibit fundamental differences. In the first model, at each round the learner deterministically chooses a probability distribution over classifiers inducing expected values on each vertex (probabilities of being classified as positive), which the strategic agents respond to. We show that any learner in this model has to suffer linear regret. On the other hand, in the second model, while the adversary who selects the next agent must respond to the learner's probability distribution over classifiers, the agent then responds to the actual hypothesis classifier drawn from this distribution. Surprisingly, we show this model is more advantageous to the learner, and we design randomized algorithms that achieve sublinear regret bounds against both oblivious and adaptive adversaries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.12355v2</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Saba Ahmadi, Avrim Blum, Kunhe Yang</dc:creator>
    </item>
    <item>
      <title>Random partitions, potential, value, and externalities</title>
      <link>https://arxiv.org/abs/2402.00394</link>
      <description>arXiv:2402.00394v2 Announce Type: replace-cross 
Abstract: The Shapley value equals a player's contribution to the potential of a game. The potential is a most natural one-number summary of a game, which can be computed as the expected accumulated worth of a random partition of the players. This computation integrates the coalition formation of all players and readily extends to games with externalities. We investigate those potential functions for games with externalities that can be computed this way. It turns out that the potential that corresponds to the MPW solution introduced by Macho-Stadler et al. (2007, J. Econ. Theory 135, 339--356) is unique in the following sense. It is obtained as the expected accumulated worth of a random partition, it generalizes the potential for games without externalities, and it induces a solution that satisfies the null player property even in the presence of externalities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.00394v2</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <category>math.CO</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Andr\'e Casajus, Yukihiko Funaki, Frank Huettner</dc:creator>
    </item>
  </channel>
</rss>
