<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.ET updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.ET</link>
    <description>cs.ET updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.ET" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 19 Feb 2026 05:00:17 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Decomposing Large-Scale Ising Problems on FPGAs: A Hybrid Hardware Approach</title>
      <link>https://arxiv.org/abs/2602.15985</link>
      <description>arXiv:2602.15985v1 Announce Type: new 
Abstract: Emerging analog computing substrates, such as oscillator-based Ising machines, offer rapid convergence times for combinatorial optimization but often suffer from limited scalability due to physical implementation constraints. To tackle real-world problems involving thousands of variables, problem decomposition is required; however, performing this step on standard CPUs introduces significant latency, preventing the high-speed solver from operating at full capacity. This work presents a heterogeneous system that offloads the decomposition workload to an FPGA, tightly integrated with a custom 28nm Ising solver. By migrating the decomposition logic to reconfigurable hardware and utilizing parallel processing elements, the system minimizes the communication latency typically associated with host-device interactions. Our evaluation demonstrates that this co-design approach effectively bridges the speed gap between digital preprocessing and analog solving, achieving nearly 2$\times$ speedup and an energy efficiency improvement of over two orders of magnitude compared to optimized software baselines running on modern CPUs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15985v1</guid>
      <category>cs.ET</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruihong Yin, Yue Zheng, Chaohui Li, Ahmet Efe, Abhimanyu Kumar, Ziqing Zeng, Ulya R. Karpuzcu, Sachin S. Sapatnekar, Chris H. Kim</dc:creator>
    </item>
    <item>
      <title>Bibby AI -- AI Latex Editor writing assistant for researchers vs Overleaf Alternative vs OpenAI Prism. (Bibby AI Latex Editor)</title>
      <link>https://arxiv.org/abs/2602.16432</link>
      <description>arXiv:2602.16432v1 Announce Type: new 
Abstract: Large language models are increasingly integrated into academic writing workflows; however, the most widely used \LaTeX\ editors remain AI-peripheral -- offering compilation and collaboration, but no native intelligence. This separation forces researchers to leave their editing environment for AI assistance, fragmenting document context and interrupting writing flow. We present Bibby AI (trybibby.com), a native, AI-first \LaTeX\ editor that unifies the complete research writing lifecycle within a single interface. Bibby embeds an AI writing assistant, smart citation search, AI table and equation generation, an AI paper reviewer, abstract generator, literature review drafting, a deep research assistant, and real-time \LaTeX\ error detection and auto-fix -- all natively, without plugins or copy-paste workflows. We introduce LaTeXBench-500, a benchmark of 500 real-world compilation errors across six categories. Bibby achieves 91.4\% detection accuracy and 83.7\% one-click fix accuracy, outperforming Overleaf's native diagnostics (61.2\%) and OpenAI Prism (78.3 / 64.1\%) by large margins. Bibby demonstrates that a privacy-preserving, research-first AI editor can meaningfully accelerate every stage of academic manuscript preparation. We found that Bibby AI is a far superior alternative to overleaf latex and better than OpenAI Prism functionalities and AI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.16432v1</guid>
      <category>cs.ET</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nilesh jain, Rohit Yadav, Andrej Karpathy</dc:creator>
    </item>
    <item>
      <title>Edge-Local and Qubit-Efficient Quantum Graph Learning for the NISQ Era</title>
      <link>https://arxiv.org/abs/2602.16018</link>
      <description>arXiv:2602.16018v1 Announce Type: cross 
Abstract: Graph neural networks (GNNs) are a powerful framework for learning representations from graph-structured data, but their direct implementation on near-term quantum hardware remains challenging due to circuit depth, multi-qubit interactions, and qubit scalability constraints. In this work, we introduce a fully quantum graph convolutional architecture designed explicitly for unsupervised learning in the noisy intermediate-scale quantum (NISQ) regime. Our approach combines a variational quantum feature extraction layer with an edge-local and qubit-efficient quantum message-passing mechanism inspired by the Quantum Alternating Operator Ansatz (QAOA) framework. Unlike prior models that rely on global operations or multi-controlled unitaries, our model decomposes message passing into pairwise interactions along graph edges using only hardware-native single- and two-qubit gates. This design reduces the qubit requirement from $O(Nn)$ to $O(n)$ for a graph with $N$ nodes and $n$-qubit feature registers, enabling implementation on current quantum devices regardless of graph size. We train the model using the Deep Graph Infomax objective to perform unsupervised node representation learning. Experiments on the Cora citation network and a large-scale genomic SNP dataset demonstrate that our model remains competitive with prior quantum and hybrid approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.16018v1</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Armin Ahmadkhaniha, Jake Doliskani</dc:creator>
    </item>
    <item>
      <title>MARLEM: A Multi-Agent Reinforcement Learning Simulation Framework for Implicit Cooperation in Decentralized Local Energy Markets</title>
      <link>https://arxiv.org/abs/2602.16063</link>
      <description>arXiv:2602.16063v1 Announce Type: cross 
Abstract: This paper introduces a novel, open-source MARL simulation framework for studying implicit cooperation in LEMs, modeled as a decentralized partially observable Markov decision process and implemented as a Gymnasium environment for MARL. Our framework features a modular market platform with plug-and-play clearing mechanisms, physically constrained agent models (including battery storage), a realistic grid network, and a comprehensive analytics suite to evaluate emergent coordination. The main contribution is a novel method to foster implicit cooperation, where agents' observations and rewards are enhanced with system-level key performance indicators to enable them to independently learn strategies that benefit the entire system and aim for collectively beneficial outcomes without explicit communication. Through representative case studies (available in a dedicated GitHub repository in https://github.com/salazarna/marlem, we show the framework's ability to analyze how different market configurations (such as varying storage deployment) impact system performance. This illustrates its potential to facilitate emergent coordination, improve market efficiency, and strengthen grid stability. The proposed simulation framework is a flexible, extensible, and reproducible tool for researchers and practitioners to design, test, and validate strategies for future intelligent, decentralized energy systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.16063v1</guid>
      <category>eess.SY</category>
      <category>cs.CE</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>stat.CO</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nelson Salazar-Pena, Alejandra Tabares, Andres Gonzalez-Mancera</dc:creator>
    </item>
    <item>
      <title>DARTH-PUM: A Hybrid Processing-Using-Memory Architecture</title>
      <link>https://arxiv.org/abs/2602.16075</link>
      <description>arXiv:2602.16075v1 Announce Type: cross 
Abstract: Analog processing-using-memory (PUM; a.k.a. in-memory computing) makes use of electrical interactions inside memory arrays to perform bulk matrix-vector multiplication (MVM) operations. However, many popular matrix-based kernels need to execute non-MVM operations, which analog PUM cannot directly perform. To retain its energy efficiency, analog PUM architectures augment memory arrays with CMOS-based domain-specific fixed-function hardware to provide complete kernel functionality, but the difficulty of integrating such specialized CMOS logic with memory arrays has largely limited analog PUM to being an accelerator for machine learning inference, or for closely related kernels. An opportunity exists to harness analog PUM for general-purpose computation: recent works have shown that memory arrays can also perform Boolean PUM operations, albeit with very different supporting hardware and electrical signals than analog PUM.
  We propose DARTH-PUM, a general-purpose hybrid PUM architecture that tackles key hardware and software challenges to integrating analog PUM and digital PUM. We propose optimized peripheral circuitry, coordinating hardware to manage and interface between both types of PUM, an easy-to-use programming interface, and low-cost support for flexible data widths. These design elements allow us to build a practical PUM architecture that can execute kernels fully in memory, and can scale easily to cater to domains ranging from embedded applications to large-scale data-driven computing. We show how three popular applications (AES encryption, convolutional neural networks, large-language models) can map to and benefit from DARTH-PUM, with speedups of 59.4x, 14.8x, and 40.8x over an analog+CPU baseline.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.16075v1</guid>
      <category>cs.AR</category>
      <category>cs.CR</category>
      <category>cs.ET</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ryan Wong, Ben Feinberg, Saugata Ghose</dc:creator>
    </item>
    <item>
      <title>Machine Learning Driven Prediction of the Behavior of Biohybrid Actuators</title>
      <link>https://arxiv.org/abs/2602.16330</link>
      <description>arXiv:2602.16330v1 Announce Type: cross 
Abstract: Skeletal muscle-based biohybrid actuators have proved to be a promising component in soft robotics, offering efficient movement. However, their intrinsic biological variability and nonlinearity pose significant challenges for controllability and predictability. To address these issues, this study investigates the application of supervised learning, a form of machine learning, to model and predict the behavior of biohybrid machines (BHMs), focusing on a muscle ring anchored on flexible polymer pillars. First, static prediction models (i.e., random forest and neural network regressors) are trained to estimate the maximum exerted force achieved from input variables such as muscle sample, electrical stimulation parameters, and baseline exerted force. Second, a dynamic modeling framework, based on Long Short-Term Memory networks, is developed to serve as a digital twin, replicating the time series of exerted forces observed in response to electrical stimulation. Both modeling approaches demonstrate high predictive accuracy. The best performance of the static models is characterized by R2 of 0.9425, whereas the dynamic model achieves R2 of 0.9956. The static models can enable optimization of muscle actuator performance for targeted applications and required force outcomes, while the dynamic model provides a foundation for developing robustly adaptive control strategies in future biohybrid robotic systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.16330v1</guid>
      <category>cs.RO</category>
      <category>cs.ET</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Michail-Antisthenis Tsompanas, Marco Perez Hernandez, Faisal Abdul-Fattah, Karim Elhakim, Mostafa Ibrahim, Judith Fuentes, Florencia Lezcano, Riccardo Collu, Massimo Barbaro, Stefano Lai, Samuel Sanchez, Andrew Adamatzky</dc:creator>
    </item>
    <item>
      <title>A Multihop Rendezvous Protocol for Cognitive Radio-based Emergency Response Network</title>
      <link>https://arxiv.org/abs/2602.16367</link>
      <description>arXiv:2602.16367v1 Announce Type: cross 
Abstract: This letter proposes a novel Multihop Dual Modular Clock Algorithm (M-DMCA) for efficient node discovery in cognitive radio-based emergency response networks. M-DMCA supports dual-channel selection per timeslot and incorporates a three-way handshake mechanism to significantly reduce rendezvous time. Performance evaluation under a worst-case scenario with 20 nodes, asymmetric channel sets of size 20, channel similarity index (m) as 2, and high primary radio activity shows that M-DMCA achieves a 24% reduction in rendezvous time compared to the multihop Extended Modular Clock Algorithm (EMCA), outperforming existing rendezvous protocols.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.16367v1</guid>
      <category>cs.NI</category>
      <category>cs.ET</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zahid Ali, Saritha Unnikrishnan, Eoghan Furey, Ian McLoughlin, Saim Ghafoor</dc:creator>
    </item>
    <item>
      <title>MerLean: An Agentic Framework for Autoformalization in Quantum Computation</title>
      <link>https://arxiv.org/abs/2602.16554</link>
      <description>arXiv:2602.16554v1 Announce Type: cross 
Abstract: We introduce MerLean, a fully automated agentic framework for autoformalization in quantum computation. MerLean extracts mathematical statements from \LaTeX{} source files, formalizes them into verified Lean~4 code built on Mathlib, and translates the result back into human-readable \LaTeX{} for semantic review. We evaluate MerLean on three theoretical quantum computing papers producing 2,050 Lean declarations from 114 statements in total. MerLean achieves end-to-end formalization on all three papers, reducing the verification burden to only the newly introduced definitions and axioms. Our results demonstrate that agentic autoformalization can scale to frontier research, offering both a practical tool for machine-verified peer review and a scalable engine for mining high-quality synthetic data to train future reasoning models. Our approach can also be generalized to any other rigorous research in mathematics and theoretical physics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.16554v1</guid>
      <category>cs.LO</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>quant-ph</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuanjie Ren, Jinzheng Li, Yidi Qi</dc:creator>
    </item>
    <item>
      <title>Weight transport through spike timing for robust local gradients</title>
      <link>https://arxiv.org/abs/2503.02642</link>
      <description>arXiv:2503.02642v2 Announce Type: replace-cross 
Abstract: In both machine learning and in computational neuroscience, plasticity in functional neural networks is frequently expressed as gradient descent on a cost. Often, this imposes symmetry constraints that are difficult to reconcile with local computation, as is required for biological networks or neuromorphic hardware. For example, wake-sleep learning in networks characterized by Boltzmann distributions assumes symmetric connectivity. Similarly, the error backpropagation algorithm is notoriously plagued by the weight transport problem between the representation and the error stream. Existing solutions such as feedback alignment circumvent the problem by deferring to the robustness of these algorithms to weight asymmetry. However, they scale poorly with network size and depth. We introduce spike-based alignment learning (SAL), a complementary learning rule for spiking neural networks, which uses spike timing statistics to extract and correct the asymmetry between effective reciprocal connections. Apart from being spike-based and fully local, our proposed mechanism takes advantage of noise. Based on an interplay between Hebbian and anti-Hebbian plasticity, synapses can thereby recover the true local gradient. This also alleviates discrepancies that arise from neuron and synapse variability -- an omnipresent property of physical neuronal networks. We demonstrate the efficacy of our mechanism using different spiking network models. First, SAL can significantly improve convergence to the target distribution in probabilistic spiking networks versus Hebbian plasticity alone. Second, in neuronal hierarchies based on cortical microcircuits, SAL effectively aligns feedback weights to the forward pathway, thus allowing the backpropagation of correct feedback errors. Third, our approach enables competitive performance in deep networks using only local plasticity for weight transport.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.02642v2</guid>
      <category>q-bio.NC</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <pubDate>Thu, 19 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Timo Gierlich, Andreas Baumbach, Akos F. Kungl, Kevin Max, Mihai A. Petrovici</dc:creator>
    </item>
  </channel>
</rss>
