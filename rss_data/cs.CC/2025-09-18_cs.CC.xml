<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CC</link>
    <description>cs.CC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 18 Sep 2025 04:00:25 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 18 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Smaller Circuits for Bit Addition</title>
      <link>https://arxiv.org/abs/2509.13966</link>
      <description>arXiv:2509.13966v1 Announce Type: new 
Abstract: Bit addition arises virtually everywhere in digital circuits: arithmetic operations, increment/decrement operators, computing addresses and table indices, and so on. Since bit addition is such a basic task in Boolean circuit synthesis, a lot of research has been done on constructing efficient circuits for various special cases of it. A vast majority of these results are devoted to optimizing the circuit depth (also known as delay).
  In this paper, we investigate the circuit size (also known as area) over the full binary basis of bit addition. Though most of the known circuits are built from Half Adders and Full Adders, we show that, in many interesting scenarios, these circuits have suboptimal size. Namely, we improve an upper bound $5n-3m$ to $4.5n-2m$, where $n$ is the number of input bits and $m$ is the number of output bits. In the regimes where $m$ is small compared to $n$ (for example, for computing the sum of $n$ bits or multiplying two $n$-bit integers), this leads to $10\%$ improvement.
  We complement our theoretical result by an open-source implementation of generators producing circuits for bit addition and multiplication. The generators allow one to produce the corresponding circuits in two lines of code and to compare them to existing designs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.13966v1</guid>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>cs.LO</category>
      <pubDate>Thu, 18 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mikhail Goncharov, Alexander S. Kulikov, Georgie Levtsov</dc:creator>
    </item>
    <item>
      <title>Computational complexity of Berry phase estimation in topological phases of matter</title>
      <link>https://arxiv.org/abs/2509.13423</link>
      <description>arXiv:2509.13423v1 Announce Type: cross 
Abstract: The Berry phase is a fundamental quantity in the classification of topological phases of matter. In this paper, we present a new quantum algorithm and several complexity-theoretical results for the Berry phase estimation (BPE) problems. Our new quantum algorithm achieves BPE in a more general setting than previously known quantum algorithms, with a theoretical guarantee. For the complexity-theoretic results, we consider three cases. First, we prove $\mathsf{BQP}$-completeness when we are given a guiding state that has a large overlap with the ground state. This result establishes an exponential quantum speedup for estimating the Berry phase. Second, we prove $\mathsf{dUQMA}$-completeness when we have \textit{a priori} bound for ground state energy. Here, $\mathsf{dUQMA}$ is a variant of the unique witness version of $\mathsf{QMA}$ (i.e., $\mathsf{UQMA}$), which we introduce in this paper, and this class precisely captures the complexity of BPE without the known guiding state. Remarkably, this problem turned out to be the first natural problem contained in both $\mathsf{UQMA}$ and $\mathsf{co}$-$\mathsf{UQMA}$. Third, we show $\mathsf{P}^{\mathsf{dUQMA[log]}}$-hardness and containment in $\mathsf{P}^{\mathsf{PGQMA[log]}}$ when we have no additional assumption. These results advance the role of quantum computing in the study of topological phases of matter and provide a pathway for clarifying the connection between topological phases of matter and computational complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.13423v1</guid>
      <category>quant-ph</category>
      <category>cond-mat.str-el</category>
      <category>cs.CC</category>
      <pubDate>Thu, 18 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ryu Hayakawa, Kazuki Sakamoto, Chusei Kiumi</dc:creator>
    </item>
    <item>
      <title>Hardness of Dynamic Core and Truss Decompositions</title>
      <link>https://arxiv.org/abs/2509.13584</link>
      <description>arXiv:2509.13584v1 Announce Type: cross 
Abstract: The k-core of a graph is its maximal subgraph with minimum degree at least k, and the core value of a vertex u is the largest k for which u is contained in the k-core of the graph. Among cohesive subgraphs, k-core and its variants have received a lot of attention recently, particularly on dynamic graphs, as reported by Hanauer, Henzinger, and Schulz in their recent survey on dynamic graph algorithms. We answer questions on k-core stated in the survey, proving that there is no efficient dynamic algorithm for k-core or to find (2 - {\epsilon})-approximations for the core values, unless we can improve decade-long state-of-the-art algorithms in many areas including matrix multiplication and satisfiability, based on the established OMv and SETH conjectures. Some of our results show that there is no dynamic algorithm for k-core asymptotically faster than the trivial ones. This explains why most recent research papers in this area focus not on a generic efficient dynamic algorithm, but on finding a bounded algorithm, which is fast when few core values change per update. However, we also prove that such bounded algorithms do not exist, based on the OMv conjecture. We present lower bounds also for a directed version of the problem, and for the edge variant of the problem, known as k-truss. On the positive side, we present a polylogarithmic dynamic algorithm for 2-core.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.13584v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Thu, 18 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yan S. Couto, Cristina G. Fernandes</dc:creator>
    </item>
    <item>
      <title>4-uniform Maker-Breaker and Maker-Maker games are PSPACE-complete</title>
      <link>https://arxiv.org/abs/2509.13819</link>
      <description>arXiv:2509.13819v1 Announce Type: cross 
Abstract: We study two positional games where two players take turns picking a previously unpicked vertex of a hypergraph $H$. We say a player fills an edge of $H$ if that player has picked all the vertices of that edge. In the Maker-Maker game, whoever first fills an edge wins, or we get a draw if no edge is filled. In the Maker-Breaker game, the first player aims at filling an edge while the second player aims at preventing the first player from filling an edge. We show that, for both games, deciding whether the first player has a winning strategy is a PSPACE-complete problem even when restricted to 4-uniform hypergraphs. For the Maker-Maker game, this improves on a previous result for hypergraphs of rank 4. For the Maker-Breaker game, this improves on a previous result for 5-uniform hypergraphs, and closes the complexity gap as the problem for hypergraphs of rank 3 is known to be solvable in polynomial time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.13819v1</guid>
      <category>cs.DM</category>
      <category>cs.CC</category>
      <category>math.CO</category>
      <pubDate>Thu, 18 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Florian Galliot</dc:creator>
    </item>
    <item>
      <title>Computing shortest closed curves on non-orientable surfaces</title>
      <link>https://arxiv.org/abs/2403.11749</link>
      <description>arXiv:2403.11749v2 Announce Type: replace-cross 
Abstract: We initiate the study of computing shortest non-separating simple closed curves with some given topological properties on non-orientable surfaces. While, for orientable surfaces, any two non-separating simple closed curves are related by a self-homeomorphism of the surface, and computing shortest such curves has been vastly studied, for non-orientable ones the classification of non-separating simple closed curves up to ambient homeomorphism is subtler, depending on whether the curve is one-sided or two-sided, and whether it is orienting or not (whether it cuts the surface into an orientable one).
  We prove that computing a shortest orienting (weakly) simple closed curve on a non-orientable combinatorial surface is NP-hard but fixed-parameter tractable in the genus of the surface. In contrast, we can compute a shortest non-separating non-orienting (weakly) simple closed curve with given sidedness in $g^{O(1)}.n\log n$ time, where $g$ is the genus and $n$ the size of the surface.
  For these algorithms, we develop tools that can be of independent interest, to compute a variation on canonical systems of loops for non-orientable surfaces based on the computation of an orienting curve, and some covering spaces that are essentially quotients of homology covers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11749v2</guid>
      <category>cs.CG</category>
      <category>cs.CC</category>
      <category>math.GT</category>
      <pubDate>Thu, 18 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.20382/jocg.v16i2a8</arxiv:DOI>
      <arxiv:journal_reference>Journal of Computational Geometry 16 (2):237-264, 2025</arxiv:journal_reference>
      <dc:creator>Denys Bulavka, \'Eric Colin de Verdi\`ere, Niloufar Fuladi</dc:creator>
    </item>
    <item>
      <title>Parameterized Maximum Node-Disjoint Paths</title>
      <link>https://arxiv.org/abs/2404.14849</link>
      <description>arXiv:2404.14849v2 Announce Type: replace-cross 
Abstract: We revisit the Maximum Node-Disjoint Paths problem, the natural optimization version of Node-Disjoint Paths, where we are given a graph $G$, $k$ pairs of vertices $(s_i, t_i)$ and an integer $\ell$, and are asked whether there exist at least $\ell$ vertex-disjoint paths in $G$ whose endpoints are given pairs. We present several results, with an emphasis towards FPT approximation.
  Our main positive contribution is to show that the problem's intractability can be overcome using approximation and that for several of the structural parameters for which the problem is hard, most notably tree-depth, it admits an efficient FPT approximation scheme, returning a $(1-\varepsilon)$-approximate solution in time $f(td,\varepsilon)n^{O(1)}$. We manage to obtain these results by comprehensively mapping out the structural parameters for which the problem is FPT if $\ell$ is also a parameter, hence showing that understanding $\ell$ as a parameter is key to the problem's approximability. This, in turn, is a problem we are able to solve via a surprisingly simple color-coding algorithm, which relies on identifying an insightful problem-specific variant of the natural parameter, namely the number of vertices used in the solution.
  A natural question is whether the FPT approximation algorithm we devised for tree-depth can be extended to pathwidth. We resolve this negatively, showing that under the Parameterized Inapproximability Hypothesis no FPT approximation scheme for this parameter is possible, even in time $f(pw,\varepsilon)n^{g(\varepsilon)}$, thus precisely determining the parameter border where the problem transitions from ``hard but approximable'' to ``inapproximable''.
  Lastly, we strengthen existing lower bounds by replacing W[1]-hardness by XNLP-completeness for parameter pathwidth, and improving the $n^{o(\sqrt{td})}$ ETH-based lower bound for tree-depth to $n^{o(td)}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.14849v2</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Thu, 18 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael Lampis, Manolis Vasilakis</dc:creator>
    </item>
    <item>
      <title>Unconditionally separating noisy $\mathsf{QNC}^0$ from bounded polynomial threshold circuits of constant depth</title>
      <link>https://arxiv.org/abs/2408.16378</link>
      <description>arXiv:2408.16378v2 Announce Type: replace-cross 
Abstract: The rapid evolution of quantum devices fuels concerted efforts to experimentally establish quantum advantage over classical computing. Many demonstrations of quantum advantage, however, rely on computational assumptions and face verification challenges. Furthermore, steady advances in classical algorithms and machine learning make the issue of provable, practically demonstrable quantum advantage a moving target. In this work, we unconditionally demonstrate that parallel quantum computation can exhibit greater computational power than previously recognized. We prove that polynomial-size biased threshold circuits of constant depth -- which model neural networks with tunable expressivity -- fail to solve certain problems solvable by small constant-depth quantum circuits with local gates, for values of the bias that allow quantifiably large computational power. Additionally, we identify a family of problems that are solvable in constant depth by a universal quantum computer over prime-dimensional qudits with bounded connectivity, but remain hard for polynomial-size biased threshold circuits. We thereby bridge the foundational theory of non-local games in higher dimensions with computational advantage on emerging devices operating on a wide range of physical platforms. Finally, we show that these quantum advantages are robust to noise across all prime qudit dimensions with all-to-all connectivity, enhancing their practical appeal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.16378v2</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <pubDate>Thu, 18 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1038/s41467-025-58545-4</arxiv:DOI>
      <arxiv:journal_reference>Nat Commun 16, 3559 (2025)</arxiv:journal_reference>
      <dc:creator>Min-Hsiu Hsieh, Leandro Mendes, Michael de Oliveira, Sathyawageeswar Subramanian</dc:creator>
    </item>
    <item>
      <title>On estimating the trace of quantum state powers</title>
      <link>https://arxiv.org/abs/2410.13559</link>
      <description>arXiv:2410.13559v3 Announce Type: replace-cross 
Abstract: We investigate the computational complexity of estimating the trace of quantum state powers $\text{tr}(\rho^q)$ for an $n$-qubit mixed quantum state $\rho$, given its state-preparation circuit of size $\text{poly}(n)$. This quantity is closely related to and often interchangeable with the Tsallis entropy $\text{S}_q(\rho) = \frac{1-\text{tr}(\rho^q)}{q-1}$, where $q = 1$ corresponds to the von Neumann entropy. For any non-integer $q \geq 1 + \Omega(1)$, we provide a quantum estimator for $\text{S}_q(\rho)$ with time complexity $\text{poly}(n)$, exponentially improving the prior best results of $\exp(n)$ due to Acharya, Issa, Shende, and Wagner (ISIT 2019), Wang, Guan, Liu, Zhang, and Ying (TIT 2024), and Wang, Zhang, and Li (TIT 2024), and Wang and Zhang (ESA 2024). Our speedup is achieved by introducing efficiently computable uniform approximations of positive power functions into quantum singular value transformation.
  Our quantum algorithm reveals a sharp phase transition between the case of $q=1$ and constant $q&gt;1$ in the computational complexity of the Quantum $q$-Tsallis Entropy Difference Problem (TsallisQED$_q$), particularly deciding whether the difference $\text{S}_q(\rho_0) - \text{S}_q(\rho_1)$ is at least $0.001$ or at most $-0.001$:
  - For any $1+\Omega(1) \leq q \leq 2$, TsallisQED$_q$ is $\mathsf{BQP}$-complete, which implies that Purity Estimation is also $\mathsf{BQP}$-complete.
  - For any $1 \leq q \leq 1 + \frac{1}{n-1}$, TsallisQED$_q$ is $\mathsf{QSZK}$-hard, leading to hardness of approximating the von Neumann entropy because $\text{S}_q(\rho) \leq \text{S}(\rho)$, as long as $\mathsf{BQP} \subsetneq \mathsf{QSZK}$.
  The hardness results are derived from reductions based on new inequalities for the quantum $q$-Jensen-(Shannon-)Tsallis divergence with $1\leq q \leq 2$, which are of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.13559v3</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Thu, 18 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1137/1.9781611978322.28</arxiv:DOI>
      <arxiv:journal_reference>Proceedings of the 2025 Annual ACM-SIAM Symposium on Discrete Algorithms (SODA), pp. 947-993, 2025</arxiv:journal_reference>
      <dc:creator>Yupan Liu, Qisheng Wang</dc:creator>
    </item>
  </channel>
</rss>
