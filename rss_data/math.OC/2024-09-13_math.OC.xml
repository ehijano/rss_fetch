<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 13 Sep 2024 04:02:30 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Optimal Mechanisms for Demand Response: An Indifference Set Approach</title>
      <link>https://arxiv.org/abs/2409.07655</link>
      <description>arXiv:2409.07655v1 Announce Type: new 
Abstract: The time at which renewable (e.g., solar or wind) energy resources produce electricity cannot generally be controlled. In many settings, consumers have some flexibility in their energy consumption needs, and there is growing interest in demand-response programs that leverage this flexibility to shift energy consumption to better match renewable production -- thus enabling more efficient utilization of these resources. We study optimal demand response in a model where consumers operate home energy management systems (HEMS) that can compute the "indifference set" of energy-consumption profiles that meet pre-specified consumer objectives, receive demand-response signals from the grid, and control consumer devices within the indifference set. For example, if a consumer asks for the indoor temperature to remain between certain upper and lower bounds, a HEMS could time use of air conditioning or heating to align with high renewable production when possible. Here, we show that while price-based mechanisms do not in general achieve optimal demand response, i.e., dynamic pricing cannot induce HEMS to choose optimal demand consumption profiles within the available indifference sets, pricing is asymptotically optimal in a mean-field limit with a growing number of consumers. Furthermore, we show that large-sample optimal dynamic prices can be efficiently derived via an algorithm that only requires querying HEMS about their planned consumption schedules given different prices. We demonstrate our approach in a grid simulation powered by OpenDSS, and show that it achieves meaningful demand response without creating grid instability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.07655v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammad Mehrabi, Omer Karaduman, Stefan Wager</dc:creator>
    </item>
    <item>
      <title>Optimal control for coupled sweeping processes under minimal assumptions</title>
      <link>https://arxiv.org/abs/2409.07722</link>
      <description>arXiv:2409.07722v1 Announce Type: new 
Abstract: In this paper, the study of nonsmooth optimal control problems (P) involving a controlled sweeping process with three main characteristics is launched. First, the sweeping sets C(t) are nonsmooth, unbounded, time-dependent, uniformly prox-regular, and satisfy minimal assumptions. Second, the sweeping process is coupled with a controlled differential equation. Third, joint-state endpoints constraint set S, including periodic conditions, is present. The existence and uniqueness of a Lipschitz solution for our dynamic is established, the existence of an optimal solution for our general form of optimal control is obtained, and the full form of the nonsmooth Pontryagin maximum principle for strong local minimizers in (P) is derived under minimal hypotheses. One of the novelties of this paper is the idea to work with a well-constructed problem corresponding to truncated sweeping sets and joint endpoint constraints that shares the same strong local minimizer as (P) and for which the exponential-penalty approximation technique can be developed using only the assumptions on (P).</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.07722v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Samara Chamoun, Vera Zeidan</dc:creator>
    </item>
    <item>
      <title>Accelerated Multi-Time-Scale Stochastic Approximation: Optimal Complexity and Applications in Reinforcement Learning and Multi-Agent Games</title>
      <link>https://arxiv.org/abs/2409.07767</link>
      <description>arXiv:2409.07767v1 Announce Type: new 
Abstract: Multi-time-scale stochastic approximation is an iterative algorithm for finding the fixed point of a set of $N$ coupled operators given their noisy samples. It has been observed that due to the coupling between the decision variables and noisy samples of the operators, the performance of this method decays as $N$ increases. In this work, we develop a new accelerated variant of multi-time-scale stochastic approximation, which significantly improves the convergence rates of its standard counterpart. Our key idea is to introduce auxiliary variables to dynamically estimate the operators from their samples, which are then used to update the decision variables. These auxiliary variables help not only to control the variance of the operator estimates but also to decouple the sampling noise and the decision variables. This allows us to select more aggressive step sizes to achieve an optimal convergence rate. Specifically, under a strong monotonicity condition, we show that for any value of $N$ the $t^{\text{th}}$ iterate of the proposed algorithm converges to the desired solution at a rate $\widetilde{O}(1/t)$ when the operator samples are generated from a single from Markov process trajectory.
  A second contribution of this work is to demonstrate that the objective of a range of problems in reinforcement learning and multi-agent games can be expressed as a system of fixed-point equations. As such, the proposed approach can be used to design new learning algorithms for solving these problems. We illustrate this observation with numerical simulations in a multi-agent game and show the advantage of the proposed method over the standard multi-time-scale stochastic approximation algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.07767v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sihan Zeng, Thinh T. Doan</dc:creator>
    </item>
    <item>
      <title>Optimal Consumption for Recursive Preferences with Local Substitution under Risk</title>
      <link>https://arxiv.org/abs/2409.07799</link>
      <description>arXiv:2409.07799v1 Announce Type: new 
Abstract: We explore intertemporal preferences that are recursive and account for local intertemporal substitution. First, we establish a rigorous foundation for these preferences and analyze their properties. Next, we examine the associated optimal consumption problem, proving the existence and uniqueness of the optimal consumption plan. We present an infinite-dimensional version of the Kuhn-Tucker theorem, which provides the necessary and sufficient conditions for optimality. Additionally, we investigate quantitative properties and the construction of the optimal consumption plan. Finally, we offer a detailed description of the structure of optimal consumption within a geometric Poisson framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.07799v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hanwu Li, Frank Riedel</dc:creator>
    </item>
    <item>
      <title>Markovian Foundations for Quasi-Stochastic Approximation in Two Timescales: Extended Version</title>
      <link>https://arxiv.org/abs/2409.07842</link>
      <description>arXiv:2409.07842v1 Announce Type: new 
Abstract: Many machine learning and optimization algorithms can be cast as instances of stochastic approximation (SA). The convergence rate of these algorithms is known to be slow, with the optimal mean squared error (MSE) of order $O(n^{-1})$. In prior work it was shown that MSE bounds approaching $O(n^{-4})$ can be achieved through the framework of quasi-stochastic approximation (QSA); essentially SA with careful choice of deterministic exploration. These results are extended to two time-scale algorithms, as found in policy gradient methods of reinforcement learning and extremum seeking control. The extensions are made possible in part by a new approach to analysis, allowing for the interpretation of two timescale algorithms as instances of single timescale QSA, made possible by the theory of negative Lyapunov exponents for QSA. The general theory is illustrated with applications to extremum seeking control (ESC).</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.07842v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Caio Kalil Lauand, Sean Meyn</dc:creator>
    </item>
    <item>
      <title>A Lagrangian shape and topology optimization framework based on semi-discrete optimal transport</title>
      <link>https://arxiv.org/abs/2409.07873</link>
      <description>arXiv:2409.07873v1 Announce Type: new 
Abstract: This article revolves around shape and topology optimization, in the applicative context where the objective and constraint functionals depend on the solution to a physical boundary value problem posed on the optimized domain. We introduce a novel framework based on modern concepts from computational geometry, optimal transport and numerical analysis. Its pivotal feature is a representation of the optimized shape by the cells of an adapted version of a Laguerre diagram. Although such objects are originally described by a collection of seed points and weights, recent results from optimal transport theory suggest a more intuitive parametrization in terms of the seed points and measures of the associated cells. The polygonal mesh of the shape induced by this diagram serves as support for the deployment of the Virtual Element Method for the numerical solution of the physical boundary value problem at play and the calculation of the objective and constraint functionals. The sensitivities of the latter are derived next; at first, we calculate their derivatives with respect to the positions of the vertices of the Laguerre diagram by shape calculus techniques; a suitable adjoint methodology is then developed to express them in terms of the seed points and cell measures of the diagram. The evolution of the shape is realized by first updating the design variables according to these sensitivities and then reconstructing the diagram with efficient algorithms from computational geometry. Our shape optimization strategy is versatile: it can be applied to a wide gammut of physical situations. It is Lagrangian by essence, and it thereby benefits from all the assets of a consistently meshed representation of the shape. Yet, it naturally handles dramatic motions, including topological changes, in a very robust fashion. These features, among others, are illustrated by a series of 2d numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.07873v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Charles Dapogny, Bruno Levy, Edouard Oudet</dc:creator>
    </item>
    <item>
      <title>On an optimization model for firefighting helicopter planning</title>
      <link>https://arxiv.org/abs/2409.07937</link>
      <description>arXiv:2409.07937v1 Announce Type: new 
Abstract: During a wildfire, the work of the aerial coordinator is crucial for the control of the wildfire and the minimization of the burned area and the damage caused. Since it could be very useful for the coordinator to have decision-making tools at his/her disposal, this framework deals with an optimization model to obtain the optimal planning of firefighting helicopters, deciding the points where the aircraft should load water, the areas of the wildfire where they should work, and the rest bases to which each helicopter should be assigned. It was developed a Mixed Integer Linear Programming model which takes into account the configuration of helicopters, in closed circuits, as well as the flight aerial regulations in Spain. Due to the complexity of the model, two algorithms are developed, based on the Simulated Annealing and Iterated Local Search metaheuristic techniques. Both algorithms are tested with real data instances, obtaining very promising results for future application in the planning of aircraft throughout a wildfire evolution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.07937v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Marta Rodr\'iguez Barreiro, Mar\'ia Jos\'e Ginzo Villamayor, Fernando P\'erez Porras, Mar\'ia Luisa Carpente Rodr\'iguez, Silvia Mar\'ia Lorenzo Freire</dc:creator>
    </item>
    <item>
      <title>Duality theory in linear optimization and its extensions -- formally verified</title>
      <link>https://arxiv.org/abs/2409.08119</link>
      <description>arXiv:2409.08119v1 Announce Type: new 
Abstract: Farkas established that a system of linear inequalities has a solution if and only if we cannot obtain a contradiction by taking a linear combination of the inequalities. We state and formally prove several Farkas-like theorems over linearly ordered fields in Lean 4. Furthermore, we extend duality theory to the case when some coefficients are allowed to take ``infinite values''.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08119v1</guid>
      <category>math.OC</category>
      <category>cs.LO</category>
      <pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Martin Dvorak, Vladimir Kolmogorov</dc:creator>
    </item>
    <item>
      <title>How can the tragedy of the commons be prevented?: Introducing Linear Quadratic Mixed Mean Field Games</title>
      <link>https://arxiv.org/abs/2409.08235</link>
      <description>arXiv:2409.08235v1 Announce Type: new 
Abstract: In a regular mean field game (MFG), the agents are assumed to be insignificant, they do not realize their effect on the population level and this may result in a phenomenon coined as the Tragedy of the Commons by the economists. However, in real life this phenomenon is often avoided thanks to the underlying altruistic behavior of (all or some of the) agents. Motivated by this observation, we introduce and analyze two different mean field models to include altruism in the decision making of agents. In the first model, mixed individual MFGs, there are infinitely many agents who are partially altruistic (i.e., they behave partially cooperatively) and partially non-cooperative. In the second model, mixed population MFGs, one part of the population behaves cooperatively and the remaining agents behave non-cooperatively. Both models are introduced in a general linear quadratic framework for which we characterize the equilibrium via forward backward stochastic differential equations. Furthermore, we give explicit solutions in terms of ordinary differential equations, and prove the existence and uniqueness results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08235v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gokce Dayanikli, Mathieu Lauriere</dc:creator>
    </item>
    <item>
      <title>Multi-period railway line planning for integrated passenger-freight transportation</title>
      <link>https://arxiv.org/abs/2409.08256</link>
      <description>arXiv:2409.08256v1 Announce Type: new 
Abstract: This paper addresses a multi-period line planning problem in an integrated passenger-freight railway system, aiming to maximize profit while serving passengers and freight using a combination of dedicated passenger trains, dedicated freight trains, and mixed trains. To accommodate demand with different time sensitivities, we develop a period-extended change&amp;go-network that tracks the paths taken by passengers and freight. The problem is formulated as a path-based mixed integer programming model, with the linear relaxation solved using column generation. Paths for passengers and freight are dynamically generated by solving pricing problems defined as elementary shortest-path problems with duration constraints. We propose two heuristic approaches: price-and-branch and a diving heuristic, with acceleration strategies, to find integer feasible solutions efficiently. Computational experiments on the Chinese high-speed railway network demonstrate that the diving heuristic outperforms the price-and-branch heuristic in both computational time and solution quality. Additionally, the experiments highlight the benefits of integrating freight, the advantages of multi-period line planning, and the impact of different demand patterns on line operations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08256v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wanru Chen, Rolf N. van Lieshout, Dezhi Zhang, Tom Van Woensel</dc:creator>
    </item>
    <item>
      <title>Self-Supervised Learning of Iterative Solvers for Constrained Optimization</title>
      <link>https://arxiv.org/abs/2409.08066</link>
      <description>arXiv:2409.08066v1 Announce Type: cross 
Abstract: Obtaining the solution of constrained optimization problems as a function of parameters is very important in a multitude of applications, such as control and planning. Solving such parametric optimization problems in real time can present significant challenges, particularly when it is necessary to obtain highly accurate solutions or batches of solutions. To solve these challenges, we propose a learning-based iterative solver for constrained optimization which can obtain very fast and accurate solutions by customizing the solver to a specific parametric optimization problem. For a given set of parameters of the constrained optimization problem, we propose a first step with a neural network predictor that outputs primal-dual solutions of a reasonable degree of accuracy. This primal-dual solution is then improved to a very high degree of accuracy in a second step by a learned iterative solver in the form of a neural network. A novel loss function based on the Karush-Kuhn-Tucker conditions of optimality is introduced, enabling fully self-supervised training of both neural networks without the necessity of prior sampling of optimizer solutions. The evaluation of a variety of quadratic and nonlinear parametric test problems demonstrates that the predictor alone is already competitive with recent self-supervised schemes for approximating optimal solutions. The second step of our proposed learning-based iterative constrained optimizer achieves solutions with orders of magnitude better accuracy than other learning-based approaches, while being faster to evaluate than state-of-the-art solvers and natively allowing for GPU parallelization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08066v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lukas L\"uken, Sergio Lucia</dc:creator>
    </item>
    <item>
      <title>Learning incomplete factorization preconditioners for GMRES</title>
      <link>https://arxiv.org/abs/2409.08262</link>
      <description>arXiv:2409.08262v1 Announce Type: cross 
Abstract: In this paper, we develop a data-driven approach to generate incomplete LU factorizations of large-scale sparse matrices. The learned approximate factorization is utilized as a preconditioner for the corresponding linear equation system in the GMRES method. Incomplete factorization methods are one of the most commonly applied algebraic preconditioners for sparse linear equation systems and are able to speed up the convergence of Krylov subspace methods. However, they are sensitive to hyper-parameters and might suffer from numerical breakdown or lead to slow convergence when not properly applied. We replace the typically hand-engineered algorithms with a graph neural network based approach that is trained against data to predict an approximate factorization. This allows us to learn preconditioners tailored for a specific problem distribution. We analyze and empirically evaluate different loss functions to train the learned preconditioners and show their effectiveness to decrease the number of GMRES iterations and improve the spectral properties on our synthetic dataset. The code is available at https://github.com/paulhausner/neural-incomplete-factorization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08262v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Paul H\"ausner, Aleix Nieto Juscafresa, Jens Sj\"olund</dc:creator>
    </item>
    <item>
      <title>Finite Codimensionality Method in Infinite-dimensional Optimization Problems</title>
      <link>https://arxiv.org/abs/2102.00652</link>
      <description>arXiv:2102.00652v4 Announce Type: replace 
Abstract: This paper is devoted to establishing an enhanced Fritz John type first-order necessary condition for a general constrained nonlinear infinite-dimensional optimization problem. Unlike traditional constraint qualifications in optimization theory, a condition of finite codimensionality is employed to ensure the existence of nontrivial Lagrange multipliers. As applications, first-order necessary conditions for optimal control problems of some deterministic/stochastic control systems are derived in a unified manner. Compared with the existing constraint qualifications, the finite codimensionality condition, which is equivalent to some suitable {\it a priori} estimates, can offer a more straightforward verification process in these applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2102.00652v4</guid>
      <category>math.OC</category>
      <pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xu Liu, Qi L\"u, Haisen Zhang, Xu Zhang</dc:creator>
    </item>
    <item>
      <title>Continuous iterative algorithms for anti-Cheeger cut</title>
      <link>https://arxiv.org/abs/2103.10705</link>
      <description>arXiv:2103.10705v2 Announce Type: replace 
Abstract: As a judicious correspondence to the classical maxcut, the anti-Cheeger cut has more balanced structure, but few numerical results on it have been reported so far. In this paper, we propose a continuous iterative algorithm (CIA) for the anti-Cheeger cut problem through fully using an equivalent continuous formulation. It does not need rounding at all and has advantages that all subproblems have explicit analytic solutions, the objective function values are monotonically updated and the iteration points converge to a local optimum in finite steps via an appropriate subgradient selection. It can also be easily combined with the maxcut iterations for breaking out of local optima and improving the solution quality thanks to the similarity between the anti-Cheeger cut problem and the maxcut problem. The performance of CIAs is fully demonstrated through numerical experiments on G-set from two aspects: one is on the solution quality where we find that the approximate solutions obtained by CIAs are of comparable quality to those by the multiple search operator heuristic method; the other is on the computational cost where we show that CIAs always run faster than the often-used continuous iterative algorithm based on the rank-two relaxation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2103.10705v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.CO</category>
      <category>math.NA</category>
      <pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sihong Shao, Chuan Yang</dc:creator>
    </item>
    <item>
      <title>Golf Strategy Optimization and the Value of Golf Skills</title>
      <link>https://arxiv.org/abs/2309.00485</link>
      <description>arXiv:2309.00485v2 Announce Type: replace 
Abstract: This study investigates strategic considerations in professional golf's Stroke Play format. We develop a Markov Decision Process (MDP) model, specifically a stochastic shortest path model, to optimize a golfer's strategy for any golf course. The model integrates golf course layout details and player skills. We demonstrate this approach using Professional Golfers' Association Tour data and aerial views of golf courses. To the best of our knowledge, this is the first exact, data-driven approach for golf strategy optimization in the literature. While MDPs are commonly used for sport strategy optimization, scaling this approach to golf poses a challenge due to the curse of dimensionality. Our primary objective is to prove that an exact approach is computationally feasible for such large-scale problems, provided that low-level coding and meticulous code optimization are employed. Furthermore, we illustrate how this framework could be used to determine which aspects of a player's game should be prioritized for improvement and challenge the "Drive for show, putt for dough adage". Additionally, we demonstrate how our methodology can be used to quantify the value of different golf skills.To ensure replicability and facilitate the adaptation and extension of our methodology, we provide open access to all our codes and analyses (in R and C++).</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.00485v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gautier Stauffer, Matthieu Guillot</dc:creator>
    </item>
    <item>
      <title>The Computational Complexity of Finding Stationary Points in Non-Convex Optimization</title>
      <link>https://arxiv.org/abs/2310.09157</link>
      <description>arXiv:2310.09157v2 Announce Type: replace 
Abstract: Finding approximate stationary points, i.e., points where the gradient is approximately zero, of non-convex but smooth objective functions $f$ over unrestricted $d$-dimensional domains is one of the most fundamental problems in classical non-convex optimization. Nevertheless, the computational and query complexity of this problem are still not well understood when the dimension $d$ of the problem is independent of the approximation error. In this paper, we show the following computational and query complexity results:
  1. The problem of finding approximate stationary points over unrestricted domains is PLS-complete.
  2. For $d = 2$, we provide a zero-order algorithm for finding $\varepsilon$-approximate stationary points that requires at most $O(1/\varepsilon)$ value queries to the objective function.
  3. We show that any algorithm needs at least $\Omega(1/\varepsilon)$ queries to the objective function and/or its gradient to find $\varepsilon$-approximate stationary points when $d=2$. Combined with the above, this characterizes the query complexity of this problem to be $\Theta(1/\varepsilon)$.
  4. For $d = 2$, we provide a zero-order algorithm for finding $\varepsilon$-KKT points in constrained optimization problems that requires at most $O(1/\sqrt{\varepsilon})$ value queries to the objective function. This closes the gap between the works of Bubeck and Mikulincer [2020] and Vavasis [1993] and characterizes the query complexity of this problem to be $\Theta(1/\sqrt{\varepsilon})$.
  5. Combining our results with the recent result of Fearnley et al. [2022], we show that finding approximate KKT points in constrained optimization is reducible to finding approximate stationary points in unconstrained optimization but the converse is impossible.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.09157v2</guid>
      <category>math.OC</category>
      <category>cs.CC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexandros Hollender, Manolis Zampetakis</dc:creator>
    </item>
    <item>
      <title>On Time-Inconsistency in Mean Field Games</title>
      <link>https://arxiv.org/abs/2312.07770</link>
      <description>arXiv:2312.07770v2 Announce Type: replace 
Abstract: We investigate an infinite-horizon time-inconsistent mean-field game (MFG) in a discrete time setting. We first present a classic equilibrium for the MFG and its associated existence result. This classic equilibrium aligns with the conventional equilibrium concept studied in MFG literature when the context is time-consistent. Then we demonstrate that while this equilibrium produces an approximate optimal strategy when applied to the related $N$-agent games, it does so solely in a precommitment sense. Therefore, it cannot function as a genuinely approximate equilibrium strategy from the perspective of a sophisticated agent within the $N$-agent game. To address this limitation, we propose a new consistent equilibrium concept in both the MFG and the $N$-agent game. We show that a consistent equilibrium in the MFG can indeed function as an approximate consistent equilibrium in the $N$-agent game. Additionally, we analyze the convergence of consistent equilibria for $N$-agent games toward a consistent MFG equilibrium as $N$ tends to infinity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.07770v2</guid>
      <category>math.OC</category>
      <category>cs.GT</category>
      <category>math.PR</category>
      <pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Erhan Bayraktar, Zhenhua Wang</dc:creator>
    </item>
    <item>
      <title>Randomized Feasibility-Update Algorithms for Variational Inequality Problems</title>
      <link>https://arxiv.org/abs/2402.05462</link>
      <description>arXiv:2402.05462v3 Announce Type: replace 
Abstract: This paper considers a variational inequality (VI) problem arising from a game among multiple agents, where each agent aims to minimize its own cost function subject to its constrained set represented as the intersection of a (possibly infinite) number of convex functional level sets. A direct projection-based approach or Lagrangian-based techniques for such a problem can be computationally expensive if not impossible to implement. To deal with the problem, we consider randomized methods that avoid the projection step on the whole constraint set by employing random feasibility updates. In particular, we propose and analyze such random methods for solving VIs based on the projection method, Korpelevich method, and Popov method. We establish the almost sure convergence of the methods and, also, provide their convergence rate guarantees. We illustrate the performance of the methods in simulations for two-agent games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.05462v3</guid>
      <category>math.OC</category>
      <pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Abhishek Chakraborty, Angelia Nedi\'c</dc:creator>
    </item>
    <item>
      <title>Regret Minimization in Scalar, Static, Non-linear Optimization Problems</title>
      <link>https://arxiv.org/abs/2403.15344</link>
      <description>arXiv:2403.15344v2 Announce Type: replace 
Abstract: We study the problem of determining an effective exploration strategy in static and non-linear optimization problems, which depend on an unknown scalar parameter to be learned from online collected noisy data. An optimal trade-off between exploration and exploitation is crucial for effective optimization under uncertainties, and to achieve this we consider a cumulative regret minimization approach over a finite horizon, with each time instant in the horizon characterized by a stochastic exploration signal, whose variance is to be designed. We aim to extend the well-established concepts of regret minimization from linear to non-linear systems, with a focus on the subsequent conceptual differences and challenges. Thus, under an idealized assumption on an appropriately defined information function associated with the excitation, we are able to show that an optimal exploration strategy is either to use no exploration at all (called lazy exploration) or adding an exploration excitation only at the first time instant of the horizon (called immediate exploration). A quadratic numerical example is presented to demonstrate the effectiveness of the proposed strategy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15344v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Ying Wang, Mirko Pasquini, K\'evin Colin, H{\aa}kan Hjalmarsson</dc:creator>
    </item>
    <item>
      <title>GPU-accelerated dynamic nonlinear optimization with ExaModels and MadNLP</title>
      <link>https://arxiv.org/abs/2403.15913</link>
      <description>arXiv:2403.15913v2 Announce Type: replace 
Abstract: We investigate the potential of Graphics Processing Units (GPUs) to solve large-scale nonlinear programs with a dynamic structure. Using ExaModels, a GPU-accelerated automatic differentiation tool, and the interior-point solver MadNLP, we significantly reduce the time to solve dynamic nonlinear optimization problems. The sparse linear systems formulated in the interior-point method is solved on the GPU using a hybrid solver combining an iterative method with a sparse Cholesky factorization, which harness the newly released NVIDIA cuDSS solver. Our results on the classical distillation column instance show that despite a significant pre-processing time, the hybrid solver allows to reduce the time per iteration by a factor of 25 for the largest instance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15913v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fran\c{c}ois Pacaud, Sungho Shin</dc:creator>
    </item>
    <item>
      <title>Online Feedback Optimization over Networks: A Distributed Model-free Approach</title>
      <link>https://arxiv.org/abs/2403.19834</link>
      <description>arXiv:2403.19834v2 Announce Type: replace 
Abstract: Online feedback optimization (OFO) enables optimal steady-state operations of a physical system by employing an iterative optimization algorithm as a dynamic feedback controller. When the plant consists of several interconnected sub-systems, centralized implementations become impractical due to the heavy computational burden and the need to pre-compute system-wide sensitivities, which may not be easily accessible in practice. Motivated by these challenges, we develop a fully distributed model-free OFO controller, featuring consensus-based tracking of the global objective value and local iterative (projected) updates that use stochastic gradient estimates. We characterize how the closed-loop performance depends on the size of the network, the number of iterations, and the level of accuracy of consensus. Numerical simulations on a voltage control problem in a direct current power grid corroborate the theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.19834v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenbin Wang, Zhiyu He, Giuseppe Belgioioso, Saverio Bolognani, Florian D\"orfler</dc:creator>
    </item>
    <item>
      <title>Wiener Chaos in Kernel Regression: Towards Untangling Aleatoric and Epistemic Uncertainty</title>
      <link>https://arxiv.org/abs/2312.07387</link>
      <description>arXiv:2312.07387v2 Announce Type: replace-cross 
Abstract: Gaussian Processes (GPs) are a versatile method that enables different approaches towards learning for dynamics and control. Gaussianity assumptions appear in two dimensions in GPs: The positive semi-definite kernel of the underlying reproducing kernel Hilbert space is used to construct the co-variance of a Gaussian distribution over functions, while measurement noise (i.e. data corruption) is usually modeled as i.i.d. additive Gaussians. In this note, we generalize the setting and consider kernel ridge regression with additive i.i.d. non-Gaussian measurement noise. To apply the usual kernel trick, we rely on the representation of the uncertainty via polynomial chaos expansions, which are series expansions for random variables of finite variance introduced by Norbert Wiener. We derive and discuss the analytic $\mathcal{L}^2$ solution to the arising Wiener kernel regression. Considering a polynomial dynamic system as a numerical example, we show that our approach allows us to distinguish the uncertainty that stems from the noise in the data samples from the total uncertainty encoded in the GP posterior distribution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.07387v2</guid>
      <category>stat.ML</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>T. Faulwasser, O. Molodchyk</dc:creator>
    </item>
    <item>
      <title>Network-Aware and Welfare-Maximizing Dynamic Pricing for Energy Sharing</title>
      <link>https://arxiv.org/abs/2404.02458</link>
      <description>arXiv:2404.02458v2 Announce Type: replace-cross 
Abstract: The proliferation of behind-the-meter (BTM) distributed energy resources (DER) within the electrical distribution network presents significant supply and demand flexibilities, but also introduces operational challenges such as voltage spikes and reverse power flows. In response, this paper proposes a network-aware dynamic pricing framework tailored for energy-sharing coalitions that aggregate small, but ubiquitous, BTM DER downstream of a distribution system operator's (DSO) revenue meter that adopts a generic net energy metering (NEM) tariff. By formulating a Stackelberg game between the energy-sharing market leader and its prosumers, we show that the dynamic pricing policy induces the prosumers toward a network-safe operation and decentrally maximizes the energy-sharing social welfare. The dynamic pricing mechanism involves a combination of a locational ex-ante dynamic price and an ex-post allocation, both of which are functions of the energy sharing's BTM DER. The ex-post allocation is proportionate to the price differential between the DSO NEM price and the energy-sharing locational price. Simulation results using real DER data and the IEEE 13-bus test systems illustrate the dynamic nature of network-aware pricing at each bus, and its impact on voltage.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02458v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>63rd IEEE Conference on Decision and Control, Milano, Italy, 2024</arxiv:journal_reference>
      <dc:creator>Ahmed S. Alahmed, Guido Cavraro, Andrey Bernstein, Lang Tong</dc:creator>
    </item>
    <item>
      <title>All convex bodies are in the subdifferential of some everywhere differentiable locally Lipschitz function</title>
      <link>https://arxiv.org/abs/2405.09206</link>
      <description>arXiv:2405.09206v2 Announce Type: replace-cross 
Abstract: We construct a differentiable locally Lipschitz function $f$ in $\mathbb{R}^{N}$ with the property that for every convex body $K\subset \mathbb{R}^N$ there exists $\bar x \in \mathbb{R}^N$  such that $K$ coincides with the set $\partial_L f(\bar x)$ of limits of derivatives $\{Df(x_n)\}_{n\geq 1}$ of sequences $\{x_n\}_{n\geq 1}$ converging to~$\bar x$. The technique can be further refined to recover all compact connected subsets with nonempty interior, disclosing an important difference between differentiable and continuously differentiable functions. It stems out from our approach that the class of these pathological functions contains an infinite dimensional vector space and is dense in the space of all locally Lipschitz functions for the uniform convergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.09206v2</guid>
      <category>math.CA</category>
      <category>math.FA</category>
      <category>math.OC</category>
      <pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aris Daniilidis (TU Wien), Robert Deville (IMB), Sebastian Tapia-Garcia (TU Wien)</dc:creator>
    </item>
  </channel>
</rss>
