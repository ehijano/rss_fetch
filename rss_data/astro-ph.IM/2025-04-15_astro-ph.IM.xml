<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>astro-ph.IM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/astro-ph.IM</link>
    <description>astro-ph.IM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/astro-ph.IM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 16 Apr 2025 04:00:02 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>LCDC: Bridging Science and Machine Learning for Light Curve Analysis</title>
      <link>https://arxiv.org/abs/2504.10550</link>
      <description>arXiv:2504.10550v1 Announce Type: new 
Abstract: The characterization and analysis of light curves are vital for understanding the physical and rotational properties of artificial space objects such as satellites, rocket stages, and space debris. This paper introduces the Light Curve Dataset Creator (LCDC), a Python-based toolkit designed to facilitate the preprocessing, analysis, and machine learning applications of light curve data. LCDC enables seamless integration with publicly available datasets, such as the newly introduced Mini Mega Tortora (MMT) database. Moreover, it offers data filtering, transformation, as well as feature extraction tooling. To demonstrate the toolkit's capabilities, we created the first standardized dataset for rocket body classification, RoBo6, which was used to train and evaluate several benchmark machine learning models, addressing the lack of reproducibility and comparability in recent studies. Furthermore, the toolkit enables advanced scientific analyses, such as surface characterization of the Atlas 2AS Centaur and the rotational dynamics of the Delta 4 rocket body, by streamlining data preprocessing, feature extraction, and visualization. These use cases highlight LCDC's potential to advance space debris characterization and promote sustainable space exploration. Additionally, they highlight the toolkit's ability to enable AI-focused research within the space debris community.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.10550v1</guid>
      <category>astro-ph.IM</category>
      <category>astro-ph.EP</category>
      <category>cs.LG</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniel Kyselica, Tom\'a\v{s} Hrob\'ar, Ji\v{r}\'i \v{S}ilha, Roman \v{D}urikovi\v{c}, Marek \v{S}uppa</dc:creator>
    </item>
    <item>
      <title>Inferring the Hubble Constant Using Simulated Strongly Lensed Supernovae and Neural Network Ensembles</title>
      <link>https://arxiv.org/abs/2504.10553</link>
      <description>arXiv:2504.10553v1 Announce Type: new 
Abstract: Strongly lensed supernovae are a promising new probe to obtain independent measurements of the Hubble constant (${H_0}$). In this work, we employ simulated gravitationally lensed Type Ia supernovae (glSNe Ia) to train our machine learning (ML) pipeline to constrain $H_0$. We simulate image time-series of glSNIa, as observed with the upcoming Nancy Grace Roman Space Telescope, that we employ for training an ensemble of five convolutional neural networks (CNNs). The outputs of this ensemble network are combined with a simulation-based inference (SBI) framework to quantify the uncertainties on the network predictions and infer full posteriors for the $H_0$ estimates. We illustrate that the combination of multiple glSN systems enhances constraint precision, providing a $4.4\%$ estimate of $H_0$ based on 100 simulated systems, which is in agreement with the ground truth. This research highlights the potential of leveraging the capabilities of ML with glSNe systems to obtain a pipeline capable of fast and automated $H_0$ measurements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.10553v1</guid>
      <category>astro-ph.IM</category>
      <category>astro-ph.CO</category>
      <category>cs.LG</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gon\c{c}alo Gon\c{c}alves, Nikki Arendse, Doogesh Kodi Ramanah, Rados{\l}aw Wojtak</dc:creator>
    </item>
    <item>
      <title>Cataclysmic Variable Candidates Identified in eROSITA-DE DR1,XMM-Newton, Swift, and ROSAT Catalogs</title>
      <link>https://arxiv.org/abs/2504.10794</link>
      <description>arXiv:2504.10794v1 Announce Type: new 
Abstract: Cataclysmic variables (CVs), binary systems with a white dwarf accreting from a low-mass star, are significant Galactic X-ray sources. We present a systematic search for X-ray emitting CV candidates by cross-matching four X-ray catalogs (eROSITA, XMM-Newton, Swift, and ROSAT) with Gaia sources located in the bridge region between the main sequence and white dwarf cooling sequence in the Hertzsprung-Russell diagram. From 444 candidates (267 confirmed CVs and 177 new candidates), we detect orbital modulation in 56 sources using ZTF/TESS light curves. The eROSITA catalog contributes 51% of candidates, outperforming other surveys due to its wider sky coverage and higher sensitivity (~10^{-14} erg cm^{-2} s^{-1}). Our method demonstrates the efficiency of combining X-ray data with time-domain analysis for CV identification, with future eROSITA observations expected to expand the population of X-ray emitting CVs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.10794v1</guid>
      <category>astro-ph.IM</category>
      <category>astro-ph.HE</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiangxiang Wang, Jumpei Takata</dc:creator>
    </item>
    <item>
      <title>Design and Fabrication of a lightweight three-lens corrector system for the 2.34-m Vainu Bappu Telescope</title>
      <link>https://arxiv.org/abs/2504.10872</link>
      <description>arXiv:2504.10872v1 Announce Type: new 
Abstract: The Vainu Bappu Telescope (VBT) is a 2.34-m reflector, primarily supported on-axis field of view, offering high-resolution and low-to-medium resolution spectroscopic observations in its prime and Cassegrain configurations. This study presents the design and fabrication of a compact, lightweight, three-element wide-field corrector (WFC) utilizing three spherical lenses to cover a polychromatic wavelength range over a 30$'$ FoV at prime focus. The WFC design was optimized using ZEMAX, ensuring precision in aberrations, tolerances, and atmospheric dispersion. The fabricated lenses met stringent tolerances, with a $\pm$1 mm deviation in radius of curvature and 2 mm deviation in center thickness. A mechanical mount was developed to integrate all the WFC lenses, and wavefront error testing for the WFC system was performed using ZYGO interferometry, yielding a Wavefront Error of 0.05 $\lambda$. Laboratory performance tests were designed and conducted using a dedicated setup with achromatic lenses and 100 $\mu m$ fiber-coupled polychromatic light source showed a deviation of 0.1 pixel on-axis and 0.5 pixel at the extreme off-axis field compared to the ZEMAX design, demonstrating that the optical performance of WFC is with minimal aberrations across the entire FoV. The successful integration of the WFC at the VBT prime focus will increase the FoV, enabling the multi-fiber, multi-spectrograph setup in 30 arcmin field that will facilitate both OMR and Echelle spectrograph to be used on the same night along with the addition of new multi-object spectrograph and an integral field unit instrument. This will mark a significant upgrade for the VBT, broadening its research potential, and expanding its observational versatility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.10872v1</guid>
      <category>astro-ph.IM</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nitish Singh, S. Sriram, Ramya Sethuram, Bharat Kumar Yerra, Rahuldeb Burman, G. Nataraj, C Chethan, P. Madan Mohan Kemkar, K Sagayanathan, Saikat Das, Francis Xavier Rozario J</dc:creator>
    </item>
    <item>
      <title>A Highly Efficient Cross-matching Scheme using Learned Index Structure</title>
      <link>https://arxiv.org/abs/2504.10931</link>
      <description>arXiv:2504.10931v1 Announce Type: new 
Abstract: Spatial data fusion is a bottleneck when it meets the scale of 10 billion records. Cross-matching celestial catalogs is just one example of this. To challenge this, we present a framework that enables efficient cross-matching using Learned Index Structures. Our approach involves a data transformation method to map multi-dimensional data into easily learnable distributions, coupled with a novel search algorithm that leverages the advantages of model pairs, significantly enhancing the efficiency of nearest-neighbor search. In this study, we utilized celestial catalog data derived from astronomical surveys to construct the index and evaluated the speed of the cross-matching process. Using the HEALPix segmentation scheme, we built an independent model object for each tile and developed an end-to-end pipeline to construct a framework with semantic guarantees for record retrieval in query and range search. Our results show that the proposed method improves cross-matching speed by more than four times compared to KD-trees for a radius range between 1 milli-arcseconds and 100 arcseconds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.10931v1</guid>
      <category>astro-ph.IM</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Phu-Minh Lam, Dongwei Fan, Hongbo Wei, Jun Wang, Yu Zhou, Qi Ma, Baolong Zhang, Xiazhao Zhang, Yongheng Wang</dc:creator>
    </item>
    <item>
      <title>Extended source fringe flats for the JWST MIRI Medium Resolution Spectrometer</title>
      <link>https://arxiv.org/abs/2504.11328</link>
      <description>arXiv:2504.11328v1 Announce Type: new 
Abstract: The detectors of the JWST Mid-Infrared Instrument (MIRI) Medium Resolution Spectrometer (MRS) form low-finesse resonating cavities that cause periodic count rate modulations (fringes) with peak amplitudes of up to 15% for sources external to MIRI. To detect weak features on a strong continuum and reliably measure line fluxes and line-flux ratios, fringe correction is crucial. This paper describes the first of two steps implemented in the JWST Science Calibration Pipeline, which is the division by a static fringe flat that removes the bulk of the fringes for extended sources. Fringe flats were derived by fitting a numerical model to observations of spatially extended sources. The model includes fringes that originate from two resonating cavities in the detector substrate (a third fringe component that originates from the dichroic filters is not included). The model, numerical implementation, and resulting fringe flats are described, and the efficiency of the calibration was evaluated for sources of various spatial extents on the detector. Flight fringe flats are obtained from observations of the planetary nebula NGC 7027. The two fringe components are well recovered and fitted by the model. The derived parameters are used to build a fringe flat for each MRS spectral band, except for 1A and 1B due to the low signal-to-noise ratio of NGC 7027 in these bands. When applied to extended sources, fringe amplitudes are reduced to the sub-percent level on individual spaxels. For point sources, they are reduced to amplitudes of 1 to 5% considering individual spaxels and a single dither position, and decrease to the 1 to 2% level after two-dimensional residual fringe correction. The fringe flats derived from this work are the reference files currently in use by the JWST Science Calibration Pipeline. They provide an efficient calibration for extended sources, and are less efficient for point sources.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.11328v1</guid>
      <category>astro-ph.IM</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>N. Crouzet, M. Mueller, B. Sargent, F. Lahuis, D. Kester, G. Yang, I. Argyriou, D. Gasman, P. J. Kavanagh, A. Labiano, K. Larson, D. R. Law, J. \'Alvarez-M\'arquez, B. R. Brandl, A. Glasse, P. Patapis, P. R. Roelfsema, {\L}. Tychoniec, E. F. van Dishoeck, G. S. Wright</dc:creator>
    </item>
    <item>
      <title>Mitigating Eddington and Malmquist Biases in Latent-Inclination Regression of the Tully-Fisher Relation</title>
      <link>https://arxiv.org/abs/2504.10589</link>
      <description>arXiv:2504.10589v1 Announce Type: cross 
Abstract: Precise estimation of the Tully-Fisher relation is compromised by statistical biases and uncertain inclination corrections. To account for selection effects (Malmquist bias) while avoiding individual inclination corrections, I introduce a Bayesian method based on likelihood functions that incorporate Sine-distributed scatter of rotation velocities, Gaussian scatter from intrinsic dispersion and measurement error, and the observational selection function. However, tests of unidirectional models on simulated datasets reveal an additional bias arising from neglect of the Gaussian scatter in the independent variable. This additional bias is identified as a generalized Eddington bias, which distorts the data distribution independently of Malmuqist bias. I introduce two extensions to the Bayesian method that successfully mitigate the Eddington bias: (1) analytical bias corrections of the dependent variable prior to likelihood computation, and (2) a bidirectional dual-scatter model that includes the Gaussian scatter of the independent variable in the likelihood function. By rigorously accounting for Malmquist and Eddington biases in a latent-inclination regression analysis, this work establishes a framework for unbiased distance estimates from standardizable candles, critical for improving determinations of the Hubble constant.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.10589v1</guid>
      <category>stat.ME</category>
      <category>astro-ph.GA</category>
      <category>astro-ph.IM</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hai Fu</dc:creator>
    </item>
    <item>
      <title>PALACE v1.0: Paranal Airglow Line And Continuum Emission model</title>
      <link>https://arxiv.org/abs/2504.10683</link>
      <description>arXiv:2504.10683v1 Announce Type: cross 
Abstract: Below about 2.3 $\mu$m, the nighttime emission of the Earth's atmosphere is dominated by non-thermal radiation from the mesosphere and thermosphere. As this airglow can even outshine scattered moonlight in the near-infrared regime, the understanding of the Earth's night-sky brightness requires good knowledge of the complex airglow emission spectrum and its variability. As airglow modelling is very challenging, the comprehensive characterisation of airglow emission requires large data sets of empirical data. For fixed locations, this can be best achieved by archived spectra of large astronomical telescopes with a wide wavelength coverage, high spectral resolving power, and good temporal sampling. Using 10 years of data from the X-shooter echelle spectrograph in the wavelength range from 0.3 to 2.5 $\mu$m and additional data from the Ultraviolet and Visual Echelle Spectrograph at the Very Large Telescope at Cerro Paranal in Chile, we have succeeded to build a comprehensive spectroscopic airglow model for this low-latitude site under consideration of theoretical data from the HITRAN database for molecules and from different sources for atoms. The Paranal Airglow Line And Continuum Emission (PALACE) model comprises 9 chemical species, 26,541 emission lines, and 3 unresolved continuum components. Moreover, there are climatologies of relative intensity, solar cycle effect, and residual variability with respect to local time and day of year for 23 variability classes. Spectra can be calculated with a stand-alone code for different conditions, also including optional atmospheric absorption and scattering. In comparison to the observed X-shooter spectra, PALACE shows convincing agreement and is significantly better than the previous, widely used airglow model for Cerro Paranal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.10683v1</guid>
      <category>physics.ao-ph</category>
      <category>astro-ph.EP</category>
      <category>astro-ph.IM</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.5194/egusphere-2024-3512</arxiv:DOI>
      <dc:creator>Stefan Noll, Carsten Schmidt, Patrick Hannawald, Wolfgang Kausch, Stefan Kimeswenger</dc:creator>
    </item>
    <item>
      <title>Inferring Fireball Velocity Profiles and Characteristic Parameters of Meteoroids from Incomplete Datasets</title>
      <link>https://arxiv.org/abs/2504.10715</link>
      <description>arXiv:2504.10715v1 Announce Type: cross 
Abstract: Extracting additional information from old or incomplete fireball datasets remains a challenge. To address missing point-by-point observations, we introduce a method for estimating atmospheric flight parameters of meteoroids using metaheuristic optimization techniques. Using a fireball catalog from the European Fireball Network (EN), we reconstruct velocity profiles, meteoroid bulk densities, mass loss rates, and ablation and ballistic coefficients, based on the initial and terminal points' height, velocity, and mass with the purely dynamical $\alpha$-$\beta$ model. Additionally, the method's performance is compared to the Meteorite Observation and Recovery Project (MORP) derived fits, confirming the robustness of the computed parameters for objects with asteroidal compositions. Our findings show that $\alpha$-$\beta$ model yields parameters consistent with the photometric and dynamic mass estimates in the EN catalog for $P_E$ type I events. However, in the implementation proposed here, $\alpha$-$\beta$ model encounters limitations in accurately representing the final deceleration of more fragile high-velocity meteoroids. This is likely due to challenges in representing complex fragmentation processes by fitting only two points, even when initial and terminal residuals are minimal. The retrieved $\alpha$-$\beta$ distribution differs from the one derived from MORP data, likely due to the imposed mass constraints, which strongly influence the results, especially the bulk density. The results suggest that $P_E$ constraints reduce fitting accuracy (from 90\% to 44\%), while flexibility and freedom from assumptions improve $\alpha$-$\beta$ performance. The method yields 26\% of the events compatible with the catalog $P_E$ classification. Our approach is well-suited for interpreting historical or sparse datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.10715v1</guid>
      <category>astro-ph.EP</category>
      <category>astro-ph.IM</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eloy Pe\~na-Asensio, Maria Gritsevich</dc:creator>
    </item>
    <item>
      <title>Unveiling faint X-ray AGN populations in the NewAthena era: Insights from cosmological simulations</title>
      <link>https://arxiv.org/abs/2504.10731</link>
      <description>arXiv:2504.10731v1 Announce Type: cross 
Abstract: Recent observations expanded our understanding of galaxy formation and evolution, yet key challenges persist in the X-ray regime, crucial for studying Active Galactic Nuclei (AGN). These limitations drive the development of next-generation observatories such as ESA's NewAthena. Now in phase B (preliminary design), the mission requires extensive testing to ensure compliance with its scientific goals, particularly given the uncertainties surrounding high redshift AGN. This work leverages the IllustrisTNG cosmological simulation to build an X-ray AGN mock catalogue and assess the performance of NewAthena's WFI. We created a Super Massive Black Hole (SMBH) light cone, spanning 10 deg2, with corrections to account for the limited resolution of the simulation and X-ray properties derived in post-processing. The resulting catalogue reveals a 5* overabundance of faint AGN compared to current X-ray constraints, an inconsistency potentially resolved by invoking a higher Compton-thick (CTK) fraction and intrinsic X-ray weakness, as suggested by recent JWST findings. An end-to-end survey simulation using SIXTE predicts 250000 AGN detections, including 20,000 at z &gt; 3 and 35 in the Epoch of Reionization (z &gt; 6); notably, only AGN with LX &gt; 43.5 erg/s are detectable at z &gt; 6. The analysis also forecasts a significant population of detectable CTK AGN, even beyond z &gt; 4. These findings suggest X-ray observations will, for the first time, probe a significant AGN population in the EoR, offering new insights into SMBH growth. They also provide key input for refining NewAthena's mission design and optimizing its survey strategy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.10731v1</guid>
      <category>astro-ph.GA</category>
      <category>astro-ph.CO</category>
      <category>astro-ph.HE</category>
      <category>astro-ph.IM</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nuno Covas, Israel Matute, Stergios Amarantidis, Jos\'e Afonso, Giorgio Lanzuisi, Andrea Comastri, Stefano Marchesi, Ciro Pappalardo, Rodrigo Carvajal, Polychronis Papaderos</dc:creator>
    </item>
    <item>
      <title>Fast detection and reconstruction of merging Massive Black Hole Binary signals</title>
      <link>https://arxiv.org/abs/2504.11322</link>
      <description>arXiv:2504.11322v1 Announce Type: cross 
Abstract: The Laser Interferometer Space Antenna (LISA) will detect gravitational waves from the population of merging massive black holes binaries (MBHBs) throughout the Universe. The LISA data stream will feature many superposed signals from different astrophysical sources, requiring a global fit procedure. Most of the MBHB signals will be loud enough to be detected days or even weeks before the merger; and for those sources LISA will be able to predict the time of the merger well in advance of the coalescence, as well as an approximate position in the sky. In this paper, we present a fast detection and signal reconstruction scheme for massive black hole binaries in the LISA observation band. We propose: (i) a detection scheme for MBHB mergers allowing a first subtraction of these signals for the purpose of a global fit, and (ii) an efficient early detection scheme providing a time-of-merger estimate for a pre-merger signal, that will allow to trigger a protection period, placing LISA in ``do not disturb'' mode and enabling more detailed analysis that will facilitate multi-messenger observations. We highlight the effect of confusion of several overlapping in time MBHB signals in the pre-merger detection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.11322v1</guid>
      <category>gr-qc</category>
      <category>astro-ph.CO</category>
      <category>astro-ph.IM</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Senwen Deng, Stanislav Babak, Sylvain Marsat</dc:creator>
    </item>
    <item>
      <title>Finding radio transients with anomaly detection and active learning based on volunteer classifications</title>
      <link>https://arxiv.org/abs/2410.01034</link>
      <description>arXiv:2410.01034v2 Announce Type: replace 
Abstract: In this work we explore the applicability of unsupervised machine learning algorithms to finding radio transients. Facilities such as the Square Kilometre Array (SKA) will provide huge volumes of data in which to detect rare transients; the challenge for astronomers is how to find them. We demonstrate the effectiveness of anomaly detection algorithms using 1.3 GHz light curves from the SKA precursor MeerKAT. We make use of three sets of descriptive parameters ('feature sets') as applied to two anomaly detection techniques in the Astronomaly package and analyse our performance by comparison with citizen science labels on the same dataset. Using transients found by volunteers as our ground truth, we demonstrate that anomaly detection techniques can recall over half of the radio transients in the 10 per cent of the data with the highest anomaly scores. We find that the choice of anomaly detection algorithm makes a minor difference, but that feature set choice is crucial, especially when considering available resources for human inspection and/or follow-up. Active learning, where human labels are given for just 2 per cent of the data, improves recall by up to 20 percentage points, depending on the combination of features and model used. The best performing results produce a factor of 5 times fewer sources requiring vetting by experts. This is the first effort to apply anomaly detection techniques to finding radio transients and shows great promise for application to other datasets, and as a real-time transient detection system for upcoming large surveys.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.01034v2</guid>
      <category>astro-ph.IM</category>
      <category>astro-ph.HE</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1093/mnras/staf336</arxiv:DOI>
      <arxiv:journal_reference>MNRAS, 2025, 538, 3, pp.1397-1414</arxiv:journal_reference>
      <dc:creator>Alex Andersson, Chris Lintott, Rob Fender, Michelle Lochner, Patrick Woudt, Jakob van den Eijnden, Alexander van der Horst, Assaf Horesh, Payaswini Saikia, Gregory R. Sivakoff, Lilia Tremou, Mattia Vaccari</dc:creator>
    </item>
    <item>
      <title>DeepDISC-photoz: Deep Learning-Based Photometric Redshift Estimation for Rubin LSST</title>
      <link>https://arxiv.org/abs/2411.18769</link>
      <description>arXiv:2411.18769v2 Announce Type: replace 
Abstract: Photometric redshifts will be a key data product for the Rubin Observatory Legacy Survey of Space and Time (LSST) as well as for future ground and space-based surveys. The need for photometric redshifts, or photo-zs, arises from sparse spectroscopic coverage of observed galaxies. LSST is expected to observe billions of objects, making it crucial to have a photo-z estimator that is accurate and efficient. To that end, we present DeepDISC photo-z, a photo-z estimator that is an extension of the DeepDISC framework. The base DeepDISC network simultaneously detects, segments, and classifies objects in multi-band coadded images. We introduce photo-z capabilities to DeepDISC by adding a redshift estimation Region of Interest head, which produces a photo-z probability distribution function for each detected object. On simulated LSST images, DeepDISC photo-z outperforms traditional catalog-based estimators, in both point estimate and probabilistic metrics. We validate DeepDISC by examining dependencies on systematics including galactic extinction, blending and PSF effects. We also examine the impact of the data quality and the size of the training set and model. We find that the biggest factor in DeepDISC photo-z quality is the signal-to-noise of the imaging data, and see a reduction in photo-z scatter approximately proportional to the image data signal-to-noise. Our code is fully public and integrated in the RAIL photo-z package for ease of use and comparison to other codes at https://github.com/LSSTDESC/rail_deepdisc</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.18769v2</guid>
      <category>astro-ph.IM</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Grant Merz, Xin Liu, Samuel Schmidt, Alex I. Malz, Tianqing Zhang, Doug Branton, Colin J. Burke, Melissa Delucchi, Yaswant Sai Ejjagiri, Jeremy Kubica, Yichen Liu, Olivia Lynn, Drew Oldag, The LSST Dark Energy Science Collaboration</dc:creator>
    </item>
    <item>
      <title>SynthPop: A New Framework for Synthetic Milky Way Population Generation</title>
      <link>https://arxiv.org/abs/2411.18821</link>
      <description>arXiv:2411.18821v2 Announce Type: replace 
Abstract: We present SynthPop, a new open source, modular population synthesis Galactic modeling software to simulate catalogs of Milky Way stars along any sightline outward from the Sun. Motivated by a lack flexibility in existing Galactic models, SynthPop is coded entirely in python, can be run standalone or as an imported module, and is configured by json files that allow different model components to be switched out as desired. We describe the modular code structure, how the population generation process runs, and how to use the code. We also present model validation testing and known inaccuracies, and present an example of the code use, comparing Gaia data and the Gaia Universe Model Snapshot to a SynthPop implementation. The code is available now via GitHub with ReadTheDocs documentation and can be installed via pip.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.18821v2</guid>
      <category>astro-ph.IM</category>
      <category>astro-ph.GA</category>
      <category>astro-ph.SR</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jonas Kl\"uter, Macy J. Huston, Abigail Aronica, Samson A. Johnson, Matthew Penny, Marz Newman, Farzaneh Zohrabi, Alison L. Crisp, Allison Chevis</dc:creator>
    </item>
    <item>
      <title>Application of Non-Linear Noise Regression in the Virgo Detector</title>
      <link>https://arxiv.org/abs/2410.06220</link>
      <description>arXiv:2410.06220v3 Announce Type: replace-cross 
Abstract: Since the first detection of gravitational waves (GWs) in 2015, the International Gravitational-wave Network has made substantial strides in improving the sensitivity of ground-based detectors. Despite these advancements, many GW signals remain below the detection threshold due to environmental noise that limits sensitivity. In recent years, algorithms such as DeepClean have been developed to estimate and remove contamination from various noise sources, addressing linear, non-linear, and non-stationary coupling mechanisms. In this paper, we present noise reduction in the Virgo detector using DeepClean, serving as a preliminary step toward integrating Virgo into the online noise reduction pipeline for the O5 observing run. Our results demonstrate the applicability of DeepClean in Virgo O3b data, where noise was reconstructed from a total of 225 auxiliary witness channels. These channels were divided into 13 subsets, each corresponding to a specific frequency band, with training and subtraction performed layer-wise in a sequential manner. We observe that the subtraction improves the binary neutron star inspiral range by up to 1.3 Mpc, representing an approximately 2.5% increase. To ensure robust validation, we conduct an injection study with binary black hole waveforms. Matched-filter analyses of the injections showed an average improvement of 1.7% in the recovered signal-to-noise ratio, while parameter estimation confirmed that DeepClean introduces no bias in the recovered parameters. The successful demonstration provides a pathway for online non-linear noise subtraction in Virgo in the future observing runs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06220v3</guid>
      <category>gr-qc</category>
      <category>astro-ph.IM</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>R. Weizmann Kiendrebeogo, Muhammed Saleem, Marie Anne Bizouard, Andy H. Y. Chen, Nelson Christensen, Chia-Jui Chou, Michael W. Coughlin, Kamiel Janssens, S. Zacharie Kam, Jean Koulidiati, Shu-Wei Yeh</dc:creator>
    </item>
    <item>
      <title>Unsupervised Machine Learning for Classifying CHIME Fast Radio Bursts and Investigating Empirical Relations</title>
      <link>https://arxiv.org/abs/2411.14040</link>
      <description>arXiv:2411.14040v2 Announce Type: replace-cross 
Abstract: Fast Radio Bursts (FRBs) are highly energetic millisecond-duration astrophysical phenomena typically categorized as repeaters or non-repeaters. However, observational limitations may result in misclassifications, potentially leading to a higher proportion of repeaters than currently identified. In this study, we leverage unsupervised machine learning techniques to classify FRBs using data from the CHIME/FRB catalogs, including both the first catalog and a recent repeater catalog. By employing Uniform Manifold Approximation and Projection for dimensionality reduction and clustering algorithms (k-means and Hierarchical Density-Based Spatial Clustering of Applications with Noise), we successfully segregate repeaters and non-repeaters into distinct clusters, identifying over 100 potential repeater candidates. Our analysis reveals several empirical relations within the clusters, including the ${\rm log \,}\Delta t_{sc}-{\rm log \,}\Delta t_{rw}$, ${\rm log \,}\Delta t_{sc}-{\rm log \,}T_B$, and $r - \gamma$ correlations, where ${\Delta t_{sc}, \Delta t_{rw}, T_B, r, \gamma}$ represent scattering time, rest-frame width, brightness temperature, spectral running, and spectral index, respectively. The Chow test results reveal that while some repeaters and non-repeaters share similar empirical relationships, the overall distinctions between the two groups remain significant, reinforcing the classification of FRBs into repeaters and non-repeaters. These findings provide new insights into the physical properties and emission mechanisms of FRBs. This study demonstrates the effectiveness of unsupervised learning in classifying FRBs and identifying potential repeaters, paving the way for more precise investigations into their origins and applications in cosmology. Future improvements in observational data and machine learning methodologies are expected to further enhance our understanding of FRBs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.14040v2</guid>
      <category>astro-ph.HE</category>
      <category>astro-ph.CO</category>
      <category>astro-ph.IM</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.3847/1538-4357/adb72b</arxiv:DOI>
      <arxiv:journal_reference>2025 ApJ 982 16</arxiv:journal_reference>
      <dc:creator>Da-Chun Qiang, Jie Zheng, Zhi-Qiang You, Sheng Yang</dc:creator>
    </item>
    <item>
      <title>Proton Radiation Damage and Annealing of COSI p-type Cross-strip HPGe Detectors</title>
      <link>https://arxiv.org/abs/2501.02412</link>
      <description>arXiv:2501.02412v2 Announce Type: replace-cross 
Abstract: In order to understand the effects of a space radiation environment on cross-strip germanium detectors, we investigated the effects of high-energy proton damage on a COSI detector and the capabilities of high-temperature annealing in repairing detector spectral resolution. We irradiated a COSI-balloon cross-strip high-purity germanium (HPGe) detector with 150 MeV protons resulting in a net fluence of $4.95\times10^8$ p$^+$/cm$^2$ and corresponding to ~10 years in COSI's space radiation environment. We repaired the resulting degradation in spectral resolution through a series of high-temperature anneals to obtain a final FWHM of 4.08 keV, within 37% of its preradiation value (2.98 keV FWHM). We characterized the repair of charge traps with time spent under high-temperature anneal to inform an annealing procedure for long-term maintenance of COSI's spectral resolution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.02412v2</guid>
      <category>physics.ins-det</category>
      <category>astro-ph.IM</category>
      <category>nucl-ex</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sophia E. Haight, Steven E. Boggs, Gabriel Brewster, Sean N. Pike, Jarred M. Roberts, Albert Y. Shih, Joanna M. Szornel, John A. Tomsick, Aravind B. Valluvan, Andreas Zoglauer</dc:creator>
    </item>
    <item>
      <title>Modular global-fit pipeline for LISA data analysis</title>
      <link>https://arxiv.org/abs/2501.10277</link>
      <description>arXiv:2501.10277v2 Announce Type: replace-cross 
Abstract: We anticipate that the data acquired by the Laser Interferometer Space Antenna (LISA) will be dominated by the gravitational wave signals from several astrophysical populations. The analysis of these data is a new challenge and is the main focus of this paper. Numerous gravitational wave signals overlap in the time and/or frequency domain, and the possible correlation between them has to be taken into account during their detection and characterization. In this work, we present a method to address the LISA data analysis challenge; it is flexible and scalable for a number of sources and across several populations. Its performance is demonstrated on the simulated data LDC2a.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10277v2</guid>
      <category>gr-qc</category>
      <category>astro-ph.CO</category>
      <category>astro-ph.IM</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Senwen Deng, Stanislav Babak, Maude Le Jeune, Sylvain Marsat, \'Eric Plagnol, Andrea Sartirana</dc:creator>
    </item>
    <item>
      <title>ExoMolHR: A Relational Database of Empirical High-Resolution Molecular Spectra</title>
      <link>https://arxiv.org/abs/2504.08731</link>
      <description>arXiv:2504.08731v2 Announce Type: replace-cross 
Abstract: ExoMolHR is an empirical, high-resolution molecular spectrum calculator for the high-temperature molecular line lists available from the ExoMol molecular database. Uncertainties, where available, in recommended ExoMol datasets are used to select highly accurate spectral lines. These lines largely rely on empirical energy levels generated through the MARVEL (measured active rotation vibration energy levels) procedure, which is being systematically used to improve the energy and transition data provided by the ExoMol database. The freely accessible ExoMolHR database provides line positions with calculated intensities for a user-specified wavenumber/wavelength range and temperature. Spectra can be plotted on the ExoMolHR website (https://www.exomol.com/exomolhr/) or downloaded as a CSV file. Cross sections can be calculated using the Python program PyExoCross. The ExoMolHR database currently provides 24307135 spectral lines for 33 molecules and 58 isotopologues; these numbers will increase as the ExoMol database is updated.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.08731v2</guid>
      <category>astro-ph.EP</category>
      <category>astro-ph.GA</category>
      <category>astro-ph.IM</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.3847/1538-4365/ada288</arxiv:DOI>
      <arxiv:journal_reference>The Astrophysical Journal Supplement Series 276 (2025) 67</arxiv:journal_reference>
      <dc:creator>Jingxin Zhang, Christian Hill, Jonathan Tennyson, Sergei N. Yurchenko</dc:creator>
    </item>
  </channel>
</rss>
