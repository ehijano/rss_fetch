<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cond-mat.dis-nn updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cond-mat.dis-nn</link>
    <description>cond-mat.dis-nn updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cond-mat.dis-nn" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 04 Feb 2026 03:03:38 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Inferring Concepts from Noisy Examples in Hopfield-like Neural Networks</title>
      <link>https://arxiv.org/abs/2602.01393</link>
      <description>arXiv:2602.01393v1 Announce Type: new 
Abstract: We study a variant of the pseudo-inverse learning rule for Hopfield-like Neural Networks, which allows the network to infer archetypal concepts on the basis of a limited number of examples. The mean-field replica theory for this model reveals how this generalization ability is mediated by a multitude of states, with diverse thermodynamic properties, coexisting with the standard Hopfield ones. They appear and vanish through smooth transitions or discontinuous jumps and, interestingly, show much stronger Replica Symmetry Breaking (RSB) effects than the standard Hopfield model, as captured by our 1RSB analysis. Our results, in excellent agreement with numerical simulations, provide deeper insight into the interplay between memory storage and generalization in attractor neural networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01393v1</guid>
      <category>cond-mat.dis-nn</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marco Benedetti, Giulia Fischetti, Enzo Marinari, Gleb Oshanin, Victor Dotsenko</dc:creator>
    </item>
    <item>
      <title>Reshaping Global Loop Structure to Accelerate Local Optimization by Smoothing Rugged Landscapes</title>
      <link>https://arxiv.org/abs/2602.01490</link>
      <description>arXiv:2602.01490v1 Announce Type: new 
Abstract: Probabilistic graphical models with frustration exhibit rugged energy landscapes that trap iterative optimization dynamics. These landscapes are shaped not only by local interactions, but crucially also by the global loop structure of the graph. The famous Bethe approximation treats the graph as a tree, effectively ignoring global structure, thereby limiting its effectiveness for optimization. Loop expansions capture such global structure in principle, but are often impractical due to combinatorial explosion. The $M$-layer construction provides an alternative: make $M$ copies of the graph and reconnect edges between them uniformly at random. This provides a controlled sequence of approximations from the original graph at $M=1$, to the Bethe approximation as $M \rightarrow \infty$. Here we generalize this construction by replacing uniform random rewiring with a structured mixing kernel $Q$ that sets the probability that any two layers are interconnected. As a result, the global loop structure can be shaped without modifying local interactions. We show that, after this copy-and-reconnect transformation, there exists a regime in which layer-to-layer fluctuations decay, increasing the probability of reaching the global minimum of the energy function of the original graph. This yields a highly general and practical tool for optimization. Using this approach, the computational cost required to reach these optimal solutions is reduced across sparse and dense Ising benchmarks, including spin glasses and planted instances. When combined with replica-exchange Monte Carlo, the same construction increases the polynomial-time algorithmic threshold for the maximum independent set problem. A cavity analysis shows that structured inter-layer coupling significantly smooths rugged energy landscapes by collapsing configurational complexity and suppressing many suboptimal metastable states.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01490v1</guid>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.stat-mech</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Timothee Leleu, Sam Reifenstein, Atsushi Yamamura, Surya Ganguli</dc:creator>
    </item>
    <item>
      <title>Putting machine learning to the test in a quantum many-body system</title>
      <link>https://arxiv.org/abs/2602.01981</link>
      <description>arXiv:2602.01981v1 Announce Type: new 
Abstract: Quantum many-body systems pose a formidable computational challenge due to the exponential growth of their Hilbert space. While machine learning (ML) has shown promise as an alternative paradigm, most applications remain at the proof-of-concept stage, focusing narrowly on energy estimation at the lower end of the spectrum. Here, we push ML beyond this frontier by extensively testing HubbardNet, a deep neural network architecture for the Bose-Hubbard model. Pushing improvements in the optimizer and learning rates, and introducing physics-informed output activations that can resolve extremely small wave-function amplitudes, we achieve ground-state energy errors reduced by orders of magnitude and wave-function fidelities exceeding 99%. We further assess physical relevance by analysing generalized inverse participation ratios and multifractal dimensions for ground and excited states in one and two dimensions, demonstrating that optimized ML models reproduce localization, delocalization, and multifractality trends across the spectrum. Crucially, these qualitative predictions remain robust across four decades of the interaction strength, e.g. spanning across superfluid, Mott-insulating, as well as quantum chaotic regimes. Together, these results suggest ML as a viable qualitative predictor of many-body structure, complementing the quantitative strengths of exact diagonalization and tensor-network methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01981v1</guid>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.quant-gas</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yilun Gao, Alberto Rodr\'iguez, Rudolf A. R\"omer</dc:creator>
    </item>
    <item>
      <title>Machine-Learned Hamiltonians for Quantum Transport Simulation of Valence Change Memories</title>
      <link>https://arxiv.org/abs/2602.02125</link>
      <description>arXiv:2602.02125v1 Announce Type: new 
Abstract: The construction of the Hamiltonian matrix \textbf{H} is an essential, yet computationally expensive step in \textit{ab-initio} device simulations based on density-functional theory (DFT). In homogeneous structures, the fact that a unit cell repeats itself along at least one direction can be leveraged to minimize the number of atoms considered and the calculation time. However, such an approach does not lend itself to amorphous or defective materials for which no periodicity exists. In these cases, (much) larger domains containing thousands of atoms might be needed to accurately describe the physics at play, pushing DFT tools to their limit. Here we address this issue by learning and directly predicting the Hamiltonian matrix of large structures through equivariant graph neural networks and so-called augmented partitioning training. We demonstrate the strength of our approach by modeling valence change memory (VCM) cells, achieving a Mean Absolute Error (MAE) of 3.39 to 3.58 meV, as compared to DFT, when predicting the Hamiltonian matrix entries of systems made of $\sim$5,000 atoms. We then replace the DFT-computed Hamiltonian of these VCMs with the predicted one to compute their energy-resolved transmission function with a quantum transport tool. A qualitatively good agreement between both sets of curves is obtained. Our work provides a path forward to overcome the memory and computational limits of DFT, thus enabling the study of large-scale devices beyond current \textit{ab-initio} capabilities</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.02125v1</guid>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.mes-hall</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/SISPAD66650.2025.11186322</arxiv:DOI>
      <dc:creator>Chen Hao Xia, Manasa Kaniselvan, Marko Mladenoivi\'c, Mathieu Luisier</dc:creator>
    </item>
    <item>
      <title>Interaction-induced moir\'e lattices: from mosaic mobility edges to many-body localization</title>
      <link>https://arxiv.org/abs/2602.02177</link>
      <description>arXiv:2602.02177v1 Announce Type: new 
Abstract: We study localization driven solely by interparticle interactions in moir\'e lattice systems without intrinsic disorder or externally imposed quasiperiodic potentials. We consider a one-dimensional bilayer with incommensurate lattice constants, described by a spin-dependent Fermi-Hubbard-type model with short-range interlayer interactions, where quasiperiodicity emerges only through interactions. Exact diagonalization shows that quenching hopping in one layer generates an interaction-induced mosaic potential with multiple mobility edges. When both layers are dynamical, increasing interlayer interactions drives transitions among ergodic, critical, and many-body localized regimes, with energy-dependent coexistence in certain parameter ranges. An exact mapping to a noninteracting single-particle model on a higher-dimensional structured graph provides a unified interpretation of these results and suggests an experimentally accessible route to interaction-induced moir\'e physics and localization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.02177v1</guid>
      <category>cond-mat.dis-nn</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yan-Hao Yang, Zhihao Xu, Lei Ying, Qizhong Zhu</dc:creator>
    </item>
    <item>
      <title>Fermionic magic resources in disordered quantum spin chains</title>
      <link>https://arxiv.org/abs/2602.00245</link>
      <description>arXiv:2602.00245v1 Announce Type: cross 
Abstract: Fermionic non-Gaussianity quantifies a quantum state's deviation from a classically tractable free-fermionic description, constituting a necessary resource for computational quantum advantage. Here we use fermionic antiflatness (FAF) to measure this deviation across ergodic and many-body localized (MBL) regimes. We focus on the paradigmatic disordered spin-$1\!/2$ XXZ chain and its impurity variant with local interactions. Across highly excited eigenstates, FAF evolves from typical-state behavior at weak disorder to strongly suppressed values deep in the MBL regime, with volume-law scaling in the XXZ chain and an area-law bound in the impurity setting. Rare long range catlike eigenstates exhibit a pronounced enhancement of FAF, making it a sensitive diagnostic of mechanisms proposed to destabilize MBL. Starting from product states, we find that in the MBL regime FAF grows slowly in time, approaching saturation via a power-law relaxation. Overall, our results show that MBL suppresses fermionic non-Gaussianity, and the associated complexity beyond free fermions, while ergodicity restores it, motivating explorations of fermionic non-Gaussianity in other ergodicity-breaking phenomena.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.00245v1</guid>
      <category>quant-ph</category>
      <category>cond-mat.dis-nn</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pedro R. Nic\'acio Falc\~ao, Jakub Zakrzewski, Piotr Sierant</dc:creator>
    </item>
    <item>
      <title>Neural Ising Machines via Unrolling and Zeroth-Order Training</title>
      <link>https://arxiv.org/abs/2602.00302</link>
      <description>arXiv:2602.00302v1 Announce Type: cross 
Abstract: We propose a data-driven heuristic for NP-hard Ising and Max-Cut optimization that learns the update rule of an iterative dynamical system. The method learns a shared, node-wise update rule that maps local interaction fields to spin updates, parameterized by a compact multilayer perceptron with a small number of parameters. Training is performed using a zeroth-order optimizer, since backpropagation through long, recurrent Ising-machine dynamics leads to unstable and poorly informative gradients. We call this approach a neural network parameterized Ising machine (NPIM). Despite its low parameter count, the learned dynamics recover effective algorithmic structure, including momentum-like behavior and time-varying schedules, enabling efficient search in highly non-convex energy landscapes. Across standard Ising and neural combinatorial optimization benchmarks, NPIM achieves competitive solution quality and time-to-solution relative to recent learning-based methods and strong classical Ising-machine heuristics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.00302v1</guid>
      <category>cs.LG</category>
      <category>cond-mat.dis-nn</category>
      <category>nlin.CD</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sam Reifenstein, Timothee Leleu</dc:creator>
    </item>
    <item>
      <title>Predicting the hydrogen bond strength from water reorientation dynamics at short timescales</title>
      <link>https://arxiv.org/abs/2602.00311</link>
      <description>arXiv:2602.00311v1 Announce Type: cross 
Abstract: Path-integral molecular dynamics simulations and electronic structure-based energy decomposition analysis (EDA) are employed to connect hydrogen bond (H-bond) strength, its asymmetry, and the total delocalization energy at the water/air interface to experimentally measurable observables, such as the reorientation dynamics and the sum-frequency generation (SFG) spectrum. Using SFG spectra for distinct layers at the water/air interface, we validate the accuracy of our simulations and report a red-shift from the interface to bulk and a strongly bonded water peak at around 3250 cm$^{-1}$ in the layer closest to bulk. The reorientation dynamics of water molecules slow down from the interface to bulk, which correlates with the SFG results. From our EDA based on absolutely localized molecular orbitals, we observe a strong decline in total delocalization energy from bulk to the interface, as well as a decline in the strength of the strongest donor and acceptor interactions. The asymmetry between the two strongest interactions similarly rises towards the interface, while the importance of interactions from the outer solvation shells is greatly diminished and is lower than previously reported. Finally, we find that the strength of the strongest H-bond donor/acceptor is best correlated with the local minimum of the autocorrelation function resembling the L2 band librational motions. Following that, we propose a simple yet quantitative relationship between H-bond strength and the short-time reorientation dynamics at the water/air interface that could potentially be extended to predict H-bond strength in other hydrophobic systems from experimentally obtainable observables.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.00311v1</guid>
      <category>physics.chem-ph</category>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.soft</category>
      <category>cond-mat.stat-mech</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Frederik Zysk, Ana Vila Verde, Naveen K. Kaliannan, Kristof Karhan, Thomas D. K\"uhne</dc:creator>
    </item>
    <item>
      <title>Memory effects govern scale-free dynamics beyond universality classes</title>
      <link>https://arxiv.org/abs/2602.00374</link>
      <description>arXiv:2602.00374v1 Announce Type: cross 
Abstract: Scale-invariant avalanches -- with events of all sizes following power-law distributions -- are considered critical. Above the upper critical dimension of four, the mean-field solution with a robust $3/2$ size exponent describes the dynamics. In two and three dimensions, spatial constraints yield smaller yet robust exponent values governed by universality classes. However, both earthquake data and experiments often show exponent values larger than $3/2$, challenging those theoretical arguments based on critical behavior. Through extensive simulations in the classical OFC earthquake model, here we show a clear transition from the theoretical expected behavior of a robust exponent value, to a regime of quasi-critical dynamics with larger than $3/2$ exponents that depend on dissipation. While the first critical regime exhibits an inherently memoryless behavior, both the transition and the second regime are driven by memory effects provoked by the growth of avalanches over the traces left by previous events, due to dissipative mechanisms. The system hovers at a distance $d_{cp}$ from the critical point, and accounting for a power-law distribution of $d_{cp}$, validated by susceptibility measurements, captures the transition. This framework provides a unified description of both critical and quasi-critical behavior, and thus of the full spectrum of scale-free dynamics observed in nature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.00374v1</guid>
      <category>cond-mat.stat-mech</category>
      <category>cond-mat.dis-nn</category>
      <category>nlin.AO</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>K. Duplat, A. Douin, O. Ramos</dc:creator>
    </item>
    <item>
      <title>Emergence of Distortions in High-Dimensional Guided Diffusion Models</title>
      <link>https://arxiv.org/abs/2602.00716</link>
      <description>arXiv:2602.00716v1 Announce Type: cross 
Abstract: Classifier-free guidance (CFG) is the de facto standard for conditional sampling in diffusion models, yet it often leads to a loss of diversity in generated samples. We formalize this phenomenon as generative distortion, defined as the mismatch between the CFG-induced sampling distribution and the true conditional distribution. Considering Gaussian mixtures and their exact scores, and leveraging tools from statistical physics, we characterize the onset of distortion in a high-dimensional regime as a function of the number of classes. Our analysis reveals that distortions emerge through a phase transition in the effective potential governing the guided dynamics. In particular, our dynamical mean-field analysis shows that distortion persists when the number of modes grows exponentially with dimension, but vanishes in the sub-exponential regime. Consistent with prior finite-dimensional results, we further demonstrate that vanilla CFG shifts the mean and shrinks the variance of the conditional distribution. We show that standard CFG schedules are fundamentally incapable of preventing variance shrinkage. Finally, we propose a theoretically motivated guidance schedule featuring a negative-guidance window, which mitigates loss of diversity while preserving class separability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.00716v1</guid>
      <category>stat.ML</category>
      <category>cond-mat.dis-nn</category>
      <category>cs.LG</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Enrico Ventura, Beatrice Achilli, Luca Ambrogioni, Carlo Lucibello</dc:creator>
    </item>
    <item>
      <title>Universality and anisotropy of the Photonic Urbach Tail</title>
      <link>https://arxiv.org/abs/2602.00829</link>
      <description>arXiv:2602.00829v1 Announce Type: cross 
Abstract: Disorder in photonic crystals and waveguides creates states inside the photonic band gap. These states are often described as Lifshitz tails despite exhibiting energy distributions inconsistent with Lifshitz statistics near the band edge. Here we show that in photonic-crystal waveguides with intentionally engineered anisotropic disorder, the band-edge tail accessible experimentally follows an Urbach law universally, with cumulative statistics $F(\Delta)=\exp[-(\Delta/\alpha)^\beta]$, where $\Delta$ is the spectral detuning from the band edge, and an exponent $\beta \approx 1$ independent of disorder strength and orientation. In contrast to Lifshitz behavior, the density of states is maximal at the band edge and decays into the gap. Crucially, we find that the Urbach energy $\alpha$ is anisotropic, with a pronounced directional splitting and qualitatively different scaling for disorder parallel and perpendicular to the waveguide axis. These conclusions are supported by quantitative agreement between optical measurements of GaAs photonic-crystal waveguides and full-vector simulations. The anisotropic Urbach energy emerges as a sensitive probe of disorder-mode coupling and a practical metric to characterize structural disorder in photonic devices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.00829v1</guid>
      <category>physics.optics</category>
      <category>cond-mat.dis-nn</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>M. Men\'endez, Lan Hoang Mai, Nazifa Tasnim Arony, Henry Carfagno, Lauren N. McCabe, Joshua M. O. Zide, Cefe L\'opez, Matthew F. Doty, P. D. Garc\'ia</dc:creator>
    </item>
    <item>
      <title>Superstable Geometry in Triadic Percolation</title>
      <link>https://arxiv.org/abs/2602.01374</link>
      <description>arXiv:2602.01374v1 Announce Type: cross 
Abstract: Triadic percolation turns bond percolation into a dynamical problem governed by an effective one-dimensional unimodal map. We show that the geometry of superstable cycles provides a direct, map-agnostic probe of local nonlinearity: specifically, the distance from the map's maximum to a distinguished next-to-maximum point on the attracting $2^n$-cycle (which coincides with a preimage of the maximum at $2^n$-superstability) scales as $|\Delta p|^{\gamma}$ with $\gamma = 1/z$, where $z$ is the nonflat order of the maximum. This prediction is verified across canonical unimodal families and heterogeneous triadic ensembles, with Lyapunov spectra corroborating the one-dimensional reduction. A derivative condition on the activation kernel fixes the local nonlinearity order $z$ (and thus, under standard unimodal-map hypotheses, the associated $z$-logistic universality class) and gives conditions under which $z&gt;2$ can be realized. The diagnostic operates directly on orbit data under standard regularity assumptions, providing a practical tool to classify universality in higher-order networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01374v1</guid>
      <category>cond-mat.stat-mech</category>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.soft</category>
      <category>cs.NI</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Fatemeh Aghaei, Abbas Ali Saberi, Holger Kantz, Juergen Kurths</dc:creator>
    </item>
    <item>
      <title>Many-body localization for the random XXZ spin chain in fixed energy intervals</title>
      <link>https://arxiv.org/abs/2602.01441</link>
      <description>arXiv:2602.01441v1 Announce Type: cross 
Abstract: A key signature of MBL (many-body localization) is the slow rate at which information spreads. It is shown that the infinite random Heisenberg XXZ spin-$\frac12$ chain exhibits slow propagation of information (logarithmic light cone) in any arbitrary but fixed energy interval. The relevant parameter regime, which covers both weak interaction and strong disorder, is determined solely by the energy interval.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01441v1</guid>
      <category>math-ph</category>
      <category>cond-mat.dis-nn</category>
      <category>math.MP</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Elgart, Abel Klein</dc:creator>
    </item>
    <item>
      <title>Two-lifetime model for the cuprates revisited</title>
      <link>https://arxiv.org/abs/2602.02097</link>
      <description>arXiv:2602.02097v1 Announce Type: cross 
Abstract: Several models of the strange-metal state of the cuprate superconductors postulate the existence of strong inelastic forward scattering of the electrons, but direct evidence of such scattering is missing. Here we show that angle-resolved photoemission spectroscopy (ARPES) provides a unique tool which can address this issue. We propose a two-lifetime phenomenological model of the superconducting state of the cuprates and we show that it explains several salient low-energy features of the measured ARPES spectra. The model enables discrimination between forward- and large-angle scattering and, in addition, gives access to the magnitude of the gap function away from the Fermi surface.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.02097v1</guid>
      <category>cond-mat.supr-con</category>
      <category>cond-mat.dis-nn</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lucia Gelenekyov\'a, Franti\v{s}ek Herman, Hana Havranov\'a, Richard Hlubina</dc:creator>
    </item>
    <item>
      <title>Multifractality in critical neural field dynamics</title>
      <link>https://arxiv.org/abs/2312.03219</link>
      <description>arXiv:2312.03219v2 Announce Type: replace 
Abstract: The brain criticality hypothesis has largely only characterized brain dynamics in terms of their self-similarity, although experimental evidence suggests that the brain exhibits significant multifractality. To understand how multifractality may emerge in critical-like systems modeling neuronal activity, we used a neural field model exhibiting neural oscillations and a critical phase transition. We find that multifractality emerges near a synchronization phase transition, and that the pattern of variation of multifractality changes when placing the model at a different phase transition. These findings show that multifractality in temporal dynamics emerges near criticality in neural fields, providing a formal basis for interpreting multifractality in brain recordings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.03219v2</guid>
      <category>cond-mat.dis-nn</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Merlin Dumeur, Sheng H. Wang, J. Matias Palva, Philippe Ciuciu</dc:creator>
    </item>
    <item>
      <title>A mean-field theory for heterogeneous random growth with redistribution</title>
      <link>https://arxiv.org/abs/2503.23189</link>
      <description>arXiv:2503.23189v3 Announce Type: replace 
Abstract: We study the competition between random multiplicative growth and redistribution/migration in the mean-field limit, when the number of sites is very large but finite. We find that for static random growth rates, migration should be strong enough to prevent localisation, i.e. extreme concentration on the fastest growing site. In the presence of an additional temporal noise in the growth rates, a third partially localised phase is predicted theoretically, using results from Derrida's Random Energy Model. Such temporal fluctuations mitigate concentration effects, but do not make them disappear. We discuss our results in the context of population growth and wealth inequalities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.23189v3</guid>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.stat-mech</category>
      <category>econ.GN</category>
      <category>math.PR</category>
      <category>q-bio.PE</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maximilien Bernard, Jean-Philippe Bouchaud, Pierre Le Doussal</dc:creator>
    </item>
    <item>
      <title>Extracting average properties of disordered spin chains with translationally invariant tensor networks</title>
      <link>https://arxiv.org/abs/2504.21089</link>
      <description>arXiv:2504.21089v2 Announce Type: replace 
Abstract: We develop a tensor network-based method for calculating disorder-averaged expectation values in random spin chains without having to explicitly sample over disorder configurations. The algorithm exploits statistical translation invariance and works directly in the thermodynamic limit. We benchmark our method on the infinite-randomness critical point of the random transverse field Ising model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.21089v2</guid>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.str-el</category>
      <category>quant-ph</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kevin Vervoort, Wei Tang, Nick Bultinck</dc:creator>
    </item>
    <item>
      <title>Spatial QUBO: Convolutional Formulation of Large-Scale Binary Optimization with Dense Interactions</title>
      <link>https://arxiv.org/abs/2506.24008</link>
      <description>arXiv:2506.24008v2 Announce Type: replace 
Abstract: The spatial photonic Ising machine (SPIM) is a promising optical hardware solver for large-scale combinatorial optimization problems with dense interactions. As the SPIM can represent Ising problems with rank-one coupling matrices, multiplexed versions have been proposed to enhance the applicability to higher-rank interactions. However, the multiplexing cost reduces the implementation efficiency, and even without multiplexing, the SPIM is known to represent coupling matrices beyond rank-one. In this paper, to clarify the intrinsic representation power of the original SPIM, we propose spatial QUBO (spQUBO), a formulation of Ising problems with spatially convolutional structures. We prove that any spQUBO reduces to a two-dimensional spQUBO, with the convolutional structure preserved, and that any two-dimensional spQUBO can be efficiently implemented on the SPIM without multiplexing. We further demonstrate its practical applicability to distance-based combinatorial optimization, such as placement problems and clustering problems. These results advance our understanding of the class of optimization problems where SPIMs exhibit superior efficiency and scalability. Furthermore, spQUBO's efficiency is not limited to the SPIM architecture; we show that its convolutional structure allows efficient computation using Fast Fourier Transforms (FFT).</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.24008v2</guid>
      <category>cond-mat.dis-nn</category>
      <category>cs.ET</category>
      <category>physics.app-ph</category>
      <category>physics.optics</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hiroshi Yamashita, Hideyuki Suzuki</dc:creator>
    </item>
    <item>
      <title>The Nuclear Route: Sharp Asymptotics of ERM in Overparameterized Quadratic Networks</title>
      <link>https://arxiv.org/abs/2505.17958</link>
      <description>arXiv:2505.17958v3 Announce Type: replace-cross 
Abstract: We study the high-dimensional asymptotics of empirical risk minimization (ERM) in over-parametrized two-layer neural networks with quadratic activations trained on synthetic data. We derive sharp asymptotics for both training and test errors by mapping the $\ell_2$-regularized learning problem to a convex matrix sensing task with nuclear norm penalization. This reveals that capacity control in such networks emerges from a low-rank structure in the learned feature maps. Our results characterize the global minima of the loss and yield precise generalization thresholds, showing how the width of the target function governs learnability. This analysis bridges and extends ideas from spin-glass methods, matrix factorization, and convex optimization and emphasizes the deep link between low-rank matrix sensing and learning in quadratic neural networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.17958v3</guid>
      <category>stat.ML</category>
      <category>cond-mat.dis-nn</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>NeurIPS 2025</arxiv:journal_reference>
      <dc:creator>Vittorio Erba, Emanuele Troiani, Lenka Zdeborov\'a, Florent Krzakala</dc:creator>
    </item>
    <item>
      <title>Bayes optimal learning of attention-indexed models</title>
      <link>https://arxiv.org/abs/2506.01582</link>
      <description>arXiv:2506.01582v3 Announce Type: replace-cross 
Abstract: We introduce the attention-indexed model (AIM), a theoretical framework for analyzing learning in deep attention layers. Inspired by multi-index models, AIM captures how token-level outputs emerge from layered bilinear interactions over high-dimensional embeddings. Unlike prior tractable attention models, AIM allows full-width key and query matrices, aligning more closely with practical transformers. Using tools from statistical mechanics and random matrix theory, we derive closed-form predictions for Bayes-optimal generalization error and identify sharp phase transitions as a function of sample complexity, model width, and sequence length. We propose a matching approximate message passing algorithm and show that gradient descent can reach optimal performance. AIM offers a solvable playground for understanding learning in self-attention layers, that are key components of modern architectures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01582v3</guid>
      <category>cs.LG</category>
      <category>cond-mat.dis-nn</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>stat.ML</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>NeurIPS 2025</arxiv:journal_reference>
      <dc:creator>Fabrizio Boncoraglio, Emanuele Troiani, Vittorio Erba, Lenka Zdeborov\'a</dc:creator>
    </item>
    <item>
      <title>The neural networks with tensor weights and emergent fermionic Wick rules in the large-width limit</title>
      <link>https://arxiv.org/abs/2507.05303</link>
      <description>arXiv:2507.05303v3 Announce Type: replace-cross 
Abstract: In this paper, we study complex-valued neural network (CVNNs) with tensor-valued hidden-to-output weights within the framework of neural-network quantum field theory (NN-QFT). For standard CVNNs with scalar weights, we derive the generating functional and identify the exact Gaussian process that arises in the infinite-width limit, together with its associated effective quantum state. When the last-layer weights are promoted to Clifford-algebra-valued tensors, the network output becomes complex matrix-valued, and a fermion-like sign structure in the large-width correlation functions of the network output is induced. We show that, in the infinite-width limit, correlators with equal numbers of $f^{\dag}$ and $f$ obey fermionic Wick rules and can be written as determinants built from a scalar Euclidean kernel $S(x,y)=\langle f^{\dag}(x)f(y)\rangle$. This provides a sign-structured extension of NN-QFT at the level of Euclidean correlators and Feynman rules, even though a microscopic Grassmann path integral representation for the network parameters has not yet been constructed. Our analysis thus pushes the NN-QFT correspondence beyond purely bosonic Gaussian fields and suggests a possible route to encoding fermion-like symmetries in neural architectures for QFT correspondence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.05303v3</guid>
      <category>hep-th</category>
      <category>cond-mat.dis-nn</category>
      <category>cs.LG</category>
      <category>hep-ph</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.physletb.2025.140146</arxiv:DOI>
      <arxiv:journal_reference>Phys. Lett. B 873 (2026) 140146</arxiv:journal_reference>
      <dc:creator>Guojun Huang, Kai Zhou</dc:creator>
    </item>
    <item>
      <title>Single-Head Attention in High Dimensions: A Theory of Generalization, Weights Spectra, and Scaling Laws</title>
      <link>https://arxiv.org/abs/2509.24914</link>
      <description>arXiv:2509.24914v2 Announce Type: replace-cross 
Abstract: Trained attention layers exhibit striking and reproducible spectral structure of the weights, including low-rank collapse, bulk deformation, and isolated spectral outliers, yet the origin of these phenomena and their implications for generalization remain poorly understood. We study empirical risk minimization in a single-head tied-attention layer trained on synthetic high-dimensional sequence tasks generated from the attention-indexed model. Using tools from random matrix theory, spin-glass theory, and approximate message passing, we obtain an exact high-dimensional characterization of training and test error, interpolation and recovery thresholds, and the spectrum of the key and query matrices. Our theory predicts the full singular-value distribution of the trained query-key map, including low-rank structure and isolated spectral outliers, in qualitative agreement with observations in more realistic transformers. Finally, for targets with power-law spectra, we show that learning proceeds through sequential spectral recovery, leading to the emergence of power-law scaling laws.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24914v2</guid>
      <category>stat.ML</category>
      <category>cond-mat.dis-nn</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fabrizio Boncoraglio, Vittorio Erba, Emanuele Troiani, Yizhou Xu, Florent Krzakala, Lenka Zdeborov\'a</dc:creator>
    </item>
    <item>
      <title>Triadic percolation on multilayer networks</title>
      <link>https://arxiv.org/abs/2510.09341</link>
      <description>arXiv:2510.09341v2 Announce Type: replace-cross 
Abstract: Triadic interactions are special types of higher-order interactions that occur when regulator nodes modulate the interactions between other two or more nodes. In presence of triadic interactions, a percolation process occurring on a single-layer network becomes a fully-fledged dynamical system, characterized by period-doubling and a route to chaos. Here, we generalize the model to multilayer networks and name it as the multilayer triadic percolation (MTP) model. We find a much richer dynamical behavior of the MTP model than its single-layer counterpart. MTP displays a Neimark-Sacker bifurcation, leading to oscillations of arbitrarily large period or pseudo-periodic oscillations. Moreover, MTP admits period-two oscillations without negative regulatory interactions, whereas single-layer systems only display discontinuous hybrid transitions. This comprehensive model offers new insights on the importance of regulatory interactions in real-world systems such as brain networks, climate, and ecological systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.09341v2</guid>
      <category>nlin.AO</category>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.stat-mech</category>
      <category>nlin.CD</category>
      <category>physics.soc-ph</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1103/yvtg-wnn4</arxiv:DOI>
      <arxiv:journal_reference>Physical Review E 113.1 (2026): 014313</arxiv:journal_reference>
      <dc:creator>Hanlin Sun, Filippo Radicchi, Ginestra Bianconi</dc:creator>
    </item>
    <item>
      <title>High bosonic Bott index and transport of multi-band topological magnons</title>
      <link>https://arxiv.org/abs/2512.24184</link>
      <description>arXiv:2512.24184v2 Announce Type: replace-cross 
Abstract: Magnons are bosonic quasiparticles in magnetically ordered systems. Bosonic Bott index has been affirmed as a real-space topological invariant for a two-band ferromagnetic model. In this work,we theoretically investigate the topology and transport of magnons in a multi-band bosonic Kagome ferromagnetic model. We demonstrate the validity of the bosonic Bott indices of values larger than 1 in multi-band magnonic systems by showing the agreement with Chern numbers in the clean limit and the bulk-boundary correspondence during the topological phase transition. For the high Bott index phase, the disorder-induced topological phase transition occurs in a multi-step manner. Using a generalized Landauer-Buttiker formalism, we reveal how the magnon transport depends on Gilbert damping and disorder under coherent excitation or temperature difference. The results further justify the bosonic Bott index as a robust real-space topological invariant for multi-band magnonic systems and provide insights into the transport of topological magnons.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.24184v2</guid>
      <category>cond-mat.other</category>
      <category>cond-mat.dis-nn</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kai Tao Huang, X. S Wang</dc:creator>
    </item>
    <item>
      <title>A Scalable Measure of Loss Landscape Curvature for Analyzing the Training Dynamics of LLMs</title>
      <link>https://arxiv.org/abs/2601.16979</link>
      <description>arXiv:2601.16979v2 Announce Type: replace-cross 
Abstract: Understanding the curvature evolution of the loss landscape is fundamental to analyzing the training dynamics of neural networks. The most commonly studied measure, Hessian sharpness ($\lambda_{\max}^H$) -- the largest eigenvalue of the loss Hessian -- determines local training stability and interacts with the learning rate throughout training. Despite its significance in analyzing training dynamics, direct measurement of Hessian sharpness remains prohibitive for Large Language Models (LLMs) due to high computational cost. We analyze $\textit{critical sharpness}$ ($\lambda_c$), a computationally efficient measure requiring fewer than $10$ forward passes given the update direction $\Delta \mathbf{\theta}$. Critically, this measure captures well-documented Hessian sharpness phenomena, including progressive sharpening and Edge of Stability. Using this measure, we provide the first demonstration of these sharpness phenomena at scale, up to $7$B parameters, spanning both pre-training and mid-training of OLMo-2 models. We further introduce $\textit{relative critical sharpness}$ ($\lambda_c^{1\to 2}$), which quantifies the curvature of one loss landscape while optimizing another, to analyze the transition from pre-training to fine-tuning and guide data mixing strategies. Critical sharpness provides practitioners with a practical tool for diagnosing curvature dynamics and informing data composition choices at scale. More broadly, our work shows that scalable curvature measures can provide actionable insights for large-scale training.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.16979v2</guid>
      <category>cs.LG</category>
      <category>cond-mat.dis-nn</category>
      <category>cs.AI</category>
      <category>stat.ML</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dayal Singh Kalra, Jean-Christophe Gagnon-Audet, Andrey Gromov, Ishita Mediratta, Kelvin Niu, Alexander H Miller, Michael Shvartsman</dc:creator>
    </item>
  </channel>
</rss>
