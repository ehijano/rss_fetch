<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-fin.ST updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-fin.ST</link>
    <description>q-fin.ST updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-fin.ST" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 05 Jun 2024 01:58:14 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 04 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Machine Learning Methods for Pricing Financial Derivatives</title>
      <link>https://arxiv.org/abs/2406.00459</link>
      <description>arXiv:2406.00459v1 Announce Type: cross 
Abstract: Stochastic differential equation (SDE) models are the foundation for pricing and hedging financial derivatives. The drift and volatility functions in SDE models are typically chosen to be algebraic functions with a small number (less than 5) parameters which can be calibrated to market data. A more flexible approach is to use neural networks to model the drift and volatility functions, which provides more degrees-of-freedom to match observed market data. Training of models requires optimizing over an SDE, which is computationally challenging. For European options, we develop a fast stochastic gradient descent (SGD) algorithm for training the neural network-SDE model. Our SGD algorithm uses two independent SDE paths to obtain an unbiased estimate of the direction of steepest descent. For American options, we optimize over the corresponding Kolmogorov partial differential equation (PDE). The neural network appears as coefficient functions in the PDE. Models are trained on large datasets (many contracts), requiring either large simulations (many Monte Carlo samples for the stock price paths) or large numbers of PDEs (a PDE must be solved for each contract). Numerical results are presented for real market data including S&amp;P 500 index options, S&amp;P 100 index options, and single-stock American options. The neural-network-based SDE models are compared against the Black-Scholes model, the Dupire's local volatility model, and the Heston model. Models are evaluated in terms of how accurate they are at pricing out-of-sample financial derivatives, which is a core task in derivative pricing at financial institutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00459v1</guid>
      <category>q-fin.CP</category>
      <category>q-fin.MF</category>
      <category>q-fin.ST</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lei Fan, Justin Sirignano</dc:creator>
    </item>
    <item>
      <title>Statistics-Informed Parameterized Quantum Circuit via Maximum Entropy Principle for Data Science and Finance</title>
      <link>https://arxiv.org/abs/2406.01335</link>
      <description>arXiv:2406.01335v1 Announce Type: cross 
Abstract: Quantum machine learning has demonstrated significant potential in solving practical problems, particularly in statistics-focused areas such as data science and finance. However, challenges remain in preparing and learning statistical models on a quantum processor due to issues with trainability and interpretability. In this letter, we utilize the maximum entropy principle to design a statistics-informed parameterized quantum circuit (SI-PQC) that efficiently prepares and trains quantum computational statistical models, including arbitrary distributions and their weighted mixtures. The SI-PQC features a static structure with trainable parameters, enabling in-depth optimized circuit compilation, exponential reductions in resource and time consumption, and improved trainability and interpretability for learning quantum states and classical model parameters simultaneously. As an efficient subroutine for preparing and learning in various quantum algorithms, the SI-PQC addresses the input bottleneck and facilitates the injection of prior knowledge.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01335v1</guid>
      <category>quant-ph</category>
      <category>q-fin.ST</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xi-Ning Zhuang, Zhao-Yun Chen, Cheng Xue, Xiao-Fan Xu, Chao Wang, Huan-Yu Liu, Tai-Ping Sun, Yun-Jie Wang, Yu-Chun Wu, Guo-Ping Guo</dc:creator>
    </item>
    <item>
      <title>Time Instability of the Fama-French Multifactor Models: An International Evidence</title>
      <link>https://arxiv.org/abs/2208.01270</link>
      <description>arXiv:2208.01270v3 Announce Type: replace 
Abstract: This paper investigates the time-varying structure of Fama and French's (1993; 2015) multi-factor models using Fama and MacBeth's (1973) two-step estimation based on the rolling window method. In particular, we employ the generalized GRS statistics proposed by Kamstra and Shi (2024) to examine whether the validity of the risk factors (or factor redundancy) in the FF3 and FF5 models remains stable over time, and investigate whether the manner of portfolio sorting affects the time stability of the validity of the risk factors. In addition, we examine whether the similar results are obtained even when we use different datasets by country and region. First, we find that the effectiveness of factors in the FF3 and FF5 models is not stable over time in all countries. Second, the effectiveness of factors is also affected by the manner of portfolio sorting. Third, the validity of the FF3, FF5, and their nested models do not remain stable over time except for Japan. This suggests that the efficient market hypothesis is supported in the Japanese stock market. Finally, the factor redundancy varies over time and is affected by the manner of portfolio sorting mainly in the U.S. and Europe.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.01270v3</guid>
      <category>q-fin.ST</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <category>q-fin.PR</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Koichiro Moriya, Akihiko Noda</dc:creator>
    </item>
    <item>
      <title>An adaptive volatility method for probabilistic forecasting and its application to the M6 financial forecasting competition</title>
      <link>https://arxiv.org/abs/2303.01855</link>
      <description>arXiv:2303.01855v2 Announce Type: replace-cross 
Abstract: In this paper, we address the problem of probabilistic forecasting using an adaptive volatility method rooted in classical time-varying volatility models and leveraging online stochastic optimization algorithms. These principles were successfully applied in the M6 forecasting competition under the team named AdaGaussMC. Our approach takes a unique path by embracing the Efficient Market Hypothesis (EMH) instead of trying to beat the market directly. We focus on evaluating the efficient market, emphasizing the importance of online forecasting in adapting to the dynamic nature of financial markets. The three key points of our approach are: (a) apply the univariate time-varying volatility model AdaVol, (b) obtain probabilistic forecasts of future returns, and (c) optimize the competition metrics using stochastic gradient-based algorithms. We contend that the simplicity of our approach contributes to its robustness and consistency. Remarkably, our performance in the M6 competition resulted in an overall 7th ranking, with a noteworthy 5th position in the forecasting task. This achievement, considering the perceived simplicity of our approach, underscores the efficacy of our adaptive volatility method in the realm of probabilistic forecasting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.01855v2</guid>
      <category>q-fin.PM</category>
      <category>q-fin.ST</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Joseph de Vilmarest, Nicklas Werge</dc:creator>
    </item>
    <item>
      <title>Not feeling the buzz: Correction study of mispricing and inefficiency in online sportsbooks</title>
      <link>https://arxiv.org/abs/2306.01740</link>
      <description>arXiv:2306.01740v3 Announce Type: replace-cross 
Abstract: We present a replication and correction of a recent article (Ramirez, P., Reade, J.J., Singleton, C., Betting on a buzz: Mispricing and inefficiency in online sportsbooks, International Journal of Forecasting, 39:3, 2023, pp. 1413-1423, doi: 10.1016/j.ijforecast.2022.07.011). RRS measure profile page views on Wikipedia to generate a "buzz factor" metric for tennis players and show that it can be used to form a profitable gambling strategy by predicting bookmaker mispricing. Here, we use the same dataset as RRS to reproduce their results exactly, thus confirming the robustness of their mispricing claim. However, we discover that the published betting results are significantly affected by a single bet (the "Hercog" bet), which returns substantial outlier profits based on erroneously long odds. When this data quality issue is resolved, the majority of reported profits disappear and only one strategy, which bets on "competitive" matches, remains significantly profitable in the original out-of-sample period. While one profitable strategy offers weaker support than the original study, it still provides an indication that market inefficiencies may exist, as originally claimed by RRS. As an extension, we continue backtesting after 2020 on a cleaned dataset. Results show that (a) the "competitive" strategy generates no further profits, potentially suggesting markets have become more efficient, and (b) model coefficients estimated over this more recent period are no longer reliable predictors of bookmaker mispricing. We present this work as a case study demonstrating the importance of replication studies in sports forecasting, and the necessity to clean data. We open-source release comprehensive datasets and code.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.01740v3</guid>
      <category>stat.AP</category>
      <category>cs.CE</category>
      <category>q-fin.GN</category>
      <category>q-fin.ST</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lawrence Clegg, John Cartlidge</dc:creator>
    </item>
    <item>
      <title>Review of deep learning models for crypto price prediction: implementation and evaluation</title>
      <link>https://arxiv.org/abs/2405.11431</link>
      <description>arXiv:2405.11431v2 Announce Type: replace-cross 
Abstract: There has been much interest in accurate cryptocurrency price forecast models by investors and researchers. Deep Learning models are prominent machine learning techniques that have transformed various fields and have shown potential for finance and economics. Although various deep learning models have been explored for cryptocurrency price forecasting, it is not clear which models are suitable due to high market volatility. In this study, we review the literature about deep learning for cryptocurrency price forecasting and evaluate novel deep learning models for cryptocurrency stock price prediction. Our deep learning models include variants of long short-term memory (LSTM) recurrent neural networks, variants of convolutional neural networks (CNNs), and the Transformer model. We evaluate univariate and multivariate approaches for multi-step ahead predicting of cryptocurrencies close-price. We also carry out volatility analysis on the four cryptocurrencies which reveals significant fluctuations in their prices throughout the COVID-19 pandemic. Additionally, we investigate the prediction accuracy of two scenarios identified by different training sets for the models. First, we use the pre-COVID-19 datasets to model cryptocurrency close-price forecasting during the early period of COVID-19. Secondly, we utilise data from the COVID-19 period to predict prices for 2023 to 2024. Our results show that the convolutional LSTM with a multivariate approach provides the best prediction accuracy in two major experimental settings.
  Our results also indicate that the multivariate deep learning models exhibit better performance in forecasting four different cryptocurrencies when compared to the univariate models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.11431v2</guid>
      <category>cs.LG</category>
      <category>q-fin.ST</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jingyang Wu, Xinyi Zhang, Fangyixuan Huang, Haochen Zhou, Rohtiash Chandra</dc:creator>
    </item>
  </channel>
</rss>
