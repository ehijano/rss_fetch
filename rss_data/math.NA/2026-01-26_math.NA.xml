<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.NA</link>
    <description>math.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 27 Jan 2026 03:40:44 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Numerical efficiency of explicit time integrators for phase-field models</title>
      <link>https://arxiv.org/abs/2601.16522</link>
      <description>arXiv:2601.16522v1 Announce Type: new 
Abstract: Phase-field simulations are a practical but also expensive tool to calculate microstructural evolution. This work aims to compare explicit time integrators for a broad class of phase-field models involving coupling between the phase-field and concentration. Particular integrators are adapted to constraints on the phase-field as well as storage scheme implications. Reproducible benchmarks are defined with a focus on having exact sharp interface solutions, allowing for identification of dominant error terms. Speedups of 4 to 114 over the classic forward Euler integrator are achievable while still using a fully explicit scheme without appreciable accuracy loss. Application examples include final stage sintering with pores slowing down grain growth as they move and merge over time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.16522v1</guid>
      <category>math.NA</category>
      <category>cond-mat.mtrl-sci</category>
      <category>cs.NA</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marco Seiz, Tomohiro Takaki</dc:creator>
    </item>
    <item>
      <title>The inverse of the star discrepancy of a union of randomly shifted Korobov rank-1 lattice point sets depends polynomially on the dimension</title>
      <link>https://arxiv.org/abs/2601.16571</link>
      <description>arXiv:2601.16571v1 Announce Type: new 
Abstract: The inverse of the star discrepancy, $N(\epsilon, s)$, defined as the minimum number of points required to achieve a star discrepancy of at most $\epsilon$ in dimension $s$, is known to depend linearly on $s$. However, explicit constructions achieving this optimal linear dependence remain elusive. Recently, Dick and Pillichshammer (2025) made significant progress by showing that a multiset union of randomly digitally shifted Korobov polynomial lattice point sets almost achieve the optimal dimension dependence with high probability.
  In this paper, we investigate the analog of this result in the setting of classical integer arithmetic using Fourier analysis. We analyze point sets constructed as multiset unions of Korobov rank-1 lattice point sets modulo a prime $N$. We provide a comprehensive analysis covering four distinct construction scenarios, combining either random or fixed integer generators with either continuous torus shifts or discrete grid shifts. We prove that in all four cases, the star discrepancy is bounded by a term of order $O(s \log(N_{tot}) / \sqrt{N_{tot}})$ with high probability, where $N_{tot}$ is the total number of points. This implies that the inverse of the star discrepancy for these structured sets depends quadratically on the dimension $s$. While the proofs are probabilistic, our results significantly reduce the search space for optimal point sets from a continuum to a finite set of candidates parameterized by integer generators and random shifts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.16571v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiarui Du, Josef Dick</dc:creator>
    </item>
    <item>
      <title>A High-resolution Spatiotemporal Coupling Ghost Fluid Method for Two-Dimensional Compressible Multimedium Flows with Source Terms</title>
      <link>https://arxiv.org/abs/2601.16590</link>
      <description>arXiv:2601.16590v1 Announce Type: new 
Abstract: While exact and approximate Riemann solvers are widely used, they exhibit two fundamental limitations: 1) Fail to represent continuous entropy transport processes, resulting in thermodynamic incompatibility that limits their applicability to compressible flows. 2) Consider only the effects of normal components at interfaces while neglecting the effects of tangential flux and source term, making them unsuitable for multidimensional problems and cases involving source terms. These limitations persist in Riemann problem-based ghost fluid methods. To address these challenges, we developed a novel spatiotemporal coupling high-resolution ghost fluid method featuring two key advancements: 1) Integration of nonlinear geometrical optics to properly account for thermodynamic entropy evolution. 2) Implementation of the Lax-Wendroff/Cauchy-Kowalevski approach to incorporate tangential fluxes and source term effects. These enhancements have been systematically applied to Riemann problem-based ghost fluid methods. Comprehensive numerical experiments demonstrate significant improvements in simulation accuracy and robustness compared to conventional approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.16590v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhixin Huo</dc:creator>
    </item>
    <item>
      <title>A robust and stable hybrid neural network/finite element method for 2D flows that generalizes to different geometries</title>
      <link>https://arxiv.org/abs/2601.16598</link>
      <description>arXiv:2601.16598v1 Announce Type: new 
Abstract: The deep neural network multigrid solver (DNN-MG) combines a coarse-grid finite element simulation with a deep neural network that corrects the solution on finer grid levels, thereby improving the computational efficiency. In this work, we discuss various design choices for the DNN-MG method and demonstrate significant improvements in accuracy and generalizability when applied to the solution of the instationary Navier-Stokes equations. We investigate the stability of the hybrid simulation and show how the neural networks can be made more robust with the help of replay buffers. By retraining on data derived from the hybrid simulation, the error caused by the neural network over multiple time-steps can be minimized without the need for a differentiable numerical solver. Furthermore, we compare multiple neural network architectures, including recurrent neural networks and Transformers, and study their ability to utilize more information from an increased temporal and spatial receptive field. Transformers allow us to make use of information from cells outside the predicted patch even with unstructured meshes while maintaining the locality of our approach. This can further improve the accuracy of DNN-MG without a significant impact on performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.16598v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Robert Jendersie, Nils Margenberg, Christian Lessig, Thomas Richter</dc:creator>
    </item>
    <item>
      <title>Convergent adaptive iterative schemes for solving multi-physics problems</title>
      <link>https://arxiv.org/abs/2601.16640</link>
      <description>arXiv:2601.16640v1 Announce Type: new 
Abstract: In this paper, we derive a practical, general framework for creating adaptive iterative (linearization or splitting) algorithms to solve multi-physics problems. This means that, given an iterative method, we derive \textit{a posteriori} estimators to predict the success or failure of the method. Based on these estimators, we propose adaptive algorithms, including adaptively switching between methods, adaptive time-stepping methods, and the adaptive tuning of stabilization parameters. We apply this framework to two-phase flow in porous media, surfactant transport in porous media, and quasi-static poroelasticity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.16640v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jakob S. Stokke, Kundan Kumar, Florin A. Radu</dc:creator>
    </item>
    <item>
      <title>A Predictor Corrector Convex Splitting Method for Stefan Problems Based on Extreme Learning Machines</title>
      <link>https://arxiv.org/abs/2601.16655</link>
      <description>arXiv:2601.16655v1 Announce Type: new 
Abstract: Solving Stefan problems via neural networks is inherently challenged by the nonlinear coupling between the solutions and the free boundary, which results in a non-convex optimization problem. To address this, this work proposes an Operator Splitting Method (OSM) based on Extreme Learning Machines (ELM) to decouple the geometric interface evolution from the physical field reconstruction. Within a predictor-corrector framework, the method splits the coupled system into an alternating sequence of two linear and convex subproblems: solving the diffusion equation on fixed subdomains and updating the interface geometry based on the Stefan condition. A key contribution is the formulation of both steps as linear least-squares problems; this transforms the computational strategy from a non-convex gradient-based optimization into a stable fixed-point iteration composed of alternating convex solvers. From a theoretical perspective, the relaxed iterative operator is shown to be locally contractive, and its fixed points are consistent with stationary points of the coupled residual functional. Benchmarks across 1D to 3D domains demonstrate the stability and high accuracy of the method, confirming that the proposed framework provides a highly accurate and efficient numerical solution for free boundary problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.16655v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Siyuan Lang, Zhiyue Zhang</dc:creator>
    </item>
    <item>
      <title>Distance to nearest skew-symmetric matrix polynomials of bounded rank</title>
      <link>https://arxiv.org/abs/2601.16676</link>
      <description>arXiv:2601.16676v1 Announce Type: new 
Abstract: We propose an algorithm that approximates a given matrix polynomial of degree $d$ by another skew-symmetric matrix polynomial of a specified rank and degree at most $d$. The algorithm is built on recent advances in the theory of generic eigenstructures and factorizations for skew-symmetric matrix polynomials of bounded rank and degree. Taking into account that the rank of a skew-symmetric matrix polynomial is even, the algorithm works for any prescribed even rank greater than or equal to $2$ and produces a skew-symmetric matrix polynomial of that exact rank. We also adapt the algorithm for matrix pencils to achieve a better performance. Lastly, we present numerical experiments for testing our algorithms and for comparison to the previously known ones.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.16676v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrii Dmytryshyn, Froil\'an M. Dopico, Rakel Hellberg</dc:creator>
    </item>
    <item>
      <title>Barotropic-Baroclinic Splitting for Multilayer Shallow Water Models with Exchanges</title>
      <link>https://arxiv.org/abs/2601.16709</link>
      <description>arXiv:2601.16709v1 Announce Type: new 
Abstract: This work presents the numerical analysis of a barotropic-baroclinic splitting in a nonlinear multilayer framework with exchanges between the layers in terrain-following coordinates. The splitting is formulated as an exact operator splitting. The barotropic step handles free surface evolution and depth-averaged velocity via a well-balanced one-layer model, while the baroclinic step manages vertical exchanges between layers and adjusts velocities to their mean values. We show that the barotropic-baroclinic splitting preserves total energy conservation and meets both a discrete maximum principle and a discrete entropy inequality. Several numerical experiments are presented showing the gain in computational cost, particularly in low Froude simulations, with no loss of accuracy. The benefits of using a well-balancing strategy in the barotropic step to preserve the geostrophic equilibrium are inherited in the overall scheme.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.16709v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nina Aguillon, Sophie H\"ornschemeyer, Jacques Sainte-Marie</dc:creator>
    </item>
    <item>
      <title>A locking-free nodal-based polytopal method for linear elasticity</title>
      <link>https://arxiv.org/abs/2601.16728</link>
      <description>arXiv:2601.16728v1 Announce Type: new 
Abstract: This work presents a Discrete de Rham (DDR) numerical scheme for solving linear elasticity problems on general polyhedral meshes, with a focus on preventing volumetric locking in the quasi-incompressible regime. The method is formulated as a nodal-based approach using the lowest-order gradient space of the DDR complex, enriched with scalar face bubble degrees of freedom that effectively capture the normal flux across element faces. This face-bubble enrichment is crucial for ensuring sufficient approximation flexibility of the divergence field, thereby eliminating the {volumetric locking} phenomenon that typically occurs as the Lam\'e parameter $\lambda$ approaches infinity. We establish $H^1$-error estimates that are independent of $\lambda\ge 0$, and depend only on the lower bound of $\mu$, guaranteeing robustness across the entire range from compressible to nearly incompressible regimes. We also show how to adapt our scheme to the frictionless contact mechanics model, maintaining a locking-free estimate for the primal variable (displacement). Numerical experiments confirm that the proposed {locking-free} method delivers accurate and stable approximations on general polytopal discretizations, even when the material behaves as an incompressible medium. The flexibility and robustness of this approach make it a practical alternative to mixed formulations for engineering applications involving nearly incompressible elastic materials.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.16728v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jerome Droniou, Raman Kumar</dc:creator>
    </item>
    <item>
      <title>On the analysis of spectral deferred corrections for differential-algebraic equations of index one</title>
      <link>https://arxiv.org/abs/2601.16744</link>
      <description>arXiv:2601.16744v1 Announce Type: new 
Abstract: In this paper, we present a new SDC scheme for solving semi-explicit DAEs with the ability to be parallelized in which only the differential equations are numerically integrated is presented. In Shu et al. (2007) it was shown that SDC for ODEs achieves one order per iteration. We show that this carries over to the new SDC scheme. The method is derived from the approach of spectral deferred corrections and the idea of enforcing the algebraic constraints without numerical integration as in the approach of $\varepsilon$-embedding in Hairer and Wanner (1996). It enforces the algebraic constraints to be satisfied in each iteration and allows an efficient solve of semi-explicit DAEs with high-accuracy. The proposed scheme is compared with other DAE methods. We demonstrate that the proposed SDC scheme is competitive with Runge-Kutta methods for DAEs in terms of accuracy and its parallelized versions are very efficient in comparison to other SDC methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.16744v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matthias Bolten, Lisa Wimmer</dc:creator>
    </item>
    <item>
      <title>Adaptive integration of 5-convex and 5-concave functions</title>
      <link>https://arxiv.org/abs/2601.16796</link>
      <description>arXiv:2601.16796v1 Announce Type: new 
Abstract: An adaptive method connected with 3-point Gauss quadrature and 4-point Lobatto quadrature is introduced and investigated for 5-convex functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.16796v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Szymon W\k{a}sowicz</dc:creator>
    </item>
    <item>
      <title>Discrete FEM-BEM coupling with the Generalized Optimized Schwarz Method</title>
      <link>https://arxiv.org/abs/2601.16817</link>
      <description>arXiv:2601.16817v1 Announce Type: new 
Abstract: The present contribution aims at developing a non-overlapping Domain Decomposition (DD) approach to the solution of acoustic wave propagation boundary value problems based on the Helmholtz equation, on both bounded and unbounded domains. This DD solver, called Generalized Optimized Schwarz Method (GOSM), is a substructuring method, that is, the unknowns of an iteration are associated with the subdomains interfaces. We extend the analysis presented in a previous paper of one of the author to a fully discrete setting. We do not consider only a specific set of boundary conditions, but a whole class including, e.g., Dirichlet, Neumann, and Robin conditions. Our analysis will also cover interface conditions corresponding to a Finite Element Method - Boundary Element Method (FEM-BEM) coupling. In particular, we shall focus on three classical FEM-BEM couplings, namely the Costabel, Johnson-N\'ed\'elec and Bielak-MacCamy couplings. As a remarkable outcome, the present contribution yields well-posed substructured formulations of these classical FEM-BEM couplings for wavenumbers different from classical spurious resonances. We also establish an explicit relation between the dimensions of the kernels of the initial variational formulation, the local problems and the substructured formulation. That relation especially holds for any wavenumber for the substructured formulation of Costabel FEM-BEM coupling, which allows us to prove that the latter formulation is well-posed even at spurious resonances. Besides, we introduce a systematically geometrically convergent iterative method for the Costabel FEM-BEM coupling, with estimates on the convergence speed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.16817v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Antonin Boisneault, Marcella Bonazzoli, Xavier Claeys, Pierre Marchand</dc:creator>
    </item>
    <item>
      <title>Cell-vertex WENO schemes with shock-capturing quadrature for high-order finite element discretizations of hyperbolic problems</title>
      <link>https://arxiv.org/abs/2601.16911</link>
      <description>arXiv:2601.16911v1 Announce Type: new 
Abstract: We propose a new kind of localized shock capturing for continuous (CG) and discontinuous Galerkin (DG) discretizations of hyperbolic conservation laws. The underlying framework of dissipation-based weighted essentially nonoscillatory (WENO) stabilization for high-order CG and DG approximations was introduced in our previous work. In this general framework, Hermite WENO (HWENO) reconstructions are used to calculate local smoothness sensors that determine the appropriate amount of artificial viscosity for each cell. In the original version, candidate polynomials for WENO averaging are constructed using the derivative data from von Neumann neighbors. We upgrade this standard `cell-cell' reconstruction procedure by using WENO polynomials associated with mesh vertices as candidate polynomials for cell-based WENO averaging. The Hermite data of individual cells is sent to vertices of those cells, after which vertex-averaged HWENO data is sent back to cells containing the vertices. The new `cell-vertex' averaging procedure includes the data of vertex neighbors without explicitly adding them to the reconstruction stencils. It mitigates mesh imprinting and can also be used in classical HWENO limiters for DG methods. The second main novelty of the proposed approach is a quadrature-driven distribution of artificial viscosity within high-order finite elements. Replacing the linear quadrature weights by their nonlinear WENO-type counterparts, we concentrate shock-capturing dissipation near discontinuities while minimizing it in smooth portions of troubled cells. This redistribution of WENO stabilization preserves the total dissipation rate within each cell and improves local shock resolution without relying on subcell decomposition techniques. Numerical experiments in one and two dimensions demonstrate substantial improvements in accuracy and robustness for high-order elements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.16911v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joshua Vedral, Dmitri Kuzmin</dc:creator>
    </item>
    <item>
      <title>Distributional Computational Graphs: Error Bounds</title>
      <link>https://arxiv.org/abs/2601.16250</link>
      <description>arXiv:2601.16250v1 Announce Type: cross 
Abstract: We study a general framework of distributional computational graphs: computational graphs whose inputs are probability distributions rather than point values. We analyze the discretization error that arises when these graphs are evaluated using finite approximations of continuous probability distributions. Such an approximation might be the result of representing a continuous real-valued distribution using a discrete representation or from constructing an empirical distribution from samples (or might be the output of another distributional computational graph). We establish non-asymptotic error bounds in terms of the Wasserstein-1 distance, without imposing structural assumptions on the computational graph.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.16250v1</guid>
      <category>stat.ML</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Olof Hallqvist Elias, Michael Selby, Phillip Stanley-Marbell</dc:creator>
    </item>
    <item>
      <title>A Constructive Cayley Representation of Orthogonal Matrices and Applications to Optimization</title>
      <link>https://arxiv.org/abs/2601.16271</link>
      <description>arXiv:2601.16271v1 Announce Type: cross 
Abstract: It is known that every real orthogonal matrix can be brought into the domain of the Cayley transform by multiplication with a suitable diagonal signature matrix. In this paper we provide a constructive and numerically efficient algorithm that, given a real orthogonal matrix $U$, computes a diagonal matrix $D$ with entries in $\{\pm1\}$ such that the Cayley transform of $DU$ is well defined. This yields a representation of $U$ in the form \[ U = D(I-S)(I+S)^{-1}, \] where $S$ is a skew-symmetric matrix. The proposed algorithm requires $O(n^{3})$ arithmetic operations and produces an explicit quantitative bound on the associated skew-symmetric generator. As an application, we show how this construction can be used to control singularities in Cayley-transform-based optimization methods on the orthogonal group.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.16271v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.AG</category>
      <category>math.NA</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Iwo Biborski</dc:creator>
    </item>
    <item>
      <title>SeeMPS: A Python-based Matrix Product State and Tensor Train Library</title>
      <link>https://arxiv.org/abs/2601.16734</link>
      <description>arXiv:2601.16734v1 Announce Type: cross 
Abstract: We introduce SeeMPS, a Python library dedicated to implementing tensor network algorithms based on the well-known Matrix Product States (MPS) and Quantized Tensor Train (QTT) formalisms. SeeMPS is implemented as a complete finite precision linear algebra package where exponentially large vector spaces are compressed using the MPS/TT formalism. It enables both low-level operations, such as vector addition, linear transformations, and Hadamard products, as well as high-level algorithms, including the approximation of linear equations, eigenvalue computations, and exponentially efficient Fourier transforms. This library can be used for traditional quantum many-body physics applications and also for quantum-inspired numerical analysis problems, such as solving PDEs, interpolating and integrating multidimensional functions, sampling multivariate probability distributions, etc.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.16734v1</guid>
      <category>quant-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Paula Garc\'ia-Molina, Juan Jos\'e Rodr\'iguez-Aldavero, Jorge Gidi, Juan Jos\'e Garc\'ia-Ripoll</dc:creator>
    </item>
    <item>
      <title>Stochastic Modeling and Resource Dimensioning of Multi-Cellular Edge Intelligent Systems</title>
      <link>https://arxiv.org/abs/2601.16848</link>
      <description>arXiv:2601.16848v1 Announce Type: cross 
Abstract: Edge intelligence enables AI inference at the network edge, co-located with or near the radio access network, rather than in centralized clouds or on mobile devices. It targets low-latency, resource-constrained applications with large data volumes, requiring tight integration of wireless access and on-site computing. Yet system performance and cost-efficiency hinge on joint pre-deployment dimensioning of radio and computational resources, especially under spatial and temporal uncertainty. Prior work largely emphasizes run-time allocation or relies on simplified models that decouple radio and computing, missing end-to-end correlations in large-scale deployments. This paper introduces a unified stochastic framework to dimension multi-cell edge-intelligent systems. We model network topology with Poisson point processes, capturing random user and base-station locations, inter-cell interference, distance-based fractional power control, and peak-power constraints. By combining this with queueing theory and empirical AI inference workload profiling, we derive tractable expressions for end-to-end offloading delay. These enable a non-convex joint optimization that minimizes deployment cost under statistical QoS guarantees, expressed through strict tail-latency and inference-accuracy constraints. We prove the problem decomposes into convex subproblems, yielding global optimality. Numerical results in noise- and interference-limited regimes identify cost-efficient design regions and configurations that cause under-utilization or user unfairness. Smaller cells reduce transmission delay but raise per-request computing cost due to weaker server multiplexing, whereas larger cells show the opposite trend. Densification reduces computational costs only when frequency reuse scales with base-station density; otherwise, sparser deployments improve fairness and efficiency in interference-limited settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.16848v1</guid>
      <category>cs.NI</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.AP</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jaume Anguera Peris, Joakim Jald\'en</dc:creator>
    </item>
    <item>
      <title>Multigrade Neural Network Approximation</title>
      <link>https://arxiv.org/abs/2601.16884</link>
      <description>arXiv:2601.16884v1 Announce Type: cross 
Abstract: We study multigrade deep learning (MGDL) as a principled framework for structured error refinement in deep neural networks. While the approximation power of neural networks is now relatively well understood, training very deep architectures remains challenging due to highly non-convex and often ill-conditioned optimization landscapes. In contrast, for relatively shallow networks, most notably one-hidden-layer $\texttt{ReLU}$ models, training admits convex reformulations with global guarantees, motivating learning paradigms that improve stability while scaling to depth. MGDL builds upon this insight by training deep networks grade by grade: previously learned grades are frozen, and each new residual block is trained solely to reduce the remaining approximation error, yielding an interpretable and stable hierarchical refinement process. We develop an operator-theoretic foundation for MGDL and prove that, for any continuous target function, there exists a fixed-width multigrade $\texttt{ReLU}$ scheme whose residuals decrease strictly across grades and converge uniformly to zero. To the best of our knowledge, this work provides the first rigorous theoretical guarantee that grade-wise training yields provable vanishing approximation error in deep networks. Numerical experiments further illustrate the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.16884v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.ML</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shijun Zhang, Zuowei Shen, Yuesheng Xu</dc:creator>
    </item>
    <item>
      <title>Convergence Analysis of a Stochastic Interacting Particle-Field Algorithm for 3D Parabolic-Parabolic Keller-Segel Systems</title>
      <link>https://arxiv.org/abs/2504.10089</link>
      <description>arXiv:2504.10089v2 Announce Type: replace 
Abstract: Chemotaxis models describe the movement of organisms in response to chemical gradients. In this paper, we present a stochastic interacting particle-field algorithm with a random batch approximation (SIPF-$r$) for the three-dimensional (3D) parabolic-parabolic Keller-Segel (KS) system, also referred to as the fully parabolic KS system. The SIPF-$r$ method approximates the KS system by coupling particle-based representations of the density with a smooth field variable computed using spectral methods. By incorporating the random batch method (RBM), we bypass the mean-field limit and significantly reduce computational complexity. Under mild assumptions on the regularity of the original KS system and the boundedness of numerical approximations, we prove that the empirical measure of the SIPF-$r$ particle system converges, with high probability, to the exact measure of the limiting McKean-Vlasov process in the $1$-Wasserstein distance. Finally, we present numerical experiments to validate the theoretical convergence rates, and demonstrate the performance and robustness of the SIPF-$r$ method as a diagnostic tool for intense focusing and potential finite-time singularity in 3D, subject to critical initial mass thresholds in the system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.10089v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Boyi Hu, Zhongjian Wang, Jack Xin, Zhiwen Zhang</dc:creator>
    </item>
    <item>
      <title>Parametric Model Order Reduction by Box Clustering with Applications in Mechatronic Systems</title>
      <link>https://arxiv.org/abs/2505.11255</link>
      <description>arXiv:2505.11255v2 Announce Type: replace 
Abstract: High temperatures and structural deformations can compromise the functionality and reliability of new components for mechatronic systems. Therefore, high-fidelity simulations (HFS) are employed during the design process, as they enable a detailed analysis of the thermal and structural behavior of the system. However, such simulations are both computationally expensive and tedious, particularly during iterative optimization procedures. Establishing a parametric reduced order model (pROM) can accelerate the design's optimization if the model can accurately predict the behavior over a wide range of material and geometric properties. However, many existing methods exhibit limitations when applied to wide design ranges. In this work, we introduce the parametric Box Reduction (pBR) method, a matrix interpolation technique that minimizes the non-physical influence of training points due to the large parameter ranges. For this purpose, we define a new interpolation function that computes a local weight for each design variable and integrates them into the global function. Furthermore, we develop an intuitive clustering technique to select the training points for the model, avoiding numerical artifacts from distant points. Additionally, these two strategies do not require normalizing the parameter space and handle every property equally. The effectiveness of the pBR method is validated through two physical applications: structural deformation of a cantilever Timoshenko beam and heat transfer of a power module of a power converter. The results demonstrate that the pBR approach can accurately capture the behavior of mechatronic components across large parameter ranges without sacrificing computational efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.11255v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Juan Angelo Vargas-Fajardo, Diana Manvelyan-Stroot, Catharina Czech, Pietro Botazzoli, Fabian Duddeck</dc:creator>
    </item>
    <item>
      <title>The Bayesian Finite Element Method in Inverse Problems: a Critical Comparison between Probabilistic Models for Discretization Error</title>
      <link>https://arxiv.org/abs/2506.02815</link>
      <description>arXiv:2506.02815v2 Announce Type: replace 
Abstract: When using the finite element method (FEM) in inverse problems, its discretization error can produce parameter estimates that are inaccurate and overconfident. The Bayesian finite element method (BFEM) provides a probabilistic model for the epistemic uncertainty due to discretization error. In this work, we apply BFEM to various inverse problems, and compare its performance to the random mesh finite element method (RM-FEM) and the statistical finite element method (statFEM), which serve as a frequentist and inference-based counterpart to BFEM. We find that by propagating this uncertainty to the posterior, BFEM can produce more accurate parameter estimates and prevent overconfidence, compared to FEM. Because the BFEM covariance operator is designed to leave uncertainty only in the appropriate space, orthogonal to the FEM basis, BFEM is able to outperform RM-FEM, which does not have such a structure to its covariance. Although inferring the discretization error via a model misspecification component is possible as well, as is done in statFEM, the feasibility of such an approach is contingent on the availability of sufficient data. We find that the BFEM is the most robust way to consistently propagate uncertainty due to discretization error to the posterior of a Bayesian inverse problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02815v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anne Poot, Iuri Rocha, Pierre Kerfriden, Frans van der Meer</dc:creator>
    </item>
    <item>
      <title>Pointwise-in-time error bounds for semilinear and quasilinear fractional subdiffusion equations on graded meshes</title>
      <link>https://arxiv.org/abs/2506.12954</link>
      <description>arXiv:2506.12954v2 Announce Type: replace 
Abstract: Time-fractional semilinear and quasilinear parabolic equations with a Caputo time derivative of order $\alpha\in(0,1)$ are considered, solutions of which exhibit a singular behaviour at an initial time of type $t^\sigma$ for any fixed $\sigma \in (0,1) \cup (1,2)$. The L1 scheme in time is combined with a general class of discretizations for the semilinear term. For such discretizations, we obtain sharp pointwise-in-time error bounds on graded temporal meshes with arbitrary degree of grading. Both semi-discretizations in time and full discretizations using finite differences and finite elements in space are addressed. The theoretcal findings are illustrated by numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.12954v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Natalia Kopteva, Sean Kelly</dc:creator>
    </item>
    <item>
      <title>Physics-Constrained Learning of Energy-Preserving Stencils for Maxwell's Equations</title>
      <link>https://arxiv.org/abs/2601.01902</link>
      <description>arXiv:2601.01902v4 Announce Type: replace 
Abstract: We study data-driven construction of spatial discretizations for the one-dimensional Maxwell system. Using high-fidelity training data from a spectral discretization, we learn a \emph{linear convolution stencil} that approximates the spatial derivative operator in Maxwell's equations. We formulate a convex quadratic program for the stencil coefficients with linear constraints that enforce skew-adjointness of the discrete derivative; these constraints guarantee a semi-discrete electromagnetic energy identity and yield a CFL condition expressed directly in terms of the stencil's Fourier symbol. We compare several convex solvers for the resulting quadratic program -- projected gradient, Nesterov-accelerated gradient, ADMM, and an interior-point reference implemented in CVXPY -- and evaluate the learned operators in time-dependent Maxwell simulations using a Crank--Nicolson (CN) discretization. Numerical experiments, including cases with nonstandard target operators and noisy training data, show that (i) energy-constrained learned stencils achieve accuracy comparable to standard central differences while exactly preserving the discrete electromagnetic energy under CN time-stepping, and (ii) ADMM and interior-point solvers produce nearly identical operators, with ADMM offering a favorable tradeoff between accuracy, constraint satisfaction, and runtime.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.01902v4</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Victory Obieke</dc:creator>
    </item>
    <item>
      <title>Frank-Wolfe algorithm for DC optimization problem</title>
      <link>https://arxiv.org/abs/2308.16444</link>
      <description>arXiv:2308.16444v3 Announce Type: replace-cross 
Abstract: In the present paper, we formulate two versions of Frank--Wolfe algorithm or conditional gradient method to solve the DC optimization problem with an adaptive step size. The DC objective function consists of two components; the first is thought to be differentiable with a continuous Lipschitz gradient, while the second is only thought to be convex. The second version is based on the first and employs finite differences to approximate the gradient of the first component of the objective function. In contrast to past formulations that used the curvature/Lipschitz-type constant of the objective function, the step size computed does not require any constant associated with the components. For the first version, we established that the algorithm is well-defined of the algorithm and that every limit point of the generated sequence is a stationary point of the problem. We also introduce the class of weak-star-convex functions and show that, despite the fact that these functions are non-convex in general, the rate of convergence of the first version of the algorithm to minimize these functions is ${\cal O}(1/k)$. The finite difference used to approximate the gradient in the second version of the Frank-Wolfe algorithm is computed with the step-size adaptively updated using two previous iterations. Unlike previous applications of finite difference in the Frank-Wolfe algorithm, which provided approximate gradients with absolute error, the one used here provides us with a relative error, simplifying the algorithm analysis. In this case, we show that all limit points of the generated sequence for the second version of the Frank-Wolfe algorithm are stationary points for the problem under consideration, and we establish that the rate of convergence for the duality gap is ${\cal O}(1/\sqrt{k})$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.16444v3</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>R. D\'iaz Mill\'an, O. P. Ferreira, J. Ugon</dc:creator>
    </item>
    <item>
      <title>Entropic transfer operators for stochastic systems</title>
      <link>https://arxiv.org/abs/2503.05308</link>
      <description>arXiv:2503.05308v2 Announce Type: replace-cross 
Abstract: Dynamical systems can be analyzed via their Frobenius-Perron transfer operator and its estimation from data is an active field of research. Recently entropic transfer operators have been introduced to estimate the operator of deterministic systems. The approach is based on the regularizing properties of entropic optimal transport plans. In this article we generalize the method to stochastic and non-stationary systems and give a quantitative convergence analysis of the empirical operator as the available samples increase. We introduce a way to extend the operator's eigenfunctions to previously unseen samples, such that they can be efficiently included into a spectral embedding. The practicality and numerical scalability of the method are demonstrated on a real-world fluid dynamics experiment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.05308v2</guid>
      <category>math.DS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hancheng Bi, Cl\'ement Sarrazin, Bernhard Schmitzer, Thilo D. Stier</dc:creator>
    </item>
    <item>
      <title>Interpretable and flexible non-intrusive reduced-order models using reproducing kernel Hilbert spaces</title>
      <link>https://arxiv.org/abs/2506.10224</link>
      <description>arXiv:2506.10224v2 Announce Type: replace-cross 
Abstract: This paper develops an interpretable, non-intrusive reduced-order modeling technique using regularized kernel interpolation. Existing non-intrusive approaches approximate the dynamics of a reduced-order model (ROM) by solving a data-driven least-squares regression problem for low-dimensional matrix operators. Our approach instead leverages regularized kernel interpolation, which yields an optimal approximation of the ROM dynamics from a user-defined reproducing kernel Hilbert space. We show that our kernel-based approach can produce interpretable ROMs whose structure mirrors full-order model structure by embedding judiciously chosen feature maps into the kernel. The approach is flexible and allows a combination of informed structure through feature maps and closure terms via more general nonlinear terms in the kernel. We also derive a computable a posteriori error bound that combines standard error estimates for intrusive projection-based ROMs and kernel interpolants. The approach is demonstrated in several numerical experiments that include comparisons to operator inference using both proper orthogonal decomposition and quadratic manifold dimension reduction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10224v2</guid>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.cma.2026.118734</arxiv:DOI>
      <arxiv:journal_reference>Computer Methods in Applied Mechanics and Engineering 452A (2026), 118734</arxiv:journal_reference>
      <dc:creator>Alejandro N Diaz, Shane A McQuarrie, John T Tencer, Patrick J Blonigan</dc:creator>
    </item>
    <item>
      <title>RONOM: Reduced-Order Neural Operator Modeling</title>
      <link>https://arxiv.org/abs/2507.12814</link>
      <description>arXiv:2507.12814v2 Announce Type: replace-cross 
Abstract: Time-dependent partial differential equations are ubiquitous in physics-based modeling, but they remain computationally intensive in many-query scenarios, such as real-time forecasting, optimal control, and uncertainty quantification. Reduced-order modeling (ROM) addresses these challenges by constructing a low-dimensional surrogate model but relies on a fixed discretization, which limits flexibility across varying meshes during evaluation. Operator learning approaches, such as neural operators, offer an alternative by parameterizing mappings between infinite-dimensional function spaces, enabling adaptation to data across different resolutions. Whereas ROM provides rigorous numerical error estimates, neural operator learning largely focuses on discretization convergence and invariance without quantifying the error between the infinite-dimensional and the discretized operators. This work introduces the reduced-order neural operator modeling (RONOM) framework, which bridges concepts from ROM and operator learning. We establish a discretization error bound analogous to those in ROM, and get insights into RONOM's discretization convergence and discretization robustness. Moreover, three numerical examples are presented that compare RONOM to existing neural operators for solving partial differential equations. The results demonstrate that RONOM using standard vector-to-vector neural networks can achieve comparable performance in input generalization and achieves superior performance in both spatial super-resolution and discretization robustness, while also offering novel insights into temporal super-resolution scenarios and ROM-based approaches for learning on time-dependent data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.12814v2</guid>
      <category>cs.LG</category>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Sven Dummer, Dongwei Ye, Christoph Brune</dc:creator>
    </item>
  </channel>
</rss>
