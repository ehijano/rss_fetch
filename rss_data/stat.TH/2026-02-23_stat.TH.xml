<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.TH updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.TH</link>
    <description>stat.TH updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.TH" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 23 Feb 2026 05:00:22 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 23 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Central limit theorem for the global clustering coefficient of random geometric graphs</title>
      <link>https://arxiv.org/abs/2602.17896</link>
      <description>arXiv:2602.17896v1 Announce Type: new 
Abstract: The global clustering coefficient serves as a powerful metric for the structural analysis and comparison of complex networks. Random geometric graphs offer a realistic framework for representing the spatial constraints and geometry often found in real-world network datasets. In this paper, we establish a central limit theorem for the global clustering coefficient of random geometric graphs. Our main result identifies the centering and scaling sequences required for convergence in law to the standard normal distribution. Our approach varies by regime: in the dense case, we employ the Lyapunov CLT; in the intermediate case, we utilize the asymptotic theory of $U$-statistics with sample-size-dependent kernels; and in the sparse regime, we use the method of moments to derive the asymptotic distribution. Notably, the convergence rates for non-uniform and uniform random geometric graphs diverge in the dense regime, yet they coincide in the sparse regime. In addition, we find that the global clustering coefficient for both uniform and non-uniform RGGs is asymptotically equal to $3/4$</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.17896v1</guid>
      <category>math.ST</category>
      <category>stat.OT</category>
      <category>stat.TH</category>
      <pubDate>Mon, 23 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Mingao Yuan, Md. Niamul Islam Sium</dc:creator>
    </item>
    <item>
      <title>Minimax optimal adaptive structured transfer learning through semi-parametric domain-varying coefficient model</title>
      <link>https://arxiv.org/abs/2602.17967</link>
      <description>arXiv:2602.17967v1 Announce Type: new 
Abstract: Transfer learning aims to improve inference in a target domain by leveraging information from related source domains, but its effectiveness critically depends on how cross-domain heterogeneity is modeled and controlled. When the conditional mechanism linking covariates and responses varies across domains, indiscriminate information pooling can lead to negative transfer, degrading performance relative to target-only estimation. We study a multi-source, single-target transfer learning problem under conditional distributional drift and propose a semiparametric domain-varying coefficient model (DVCM), in which domain-relatedness is encoded through an observable domain identifier. This framework generalizes classical varying-coefficient models to structured transfer learning and interpolates between invariant and fully heterogeneous regimes. Building on this model, we develop an adaptive transfer learning estimator that selectively borrows strength from informative source domains while provably safeguarding against negative transfer. Our estimator is computationally efficient and easy to implement; we also show that it is minimax rate-optimal and derive its asymptotic distribution, enabling valid uncertainty quantification and hypothesis testing despite data-adaptive pooling and shrinkage. Our results precisely characterize the interplay among domain heterogeneity, the smoothness of the underlying mean function, and the number of source domains and are corroborated by comprehensive numerical experiments and two real-data applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.17967v1</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Mon, 23 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hanxiao Chen, Debarghya Mukherjee</dc:creator>
    </item>
    <item>
      <title>Kolmogorov-Type Maximal Inequalities for Independent and Dependent Negative Binomial Random Variables: Sharp Bounds, Sub-Exponential Refinements, and Applications to Overdispersed Count Data</title>
      <link>https://arxiv.org/abs/2602.18184</link>
      <description>arXiv:2602.18184v1 Announce Type: new 
Abstract: This paper develops Kolmogorov-type maximal inequalities for sums of Negative Binomial random variables under both independence and dependence structures. For independent heterogeneous Negative Binomial variables we derive sharp Markov-type deviation inequalities and Kolmogorov-type bounds expressed in terms of Tweedie dispersion parameters, providing explicit control limits for NB2 generalized linear model monitoring. For dependent count data arising through a shared Gamma mixing variable, we establish a \emph{sub-exponential Bernstein-type refinement} that exploits the Poisson-Gamma hierarchical structure to yield exponentially decaying tail probabilities -- this refinement is new in the literature. Through moment-matched Monte Carlo experiments ($n=20$, 2{,}000 replications), we document a 55\% reduction in mean maximum deviation under appropriate dependence structures, a stabilization effect we explain analytically. A concrete epidemiological application with NB2 parameters calibrated from COVID-19 surveillance data demonstrates practical utility. These results materially advance the applicability of classical maximal inequalities to overdispersed and dependent count data prevalent in public health, insurance, and ecological modeling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.18184v1</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Mon, 23 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Aristides V. Doumas, S. Spektor</dc:creator>
    </item>
    <item>
      <title>Quantitative concentration inequalities for the uniform approximation of the IDS</title>
      <link>https://arxiv.org/abs/2602.18214</link>
      <description>arXiv:2602.18214v1 Announce Type: new 
Abstract: The integrated density of states (IDS) is a fundamental spectral quantity for quantum Hamiltonians modeling condensed matter systems, describing how densely energy levels are distributed. It can be interpreted as a volume-averaged spectral distribution. Hence, there are two equivalent definitions of the IDS related by the Pastur-Shubin formula: an operator-theoretic trace formula and a limit of normalized eigenvalue counting functions on finite volumes. We study a discrete random Schr\"odinger operator with bounded random potentials of finite-range correlations and prove a quantitative concentration inequality ensuring, with explicit high probability, that the empirical IDS (normalized eigenvalue counting function) uniformly approximates the abstract IDS trace formula within a prescribed error, thereby implying confidence regions for the IDS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.18214v1</guid>
      <category>math.ST</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.SP</category>
      <category>stat.TH</category>
      <pubDate>Mon, 23 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Max K\"amper, Christoph Schumacher, Fabian Schwarzenberger, Ivan Veselic</dc:creator>
    </item>
    <item>
      <title>Bayesian Optimality of In-Context Learning with Selective State Spaces</title>
      <link>https://arxiv.org/abs/2602.17744</link>
      <description>arXiv:2602.17744v1 Announce Type: cross 
Abstract: We propose Bayesian optimal sequential prediction as a new principle for understanding in-context learning (ICL). Unlike interpretations framing Transformers as performing implicit gradient descent, we formalize ICL as meta-learning over latent sequence tasks. For tasks governed by Linear Gaussian State Space Models (LG-SSMs), we prove a meta-trained selective SSM asymptotically implements the Bayes-optimal predictor, converging to the posterior predictive mean. We further establish a statistical separation from gradient descent, constructing tasks with temporally correlated noise where the optimal Bayesian predictor strictly outperforms any empirical risk minimization (ERM) estimator. Since Transformers can be seen as performing implicit ERM, this demonstrates selective SSMs achieve lower asymptotic risk due to superior statistical efficiency. Experiments on synthetic LG-SSM tasks and a character-level Markov benchmark confirm selective SSMs converge faster to Bayes-optimal risk, show superior sample efficiency with longer contexts in structured-noise settings, and track latent states more robustly than linear Transformers. This reframes ICL from "implicit optimization" to "optimal inference," explaining the efficiency of selective SSMs and offering a principled basis for architecture design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.17744v1</guid>
      <category>cs.LG</category>
      <category>cs.CL</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Mon, 23 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Di Zhang, Jiaqi Xing</dc:creator>
    </item>
    <item>
      <title>Interactive Learning of Single-Index Models via Stochastic Gradient Descent</title>
      <link>https://arxiv.org/abs/2602.17876</link>
      <description>arXiv:2602.17876v1 Announce Type: cross 
Abstract: Stochastic gradient descent (SGD) is a cornerstone algorithm for high-dimensional optimization, renowned for its empirical successes. Recent theoretical advances have provided a deep understanding of how SGD enables feature learning in high-dimensional nonlinear models, most notably the \textit{single-index model} with i.i.d. data. In this work, we study the sequential learning problem for single-index models, also known as generalized linear bandits or ridge bandits, where SGD is a simple and natural solution, yet its learning dynamics remain largely unexplored. We show that, similar to the optimal interactive learner, SGD undergoes a distinct ``burn-in'' phase before entering the ``learning'' phase in this setting. Moreover, with an appropriately chosen learning rate schedule, a single SGD procedure simultaneously achieves near-optimal (or best-known) sample complexity and regret guarantees across both phases, for a broad class of link functions. Our results demonstrate that SGD remains highly competitive for learning single-index models under adaptive data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.17876v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 23 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nived Rajaraman, Yanjun Han</dc:creator>
    </item>
    <item>
      <title>Learning from Biased and Costly Data Sources: Minimax-optimal Data Collection under a Budget</title>
      <link>https://arxiv.org/abs/2602.17894</link>
      <description>arXiv:2602.17894v1 Announce Type: cross 
Abstract: Data collection is a critical component of modern statistical and machine learning pipelines, particularly when data must be gathered from multiple heterogeneous sources to study a target population of interest. In many use cases, such as medical studies or political polling, different sources incur different sampling costs. Observations often have associated group identities (for example, health markers, demographics, or political affiliations) and the relative composition of these groups may differ substantially, both among the source populations and between sources and target population.
  In this work, we study multi-source data collection under a fixed budget, focusing on the estimation of population means and group-conditional means. We show that naive data collection strategies (e.g. attempting to "match" the target distribution) or relying on standard estimators (e.g. sample mean) can be highly suboptimal. Instead, we develop a sampling plan which maximizes the effective sample size: the total sample size divided by $D_{\chi^2}(q\mid\mid\overline{p}) + 1$, where $q$ is the target distribution, $\overline{p}$ is the aggregated source distribution, and $D_{\chi^2}$ is the $\chi^2$-divergence. We pair this sampling plan with a classical post-stratification estimator and upper bound its risk. We provide matching lower bounds, establishing that our approach achieves the budgeted minimax optimal risk. Our techniques also extend to prediction problems when minimizing the excess risk, providing a principled approach to multi-source learning with costly and heterogeneous data sources.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.17894v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 23 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael O. Harding, Vikas Singh, Kirthevasan Kandasamy</dc:creator>
    </item>
    <item>
      <title>A variational framework for modal estimation</title>
      <link>https://arxiv.org/abs/2602.17956</link>
      <description>arXiv:2602.17956v1 Announce Type: cross 
Abstract: We approach multivariate mode estimation through Gibbs distributions and introduce GERVE (Gibbs-measure Entropy-Regularised Variational Estimation), a likelihood-free framework that approximates Gibbs measures directly from samples by maximizing an entropy-regularised variational objective with natural-gradient updates. GERVE brings together kernel density estimation, mean-shift, variational inference, and annealing in a single platform for mode estimation. It fits Gaussian mixtures that concentrate on high-density regions and yields cluster assignments from responsibilities, with reduced sensitivity to the chosen number of components. We provide theory in two regimes: as the Gibbs temperature approaches zero, mixture components converge to population modes; at fixed temperature, maximisers of the empirical objective exist, are consistent, and are asymptotically normal. We also propose a bootstrap procedure for per-mode confidence ellipses and stability scores. Simulation and real-data studies show accurate mode recovery and emergent clustering, robust to mixture overspecification. GERVE is a practical likelihood-free approach when the number of modes or groups is unknown and full density estimation is impractical.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.17956v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.TH</category>
      <pubDate>Mon, 23 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>T\^am LeMinh, Julyan Arbel, Florence Forbes, Hien Duy Nguyen</dc:creator>
    </item>
    <item>
      <title>On the Generalization and Robustness in Conditional Value-at-Risk</title>
      <link>https://arxiv.org/abs/2602.18053</link>
      <description>arXiv:2602.18053v1 Announce Type: cross 
Abstract: Conditional Value-at-Risk (CVaR) is a widely used risk-sensitive objective for learning under rare but high-impact losses, yet its statistical behavior under heavy-tailed data remains poorly understood. Unlike expectation-based risk, CVaR depends on an endogenous, data-dependent quantile, which couples tail averaging with threshold estimation and fundamentally alters both generalization and robustness properties. In this work, we develop a learning-theoretic analysis of CVaR-based empirical risk minimization under heavy-tailed and contaminated data. We establish sharp, high-probability generalization and excess risk bounds under minimal moment assumptions, covering fixed hypotheses, finite and infinite classes, and extending to $\beta$-mixing dependent data; we further show that these rates are minimax optimal. To capture the intrinsic quantile sensitivity of CVaR, we derive a uniform Bahadur-Kiefer type expansion that isolates a threshold-driven error term absent in mean-risk ERM and essential in heavy-tailed regimes. We complement these results with robustness guarantees by proposing a truncated median-of-means CVaR estimator that achieves optimal rates under adversarial contamination. Finally, we show that CVaR decisions themselves can be intrinsically unstable under heavy tails, establishing a fundamental limitation on decision robustness even when the population optimum is well separated. Together, our results provide a principled characterization of when CVaR learning generalizes and is robust, and when instability is unavoidable due to tail scarcity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.18053v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 23 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dinesh Karthik Mulumudi, Piyushi Manupriya, Gholamali Aminian, Anant Raj</dc:creator>
    </item>
    <item>
      <title>Semiparametric Uncertainty Quantification via Isotonized Posterior for Deconvolutions</title>
      <link>https://arxiv.org/abs/2602.18210</link>
      <description>arXiv:2602.18210v1 Announce Type: cross 
Abstract: We address the problem of uncertainty quantification for the deconvolution model \(Z = X + Y\), where \(X\) and \(Y\) are nonnegative random variables and the goal is to estimate the signal's distribution of \(X \sim F_0\) supported on~\([0,\infty)\), from observations where the noise distribution is known. Existing frequentist methods often produce confidence intervals for $F_0(x)$ that depend on unknown nuisance parameters, such as the density of \(X\) and its derivative, which are difficult to estimate in practice. This paper introduces a novel and computationally efficient nonparametric Bayesian approach, based on projecting the posterior, to overcome this limitation. Our method leverages the solution \(p\) to a specific Volterra integral equation as in \cite{74}, which relates the cumulative distribution function (CDF) of the signal, \(F_0\), to the distribution of the observables. We place a Dirichlet Process prior directly on the distribution of the observed data $Z$, yielding a simple, conjugate posterior. To ensure the resulting estimates for \(F_0\) are valid CDFs, we isotonize posterior draws taking the Greatest Convex Majorant of the primitive of the posterior draws and defining what we term the Isotonic Inverse Posterior. We show that this framework yields posterior credible sets for \(F_0\) that are not only computationally fast to generate but also possess asymptotically correct frequentist coverage after a straightforward recalibration technique for the so-called Bayes Chernoff distribution introduced in \cite{54}. Our approach thus does not require the estimation of nuisance parameters to deliver uncertainty quantification for the parameter of interest $F_0(x)$. The practical effectiveness and robustness of the method are demonstrated through a simulation study with various noise distributions for $Y$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.18210v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 23 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Francesco Gili, Geurt Jongbloed</dc:creator>
    </item>
    <item>
      <title>Design-based inference for generalized causal effects in randomized experiments</title>
      <link>https://arxiv.org/abs/2602.18383</link>
      <description>arXiv:2602.18383v1 Announce Type: cross 
Abstract: Generalized causal effect estimands, including the Mann-Whitney parameter and causal net benefit, provide flexible summaries of treatment effects in randomized experiments with non-Gaussian or multivariate outcomes. We develop a unified design-based inference framework for regression adjustment and variance estimation of a broad class of generalized causal effect estimands defined through pairwise contrast functions. Leveraging the theory of U-statistics and finite-population asymptotics, we establish the consistency and asymptotic normality of regression estimators constructed from individual pairs and per-unit pair averages, even when the working models are misspecified. Consequently, these estimators are model-assisted rather than model-based. In contrast to classical average treatment effect estimands, we show that for nonlinear contrast functions, covariate adjustment preserves consistency but does not admit a universal efficiency guarantee. For inference, we demonstrate that standard heteroskedasticity-robust and cluster-robust variance estimators are generally inconsistent in this setting. As a remedy, we prove that a complete two-way cluster-robust variance estimator, which fully accounts for pairwise dependence and reverse comparisons, is consistent.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.18383v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 23 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xinyuan Chen, Fan Li</dc:creator>
    </item>
    <item>
      <title>Asymptotically normal estimators in high-dimensional linear regression</title>
      <link>https://arxiv.org/abs/2602.07480</link>
      <description>arXiv:2602.07480v3 Announce Type: replace 
Abstract: We establish asymptotic normality for estimators in high-dimensional linear regression by proving weak convergence in a separable Hilbert space, thereby enabling direct use of standard asymptotic tools, for example, the continuous mapping theorem. The approach allows the number of non-zero coefficients to grow, provided only a fixed number have moderate magnitude. As an application, we test linear hypotheses with a statistic whose null limit is a finite weighted sum of independent chi-squared variables, yielding plug-in critical values with asymptotically correct size.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07480v3</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 23 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kou Fujimori, Koji Tsukuda</dc:creator>
    </item>
    <item>
      <title>Non-Stationary Covariance Functions for Spatial Data on Linear Networks</title>
      <link>https://arxiv.org/abs/2602.15328</link>
      <description>arXiv:2602.15328v2 Announce Type: replace 
Abstract: We introduce a novel class of non-stationary covariance functions for random fields on linear networks that allows both the variance and the correlation range of the random field to vary spatially. The proposed covariance functions are useful to model random fields with a spatial dependence that is locally isotropic with respect to the resistance metric, a distance that reflects the topology of the network. The framework admits explicit stochastic representations of the associated random fields and can be naturally extended to matrix-valued covariance functions for vector-valued random fields. We assess the statistical and computational performance of a weighted local likelihood estimator for the proposed models using synthetic data generated on the street network of the University of Chicago neighborhood.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15328v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 23 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alfredo Alegr\'ia</dc:creator>
    </item>
    <item>
      <title>Large deviations for Independent Metropolis Hastings and Metropolis-adjusted Langevin algorithm</title>
      <link>https://arxiv.org/abs/2403.08691</link>
      <description>arXiv:2403.08691v4 Announce Type: replace-cross 
Abstract: In this paper, we prove large deviation principles for the empirical measures associated with the Independent Metropolis Hastings (IMH) sampler and the Metropolis-adjusted Langevin Algorithm (MALA). These are the first large deviation results for empirical measures of Markov chains arising from specific Metropolis-Hastings methods on a continuous state space. Moreover, we show that the existing large deviation framework, that we developed in a previous work (Milinanni and Nyquist, 2024), does not cover the Random Walk Metropolis sampler, even in cases when the underlying Markov chain is geometrically ergodic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.08691v4</guid>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 23 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Federica Milinanni, Pierre Nyquist</dc:creator>
    </item>
    <item>
      <title>Lean Formalization of Generalization Error Bound by Rademacher Complexity and Dudley's Entropy Integral</title>
      <link>https://arxiv.org/abs/2503.19605</link>
      <description>arXiv:2503.19605v4 Announce Type: replace-cross 
Abstract: Understanding and certifying the generalization performance of machine learning algorithms -- i.e. obtaining theoretical estimates of the test error from a finite training sample -- is a central theme of statistical learning theory. Among the many complexity measures used to derive such guarantees, Rademacher complexity yields sharp, data-dependent bounds that apply well beyond classical $0$--$1$ classification. In this study, we formalize the generalization error bound by Rademacher complexity in Lean 4, building on measure-theoretic probability theory available in the Mathlib library. Our development provides a mechanically-checked pipeline from the definitions of empirical and expected Rademacher complexity, through a formal symmetrization argument and a bounded-differences analysis, to high-probability uniform deviation bounds via a formally proved McDiarmid inequality. A key technical contribution is a reusable mechanism for lifting results from countable hypothesis classes (where measurability of suprema is straightforward in Mathlib) to separable topological index sets via a reduction to a countable dense subset. As worked applications of the abstract theorem, we mechanize standard empirical Rademacher bounds for linear predictors under $\ell_2$ and $\ell_1$ regularization, and we also formalize a Dudley-type entropy integral bound based on covering numbers and a chaining construction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.19605v4</guid>
      <category>cs.LG</category>
      <category>cs.CL</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 23 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sho Sonoda, Kazumi Kasaura, Yuma Mizuno, Kei Tsukamoto, Naoto Onda</dc:creator>
    </item>
    <item>
      <title>Assimilative Causal Inference</title>
      <link>https://arxiv.org/abs/2505.14825</link>
      <description>arXiv:2505.14825v2 Announce Type: replace-cross 
Abstract: Causal inference is fundamental across scientific disciplines, yet existing methods struggle to capture instantaneous, time-evolving causal relationships in complex, high-dimensional systems. In this paper, assimilative causal inference (ACI) is developed, which is a methodological framework that leverages Bayesian data assimilation to trace causes backward from observed effects. ACI solves the inverse problem rather than quantifying forward influence. It uniquely identifies dynamic causal interactions without requiring observations of candidate causes, accommodates short datasets, and, in principle, can be implemented in high-dimensional settings by employing efficient data assimilation algorithms. Crucially, it provides online tracking of causal roles that may reverse intermittently and facilitates a mathematically rigorous criterion for the causal influence range, revealing how far effects propagate. The effectiveness of ACI is demonstrated by complex dynamical systems showcasing intermittency and extreme events. ACI opens valuable pathways for studying complex systems, where transient causal structures are critical.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.14825v2</guid>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>physics.data-an</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Mon, 23 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1038/s41467-026-68568-0</arxiv:DOI>
      <arxiv:journal_reference>Nature Communications 17, 1854 (2026)</arxiv:journal_reference>
      <dc:creator>Marios Andreou, Nan Chen, Erik Bollt</dc:creator>
    </item>
    <item>
      <title>The Minimax Lower Bound of Kernel Stein Discrepancy Estimation</title>
      <link>https://arxiv.org/abs/2510.15058</link>
      <description>arXiv:2510.15058v2 Announce Type: replace-cross 
Abstract: Kernel Stein discrepancies (KSDs) have emerged as a powerful tool for quantifying goodness-of-fit over the last decade, featuring numerous successful applications. To the best of our knowledge, all existing KSD estimators with known rate achieve $\sqrt n$-convergence. In this work, we present two complementary results (with different proof strategies), establishing that the minimax lower bound of KSD estimation is $n^{-1/2}$ and settling the optimality of these estimators. Our first result focuses on KSD estimation on $\mathbb R^d$ with the Langevin-Stein operator; our explicit constant for the Gaussian kernel indicates that the difficulty of KSD estimation may increase exponentially with the dimensionality $d$. Our second result settles the minimax lower bound for KSD estimation on general domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.15058v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 23 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jose Cribeiro-Ramallo, Agnideep Aich, Florian Kalinke, Ashit Baran Aich, Zolt\'an Szab\'o</dc:creator>
    </item>
    <item>
      <title>On the inverse of covariance matrices for unbalanced crossed designs</title>
      <link>https://arxiv.org/abs/2512.09273</link>
      <description>arXiv:2512.09273v2 Announce Type: replace-cross 
Abstract: This paper addresses a long-standing open problem in the analysis of linear mixed models with crossed random effects under unbalanced designs: how to find an analytic expression for the inverse of $\mathbf{V}$, the covariance matrix of the observed response. The inverse matrix $\mathbf{V}^{-1}$ is required for likelihood-based estimation and inference. However, for unbalanced crossed designs, $\mathbf{V}$ is dense and the lack of a closed-form representation for $\mathbf{V}^{-1}$, until now, has made using likelihood-based methods computationally challenging and difficult to analyse mathematically. We use the Khatri--Rao product to represent $\mathbf{V}$ and then to construct a modified covariance matrix whose inverse admits an exact spectral decomposition. Building on this construction, we obtain an elegant and simple approximation to $\mathbf{V}^{-1}$ for asymptotic unbalanced designs. For non-asymptotic settings, we derive an accurate and interpretable approximation under mildly unbalanced data and establish an exact inverse representation as a low-rank correction to this approximation, applicable to arbitrary degrees of unbalance. Simulation studies demonstrate the accuracy, stability, and computational tractability of the proposed framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.09273v2</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 23 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ziyang Lyu, S. A. Sisson, A. H. Welsh</dc:creator>
    </item>
    <item>
      <title>Nonparametric Identification of Demand without Exogenous Product Characteristics</title>
      <link>https://arxiv.org/abs/2512.23211</link>
      <description>arXiv:2512.23211v2 Announce Type: replace-cross 
Abstract: We study identification of differentiated product demand from market-level data when product characteristics can be endogenous. Past work suggests nonparametric identification may be impossible: that is, in addition to standard price instruments, exogenous characteristic-based instruments are essentially necessary to identify sufficiently flexible demand models with standard index restrictions. We show, however, that price counterfactuals are nonparametrically identified using recentered instruments -- which combine exogenous price instruments with possibly endogenous product characteristics -- under a weaker index restriction and a new condition we term faithfulness. We argue that faithfulness, like the usual completeness condition for nonparametric instrumental variable identification, is best viewed as a technical requirement on the strength of identifying variation rather than a substantive economic or statistical restriction. We show the two conditions are closely related, though generally distinct. We conclude with several practical implications for the parametric estimation of demand counterfactuals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.23211v2</guid>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Mon, 23 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kirill Borusyak, Jiafeng Chen, Peter Hull, Lihua Lei</dc:creator>
    </item>
    <item>
      <title>Estimating the Shannon Entropy Using the Pitman--Yor Process</title>
      <link>https://arxiv.org/abs/2602.08347</link>
      <description>arXiv:2602.08347v2 Announce Type: replace-cross 
Abstract: The Shannon entropy is a fundamental measure for quantifying diversity and model complexity in fields such as information theory, ecology, and genetics. However, many existing studies assume that the number of species is known, an assumption that is often unrealistic in practice. In recent years, efforts have been made to relax this restriction. Motivated by these developments, this study proposes an entropy estimation method based on the Pitman--Yor process, a representative approach in Bayesian nonparametrics. By approximating the true distribution as an infinite-dimensional process, the proposed method enables stable estimation even when the number of observed species is smaller than the true number of species. This approach provides a principled way to deal with the uncertainty in species diversity and enhances the reliability and robustness of entropy-based diversity assessment. In addition, we investigate the convergence property of the Shannon entropy for regularly varying distributions and use this result to establish the consistency of the proposed estimator. Finally, we demonstrate the effectiveness of the proposed method through numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08347v2</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 23 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Takato Hashino, Koji Tsukuda</dc:creator>
    </item>
  </channel>
</rss>
