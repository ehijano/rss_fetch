<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CC</link>
    <description>cs.CC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 03 Sep 2025 04:01:07 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Constricting the Computational Complexity Gap of the $4$-Coloring Problem in $(P_t,C_3)$-free Graphs</title>
      <link>https://arxiv.org/abs/2509.02423</link>
      <description>arXiv:2509.02423v1 Announce Type: new 
Abstract: The $k$-Coloring problem on hereditary graph classes has been a deeply researched problem over the last decade. A hereditary graph class is characterized by a (possibly infinite) list of minimal forbidden induced subgraphs. We say that a graph is $(H_1,H_2,\ldots)$-free if it does not contain any of $H_1,H_2,\ldots$ as induced subgraphs. The complexity landscape of the problem remains unclear even when restricting to the case $k=4$ and classes defined by a few forbidden induced subgraphs. While the case of only one forbidden induced subgraph has been completely resolved lately, the complexity when considering two forbidden induced subgraphs still has a couple of unknown cases. In particular, $4$-Coloring on $(P_6,C_3)$-free graphs is polynomial while it is NP-hard on $(P_{22},C_3)$-free graphs.
  We provide a reduction showing NP-completeness of $4$-Coloring on $(P_t,C_3)$-free graphs for $19\leq t\leq 21$, thus constricting the gap of cases whose complexity remains unknown. Our proof includes a computer search ensuring that the graph family obtained through the reduction is indeed $P_{19}$-free.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.02423v1</guid>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>math.CO</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Justyna Jaworska, Bart{\l}omiej Kielak, Tom\'a\v{s} Masa\v{r}\'ik, Jana Masa\v{r}\'ikov\'a</dc:creator>
    </item>
    <item>
      <title>The rotation-invariant Hamiltonian problem is QMA$_{\rm EXP}$-complete</title>
      <link>https://arxiv.org/abs/2509.00161</link>
      <description>arXiv:2509.00161v1 Announce Type: cross 
Abstract: In this work, we study a variant of the local Hamiltonian problem where we restrict to Hamiltonians that live on a lattice and are invariant under translations and rotations of the lattice. In the one-dimensional case this problem is known to be QMA$_{\rm EXP}$-complete. On the other hand, if we fix the lattice length then in the high-dimensional limit the ground state becomes unentangled due to arguments from mean-field theory. We take steps towards understanding this complexity spectrum by studying a problem that is intermediate between these two extremes. Namely, we consider the regime where the lattice dimension is arbitrary but fixed and the lattice length is scaled. We prove that this rotation-invariant Hamiltonian problem is QMA$_{\rm EXP}$-complete answering an open question of [Gottesman, Irani 2013]. This characterizes a broad parameter range in which these rotation-invariant Hamiltonians have high computational complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.00161v1</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jon Nelson, Daniel Gottesman</dc:creator>
    </item>
    <item>
      <title>How to Compute a Moving Sum</title>
      <link>https://arxiv.org/abs/2509.00537</link>
      <description>arXiv:2509.00537v1 Announce Type: cross 
Abstract: Windowed recurrences are sliding window calculations where a function is applied iteratively across the window of data, and are ubiquitous throughout the natural, social, and computational sciences. In this monograph we explore the computational aspects of these calculations, including sequential and parallel computation, and develop the theory underlying the algorithms and their applicability. We introduce an efficient new sequential algorithm with low latency, and develop new techniques to derive and analyze the complexity and domain of validity of existing sequential algorithms. For parallel computation we derive new parallel and vector algorithms by relating windowed recurrences to the algebraic construction of semidirect products, and to algorithms for exponentiation in semigroups. In the middle chapters of the monograph we further develop the theory of semi-associativity and the algebraic conditions for representing function composition and function application by data. This systematizes the techniques used by practitioners to parallelize recurrence calculations. We end the monograph with an extensive gallery of examples of interest to specialists in many fields. Throughout the monograph new algorithms are described with pseudo-code transcribed from functioning source code.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.00537v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David K. Maslen, Daniel N. Rockmore</dc:creator>
    </item>
    <item>
      <title>Large cliques and large independent sets: can they coexist?</title>
      <link>https://arxiv.org/abs/2509.00721</link>
      <description>arXiv:2509.00721v1 Announce Type: cross 
Abstract: For a graph $G$ and a parameter $k$, we call a vertex $k$-enabling if it belongs both to a clique of size $k$ and to an independent set of size $k$, and we call it $k$-excluding otherwise. Motivated by issues that arise in secret sharing schemes, we study the complexity of detecting vertices that are $k$-excluding. We show that for every $\epsilon$, for sufficiently large $n$, if $k &gt; (\frac{1}{4} + \epsilon)n$, then every graph on $n$ vertices must have a $k$-excluding vertex, and moreover, such a vertex can be found in polynomial time. In contrast, if $k &lt; (\frac{1}{4} - \epsilon)n$, a regime in which it might be that all vertices are $k$-enabling, deciding whether a graph has no $k$-excluding vertex is NP-hard.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.00721v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Uriel Feige, Ilia Pauzner</dc:creator>
    </item>
    <item>
      <title>Quantum Statistical Witness Indistinguishability</title>
      <link>https://arxiv.org/abs/2509.01945</link>
      <description>arXiv:2509.01945v1 Announce Type: cross 
Abstract: Statistical witness indistinguishability is a relaxation of statistical zero-knowledge which guarantees that the transcript of an interactive proof reveals no information about which valid witness the prover used to generate it. In this paper we define and initiate the study of QSWI, the class of problems with quantum statistically witness indistinguishable proofs.
  Using inherently quantum techniques from Kobayashi (TCC 2008), we prove that any problem with an honest-verifier quantum statistically witness indistinguishable proof has a 3-message public-coin malicious-verifier quantum statistically witness indistinguishable proof. There is no known analogue of this result for classical statistical witness indistinguishability. As a corollary, our result implies SWI is contained in QSWI.
  Additionally, we extend the work of Bitansky et al. (STOC 2023) to show that quantum batch proofs imply quantum statistically witness indistinguishable proofs with inverse-polynomial witness indistinguishability error.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.01945v1</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.CR</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shafik Nassar, Ronak Ramachandran</dc:creator>
    </item>
    <item>
      <title>Non-Boolean OMv: One More Reason to Believe Lower Bounds for Dynamic Problems</title>
      <link>https://arxiv.org/abs/2409.15970</link>
      <description>arXiv:2409.15970v2 Announce Type: replace 
Abstract: Most of the known tight lower bounds for dynamic problems are based on the Online Boolean Matrix-Vector Multiplication (OMv) Hypothesis, which is not as well studied and understood as some more popular hypotheses in fine-grained complexity. It would be desirable to base hardness of dynamic problems on a more believable hypothesis. We propose analogues of the OMv Hypothesis for variants of matrix multiplication that are known to be harder than Boolean product in the offline setting, namely: equality, dominance, min-witness, min-max, and bounded monotone min-plus products. These hypotheses are a priori weaker assumptions than the standard (Boolean) OMv Hypothesis. Somewhat surprisingly, we show that they are actually equivalent to it. This establishes the first such fine-grained equivalence class for dynamic problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.15970v2</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bingbing Hu, Adam Polak</dc:creator>
    </item>
    <item>
      <title>Relative-error monotonicity testing</title>
      <link>https://arxiv.org/abs/2410.09235</link>
      <description>arXiv:2410.09235v2 Announce Type: replace 
Abstract: The standard model of Boolean function property testing is not well suited for testing $\textit{sparse}$ functions which have few satisfying assignments, since every such function is close (in the usual Hamming distance metric) to the constant-0 function. In this work we propose and investigate a new model for property testing of Boolean functions, called $\textit{relative-error testing}$, which provides a natural framework for testing sparse functions.
  This new model defines the distance between two functions $f, g: \{0,1\}^n \to \{0,1\}$ to be $$\textsf{reldist}(f,g) := { \frac{|f^{-1}(1) \triangle g^{-1}(1)|} {|f^{-1}(1)|}}.$$ This is a more demanding distance measure than the usual Hamming distance ${ {|f^{-1}(1) \triangle g^{-1}(1)|}/{2^n}}$ when $|f^{-1}(1)| \ll 2^n$; to compensate for this, algorithms in the new model have access both to a black-box oracle for the function $f$ being tested and to a source of independent uniform satisfying assignments of $f$.
  In this paper we first give a few general results about the relative-error testing model; then, as our main technical contribution, we give a detailed study of algorithms and lower bounds for relative-error testing of $\textit{monotone}$ Boolean functions. We give upper and lower bounds which are parameterized by $N=|f^{-1}(1)|$, the sparsity of the function $f$ being tested. Our results show that there are interesting differences between relative-error monotonicity testing of sparse Boolean functions, and monotonicity testing in the standard model. These results motivate further study of the testability of Boolean function properties in the relative-error model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09235v2</guid>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xi Chen, Anindya De, Yizhi Huang, Yuhao Li, Shivam Nadimpalli, Rocco A. Servedio, Tianqi Yang</dc:creator>
    </item>
    <item>
      <title>Push-1 is PSPACE-complete, and the automated verification of motion planning gadgets</title>
      <link>https://arxiv.org/abs/2508.17602</link>
      <description>arXiv:2508.17602v2 Announce Type: replace 
Abstract: Push-1 is one of the simplest abstract frameworks for motion planning; however, the complexity of deciding if a Push-1 problem can be solved was a several-decade-old open question. We resolve the complexity of the motion planning problem Push-1 by showing that it is PSPACE-complete, and we formally verify the correctness of our constructions. Our results build upon a recent work which demonstrated that Push-1F (a variant of Push-1 with fixed blocks) and Push-k for $k \geq 2$ (a variant of Push-1 where the agent can push $k$ blocks at once) are PSPACE-complete and more generally on the motion-planning-though-gadgets framework.
  In the process of resolving this open problem, we make two general contributions to the motion planning complexity theory. First, our proof technique extends the standard motion planning framework by assigning the agent a state. This state is preserved when traversing between gadgets but can change when taking transitions in gadgets. Second, we designed and implemented a system, GADGETEER, for computationally verifying the behavior of systems of gadgets. This system is agnostic to the underlying motion planning problem, and allows for formally verifying the correspondence between a low-level construction and a high-level system of gadgets as well as automatically synthesizing gadgets from low-level constructions. In the case of Push-1, we use this system to formally prove that our constructions match our high-level specifications of their behavior. This culminates in the construction and verification of a self-closing door, as deciding reachability in a system of self-closing doors is PSPACE-complete.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.17602v2</guid>
      <category>cs.CC</category>
      <category>cs.CG</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zachary DeStefano, Bufang Liang</dc:creator>
    </item>
    <item>
      <title>Isometric path complexity of graphs</title>
      <link>https://arxiv.org/abs/2301.00278</link>
      <description>arXiv:2301.00278v5 Announce Type: replace-cross 
Abstract: A set $S$ of isometric paths of a graph $G$ is ``$v$-rooted'', where $v$ is a vertex of $G$, if $v$ is one of the endpoints of all the isometric paths in $S$. The isometric path complexity of a graph $G$, denoted by $ipco{G}$, is the minimum integer $k$ such that there exists a vertex $v\in V(G)$ satisfying the following property: the vertices of any single isometric path $P$ of $G$ can be covered by $k$ many $v$-rooted isometric paths.
  First, we provide an $O(n^2 m)$-time algorithm to compute the isometric path complexity of a graph with $n$ vertices and $m$ edges. Then we show that the isometric path complexity remains bounded for graphs in three seemingly unrelated graph classes, namely, hyperbolic graphs, (theta, prism, pyramid)-free graphs, and outerstring graphs.
  There is a direct algorithmic consequence of having small isometric path complexity. Specifically, we show that if the isometric path complexity of a graph $G$ is bounded by a constant, then there exists a polynomial-time constant-factor approximation algorithm for ISOMETRIC PATH COVER, whose objective is to cover all vertices of a graph with a minimum number of isometric paths. This applies to all the above graph classes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.00278v5</guid>
      <category>math.CO</category>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.disc.2025.114743</arxiv:DOI>
      <arxiv:journal_reference>Discrete Mathematics 349(2):114743, 2026</arxiv:journal_reference>
      <dc:creator>Dibyayan Chakraborty, J\'er\'emie Chalopin, Florent Foucaud, Yann Vax\`es</dc:creator>
    </item>
    <item>
      <title>Algorithmic Randomness and Probabilistic Laws</title>
      <link>https://arxiv.org/abs/2303.01411</link>
      <description>arXiv:2303.01411v2 Announce Type: replace-cross 
Abstract: We apply recent ideas about complexity and randomness to the philosophy of laws and chances. We develop two ways to use algorithmic randomness to characterize probabilistic laws of nature. The first, a generative chance* law, employs a nonstandard notion of chance. The second, a probabilistic* constraining law, impose relative frequency and randomness constraints that every physically possible world must satisfy. The constraining notion removes a major obstacle to a unified governing account of non-Humean laws, on which laws govern by constraining physical possibilities; it also provides independently motivated solutions to familiar problems for the Humean best-system account (the Big Bad Bug and the zero-fit problem). On either approach, probabilistic laws are tied more tightly to corresponding sets of possible worlds: some histories permitted by traditional probabilistic laws are now ruled out as physically impossible. Consequently, the framework avoids one variety of empirical underdetermination while bringing to light others that are typically overlooked.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.01411v2</guid>
      <category>physics.hist-ph</category>
      <category>cs.CC</category>
      <category>math.PR</category>
      <category>quant-ph</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jeffrey A. Barrett, Eddy Keming Chen</dc:creator>
    </item>
    <item>
      <title>Quantum state testing beyond the polarizing regime and quantum triangular discrimination</title>
      <link>https://arxiv.org/abs/2303.01952</link>
      <description>arXiv:2303.01952v5 Announce Type: replace-cross 
Abstract: The complexity class Quantum Statistical Zero-Knowledge ($\mathsf{QSZK}$) captures computational difficulties of the time-bounded quantum state testing problem with respect to the trace distance, deciding whether $\mathrm{T}(\rho_0,\rho_1)$ is at least $\alpha$ or at most $\beta$, known as the Quantum State Distinguishability Problem ($\mathrm{QSDP}$) introduced by Watrous (FOCS 2002). However, $\mathrm{QSDP}[\alpha,\beta]$ is in $\mathsf{QSZK}$ only within the constant polarizing regime, where $\alpha$ and $\beta$ are constants satisfying $\alpha^2 &gt; \beta$ (rather than $\alpha &gt; \beta$), similar to its classical counterpart shown by Sahai and Vadhan (JACM 2003) due to the polarization lemma (error reduction for $\mathrm{SDP}$).
  Recently, Berman, Degwekar, Rothblum, and Vasudevan (TCC 2019) extended the $\mathsf{SZK}$ containment of $\mathrm{SDP}$ beyond the polarizing regime via the time-bounded distribution testing problems with respect to the triangular discrimination and the Jensen-Shannon divergence. Our work introduces proper quantum analogs for these problems by defining quantum counterparts for triangular discrimination. We investigate whether the quantum analogs behave similarly to their classical counterparts and examine the limitations of existing approaches to polarization regarding quantum distances. These new $\mathsf{QSZK}$-complete problems improve $\mathsf{QSZK}$ containments of $\mathrm{QSDP}$ beyond the polarizing regime and establish a simple $\mathsf{QSZK}$-hardness for the quantum entropy difference problem ($\mathrm{QEDP}$) defined by Ben-Aroya, Schwartz, and Ta-Shma (ToC 2010). Furthermore, we prove that $\mathrm{QSDP}$ with some exponentially small errors is in $\mathsf{PP}$, while the same problem without error is in $\mathsf{NQP}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.01952v5</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yupan Liu</dc:creator>
    </item>
    <item>
      <title>An algebraic proof of the dichotomy for graph orientation problems with forbidden tournaments</title>
      <link>https://arxiv.org/abs/2405.20263</link>
      <description>arXiv:2405.20263v3 Announce Type: replace-cross 
Abstract: For a set F of finite tournaments, the F-free orientation problem is the problem of deciding if a given finite undirected graph can be oriented in such a way that the resulting oriented graph does not contain any member of F. Using the theory of smooth approximations, we give a new shorter proof of the complexity dichotomy for such problems obtained recently by Bodirsky and Guzm\'{a}n-Pro. In fact, our approach yields a complexity dichotomy for a considerably larger class of computational problems where one is given an undirected graph along with additional local constraints on the allowed orientations. Moreover, the border between tractable and hard problems is also described by a decidable algebraic condition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20263v3</guid>
      <category>math.CO</category>
      <category>cs.CC</category>
      <category>cs.LO</category>
      <category>math.RA</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Roman Feller, Michael Pinsker</dc:creator>
    </item>
    <item>
      <title>Adaptive and oblivious statistical adversaries are equivalent</title>
      <link>https://arxiv.org/abs/2410.13548</link>
      <description>arXiv:2410.13548v2 Announce Type: replace-cross 
Abstract: We resolve a fundamental question about the ability to perform a statistical task, such as learning, when an adversary corrupts the sample. Such adversaries are specified by the types of corruption they can make and their level of knowledge about the sample. The latter distinguishes between sample-adaptive adversaries which know the contents of the sample when choosing the corruption, and sample-oblivious adversaries, which do not. We prove that for all types of corruptions, sample-adaptive and sample-oblivious adversaries are \emph{equivalent} up to polynomial factors in the sample size. This resolves the main open question introduced by [BLMT22] and further explored in [CHL+23].
  Specifically, consider any algorithm $A$ that solves a statistical task even when a sample-oblivious adversary corrupts its input. We show that there is an algorithm $A'$ that solves the same task when the corresponding sample-adaptive adversary corrupts its input. The construction of $A'$ is simple and maintains the computational efficiency of $A$: It requests a polynomially larger sample than $A$ uses and then runs $A$ on a uniformly random subsample.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.13548v2</guid>
      <category>cs.LG</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Guy Blanc, Gregory Valiant</dc:creator>
    </item>
    <item>
      <title>Proof of Hiding Conjecture in Gaussian Boson Sampling</title>
      <link>https://arxiv.org/abs/2508.00983</link>
      <description>arXiv:2508.00983v2 Announce Type: replace-cross 
Abstract: Gaussian boson sampling (GBS) is a promising protocol for demonstrating quantum computational advantage. One of the key steps for proving classical hardness of GBS is the so-called ``hiding conjecture'', which asserts that one can ``hide'' a complex Gaussian matrix as a submatrix of the outer product of Haar unitary submatrices in total variation distance. In this paper, we prove the hiding conjecture for input states with the maximal number of squeezed states, which is a setup that has recently been realized experimentally [Madsen et al., Nature 606, 75 (2022)]. In this setting, the hiding conjecture states that a $o(\sqrt{M})\times o(\sqrt{M})$ submatrix of an $M\times M$ circular orthogonal ensemble (COE) random matrix can be well-approximated by a complex Gaussian matrix in total variation distance as $M\to\infty$. This is the first rigorous proof of the hiding property for GBS in the experimentally relevant regime, and puts the argument for hardness of classically simulating GBS with a maximal number of squeezed states on a comparable level to that of the conventional boson sampling of [Aaronson and Arkhipov, Theory Comput. 9, 143 (2013)].</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00983v2</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Laura Shou, Sarah H. Miller, Victor Galitski</dc:creator>
    </item>
  </channel>
</rss>
