<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.ET updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.ET</link>
    <description>cs.ET updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.ET" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 25 Apr 2025 04:00:47 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Molecular Communication Channel as a Physical Reservoir Computer</title>
      <link>https://arxiv.org/abs/2504.17022</link>
      <description>arXiv:2504.17022v1 Announce Type: new 
Abstract: Molecular Communication (MC) channels inherently possess significant memory and nonlinear dynamics due to diffusion and receptor kinetics, often posing challenges for reliable data transmission. This work reconceptualizes these intrinsic properties as computational resources by framing a canonical point-to-point MC channel, consisting of ligand diffusion and reversible ligand-receptor binding at a spherical receiver, as a physical reservoir computer (PRC). We utilize the time-varying fraction of bound receptors as the reservoir's internal state, employing time-multiplexing to generate high-dimensional virtual nodes without explicit recurrence. Only a linear readout layer is trained via ridge regression. Through deterministic mean-field modeling and particle-based spatial stochastic simulations, we demonstrate the MC system's capability for complex temporal processing by successfully performing next-step prediction on standard chaotic time-series benchmarks (Mackey-Glass and NARMA10). Performance, quantified by Normalized Root Mean Square Error (NRMSE), exhibits a non-monotonic dependence on key system parameters (receptor kinetic rates, diffusion coefficient, transmitter-receiver distance), revealing optimal operational regimes. These findings validate the potential of using MC channel as effective and low-complexity computational substrate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.17022v1</guid>
      <category>cs.ET</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mustafa Uzun, Kaan Burak Ikiz, Murat Kuscu</dc:creator>
    </item>
    <item>
      <title>Range and Topology Mutation Based Wireless Agility</title>
      <link>https://arxiv.org/abs/2504.17164</link>
      <description>arXiv:2504.17164v1 Announce Type: new 
Abstract: In this paper, we present formal foundations for two wireless agility techniques: (1) Random Range Mutation (RNM) that allows for periodic changes of AP coverage range randomly, and (2) Ran- dom Topology Mutation (RTM) that allows for random motion and placement of APs in the wireless infrastructure. The goal of these techniques is to proactively defend against targeted attacks (e.g., DoS and eavesdropping) by forcing the wireless clients to change their AP association randomly. We apply Satisfiability Modulo The- ories (SMT) and Answer Set Programming (ASP) based constraint solving methods that allow for optimizing wireless AP mutation while maintaining service requirements including coverage, secu- rity and energy properties under incomplete information about the adversary strategies. Our evaluation validates the feasibility, scalability, and effectiveness of the formal methods based technical approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.17164v1</guid>
      <category>cs.ET</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Qi Duan, Ehab Al-Shae, Jiang Xie</dc:creator>
    </item>
    <item>
      <title>Rethinking PM Crash Consistency in the CXL Era</title>
      <link>https://arxiv.org/abs/2504.17554</link>
      <description>arXiv:2504.17554v1 Announce Type: new 
Abstract: Persistent Memory (PM) introduces new opportunities for designing crash-consistent applications without the traditional storage overheads. However, ensuring crash consistency in PM demands intricate knowledge of CPU, cache, and memory interactions. Hardware and software mechanisms have been proposed to ease this burden, but neither proved sufficient, prompting a variety of bug detection tools.
  With the sunset of Intel Optane comes the rise of Compute Express Link (CXL) for PM. In this position paper, we discuss the impact of CXL's disaggregated and heterogeneous nature in the development of crash-consistent PM applications, and outline three research directions: hardware primitives, persistency frameworks, and bug detection tools.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.17554v1</guid>
      <category>cs.ET</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jo\~ao Oliveira, Jo\~ao Gon\c{c}alves, Miguel Matos</dc:creator>
    </item>
    <item>
      <title>Intrinsic Barriers to Explaining Deep Foundation Models</title>
      <link>https://arxiv.org/abs/2504.16948</link>
      <description>arXiv:2504.16948v1 Announce Type: cross 
Abstract: Deep Foundation Models (DFMs) offer unprecedented capabilities but their increasing complexity presents profound challenges to understanding their internal workings-a critical need for ensuring trust, safety, and accountability. As we grapple with explaining these systems, a fundamental question emerges: Are the difficulties we face merely temporary hurdles, awaiting more sophisticated analytical techniques, or do they stem from \emph{intrinsic barriers} deeply rooted in the nature of these large-scale models themselves? This paper delves into this critical question by examining the fundamental characteristics of DFMs and scrutinizing the limitations encountered by current explainability methods when confronted with this inherent challenge. We probe the feasibility of achieving satisfactory explanations and consider the implications for how we must approach the verification and governance of these powerful technologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16948v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhen Tan, Huan Liu</dc:creator>
    </item>
    <item>
      <title>A Novel Graph Transformer Framework for Gene Regulatory Network Inference</title>
      <link>https://arxiv.org/abs/2504.16961</link>
      <description>arXiv:2504.16961v1 Announce Type: cross 
Abstract: The inference of gene regulatory networks (GRNs) is a foundational stride towards deciphering the fundamentals of complex biological systems. Inferring a possible regulatory link between two genes can be formulated as a link prediction problem. Inference of GRNs via gene coexpression profiling data may not always reflect true biological interactions, as its susceptibility to noise and misrepresenting true biological regulatory relationships. Most GRN inference methods face several challenges in the network reconstruction phase. Therefore, it is important to encode gene expression values, leverege the prior knowledge gained from the available inferred network structures and positional informations of the input network nodes towards inferring a better and more confident GRN network reconstruction. In this paper, we explore the integration of multiple inferred networks to enhance the inference of Gene Regulatory Networks (GRNs). Primarily, we employ autoencoder embeddings to capture gene expression patterns directly from raw data, preserving intricate biological signals. Then, we embed the prior knowledge from GRN structures transforming them into a text-like representation using random walks, which are then encoded with a masked language model, BERT, to generate global embeddings for each gene across all networks. Additionally, we embed the positional encodings of the input gene networks to better identify the position of each unique gene within the graph. These embeddings are integrated into graph transformer-based model, termed GT-GRN, for GRN inference. The GT-GRN model effectively utilizes the topological structure of the ground truth network while incorporating the enriched encoded information. Experimental results demonstrate that GT-GRN significantly outperforms existing GRN inference methods, achieving superior accuracy and highlighting the robustness of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16961v1</guid>
      <category>cs.LG</category>
      <category>cs.ET</category>
      <category>q-bio.GN</category>
      <category>q-bio.MN</category>
      <category>q-bio.QM</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Binon Teji, Swarup Roy</dc:creator>
    </item>
    <item>
      <title>Factually: Exploring Wearable Fact-Checking for Augmented Truth Discernment</title>
      <link>https://arxiv.org/abs/2504.17204</link>
      <description>arXiv:2504.17204v1 Announce Type: cross 
Abstract: Wearable devices are transforming human capabilities by seamlessly augmenting cognitive functions. In this position paper, we propose a voice-based, interactive learning companion designed to amplify and extend cognitive abilities through informal learning. Our vision is threefold: (1) to enable users to discover new knowledge on-the-go through contextual interactive quizzes, fostering critical thinking and mindfulness, (2) to proactively detect misinformation, empowering users to critically assess information in real time, and (3) to provide spoken language correction and prompting hints for second language learning and effective communication. As an initial step toward this vision, we present Factually - a proactive, wearable fact-checking system integrated into devices like smartwatches or rings. Factually discreetly alerts users to potential falsehoods via vibrotactile feedback, helping them assess information critically. We demonstrate its utility through three illustrative scenarios, highlighting its potential to extend cognitive abilities for real-time misinformation detection. Early qualitative feedback suggests that Factually can enhance users' fact-checking capabilities, offering both practical and experiential benefits.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.17204v1</guid>
      <category>cs.HC</category>
      <category>cs.ET</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:journal_reference>Proceedings of the 2025 ACM CHI Workshop on Human-AI Interaction for Augmented Reasoning</arxiv:journal_reference>
      <dc:creator>Chitralekha Gupta, Hanjun Wu, Praveen Sasikumar, Shreyas Sridhar, Priambudi Bagaskara, Suranga Nanayakkara</dc:creator>
    </item>
    <item>
      <title>Building Sustainable and Trustworthy Indigenous Knowledge Preservation Ecosystem</title>
      <link>https://arxiv.org/abs/2504.17281</link>
      <description>arXiv:2504.17281v1 Announce Type: cross 
Abstract: This paper focuses on the essential global issue of protecting and transmitting indigenous knowledge. It reveals the challenges in this area and proposes a sustainable supply chain framework for indigenous knowledge. The paper reviews existing technological solutions and identifies technical challenges and gaps. It then introduces cutting-edge technologies to protect and disseminate indigenous knowledge more effectively. The paper also discusses how the proposed framework can address real-world challenges in protecting and transmitting indigenous knowledge, and explores future research applications of the proposed solutions. Finally, it addresses open issues and provides a detailed analysis, offering promising research directions for the protection and transmission of indigenous knowledge worldwide.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.17281v1</guid>
      <category>cs.CY</category>
      <category>cs.ET</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Siguo Bi, Xin Yuan, Wei Ni</dc:creator>
    </item>
    <item>
      <title>Learning Isometric Embeddings of Road Networks using Multidimensional Scaling</title>
      <link>https://arxiv.org/abs/2504.17534</link>
      <description>arXiv:2504.17534v1 Announce Type: cross 
Abstract: The lack of generalization in learning-based autonomous driving applications is shown by the narrow range of road scenarios that vehicles can currently cover. A generalizable approach should capture many distinct road structures and topologies, as well as consider traffic participants, and dynamic changes in the environment, so that vehicles can navigate and perform motion planning tasks even in the most difficult situations. Designing suitable feature spaces for neural network-based motion planers that encapsulate all kinds of road scenarios is still an open research challenge. This paper tackles this learning-based generalization challenge and shows how graph representations of road networks can be leveraged by using multidimensional scaling (MDS) techniques in order to obtain such feature spaces. State-of-the-art graph representations and MDS approaches are analyzed for the autonomous driving use case. Finally, the option of embedding graph nodes is discussed in order to perform easier learning procedures and obtain dimensionality reduction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.17534v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.SC</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Juan Carlos Climent Pardo</dc:creator>
    </item>
    <item>
      <title>Towards a HIPAA Compliant Agentic AI System in Healthcare</title>
      <link>https://arxiv.org/abs/2504.17669</link>
      <description>arXiv:2504.17669v1 Announce Type: cross 
Abstract: Agentic AI systems powered by Large Language Models (LLMs) as their foundational reasoning engine, are transforming clinical workflows such as medical report generation and clinical summarization by autonomously analyzing sensitive healthcare data and executing decisions with minimal human oversight. However, their adoption demands strict compliance with regulatory frameworks such as Health Insurance Portability and Accountability Act (HIPAA), particularly when handling Protected Health Information (PHI). This work-in-progress paper introduces a HIPAA-compliant Agentic AI framework that enforces regulatory compliance through dynamic, context-aware policy enforcement. Our framework integrates three core mechanisms: (1) Attribute-Based Access Control (ABAC) for granular PHI governance, (2) a hybrid PHI sanitization pipeline combining regex patterns and BERT-based model to minimize leakage, and (3) immutable audit trails for compliance verification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.17669v1</guid>
      <category>cs.MA</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Subash Neupane, Shaswata Mitra, Sudip Mittal, Shahram Rahimi</dc:creator>
    </item>
    <item>
      <title>Disaggregated Deep Learning via In-Physics Computing at Radio Frequency</title>
      <link>https://arxiv.org/abs/2504.17752</link>
      <description>arXiv:2504.17752v1 Announce Type: cross 
Abstract: Modern edge devices, such as cameras, drones, and Internet-of-Things nodes, rely on deep learning to enable a wide range of intelligent applications, including object recognition, environment perception, and autonomous navigation. However, deploying deep learning models directly on the often resource-constrained edge devices demands significant memory footprints and computational power for real-time inference using traditional digital computing architectures. In this paper, we present WISE, a novel computing architecture for wireless edge networks designed to overcome energy constraints in deep learning inference. WISE achieves this goal through two key innovations: disaggregated model access via wireless broadcasting and in-physics computation of general complex-valued matrix-vector multiplications directly at radio frequency. Using a software-defined radio platform with wirelessly broadcast model weights over the air, we demonstrate that WISE achieves 95.7% image classification accuracy with ultra-low operation power of 6.0 fJ/MAC per client, corresponding to a computation efficiency of 165.8 TOPS/W. This approach enables energy-efficient deep learning inference on wirelessly connected edge devices, achieving more than two orders of magnitude improvement in efficiency compared to traditional digital computing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.17752v1</guid>
      <category>cs.LG</category>
      <category>cs.ET</category>
      <category>eess.SP</category>
      <category>physics.app-ph</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhihui Gao, Sri Krishna Vadlamani, Kfir Sulimany, Dirk Englund, Tingjun Chen</dc:creator>
    </item>
    <item>
      <title>Towards Scalable Multi-Chip Wireless Networks with Near-Field Time Reversal</title>
      <link>https://arxiv.org/abs/2404.17325</link>
      <description>arXiv:2404.17325v2 Announce Type: replace 
Abstract: The concept of Wireless Network-on-Chip (WNoC) has emerged as a potential solution to address the escalating communication demands of modern computing systems due to its low-latency, versatility, and reconfigurability. However, for WNoC to fulfill its potential, it is essential to establish multiple high-speed wireless links across chips. Unfortunately, the compact and enclosed nature of computing packages introduces significant challenges in the form of Co-Channel Interference and Inter-Symbol Interference, which not only hinder the deployment of multiple spatial channels but also severely restrict the symbol rate of each individual channel. In this paper, we posit that Time Reversal (TR) could be effective in addressing both impairments in this static scenario thanks to its spatiotemporal focusing capabilities even in the near field. Through comprehensive full-wave simulations and bit error rate analysis in multiple scenarios and at multiple frequency bands, we provide evidence that TR can increase the symbol rate by an order of magnitude, enabling the deployment of multiple concurrent links and achieving aggregate speeds exceeding 100 Gb/s. Finally, we evaluate the impact of reducing the sampling rate of the TR filter on the achievable speeds, paving the way to practical TR-based wireless communications at the chip scale.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17325v2</guid>
      <category>cs.ET</category>
      <category>eess.SP</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ama Bandara, F\'atima Rodr\'iguez-Gal\'an, Pau Talarn, Elana Pereira de Santana, Evgenii Vinogradov, Peter Haring Bol\'ivar, Eduard Alarc\'on, Sergi Abadal</dc:creator>
    </item>
    <item>
      <title>SPAARC: Spatial Proximity and Association based prefetching for Augmented Reality in edge Cache</title>
      <link>https://arxiv.org/abs/2502.15192</link>
      <description>arXiv:2502.15192v2 Announce Type: replace 
Abstract: Mobile Augmented Reality (MAR) applications face performance challenges due to their high computational demands and need for low-latency responses. Traditional approaches like on-device storage or reactive data fetching from the cloud often result in limited AR experiences or unacceptable lag. Edge caching, which caches AR objects closer to the user, provides a promising solution. However, existing edge caching approaches do not consider AR-specific features such as AR object sizes, user interactions, and physical location. This paper investigates how to further optimize edge caching by employing AR-aware prefetching techniques. We present SPAARC, a Spatial Proximity and Association-based Prefetching policy specifically designed for MAR Caches. SPAARC intelligently prioritizes the caching of virtual objects based on their association with other similar objects and the user's proximity to them. It also considers the recency of associations and uses a lazy fetching strategy to efficiently manage edge resources and maximize Quality of Experience (QoE).
  Through extensive evaluation using both synthetic and real-world workloads, we demonstrate that SPAARC significantly improves cache hit rates compared to standard caching algorithms, achieving gains ranging from 3% to 40% while reducing the need for on-demand data retrieval from the cloud. Further, we present an adaptive tuning algorithm that automatically tunes SPAARC parameters to achieve optimal performance. Our findings demonstrate the potential of SPAARC to substantially enhance the user experience in MAR applications by ensuring the timely availability of virtual objects.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.15192v2</guid>
      <category>cs.ET</category>
      <category>cs.DC</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nikhil Sreekumar, Abhishek Chandra, Jon Weissman</dc:creator>
    </item>
    <item>
      <title>HyDra: SOT-CAM Based Vector Symbolic Macro for Hyperdimensional Computing</title>
      <link>https://arxiv.org/abs/2504.14020</link>
      <description>arXiv:2504.14020v2 Announce Type: replace 
Abstract: Hyperdimensional computing (HDC) is a brain-inspired paradigm valued for its noise robustness, parallelism, energy efficiency, and low computational overhead. Hardware accelerators are being explored to further enhance its performance, but current solutions are often limited by application specificity and the latency of encoding and similarity search. This paper presents a generalized, reconfigurable on-chip training and inference architecture for HDC, utilizing spin-orbit-torque magnetic (SOT-MRAM) content-addressable memory (CAM). The proposed SOT-CAM array integrates storage and computation, enabling in-memory execution of key HDC operations: binding (bitwise multiplication), permutation (bit rotation), and efficient similarity search. To mitigate interconnect parasitic effect in similarity search, a four-stage voltage scaling scheme has been proposed to ensure accurate Hamming distance representation. Additionally, a novel bit drop method replaces bit rotation during read operations, and an HDC-specific adder reduces energy and area by 1.51x and 1.43x, respectively. Benchmarked at 7nm, the architecture achieves energy reductions of 21.5x, 552.74x, 1.45x, and 282.57x for addition, permutation, multiplication, and search operations, respectively, compared to CMOS-based HDC. Against state-of-the-art HD accelerators, it achieves a 2.27x lower energy consumption and outperforms CPU and eGPU implementations by 2702x and 23161x, respectively, with less than 3% drop in accuracy</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14020v2</guid>
      <category>cs.ET</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Md Mizanur Rahaman Nayan, Che-Kai Liu, Zishen Wan, Arijit Raychowdhury, Azad J Naeemi</dc:creator>
    </item>
    <item>
      <title>Count2Multiply: Reliable In-Memory High-Radix Counting</title>
      <link>https://arxiv.org/abs/2409.10136</link>
      <description>arXiv:2409.10136v3 Announce Type: replace-cross 
Abstract: Computing-in-memory (CIM) has been demonstrated across various memory technologies, ranging from memristive crossbars performing analog dot-product computations to large-scale digital bitwise operations in commodity DRAM and other proposed non-volative memory technologies. However, current CIM solutions face latency and reliability challenges. CIM fidelity lags considerably behind access fidelity. Furthermore, bulk-bitwise CIM, although highly parallelized, requires long latency for operations like multiplication and addition, due to their bit-serial computation. This paper presents Count2Multiply, a technology-agnostic digital CIM approach to perform multiplication, addition and other operations using high-radix, massively parallel counting enabled by CIM bulk-bitwise logic operations. Designed to meet fault tolerance requirements, Count2Multiply integrates traditional row-wise error correction codes, such as Hamming and BCH, to address the high error rates in existing CIM designs. We demonstrate Count2Multiply with a detailed application to CIM in conventional DRAM due to its ubiquity and high endurance. However, we note that the Count2Multiply architecture is compatible with other functionally complete CIM proposals. Compared to the state-of-the-art in-DRAM CIM method, Count2Multiply achieves up to 10x speedup, 8x higher GOPS/Watt, and 9.5x higher GOPS/area, while outperforming GPU for vector-matrix multiplications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.10136v3</guid>
      <category>cs.AR</category>
      <category>cs.ET</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jo\~ao Paulo Cardoso de Lima, Benjamin Franklin Morris III, Asif Ali Khan, Jeronimo Castrillon, Alex K. Jones</dc:creator>
    </item>
    <item>
      <title>Evaluating DAO Sustainability and Longevity Through On-Chain Governance Metrics</title>
      <link>https://arxiv.org/abs/2504.11341</link>
      <description>arXiv:2504.11341v2 Announce Type: replace-cross 
Abstract: Decentralised Autonomous Organisations (DAOs) automate governance and resource allocation through smart contracts, aiming to shift decision-making to distributed token holders. However, many DAOs face sustainability challenges linked to limited user participation, concentrated voting power, and technical design constraints. This paper addresses these issues by identifying research gaps in DAO evaluation and introducing a framework of Key Performance Indicators (KPIs) that capture governance efficiency, financial robustness, decentralisation, and community engagement. We apply the framework to a custom-built dataset of real-world DAOs constructed from on-chain data and analysed using non-parametric methods. The results reveal recurring governance patterns, including low participation rates and high proposer concentration, which may undermine long-term viability. The proposed KPIs offer a replicable, data-driven method for assessing DAO governance structures and identifying potential areas for improvement. These findings support a multidimensional approach to evaluating decentralised systems and provide practical tools for researchers and practitioners working to improve the resilience and effectiveness of DAO-based governance models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.11341v2</guid>
      <category>cs.CY</category>
      <category>cs.ET</category>
      <category>cs.SI</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Silvio Meneguzzo, Claudio Schifanella, Valentina Gatteschi, Giuseppe Destefanis</dc:creator>
    </item>
  </channel>
</rss>
