<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.SE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.SE</link>
    <description>cs.SE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.SE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 11 Jul 2024 01:33:41 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 10 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>How to Measure Performance in Agile Software Development? A Mixed-Method Study</title>
      <link>https://arxiv.org/abs/2407.06357</link>
      <description>arXiv:2407.06357v1 Announce Type: new 
Abstract: Context: Software process improvement (SPI) is known as a key for being successfull in software development. Measuring quality and performance is of high importance in agile software development as agile approaches focussing strongly on short-term success in dynamic markets. Even if software engineering research emphasizes the importance of performance metrics while using agile methods, the literature lacks on detail how to apply such metrics in practice and what challenges may occur while using them. Objective: The core objective of our study is to identify challenges that arise when using agile software development performance metrics in practice and how we can improve their successful application. Method: We decided to design a mixed-method study. First, we performed a rapid literature review to provide an up-to-date overview of used performance metrics. Second, we conducted a single case study using a focus group approach and qualitativ data collection and analysis in a real-world setting. Results: Our results show that while widely used performance metrics such as story points and burn down charts are widely used in practice, agile software development teams face challenges due to a lack of transparency and standardization as well as insufficient accuracy. Contributions: Based on our findings, we present a repository of widely used performance metrics for agile software development. Furthermore, we present implications for practitioners and researchers especially how to deal with challenges agile software development face while applying such metrics in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.06357v1</guid>
      <category>cs.SE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kevin Phong Pham, Michael Neumann</dc:creator>
    </item>
    <item>
      <title>CodeCSE: A Simple Multilingual Model for Code and Comment Sentence Embeddings</title>
      <link>https://arxiv.org/abs/2407.06360</link>
      <description>arXiv:2407.06360v1 Announce Type: new 
Abstract: Pretrained language models for code token embeddings are used in code search, code clone detection, and other code-related tasks. Similarly, code function embeddings are useful in such tasks. However, there are no out-of-box models for function embeddings in the current literature. So, this paper proposes CodeCSE, a contrastive learning model that learns embeddings for functions and their descriptions in one space. We evaluated CodeCSE using code search. CodeCSE's multi-lingual zero-shot approach is as efficient as the models finetuned from GraphCodeBERT for specific languages. CodeCSE is open source at https://github.com/emu-se/codecse and the pretrained model is available at the HuggingFace public hub: https://huggingface.co/sjiang1/codecse</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.06360v1</guid>
      <category>cs.SE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anthony Varkey, Siyuan Jiang, Weijing Huang</dc:creator>
    </item>
    <item>
      <title>LLM for Mobile: An Initial Roadmap</title>
      <link>https://arxiv.org/abs/2407.06573</link>
      <description>arXiv:2407.06573v1 Announce Type: new 
Abstract: When mobile meets LLMs, mobile app users deserve to have more intelligent usage experiences. For this to happen, we argue that there is a strong need to appl LLMs for the mobile ecosystem. We therefore provide a research roadmap for guiding our fellow researchers to achieve that as a whole. In this roadmap, we sum up six directions that we believe are urgently required for research to enable native intelligence in mobile devices. In each direction, we further summarize the current research progress and the gaps that still need to be filled by our fellow researchers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.06573v1</guid>
      <category>cs.SE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daihang Chen, Yonghui Liu, Mingyi Zhou, Yanjie Zhao, Haoyu Wang, Shuai Wang, Xiao Chen, Tegawend\'e F. Bissyand\'e, Jacques Klein, Li Li</dc:creator>
    </item>
    <item>
      <title>The Cost of Executing Business Processes on Next-Generation Blockchains: The Case of Algorand</title>
      <link>https://arxiv.org/abs/2407.06725</link>
      <description>arXiv:2407.06725v1 Announce Type: new 
Abstract: Process (or workflow) execution on blockchain suffers from limited scalability; specifically, costs in the form of transactions fees are a major limitation for employing traditional public blockchain platforms in practice. Research, so far, has mainly focused on exploring first (Bitcoin) and second-generation (e.g., Ethereum) blockchains for business process enactment. However, since then, novel blockchain systems have been introduced - aimed at tackling many of the problems of previous-generation blockchains. We study such a system, Algorand, from a process execution perspective. Algorand promises low transaction fees and fast finality. However, Algorand's cost structure differs greatly from previous generation blockchains, rendering earlier cost models for blockchain-based process execution non-applicable. We discuss and contrast Algorand's novel cost structure with Ethereum's well-known cost model. To study the impact for process execution, we present a compiler for BPMN Choreographies, with an intermediary layer, which can support multi-platform output, and provide a translation to TEAL contracts, the smart contract language of Algorand. We compare the cost of executing processes on Algorand to previous work as well as traditional cloud computing. In short: they allow vast cost benefits. However, we note a multitude of future research challenges that remain in investigating and comparing such results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.06725v1</guid>
      <category>cs.SE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fabian Stiehle, Ingo Weber</dc:creator>
    </item>
    <item>
      <title>Exploring the Experiences of Experts: Sustainability in Agile Software Development -- Insights from the Finnish Software Industry</title>
      <link>https://arxiv.org/abs/2407.06978</link>
      <description>arXiv:2407.06978v1 Announce Type: new 
Abstract: Agile software development is gaining popularity among software developers due to its benefits. As the interest in agile software development grows, there is an increasing focus on investigating sustainability within this field. This study aimed to explore sustainability within agile software development in the Finnish software industry and, through gathered experiences, contribute to the software engineering roadmap 2030. Using an interview approach, we conducted an empirical study within the Finnish software industry to achieve this goal. The findings indicate a growing interest among experts in integrating sustainability into agile software development. The results show that the Scrum methodology is the most popular approach in the Finnish software industry, and addressing different sustainability dimensions can have a ripple effect on each other. The study proposes three key elements to be considered in the software engineering roadmap 2030: integrating sustainability into software engineering education, creating sustainability tools and frameworks, and assessing the energy efficiency of libraries used in software development.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.06978v1</guid>
      <category>cs.SE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hatef Shamshiri, Ashok Tripathi, Shola Oyedeji, Jari Porras</dc:creator>
    </item>
    <item>
      <title>Elevating Academic Administration: A Comprehensive Faculty Dashboard for Tracking Student Evaluations and Research</title>
      <link>https://arxiv.org/abs/2407.07057</link>
      <description>arXiv:2407.07057v1 Announce Type: new 
Abstract: The USC Faculty Dashboard is a web application designed to revolutionize how department heads, professors, and instructors monitor progress and make decisions, providing a centralized hub for efficient data storage and analysis. Currently, there's a gap in tools tailored for department heads to concisely manage the performance of their department, which our platform aims to fill. The USC Faculty Dashboard offers easy access to upload and view student evaluation and research information, empowering department heads to evaluate the performance of faculty members and seamlessly track their research grants, publications, and expenditures. Furthermore, professors and instructors gain personalized performance analysis tools, with full access to their own data as well as curated access to peer data to assess their relative performance. The source code as well as the link to the deployed application can be found at https://github.com/SCCapstone/K3MS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.07057v1</guid>
      <category>cs.SE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Senior Theses. 695. https://scholarcommons.sc.edu/senior_theses/695</arxiv:journal_reference>
      <dc:creator>Musa Azeem, Muhammad Tukhtasunov, Savannah Noblitt, Mitchel Jonker, Kevin Protzman</dc:creator>
    </item>
    <item>
      <title>Prompting Techniques for Secure Code Generation: A Systematic Investigation</title>
      <link>https://arxiv.org/abs/2407.07064</link>
      <description>arXiv:2407.07064v1 Announce Type: new 
Abstract: Large Language Models (LLMs) are gaining momentum in software development with prompt-driven programming enabling developers to create code from natural language (NL) instructions. However, studies have questioned their ability to produce secure code and, thereby, the quality of prompt-generated software. Alongside, various prompting techniques that carefully tailor prompts have emerged to elicit optimal responses from LLMs. Still, the interplay between such prompting strategies and secure code generation remains under-explored and calls for further investigations. OBJECTIVE: In this study, we investigate the impact of different prompting techniques on the security of code generated from NL instructions by LLMs. METHOD: First we perform a systematic literature review to identify the existing prompting techniques that can be used for code generation tasks. A subset of these techniques are evaluated on GPT-3, GPT-3.5, and GPT-4 models for secure code generation. For this, we used an existing dataset consisting of 150 NL security-relevant code-generation prompts. RESULTS: Our work (i) classifies potential prompting techniques for code generation (ii) adapts and evaluates a subset of the identified techniques for secure code generation tasks and (iii) observes a reduction in security weaknesses across the tested LLMs, especially after using an existing technique called Recursive Criticism and Improvement (RCI), contributing valuable insights to the ongoing discourse on LLM-generated code security.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.07064v1</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <category>cs.CR</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Catherine Tony, Nicol\'as E. D\'iaz Ferreyra, Markus Mutas, Salem Dhiff, Riccardo Scandariato</dc:creator>
    </item>
    <item>
      <title>On Simulation of Power Systems and Microgrid Components with SystemC-AMS</title>
      <link>https://arxiv.org/abs/2407.06217</link>
      <description>arXiv:2407.06217v1 Announce Type: cross 
Abstract: Cyber-physical systems such as microgrids consist of interconnected components, localized power systems, and distributed energy resources with clearly defined electrical boundaries. They can function independently but can also work in tandem with the main grid. Power system converters and their control loops play an essential role in stabilizing grids and interfacing a microgrid with the main grid. The optimal selection of microgrid components for installation is expensive. Simulation of microgrids provides a cost-effective solution. However, when studying the electromagnetic transient response, their simulation is slow. Furthermore, software packages facilitating electromagnetic transient response may be prohibitively expensive. This paper presents a faster method for simulating the electromagnetic transient response of microgrid components using SystemC-AMS. We present a use case of a photovoltaic grid-following inverter with a phase-locked loop to track reference active and reactive power. Our results demonstrate that the simulation performed using SystemC-AMS is roughly three times faster than the benchmark simulation conducted using Simulink. Our implementation of a photovoltaic grid-following inverter equipped with a phase-locked loop for monitoring reference active and reactive power reveals that the simulation executed using SystemC-AMS is approximately three times faster than the benchmark simulation carried out using Simulink. Our implementation adopts a model-based design and produces a library of components that can be used to construct increasingly complex grid architectures. Additionally, the C-based nature allows for the integration of external libraries for added real-time capability and optimization functionality. We also present a use case for real-time simulation using a DC microgrid with a constant resistive load.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.06217v1</guid>
      <category>eess.SY</category>
      <category>cs.SE</category>
      <category>cs.SY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rahul Bhadani, Satyaki Banik, Hao Tu, Srdjan Lukic, Gabor Karsai</dc:creator>
    </item>
    <item>
      <title>CodeUpdateArena: Benchmarking Knowledge Editing on API Updates</title>
      <link>https://arxiv.org/abs/2407.06249</link>
      <description>arXiv:2407.06249v1 Announce Type: cross 
Abstract: Large language models (LLMs) are increasingly being used to synthesize and reason about source code. However, the static nature of these models' knowledge does not reflect the fact that libraries and API functions they invoke are continuously evolving, with functionality being added or changing. While numerous benchmarks evaluate how LLMs can generate code, no prior work has studied how an LLMs' knowledge about code API functions can be updated. To fill this gap, we present CodeUpdateArena, a benchmark for knowledge editing in the code domain. An instance in our benchmark consists of a synthetic API function update paired with a program synthesis example that uses the updated functionality; our goal is to update an LLM to be able to solve this program synthesis example without providing documentation of the update at inference time. Compared to knowledge editing for facts encoded in text, success here is more challenging: a code LLM must correctly reason about the semantics of the modified function rather than just reproduce its syntax. Our dataset is constructed by first prompting GPT-4 to generate atomic and executable function updates. Then, for each update, we generate program synthesis examples whose code solutions are prone to use the update. Our benchmark covers updates of various types to 54 functions from seven diverse Python packages, with a total of 670 program synthesis examples. Our experiments show that prepending documentation of the update to open-source code LLMs (i.e., DeepSeek, CodeLlama) does not allow them to incorporate changes for problem solving, and existing knowledge editing techniques also have substantial room for improvement. We hope our benchmark will inspire new methods for knowledge updating in code LLMs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.06249v1</guid>
      <category>cs.CL</category>
      <category>cs.SE</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zeyu Leo Liu, Shrey Pandit, Xi Ye, Eunsol Choi, Greg Durrett</dc:creator>
    </item>
    <item>
      <title>Toward Programming Languages for Reasoning: Humans, Symbolic Systems, and AI Agents</title>
      <link>https://arxiv.org/abs/2407.06356</link>
      <description>arXiv:2407.06356v1 Announce Type: cross 
Abstract: Integration, composition, mechanization, and AI assisted development are the driving themes in the future of software development. At their core these concepts are rooted in the increasingly important role of computing in our world, the desire to deliver functionality faster, with higher quality, and to empower more people to benefit from programmatic automation. These themes, and how they impact the human developers driving them, are the foundations for the next generation of programming languages. At first glance the needs of mechanization tools, AI agents, and human developers along with the various goals around development velocity, software quality, and software democratization are a broad and seemingly diverse set of needs. However, at their core is a single challenge that, once resolved, enables us to make radical progress in all of these areas.
  Our hypothesis is that, fundamentally, software development is a problem of reasoning about code and semantics. This is true for human developers implementing a feature, symbolic tools building models of application behavior, and even for language based AI agents as they perform tasks. While the particular aspects of reasoning that each agent struggles with varies to some degree, they share many common themes and, surprisingly, most mainstream languages extensively employ (anti)features that make this task harder or infeasible! This paper proposes a novel approach to this challenge -- instead of new language features or logical constructs, that add more complexity to what is already a problem of complexity, we propose radical simplification in the form of the Bosque platform and language.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.06356v1</guid>
      <category>cs.PL</category>
      <category>cs.SE</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3622758.3622895</arxiv:DOI>
      <dc:creator>Mark Marron</dc:creator>
    </item>
    <item>
      <title>A Comparison of Vulnerability Feature Extraction Methods from Textual Attack Patterns</title>
      <link>https://arxiv.org/abs/2407.06753</link>
      <description>arXiv:2407.06753v1 Announce Type: cross 
Abstract: Nowadays, threat reports from cybersecurity vendors incorporate detailed descriptions of attacks within unstructured text. Knowing vulnerabilities that are related to these reports helps cybersecurity researchers and practitioners understand and adjust to evolving attacks and develop mitigation plans. This paper aims to aid cybersecurity researchers and practitioners in choosing attack extraction methods to enhance the monitoring and sharing of threat intelligence. In this work, we examine five feature extraction methods (TF-IDF, LSI, BERT, MiniLM, RoBERTa) and find that Term Frequency-Inverse Document Frequency (TF-IDF) outperforms the other four methods with a precision of 75\% and an F1 score of 64\%. The findings offer valuable insights to the cybersecurity community, and our research can aid cybersecurity researchers in evaluating and comparing the effectiveness of upcoming extraction methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.06753v1</guid>
      <category>cs.CR</category>
      <category>cs.SE</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Refat Othman, Bruno Rossi, Russo Barbara</dc:creator>
    </item>
    <item>
      <title>Cybersecurity Defenses: Exploration of CVE Types through Attack Descriptions</title>
      <link>https://arxiv.org/abs/2407.06759</link>
      <description>arXiv:2407.06759v1 Announce Type: cross 
Abstract: Vulnerabilities in software security can remain undiscovered even after being exploited. Linking attacks to vulnerabilities helps experts identify and respond promptly to the incident. This paper introduces VULDAT, a classification tool using a sentence transformer MPNET to identify system vulnerabilities from attack descriptions. Our model was applied to 100 attack techniques from the ATT&amp;CK repository and 685 issues from the CVE repository. Then, we compare the performance of VULDAT against the other eight state-of-the-art classifiers based on sentence transformers. Our findings indicate that our model achieves the best performance with F1 score of 0.85, Precision of 0.86, and Recall of 0.83. Furthermore, we found 56% of CVE reports vulnerabilities associated with an attack were identified by VULDAT, and 61% of identified vulnerabilities were in the CVE repository.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.06759v1</guid>
      <category>cs.CR</category>
      <category>cs.SE</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Refat Othman, Bruno Rossi, Barbara Russo</dc:creator>
    </item>
    <item>
      <title>A Simple Way to Verify Linearizability of Concurrent Stacks</title>
      <link>https://arxiv.org/abs/2110.05801</link>
      <description>arXiv:2110.05801v2 Announce Type: replace 
Abstract: Linearizability is a commonly accepted correctness criterion for concurrent data structures. However, verifying linearizability of highly concurrent data structures is still a challenging task. In this paper, we present a simple and complete proof technique for verifying linearizability of concurrent stacks. Our proof technique reduces linearizability of concurrent stacks to establishing a set of conditions. These conditions are based on the happened-before order of operations, intuitively express the LIFO semantics and can be proved by simple arguments. Designers of concurrent data structures can easily and quickly learn to use the proof technique. We have successfully applied the method to several challenging concurrent stacks: the TS stack, the HSY stack, and the FA stack, etc.</description>
      <guid isPermaLink="false">oai:arXiv.org:2110.05801v2</guid>
      <category>cs.SE</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tangliu Wen</dc:creator>
    </item>
    <item>
      <title>SmartChoices: Augmenting Software with Learned Implementations</title>
      <link>https://arxiv.org/abs/2304.13033</link>
      <description>arXiv:2304.13033v3 Announce Type: replace 
Abstract: In many software systems, heuristics are used to make decisions - such as cache eviction, task scheduling, and information presentation - that have a significant impact on overall system behavior. While machine learning may outperform these heuristics, replacing existing heuristics in a production system safely and reliably can be prohibitively costly. We present SmartChoices, a novel approach that reduces the cost to deploy production-ready ML solutions for contextual bandits problems. SmartChoices' interface cleanly separates problem formulation from implementation details: engineers describe their use case by defining datatypes for the context, arms, and feedback that are passed to SmartChoices APIs, while SmartChoices manages encoding &amp; logging data and training, evaluating &amp; deploying policies. Our implementation codifies best practices, is efficient enough for use in low-level applications, and provides valuable production features off the shelf via a shared library. Overall, SmartChoices enables non-experts to rapidly deploy production-ready ML solutions by eliminating many sources of technical debt common to ML systems. Engineers have independently used SmartChoices to improve a wide range of software including caches, batch processing workloads, and UI layouts, resulting in better latency, throughput, and click-through rates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.13033v3</guid>
      <category>cs.SE</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel Golovin, Gabor Bartok, Eric Chen, Emily Donahue, Tzu-Kuo Huang, Efi Kokiopoulou, Ruoyan Qin, Nikhil Sarda, Justin Sybrandt, Vincent Tjeng</dc:creator>
    </item>
    <item>
      <title>MELT: Mining Effective Lightweight Transformations from Pull Requests</title>
      <link>https://arxiv.org/abs/2308.14687</link>
      <description>arXiv:2308.14687v2 Announce Type: replace 
Abstract: Software developers often struggle to update APIs, leading to manual, time-consuming, and error-prone processes. We introduce MELT, a new approach that generates lightweight API migration rules directly from pull requests in popular library repositories. Our key insight is that pull requests merged into open-source libraries are a rich source of information sufficient to mine API migration rules. By leveraging code examples mined from the library source and automatically generated code examples based on the pull requests, we infer transformation rules in \comby, a language for structural code search and replace. Since inferred rules from single code examples may be too specific, we propose a generalization procedure to make the rules more applicable to client projects. MELT rules are syntax-driven, interpretable, and easily adaptable. Moreover, unlike previous work, our approach enables rule inference to seamlessly integrate into the library workflow, removing the need to wait for client code migrations. We evaluated MELT on pull requests from four popular libraries, successfully mining 461 migration rules from code examples in pull requests and 114 rules from auto-generated code examples. Our generalization procedure increases the number of matches for mined rules by 9x. We applied these rules to client projects and ran their tests, which led to an overall decrease in the number of warnings and fixing some test cases demonstrating MELT's effectiveness in real-world scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.14687v2</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/ASE56229.2023.00117</arxiv:DOI>
      <arxiv:journal_reference>38th IEEE/ACM International Conference on Automated Software Engineering, ASE 2023, Luxembourg, September 11-15, 2023</arxiv:journal_reference>
      <dc:creator>Daniel Ramos, Hailie Mitchell, In\^es Lynce, Vasco Manquinho, Ruben Martins, Claire Le Goues</dc:creator>
    </item>
    <item>
      <title>Describing Globally Distributed Software Architectures for Tax Compliance</title>
      <link>https://arxiv.org/abs/2312.00925</link>
      <description>arXiv:2312.00925v3 Announce Type: replace 
Abstract: Background: The company-internal reuse of software components owned by organizational units in different countries constitutes an implicit licensing across borders, which is taxable. This makes tax authorities a less known stakeholder in software architectures. Objective: Therefore, we investigate how software companies can describe the implicit license structure of their globally distributed software architectures to tax authorities. Method: We develop a viewpoint that frames the concerns of tax authorities, use this viewpoint to construct a view of a large-scale microservice architecture of a multinational enterprise, and evaluate the resulting software architecture description with a panel of four tax experts. Results: The panel found our proposed architectural viewpoint properly and sufficiently frames the concerns of taxation stakeholders. However, unclear jurisdictions of owners and potentially insufficient definitions of code ownership and software component introduce significant noise to the view that limits the usefulness and explanatory power of our software architecture description. Conclusion: While our software architecture description provides a solid foundation, we believe it only represents the tip of the iceberg. Future research is necessary to pave the way for advancements in tax compliance within software engineering.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.00925v3</guid>
      <category>cs.SE</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Dorner, Oliver Treidler, Tom-Eric Kunz, Ehsan Zabardast, Daniel Mendez, Darja \v{S}mite, Maximilian Capraro, Krzysztof Wnuk</dc:creator>
    </item>
    <item>
      <title>6GSoft: Software for Edge-to-Cloud Continuum</title>
      <link>https://arxiv.org/abs/2407.05963</link>
      <description>arXiv:2407.05963v2 Announce Type: replace 
Abstract: In the era of 6G, developing and managing software requires cutting-edge software engineering (SE) theories and practices tailored for such complexity across a vast number of connected edge devices. Our project aims to lead the development of sustainable methods and energy-efficient orchestration models specifically for edge environments, enhancing architectural support driven by AI for contemporary edge-to-cloud continuum computing. This initiative seeks to position Finland at the forefront of the 6G landscape, focusing on sophisticated edge orchestration and robust software architectures to optimize the performance and scalability of edge networks. Collaborating with leading Finnish universities and companies, the project emphasizes deep industry-academia collaboration and international expertise to address critical challenges in edge orchestration and software architecture, aiming to drive significant advancements in software productivity and market impact.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.05963v2</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <category>cs.NI</category>
      <category>cs.SI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Muhammad Azeem Akbar, Matteo Esposito, Sami Hyrynsalmi, Karthikeyan Dinesh Kumar, Valentina Lenarduzzi, Xiaozhou Li, Ali Mehraj, Tommi Mikkonen, Sergio Moreschini, Niko M\"akitalo, Markku Oivo, Anna-Sofia Paavonen, Risha Parveen, Kari Smolander, Ruoyu Su, Kari Syst\"a, Davide Taibi, Nan Yang, Zheying Zhang, Muhammad Zohaib</dc:creator>
    </item>
    <item>
      <title>A hybrid LLM workflow can help identify user privilege related variables in programs of any size</title>
      <link>https://arxiv.org/abs/2403.15723</link>
      <description>arXiv:2403.15723v2 Announce Type: replace-cross 
Abstract: Many programs involves operations and logic manipulating user privileges, which is essential for the security of an organization. Therefore, one common malicious goal of attackers is to obtain or escalate the privileges, causing privilege leakage. To protect the program and the organization against privilege leakage attacks, it is important to eliminate the vulnerabilities which can be exploited to achieve such attacks. Unfortunately, while memory vulnerabilities are less challenging to find, logic vulnerabilities are much more imminent, harmful and difficult to identify. Accordingly, many analysts choose to find user privilege related (UPR) variables first as start points to investigate the code where the UPR variables may be used to see if there exists any vulnerabilities, especially the logic ones. In this paper, we introduce a large language model (LLM) workflow that can assist analysts in identifying such UPR variables, which is considered to be a very time-consuming task. Specifically, our tool will audit all the variables in a program and output a UPR score, which is the degree of relationship (closeness) between the variable and user privileges, for each variable. The proposed approach avoids the drawbacks introduced by directly prompting a LLM to find UPR variables by focusing on leverage the LLM at statement level instead of supplying LLM with very long code snippets. Those variables with high UPR scores are essentially potential UPR variables, which should be manually investigated. Our experiments show that using a typical UPR score threshold (i.e., UPR score &gt;0.8), the false positive rate (FPR) is only 13.49%, while UPR variable found is significantly more than that of the heuristic based method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15723v2</guid>
      <category>cs.CR</category>
      <category>cs.SE</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haizhou Wang, Zhilong Wang, Peng Liu</dc:creator>
    </item>
    <item>
      <title>Using Grammar Masking to Ensure Syntactic Validity in LLM-based Modeling Tasks</title>
      <link>https://arxiv.org/abs/2407.06146</link>
      <description>arXiv:2407.06146v2 Announce Type: replace-cross 
Abstract: We present and evaluate a method called grammar masking, which is used to guide large language models (LLMs) toward producing syntactically correct models for a given context-free grammar. Prompt engineering methods such as few-shot learning or priming can be used to improve the chances of an LLM producing correct syntax, but the more complex the grammar, the more time-consuming and less promising these methods become. Previous work is focused primarily on the usage of either language model training or prompt engineering. In this work, a method is presented that restricts the output to a given grammar using constrained decoding to ensure the output adheres to a valid syntax. We use several DSLs built with MontiCore and task multiple LLMs to produce models with and without constrained decoding. A corresponding parser is used to confirm the syntactic correctness of each model. We show that grammar masking can dramatically improve the modeling capabilities of several LLMs, reducing the need for well-refined prompting while increasing the chance of producing correct models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.06146v2</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.SE</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lukas Netz, Jan Reimer, Bernhard Rumpe</dc:creator>
    </item>
  </channel>
</rss>
