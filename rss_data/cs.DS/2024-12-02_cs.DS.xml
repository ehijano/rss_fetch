<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 03 Dec 2024 04:25:26 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Near-Optimal Trace Reconstruction for Mildly Separated Strings</title>
      <link>https://arxiv.org/abs/2411.18765</link>
      <description>arXiv:2411.18765v1 Announce Type: new 
Abstract: In the trace reconstruction problem our goal is to learn an unknown string $x\in \{0,1\}^n$ given independent traces of $x$. A trace is obtained by independently deleting each bit of $x$ with some probability $\delta$ and concatenating the remaining bits. It is a major open question whether the trace reconstruction problem can be solved with a polynomial number of traces when the deletion probability $\delta$ is constant. The best known upper bound and lower bounds are respectively $\exp(\tilde O(n^{1/5}))$ and $\tilde \Omega(n^{3/2})$ both by Chase [Cha21b,Cha21a]. Our main result is that if the string $x$ is mildly separated, meaning that the number of zeros between any two ones in $x$ is at least polylog$n$, and if $\delta$ is a sufficiently small constant, then the trace reconstruction problem can be solved with $O(n \log n)$ traces and in polynomial time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.18765v1</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anders Aamand, Allen Liu, Shyam Narayanan</dc:creator>
    </item>
    <item>
      <title>Fast Schulze Voting Using Quickselect</title>
      <link>https://arxiv.org/abs/2411.18790</link>
      <description>arXiv:2411.18790v1 Announce Type: new 
Abstract: The Schulze voting method aggregates voter preference data using maxmin-weight graph paths, achieving the Condorcet property that a candidate who would win every head-to-head contest will also win the overall election. Once the voter preferences among $m$ candidates have been arranged into an $m\times m$ matrix of pairwise election outcomes, a previous algorithm of Sornat, Vassilevska Williams and Xu (EC '21) determines the Schulze winner in randomized expected time $O(m^2\log^4 m)$. We improve this to randomized expected time $O(m^2\log m)$ using a modified version of quickselect.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.18790v1</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arushi Arora, David Eppstein, Randy Le Huynh</dc:creator>
    </item>
    <item>
      <title>Improved Approximation Algorithms for Flexible Graph Connectivity and Capacitated Network Design</title>
      <link>https://arxiv.org/abs/2411.18809</link>
      <description>arXiv:2411.18809v1 Announce Type: new 
Abstract: We present improved approximation algorithms for some problems in the related areas of Flexible Graph Connectivity and Capacitated Network Design. In the $(p,q)$-Flexible Graph Connectivity problem, denoted $(p,q)$-FGC, the input is a graph $G(V, E)$ where $E$ is partitioned into safe and unsafe edges, and the goal is to find a minimum cost set of edges $F$ such that the subgraph $G'(V, F)$ remains $p$-edge connected upon removal of any $q$ unsafe edges from $F$. In the related Cap-$k$-ECSS problem, we are given a graph $G(V,E)$ whose edges have arbitrary integer capacities, and the goal is to find a minimum cost subset of edges $F$ such that the graph $G'(V,F)$ is $k$-edge connected.
  We obtain a $7$-approximation algorithm for the $(1,q)$-FGC problem that improves upon the previous best $(q+1)$-approximation. We also give an $O(\log{k})$-approximation algorithm for the Cap-$k$-ECSS problem, improving upon the previous best $O(\log{n})$-approximation whenever $k = o(n)$. Both these results are obtained by using natural LP relaxations strengthened with the knapsack-cover inequalities, and then during the rounding process utilizing an $O(1)$-approximation algorithm for the problem of covering small cuts. We also show that the the problem of covering small cuts inherently arises in another variant of $(p,q)$-FGC. Specifically, we show $O(1)$-approximate reductions between the $(2,q)$-FGC problem and the 2-Cover$\;$Small$\;$Cuts problem where each small cut needs to be covered twice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.18809v1</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ishan Bansal, Joseph Cheriyan, Sanjeev Khanna, Miles Simmons</dc:creator>
    </item>
    <item>
      <title>Streaming Algorithms via Local Algorithms for Maximum Directed Cut</title>
      <link>https://arxiv.org/abs/2411.18829</link>
      <description>arXiv:2411.18829v1 Announce Type: new 
Abstract: We explore the use of local algorithms in the design of streaming algorithms for the Maximum Directed Cut problem. Specifically, building on the local algorithm of Buchbinder et al. (FOCS'12) and Censor-Hillel et al. (ALGOSENSORS'17), we develop streaming algorithms for both adversarially and randomly ordered streams that approximate the value of maximum directed cut in bounded-degree graphs. In $n$-vertex graphs, for adversarially ordered streams, our algorithm uses $O(n^{1-\Omega(1)})$ (sub-linear) space and for randomly ordered streams, our algorithm uses logarithmic space. Moreover, both algorithms require only one pass over the input stream. With a constant number of passes, we give a logarithmic-space algorithm which works even on graphs with unbounded degree on adversarially ordered streams. Our algorithms achieve any fixed constant approximation factor less than $\frac12$. In the single-pass setting, this is tight: known lower bounds show that obtaining any constant approximation factor greater than $\frac12$ is impossible without using linear space in adversarially ordered streams (Kapralov and Krachun, STOC'19) and $\Omega(\sqrt{n})$ space in randomly ordered streams, even on bounded degree graphs (Kapralov, Khanna, and Sudan, SODA'15).
  In terms of techniques, our algorithms partition the vertices into a small number of different types based on the structure of their local neighborhood, ensuring that each type carries enough information about the structure to approximately simulate the local algorithm on a vertex with that type. We then develop tools to accurately estimate the frequency of each type. This allows us to simulate an execution of the local algorithm on all vertices, and thereby approximate the value of the maximum directed cut.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.18829v1</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Raghuvansh R. Saxena, Noah G. Singer, Madhu Sudan, Santhoshini Velusamy</dc:creator>
    </item>
    <item>
      <title>A Simple and Fast Algorithm for Fair Cuts</title>
      <link>https://arxiv.org/abs/2411.19098</link>
      <description>arXiv:2411.19098v1 Announce Type: new 
Abstract: We present a simple and faster algorithm for computing fair cuts on undirected graphs, a concept introduced in recent work of Li et al. (SODA 2023). Informally, for any parameter $\epsilon&gt;0$, a $(1+\epsilon)$-fair $(s,t)$-cut is an $(s,t)$-cut such that there exists an $(s,t)$-flow that uses $1/(1+\epsilon)$ fraction of the capacity of every edge in the cut. Our algorithm computes a $(1+\epsilon)$-fair cut in $\tilde O(m/\epsilon)$ time, improving on the $\tilde O(m/\epsilon^3)$ time algorithm of Li et al. and matching the $\tilde O(m/\epsilon)$ time algorithm of Sherman (STOC 2017) for standard $(1+\epsilon)$-approximate min-cut.
  Our main idea is to run Sherman's approximate max-flow/min-cut algorithm iteratively on a (directed) residual graph. While Sherman's algorithm is originally stated for undirected graphs, we show that it provides guarantees for directed graphs that are good enough for our purposes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19098v1</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jason Li, Owen Li</dc:creator>
    </item>
    <item>
      <title>Better Approximation for Weighted k-Matroid Intersection</title>
      <link>https://arxiv.org/abs/2411.19366</link>
      <description>arXiv:2411.19366v1 Announce Type: new 
Abstract: We consider the problem of finding an independent set of maximum weight simultaneously contained in $k$ matroids over a common ground set. This $k$-matroid intersection problem appears naturally in many contexts, for example in generalizing graph and hypergraph matching problems. In this paper, we provide a $(k+1)/(2 \ln 2)$-approximation algorithm for the weighted $k$-matroid intersection problem. This is the first improvement over the longstanding $(k-1)$-guarantee of Lee, Sviridenko and Vondr\'ak (2009). Along the way, we also give the first improvement over greedy for the more general weighted matroid $k$-parity problem.
  Our key innovation lies in a randomized reduction in which we solve almost unweighted instances iteratively. This perspective allows us to use insights from the unweighted problem for which Lee, Sviridenko, and Vondr\'ak have designed a $k/2$-approximation algorithm. We analyze this procedure by constructing refined matroid exchanges and leveraging randomness to avoid bad local minima.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19366v1</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Neta Singer, Theophile Thiery</dc:creator>
    </item>
    <item>
      <title>Hashing for Sampling-Based Estimation</title>
      <link>https://arxiv.org/abs/2411.19394</link>
      <description>arXiv:2411.19394v1 Announce Type: new 
Abstract: Hash-based sampling and estimation are common themes in computing. Using hashing for sampling gives us the coordination needed to compare samples from different sets. Hashing is also used when we want to count distinct elements. The quality of the estimator for, say, the Jaccard similarity between two sets, depends on the concentration of the number of sampled elements from their intersection. Often we want to compare one query set against many stored sets to find one of the most similar sets, so we need strong concentration and low error-probability. In this paper, we provide strong explicit concentration bounds for Tornado Tabulation hashing [Bercea, Beretta, Klausen, Houen, and Thorup, FOCS'23] which is a realistic constant time hashing scheme. Previous concentration bounds for fast hashing were off by orders of magnitude, in the sample size needed to guarantee the same concentration. The true power of our result appears when applied in the local uniformity framework by [Dahlgaard, Knudsen, Rotenberg, and Thorup, STOC'15].</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19394v1</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anders Aamand, Ioana O. Bercea, Jakob B{\ae}k Tejs Houen, Jonas Klausen, Mikkel Thorup</dc:creator>
    </item>
    <item>
      <title>A Bottom-Up Algorithm for Negative-Weight SSSP with Integrated Negative Cycle Finding</title>
      <link>https://arxiv.org/abs/2411.19449</link>
      <description>arXiv:2411.19449v1 Announce Type: new 
Abstract: We present a simplified algorithm for solving the Negative-Weight Single-Source Shortest Paths (SSSP) problem, focusing on enhancing clarity and practicality over prior methods. Our algorithm uses graph diameter as a recursive parameter, offering greater robustness to the properties of the decomposed graph compared to earlier approaches. Additionally, we fully integrate negative-weight cycle finding into the algorithm by augmenting the Bellman-Ford/Dijkstra hybrid, eliminating the need for a separate cycle-finding procedure found in prior methods. Although the algorithm achieves no theoretical efficiency gains, it simplifies negative cycle finding and emphasizes design simplicity, making it more accessible for implementation and analysis. This work highlights the importance of robust parameterization and algorithmic simplicity in addressing the challenges of Negative-Weight SSSP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19449v1</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jason Li, Connor Mowry</dc:creator>
    </item>
    <item>
      <title>Paired-domination Problem on Circle and $k$-polygon Graphs</title>
      <link>https://arxiv.org/abs/2411.19473</link>
      <description>arXiv:2411.19473v1 Announce Type: new 
Abstract: A vertex set $D \subseteq V$ is considered a dominating set of $G$ if every vertex in $V - D$ is adjacent to at least one vertex in $D$. We called a dominating set $D$ as a paired-dominating set if the subgraph of $G$ induced by $D$ contains a perfect matching. In this paper, we show that determining the minimum paired-dominating set on circle graphs is NP-complete. We further propose an $O(n(\frac{n}{k^2-k})^{2k^2-2k})$-time algorithm for $k$-polygon graphs, a subclass of circle graphs, for finding the minimum paired-dominating set. Moreover, we extend our method to improve the algorithm for finding the minimum dominating set on $k$-polygon graphs in~[\emph{E.S.~Elmallah and L.K.~Stewart, Independence and domination in polygon graphs, Discrete Appl. Math., 1993}] and reduce their time-complexity from $O(n^{4k^2+3})$ to $O(n(\frac{n}{k^2-k})^{2k^2-4k})$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19473v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>math.CO</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ta-Yu Mu, Ching-Chi Lin</dc:creator>
    </item>
    <item>
      <title>Optimal Algorithm for Paired-Domination in Distance-Hereditary Graphs</title>
      <link>https://arxiv.org/abs/2411.19476</link>
      <description>arXiv:2411.19476v1 Announce Type: new 
Abstract: The domination problem and its variants represent a classical domain within algorithmic graph theory. Among these variants, the paired-domination problem holds particular prominence due to its real-world implications in security and surveillance domains. Given an input graph $G$, the paired-domination problem involves identifying a minimum dominating set $D$ that induces a subgraph of $G$ with a perfect matching. Lin et al.~[\emph{Paired-domination problem on distance-hereditary graphs}, Algorithmica, 2020] previously presented a solution to this problem with a time complexity of $O(n^2)$. This paper significantly enhances their findings by introducing an $O(n+m)$-time algorithm. Furthermore, the time complexity of this algorithm can be reduced to $O(n)$ when provided with a decomposition tree for the graph $G$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19476v1</guid>
      <category>cs.DS</category>
      <category>math.CO</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ta-Yu Mu, Ching-Chi Lin</dc:creator>
    </item>
    <item>
      <title>Scalable Order-Preserving Pattern Mining</title>
      <link>https://arxiv.org/abs/2411.19511</link>
      <description>arXiv:2411.19511v1 Announce Type: new 
Abstract: Time series are ubiquitous in domains ranging from medicine to marketing and finance. Frequent Pattern Mining (FPM) from a time series has thus received much attention. Recently, it has been studied under the order-preserving (OP) matching relation stating that a match occurs when two time series have the same relative order on their elements. Here, we propose exact, highly scalable algorithms for FPM in the OP setting. Our algorithms employ an OP suffix tree (OPST) as an index to store and query time series efficiently. Unfortunately, there are no practical algorithms for OPST construction. Thus, we first propose a novel and practical $\mathcal{O}(n\sigma\log \sigma)$-time and $\mathcal{O}(n)$-space algorithm for constructing the OPST of a length-$n$ time series over an alphabet of size $\sigma$. We also propose an alternative faster OPST construction algorithm running in $\mathcal{O}(n\log \sigma)$ time using $\mathcal{O}(n)$ space; this algorithm is mainly of theoretical interest. Then, we propose an exact $\mathcal{O}(n)$-time and $\mathcal{O}(n)$-space algorithm for mining all maximal frequent OP patterns, given an OPST. This significantly improves on the state of the art, which takes $\Omega(n^3)$ time in the worst case. We also formalize the notion of closed frequent OP patterns and propose an exact $\mathcal{O}(n)$-time and $\mathcal{O}(n)$-space algorithm for mining all closed frequent OP patterns, given an OPST. We conducted experiments using real-world, multi-million letter time series showing that our $\mathcal{O}(n\sigma \log \sigma)$-time OPST construction algorithm runs in $\mathcal{O}(n)$ time on these datasets despite the $\mathcal{O}(n\sigma \log \sigma)$ bound; that our frequent pattern mining algorithms are up to orders of magnitude faster than the state of the art and natural Apriori-like baselines; and that OP pattern-based clustering is effective.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19511v1</guid>
      <category>cs.DS</category>
      <category>cs.DB</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ling Li, Wiktor Zuba, Grigorios Loukides, Solon P. Pissis, Maria Matsangidou</dc:creator>
    </item>
    <item>
      <title>A rounding and clustering-based exact algorithm for the p-center problem</title>
      <link>https://arxiv.org/abs/2411.19724</link>
      <description>arXiv:2411.19724v1 Announce Type: new 
Abstract: The p-center problem consists in selecting p facilities from a set of possible sites and allocating a set of clients to them in such a way that the maximum distance between a client and the facility to which it is allocated is minimized. This paper proposes a new scalable exact solution algorithm based on client clustering and an iterative distance rounding procedure. The client clustering enables to initialize and update a subset of clients for which the p-center problem is iteratively solved. The rounding drastically reduces the number of distinct distances considered at each iteration. Our algorithm is tested on 396 benchmark instances with up to 1.9 million clients and facilities. We outperform the two state-of-the-art exact methods considered when p is not very small (i.e., p &gt; 5).</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19724v1</guid>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zacharie Ales, Cristian Duran-Matelunaa, Sourour Elloumi</dc:creator>
    </item>
    <item>
      <title>Extraction Theorems With Small Extraction Numbers</title>
      <link>https://arxiv.org/abs/2411.18655</link>
      <description>arXiv:2411.18655v1 Announce Type: cross 
Abstract: In this work, we develop Extraction Theorems for classes of geometric objects with small extraction numbers. These classes include intervals, axis-parallel segments, axis-parallel rays, and octants. We investigate these classes of objects and prove small bounds on the extraction numbers. The tightness of these bounds is demonstrated by examples with matching lower bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.18655v1</guid>
      <category>cs.CG</category>
      <category>cs.DS</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arjun Agarwal, Sayan Bandyapadhyay</dc:creator>
    </item>
    <item>
      <title>Strongly-Linearizable Bags</title>
      <link>https://arxiv.org/abs/2411.19365</link>
      <description>arXiv:2411.19365v1 Announce Type: cross 
Abstract: Strongly-linearizable objects are valuable building blocks for the design of concurrent data structures. Yet, many objects that have linearizable implementations from some set of objects do not have strongly-linearizable implementations from that set of objects. We focus on one such object with consensus number 2: the bag, a multiset from which processes can take arbitrary elements.
  We present the first lock-free, strongly-linearizable implementation of a bag from interfering objects (specifically, registers, test&amp;set objects, and readable fetch&amp;increment objects). We show that a previously proposed implementation is, in fact, not strongly-linearizable.
  Since a bag can be arbitrarily large, the amount of space that it requires must be unbounded. A more practical object is a $b$-bounded bag, which is a bag whose maximum capacity is $b$ elements. However, a 1-bounded bag has no lock-free, strongly-linearizable implementation from interfering objects. If we restrict the 1-bounded bag so that only one process can insert into it, we are able to obtain a wait-free, linearizable implementation and a lock-free, strongly-linearizable implementation from a bounded number of readable, resettable test&amp;set objects and registers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19365v1</guid>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Faith Ellen, Gal Sela</dc:creator>
    </item>
    <item>
      <title>A Simple Sparse Matrix Vector Multiplication Approach to Padded Convolution</title>
      <link>https://arxiv.org/abs/2411.19419</link>
      <description>arXiv:2411.19419v1 Announce Type: cross 
Abstract: We introduce an algorithm for efficiently representing convolution with zero-padding and stride as a sparse transformation matrix, applied to a vectorized input through sparse matrix-vector multiplication (SpMV). We provide a theoretical contribution with an explicit expression for the number of non-zero multiplications in convolutions with stride and padding, offering insight into the potential for leveraging sparsity in convolution operations. A proof-of-concept implementation is presented in Python, demonstrating the performance of our method on both CPU and GPU architectures. This work contributes to the broader exploration of sparse matrix techniques in convolutional algorithms, with a particular focus on leveraging matrix multiplications for parallelization. Our findings lay the groundwork for future advancements in exploiting sparsity to improve the efficiency of convolution operations in fields such as machine learning and signal processing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19419v1</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zan Chaudhry</dc:creator>
    </item>
    <item>
      <title>Tractable Agreement Protocols</title>
      <link>https://arxiv.org/abs/2411.19791</link>
      <description>arXiv:2411.19791v1 Announce Type: cross 
Abstract: We present an efficient reduction that converts any machine learning algorithm into an interactive protocol, enabling collaboration with another party (e.g., a human) to achieve consensus on predictions and improve accuracy. This approach imposes calibration conditions on each party, which are computationally and statistically tractable relaxations of Bayesian rationality. These conditions are sensible even in prior-free settings, representing a significant generalization of Aumann's classic "agreement theorem."
  In our protocol, the model first provides a prediction. The human then responds by either agreeing or offering feedback. The model updates its state and revises its prediction, while the human may adjust their beliefs. This iterative process continues until the two parties reach agreement. Initially, we study a setting that extends Aumann's Agreement Theorem, where parties aim to agree on a one-dimensional expectation by iteratively sharing their current estimates. Here, we recover the convergence theorem of Aaronson'05 under weaker assumptions. We then address the case where parties hold beliefs over distributions with d outcomes, exploring two feedback mechanisms. The first involves vector-valued estimates of predictions, while the second adopts a decision-theoretic approach: the human, needing to take an action from a finite set based on utility, communicates their utility-maximizing action at each round. In this setup, the number of rounds until agreement remains independent of d. Finally, we generalize to scenarios with more than two parties, where computational complexity scales linearly with the number of participants. Our protocols rely on simple, efficient conditions and produce predictions that surpass the accuracy of any individual party's alone.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19791v1</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Natalie Collina, Surbhi Goel, Varun Gupta, Aaron Roth</dc:creator>
    </item>
    <item>
      <title>Minimization I.I.D. Prophet Inequality via Extreme Value Theory: A Unified Approach</title>
      <link>https://arxiv.org/abs/2411.19851</link>
      <description>arXiv:2411.19851v1 Announce Type: cross 
Abstract: The I.I.D. Prophet Inequality is a fundamental problem where, given $n$ independent random variables $X_1,\dots,X_n$ drawn from a known distribution $\mathcal{D}$, one has to decide at every step $i$ whether to stop and accept $X_i$ or discard it forever and continue. The goal is to maximize or minimize the selected value and compete against the all-knowing prophet. For maximization, a tight constant-competitive guarantee of $\approx 0.745$ is well-known (Correa et al, 2019), whereas minimization is qualitatively different: the optimal constant is distribution-dependent and can be arbitrarily large (Livanos and Mehta, 2024).
  In this paper, we provide a novel framework via the lens of Extreme Value Theory to analyze optimal threshold algorithms. We show that the competitive ratio for the minimization setting has a closed form described by a function $\Lambda$, which depends only on the extreme value index $\gamma$; in particular, it corresponds to $\Lambda(\gamma)$ for $\gamma \leq 0$. Despite the contrast of maximization and minimization, our framework turns out to be universal and we recover the results of (Kennedy and Kertz, 1991) for maximization as well. Surprisingly, the optimal competitive ratio for maximization is given by the same function $\Lambda(\gamma)$, but for $\gamma \geq 0$. Along the way, we obtain several results on the algorithm and the prophet's objectives from the perspective of extreme value theory, which might be of independent interest.
  We next study single-threshold algorithms for minimization. Using extreme value theory, we generalize the results of (Livanos and Mehta, 2024) which hold only for special classes of distributions, and obtain poly-logarithmic in $n$ guarantees. Finally, we consider the $k$-multi-unit prophet inequality for minimization and show that there exist constant-competitive single-threshold algorithms when $k \geq \log{n}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19851v1</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vasilis Livanos, Ruta Mehta</dc:creator>
    </item>
    <item>
      <title>Statistical inference of a ranked community in a directed graph</title>
      <link>https://arxiv.org/abs/2411.19885</link>
      <description>arXiv:2411.19885v1 Announce Type: cross 
Abstract: We study the problem of detecting or recovering a planted ranked subgraph from a directed graph, an analog for directed graphs of the well-studied planted dense subgraph model. We suppose that, among a set of $n$ items, there is a subset $S$ of $k$ items having a latent ranking in the form of a permutation $\pi$ of $S$, and that we observe a fraction $p$ of pairwise orderings between elements of $\{1, \dots, n\}$ which agree with $\pi$ with probability $\frac{1}{2} + q$ between elements of $S$ and otherwise are uniformly random. Unlike in the planted dense subgraph and planted clique problems where the community $S$ is distinguished by its unusual density of edges, here the community is only distinguished by the unusual consistency of its pairwise orderings. We establish computational and statistical thresholds for both detecting and recovering such a ranked community. In the log-density setting where $k$, $p$, and $q$ all scale as powers of $n$, we establish the exact thresholds in the associated exponents at which detection and recovery become statistically and computationally feasible. These regimes include a rich variety of behaviors, exhibiting both statistical-computational and detection-recovery gaps. We also give finer-grained results for two extreme cases: (1) $p = 1$, $k = n$, and $q$ small, where a full tournament is observed that is weakly correlated with a global ranking, and (2) $p = 1$, $q = \frac{1}{2}$, and $k$ small, where a small "ordered clique" (totally ordered directed subgraph) is planted in a random tournament.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19885v1</guid>
      <category>math.ST</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dmitriy Kunisky, Daniel A. Spielman, Alexander S. Wein, Xifan Yu</dc:creator>
    </item>
    <item>
      <title>Classical and Quantum Algorithms for the Deterministic L-system Inductive Inference Problem</title>
      <link>https://arxiv.org/abs/2411.19906</link>
      <description>arXiv:2411.19906v1 Announce Type: cross 
Abstract: L-systems can be made to model and create simulations of many biological processes, such as plant development. Finding an L-system for a given process is typically solved by hand, by experts, in a hugely time-consuming process. It would be significant if this could be done automatically from data, such as from sequences of images. In this paper, we are interested in inferring a particular type of L-system, deterministic context-free L-system (D0L-system) from a sequence of strings. We introduce the characteristic graph of a sequence of strings, which we then utilize to translate our problem (inferring D0L-system) in polynomial time into the maximum independent set problem (MIS) and the SAT problem. After that, we offer a classical exact algorithm and an approximate quantum algorithm for the problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19906v1</guid>
      <category>quant-ph</category>
      <category>cs.CL</category>
      <category>cs.DS</category>
      <category>cs.FL</category>
      <category>cs.LG</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ali Lotfi, Ian McQuillan, Steven Rayan</dc:creator>
    </item>
    <item>
      <title>The Leafed Induced Subtree in chordal and bounded treewidth graphs</title>
      <link>https://arxiv.org/abs/2301.12783</link>
      <description>arXiv:2301.12783v3 Announce Type: replace 
Abstract: In the Fully Leafed Induced Subtrees, one is given a graph $G$ and two integers $a$ and $b$ and the question is to find an induced subtree of $G$ with $a$ vertices and at least $b$ leaves. This problem is known to be NP-complete even when the input graph is $4$-regular. Polynomial algorithms are known when the input graph is restricted to be a tree or series-parallel. In this paper we generalize these results by providing an FPT algorithm parameterized by treewidth. We also provide a polynomial algorithm when the input graph is restricted to be a chordal graph.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.12783v3</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Julien Baste</dc:creator>
    </item>
    <item>
      <title>Range (R\'enyi) Entropy Queries and Partitioning</title>
      <link>https://arxiv.org/abs/2312.15959</link>
      <description>arXiv:2312.15959v2 Announce Type: replace 
Abstract: Data partitioning that maximizes/minimizes the Shannon entropy, or more generally the R\'enyi entropy is a crucial subroutine in data compression, columnar storage, and cardinality estimation algorithms. These partition algorithms can be accelerated if we have a data structure to compute the entropy in different subsets of data when the algorithm needs to decide what block to construct. Such a data structure will also be useful for data analysts exploring different subsets of data to identify areas of interest. While it is generally known how to compute the Shannon or the R\'enyi entropy of a discrete distribution in the offline or streaming setting efficiently, we focus on the query setting where we aim to efficiently derive the entropy among a subset of data that satisfy some linear predicates. We solve this problem in a typical setting when we deal with real data, where data items are geometric points and each requested area is a query (hyper)rectangle. More specifically, we consider a set $P$ of $n$ weighted and colored points in $\mathbb{R}^d$. For the range S-entropy (resp. R-entropy) query problem, the goal is to construct a low space data structure, such that given a query (hyper)rectangle $R$, it computes the Shannon (resp. R\'enyi) entropy based on the colors and the weights of the points in $P\cap R$, in sublinear time. We show conditional lower bounds proving that we cannot hope for data structures with near-linear space and near-constant query time for both the range S-entropy and R-entropy query problems. Then, we propose exact data structures for $d=1$ and $d&gt;1$ with $o(n^{2d})$ space and $o(n)$ query time for both problems. Finally, we propose near linear space data structures for returning either an additive or a multiplicative approximation of the Shannon (resp. R\'enyi) entropy in $P\cap R$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.15959v2</guid>
      <category>cs.DS</category>
      <category>cs.DB</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aryan Esmailpour, Sanjay Krishnan, Stavros Sintos</dc:creator>
    </item>
    <item>
      <title>O(1) Insertion for Random Walk d-ary Cuckoo Hashing up to the Load Threshold</title>
      <link>https://arxiv.org/abs/2401.14394</link>
      <description>arXiv:2401.14394v4 Announce Type: replace 
Abstract: The random walk $d$-ary cuckoo hashing algorithm was defined by Fotakis, Pagh, Sanders, and Spirakis to generalize and improve upon the standard cuckoo hashing algorithm of Pagh and Rodler. Random walk $d$-ary cuckoo hashing has low space overhead, guaranteed fast access, and fast in practice insertion time. In this paper, we give a theoretical insertion time bound for this algorithm. More precisely, for every $d\ge 3$ hashes, let $c_d^*$ be the sharp threshold for the load factor at which a valid assignment of $cm$ objects to a hash table of size $m$ likely exists. We show that for any $d\ge 4$ hashes and load factor $c&lt;c_d^*$, the expectation of the random walk insertion time is $O(1)$, that is, a constant depending only on $d$ and $c$ but not $m$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.14394v4</guid>
      <category>cs.DS</category>
      <category>math.CO</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tolson Bell, Alan Frieze</dc:creator>
    </item>
    <item>
      <title>Combining Crown Structures for Vulnerability Measures</title>
      <link>https://arxiv.org/abs/2405.02378</link>
      <description>arXiv:2405.02378v2 Announce Type: replace 
Abstract: Over the past decades, various metrics have emerged in graph theory to grasp the complex nature of network vulnerability. In this paper, we study two specific measures: (weighted) vertex integrity (wVI) and (weighted) component order connectivity (wCOC). These measures not only evaluate the number of vertices required to decompose a graph into fragments, but also take into account the size of the largest remaining component. The main focus of our paper is on kernelization algorithms tailored to both measures. We capitalize on the structural attributes inherent in different crown decompositions, strategically combining them to introduce novel kernelization algorithms that advance the current state of the field. In particular, we extend the scope of the balanced crown decomposition provided by Casel et al.~[7] and expand the applicability of crown decomposition techniques.
  In summary, we improve the vertex kernel of VI from $p^3$ to $p^2$, and of wVI from $p^3$ to $3(p^2 + p^{1.5} p_{\ell})$, where $p_{\ell} &lt; p$ represents the weight of the heaviest component after removing a solution. For wCOC we improve the vertex kernel from $\mathcal{O}(k^2W + kW^2)$ to $3\mu(k + \sqrt{\mu}W)$, where $\mu = \max(k,W)$. We also give a combinatorial algorithm that provides a $2kW$ vertex kernel in FPT-runtime when parameterized by $r$, where $r \leq k$ is the size of a maximum $(W+1)$-packing. We further show that the algorithm computing the $2kW$ vertex kernel for COC can be transformed into a polynomial algorithm for two special cases, namely when $W=1$, which corresponds to the well-known vertex cover problem, and for claw-free graphs. In particular, we show a new way to obtain a $2k$ vertex kernel (or to obtain a 2-approximation) for the vertex cover problem by only using crown structures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.02378v2</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Katrin Casel, Tobias Friedrich, Aikaterini Niklanovits, Kirill Simonov, Ziena Zeif</dc:creator>
    </item>
    <item>
      <title>Approximation Algorithms for Correlated Knapsack Orienteering</title>
      <link>https://arxiv.org/abs/2408.16566</link>
      <description>arXiv:2408.16566v2 Announce Type: replace 
Abstract: We consider the {\em correlated knapsack orienteering} (CSKO) problem: we are given a travel budget $B$, processing-time budget $W$, finite metric space $(V,d)$ with root $\rho\in V$, where each vertex is associated with a job with possibly correlated random size and random reward that become known only when the job completes. Random variables are independent across different vertices. The goal is to compute a $\rho$-rooted path of length at most $B$, in a possibly adaptive fashion, that maximizes the reward collected from jobs that are processed by time $W$. To our knowledge, CSKO has not been considered before, though prior work has considered the uncorrelated problem, {\em stochastic knapsack orienteering}, and {\em correlated orienteering}, which features only one budget constraint on the {\em sum} of travel-time and processing-times.
  We show that the {\em adaptivity gap of CSKO is not a constant, and is at least $\Omega\bigl(\max\sqrt{\log{B}},\sqrt{\log\log{W}}\}\bigr)$}. Complementing this, we devise {\em non-adaptive} algorithms that obtain: (a) $O(\log\log W)$-approximation in quasi-polytime; and (b) $O(\log W)$-approximation in polytime. We obtain similar guarantees for CSKO with cancellations, wherein a job can be cancelled before its completion time, foregoing its reward. We also consider the special case of CSKO, wherein job sizes are weighted Bernoulli distributions, and more generally where the distributions are supported on at most two points (2-CSKO). Although weighted Bernoulli distributions suffice to yield an $\Omega(\sqrt{\log\log B})$ adaptivity-gap lower bound for (uncorrelated) {\em stochastic orienteering}, we show that they are easy instances for CSKO. We develop non-adaptive algorithms that achieve $O(1)$-approximation in polytime for weighted Bernoulli distributions, and in $(n+\log B)^{O(\log W)}$-time for the more general case of 2-CSKO.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.16566v2</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>David Aleman Espinosa, Chaitanya Swamy</dc:creator>
    </item>
    <item>
      <title>Optimized 2-Approximation of Treewidth</title>
      <link>https://arxiv.org/abs/2411.16918</link>
      <description>arXiv:2411.16918v2 Announce Type: replace 
Abstract: This paper presents a linear FPT algorithm to find a tree decomposition with a 2-approximation of the treewidth with a significantly smaller exponential dependence on the treewidth in the running time than previously known.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.16918v2</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mahdi Belbasi, Martin F\"urer, Medha Kumar</dc:creator>
    </item>
    <item>
      <title>A smoothed-Bayesian approach to frequency recovery from sketched data</title>
      <link>https://arxiv.org/abs/2309.15408</link>
      <description>arXiv:2309.15408v3 Announce Type: replace-cross 
Abstract: We provide a novel statistical perspective on a classical problem at the intersection of computer science and information theory: recovering the empirical frequency of a symbol in a large discrete dataset using only a compressed representation, or sketch, obtained via random hashing. Departing from traditional algorithmic approaches, recent works have proposed Bayesian nonparametric (BNP) methods that can provide more informative frequency estimates by leveraging modeling assumptions about the distribution of the sketched data. In this paper, we propose a smoothed-Bayesian method, inspired by existing BNP approaches but designed in a frequentist framework to overcome the computational limitations of the BNP approaches when dealing with large-scale data from realistic distributions, including those with power-law tail behaviors. For sketches obtained with a single hash function, our approach is supported by rigorous frequentist properties, including unbiasedness and optimality under a squared error loss function within an intuitive class of linear estimators. For sketches with multiple hash functions, we introduce an approach based on multi-view learning to construct computationally efficient frequency estimators. We validate our method on synthetic and real data, comparing its performance to that of existing alternatives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.15408v3</guid>
      <category>stat.ME</category>
      <category>cs.DS</category>
      <category>cs.IR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mario Beraha, Stefano Favaro, Matteo Sesia</dc:creator>
    </item>
    <item>
      <title>Convergence Analysis for Deep Sparse Coding via Convolutional Neural Networks</title>
      <link>https://arxiv.org/abs/2408.05540</link>
      <description>arXiv:2408.05540v2 Announce Type: replace-cross 
Abstract: In this work, we explore intersections between sparse coding and deep learning to enhance our understanding of feature extraction capabilities in advanced neural network architectures. We begin by introducing a novel class of Deep Sparse Coding (DSC) models and establish thorough theoretical analysis of their uniqueness and stability properties. By applying iterative algorithms to these DSC models, we derive convergence rates for convolutional neural networks (CNNs) in their ability to extract sparse features. This provides a strong theoretical foundation for the use of CNNs in sparse feature learning tasks. We additionally extend the convergence analysis to more general neural network architectures, including those with diverse activation functions, as well as self-attention and transformer-based models. This broadens the applicability of our findings to a wide range of deep learning methods for deep sparse feature extraction. Inspired by the strong connection between sparse coding and CNNs, we also explore training strategies to encourage neural networks to learn more sparse features. Through numerical experiments, we demonstrate the effectiveness of these approaches, providing valuable insights for the design of efficient and interpretable deep learning models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05540v2</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>cs.IT</category>
      <category>cs.NE</category>
      <category>math.IT</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jianfei Li, Han Feng, Ding-Xuan Zhou</dc:creator>
    </item>
  </channel>
</rss>
