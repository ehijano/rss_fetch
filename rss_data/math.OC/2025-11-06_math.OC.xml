<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 07 Nov 2025 02:35:02 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Towards a geometric characterization of unbounded integer cubic optimization problems via thin rays</title>
      <link>https://arxiv.org/abs/2511.02983</link>
      <description>arXiv:2511.02983v1 Announce Type: new 
Abstract: We study geometric characterizations of unbounded integer polynomial optimization problems. While unboundedness along a ray fully characterizes unbounded integer linear and quadratic optimization problems, we show that this is not the case for cubic polynomials. To overcome this, we introduce thin rays, which are rays with an arbitrarily small neighborhood, and prove that they characterize unboundedness for integer cubic optimization problems in dimension up to three, and we conjecture that the same holds in all dimensions. Our techniques also provide a complete characterization of unbounded integer quadratic optimization problems in arbitrary dimension, without assuming rational coefficients. These results underscore the significance of thin rays and offer new tools for analyzing integer polynomial optimization problems beyond the quadratic case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.02983v1</guid>
      <category>math.OC</category>
      <category>cs.DM</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alberto Del Pia</dc:creator>
    </item>
    <item>
      <title>Projection-width: a unifying structural parameter for separable discrete optimization</title>
      <link>https://arxiv.org/abs/2511.02990</link>
      <description>arXiv:2511.02990v1 Announce Type: new 
Abstract: We introduce the notion of projection-width for systems of separable constraints, defined via branch decompositions of variables and constraints. We show that several fundamental discrete optimization and counting problems can be solved in polynomial time when the projection-width is polynomially bounded. These include optimization, counting, top-k, and weighted constraint violation. Our results identify a broad class of tractable nonlinear discrete optimization and counting problems. Even when restricted to the linear setting, they subsume and substantially extend some of the strongest known tractability results across multiple research areas: integer linear optimization, binary polynomial optimization, and Boolean satisfiability. Although these results originated independently within different communities and for seemingly distinct problem classes, our framework unifies and significantly generalizes them under a single structural perspective.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.02990v1</guid>
      <category>math.OC</category>
      <category>cs.DM</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alberto Del Pia</dc:creator>
    </item>
    <item>
      <title>Robust optimal consumption, investment and reinsurance for recursive preferences</title>
      <link>https://arxiv.org/abs/2511.03031</link>
      <description>arXiv:2511.03031v1 Announce Type: new 
Abstract: This paper investigates a robust optimal consumption, investment, and reinsurance problem for an insurer with Epstein-Zin recursive preferences operating under model uncertainty. The insurer's surplus follows the diffusion approximation of the Cram\'er-Lundberg model, and the insurer can purchase proportional reinsurance. Model ambiguity is characterised by a class of equivalent probability measures, and the insurer, being ambiguity-averse, aims to maximise utility under the worst-case scenario. By solving the associated coupled forward-backward stochastic differential equation (FBSDE), we derive closed-form solutions for the optimal strategies and the value function. Our analysis reveals how ambiguity aversion, risk aversion, and the elasticity of intertemporal substitution (EIS) influence the optimal policies. Numerical experiments illustrate the effects of key parameters, showing that optimal consumption decreases with higher risk aversion and EIS, while investment and reinsurance strategies are co-dependent on both financial and insurance market parameters, even without correlation. This study provides a comprehensive framework for insurers to manage capital allocation and risk transfer under deep uncertainty.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.03031v1</guid>
      <category>math.OC</category>
      <category>q-fin.RM</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Elizabeth Dadzie, Wilfried Kuissi-Kamdem, Marcel Ndengo</dc:creator>
    </item>
    <item>
      <title>Min-Max Optimization Is Strictly Easier Than Variational Inequalities</title>
      <link>https://arxiv.org/abs/2511.03052</link>
      <description>arXiv:2511.03052v1 Announce Type: new 
Abstract: Classically, a mainstream approach for solving a convex-concave min-max problem is to instead solve the variational inequality problem arising from its first-order optimality conditions. Is it possible to solve min-max problems faster by bypassing this reduction? This paper initiates this investigation. We show that the answer is yes in the textbook setting of unconstrained quadratic objectives: the optimal convergence rate for first-order algorithms is strictly better for min-max problems than for the corresponding variational inequalities. The key reason that min-max algorithms can be faster is that they can exploit the asymmetry of the min and max variables--a property that is lost in the reduction to variational inequalities. Central to our analyses are sharp characterizations of optimal convergence rates in terms of extremal polynomials which we compute using Green's functions and conformal mappings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.03052v1</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Henry Shugart, Jason M. Altschuler</dc:creator>
    </item>
    <item>
      <title>Optimal Boundary Control of Diffusion on Graphs via Linear Programming</title>
      <link>https://arxiv.org/abs/2511.03129</link>
      <description>arXiv:2511.03129v1 Announce Type: new 
Abstract: We propose a linear programming (LP) framework for steady-state diffusion and flux optimization on geometric networks. The state variable satisfies a discrete diffusion law on a weighted, oriented graph, where conductances are scaled by edge lengths to preserve geometric fidelity. Boundary potentials act as controls that drive interior fluxes according to a linear network Laplacian. The optimization problem enforces physically meaningful sign and flux-cap constraints at all boundary edges, derived directly from a gradient bound. This yields a finite-dimensional LP whose feasible set is polyhedral, and whose boundedness and solvability follow from simple geometric or algebraic conditions on the network data.
  We prove that under the absence of negative recession directions--automatically satisfied in the presence of finite box bounds, flux caps, or sign restrictions--the LP admits a global minimizer. Several sufficient conditions guaranteeing boundedness of the feasible region are identified, covering both full-rank and rank-deficient flux maps. The analysis connects classical results such as the Minkowski--Weyl decomposition, Hoffman's bound, and the fundamental theorem of linear programming with modern network-based diffusion modeling.
  Two large-scale examples illustrate the framework: (i) A typical large stadium in a major modern city, which forms a single connected component with relatively uniform corridor widths, and a (ii) A complex street network emanating from a large, historical city center, which forms a multi-component system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.03129v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>physics.comp-ph</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Harbir Antil, Rainald L\"ohner, Felipe P\'erez</dc:creator>
    </item>
    <item>
      <title>Adaptive directional decomposition methods for nonconvex constrained optimization</title>
      <link>https://arxiv.org/abs/2511.03210</link>
      <description>arXiv:2511.03210v1 Announce Type: new 
Abstract: In this paper, we study nonconvex constrained optimization problems with both equality and inequality constraints, covering deterministic and stochastic settings. We propose a novel first-order algorithm framework that employs a decomposition strategy to balance objective reduction and constraint satisfaction, together with adaptive update of stepsizes and merit parameters. Under certain conditions, the proposed adaptive directional decomposition methods attain an iteration complexity of order \(O(\epsilon^{-2})\) for finding an \(\epsilon\)-KKT point in the deterministic setting. In the stochastic setting, we further develop stochastic variants of approaches and analyze their theoretical properties by leveraging the perturbation theory. We establish the high-probability oracle complexity to find an $\epsilon$-KKT point of order \( \tilde O(\epsilon^{-4}, \epsilon^{-6}) \) (resp. \(\tilde O(\epsilon^{-3}, \epsilon^{-5}) \)) for gradient and constraint evaluations, in the absence (resp. presence) of sample-wise smoothness. To the best of our knowledge, the obtained complexity bounds are comparable to, or improve upon, the state-of-the-art results in the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.03210v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qiankun Shi, Xiao Wang</dc:creator>
    </item>
    <item>
      <title>Technical results on the convergence of quasi-Newton methods for nonsmooth optimization</title>
      <link>https://arxiv.org/abs/2511.03296</link>
      <description>arXiv:2511.03296v1 Announce Type: new 
Abstract: It is well-known by now that the BFGS method is an effective method for minimizing nonsmooth functions. However, despite its popularity, theoretical convergence results are almost non-existent. One of the difficulties when analyzing the nonsmooth case is the fact that the secant equation forces certain eigenvalues of the quasi-Newton matrix to vanish, which is a behavior that has not yet been fully analyzed. In this article, we show what kind of behavior of the eigenvalues would be sufficient to be able to prove the convergence for piecewise differentiable functions. More precisely, we derive assumptions on the behavior from numerical experiments and then prove criticality of the limit under these assumptions. Furthermore, we show how quasi-Newton methods are able to explore the piecewise structure. While we do not prove that the observed behavior of the eigenvalues actually occurs, we believe that these results still give insight, and a certain intuition, for the convergence for nonsmooth functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.03296v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bennet Gebken</dc:creator>
    </item>
    <item>
      <title>Solutions of Two-stage Stochastic Minimax Problems</title>
      <link>https://arxiv.org/abs/2511.03339</link>
      <description>arXiv:2511.03339v1 Announce Type: new 
Abstract: This paper introduces a class of two-stage stochastic minimax problems where the first-stage objective function is nonconvex-concave while the second-stage objective function is strongly convex-concave. We establish properties of the second-stage minimax value function and solution functions, and characterize the existence and relationships among saddle points, minimax points, and KKT points. We apply the sample average approximation (SAA) to the class of two-stage stochastic minimax problems and prove the convergence of the KKT points as the sample size tends to infinity. An inexact parallel proximal gradient descent ascent algorithm is proposed to solve this class of problems with the SAA. Numerical experiments demonstrate the effectiveness of the proposed algorithm and validate the convergence properties of the SAA approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.03339v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hailin Sun, Xiaojun Chen</dc:creator>
    </item>
    <item>
      <title>Proximal gradient descent on the smoothed duality gap to solve saddle point problems</title>
      <link>https://arxiv.org/abs/2511.03442</link>
      <description>arXiv:2511.03442v1 Announce Type: new 
Abstract: In this paper, we minimize the self-centered smoothed gap, a recently introduced optimality measure, in order to solve convex-concave saddle point problems. The self-centered smoothed gap can be computed as the sum of a convex, possibly nonsmooth function and a smooth weakly convex function. Although it is not convex, we propose an algorithm that minimizes this quantity, effectively reducing convex-concave saddle point problems to a minimization problem. Its worst case complexity is comparable to the one of the restarted and averaged primal dual hybrid gradient method, and the algorithm enjoys linear convergence in favorable cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.03442v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Olivier Fercoq (S2A, LTCI)</dc:creator>
    </item>
    <item>
      <title>A Support-Set Algorithm for Optimization Problems with Nonnegative and Orthogonal Constraints</title>
      <link>https://arxiv.org/abs/2511.03443</link>
      <description>arXiv:2511.03443v1 Announce Type: new 
Abstract: In this paper, we investigate optimization problems with nonnegative and orthogonal constraints, where any feasible matrix of size $n \times p$ exhibits a sparsity pattern such that each row accommodates at most one nonzero entry. Our analysis demonstrates that, by fixing the support set, the global solution of the minimization subproblem for the proximal linearization of the objective function can be computed in closed form with at most $n$ nonzero entries. Exploiting this structural property offers a powerful avenue for dramatically enhancing computational efficiency. Guided by this insight, we propose a support-set algorithm preserving strictly the feasibility of iterates. A central ingredient is a strategically devised update scheme for support sets that adjusts the placement of nonzero entries. We establish the global convergence of the support-set algorithm to a first-order stationary point, and show that its iteration complexity required to reach an $\epsilon$-approximate first-order stationary point is $O (\epsilon^{-2})$. Numerical results are strongly in favor of our algorithm in real-world applications, including nonnegative PCA, clustering, and community detection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.03443v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lei Wang, Xin Liu, Xiaojun Chen</dc:creator>
    </item>
    <item>
      <title>A Review of Bilevel Optimization: Methods, Emerging Applications, and Recent Advancements</title>
      <link>https://arxiv.org/abs/2511.03448</link>
      <description>arXiv:2511.03448v1 Announce Type: new 
Abstract: This paper presents a comprehensive review of techniques proposed in the literature for solving bilevel optimization problems encountered in various real-life applications. Bilevel optimization is an appropriate choice for hierarchical decision-making situations, where a decision-maker needs to consider a possible response from stakeholder(s) for each of its actions to achieve his own goals. Mathematically, it leads to a nested optimization structure, in which a primary (leader's) optimization problem contains a secondary (follower's) optimization problem as a constraint. Various forms of bilevel problems, including linear, mixed-integer, single-objective, and multi-objective, are covered. For bilevel problem solving methods, various classical and evolutionary approaches are explained. Along with an overview of various areas of applications, two recent considerations of bilevel approach are introduced. The first application involves a bilevel decomposition approach for solving general optimization problems, and the second application involves Neural Architecture Search (NAS), which is a prime example of a bilevel optimization problem in the area of machine learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.03448v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dhaval Pujara, Ankur Sinha</dc:creator>
    </item>
    <item>
      <title>Explicit Ensemble Learning Surrogate for Joint Chance-Constrained Optimal Power Flow</title>
      <link>https://arxiv.org/abs/2511.03515</link>
      <description>arXiv:2511.03515v1 Announce Type: new 
Abstract: The increasing penetration of renewable generation introduces uncertainty into power systems, challenging traditional deterministic optimization methods. Chance-constrained optimization offers an approach to balancing cost and risk; however, incorporating joint chance constraints introduces computational challenges. This paper presents an ensemble support vector machine surrogate for joint chance constraint optimal power flow, where multiple linear classifiers are trained on simulated optimal power flow data and embedded as tractable hyperplane constraints via Big--M reformulations. The surrogate yields a polyhedral approximation of probabilistic line flow limits that preserves interpretability and scalability. Numerical experiments on the IEEE 118-bus system show that the proposed method achieves near-optimal costs with a negligible average error of $0.03\%$. These results demonstrate the promise of ensemble surrogates as efficient and transparent tools for risk-aware optimization of power systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.03515v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amir Bahador Javadi, Amin Kargarian</dc:creator>
    </item>
    <item>
      <title>HJB equations driven by the Dirichlet-Ferguson Laplacian in Wasserstein-Sobolev spaces</title>
      <link>https://arxiv.org/abs/2511.03522</link>
      <description>arXiv:2511.03522v1 Announce Type: new 
Abstract: We study linear and nonlinear PDEs defined on the space of $\mathcal{P}(\mathbb{T}^d)$ over the flat torus $\mathbb{T}^d$, equipped with the Dirichlet-Ferguson measure $\mathcal{D}$. We first develop an analytic framework based on the Wasserstein-Sobolev space $H^{1,2}(\mathcal{P}(\mathbb{T}^d), W_2, \mathcal{D})$ associated with the Dirichlet form induced by the infinite-dimensional Laplacian acting on functions of measures. Within this setting, we establish existence and uniqueness results for transport-diffusion and Hamilton-Jacobi equations in the Wasserstein space. Our analysis connects the PDE approach with a corresponding interacting particles system providing a probabilistic (Kolmogorov-type) representation of strong solutions. Finally, we extend the theory to semilinear equations and mean-field optimal control problems, together with consistent finite-dimensional approximations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.03522v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <category>math.PR</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fran\c{c}ois Delarue, Mattia Martini, Giacomo Enrico Sodini</dc:creator>
    </item>
    <item>
      <title>Improving Directions in Mixed Integer Bilevel Linear Optimization</title>
      <link>https://arxiv.org/abs/2511.03566</link>
      <description>arXiv:2511.03566v2 Announce Type: new 
Abstract: We consider the central role of improving directions in solution methods for mixed integer bilevel linear optimization problems (MIBLPs). Current state-of-the-art methods for solving MIBLPs employ the branch-and-cut framework originally developed for solving mixed integer linear optimization problems. This approach relies on oracles for two kinds of subproblems: those for checking whether a candidate pair of leader's and follower's decisions is bilevel feasible, and those required for generating valid inequalities. Typically, these two types of oracles are managed separately, but in this work, we explore their close connection and propose a solution framework based on solving a single type of subproblem: determining whether there exists a so-called improving feasible direction for the follower's problem. Solution of this subproblem yields information that can be used both to check feasibility and to generate strong valid inequalities. Building on prior works, we expose the foundational role of improving directions in enforcing the follower's optimality condition and extend a previously known hierarchy of optimality-based relaxations to the mixed-integer setting, showing that the associated relaxed feasible regions coincide exactly with the closure associated with intersection cuts derived from improving directions. Numerical results with an implementation using a modified version of the open source solver MibS show that this approach can yield practical improvements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.03566v2</guid>
      <category>math.OC</category>
      <category>cs.MS</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Federico Battista, Ted K. Ralphs</dc:creator>
    </item>
    <item>
      <title>Exploiting Over-Approximation Errors as Preview Information for Nonlinear Control</title>
      <link>https://arxiv.org/abs/2511.03577</link>
      <description>arXiv:2511.03577v1 Announce Type: new 
Abstract: We study the control of nonlinear constrained systems via over-approximations. Our key observation is that the over-approximation error, rather than being an unknown disturbance, can be exploited as input-dependent preview information. This leads to the notion of informed policies, which depend on both the state and the error. We formulate the concretization problem -- recovering a valid input for the true system from a preview-based policy -- as a fixed-point equation. Existence of solutions follows from the Brouwer fixed-point theorem, while efficient computation is enabled through closed-form, linear, or convex programs for input-affine systems, and through an iterative method based on the Banach fixed-point theorem for nonlinear systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.03577v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.DS</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Antoine Aspeel, Antoine Girard, Thiago Alves Lima</dc:creator>
    </item>
    <item>
      <title>Geometrically robust least squares through manifold optimization</title>
      <link>https://arxiv.org/abs/2511.03644</link>
      <description>arXiv:2511.03644v1 Announce Type: new 
Abstract: This paper presents a methodology for solving a geometrically robust least squares problem, which arises in various applications where the model is subject to geometric constraints. The problem is formulated as a minimax optimization problem on a product manifold, where one variable is constrained to a ball describing uncertainty. To handle the constraint, an exact penalty method is applied. A first-order gradient descent ascent algorithm is proposed to solve the problem, and its convergence properties are illustrated by an example. The proposed method offers a robust approach to solving a wide range of problems arising in signal processing and data-driven control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.03644v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jeremy Coulson, Alberto Padoan, Cyrus Mostajeran</dc:creator>
    </item>
    <item>
      <title>High-order Accumulative Regularization for Gradient Minimization in Convex Programming</title>
      <link>https://arxiv.org/abs/2511.03723</link>
      <description>arXiv:2511.03723v1 Announce Type: new 
Abstract: This paper develops a unified framework of high-order accumulative regularization (AR) framework for convex and uniformly convex gradient norm minimization. Existing high-order methods often exhibit a gap: the function value residual decreases fast, while the gradient norm converges much slower. To close this gap, we introduce AR that systematically transforms fast function value residual convergence rate into fast (matching) gradient norm convergence rate.
  Specifically, for composite convex problems, for computing an approximate solution such that the norm of its (sub)gradient does not exceed $\varepsilon,$ the proposed AR methods match the best corresponding convergence rate for the function value residual. We further extend the framework to uniformly convex settings, establishing linear, superlinear and sublinear convergence of the gradient norm under different lower curvature conditions. Moreover, we design parameter-free algorithms that require no input of problem parameters, e.g., Lipschitz constant of the $p$-th order gradient, the initial optimality gap and the uniform convexity parameter, and allows inexact solution for each high-order step. To our best knowledge, no parameter-free methods can attain such a fast gradient norm convergence rate which matches that of the function value residual in the convex case, and no such parameter-free methods for uniformly convex problems exist. These results substantially generalize existing parameter-free and inexact high-order methods and recover first-order algorithms as special cases, providing a unified approach for fast gradient minimization across a broad range of smoothness and curvature regimes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.03723v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yao Ji, Guanghui Lan</dc:creator>
    </item>
    <item>
      <title>Power Constrained Nonstationary Bandits with Habituation and Recovery Dynamics</title>
      <link>https://arxiv.org/abs/2511.02944</link>
      <description>arXiv:2511.02944v1 Announce Type: cross 
Abstract: A common challenge for decision makers is selecting actions whose rewards are unknown and evolve over time based on prior policies. For instance, repeated use may reduce an action's effectiveness (habituation), while inactivity may restore it (recovery). These nonstationarities are captured by the Reducing or Gaining Unknown Efficacy (ROGUE) bandit framework, which models real-world settings such as behavioral health interventions. While existing algorithms can compute sublinear regret policies to optimize these settings, they may not provide sufficient exploration due to overemphasis on exploitation, limiting the ability to estimate population-level effects. This is a challenge of particular interest in micro-randomized trials (MRTs) that aid researchers in developing just-in-time adaptive interventions that have population-level effects while still providing personalized recommendations to individuals. In this paper, we first develop ROGUE-TS, a Thompson Sampling algorithm tailored to the ROGUE framework, and provide theoretical guarantees of sublinear regret. We then introduce a probability clipping procedure to balance personalization and population-level learning, with quantified trade-off that balances regret and minimum exploration probability. Validation on two MRT datasets concerning physical activity promotion and bipolar disorder treatment shows that our methods both achieve lower regret than existing approaches and maintain high statistical power through the clipping procedure without significantly increasing regret. This enables reliable detection of treatment effects while accounting for individual behavioral dynamics. For researchers designing MRTs, our framework offers practical guidance on balancing personalization with statistical validity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.02944v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fengxu Li, Stephanie M. Carpenter, Matthew P. Buman, Yonatan Mintz</dc:creator>
    </item>
    <item>
      <title>Robust reduced-order model predictive control using peak-to-peak analysis of filtered signals</title>
      <link>https://arxiv.org/abs/2511.03002</link>
      <description>arXiv:2511.03002v1 Announce Type: cross 
Abstract: We address the design of a model predictive control (MPC) scheme for large-scale linear systems using reduced-order models (ROMs). Our approach uses a ROM, leverages tools from robust control, and integrates them into an MPC framework to achieve computational tractability with robust constraint satisfaction. Our key contribution is a method to obtain guaranteed bounds on the predicted outputs of the full-order system by predicting a (scalar) error-bounding system alongside the ROM. This bound is then used to formulate a robust ROM-based MPC that guarantees constraint satisfaction and robust performance. Our method is developed step-by-step by (i) analysing the error, (ii) bounding the peak-to-peak gain, an (iii) using filtered signals. We demonstrate our method on a 100-dimensional mass-spring-damper system, achieving over four orders of magnitude reduction in conservatism relative to existing approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.03002v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Johannes K\"ohler, Carlo Scholz, Melanie Zeilinger</dc:creator>
    </item>
    <item>
      <title>Beyond Maximum Likelihood: Variational Inequality Estimation for Generalized Linear Models</title>
      <link>https://arxiv.org/abs/2511.03087</link>
      <description>arXiv:2511.03087v1 Announce Type: cross 
Abstract: Generalized linear models (GLMs) are fundamental tools for statistical modeling, with maximum likelihood estimation (MLE) serving as the classical method for parameter inference. While MLE performs well in canonical GLMs, it can become computationally inefficient near the true parameter value. In more general settings with non-canonical or fully general link functions, the resulting optimization landscape is often non-convex, non-smooth, and numerically unstable. To address these challenges, we investigate an alternative estimator based on solving the variational inequality (VI) formulation of the GLM likelihood equations, originally proposed by Juditsky and Nemirovski as an alternative for solving nonlinear least-squares problems. Unlike their focus on algorithmic convergence in monotone settings, we analyze the VI approach from a statistical perspective, comparing it systematically with the MLE. We also extend the theory of VI estimators to a broader class of link functions, including non-monotone cases satisfying a strong Minty condition, and show that it admits weaker smoothness requirements than MLE, enabling faster, more stable, and less locally trapped optimization. Theoretically, we establish both non-asymptotic estimation error bounds and asymptotic normality for the VI estimator, and further provide convergence guarantees for fixed-point and stochastic approximation algorithms. Numerical experiments show that the VI framework preserves the statistical efficiency of MLE while substantially extending its applicability to more challenging GLM settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.03087v1</guid>
      <category>stat.ME</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Linglingzhi Zhu, Jonghyeok Lee, Yao Xie</dc:creator>
    </item>
    <item>
      <title>A Theory of Saving under Risk Preference Dynamics</title>
      <link>https://arxiv.org/abs/2511.03142</link>
      <description>arXiv:2511.03142v1 Announce Type: cross 
Abstract: Empirical evidence shows that wealthy households have substantially higher saving rates and markedly lower marginal propensity to consume (MPC) than other groups. Existing theory can account for this pattern only under restrictive assumptions on returns, discounting, and preferences. This paper develops a general theory of optimal savings with preference shocks, allowing risk aversion to vary across states and over time. We show that incorporating such heterogeneity in risk attitudes fundamentally alters the asymptotic dynamics of consumption and saving. In particular, we provide an analytical characterization of the asymptotic MPCs and show that zero asymptotic MPCs, corresponding to a 100\% asymptotic saving rate, arise under markedly weaker conditions than in existing theory. Strikingly, such outcomes occur whenever there is a positive probability that agents become less risk averse in the future. As a result, the vanishing MPC emerges as a generic feature rather than a knife-edge result of the optimal savings model, offering a more theoretically robust and empirically consistent account of the saving behavior of wealthy households.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.03142v1</guid>
      <category>econ.TH</category>
      <category>math.OC</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qingyin Ma, Xinxi Song, Alexis Akira Toda</dc:creator>
    </item>
    <item>
      <title>Computing the nearest $\Omega$-admissible descriptor dissipative Hamiltonian system</title>
      <link>https://arxiv.org/abs/2511.03265</link>
      <description>arXiv:2511.03265v1 Announce Type: cross 
Abstract: For a given set $\Omega \subseteq \mathbb{C}$, a matrix pair $(E,A)$ is called $\Omega$-admissible if it is regular, impulse-free and its eigenvalues lie inside the region $\Omega$. In this paper, we provide a dissipative Hamiltonian characterization for the matrix pairs that are $\Omega$-admissible where $\Omega$ is an LMI region. We then use these results for solving the nearest $\Omega$-admissible matrix pair problem: Given a matrix pair $(E,A)$, find the nearest $\Omega$-admissible pair $(\tilde E, \tilde A)$ to the given pair $(E,A)$. We illustrate our results on several data sets and compare with the state of the art.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.03265v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vaishali Aggarwal, Nicolas Gillis, Punit Sharma</dc:creator>
    </item>
    <item>
      <title>Evolutionary Dynamics in Continuous-time Finite-state Mean Field Games -- Part II: Stability</title>
      <link>https://arxiv.org/abs/2511.03297</link>
      <description>arXiv:2511.03297v1 Announce Type: cross 
Abstract: We study a dynamic game with a large population of players who choose actions from a finite set in continuous time. Each player has a state in a finite state space that evolves stochastically with their actions. A player's reward depends not only on their own state and action but also on the distribution of states and actions across the population, capturing effects such as congestion in traffic networks. In Part I, we introduced an evolutionary model and a new solution concept - the mixed stationary Nash Equilibrium (MSNE) - which coincides with the rest points of the mean field evolutionary model under meaningful families of revision protocols. In this second part, we investigate the evolutionary stability of MSNE. We derive conditions on both the structure of the MSNE and the game's payoff map that ensure local and global stability under evolutionary dynamics. These results characterize when MSNE can robustly emerge and persist against strategic deviations, thereby providing insight into its long-term viability in large population dynamic games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.03297v1</guid>
      <category>eess.SY</category>
      <category>cs.GT</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Leonardo Pedroso, Andrea Agazzi, W. P. M. H. Heemels, Mauro Salazar</dc:creator>
    </item>
    <item>
      <title>Calibration for minimal surfaces with free boundary and Cheeger-type problems</title>
      <link>https://arxiv.org/abs/2511.03322</link>
      <description>arXiv:2511.03322v1 Announce Type: cross 
Abstract: We study a problem of minimal surfaces with free boundary written in the form of a non convex minimization problem. Our aim is to characterize optimal solutions by finding a suitable calibration field. A natural upper bound of the infimum is given by a variant of the Cheeger problem that we solve explicitly proving the optimality thanks to the construction of a cut-locus potential. The comparison with the original problem is then discussed in detail.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.03322v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Guy Bouchitt\'e, Minh Phan</dc:creator>
    </item>
    <item>
      <title>Branch-and-Cut for Computing Approximate Equilibria of Mixed-Integer Generalized Nash Games</title>
      <link>https://arxiv.org/abs/2511.03340</link>
      <description>arXiv:2511.03340v1 Announce Type: cross 
Abstract: Generalized Nash equilibrium problems with mixed-integer variables constitute an important class of games in which each player solves a mixed-integer optimization problem, where both the objective and the feasible set is parameterized by the rivals' strategies. However, such games are known for failing to admit exact equilibria and also the assumption of all players being able to solve nonconvex problems to global optimality is questionable. This motivates the study of approximate equilibria. In this work, we consider an approximation concept that incorporates both multiplicative and additive relaxations of optimality. We propose a branch-and-cut (B&amp;C) method that computes such approximate equilibria or proves its non-existence. For this, we adopt the idea of intersection cuts and show the existence of such cuts under the condition that the constraints are linear and each player's cost function is either convex in the entire strategy profile, or, concave in the entire strategy profile and linear in the rivals' strategies. For the special case of standard Nash equilibrium problems, we introduce an alternative type of cut and show that the method terminates finitely, provided that each player has only finitely many distinct best-response sets. Finally, on the basis of the B&amp;C method, we introduce a single-tree binary-search method to compute best-approximate equilibria under some simplifying assumptions. We implemented these methods and present numerical results for a class of mixed-integer flow games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.03340v1</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alo\"is Duguet, Tobias Harks, Martin Schmidt, Julian Schwarz</dc:creator>
    </item>
    <item>
      <title>A New Algorithm for Computing the Stabilizing Solution of General Periodic Time-Varying Stochastic Game-Theoretic Riccati Differential Equations</title>
      <link>https://arxiv.org/abs/2511.03390</link>
      <description>arXiv:2511.03390v1 Announce Type: cross 
Abstract: We propose a new algorithm for a broad class of periodic time-varying Stochastic Game-Theoretic Riccati Differential Equations arising in Zero-Sum Linear-Quadratic Stochastic Differential Games. The algorithm is constructed via dual-layer matrix-valued functions iteration sequences, which reformulate the original problem into a set of interconnected bilevel subproblems. By sequentially computing the maximal periodic solutions to the Riccati differential equations associated with each subproblem, we derive the stabilizing periodic solutions for the original problem and rigorously prove the algorithm's convergence. Numerical experiments verifies algorithm effectiveness and stability. This study provides a unified numerical framework for solving a wider range of periodic time-varying Stochastic Game-Theoretic Riccati Differential Equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.03390v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yiyuan Wang</dc:creator>
    </item>
    <item>
      <title>Hesse's Redemption: Efficient Convex Polynomial Programming</title>
      <link>https://arxiv.org/abs/2511.03440</link>
      <description>arXiv:2511.03440v1 Announce Type: cross 
Abstract: Efficient algorithms for convex optimization, such as the ellipsoid method, require an a priori bound on the radius of a ball around the origin guaranteed to contain an optimal solution if one exists. For linear and convex quadratic programming, such solution bounds follow from classical characterizations of optimal solutions by systems of linear equations. For other programs, e.g., semidefinite ones, examples due to Khachiyan show that optimal solutions may require huge coefficients with an exponential number of bits, even if we allow approximations. Correspondingly, semidefinite programming is not even known to be in NP. The unconstrained minimization of convex polynomials of degree four and higher has remained a fundamental open problem between these two extremes: its optimal solutions do not admit a linear characterization and, at the same time, Khachiyan-type examples do not apply. We resolve this problem by developing new techniques to prove solution bounds when no linear characterizations are available. Even for programs minimizing a convex polynomial (of arbitrary degree) over a polyhedron, we prove that the existence of an optimal solution implies that an approximately optimal one with polynomial bit length also exists. These solution bounds, combined with the ellipsoid method, yield the first polynomial-time algorithm for convex polynomial programming, settling a question posed by Nesterov (Math. Program., 2019). Before, no polynomial-time algorithm was known even for unconstrained minimization of a convex polynomial of degree four.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.03440v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>math.AG</category>
      <category>math.OC</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lucas Slot, David Steurer, Manuel Wiedmer</dc:creator>
    </item>
    <item>
      <title>A Novel Deflation Approach for Topology Optimization and Application for Optimization of Bipolar Plates of Electrolysis Cells</title>
      <link>https://arxiv.org/abs/2406.17491</link>
      <description>arXiv:2406.17491v4 Announce Type: replace 
Abstract: Topology optimization problems usually feature multiple local minimizers. To guarantee convergence to local minimizers that perform best globally or to find local solutions that are desirable for practical applications due to easy manufacturability or aesthetic designs, it is important to compute multiple local minimizers of topology optimization problems. In this paper, we introduce a novel deflation approach to systematically find multiple local minimizers of general topology optimization problems. The approach is based on a penalization of previously found local solutions in the objective. We validate our approach on the so-called two-pipes five-holes example. Finally, we introduce a model for the topology optimization of bipolar plates of hydrogen electrolysis cells and demonstrate that our deflation approach enables the discovery of novel designs for such plates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.17491v4</guid>
      <category>math.OC</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1137/24M1670913</arxiv:DOI>
      <arxiv:journal_reference>SIAM J. Sci. Comput. 47, 2025</arxiv:journal_reference>
      <dc:creator>Leon Baeck, Sebastian Blauth, Christian Leith\"auser, Ren\'e Pinnau, Kevin Sturm</dc:creator>
    </item>
    <item>
      <title>Improving the Accuracy of DC Optimal Power Flow Formulations via Parameter Optimization</title>
      <link>https://arxiv.org/abs/2410.11725</link>
      <description>arXiv:2410.11725v2 Announce Type: replace 
Abstract: DC Optimal Power Flow (DC-OPF) problems optimize the generators' active power setpoints while satisfying constraints based on the DC power flow linearization. The computational tractability advantages of DC-OPF problems come at the expense of inaccuracies relative to AC Optimal Power Flow (AC-OPF) problems that accurately model the nonlinear steady-state behavior of power grids. This paper proposes an algorithm that significantly improves the accuracy of the generators' active power setpoints from DC-OPF problems with respect to the corresponding AC-OPF problems over a specified range of operating conditions. Using sensitivity information in a machine learning-inspired methodology, this algorithm tunes coefficient and bias parameters in the DC power flow approximation to improve the accuracy of the resulting DC-OPF solutions. Employing the Truncated Newton Conjugate-Gradient (TNC) method -- a Quasi-Newton optimization technique -- this parameter tuning occurs during an offline training phase, with the resulting parameters then used in online computations. Numerical results underscore the algorithm's efficacy with accuracy improvements in squared two-norm and $\infty$-norm losses of up to $90\%$ and $79\%$, respectively, relative to traditional DC-OPF formulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11725v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Babak Taheri, Daniel K. Molzahn</dc:creator>
    </item>
    <item>
      <title>Beyond Minimax Optimality: A Subgame Perfect Gradient Method</title>
      <link>https://arxiv.org/abs/2412.06731</link>
      <description>arXiv:2412.06731v3 Announce Type: replace 
Abstract: The study of convex optimization has historically been concerned with worst-case convergence rates. The development of the Optimized Gradient Method (OGM), due to \citet{drori2012PerformanceOF,Kim2016optimal}, marked a major milestone in this study, as OGM achieves the optimal worst-case convergence rate among all first-order methods for unconstrained smooth convex optimization. In order to examine the possibility of obtaining stronger convergence guarantees, we will consider algorithms with \emph{dynamic} convergence rates, which may improve as additional first-order information is revealed. Our main contribution is the development of an algorithm, the Subgame Perfect Gradient Method (SPGM), which refines OGM to make use of the full history of first-order information. We show that SPGM is \emph{dynamically optimal}, in the sense that in each iteration, no other algorithm can offer a strictly better convergence rate on all functions which agree with the observed first-order information up to that iteration. We formalize this notion of dynamic optimality using the game-theoretic notion of a subgame perfect equilibrium. We conclude our study with preliminary numerical experiments showing that SPGM strongly outperforms OGM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06731v3</guid>
      <category>math.OC</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Benjamin Grimmer, Kevin Shu, Alex L. Wang</dc:creator>
    </item>
    <item>
      <title>Proximal Gradient Dynamics and Feedback Control for Equality-Constrained Composite Optimization</title>
      <link>https://arxiv.org/abs/2503.15093</link>
      <description>arXiv:2503.15093v3 Announce Type: replace 
Abstract: This paper studies equality-constrained composite minimization problems. This class of problems, capturing regularization terms and inequality constraints, naturally arises in a wide range of engineering and machine learning applications. To tackle these optimization problems, inspired by recent results, we introduce the \emph{proportional--integral proximal gradient dynamics} (PI--PGD): a closed-loop system where the Lagrange multipliers are control inputs and states are the problem decision variables. First, we establish the equivalence between the stationary points of the minimization problem and the equilibria of the PI--PGD. Then for the case of affine constraints, by leveraging tools from contraction theory we give a comprehensive convergence analysis for the dynamics, showing linear--exponential convergence towards the equilibrium. That is, the distance between each solution and the equilibrium is upper bounded by a function that first decreases linearly and then exponentially. Our findings are illustrated numerically on a set of representative examples, which include an exploratory application to nonlinear equality constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.15093v3</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Veronica Centorrino, Francesca Rossi, Francesco Bullo, Giovanni Russo</dc:creator>
    </item>
    <item>
      <title>A Polynomial-Time Algorithm for Variational Inequalities under the Minty Condition</title>
      <link>https://arxiv.org/abs/2504.03432</link>
      <description>arXiv:2504.03432v2 Announce Type: replace 
Abstract: Solving variational inequalities (SVIs) is a foundational problem at the heart of optimization. However, this expressivity comes at the cost of computational hardness. As a result, most research has focused on carving out specific subclasses that elude those intractability barriers. A classical property that goes back to the 1960s is the Minty condition, which postulates that the Minty VI (MVI) problem admits a solution.
  In this paper, we establish the first polynomial-time algorithm -- that is, with complexity growing polynomially in the dimension $d$ and $\log(1/\epsilon)$ -- for solving $\epsilon$-SVIs for Lipschitz continuous mappings under the Minty condition. Prior approaches either incurred an exponentially worse dependence on $1/\epsilon$ or made restrictive assumptions. To do so, we introduce a new variant of the ellipsoid algorithm whereby separating hyperplanes are obtained after taking a gradient descent step from the center of the ellipsoid. It succeeds even though the set of SVIs can be nonconvex and not fully dimensional. Moreover, when our algorithm is applied to an instance with no MVI solution and fails to identify an SVI solution, it produces a succinct certificate of MVI infeasibility. We also show that deciding whether the Minty condition holds is $\mathsf{coNP}$-complete, thereby establishing that the disjunction of those two problems is polynomial-time solvable even though each problem is individually intractable.
  We provide several extensions and new applications of our main results. Most notably, we obtain the first polynomial-time algorithms for i) globally minimizing a (potentially nonsmooth) quasar-convex function, and ii) computing Nash equilibria in multi-player harmonic games. Finally, in two-player general-sum concave games, we give the first polynomial-time algorithm that outputs either a Nash equilibrium or a strict coarse correlated equilibrium.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03432v2</guid>
      <category>math.OC</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ioannis Anagnostides, Gabriele Farina, Tuomas Sandholm, Brian Hu Zhang</dc:creator>
    </item>
    <item>
      <title>Asynchronous Push-sum Dual Gradient Algorithm in Distributed Model Predictive Control</title>
      <link>https://arxiv.org/abs/2504.18941</link>
      <description>arXiv:2504.18941v3 Announce Type: replace 
Abstract: This paper studies the distributed model predictive control (DMPC) problem for distributed discrete-time linear systems with both local and global constraints over directed communication networks. We establish an optimization problem to formulate the DMPC policy, including the design of terminal ingredients. To cope with the global constraint, we transform the primal optimization problem into its dual problem. Then, we propose a novel asynchronous push-sum dual gradient (APDG) algorithm with an adaptive step-size scheme to solve this dual problem in a fully asynchronous distributed manner. The proposed algorithm does not require synchronous waiting and any form of coordination, which greatly improves solving efficiency. We prove that the APDG algorithm converges at an R-linear rate as long as the step-size does not exceed the designed upper bound. Furthermore, we develop a distributed termination criterion to terminate the APDG algorithm when its output solution satisfies the specified suboptimality and the global constraint, thereby avoiding an infinite number of iterations. The recursive feasibility and the stability of the closed-loop system are also established. Finally, a numerical example is provided to clarify and validate our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.18941v3</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pengbiao Wang, Xuemei Ren, Dongdong Zheng</dc:creator>
    </item>
    <item>
      <title>Stochastic Control of Dividends with a Drawdown Penalty</title>
      <link>https://arxiv.org/abs/2510.25494</link>
      <description>arXiv:2510.25494v2 Announce Type: replace 
Abstract: We consider a diffusion risk model where dividends are paid at rate $U(t) \in [0, u_0]$. We are interested in maximising the dividend payments under a drawdown constraint, that is, we penalise a drawdown size larger than a level $d &gt; 0$. We show that the optimal dividend rate $U(t)$ is either zero or the maximal rate $u_0$ and determine the optimal strategy. Moreover, we derive an explicit expression for the value function by solving a system of differential equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25494v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kira Dudziak, Hanspeter Schmidli</dc:creator>
    </item>
    <item>
      <title>Fiedler-Based Characterization and Identification of Leaders in Semi-Autonomous Networks</title>
      <link>https://arxiv.org/abs/2511.02317</link>
      <description>arXiv:2511.02317v2 Announce Type: replace 
Abstract: This paper addresses the problem of identifying leader nodes in semi-autonomous consensus networks from observed agent dynamics. Using the grounded Laplacian formulation, we derive spectral conditions that ensure the components of the Fiedler vector associated with leader and follower nodes are distinct. Building on the foundation, we emply the notion of relative tempo from prio works as an observable quantity that relates agents' steady-state velocities to the Fiedler vector. This relationship enables the development of a data-driven algorithm that reconstructs the Fiedler vector - and consequently identifies the leader set - using only steady-state velocity measurements, without requiring knowledge of the network topology. The proposed approach is validated through nuerical examples, demonstrating how spectral properties and relative tempo measurements can be combined to reveal hidden leadership structures in consensus networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.02317v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Evyatar Matmon, Daniel Zelazo</dc:creator>
    </item>
    <item>
      <title>An accelerated primal-dual flow for linearly constrained multiobjective optimization</title>
      <link>https://arxiv.org/abs/2511.02751</link>
      <description>arXiv:2511.02751v2 Announce Type: replace 
Abstract: In this paper, we propose a continuous-time primal-dual approach for linearly constrained multiobjective optimization problems. A novel dynamical model, called accelerated multiobjective primal-dual flow, is presented with a second-order equation for the primal variable and a first-order equation for the dual variable. It can be viewed as an extension of the accelerated primal-dual flow by Luo [arXiv:2109.12604, 2021] for the single objective case. To facilitate the convergence rate analysis, we introduce a new merit function, which motivates the use of the feasibility violation and the objective gap to measure the weakly Pareto optimality. By using a proper Lyapunov function, we establish the exponential decay rate in the continuous level. After that, we consider an implicit-explicit scheme, which yields an accelerated multiobjective primal-dual method with a quadratic subproblem, and prove the sublinear rates of the feasibility violation and the objective gap, under the convex case and the strongly convex case, respectively. Numerical results are provided to demonstrate the performance of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.02751v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hao Luo, Qiaoyuan Shu, Xinmin Yang</dc:creator>
    </item>
    <item>
      <title>Reactive power flow optimization in AC drive systems</title>
      <link>https://arxiv.org/abs/2504.10360</link>
      <description>arXiv:2504.10360v2 Announce Type: replace-cross 
Abstract: This paper explores a limit avoidance approach in the case of input (modulation) and output (current) constraints with the aim of enhancing system availability of AC drives. Drawing on the observation that, in a certain range of reactive power, there exists a trade-off between current and modulation magnitude, we exploit this freedom and define a constrained optimization problem. We propose two approaches, one in the form of an activation-function which drives the reactive power set-point towards safety, and an approach which uses online feedback optimization to set the reactive power dynamically. Both methods compromise reactive power tracking accuracy for increased system robustness. Through a high fidelity simulation, we compare the benefits of the two methods, highlighting their effectiveness in industrial applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.10360v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sanjay Chandrasekaran, Catalin Arghir, Pieder Joerg, Florian Doerfler, Silvia Mastellone</dc:creator>
    </item>
    <item>
      <title>A data-driven framework for team selection in Fantasy Premier League</title>
      <link>https://arxiv.org/abs/2505.02170</link>
      <description>arXiv:2505.02170v2 Announce Type: replace-cross 
Abstract: Fantasy football is a billion-dollar industry with millions of participants. Under a fixed budget, managers select squads to maximize future Fantasy Premier League (FPL) points. This study formulates lineup selection as data-driven optimization and develops deterministic and robust mixed-integer linear programs that choose the starting eleven, bench, and captain under budget, formation, and club-quota constraints (maximum three players per club). The objective is parameterized by a hybrid scoring metric that combines realized FPL points with predictions from a linear regression model trained on match-performance features identified using exploratory data analysis techniques. The study benchmarks alternative objectives and cost estimators, including simple and recency-weighted averages, exponential smoothing, autoregressive integrated moving average (ARIMA), and Monte Carlo simulation. Experiments on the 2023/24 Premier League season show that ARIMA with a constrained budget and a rolling window yields the most consistent out-of-sample performance; weighted averages and Monte Carlo are also competitive. Robust variants improve some objectives but are not uniformly superior. The framework provides transparent decision support for fantasy roster construction and extends to FPL chips, multi-week rolling-horizon transfer planning, and week-by-week dynamic captaincy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02170v2</guid>
      <category>cs.CE</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Danial Ramezani, Tai Dinh</dc:creator>
    </item>
    <item>
      <title>A Theoretical Framework for Grokking: Interpolation followed by Riemannian Norm Minimisation</title>
      <link>https://arxiv.org/abs/2505.20172</link>
      <description>arXiv:2505.20172v2 Announce Type: replace-cross 
Abstract: We study the dynamics of gradient flow with small weight decay on general training losses $F: \mathbb{R}^d \to \mathbb{R}$. Under mild regularity assumptions and assuming convergence of the unregularised gradient flow, we show that the trajectory with weight decay $\lambda$ exhibits a two-phase behaviour as $\lambda \to 0$. During the initial fast phase, the trajectory follows the unregularised gradient flow and converges to a manifold of critical points of $F$. Then, at time of order $1/\lambda$, the trajectory enters a slow drift phase and follows a Riemannian gradient flow minimising the $\ell_2$-norm of the parameters. This purely optimisation-based phenomenon offers a natural explanation for the \textit{grokking} effect observed in deep learning, where the training loss rapidly reaches zero while the test loss plateaus for an extended period before suddenly improving. We argue that this generalisation jump can be attributed to the slow norm reduction induced by weight decay, as explained by our analysis. We validate this mechanism empirically on several synthetic regression tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20172v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 06 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Etienne Boursier, Scott Pesme, Radu-Alexandru Dragomir</dc:creator>
    </item>
  </channel>
</rss>
