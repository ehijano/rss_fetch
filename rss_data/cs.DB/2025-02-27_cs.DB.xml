<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DB updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DB</link>
    <description>cs.DB updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DB" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 27 Feb 2025 05:00:13 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Credible Intervals for Knowledge Graph Accuracy Estimation</title>
      <link>https://arxiv.org/abs/2502.18961</link>
      <description>arXiv:2502.18961v1 Announce Type: new 
Abstract: Knowledge Graphs (KGs) are widely used in data-driven applications and downstream tasks, such as virtual assistants, recommendation systems, and semantic search. The accuracy of KGs directly impacts the reliability of the inferred knowledge and outcomes. Therefore, assessing the accuracy of a KG is essential for ensuring the quality of facts used in these tasks. However, the large size of real-world KGs makes manual triple-by-triple annotation impractical, thereby requiring sampling strategies to provide accuracy estimates with statistical guarantees. The current state-of-the-art approaches rely on Confidence Intervals (CIs), derived from frequentist statistics. While efficient, CIs have notable limitations and can lead to interpretation fallacies. In this paper, we propose to overcome the limitations of CIs by using \emph{Credible Intervals} (CrIs), which are grounded in Bayesian statistics. These intervals are more suitable for reliable post-data inference, particularly in KG accuracy evaluation. We prove that CrIs offer greater reliability and stronger guarantees than frequentist approaches in this context. Additionally, we introduce \emph{a}HPD, an adaptive algorithm that is more efficient for real-world KGs and statistically robust, addressing the interpretive challenges of CIs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.18961v1</guid>
      <category>cs.DB</category>
      <pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Stefano Marchesin, Gianmaria Silvello</dc:creator>
    </item>
    <item>
      <title>A Categorical Unification for Multi-Model Data: Part I Categorical Model and Normal Forms</title>
      <link>https://arxiv.org/abs/2502.19131</link>
      <description>arXiv:2502.19131v1 Announce Type: new 
Abstract: Modern database systems face a significant challenge in effectively handling the Variety of data. The primary objective of this paper is to establish a unified data model and theoretical framework for multi-model data management. To achieve this, we present a categorical framework to unify three types of structured or semi-structured data: relation, XML, and graph-structured data. Utilizing the language of category theory, our framework offers a sound formal abstraction for representing these diverse data types. We extend the Entity-Relationship (ER) diagram with enriched semantic constraints, incorporating categorical ingredients such as pullback, pushout and limit. Furthermore, we develop a categorical normal form theory which is applied to category data to reduce redundancy and facilitate data maintenance. Those normal forms are applicable to relation, XML and graph data simultaneously, thereby eliminating the need for ad-hoc, model-specific definitions as found in separated normal form theories before. Finally, we discuss the connections between this new normal form framework and Boyce-Codd normal form, fourth normal form, and XML normal form.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.19131v1</guid>
      <category>cs.DB</category>
      <pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiaheng Lu</dc:creator>
    </item>
    <item>
      <title>MixLLM: Dynamic Routing in Mixed Large Language Models</title>
      <link>https://arxiv.org/abs/2502.18482</link>
      <description>arXiv:2502.18482v1 Announce Type: cross 
Abstract: Large Language Models (LLMs) exhibit potential artificial generic intelligence recently, however, their usage is costly with high response latency. Given mixed LLMs with their own strengths and weaknesses, LLM routing aims to identify the most suitable model for each query in the stream to maximize response quality and minimize cost and latency. However, the challenges involve: (1) dynamic trade-offs among quality, cost, and latency; (2) enabling continual learning in deployed systems; and (3) navigating a varying (e.g., new LLM addition or old LLM removal) set of LLM candidates over time. To bridge these gaps, we develop MixLLM, a dynamic contextual-bandit-based routing system for query-LLM assignment. Specifically, we first leverage query tags to enhance query embeddings for the routing task. Next, we design lightweight prediction models to estimate the response qualities and costs of queries over LLMs. We then devise a meta-decision maker to choose the query-LLM assignments to best tradeoff response quality, cost, and latency. Finally, the system benefits from continual training, allowing it to adapt to evolving queries and user feedback over time. Our extensive experiments show that MixLLM achieves the best trade-offs in response quality, cost, and latency (97.25% of GPT-4's quality at 24.18% of the cost under the time constraint).</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.18482v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.DB</category>
      <category>cs.IR</category>
      <pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xinyuan Wang, Yanchi Liu, Wei Cheng, Xujiang Zhao, Zhengzhang Chen, Wenchao Yu, Yanjie Fu, Haifeng Chen</dc:creator>
    </item>
    <item>
      <title>On Aggregation Queries over Predicted Nearest Neighbors</title>
      <link>https://arxiv.org/abs/2502.18803</link>
      <description>arXiv:2502.18803v1 Announce Type: cross 
Abstract: We introduce Aggregation Queries over Nearest Neighbors (AQNNs), a novel type of aggregation queries over the predicted neighborhood of a designated object. AQNNs are prevalent in modern applications where, for instance, a medical professional may want to compute "the average systolic blood pressure of patients whose predicted condition is similar to a given insomnia patient". Since prediction typically involves an expensive deep learning model or a human expert, we formulate query processing as the problem of returning an approximate aggregate by combining an expensive oracle and a cheaper model (e.g, a simple ML model) to compute the predictions. We design the Sampler with Precision-Recall in Target (SPRinT) framework for answering AQNNs. SPRinT consists of sampling, nearest neighbor refinement, and aggregation, and is tailored for various aggregation functions. It enjoys provable theoretical guarantees, including bounds on sample size and on error in approximate aggregates. Our extensive experiments on medical, e-commerce, and video datasets demonstrate that SPRinT consistently achieves the lowest aggregation error with minimal computation cost compared to its baselines. Scalability results show that SPRinT's execution time and aggregation error remain stable as the dataset size increases, confirming its suitability for large-scale applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.18803v1</guid>
      <category>cs.DS</category>
      <category>cs.DB</category>
      <category>cs.IR</category>
      <pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Carrie Wang, Sihem Amer-Yahia, Laks V. S. Lakshmanan, Reynold Cheng</dc:creator>
    </item>
    <item>
      <title>MEBench: Benchmarking Large Language Models for Cross-Document Multi-Entity Question Answering</title>
      <link>https://arxiv.org/abs/2502.18993</link>
      <description>arXiv:2502.18993v1 Announce Type: cross 
Abstract: Multi-entity question answering (MEQA) represents significant challenges for large language models (LLM) and retrieval-augmented generation (RAG) systems, which frequently struggle to consolidate scattered information across diverse documents. While existing methods excel at single-document comprehension, they often struggle with cross-document aggregation, particularly when resolving entity-dense questions like "What is the distribution of ACM Fellows among various fields of study?", which require integrating entity-centric insights from heterogeneous sources (e.g., Wikipedia pages). To address this gap, we introduce MEBench, a novel multi-document, multi-entity benchmark designed to systematically evaluate LLMs' capacity to retrieve, consolidate, and reason over fragmented information. Our benchmark comprises 4,780 questions which are systematically categorized into three primary categories, further divided into eight distinct types, ensuring broad coverage of real-world multi-entity reasoning scenarios. Our experiments on state-of-the-art LLMs (e.g., GPT-4, Llama-3) and RAG pipelines reveal critical limitations: even advanced models achieve only 59% accuracy on MEBench. Our benchmark emphasizes the importance of completeness and factual precision of information extraction in MEQA tasks, using Entity-Attributed F1 (EA-F1) metric for granular evaluation of entity-level correctness and attribution validity. MEBench not only highlights systemic weaknesses in current LLM frameworks but also provides a foundation for advancing robust, entity-aware QA architectures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.18993v1</guid>
      <category>cs.CL</category>
      <category>cs.DB</category>
      <pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Teng Lin</dc:creator>
    </item>
    <item>
      <title>A Sampling-based Framework for Hypothesis Testing on Large Attributed Graphs</title>
      <link>https://arxiv.org/abs/2403.13286</link>
      <description>arXiv:2403.13286v2 Announce Type: replace-cross 
Abstract: Hypothesis testing is a statistical method used to draw conclusions about populations from sample data, typically represented in tables. With the prevalence of graph representations in real-life applications, hypothesis testing in graphs is gaining importance. In this work, we formalize node, edge, and path hypotheses in attributed graphs. We develop a sampling-based hypothesis testing framework, which can accommodate existing hypothesis-agnostic graph sampling methods. To achieve accurate and efficient sampling, we then propose a Path-Hypothesis-Aware SamplEr, PHASE, an m- dimensional random walk that accounts for the paths specified in a hypothesis. We further optimize its time efficiency and propose PHASEopt. Experiments on real datasets demonstrate the ability of our framework to leverage common graph sampling methods for hypothesis testing, and the superiority of hypothesis-aware sampling in terms of accuracy and time efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.13286v2</guid>
      <category>stat.ML</category>
      <category>cs.DB</category>
      <category>cs.LG</category>
      <pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Yun Wang, Chrysanthi Kosyfaki, Sihem Amer-Yahia, Reynold Cheng</dc:creator>
    </item>
  </channel>
</rss>
