<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.NA</link>
    <description>math.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 19 Sep 2025 04:04:27 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>On the extension of a class of Hermite bivariate interpolation problems</title>
      <link>https://arxiv.org/abs/2509.14359</link>
      <description>arXiv:2509.14359v1 Announce Type: new 
Abstract: We characterize the sets of solvability for Hermite bivariate interpolation problems when the sum of multiplicities is at most $2n + 2$, with $n$ the degree of the polynomial space. This result extends an earlier theorem (2000) by one of the authors concerning the case $2n+1$. The latter theorem, in turn, can be regarded as a natural generalization of a classical theorem of Severi (1921).</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14359v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hakop Hakopian, Anush Khachatryan</dc:creator>
    </item>
    <item>
      <title>Error analysis of a fully discrete structure-preserving finite element scheme for a diffuse-interface model of tumour growth</title>
      <link>https://arxiv.org/abs/2509.14486</link>
      <description>arXiv:2509.14486v1 Announce Type: new 
Abstract: We develop a fully discrete structure-preserving finite element method for a diffuse-interface model of tumour growth. The system couples a Cahn--Hilliard type equation with a nonlinear reaction-diffusion equation for nutrient concentration and admits a dissipative energy law at the continuous level. For the discretisation, we employ a scalar auxiliary variable (SAV) formulation together with a mixed finite element method for the Cahn--Hilliard part and standard conforming finite elements for the reaction-diffusion equation in space, combined with a first-order Euler time-stepping scheme. The resulting method is linear, unconditionally energy-stable, mass-preserving, and inherits a discrete energy dissipation law associated with the SAV-based approximate energy functional, while requiring the solution of only linear systems at each time step. Under suitable regularity assumptions on the exact solution, we derive rigorous error estimates in $L^2$, $H^1$, and $L^\infty$ norms, establishing first-order accuracy in time and optimal-order accuracy in space. A key step in this analysis is the proof of boundedness of the numerical solutions in $L^\infty$. Numerical experiments validate the theoretical convergence rates and demonstrate the robustness of the method in capturing characteristic phenomena such as aggregation and chemotactic tumour growth.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14486v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Agus L. Soenjaya, Ping Lin, Thanh Tran</dc:creator>
    </item>
    <item>
      <title>The extended horizontal linear complementarity problem: iterative methods and error analysis</title>
      <link>https://arxiv.org/abs/2509.14491</link>
      <description>arXiv:2509.14491v1 Announce Type: new 
Abstract: To the best of our knowledge, since the extended horizontal linear complementarity problem (EHLCP) was first introduced and studied by Kaneko in 1977, no iterative methods or error analysis have been developed for it due to the interdependence of its multiple unknowns in a 'chain-like' structure. This paper aims to address these gaps by:
  (1) proposing an equivalent fixed-point formulation of the EHLCP by using a variable transformation technique with the max-min function;
  (2) developing efficient iterative methods for solving the EHLCP based on this fixed-point form, along with their convergence analysis;
  (3) deriving global error bounds and computable estimates for the EHLCP.
  Several numerical examples from applications such as multicommodity market equilibrium and bilateral obstacle problems are given to demonstrate the effectiveness of the proposed methods and bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14491v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shi-Liang Wu, Cui-Xia Li</dc:creator>
    </item>
    <item>
      <title>The whys and hows of conditioning of DG plane wave Trefftz methods: a single element</title>
      <link>https://arxiv.org/abs/2509.14500</link>
      <description>arXiv:2509.14500v1 Announce Type: new 
Abstract: Plane-wave Trefftz methods (PWB) for the Helmholtz equation offer significant advantages over standard discretization approaches whose implementation employs more general polynomial basis functions. A disadvantage of these methods is the poor conditioning of the system matrices. In the present paper, we carefully examine the conditioning of the plane-wave discontinuous Galerkin method with reference to a single element. The properties of the mass and stiffness matrices depend on the size and geometry of the element. We study the mass and system matrices arising from a PWB on a single disk-shaped element. We then examine some preconditioning strategies, and present results showing their behaviour with three different criteria: conditioning, the behaviour of GMRES residuals, and impact on the $L^2$-error.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14500v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joseph Coyle, Nilima Nigam</dc:creator>
    </item>
    <item>
      <title>Weak Adversarial Neural Pushforward Mappings for Fokker-Planck Equations</title>
      <link>https://arxiv.org/abs/2509.14575</link>
      <description>arXiv:2509.14575v1 Announce Type: new 
Abstract: This paper presents a novel method for solving Fokker-Planck equations by learning neural samplers via a weak adversarial framework. We represent the solution distribution through a neural pushforward map, bypassing the limitations of density-based methods. A key innovation is our use of computationally efficient plane-wave test functions, whose derivatives are explicitly computed -- a treatment distinct from prior work. This approach handles distributions without densities and naturally enforces probability conservation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14575v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrew Qing He, Wei Cai</dc:creator>
    </item>
    <item>
      <title>A Weighted Sampling Method for Inverse Medium Problem with Limited Aperture</title>
      <link>https://arxiv.org/abs/2509.14580</link>
      <description>arXiv:2509.14580v1 Announce Type: new 
Abstract: Inverse medium scattering problems arise in many applications, but in practice, the measurement data are often restricted to a limited aperture by physical or experimental constraints. Classical sampling methods, such as MUSIC and the linear sampling method, are well understood for full-aperture data, yet their performance deteriorates severely under limited-aperture conditions, especially in the presence of noise. We propose a new sampling method tailored to the inverse medium problem with limited-aperture data. The method is motivated by the linear sampling framework and incorporates a weight function into the index function. The weight is designed so that the modified kernel reproduces the full-aperture behavior using only limited data, which both localizes oscillations and improves the conditioning of the far-field system, thereby yielding more accurate and stable reconstructions. We provide a theoretical justification of the method under the Born approximation and an efficient algorithm for computing the weight. Numerical experiments in two and three dimensions demonstrate that the proposed method achieves greater accuracy and robustness than existing sampling-type methods, particularly for noisy, limited-aperture data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14580v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fuqun Han, Kazufumi Ito</dc:creator>
    </item>
    <item>
      <title>Decay of Chebyshev coefficients and error estimates of associated quadrature on shrinking intervals</title>
      <link>https://arxiv.org/abs/2509.14602</link>
      <description>arXiv:2509.14602v1 Announce Type: new 
Abstract: We analyze decay of Chebyshev coefficients and local Chebyshev approximations for functions of finite regularity on finite intervals, focusing on the framework where the interval length tends to zero while the number of approximation nodes remains fixed. For all four families of Chebyshev polynomials, we derive error estimates that quantify the dependence on the interval length for (i) the decay of Chebyshev coefficients, (ii) the approximation error between continuous and discrete Chebyshev coefficients, and (iii) the convergence of Chebyshev-based quadrature rules. These results fill a gap in the existing theory and provide a unified and rigorous description of how approximation accuracy scales on shrinking intervals, offering new theoretical insight and practical guidance for high-order numerical methods on decomposed domains. Numerical experiments corroborate the theoretical results, confirming the decay rates and illustrating the error behavior in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14602v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Krishna Yamanappa Poojara, Sabhrant Sachan, Ambuj Pandey</dc:creator>
    </item>
    <item>
      <title>Unconditional and optimal error analysis of two linearized finite difference schemes for the logarithmic Schr\"odinger equation</title>
      <link>https://arxiv.org/abs/2509.14736</link>
      <description>arXiv:2509.14736v1 Announce Type: new 
Abstract: In this paper, we propose two linearized finite difference schemes for solving the logarithmic Schr\"odinger equation (LogSE) without the need for regularization of the logarithmic term. These two schemes employ the first-order and the second-order backward difference formula, respectively, for temporal discretization of the LogSE, while using the second-order central finite difference method for spatial discretization. We overcome the singularity posed by the logarithmic nonlinearity $f(u)=u\ln|u|$ in establishing optimal $l^{2}$-error estimates for the first-order scheme, and an almost optimal $l^{2}$-error estimate for the second-order scheme. Compared to the error estimates of the LogSE in the literature, our error bounds not only greatly improve the convergence rate but also get rid of the time step restriction. Furthermore, without enhancing the regularity of the exact solution or imposing any requirements on the grid ratio, we establish error estimates of the two proposed schemes in the discrete $H^{1}$ norm. However, the existing results available in the literature either fail to provide $H^{1}$ error estimates or require certain restrictions on the grid ratio. Numerical results are reported to confirm our error estimates and demonstrate rich dynamics of the LogSE.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14736v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Tingchun Wang, Jingye Yan</dc:creator>
    </item>
    <item>
      <title>The Bayesian SIAC filter</title>
      <link>https://arxiv.org/abs/2509.14771</link>
      <description>arXiv:2509.14771v1 Announce Type: new 
Abstract: We propose the Bayesian smoothness-increasing accuracy-conserving (SIAC) filter -- a hierarchical Bayesian extension of the existing deterministic SIAC filter. The SIAC filter is a powerful numerical tool for removing high-frequency noise from data or numerical solutions without degrading accuracy. However, current SIAC methodology is limited to (i) nodal data (direct, typically noisy function values) and (ii) deterministic point estimates that do not account for uncertainty propagation from input data to the SIAC reconstruction. The proposed Bayesian SIAC filter overcomes these limitations by (i) supporting general (non-nodal) data models and (ii) enabling rigorous uncertainty quantification (UQ), thereby broadening the applicability of SIAC filtering. We also develop structure-exploiting algorithms for efficient maximum a posteriori (MAP) estimation and Markov chain Monte Carlo (MCMC) sampling, with a focus on linear data models with additive Gaussian noise. Computational experiments demonstrate the effectiveness of the Bayesian SIAC filter across several applications, including signal denoising, image deblurring, and post-processing of numerical solutions to hyperbolic conservation laws. The results show that the Bayesian approach produces point estimates with accuracy comparable to, and in some cases exceeding, that of the deterministic SIAC filter. In addition, it extends naturally to general data models and provides built-in UQ.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14771v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jan Glaubitz, Tongtong Li, Jennifer Ryan, Roman Stuhlmacher</dc:creator>
    </item>
    <item>
      <title>A class of flexible and efficient partitioned Runge-Kutta-Chebyshev methods for some time-dependent partial differential equations</title>
      <link>https://arxiv.org/abs/2509.14847</link>
      <description>arXiv:2509.14847v1 Announce Type: new 
Abstract: Many time-dependent partial differential equations (PDEs) can be transformed into an ordinary differential equations (ODEs) containing moderately stiff and non-stiff terms after spatial semi-discretization. In the present paper, we construct a new class of second-order partitioned explicit stabilized methods for the above ODEs. We treat the moderately stiff term with an s-stage Runge-Kutta-Chebyshev (RKC) method and treat the non-stiff term with a 4m-stage explicit Runge-Kutta (RK) method. Different from several existing partitioned explicit stabilized methods that employ fixed-stage RK methods to handle the non-stiff term, both the parameters $s$ and $m$ in our methods can be flexibly adjusted as needed for the problems. This feature endows our methods with superior flexibility and applicability compared to several existing partitioned explicit stabilized methods, as demonstrated in several specific numerical examples (including the advection-diffusion equations, the Burgers equations, the Brusselator equations and the damped wave equations).</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14847v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiao Tang, Junwei Huang</dc:creator>
    </item>
    <item>
      <title>A cell centered Galerkin method for miscible displacement in heterogeneous porous media</title>
      <link>https://arxiv.org/abs/2509.14864</link>
      <description>arXiv:2509.14864v1 Announce Type: new 
Abstract: In this paper we present a cell centered Galerkin (CCG) method applied to miscible displacement problems in heterogeneous porous media. The CCG approach combines concepts from finite volume and discontinuous Galerkin (DG) methods to arrive at an efficient lowest-order approximation (one unknown per cell). We demonstrate that the CCG method can be defined using classical DG weak formulations, only requires one unknown per cell, and is able to deliver comparable accuracy and improved efficiency over traditional higher-order interior penalty DG methods. In addition, we prove that the CCG method for a model Poisson problem gives rise to a inverse-positive matrix in 1D. A plethora of computational experiments in 2D and 3D showcase the effectiveness of the CCG method for highly heterogeneous flow and transport problems in porous media. Comparisons between CCG and classical DG methods are included.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14864v1</guid>
      <category>math.NA</category>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maurice S. Fabien</dc:creator>
    </item>
    <item>
      <title>An Adaptive Sampling Algorithm for Level-set Approximation</title>
      <link>https://arxiv.org/abs/2509.14896</link>
      <description>arXiv:2509.14896v1 Announce Type: new 
Abstract: We propose a new numerical scheme for approximating level-sets of Lipschitz multivariate functions which is robust to stochastic noise. The algorithm's main feature is an adaptive grid-based stochastic approximation strategy which automatically refines the approximation over regions close to the level set. This strategy combines a local function approximation method with a noise reduction scheme and produces $\varepsilon$-accurate approximations with an expected cost complexity reduction of $\varepsilon^{-\left(\frac{p+1}{\alpha p}\right)}$ compared to a non-adaptive scheme, where $\alpha$ is the convergence rate of the function approximation method and we assume that the noise can be controlled in $L^p$. We provide numerical experiments in support of our theoretical findings. These include 2- and 3-dimensional functions with a complex level set structure, as well as a failure region estimation problem described by a hyperelasticity partial differential equation with random field coefficients.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14896v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matteo Croci, Abdul-Lateef Haji-Ali, Ian C. J. Powell</dc:creator>
    </item>
    <item>
      <title>Finite Volumes for a dissipative free boundary problem</title>
      <link>https://arxiv.org/abs/2509.14908</link>
      <description>arXiv:2509.14908v1 Announce Type: new 
Abstract: We study a toy model for the evolution of the oxygen concentration in an oxide layer. It consists in a transient convection diffusion equation in a one-dimensional domain of variable width. The motions of the boundaries are governed by the traces of the concentration. We exhibit a necessary and sufficient condition on the parameters involved in the model for the existence of a unique traveling-wave solution. Moreover, we show that the model admits some universal entropy structure, in the sense that any convex function of the concentration
  yields a dissipated free energy (up to exchanges with the outer environment at the boundaries). We propose then an implicit in time arbitrary Lagrangian-Eulerian finite volume scheme based on Scharfetter-Gummel fluxes. It is shown to be unconditionally convergent, to preserve exactly the travelling wave, and to dissipate all the aforementioned free energies. Numerical experiments show that our scheme is first order accurate in time and second order in space, and that the transient solution converges in the long-time limit towards the traveling-wave solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14908v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Cl\'ement Canc\`es, Claire Chainais-Hillairet, Am\'elie Dupouy</dc:creator>
    </item>
    <item>
      <title>On the Late-Time Instability of MOT solution to the Time-Domain PMCHWT Equation</title>
      <link>https://arxiv.org/abs/2509.14995</link>
      <description>arXiv:2509.14995v1 Announce Type: new 
Abstract: This paper investigates the late-time instability of marching-on-in-time solution to the time-domain PMCHWT equation. The stability analysis identifies the static solenoidal nullspace of the time-domain electric field integral operator as the primary cause of instability. Furthermore, it reveals that the instability mechanisms of the time-domain PMCHWT equation are fundamentally different from those of the time-domain electric field integral equation. In particular, the PMCHWT's instability is much more sensitive to numerical quadrature errors, and its spectral characteristics are strongly influenced by the topology and smoothness of the scatterer surface.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14995v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/LAWP.2025.3610422</arxiv:DOI>
      <dc:creator>Van Chien Le, Viviana Giunzioni, Pierrick Cordel, Francesco P. Andriulli, Kristof Cools</dc:creator>
    </item>
    <item>
      <title>Fourier heuristic PINNs to solve the biharmonic equations based on its coupled scheme</title>
      <link>https://arxiv.org/abs/2509.15004</link>
      <description>arXiv:2509.15004v1 Announce Type: new 
Abstract: Physics-informed neural networks (PINNs) have been widely utilized for solving a range of partial differential equations (PDEs) in various scientific and engineering disciplines. This paper presents a Fourier heuristic-enhanced PINN (termed FCPINN) designed to address a specific class of biharmonic equations with Dirichlet and Navier boundary conditions. The method achieves this by decomposing the high-order equations into two Poisson equations. FCPINN integrates Fourier spectral theory with a reduced-order formulation for high-order PDEs, significantly improving approximation accuracy and reducing computational complexity. This approach is especially beneficial for problems with intricate boundary constraints and high-dimensional inputs. To assess the effectiveness and robustness of the FCPINN algorithm, we conducted several numerical experiments on both linear and nonlinear biharmonic problems across different Euclidean spaces. The results show that FCPINN provides an optimal trade-off between speed and accuracy for high-order PDEs, surpassing the performance of conventional PINN and deep mixed residual method (MIM) approaches, while also maintaining stability and robustness with varying numbers of hidden layer nodes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.15004v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Yujia Huang, Xi'an Li ansd Jinran Wu</dc:creator>
    </item>
    <item>
      <title>A Bayesian thinning algorithm for the point source identification of heat equation</title>
      <link>https://arxiv.org/abs/2509.14245</link>
      <description>arXiv:2509.14245v1 Announce Type: cross 
Abstract: In this work, we propose a Bayesian thinning algorithm for recovering weighted point source functions in the heat equation from boundary flux observations. The major challenge in the classical Bayesian framework lies in constructing suitable priors for such highly structured unknowns. To address this, we introduce a level set representation on a discretized mesh for the unknown, which enables the infinite-dimensional Bayesian framework to the reconstruction. From another perspective, the point source configuration can be modeled as a marked Poisson point process (PPP), then a thinning mechanism is employed to selectively retain points. These two proposals are complementary with the Bayesian level set sampling generating candidate point sources and the thinning process acting as a filter to refine them. This combined framework is validated through numerical experiments, which demonstrate its accuracy in reconstructing point sources.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14245v1</guid>
      <category>stat.CO</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Zhiliang Deng, Chen Li, Xiaomei Yang</dc:creator>
    </item>
    <item>
      <title>A Neural Network for the Identical Kuramoto Equation: Architectural Considerations and Performance Evaluation</title>
      <link>https://arxiv.org/abs/2509.14384</link>
      <description>arXiv:2509.14384v1 Announce Type: cross 
Abstract: In this paper, we investigate the efficiency of Deep Neural Networks (DNNs) to approximate the solution of a nonlocal conservation law derived from the identical-oscillator Kuramoto model, focusing on the evaluation of an architectural choice and its impact on solution accuracy based on the energy norm and computation time. Through systematic experimentation, we demonstrate that network configuration parameters-specifically, activation function selection (tanh vs. sin vs. ReLU), network depth (4-8 hidden layers), width (64-256 neurons), and training methodology (collocation points, epoch count)-significantly influence convergence characteristics. We observe that tanh activation yields stable convergence across configurations, whereas sine activation can attain marginally lower errors and training times in isolated cases, but occasionally produce nonphysical artefacts. Our comparative analysis with traditional numerical methods shows that optimally configured DNNs offer competitive accuracy with notably different computational trade-offs. Furthermore, we identify fundamental limitations of standard feed-forward architectures when handling singular or piecewise-constant solutions, providing empirical evidence that such networks inherently oversmooth sharp features due to the natural function space limitations of standard activation functions. This work contributes to the growing body of research on neural network-based scientific computing by providing practitioners with empirical guidelines for DNN implementation while illuminating fundamental theoretical constraints that must be overcome to expand their applicability to more challenging physical systems with discontinuities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14384v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nishantak Panigrahi, Mayank Patwal</dc:creator>
    </item>
    <item>
      <title>Wohlhart's Three-Loop Mechanism: An Overconstrained and Shaky Linkage</title>
      <link>https://arxiv.org/abs/2509.14698</link>
      <description>arXiv:2509.14698v1 Announce Type: cross 
Abstract: This paper revisits a three-loop spatial linkage that was proposed in an ARK 2004 paper by Karl Wohlhart (as extension of a two-loop linkage proposed by Eddie Baker in 1980) and later analyzed in an ARK 2006 paper by Diez-Martinez et. al. A local analysis shows that this linkage has a finite degree of freedom (DOF) 3 (and is thus overconstrained) while in its reference configuration the differential DOF is 5. It is shown that its configuration space is locally a smooth manifold so that the reference configuration is not a c-space singularity. It is shown that the differential DOF is locally constant, which makes this linkage shaky (so that the reference configuration is not a singularity). The higher-order local analysis is facilitated by the computation of the kinematic tangent cone as well as a local approximation of the c-space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14698v1</guid>
      <category>cs.RO</category>
      <category>cs.NA</category>
      <category>math.DG</category>
      <category>math.GR</category>
      <category>math.NA</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1007/978-3-030-50975-0_16</arxiv:DOI>
      <arxiv:journal_reference>Lenar\v{c}i\v{c} J., Siciliano B. (eds), Advances in Robot Kinematics 2020 (ARK 2020). Springer Proceedings in Advanced Robotics, Vol 15. Springer, Cham, pp. 125-132</arxiv:journal_reference>
      <dc:creator>Andreas Mueller</dc:creator>
    </item>
    <item>
      <title>Fracture interactive geodesic active contours for bone segmentation</title>
      <link>https://arxiv.org/abs/2509.14817</link>
      <description>arXiv:2509.14817v1 Announce Type: cross 
Abstract: For bone segmentation, the classical geodesic active contour model is usually limited by its indiscriminate feature extraction, and then struggles to handle the phenomena of edge obstruction, edge leakage and bone fracture. Thus, we propose a fracture interactive geodesic active contour algorithm tailored for bone segmentation, which can better capture bone features and perform robustly to the presence of bone fractures and soft tissues. Inspired by orthopedic knowledge, we construct a novel edge-detector function that combines the intensity and gradient norm, which guides the contour towards bone edges without being obstructed by other soft tissues and therefore reduces mis-segmentation. Furthermore, distance information, where fracture prompts can be embedded, is introduced into the contour evolution as an adaptive step size to stabilize the evolution and help the contour stop at bone edges and fractures. This embedding provides a way to interact with bone fractures and improves the accuracy in the fracture regions. Experiments in pelvic and ankle segmentation demonstrate the effectiveness on addressing the aforementioned problems and show an accurate, stable and consistent performance, indicating a broader application in other bone anatomies. Our algorithm also provides insights into combining the domain knowledge and deep neural networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14817v1</guid>
      <category>cs.CV</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liheng Wang, Licheng Zhang, Hailin Xu, Jingxin Zhao, Xiuyun Su, Jiantao Li, Miutian Tang, Weilu Gao, Chong Chen</dc:creator>
    </item>
    <item>
      <title>Non-Intrusive Parametrized-Background Data-Weak Reconstruction of Cardiac Displacement Fields from Sparse MRI-like Observations</title>
      <link>https://arxiv.org/abs/2509.14844</link>
      <description>arXiv:2509.14844v1 Announce Type: cross 
Abstract: Personalized cardiac diagnostics require accurate reconstruction of myocardial displacement fields from sparse clinical imaging data, yet current methods often demand intrusive access to computational models. In this work, we apply the non-intrusive Parametrized-Background Data-Weak (PBDW) approach to three-dimensional (3D) cardiac displacement field reconstruction from limited Magnetic Resonance Image (MRI)-like observations. Our implementation requires only solution snapshots -- no governing equations, assembly routines, or solver access -- enabling immediate deployment across commercial and research codes using different constitutive models. Additionally, we introduce two enhancements: an H-size minibatch worst-case Orthogonal Matching Pursuit (wOMP) algorithm that improves Sensor Selection (SS) computational efficiency while maintaining reconstruction accuracy, and memory optimization techniques exploiting block matrix structures in vectorial problems. We demonstrate the effectiveness of the method through validation on a 3D left ventricular model with simulated scar tissue. Starting with noise-free reconstruction, we systematically incorporate Gaussian noise and spatial sparsity mimicking realistic MRI acquisition protocols. Results show exceptional accuracy in noise-free conditions (relative L2 error of order O(1e-5)), robust performance with 10% noise (relative L2 error of order O(1e-2)), and effective reconstruction from sparse measurements (relative L2 error of order O(1e-2)). The online reconstruction achieves four-order-of-magnitude computational speed-up compared to full Finite Element (FE) simulations, with reconstruction times under one tenth of second for sparse scenarios, demonstrating significant potential for integration into clinical cardiac modeling workflows.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14844v1</guid>
      <category>physics.med-ph</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Francesco C. Mantegazza, Federica Caforio, Christoph Augustin, Matthias A. F. Gsell, Gundolf Haase, Elias Karabelas</dc:creator>
    </item>
    <item>
      <title>Efficient Computation of Time-Index Powered Weighted Sums Using Cascaded Accumulators</title>
      <link>https://arxiv.org/abs/2509.15069</link>
      <description>arXiv:2509.15069v1 Announce Type: cross 
Abstract: This letter presents a novel approach for \mbox{efficiently} computing time-index powered weighted sums of the form $\sum_{n=0}^{N-1} n^{K} v[n]$ using cascaded accumulators. Traditional direct computation requires $K{\times}N$ general multiplications, which become prohibitive for large $N$, while alternative strategies based on lookup tables or signal reversal require storing entire data blocks. By exploiting accumulator properties, the proposed method eliminates the need for such storage and reduces the multiplicative cost to only $K{+}1$ constant multiplications, enabling efficient real-time implementation. The approach is particularly useful when such sums need to be efficiently computed in sample-by-sample processing systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.15069v1</guid>
      <category>eess.SP</category>
      <category>cs.DS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Deijany Rodriguez Linares, Oksana Moryakova, H{\aa}kan Johansson</dc:creator>
    </item>
    <item>
      <title>Backward Reachability Analysis of Perturbed Continuous-Time Linear Systems Using Set Propagation</title>
      <link>https://arxiv.org/abs/2310.19083</link>
      <description>arXiv:2310.19083v3 Announce Type: replace 
Abstract: Backward reachability analysis computes the set of states that reach a target set under the competing influence of control input and disturbances. Depending on their interplay, the backward reachable set either represents all states that can be steered into the target set or all states that cannot avoid entering it -- the corresponding solutions can be used for controller synthesis and safety verification, respectively. A popular technique for backward reachable set computation solves Hamilton-Jacobi-Isaacs equations, which scales exponentially with the state dimension due to gridding the state space. In this work, we instead use set propagation techniques to design backward reachability algorithms for linear time-invariant systems. Crucially, the proposed algorithms scale only polynomially with the state dimension. Our numerical examples demonstrate the tightness of the obtained backward reachable sets and show an overwhelming improvement of our proposed algorithms over state-of-the-art methods regarding scalability, as systems with well over a hundred states can now be analyzed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.19083v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TAC.2025.3592719</arxiv:DOI>
      <dc:creator>Mark Wetzlinger, Matthias Althoff</dc:creator>
    </item>
    <item>
      <title>Hybrid Schwarz preconditioners for linear systems arising from hp-discontinuous Galerkin method</title>
      <link>https://arxiv.org/abs/2502.06405</link>
      <description>arXiv:2502.06405v2 Announce Type: replace 
Abstract: We deal with the numerical solution of linear elliptic problems with varying diffusion coefficient by the $hp$-discontinuous Galerkin method. We develop a two-level hybrid Schwarz preconditioner for the arising linear algebraic systems. The preconditioner is additive with respect to the local components and multiplicative with respect to the mesh levels. We derive the $hp$ spectral bound of the preconditioned operator in the form $O((H/h)(p^2/q))$, where $H$ and $h$ are the element sizes of the coarse and fine meshes, respectively, and $p$ and $q$ are the polynomial approximation degrees on the fine and coarse meshes. Further, we present a numerical study comparing the hybrid Schwarz preconditioner with the standard additive one from the point of view of the speed of convergence and also computational costs. Moreover, we investigate the convergence of both techniques with respect to the diffusivity variation and to the domain decomposition (non-)respecting the material interfaces. Finally, the combination with a $hp$-mesh adaptation for the solution of nonlinear problem demonstrates the potential of this approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06405v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vit Dolejsi, Tomas Hammerbauer</dc:creator>
    </item>
    <item>
      <title>Trace Ratio vs Ratio Trace Methods for Multidimensional Dimensionality Reduction</title>
      <link>https://arxiv.org/abs/2502.11074</link>
      <description>arXiv:2502.11074v2 Announce Type: replace 
Abstract: We propose a higher-order dimensionality reduction framework based on the Trace Ratio (TR) optimization problem. We establish conditions for existence and uniqueness of solutions and clarify the theoretical connection between the Trace Ratio and its surrogate, the Ratio Trace (RT) formulation. Building on these foundations, we design a Newton-type iterative algorithm that operates directly in the tensor domain via the Einstein product, avoiding data flattening and preserving multi-dimensional structure.
  This approach extends classical Linear Discriminant Analysis (LDA) to higher-order tensors, offering a natural generalization of trace-based dimensionality reduction from matrices to tensors. Numerical experiments on several benchmark datasets confirm the efficiency and robustness of the proposed methods, showing consistent improvements over existing matrix- and tensor-based techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.11074v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alaeddine Zahir, Franck Dufrenois, Khalide Jbilou, Ahmed Ratnani</dc:creator>
    </item>
    <item>
      <title>A four-field mixed formulation for incompressible finite elasticity</title>
      <link>https://arxiv.org/abs/2503.00989</link>
      <description>arXiv:2503.00989v2 Announce Type: replace 
Abstract: In this work, we generalize the mass-conserving mixed stress (MCS) finite element method for Stokes equations [Gopalakrishnan J., Lederer P., and Sch\"oberl J., A mass conserving mixed stress formulation for the Stokes equations, IMA Journal of Numerical Analysis 40(3), 1838-1874 (2019)], involving normal velocity and tangential-normal stress continuous fields, to incompressible finite elasticity. By means of the three-field Hu-Washizu principle, introducing the displacement gradient and 1st Piola-Kirchhoff stress tensor as additional fields, we circumvent the inversion of the constitutive law. We lift the arising distributional derivatives of the displacement gradient to a regular auxiliary displacement gradient field. Static condensation can be applied at the element level, providing a global pure displacement problem to be solved. We present a stabilization motivated by Hybrid Discontinuous Galerkin methods. A solving algorithm is discussed, which asserts the solvability of the arising linearized subproblems for problems with physically positive eigenvalues. The excellent performance of the proposed method is corroborated by several numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00989v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guosheng Fu, Michael Neunteufel, Joachim Sch\"oberl, Adam Zdunek</dc:creator>
    </item>
    <item>
      <title>A Two-Level Direct Solver for the Hierarchical Poincar\'e-Steklov Method</title>
      <link>https://arxiv.org/abs/2503.04033</link>
      <description>arXiv:2503.04033v2 Announce Type: replace 
Abstract: We introduce a two-level direct solver for the Hierarchical Poincar\'e-Steklov (HPS) method for solving linear elliptic PDEs. HPS combines multidomain spectral collocation with a direct solver, enabling high-order discretizations for highly oscillatory solutions while preserving computational efficiency. Our method employs batched linear algebra routines with GPU acceleration to reduce the problem to subdomain interfaces, yielding a block-sparse linear system. This system is then factorized using a sparse direct solver that employs pivoting to achieve better numerical stability than the original HPS scheme. For a discretization of local order $p$ involving a total of $N$ degrees of freedom, the initial reduction step has asymptotic complexity $O(N p^6)$ in three dimensions. Nevertheless, the high efficiency of batched GPU routines makes the overall cost for practical purposes independent of polynomial order (for order $p=20$ or even higher). Additionally, the cost of the sparse direct solver is independent of the polynomial order. We present a description and justification of our method, along with numerical experiments on three-dimensional problems to evaluate its accuracy and performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.04033v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Joseph Kump, Anna Yesypenko, Per-Gunnar Martinsson</dc:creator>
    </item>
    <item>
      <title>Radial Basis Function Techniques for Neural Field Models on Surfaces</title>
      <link>https://arxiv.org/abs/2504.13379</link>
      <description>arXiv:2504.13379v2 Announce Type: replace 
Abstract: We present a numerical framework for solving neural field equations on surfaces using Radial Basis Function (RBF) interpolation and quadrature. Neural field models describe the evolution of macroscopic brain activity, but modeling studies often overlook the complex geometry of curved cortical domains. Traditional numerical methods, such as finite element or spectral methods, can be computationally expensive and challenging to implement on irregular domains. In contrast, RBF-based methods provide a flexible alternative by offering interpolation and quadrature schemes that efficiently handle arbitrary geometries with high-order accuracy. We first develop an RBF-based interpolatory projection framework for neural field models on general surfaces. Quadrature for both flat and curved domains are derived in detail, ensuring high-order accuracy and stability as they depend on RBF hyperparameters (basis functions, augmenting polynomials, and stencil size). Through numerical experiments, we demonstrate the convergence of our method, highlighting its advantages over traditional approaches in terms of flexibility and accuracy. We conclude with an exposition of numerical simulations of spatiotemporal activity on complex surfaces, illustrating the method's ability to capture complex wave propagation patterns.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.13379v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>nlin.PS</category>
      <category>q-bio.NC</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sage B Shaw, Zachary P Kilpatrick, Daniele Avitabile</dc:creator>
    </item>
    <item>
      <title>A deep solver for backward stochastic Volterra integral equations</title>
      <link>https://arxiv.org/abs/2505.18297</link>
      <description>arXiv:2505.18297v3 Announce Type: replace 
Abstract: We present the first deep-learning solver for backward stochastic Volterra integral equations (BSVIEs) and their fully-coupled forward-backward variants. The method trains a neural network to approximate the two solution fields in a single stage, avoiding the use of nested time-stepping cycles that limit classical algorithms. For the decoupled case we prove a non-asymptotic error bound composed of an a posteriori residual plus the familiar square root dependence on the time step. Numerical experiments confirm this rate and reveal two key properties: \emph{scalability}, in the sense that accuracy remains stable from low dimension up to 500 spatial variables while GPU batching keeps wall-clock time nearly constant; and \emph{generality}, since the same method handles coupled systems whose forward dynamics depend on the backward solution. These results open practical access to a family of high-dimensional, path-dependent problems in stochastic control and quantitative finance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18297v3</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.PR</category>
      <category>q-fin.MF</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kristoffer Andersson, Alessandro Gnoatto, Camilo Andr\'es Garc\'ia Trillos</dc:creator>
    </item>
    <item>
      <title>A convergent Fourier spectral Galerkin method for the fractional Camassa-Holm equation</title>
      <link>https://arxiv.org/abs/2508.13683</link>
      <description>arXiv:2508.13683v2 Announce Type: replace 
Abstract: We analyze a Fourier spectral Galerkin method for the fractional Camassa-Holm (fCH) equation involving a fractional Laplacian of exponent $\alpha \in [1,2]$ with periodic boundary conditions. The semi-discrete scheme preserves both mass and energy invariants of the fCH equation. For the fractional Benjamin-Bona-Mahony reduction, we establish existence and uniqueness of semi-discrete solutions and prove strong convergence to the unique solution in $ C^1([0, T];H^{\alpha}_{\mathrm{per}}(I))$ for given $T&gt;0$. For the general fCH equation, we demonstrate spectral accuracy in spatial discretization with optimal error estimates $\mathcal{O}(N^{-r})$ for initial data $u_0 \in H^r(I)$ with $r \geq \alpha + 2$ and exponential convergence $\mathcal{O}(e^{-cN})$ for smooth solutions. Numerical experiments validate orbital stability of solitary waves achieving optimal convergence, confirming theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.13683v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Mukul Dwivedi, Andreas Rupp</dc:creator>
    </item>
    <item>
      <title>Explicit Runge-Kutta schemes for Backward Stochastic Differential Equations</title>
      <link>https://arxiv.org/abs/2508.18707</link>
      <description>arXiv:2508.18707v2 Announce Type: replace 
Abstract: The Butcher theory provides a powerful tool for analyzing order conditions of Runge-Kutta schemes for ordinary differential equations (ODEs); however, such a theory has not yet been well established for backward stochastic differential equations (BSDEs) -- motivating the current work to address this gap. Specifically, we propose a new class of explicit Runge-Kutta schemes for BSDEs. These schemes admit a concise formulation that closely mirrors their ODE counterparts. Building on this formulation, we extend the Butcher theory to the proposed schemes, thereby enabling a symbolic derivation of Taylor expansions for the local truncation errors, and yielding the order conditions. Our approach preserves the elegance and generality of the original Butcher theory: it avoids stage-by-stage error expansions and provides a systematic, stage-inductive analysis, applicable to schemes with any number of stages and any target order. Numerical experiments support the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.18707v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shuixin Fang, Weidong Zhao, Tao Zhou</dc:creator>
    </item>
    <item>
      <title>Quasi-Monte Carlo integration over $\mathbb{R}^s$ with boundary-damping importance sampling</title>
      <link>https://arxiv.org/abs/2509.07509</link>
      <description>arXiv:2509.07509v2 Announce Type: replace 
Abstract: This paper proposes a new importance sampling (IS) that is tailored to quasi-Monte Carlo (QMC) integration over $\mathbb{R}^s$. IS introduces a multiplicative adjustment to the integrand by compensating the sampling from the proposal instead of the target distribution. Improper proposals result in severe adjustment factor for QMC. Our strategy is to first design a adjustment factor to meet desired regularities and then determine a tractable transport map from the standard uniforms to the proposal for using QMC quadrature points as inputs. The transport map has the effect of damping the boundary growth of the resulting integrand so that the effectiveness of QMC can be reclaimed. Under certain conditions on the original integrand, our proposed IS enjoys a fast convergence rate independently of the dimension $s$, making it amenable to high-dimensional problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.07509v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zexin Pan, Du Ouyang, Zhijian He</dc:creator>
    </item>
    <item>
      <title>Convergence of Pivoted Cholesky Algorithm for Lipschitz Kernels</title>
      <link>https://arxiv.org/abs/2509.13582</link>
      <description>arXiv:2509.13582v2 Announce Type: replace 
Abstract: We investigate the continuous analogue of the Cholesky factorization, namely the pivoted Cholesky algorithm. Our analysis establishes quantitative convergence guarantees for kernels of minimal smoothness. We prove that for a symmetric positive definite Lipschitz continuous kernel $K:\Omega\times \Omega \rightarrow \mathbb{R}$ on a compact domain $\Omega\subset\mathbb{R}^d$, the residual of the Cholesky algorithm with any pivoting strategy is uniformly bounded above by a constant multiple of the fill distance of pivots. In particular, our result implies that under complete pivoting (where the maximum value of the diagonal of the residual is selected as the next pivot): \begin{equation*}
  \|R_n\|_{\infty} = O(n^{-1/d}), \end{equation*} where $R_n$ is the residual after $n$ Cholesky steps and $\|\cdot\|_\infty$ is the absolute maximum value of $R_n$. Moreover, if $K$ is differentiable in both variables with a Lipschitz derivative, our convergence rate improves to $O(n^{-2/d})$. Our result closes a gap between theory and practice as previous analyses required $C^2$-regularity of $K$ to establish convergence, whereas empirical evidence indicated robust performance even for non-differentiable kernels. We further detail how our convergence results propagate to downstream applications, including discrete analogues, Gaussian process regression, and the P-greedy interpolation method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.13582v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sungwoo Jeong, Alex Townsend</dc:creator>
    </item>
    <item>
      <title>A mathematical model for Nordic skiing</title>
      <link>https://arxiv.org/abs/2410.02767</link>
      <description>arXiv:2410.02767v2 Announce Type: replace-cross 
Abstract: Nordic skiing provides fascinating opportunities for mathematical modelling studies that exploit methods and insights from physics, applied mathematics, data analysis, scientific computing and sports science. A typical ski course winds over varied terrain with frequent changes in elevation and direction, and so its geometry is naturally described by a three-dimensional space curve. The skier travels along a course under the influence of various forces, and their dynamics can be described using a nonlinear system of ordinary differential equations (ODEs) that are derived from Newton's laws of motion. We develop an algorithm for solving the governing equations that combines Hermite spline interpolation, numerical quadrature and a high-order ODE solver. Numerical simulations are compared with measurements of skiers on actual courses to demonstrate the effectiveness of the model. Throughout, we aim to illustrate how elementary concepts from undergraduate courses in calculus and scientific computing can be applied to study real problems in sport, which we hope will provide stimulating examples for both instructors and students. At the same time, we demonstrate how these concepts are capable of providing novel insights into skiing that should also be of interest to sport scientists.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02767v2</guid>
      <category>physics.class-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jane Shaw MacDonald, Rafael Ordo\~nez Cardales, John M. Stockie</dc:creator>
    </item>
    <item>
      <title>Advanced Physics-Informed Neural Network with Residuals for Solving Complex Integral Equations</title>
      <link>https://arxiv.org/abs/2501.16370</link>
      <description>arXiv:2501.16370v3 Announce Type: replace-cross 
Abstract: In this paper, we present the Residual Integral Solver Network (RISN), a novel neural network architecture designed to solve a wide range of integral and integro-differential equations, including one-dimensional, multi-dimensional, ordinary and partial integro-differential, systems, fractional types, and Helmholtz-type integral equations involving oscillatory kernels. RISN integrates residual connections with high-accuracy numerical methods such as Gaussian quadrature and fractional derivative operational matrices, enabling it to achieve higher accuracy and stability than traditional Physics-Informed Neural Networks (PINN). The residual connections help mitigate vanishing gradient issues, allowing RISN to handle deeper networks and more complex kernels, particularly in multi-dimensional problems. Through extensive experiments, we demonstrate that RISN consistently outperforms not only classical PINNs but also advanced variants such as Auxiliary PINN (A-PINN) and Self-Adaptive PINN (SA-PINN), achieving significantly lower Mean Absolute Errors (MAE) across various types of equations. These results highlight RISN's robustness and efficiency in solving challenging integral and integro-differential problems, making it a valuable tool for real-world applications where traditional methods often struggle.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.16370v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NA</category>
      <category>cs.NE</category>
      <category>math.NA</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mahdi Movahedian Moghaddam, Kourosh Parand, Saeed Reza Kheradpisheh</dc:creator>
    </item>
    <item>
      <title>A preconditioned third-order implicit-explicit algorithm with a difference of varying convex functions and extrapolation</title>
      <link>https://arxiv.org/abs/2509.09391</link>
      <description>arXiv:2509.09391v2 Announce Type: replace-cross 
Abstract: This paper proposes a novel preconditioned implicit-explicit algorithm enhanced with the extrapolation technique for non-convex optimization problems. The algorithm employs a third-order Adams-Bashforth scheme for the nonlinear and explicit parts and a third-order backward differentiation formula for the implicit part of the gradient flow in variational functions. The proposed algorithm, akin to a generalized difference-of-convex (DC) approach, employs a changing set of convex functions in each iteration. Under the Kurdyka-\L ojasiewicz (KL) properties, the global convergence of the algorithm is guaranteed, ensuring that it converges within a finite number of preconditioned iterations. Our numerical experiments, including least squares problems with SCAD regularization and the graphical Ginzburg-Landau model, demonstrate the proposed algorithm's highly efficient performance compared to conventional DC algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.09391v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Kelin Wu, Hongpeng Sun</dc:creator>
    </item>
  </channel>
</rss>
