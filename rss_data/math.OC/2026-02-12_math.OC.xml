<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 12 Feb 2026 05:00:13 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Normal cones to sublevel sets of convex and quasi-convex supremum functions</title>
      <link>https://arxiv.org/abs/2602.10342</link>
      <description>arXiv:2602.10342v1 Announce Type: new 
Abstract: We provide sharp and explicit characterizations of the normal cone to sublevel sets of suprema of arbitrary functions, expressed exclusively in terms of subdifferentials of the data functions. In the convex case, the resulting formulas involve the approximate subdifferential of the individual data functions at the nominal point. In contrast, the quasi-convex framework requires the use of the Fr\'echet subdifferential of these data functions but evaluated at nearby points. These results are applied to derive optimality conditions for infinite convex and quasi-convex optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10342v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Stephanie Caro, Rafael Correa, Abderrahim Hantoute</dc:creator>
    </item>
    <item>
      <title>Relationships between full-space and subspace quadratic interpolation models and simplex derivatives</title>
      <link>https://arxiv.org/abs/2602.10374</link>
      <description>arXiv:2602.10374v1 Announce Type: new 
Abstract: Quadratic interpolation models and simplex derivatives are fundamental tools in numerical optimization, particularly in derivative-free optimization. When constructed in suitably chosen affine subspaces, these tools have been shown to be especially effective for high-dimensional derivative-free optimization problems, where full-space model construction is often impractical. In this paper, we analyze the relationships between full-space and subspace formulations of these tools. In particular, we derive explicit conversion formulas between full-space and subspace models, including minimum-norm models, minimum Frobenius norm models, least Frobenius norm updating models, as well as models constructed via generalized simplex gradients and Hessians. We show that the full-space and subspace models coincide on the affine subspace and, in general, along directions in the orthogonal complement. Overall, our results provide a theoretical framework for understanding subspace approximation techniques and offer insight into the design and analysis of derivative-free optimization methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10374v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yiwen Chen</dc:creator>
    </item>
    <item>
      <title>Active set identification and rapid convergence for degenerate primal-dual problems</title>
      <link>https://arxiv.org/abs/2602.10436</link>
      <description>arXiv:2602.10436v1 Announce Type: new 
Abstract: Primal-dual methods for solving convex optimization problems with functional constraints often exhibit a distinct two-stage behavior. Initially, they converge towards a solution at a sublinear rate. Then, after a certain point, the method identifies the set of active constraints and the convergence enters a faster local linear regime. Theory characterizing this phenomenon spans over three decades. However, most existing work only guarantees eventual identification of the active set and relies heavily on nondegeneracy conditions, such as strict complementarity, which often fail to hold in practice. We characterize mild conditions on the problem geometry and the algorithm under which this phenomenon provably occurs. Our guarantees are entirely nonasymptotic and, importantly, do not rely on strict complementarity. Our framework encompasses several widely-used algorithms, including the proximal point method, the primal-dual hybrid gradient method, the alternating direction method of multipliers, and the extragradient method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10436v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mateo D\'iaz, Pedro Izquierdo Lehmann, Haihao Lu, Jinwen Yang</dc:creator>
    </item>
    <item>
      <title>Distributed Online Convex Optimization with Nonseparable Costs and Constraints</title>
      <link>https://arxiv.org/abs/2602.10452</link>
      <description>arXiv:2602.10452v1 Announce Type: new 
Abstract: This paper studies distributed online convex optimization with time-varying coupled constraints, motivated by distributed online control in network systems. Most prior work assumes a separability condition: the global objective and coupled constraint functions are sums of local costs and individual constraints. In contrast, we study a group of agents, networked via a communication graph, that collectively select actions to minimize a sequence of nonseparable global cost functions and to stratify nonseparable long-term constraints based on full-information feedback and intra-agent communication. We propose a distributed online primal-dual belief consensus algorithm, where each agent maintains and updates a local belief of the global collective decisions, which are repeatedly exchanged with neighboring agents. Unlike the previous consensus primal-dual algorithms under separability that ask agents to only communicate their local decisions, our belief-sharing protocol eliminates coupling between the primal consensus disagreement and the dual constraint violation, yielding sublinear regret and cumulative constraint violation (CCV) bounds, both in $O({T}^{1/2})$, where $T$ denotes the time horizon. Such a result breaks the long-standing $O(T^{3/4})$ barrier for CCV and matches the lower bound of online constrained convex optimization, indicating the online learning efficiency at the cost of communication overhead.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10452v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhaoye Pan, Haozhe Lei, Fan Zuo, Zilin Bian, Tao Li</dc:creator>
    </item>
    <item>
      <title>Unlocked Backpropagation using Wave Scattering</title>
      <link>https://arxiv.org/abs/2602.10461</link>
      <description>arXiv:2602.10461v1 Announce Type: new 
Abstract: Both the backpropagation algorithm in machine learning and the maximum principle in optimal control theory are posed as a two-point boundary problem, resulting in a "forward-backward" lock. We derive a reformulation of the maximum principle in optimal control theory as a hyperbolic initial value problem by introducing an additional "optimization time" dimension. We introduce counter-propagating wave variables with finite propagation speed and recast the optimization problem in terms of scattering relationships between them. This relaxation of the original problem can be interpreted as a physical system that equilibrates and changes its physical properties in order to minimize reflections. We discretize this continuum theory to derive a family of fully unlocked algorithms suitable for training neural networks. Different parameter dynamics, including gradient descent, can be derived by demanding dissipation and minimization of reflections at parameter ports. These results also imply that any physical substrate that supports the scattering and dissipation of waves can be interpreted as solving an optimization problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10461v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christian Pehle, Jean-Jacques Slotine</dc:creator>
    </item>
    <item>
      <title>Revisiting Superlinear Convergence of Proximal Newton-Like Methods to Degenerate Solutions</title>
      <link>https://arxiv.org/abs/2602.10470</link>
      <description>arXiv:2602.10470v1 Announce Type: new 
Abstract: We describe inexact proximal Newton-like methods for solving degenerate regularized optimization problems and for the broader problem of
  finding a zero of a generalized equation that is the sum of a continuous map and a maximal monotone operator. Superlinear convergence for both the distance to the solution set and a certain measure of first-order optimality can be achieved under a H\"olderian error bound condition, including for problems in which the continuous map is nonmonotone, with Jacobian singular at the solution and not Lipschitz. Superlinear convergence is attainable even when the Jacobian is merely uniformly continuous, relaxing the standard Lipschitz assumption to its theoretical limit. For convex regularized optimization problems, we introduce a novel globalization strategy that ensures strict objective decrease and avoids the Maratos effect, attaining local $Q$-superlinear convergence without prior knowledge of problem parameters. Unit step size acceptance in our line search strategy does not rely on continuity or even existence of the Hessian of the smooth term in the objective, making the framework compatible with other potential candidates for superlinearly convergent updates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10470v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ching-pei Lee, Stephen J. Wright</dc:creator>
    </item>
    <item>
      <title>Almost Sure Convergence of Nonlinear Stochastic Approximation: An Interplay of Noise and Step Size</title>
      <link>https://arxiv.org/abs/2602.10580</link>
      <description>arXiv:2602.10580v1 Announce Type: new 
Abstract: We study the almost sure convergence of the Stochastic Approximation algorithm to the fixed point $x^\star$ of a nonlinear operator under a negative drift condition and a general noise sequence with finite $p$-th moment for some $p &gt; 1$. Classical almost sure convergence results of Stochastic Approximation are mostly analyzed for the square-integrable noise setting, and it is shown that any non-summable but square-summable step size sequence is sufficient to obtain almost sure convergence. However, such a limitation prevents wider algorithmic application. In particular, many applications in Machine Learning and Operations Research admit heavy-tailed noise with infinite variance, rendering such guarantees inapplicable. On the other hand, when a stronger condition on the noise is available, such guarantees on the step size would be too conservative, as practitioners would like to pick a larger step size for a more preferable convergence behavior. To this end, we show that any non-summable but $p$-th power summable step size sequence is sufficient to guarantee almost sure convergence, covering the gap in the literature.
  Our guarantees are obtained using a universal Lyapunov drift argument. For the regime $p \in (1, 2)$, we show that using the Lyapunov function $\norm{x-x^\star}^p$ and applying a Taylor-like bound suffice. For $p &gt; 2$, such an approach is no longer applicable, and therefore, we introduce a novel iterate projection technique to control the nonlinear terms produced by high-moment bounds and multiplicative noise. We believe our proof techniques and their implications could be of independent interest and pave the way for finite-time analysis of Stochastic Approximation under a general noise condition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10580v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Quang Dinh Thien Nguyen, Duc Anh Nguyen, Hoang Huy Nguyen, Siva Theja Maguluri</dc:creator>
    </item>
    <item>
      <title>Fast and Large-Scale Unbalanced Optimal Transport via its Semi-Dual and Adaptive Gradient Methods</title>
      <link>https://arxiv.org/abs/2602.10697</link>
      <description>arXiv:2602.10697v1 Announce Type: new 
Abstract: Unbalanced Optimal Transport (UOT) has emerged as a robust relaxation of standard Optimal Transport, particularly effective for handling outliers and mass variations. However, scalable algorithms for UOT, specifically those based on Gradient Descent (SGD), remain largely underexplored. In this work, we address this gap by analyzing the semi-dual formulation of Entropic UOT and demonstrating its suitability for adaptive gradient methods. While the semi-dual is a standard tool for large-scale balanced OT, its geometry in the unbalanced setting appears ill-conditioned under standard analysis. Specifically, worst-case bounds on the marginal penalties using $\chi^2$ divergence suggest a condition number scaling with $n/\varepsilon$, implying poor scalability. In contrast, we show that the local condition number actually scales as $\mathcal{O}(1/\varepsilon)$, effectively removing the ill-conditioned dependence on $n$. Exploiting this property, we prove that SGD methods adapt to this local curvature, achieving a convergence rate of $\mathcal{O}(n/\varepsilon T)$ in the stochastic and online regimes, making it suitable for large-scale and semi-discrete applications. Finally, for the full batch discrete setting, we derive a nearly tight upper bound on local smoothness depending solely on the gradient. Using it to adapt step sizes, we propose a modified Adaptive Nesterov Accelerated Gradient (ANAG) method on the semi-dual functional and prove that it achieves a local complexity of $\mathcal{O}(n^2\sqrt{1/\varepsilon}\ln(1/\delta))$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10697v1</guid>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ferdinand Genans (SU, LPSM)</dc:creator>
    </item>
    <item>
      <title>Mirror descent actor-critic methods for entropy regularised MDPs in general spaces: stability and convergence</title>
      <link>https://arxiv.org/abs/2602.10838</link>
      <description>arXiv:2602.10838v1 Announce Type: new 
Abstract: We provide theoretical guarantees for convergence of discrete-time policy mirror descent with inexact advantage functions updated using temporal difference (TD) learning for entropy regularised MDPs in Polish state and action spaces. We rigorously derive sufficient conditions under which the single-loop actor-critic scheme is stable and convergent. To weaken these conditions, we introduce a variant that performs multiple TD steps per policy update and derive an explicit lower bound on the number of TD steps required to ensure stability. Finally, we establish sub-linear convergence when the number of TD steps grows logarithmically with the number of policy updates, and linear convergence when it grows linearly under a concentrability assumption.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10838v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Denis Zorba, David \v{S}i\v{s}ka, Lukasz Szpruch</dc:creator>
    </item>
    <item>
      <title>Managing delay in tail assignment: from minimum turn time to stochastic routing at Air France</title>
      <link>https://arxiv.org/abs/2602.10866</link>
      <description>arXiv:2602.10866v1 Announce Type: new 
Abstract: On-time performance is a critical challenge in the airline industry, leading to large operational and customer dissatisfaction costs. The tail assignment problem builds the sequences of flights or routes followed by individual airplanes. While airlines cannot avoid some sources of delay, choosing routes wisely limits propagation along these. This paper addresses the stochastic tail assignment problem at Air France. We propose a column generation approach for this problem. The key ingredient is the pricing algorithm, which is a stochastic shortest path problem. We use dedicated bounds to discard paths in an enumeration algorithm, and introduce new bounds based on a lattice ordering of the set of piecewise linear convex functions to strike a balance between bounds quality and computational cost. A diving heuristic enables us to retrieve integer solutions. Numerical experiments on real-world Air France instances demonstrate that our algorithms lead to an average 0.28% optimality gap on instances with up to 600 flight legs in a few hours of computing time. The resulting solutions effectively balance operational costs and delay resilience, outperforming previous approaches based on minimum turn time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10866v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>L\'eo Baty, Axel Parmentier</dc:creator>
    </item>
    <item>
      <title>Data assimilation via model reference adaptation for linear and nonlinear dynamical systems</title>
      <link>https://arxiv.org/abs/2602.10920</link>
      <description>arXiv:2602.10920v1 Announce Type: new 
Abstract: We address data assimilation for linear and nonlinear dynamical systems via the so-called \emph{model reference adaptive system}. Continuing our theoretical developments in \cite{Tram_Kaltenbacher_2021}, we deliver the first practical implementation of this approach for online parameter identification with time series data. Our semi-implicit scheme couples a modified state equation with a parameter evolution law that is driven by model-data residuals. We demonstrate four benchmark problems of increasing complexity: the Darcy flow, the Fisher-KPP equation, a nonlinear potential equation and finally, an Allen-Cahn type equation. Across all cases, explicit model reference adaptive system construction, verified assumptions and numerically stable reconstructions underline our proposed method as a reliable, versatile tool for data assimilation and real-time inversion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10920v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <category>math.DS</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Benedikt Kaltenbach, Christian Aarset, Tram Thi Ngoc Nguyen</dc:creator>
    </item>
    <item>
      <title>Adversarial Graph Traversal</title>
      <link>https://arxiv.org/abs/2602.11048</link>
      <description>arXiv:2602.11048v1 Announce Type: new 
Abstract: Suppose a Bayesian agent seeks to traverse a graph. Each time she crosses an edge, she pays a price. The first time she reaches a node, there is a payoff. She has an opponent who can reduce the payoffs. This paper uses adversarial risk analysis to find a solution to her route selection problem. It shows how the traveler is advantaged by having an accurate subjective distribution over the costs/payoffs and by having a Bayesian prior for her opponent's strategic choices. The results are relevant to military convoy routing, corporate competition, and certain games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11048v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David Banks, Elvan Ceyhan, Leah Johnson, Li Zhou</dc:creator>
    </item>
    <item>
      <title>Causal-Informed Hybrid Online Adaptive Optimization for Ad Load Personalization in Large-Scale Social Networks</title>
      <link>https://arxiv.org/abs/2602.10129</link>
      <description>arXiv:2602.10129v1 Announce Type: cross 
Abstract: Personalizing ad load in large-scale social networks requires balancing user experience and conversions under operational constraints. Traditional primal-dual methods enforce constraints reliably but adapt slowly in dynamic environments, while Bayesian Optimization (BO) enables exploration but suffers from slow convergence. We propose a hybrid online adaptive optimization framework CTRCBO ( Cohort-Based Trust Region Contextual Bayesian Optimization), combining primal-dual with BO, enhanced by trust-region updates and Gaussian Process Regression (GPR) surrogates for both objectives and constraints. Our approach leverages a upstream Causal ML model to inform the surrogate, improving decision quality and enabling efficient exploration-exploitation and online tuning. We evaluate our method on a billion-user social network, demonstrating faster convergence, robust constraint satisfaction, and improved personalization metrics, including real-world online AB test results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10129v1</guid>
      <category>cs.SI</category>
      <category>math.OC</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Aakash Mishra, Qi Xu, Zhigang Hua, Keyu Nie, Vishwanath Sangale, Vishal Vaingankar, Jizhe Zhang, Ren Mao</dc:creator>
    </item>
    <item>
      <title>Adaptive Optimization via Momentum on Variance-Normalized Gradients</title>
      <link>https://arxiv.org/abs/2602.10204</link>
      <description>arXiv:2602.10204v1 Announce Type: cross 
Abstract: We introduce MVN-Grad (Momentum on Variance-Normalized Gradients), an Adam-style optimizer that improves stability and performance by combining two complementary ideas: variance-based normalization and momentum applied after normalization. MVN-Grad scales each coordinate by an exponential moving average of gradient uncertainty and applies momentum to the resulting normalized gradients, eliminating the cross-time coupling between stale momentum and a stochastic normalizer present in standard Adam-type updates. We prove that this decoupling yields strictly smaller one-step conditional update variance than momentum-then-normalize variance methods under standard noise assumptions, and that MVN-Grad is robust to outliers: it has a uniformly bounded response to single gradient spikes.
  In low-variance regimes, we further show variance normalization avoids sign-type collapse associated with second-moment scaling and can yield accelerated convergence. Across CIFAR-100 image classification and GPT-style language modeling benchmarks, MVN-Grad matches or outperforms Adam, AdaBelief, and LaProp, delivering smoother training and improved generalization with no added overhead.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10204v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Francisco Patitucci, Aryan Mokhtari</dc:creator>
    </item>
    <item>
      <title>ImprovEvolve: Ask AlphaEvolve to Improve the Input Solution and Then Improvise</title>
      <link>https://arxiv.org/abs/2602.10233</link>
      <description>arXiv:2602.10233v1 Announce Type: cross 
Abstract: Recent advances in LLM-guided evolutionary computation, particularly AlphaEvolve, have demonstrated remarkable success in discovering novel mathematical constructions and solving challenging optimization problems. In this article, we present ImprovEvolve, a simple yet effective technique for enhancing LLM-based evolutionary approaches such as AlphaEvolve. Given an optimization problem, the standard approach is to evolve program code that, when executed, produces a solution close to the optimum. We propose an alternative program parameterization that maintains the ability to construct optimal solutions while reducing the cognitive load on the LLM. Specifically, we evolve a program (implementing, e.g., a Python class with a prescribed interface) that provides the following functionality: (1) propose a valid initial solution, (2) improve any given solution in terms of fitness, and (3) perturb a solution with a specified intensity. The optimum can then be approached by iteratively applying improve() and perturb() with a scheduled intensity. We evaluate ImprovEvolve on challenging problems from the AlphaEvolve paper: hexagon packing in a hexagon and the second autocorrelation inequality. For hexagon packing, the evolved program achieves new state-of-the-art results for 11, 12, 15, and 16 hexagons; a lightly human-edited variant further improves results for 14, 17, and 23 hexagons. For the second autocorrelation inequality, the human-edited program achieves a new state-of-the-art lower bound of 0.96258, improving upon AlphaEvolve's 0.96102.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10233v1</guid>
      <category>cs.NE</category>
      <category>cs.AI</category>
      <category>math.CA</category>
      <category>math.MG</category>
      <category>math.OC</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexey Kravatskiy, Valentin Khrulkov, Ivan Oseledets</dc:creator>
    </item>
    <item>
      <title>Solving Geodesic Equations with Composite Bernstein Polynomials for Trajectory Planning</title>
      <link>https://arxiv.org/abs/2602.10365</link>
      <description>arXiv:2602.10365v1 Announce Type: cross 
Abstract: This work presents a trajectory planning method based on composite Bernstein polynomials for autonomous systems navigating complex environments. The method is implemented in a symbolic optimization framework that enables continuous paths and precise control over trajectory shape. Trajectories are planned over a cost surface that encodes obstacles as continuous fields rather than discrete boundaries. Regions near obstacles are assigned higher costs, naturally encouraging the trajectory to maintain a safe distance while still allowing efficient routing through constrained spaces. The use of composite Bernstein polynomials preserves continuity while enabling fine control over local curvature to satisfy geodesic constraints. The symbolic representation supports exact derivatives, improving optimization efficiency. The method applies to both two- and three-dimensional environments and is suitable for ground, aerial, underwater, and space systems. In spacecraft trajectory planning, for example, it enables the generation of continuous, dynamically feasible trajectories with high numerical efficiency, making it well suited for orbital maneuvers, rendezvous and proximity operations, cluttered gravitational environments, and planetary exploration missions with limited onboard computational resources. Demonstrations show that the approach efficiently generates smooth, collision-free paths in scenarios with multiple obstacles, maintaining clearance without extensive sampling or post-processing. The optimization incorporates three constraint types: (1) a Gaussian surface inequality enforcing minimum obstacle clearance; (2) geodesic equations guiding the path along locally efficient directions on the cost surface; and (3) boundary constraints enforcing fixed start and end conditions. The method can serve as a standalone planner or as an initializer for more complex motion planning problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10365v1</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nick Gorman, Gage MacLin, Maxwell Hammond, Venanzio Cichella</dc:creator>
    </item>
    <item>
      <title>Constructing Industrial-Scale Optimization Modeling Benchmark</title>
      <link>https://arxiv.org/abs/2602.10450</link>
      <description>arXiv:2602.10450v1 Announce Type: cross 
Abstract: Optimization modeling underpins decision-making in logistics, manufacturing, energy, and finance, yet translating natural-language requirements into correct optimization formulations and solver-executable code remains labor-intensive. Although large language models (LLMs) have been explored for this task, evaluation is still dominated by toy-sized or synthetic benchmarks, masking the difficulty of industrial problems with $10^{3}$--$10^{6}$ (or more) variables and constraints. A key bottleneck is the lack of benchmarks that align natural-language specifications with reference formulations/solver code grounded in real optimization models. To fill in this gap, we introduce MIPLIB-NL, built via a structure-aware reverse construction methodology from real mixed-integer linear programs in MIPLIB~2017. Our pipeline (i) recovers compact, reusable model structure from flat solver formulations, (ii) reverse-generates natural-language specifications explicitly tied to this recovered structure under a unified model--data separation format, and (iii) performs iterative semantic validation through expert review and human--LLM interaction with independent reconstruction checks. This yields 223 one-to-one reconstructions that preserve the mathematical content of the original instances while enabling realistic natural-language-to-optimization evaluation. Experiments show substantial performance degradation on MIPLIB-NL for systems that perform strongly on existing benchmarks, exposing failure modes invisible at toy scale.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10450v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Zhong Li, Hongliang Lu, Tao Wei, Wenyu Liu, Yuxuan Chen, Yuan Lan, Fan Zhang, Zaiwen Wen</dc:creator>
    </item>
    <item>
      <title>Informal and Privatized Transit: Incentives, Efficiency and Coordination</title>
      <link>https://arxiv.org/abs/2602.10456</link>
      <description>arXiv:2602.10456v1 Announce Type: cross 
Abstract: Informal and privatized transit services, such as minibuses and shared auto-rickshaws, are integral to daily travel in large urban metropolises, providing affordable commutes where a formal public transport system is inadequate and other options are unaffordable. Despite the crucial role that these services play in meeting mobility needs, governments often do not account for these services or their underlying incentives when planning transit systems, which can significantly compromise system efficiency.
  Against this backdrop, we develop a framework to analyze the incentives underlying informal and privatized transit systems, while proposing mechanisms to guide public transit operation and incentive design when a substantial share of mobility is provided by such profit-driven private operators. We introduce a novel, analytically tractable game-theoretic model of a fully privatized informal transit system with a fixed menu of routes, in which profit-maximizing informal operators (drivers) decide where to provide service and cost-minimizing commuters (riders) decide whether to use these services. Within this framework, we establish tight price of anarchy bounds which demonstrate that decentralized, profit-maximizing driver behavior can lead to bounded yet substantial losses in cumulative driver profit and rider demand served. We further show that these performance losses can be mitigated through targeted interventions, including Stackelberg routing mechanisms in which a modest share of drivers are centrally controlled, reflecting environments where informal operators coexist with public transit, and cross-subsidization schemes that use route-specific tolls or subsidies to incentivize drivers to operate on particular routes. Finally, we reinforce these findings through numerical experiments based on a real-world informal transit system in Nalasopara, India.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10456v1</guid>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <category>math.OC</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Devansh Jalota, Matthew Tsao</dc:creator>
    </item>
    <item>
      <title>Online Generalized-mean Welfare Maximization: Achieving Near-Optimal Regret from Samples</title>
      <link>https://arxiv.org/abs/2602.10469</link>
      <description>arXiv:2602.10469v1 Announce Type: cross 
Abstract: We study online fair allocation of $T$ sequentially arriving items among $n$ agents with heterogeneous preferences, with the objective of maximizing generalized-mean welfare, defined as the $p$-mean of agents' time-averaged utilities, with $p\in (-\infty, 1)$. We first consider the i.i.d. arrival model and show that the pure greedy algorithm -- which myopically chooses the welfare-maximizing integral allocation -- achieves $\widetilde{O}(1/T)$ average regret. Importantly, in contrast to prior work, our algorithm does not require distributional knowledge and achieves the optimal regret rate using only the online samples.
  We then go beyond i.i.d. arrivals and investigate a nonstationary model with time-varying independent distributions. In the absence of additional data about the distributions, it is known that every online algorithm must suffer $\Omega(1)$ average regret. We show that only a single historical sample from each distribution is sufficient to recover the optimal $\widetilde{O}(1/T)$ average regret rate, even in the face of arbitrary non-stationarity. Our algorithms are based on the re-solving paradigm: they assume that the remaining items will be the ones seen historically in those periods and solve the resulting welfare-maximization problem to determine the decision in every period. Finally, we also account for distribution shifts that may distort the fidelity of historical samples and show that the performance of our re-solving algorithms is robust to such shifts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10469v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zongjun Yang, Rachitesh Kumar, Christian Kroer</dc:creator>
    </item>
    <item>
      <title>Online Min-Max Optimization: From Individual Regrets to Cumulative Saddle Points</title>
      <link>https://arxiv.org/abs/2602.10565</link>
      <description>arXiv:2602.10565v1 Announce Type: cross 
Abstract: We propose and study an online version of min-max optimization based on cumulative saddle points under a variety of performance measures beyond convex-concave settings. After first observing the incompatibility of (static) Nash equilibrium (SNE-Reg$_T$) with individual regrets even for strongly convex-strongly concave functions, we propose an alternate \emph{static} duality gap (SDual-Gap$_T$) inspired by the online convex optimization (OCO) framework. We provide algorithms that, using a reduction to classic OCO problems, achieve bounds for SDual-Gap$_T$~and a novel \emph{dynamic} saddle point regret (DSP-Reg$_T$), which we suggest naturally represents a min-max version of the dynamic regret in OCO. We derive our bounds for SDual-Gap$_T$~and DSP-Reg$_T$~under strong convexity-strong concavity and a min-max notion of exponential concavity (min-max EC), and in addition we establish a class of functions satisfying min-max EC~that captures a two-player variant of the classic portfolio selection problem. Finally, for a dynamic notion of regret compatible with individual regrets, we derive bounds under a two-sided Polyak-\L{}ojasiewicz (PL) condition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10565v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Abhijeet Vyas, Brian Bullins</dc:creator>
    </item>
    <item>
      <title>Stabilization of nonautonomous Navier-Stokes flows under dynamic slip boundary conditions</title>
      <link>https://arxiv.org/abs/2602.10678</link>
      <description>arXiv:2602.10678v1 Announce Type: cross 
Abstract: Exponential stabilizability of the incompressible Navier-Stokes equations under dynamic slip boundary conditions toward arbitrary time-dependent trajectories is proven. The feedback control law is constructed explicitly using oblique projections and realized through a finite number of spatially localized interior actuators, without requiring spectral assumptions. The approach extends to various slip boundary condition types (Navier, vorticity-type, and Neumann) and applies to multi-connected domains. Weak solution existence and exponential decay estimates are established, with the stabilization rate depending on the boundary dynamics parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10678v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Buddhika Priyasad, S\'ergio S. Rodrigues</dc:creator>
    </item>
    <item>
      <title>Robust Assortment Optimization from Observational Data</title>
      <link>https://arxiv.org/abs/2602.10696</link>
      <description>arXiv:2602.10696v1 Announce Type: cross 
Abstract: Assortment optimization is a fundamental challenge in modern retail and recommendation systems, where the goal is to select a subset of products that maximizes expected revenue under complex customer choice behaviors. While recent advances in data-driven methods have leveraged historical data to learn and optimize assortments, these approaches typically rely on strong assumptions -- namely, the stability of customer preferences and the correctness of the underlying choice models. However, such assumptions frequently break in real-world scenarios due to preference shifts and model misspecification, leading to poor generalization and revenue loss. Motivated by this limitation, we propose a robust framework for data-driven assortment optimization that accounts for potential distributional shifts in customer choice behavior. Our approach models potential preference shift from a nominal choice model that generates data and seeks to maximize worst-case expected revenue. We first establish the computational tractability of robust assortment planning when the nominal model is known, then advance to the data-driven setting, where we design statistically optimal algorithms that minimize the data requirements while maintaining robustness. Our theoretical analysis provides both upper bounds and matching lower bounds on the sample complexity, offering theoretical guarantees for robust generalization. Notably, we uncover and identify the notion of ``robust item-wise coverage'' as the minimal data requirement to enable sample-efficient robust assortment learning. Our work bridges the gap between robustness and statistical efficiency in assortment learning, contributing new insights and tools for reliable assortment optimization under uncertainty.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10696v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Miao Lu, Yuxuan Han, Han Zhong, Zhengyuan Zhou, Jose Blanchet</dc:creator>
    </item>
    <item>
      <title>The Wasserstein gradient flow of the Sinkhorn divergence between Gaussian distributions</title>
      <link>https://arxiv.org/abs/2602.10726</link>
      <description>arXiv:2602.10726v1 Announce Type: cross 
Abstract: We study the Wasserstein gradient flow of the Sinkhorn divergence when both the source and the target are Gaussian distributions. We prove the existence of a flow that stays in the class of Gaussian distributions, and is unique in the larger class of measures with strongly-concave and smooth log-densities. We prove that the flow globally converges toward the target measure when the source's covariance matrix is not singular, and provide counter-examples to global convergence when it is, giving a first answer to an open question raised in [Carlier et al. 2024, \S4.2]. When the covariance matrix of the source distribution commutes with that of the target, we derive more quantitative results that showcase exponential convergence toward the target when the source and the target share their support, but dropping to linear rates (O(t^{-1})) if the target is concentrated on a strict subspace of the source's support.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10726v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mathis Hardion (LIGM), Th\'eo Lacombe (LIGM)</dc:creator>
    </item>
    <item>
      <title>Trading in CEXs and DEXs with Priority Fees and Stochastic Delays</title>
      <link>https://arxiv.org/abs/2602.10798</link>
      <description>arXiv:2602.10798v1 Announce Type: cross 
Abstract: We develop a mixed control framework that combines absolutely continuous controls with impulse interventions subject to stochastic execution delays. The model extends current impulse control formulations by allowing (i) the controller to choose the mean of the stochastic delay of their impulses, and allowing (ii) for multiple pending orders, so that several impulses can be submitted and executed asynchronously at random times. The framework is motivated by an optimal trading problem between centralized (CEX) and decentralized (DEX) exchanges. In DEXs, traders control the distribution of the execution delay through the priority fee paid, introducing a fundamental trade-off between delays, uncertainty, and costs. We study the optimal trading problem of a trader exploiting trading signals in CEXs and DEXs. From a mathematical perspective, we derive the associated dynamic programming principle of this new class of impulse control problems, and establish the viscosity properties of the corresponding quasi-variational inequalities. From a financial perspective, our model provides insights on how to carry out execution across CEXs and DEXs, highlighting how traders manage latency risk optimally through priority fee selection. We show that employing the optimal priority fee has a significant outperformance over non-strategic fee selection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10798v1</guid>
      <category>q-fin.TR</category>
      <category>math.OC</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Philippe Bergault, Yadh Hafsi, Leandro S\'anchez-Betancourt</dc:creator>
    </item>
    <item>
      <title>Natural Hypergradient Descent: Algorithm Design, Convergence Analysis, and Parallel Implementation</title>
      <link>https://arxiv.org/abs/2602.10905</link>
      <description>arXiv:2602.10905v1 Announce Type: cross 
Abstract: In this work, we propose Natural Hypergradient Descent (NHGD), a new method for solving bilevel optimization problems. To address the computational bottleneck in hypergradient estimation--namely, the need to compute or approximate Hessian inverse--we exploit the statistical structure of the inner optimization problem and use the empirical Fisher information matrix as an asymptotically consistent surrogate for the Hessian. This design enables a parallel optimize-and-approximate framework in which the Hessian-inverse approximation is updated synchronously with the stochastic inner optimization, reusing gradient information at negligible additional cost. Our main theoretical contribution establishes high-probability error bounds and sample complexity guarantees for NHGD that match those of state-of-the-art optimize-then-approximate methods, while significantly reducing computational time overhead. Empirical evaluations on representative bilevel learning tasks further demonstrate the practical advantages of NHGD, highlighting its scalability and effectiveness in large-scale machine learning settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10905v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Deyi Kong, Zaiwei Chen, Shuzhong Zhang, Shancong Mou</dc:creator>
    </item>
    <item>
      <title>Tuning the burn-in phase in training recurrent neural networks improves their performance</title>
      <link>https://arxiv.org/abs/2602.10911</link>
      <description>arXiv:2602.10911v1 Announce Type: cross 
Abstract: Training recurrent neural networks (RNNs) with standard backpropagation through time (BPTT) can be challenging, especially in the presence of long input sequences. A practical alternative to reduce computational and memory overhead is to perform BPTT repeatedly over shorter segments of the training data set, corresponding to truncated BPTT. In this paper, we examine the training of RNNs when using such a truncated learning approach for time series tasks. Specifically, we establish theoretical bounds on the accuracy and performance loss when optimizing over subsequences instead of the full data sequence. This reveals that the burn-in phase of the RNN is an important tuning knob in its training, with significant impact on the performance guarantees. We validate our theoretical results through experiments on standard benchmarks from the fields of system identification and time series forecasting. In all experiments, we observe a strong influence of the burn-in phase on the training process, and proper tuning can lead to a reduction of the prediction error on the training and test data of more than 60% in some cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10911v1</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Julian D. Schiller, Malte Heinrich, Victor G. Lopez, Matthias A. M\"uller</dc:creator>
    </item>
    <item>
      <title>Trajectory-based data-driven predictive control and the state-space predictor</title>
      <link>https://arxiv.org/abs/2602.10936</link>
      <description>arXiv:2602.10936v1 Announce Type: cross 
Abstract: We define trajectory predictive control (TPC) as a family of output-feedback indirect data-driven predictive control (DDPC) methods that represent the output trajectory of a discrete-time system as a linear function of the recent input/output history and the planned input trajectory. This paper shows that for different choices of the trajectory predictor, TPC encompasses a wide variety of DDPC methods, including subspace predictive control (SPC), closed-loop SPC, $\gamma$-DDPC, causal-$\gamma$-DDPC, transient predictive control, and others. This paper introduces a trajectory predictor that corresponds to a linear state-space model with the recent input/output history as the state. With this state-space predictor, TPC is a special case of linear model predictive control and therefore inherits its mature theory. In numerical experiments, TPC performance approaches the limit of oracle $H_2$-optimal control with perfect knowledge of the underlying system model. For TPC with small training datasets, the state-space predictor outperforms other predictors because it has fewer parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10936v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Levi D. Reyes Premer, Arash J. Khabbazi, Kevin J. Kircher</dc:creator>
    </item>
    <item>
      <title>Stability Analysis of Geometric Control for a Canonical Class of Underactuated Aerial Vehicles with Spurious Forces</title>
      <link>https://arxiv.org/abs/2602.10961</link>
      <description>arXiv:2602.10961v1 Announce Type: cross 
Abstract: Standard geometric control relies on force-moment decoupling, an assumption that breaks down in many aerial platforms due to spurious forces naturally induced by control moments. While strategies for such coupled systems have been validated experimentally, a rigorous theoretical certification of their stability is currently missing. This work fills this gap by providing the first formal stability analysis for a generic class of floating rigid bodies subject to spurious forces. We introduce a canonical model and construct a Lyapunov-based proof establishing local exponential stability of the hovering equilibrium. Crucially, the analysis explicitly addresses the structural challenges - specifically the induced non-minimum-phase behavior - that prevent the application of standard cascade arguments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10961v1</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Simone Orelli, Mirko Mizzoni, Antonio Franchi</dc:creator>
    </item>
    <item>
      <title>Multi-UAV Trajectory Optimization for Bearing-Only Localization in GPS Denied Environments</title>
      <link>https://arxiv.org/abs/2602.11116</link>
      <description>arXiv:2602.11116v1 Announce Type: cross 
Abstract: Accurate localization of maritime targets by unmanned aerial vehicles (UAVs) remains challenging in GPS-denied environments. UAVs equipped with gimballed electro-optical sensors are typically used to localize targets, however, reliance on these sensors increases mechanical complexity, cost, and susceptibility to single-point failures, limiting scalability and robustness in multi-UAV operations. This work presents a new trajectory optimization framework that enables cooperative target localization using UAVs with fixed, non-gimballed cameras operating in coordination with a surface vessel. This estimation-aware optimization generates dynamically feasible trajectories that explicitly account for mission constraints, platform dynamics, and out-of-frame events. Estimation-aware trajectories outperform heuristic paths by reducing localization error by more than a factor of two, motivating their use in cooperative operations. Results further demonstrate that coordinated UAVs with fixed, non-gimballed cameras achieve localization accuracy that meets or exceeds that of single gimballed systems, while substantially lowering system complexity and cost, enabling scalability, and enhancing mission resilience.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11116v1</guid>
      <category>eess.SY</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alfonso Sciacchitano, Liraz Mudrik, Sean Kragelund, Isaac Kaminer</dc:creator>
    </item>
    <item>
      <title>A Policy Iteration Method for Inverse Mean Field Games</title>
      <link>https://arxiv.org/abs/2409.06184</link>
      <description>arXiv:2409.06184v4 Announce Type: replace 
Abstract: We propose a policy iteration method to solve an inverse problem for a mean-field game (MFG) model, specifically to reconstruct the obstacle function in the game from the partial observation data of value functions, which represent the optimal costs for agents. The proposed approach decouples this complex inverse problem, which is an optimization problem constrained by a coupled nonlinear forward and backward PDE system in the MFG, into several iterations of solving linear PDEs and linear inverse problems. This method can also be viewed as a fixed-point iteration that simultaneously solves the MFG system and inversion. We prove its linear rate of convergence. In addition, numerical examples in 1D and 2D, along with performance comparisons to a direct least-squares method, demonstrate the superior efficiency and accuracy of the proposed method for solving inverse MFGs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06184v4</guid>
      <category>math.OC</category>
      <category>cs.GT</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.NA</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kui Ren, Nathan Soedjak, Shanyin Tong</dc:creator>
    </item>
    <item>
      <title>A Riemannian Alternating Descent Ascent Algorithmic Framework for Nonconvex-Linear Minimax Problems on Riemannian Manifolds</title>
      <link>https://arxiv.org/abs/2409.19588</link>
      <description>arXiv:2409.19588v2 Announce Type: replace 
Abstract: In this paper, we consider a class of nonconvex-linear minimax problems on Riemannian manifolds, which find wide applications in machine learning and signal processing. For solving this class of problems, we develop a flexible Riemannian alternating descent ascent (RADA) algorithmic framework. Within this framework, we propose two easy-to-implement yet efficient algorithms that alternately perform one or multiple projected/Riemannian gradient descent steps and a proximal gradient ascent step at each iteration. We show that the proposed RADA algorithmic framework can find both an $\varepsilon$-Riemannian-game-stationary point and an $\varepsilon$-Riemannian-optimization-stationary point within $\mathcal{O}(\varepsilon^{-3})$ iterations, achieving the best-known iteration complexity. We also reveal intriguing similarities and differences between the algorithms developed within our proposed framework and existing algorithms, thus providing important insights into the improved efficiency of the former. Lastly, we present numerical results on sparse principal component analysis (PCA), fair PCA, and sparse spectral clustering to demonstrate the superior performance of the proposed algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19588v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Meng Xu, Bo Jiang, Ya-Feng Liu, Anthony Man-Cho So</dc:creator>
    </item>
    <item>
      <title>Sparse Approximation in Lattices and Semigroups</title>
      <link>https://arxiv.org/abs/2410.23990</link>
      <description>arXiv:2410.23990v3 Announce Type: replace 
Abstract: This paper deals with the following question: Suppose that there exist an integer or a non-negative integer solution $x$ to a system $Ax = b$, where the number of non-zero components of $x$ is $n$. The target is, for a given natural number $k &lt; n$, to approximate $b$ with $Ay$ where $y$ is an integer or non-negative integer solution with at most $k$ non-zero components. We establish upper bounds for this question in general. In specific cases, these bounds are tight. If we view the approximation quality as a function of the parameter $k$, then the paper explains why the quality of the approximation increases exponentially as $k$ goes to $n$. This paper is a complete version of an extended abstract that appeared at the 26th International Conference on Integer Programming and Combinatorial Optimization (IPCO).</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.23990v3</guid>
      <category>math.OC</category>
      <category>cs.DM</category>
      <category>math.CO</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Stefan Kuhlmann, Timm Oertel, Robert Weismantel</dc:creator>
    </item>
    <item>
      <title>EM algorithms for optimization problems with polynomial objectives</title>
      <link>https://arxiv.org/abs/2412.20481</link>
      <description>arXiv:2412.20481v2 Announce Type: replace 
Abstract: The EM (Expectation-Maximization) algorithm is regarded as an MM (Majorization-Minimization) algorithm for maximum likelihood estimation of statistical models. Expanding this view, this paper demonstrates that by choosing an appropriate probability distribution, even nonstatistical optimization problem can be cast as a negative log-likelihood-like minimization problem, which can be approached by an EM (or MM) algorithm. When a polynomial objective is optimized over a simple polyhedral feasible set and an exponential family distribution is employed, the EM algorithm can be reduced to a natural gradient descent of the employed distribution with a constant step size. This is demonstrated through three examples. In this paper, we demonstrate the global convergence of specific cases with some exponential family distributions in a general form. In instances when the feasible set is not sufficiently simple, the use of MM algorithms can nevertheless be adequately described. When the objective is to minimize a convex quadratic function and the constraints are polyhedral, global convergence can also be established based on the existing results for an entropy-like proximal point algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.20481v2</guid>
      <category>math.OC</category>
      <category>stat.CO</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kensuke Asai, Jun-ya Gotoh</dc:creator>
    </item>
    <item>
      <title>Inexact Accelerated Proximal Gradient Method Revisit: An Economical Variant via Shadow Points</title>
      <link>https://arxiv.org/abs/2504.20453</link>
      <description>arXiv:2504.20453v2 Announce Type: replace 
Abstract: We consider the problem of optimizing the sum of a smooth convex function and a non-smooth convex function via the inexact accelerated proximal gradient (APG) method. A key limitation of existing inexact APG methods is their reliance on feasible approximate solutions of the subproblems, which is often computationally expensive or even unrealistic to obtain in practice. To overcome this limitation, we develop a shadow-point enhanced inexact APG method (SpinAPG), which relaxes the feasibility requirement by allowing the computed iterates to be potentially infeasible, while introducing an auxiliary feasible shadow point solely for error control without requiring its explicit computation. This design decouples feasibility enforcement from the algorithmic updates and leads to a flexible and practically implementable inexact framework. Under suitable summable error conditions, we show that SpinAPG preserves all desirable convergence properties of the APG method, including the iterate convergence and an $o(1/k^2)$ convergence rate for the objective function values. These results complement and extend existing convergence analyses of inexact APG methods by demonstrating that the accelerated convergence can be retained even in the presence of controlled infeasibility. Numerical experiments on sparse quadratic programming problems illustrate the practical advantages of SpinAPG, showing that it can substantially reduce computational overhead by avoiding explicit computations of feasible points.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.20453v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lei Yang, Meixia Lin</dc:creator>
    </item>
    <item>
      <title>On the Linear Programming Model for Dynamic Stochastic Matching and Its Application to Pricing</title>
      <link>https://arxiv.org/abs/2506.09924</link>
      <description>arXiv:2506.09924v3 Announce Type: replace 
Abstract: Important pricing problems in centralized matching markets -- such as carpooling, food delivery and freight shipping platforms -- often exhibit a bi-level structure. At the upper level, the platform sets prices for heterogeneous demand types (e.g., rides across origin-destination pairs, food delivery orders across restaurant-customer pairs, or less-than-truckload shipments). The lower level subsequently matches converted demands to minimize operational costs; for example, by pooling riders into shared vehicles or consolidating multiple orders into single courier or trailer routes. Motivated by these applications, we study the optimal value (cost) function of a linear programming model with respect to demand arrival rates, originally proposed by Aouad and Saritac (2022) for cost-minimizing dynamic stochastic matching under limited time. In particular, we study the concavity properties of this cost function. We show that it suffices for every optimal basic feasible solution of the linear program to be nondegenerate in order to guarantee weak concavity. Leveraging this insight, we further establish that weak concavity holds when all demand types have strictly positive unmatched rates -- a natural condition in stochastic environments when demands have limited patience -- and characterize conditions under which this property is satisfied in the fluid linear program. Building on these theoretical insights, we develop a Minorization-Maximization (MM) algorithm that exploits the resulting difference-of-concave structure of the pricing problem. The algorithm requires little stepsize tuning and delivers substantial performance improvements over projected gradient methods on a large-scale, real-world ridesharing dataset with thousands of rider types (origin-destination pairs). This makes it a compelling algorithmic choice for solving such pricing problems in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.09924v3</guid>
      <category>math.OC</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junlin Chen, Chiwei Yan, Hai Jiang</dc:creator>
    </item>
    <item>
      <title>Complexity of normalized stochastic first-order methods with momentum under heavy-tailed noise</title>
      <link>https://arxiv.org/abs/2506.11214</link>
      <description>arXiv:2506.11214v2 Announce Type: replace 
Abstract: In this paper, we propose practical normalized stochastic first-order methods with Polyak momentum, multi-extrapolated momentum, and recursive momentum for solving unconstrained optimization problems. These methods employ dynamically updated algorithmic parameters and do not require explicit knowledge of problem-dependent quantities such as the Lipschitz constant or noise bound. We establish first-order oracle complexity results for finding approximate stochastic stationary points under heavy-tailed noise and weakly average smoothness conditions -- both of which are weaker than the commonly used bounded variance and mean-squared smoothness assumptions. Our complexity bounds either improve upon or match the best-known results in the literature. Numerical experiments are presented to demonstrate the practical effectiveness of the proposed methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11214v2</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.CC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chuan He, Zhaosong Lu, Defeng Sun, Zhanwang Deng</dc:creator>
    </item>
    <item>
      <title>Implicit Third-Order Peer Triplets with Variable Stepsizes for Gradient-Based Solutions in Large-Scale ODE-Constrained Optimal Control</title>
      <link>https://arxiv.org/abs/2509.11684</link>
      <description>arXiv:2509.11684v2 Announce Type: replace 
Abstract: This paper is concerned with the theory, construction and application of variable-stepsize implicit Peer two-step methods that are super-convergent for variable stepsizes, i.e., preserve their classical order achieved for uniform stepsizes when applied in a gradient-based solution algorithm to solve ODE-constrained optimal control problems in a first-discretize-then-optimize setting. Gradients of the objective function can be computed most efficiently using approximate adjoint variables. High accuracy with moderate computational effort can be achieved through time integration methods that satisfy a sufficiently large number of adjoint order conditions for variable stepsizes and provide gradients with higher-order consistency. In this paper, we enhance our previously developed variable implicit two-step Peer triplets constructed in [J. Comput. Appl. Math. 460, 2025] to get ready for large-scale dynamical systems with varying time scales without losing efficiency. A key advantage of Peer methods is their use of multiple stages with the same high stage order, which prevents order reduction - an issue commonly encountered in semi discretized PDE problems with boundary control. Two third-order methods with four stages, good stability properties, small error constants, and a grid adaptation by equi-distributing global errors are constructed and tested for a 1D boundary heat control problem and an optimal control of cytotoxic therapies in the treatment of prostate cancer.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11684v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jens Lang, Bernhard A. Schmitt</dc:creator>
    </item>
    <item>
      <title>Parameter-Efficient Subspace Optimization for LLM Fine-Tuning</title>
      <link>https://arxiv.org/abs/2512.02216</link>
      <description>arXiv:2512.02216v2 Announce Type: replace 
Abstract: This paper develops a new perspective on parameter-efficient fine-tuning (PEFT) for LLMs, inspired by classical subspace minimization. We introduce a unifying framework, Parameter-Efficient Subspace Optimization (PESO), which recovers existing methods such as LoRA and connects them to the principled algorithmic and theoretical foundations of subspace optimization. This connection highlights a natural ``exploration--exploitation'' view of subspace methods, guiding the design of new algorithms that achieve strong convergence performance while still preserving memory efficiency. We instantiate the framework into a practical algorithm, PESO-LoRA, based on a LoRA-type parameterization. Importantly, we provide convergence guarantees stated in the full-parameter space for the induced update, addressing a key limitation of LoRA-style analyses that only track low-dimensional factors. Empirically, PESO-LoRA improves over strong PEFT baselines on standard fine-tuning benchmarks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02216v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuchen Lou, Zeqi Ye, Minshuo Chen</dc:creator>
    </item>
    <item>
      <title>Circuit Diameter of Polyhedra is Strongly Polynomial</title>
      <link>https://arxiv.org/abs/2602.06958</link>
      <description>arXiv:2602.06958v2 Announce Type: replace 
Abstract: We prove a strongly polynomial bound on the circuit diameter of polyhedra, resolving the circuit analogue of the polynomial Hirsch conjecture. Specifically, we show that the circuit diameter of a polyhedron $P = \{x\in \mathbb{R}^n:\, A x = b, \, x \ge 0\}$ with $A\in\mathbb{R}^{m\times n}$ is $O(m^2 \log m)$. Our construction yields monotone circuit walks, giving the same bound for the monotone circuit diameter.
  The circuit diameter, introduced by Borgwardt, Finhold, and Hemmecke (SIDMA 2015), is a natural relaxation of the combinatorial diameter that allows steps along circuit directions rather than only along edges. All prior upper bounds on the circuit diameter were only weakly polynomial. Finding a circuit augmentation algorithm that matches this bound would yield a strongly polynomial time algorithm for linear programming, resolving Smale's 9th problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.06958v2</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bento Natura</dc:creator>
    </item>
    <item>
      <title>Learning to Choose Branching Rules for Nonconvex MINLPs</title>
      <link>https://arxiv.org/abs/2602.09996</link>
      <description>arXiv:2602.09996v2 Announce Type: replace 
Abstract: Outer-approximation-based branch-and-bound is a common algorithmic framework for solving MINLPs (mixed-integer nonlinear programs) to global optimality, with branching variable selection critically influencing overall performance. In modern global MINLP solvers, it is unclear whether branching on fractional integer variables should be prioritized over spatial branching on variables, potentially continuous, that show constraint violations, with different solvers following different defaults. We address this question using a data-driven approach. Based on a test set of hundreds of heterogeneous public and industrial MINLP instances, we train linear and random forest regression models to predict the relative speedup of the FICO(R) Xpress Global solver when using a branching rule that always prioritizes variables with violated integralities versus a mixed rule, allowing for early spatial branches.
  We introduce a practical evaluation methodology that measures the effect of the learned model directly in terms of the shifted geometric mean runtime. Using only four features derived from strong branching and the nonlinear structure, our linear regression model achieves an 8-9% reduction in geometric-mean solving time for the Xpress solver, with over 10% improvement on hard instances. We also analyze a random regression forest model. Experiments across solver versions show that a model trained on Xpress 9.6 still yields significant improvements on Xpress 9.8 without retraining.
  Our results demonstrate how regression models can successfully guide the branching-rule selection and improve the performance of a state-of-the-art commercial MINLP solver.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.09996v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Timo Berthold, Fritz Geis</dc:creator>
    </item>
    <item>
      <title>Exponential time differencing for matrix-valued dynamical systems</title>
      <link>https://arxiv.org/abs/2406.13761</link>
      <description>arXiv:2406.13761v2 Announce Type: replace-cross 
Abstract: Matrix evolution equations occur in many applications, such as dynamical Lyapunov/Sylvester systems or Riccati equations in optimization and stochastic control, machine learning or data assimilation. In many such problems, the dominant stability restriction is imposed by a stiff linear term, making standard explicit integrators impractical. Exponential time differencing (ETD) is known to produce highly stable numerical schemes by treating the linear term in an exact fashion. In particular, for stiff problems, ETD methods are the methods of choice. We extend ETD to matrix-valued evolution equations of the form $\dot Q = LQ + QR + N(Q,t)$ by deriving explicit matrix-ETD (METD) schemes. When $L$ and $R$ commute, we construct an explicit $p$-th order METD$p$ family and prove order-$p$ global convergence under standard assumptions; for the non-commuting case, we develop a Baker-Campbell-Hausdorff (BCH)-based extension. This allows us to produce highly efficient and stable integration schemes. We demonstrate efficiency and applicability on stiff PDE-derived and large-scale matrix dynamics, including an Allen-Cahn system, turbulent jet fluctuation statistics, and continuous graph neural networks. We further show that the scheme is more accurate, stable, and efficient than competing schemes in large-scale high-rank stiff systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.13761v2</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nayef Shkeir, Tobias Grafke</dc:creator>
    </item>
    <item>
      <title>Decoupled Functional Central Limit Theorems for Two-Time-Scale Stochastic Approximation</title>
      <link>https://arxiv.org/abs/2412.17070</link>
      <description>arXiv:2412.17070v4 Announce Type: replace-cross 
Abstract: In two-time-scale stochastic approximation (SA), two iterates are updated at different rates, governed by distinct step sizes, with each update influencing the other. Previous studies have demonstrated that the convergence rates of the error terms for these updates depend solely on their respective step sizes, a property known as decoupled convergence. However, a functional version of this decoupled convergence has not been explored. Our work fills this gap by establishing decoupled functional central limit theorems for two-time-scale SA, offering a more precise characterization of its asymptotic behavior. Our results show that, on each time scale, the limiting dynamics has the same form as in standard SA, and the coupling between the two iterates enters the limit only through the associated coefficients. To achieve these results, we leverage the martingale problem approach and establish tightness as a crucial intermediate step. Furthermore, to address the interdependence between different time scales, we introduce an innovative auxiliary sequence to eliminate the primary influence of the fast-time-scale update on the slow-time-scale update.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17070v4</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuze Han, Xiang Li, Jiadong Liang, Zhihua Zhang</dc:creator>
    </item>
    <item>
      <title>Accurate, provable and fast polychromatic tomographic reconstruction: A variational inequality approach</title>
      <link>https://arxiv.org/abs/2503.19925</link>
      <description>arXiv:2503.19925v2 Announce Type: replace-cross 
Abstract: We consider the problem of signal reconstruction for computed tomography (CT) under a nonlinear forward model that accounts for exponential signal attenuation, a polychromatic X-ray source, general measurement noise (e.g., Poisson shot noise), and observations acquired over multiple wavelength windows. We develop a simple iterative algorithm for single-material reconstruction, which we call EXACT (EXtragradient Algorithm for Computed Tomography), based on formulating our estimate as the fixed point of a monotone variational inequality. We prove guarantees on the statistical and computational performance of EXACT under realistic assumptions on the measurement process. We also consider a recently introduced variant of this model with Gaussian measurements and present sample and iteration complexity bounds for EXACT that improve upon those of existing algorithms. We apply our EXACT algorithm to a CT phantom image recovery task and show that it often requires fewer X-ray views, lower source intensity, and less computation time to achieve reconstruction quality similar to existing methods. Code is available at https://github.com/voilalab/exact.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.19925v2</guid>
      <category>eess.IV</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>physics.med-ph</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mengqi Lou, Kabir Aladin Verchand, Sara Fridovich-Keil, Ashwin Pananjady</dc:creator>
    </item>
    <item>
      <title>Multi-Head Finite-State Dimension</title>
      <link>https://arxiv.org/abs/2509.22912</link>
      <description>arXiv:2509.22912v2 Announce Type: replace-cross 
Abstract: We introduce multi-head finite-state dimension, a generalization of finite-state dimension in which a group of finite-state agents (the heads) with oblivious, one-way movement rules, each reporting only one symbol at a time, enable their leader to bet on subsequent symbols in an infinite data stream. In aggregate, such a scheme constitutes an $h$-head finite state gambler whose maximum achievable growth rate of capital in this task, quantified using betting strategies called gales, determines the multi-head finite-state dimension of the sequence. The 1-head case is equivalent to finite-state dimension as defined by Dai, Lathrop, Lutz and Mayordomo (2004). In our main theorem, we prove a strict hierarchy as the number of heads increases, giving an explicit sequence family that separates, for each positive integer $h$, the earning power of $h$-head finite-state gamblers from that of $(h+1)$-head finite-state gamblers. We prove that multi-head finite-state dimension is stable under finite unions but that the corresponding quantity for any fixed number $h&gt;1$ of heads--the $h$-head finite-state predimension--lacks this stability property.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22912v2</guid>
      <category>cs.IT</category>
      <category>cs.FL</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiang Huang, Xiaoyuan Li, Jack H. Lutz, Neil Lutz</dc:creator>
    </item>
    <item>
      <title>A Function-Space Stability Boundary for Generalization in Interpolating Learning Systems</title>
      <link>https://arxiv.org/abs/2602.03514</link>
      <description>arXiv:2602.03514v2 Announce Type: replace-cross 
Abstract: Modern learning systems often interpolate training data while still generalizing well, yet it remains unclear when algorithmic stability explains this behavior. We model training as a function-space trajectory and measure sensitivity to single-sample perturbations along this trajectory. We propose a contractive propagation condition and a stability certificate obtained by unrolling the resulting recursion. A small certificate implies stability-based generalization, while we also prove that there exist interpolating regimes with small risk where such contractive sensitivity cannot hold, showing that stability is not a universal explanation. Experiments confirm that certificate growth predicts generalization differences across optimizers, step sizes, and dataset perturbations. The framework therefore identifies regimes where stability explains generalization and where alternative mechanisms must account for success.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.03514v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ronald Katende</dc:creator>
    </item>
    <item>
      <title>Escaping Local Minima Provably in Non-convex Matrix Sensing: A Deterministic Framework via Simulated Lifting</title>
      <link>https://arxiv.org/abs/2602.05887</link>
      <description>arXiv:2602.05887v2 Announce Type: replace-cross 
Abstract: Low-rank matrix sensing is a fundamental yet challenging nonconvex problem whose optimization landscape typically contains numerous spurious local minima, making it difficult for gradient-based optimizers to converge to the global optimum. Recent work has shown that over-parameterization via tensor lifting can convert such local minima into strict saddle points, an insight that also partially explains why massive scaling can improve generalization and performance in modern machine learning. Motivated by this observation, we propose a Simulated Oracle Direction (SOD) escape mechanism that simulates the landscape and escape direction of the over-parametrized space, without resorting to actually lifting the problem, since that would be computationally intractable. In essence, we designed a mathematical framework to project over-parametrized escape directions onto the original parameter space to guarantee a strict decrease of objective value from existing local minima. To the best of our knowledge, this represents the first deterministic framework that could escape spurious local minima with guarantee, especially without using random perturbations or heuristic estimates. Numerical experiments demonstrate that our framework reliably escapes local minima and facilitates convergence to global optima, while incurring minimal computational cost when compared to explicit tensor over-parameterization. We believe this framework has non-trivial implications for nonconvex optimization beyond matrix sensing, by showcasing how simulated over-parameterization can be leveraged to tame challenging optimization landscapes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.05887v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tianqi Shen, Jinji Yang, Junze He, Kunhan Gao, Ziye Ma</dc:creator>
    </item>
    <item>
      <title>Do physics-informed neural networks (PINNs) need to be deep? Shallow PINNs using the Levenberg-Marquardt algorithm</title>
      <link>https://arxiv.org/abs/2602.08515</link>
      <description>arXiv:2602.08515v2 Announce Type: replace-cross 
Abstract: This work investigates the use of shallow physics-informed neural networks (PINNs) for solving forward and inverse problems of nonlinear partial differential equations (PDEs). By reformulating PINNs as nonlinear systems, the Levenberg-Marquardt (LM) algorithm is employed to efficiently optimize the network parameters. Analytical expressions for the neural network derivatives with respect to the input variables are derived, enabling accurate and efficient computation of the Jacobian matrix required by LM. The proposed approach is tested on several benchmark problems, including the Burgers, Schr\"odinger, Allen-Cahn, and three-dimensional Bratu equations. Numerical results demonstrate that LM significantly outperforms BFGS in terms of convergence speed, accuracy, and final loss values, even when using shallow network architectures with only two hidden layers. These findings indicate that, for a wide class of PDEs, shallow PINNs combined with efficient second-order optimization methods can provide accurate and computationally efficient solutions for both forward and inverse problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08515v2</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>cs.NE</category>
      <category>math.OC</category>
      <pubDate>Thu, 12 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Muhammad Luthfi Shahab, Imam Mukhlash, Hadi Susanto</dc:creator>
    </item>
  </channel>
</rss>
