<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 17 Sep 2025 01:38:07 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Strategic Cyber Defense via Reinforcement Learning-Guided Combinatorial Auctions</title>
      <link>https://arxiv.org/abs/2509.10983</link>
      <description>arXiv:2509.10983v1 Announce Type: new 
Abstract: Cyber defense operations increasingly require long-term strategic planning under uncertainty and resource constraints. We propose a new use of combinatorial auctions for allocating defensive action bundles in a realistic cyber environment, using host-specific valuations derived from reinforcement learning (RL) Q-values. These Q-values encode long-term expected utility, allowing upstream planning. We train CAFormer, a differentiable Transformer-based auction mechanism, to produce allocations that are approximately incentive-compatible under misreporting. Rather than benchmarking against existing agents, we explore the qualitative and strategic properties of the learned mechanisms. Compared to oracle and heuristic allocations, our method achieves competitive revenue while offering robustness to misreporting. In addition, we find that allocation patterns correlate with adversarial and defensive activity, suggesting implicit alignment with operational priorities. Our results demonstrate the viability of auction-based planning in cyber defense and highlight the interpretability benefits of RL-derived value structures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10983v1</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mai Pham, Vikrant Vaze, Peter Chin</dc:creator>
    </item>
    <item>
      <title>Actively Learning to Coordinate in Convex Games via Approximate Correlated Equilibrium</title>
      <link>https://arxiv.org/abs/2509.10989</link>
      <description>arXiv:2509.10989v1 Announce Type: new 
Abstract: Correlated equilibrium generalizes Nash equilibrium by allowing a central coordinator to guide players' actions through shared recommendations, similar to how routing apps guide drivers. We investigate how a coordinator can learn a correlated equilibrium in convex games where each player minimizes a convex cost function that depends on other players' actions, subject to convex constraints without knowledge of the players' cost functions. We propose a learning framework that learns an approximate correlated equilibrium by actively querying players' regrets, \emph{i.e.}, the cost saved by deviating from the coordinator's recommendations. We first show that a correlated equilibrium in convex games corresponds to a joint action distribution over an infinite joint action space that minimizes all players' regrets. To make the learning problem tractable, we introduce a heuristic that selects finitely many representative joint actions by maximizing their pairwise differences. We then apply Bayesian optimization to learn a probability distribution over the selected joint actions by querying all players' regrets. The learned distribution approximates a correlated equilibrium by minimizing players' regrets. We demonstrate the proposed approach via numerical experiments on multi-user traffic assignment games in a shared transportation network.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10989v1</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhenlong Fang, Aryan Deshwal, Yue Yu</dc:creator>
    </item>
    <item>
      <title>Identifying Imperfect Clones in Elections</title>
      <link>https://arxiv.org/abs/2509.11261</link>
      <description>arXiv:2509.11261v1 Announce Type: new 
Abstract: A perfect clone in an ordinal election (i.e., an election where the voters rank the candidates in a strict linear order) is a set of candidates that each voter ranks consecutively. We consider different relaxations of this notion: independent or subelection clones are sets of candidates that only some of the voters recognize as a perfect clone, whereas approximate clones are sets of candidates such that every voter ranks their members close to each other, but not necessarily consecutively. We establish the complexity of identifying such imperfect clones, and of partitioning the candidates into families of imperfect clones. We also study the parameterized complexity of these problems with respect to a set of natural parameters such as the number of voters, the size or the number of imperfect clones we are searching for, or their level of imperfection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11261v1</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Piotr Faliszewski, Lukasz Janeczko, Grzegorz Lisowski, Kristyna Pekarkova, Ildiko Schlotter</dc:creator>
    </item>
    <item>
      <title>An Incentive-Compatible Reward Sharing Mechanism for Mitigating Mirroring Attacks in Decentralized Data-Feed Systems</title>
      <link>https://arxiv.org/abs/2509.11294</link>
      <description>arXiv:2509.11294v1 Announce Type: new 
Abstract: Decentralized data-feed systems enable blockchain-based smart contracts to access off-chain information by aggregating values from multiple oracles. To improve accuracy, these systems typically use an aggregation function, such as majority voting, to consolidate the inputs they receive from oracles and make a decision. Depending on the final decision and the values reported by the oracles, the participating oracles are compensated through shared rewards. However, such incentive mechanisms are vulnerable to mirroring attacks, where a single user controls multiple oracles to bias the decision of the aggregation function and maximize rewards. This paper analyzes the impact of mirroring attacks on the reliability and dependability of majority voting-based data-feed systems. We demonstrate how existing incentive mechanisms can unintentionally encourage rational users to implement such attacks. To address this, we propose a new incentive mechanism that discourages Sybil behavior. We prove that the proposed mechanism leads to a Nash Equilibrium in which each user operates only one oracle. Finally, we discuss the practical implementation of the proposed incentive mechanism and provide numerical examples to demonstrate its effectiveness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11294v1</guid>
      <category>cs.GT</category>
      <category>cs.ET</category>
      <category>cs.IR</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.PR</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sina Aeeneh, Nikola Zlatanov, Jiangshan Yu</dc:creator>
    </item>
    <item>
      <title>Bilevel subsidy-enabled mobility hub network design with perturbed utility coalitional choice-based assignment</title>
      <link>https://arxiv.org/abs/2509.10465</link>
      <description>arXiv:2509.10465v1 Announce Type: cross 
Abstract: Urban mobility is undergoing rapid transformation with the emergence of new services. Mobility hubs (MHs) have been proposed as physical-digital convergence points, offering a range of public and private mobility options in close proximity. By supporting Mobility-as-a-Service, these hubs can serve as focal points where travel decisions intersect with operator strategies. We develop a bilevel MH platform design model that treats MHs as control levers. The upper level (platform) maximizes revenue or flow by setting subsidies to incentivize last-mile operators; the lower level captures joint traveler-operator decisions with a link-based Perturbed Utility Route Choice (PURC) assignment, yielding a strictly convex quadratic program. We reformulate the bilevel problem to a single-level program via the KKT conditions of the lower level and solve it with a gap-penalty method and an iterative warm-start scheme that exploits the computationally cheap lower-level problem. Numerical experiments on a toy network and a Long Island Rail Road (LIRR) case (244 nodes, 469 links, 78 ODs) show that the method attains sub-1% optimality gaps in minutes. In the base LIRR case, the model allows policymakers to quantify the social surplus value of a MH, or the value of enabling subsidy or regulating the microtransit operator's pricing. Comparing link-based subsidies to hub-based subsidies, the latter is computationally more expensive but offers an easier mechanism for comparison and control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10465v1</guid>
      <category>math.OC</category>
      <category>cs.CY</category>
      <category>cs.GT</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Hai Yang, Joseph Y. J. Chow</dc:creator>
    </item>
    <item>
      <title>Bluffing in Scrabble</title>
      <link>https://arxiv.org/abs/2509.10471</link>
      <description>arXiv:2509.10471v1 Announce Type: cross 
Abstract: It is well known that in games with imperfect information, such as poker, bluffing with some probability can be a component of the optimal strategy. However, as far as we know, nobody has ever exhibited a Scrabble position in which the optimal strategy involves bluffing, or even a Scrabble position in which the optimal strategy is a mixed (i.e., randomized) strategy. We present a carefully constructed Scrabble position, that could actually arise in a tournament game with no invalid words played, in which the optimal strategy (assuming that a tied score leads to the point being split equally, with no recourse to so-called "spread points" as a tie-breaking mechanism) is to make Move A with probability 1/3 and to make Move B with probability 2/3. Move B can reasonably be called a bluff, in the sense that it sets up a threat which the player cannot in fact execute, but which the opponent may not be able to rule out.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10471v1</guid>
      <category>math.HO</category>
      <category>cs.GT</category>
      <category>math.CO</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nick Ballard, Timothy Y. Chow</dc:creator>
    </item>
    <item>
      <title>A Service-Oriented Adaptive Hierarchical Incentive Mechanism for Federated Learning</title>
      <link>https://arxiv.org/abs/2509.10512</link>
      <description>arXiv:2509.10512v1 Announce Type: cross 
Abstract: Recently, federated learning (FL) has emerged as a novel framework for distributed model training. In FL, the task publisher (TP) releases tasks, and local model owners (LMOs) use their local data to train models. Sometimes, FL suffers from the lack of training data, and thus workers are recruited for gathering data. To this end, this paper proposes an adaptive incentive mechanism from a service-oriented perspective, with the objective of maximizing the utilities of TP, LMOs and workers. Specifically, a Stackelberg game is theoretically established between the LMOs and TP, positioning TP as the leader and the LMOs as followers. An analytical Nash equilibrium solution is derived to maximize their utilities. The interaction between LMOs and workers is formulated by a multi-agent Markov decision process (MAMDP), with the optimal strategy identified via deep reinforcement learning (DRL). Additionally, an Adaptively Searching the Optimal Strategy Algorithm (ASOSA) is designed to stabilize the strategies of each participant and solve the coupling problems. Extensive numerical experiments are conducted to validate the efficacy of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10512v1</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiaxing Cao, Yuzhou Gao, Jiwei Huang</dc:creator>
    </item>
    <item>
      <title>Pair-Bid Auction Model for Optimized Network Slicing in 5G RAN</title>
      <link>https://arxiv.org/abs/2509.10533</link>
      <description>arXiv:2509.10533v1 Announce Type: cross 
Abstract: Network slicing is a key 5G technology that enables multiple virtual networks to share physical infrastructure, optimizing flexibility and resource allocation. This involves Mobile Network Operators (MNO), Mobile Virtual Network Operators (MVNOs), and end users, where MNO leases network slices to MVNOs, and then provides customized services. This work considers end-to-end network slicing with a focus on fair sharing and financial-related power efficiency, modeled as a two level hierarchical combinatorial auction. At the upper level, an MNO auctions slices to competing MVNOs, while at the lower level, MVNOs allocate resources to end users through their own auctions. Dynamic user requests add complexity to the process. Our model optimizes resource allocation and revenue generation using a pair-bid mechanism and Vickrey-Clarke-Groves (VCG) pricing. The pair-bid approach enhances competition and efficiency, while VCG ensures truthful bidding based on marginal system impact. Simulations validate the model's effectiveness in resource distribution and financial performance, showing a 12.5% revenue improvement over the baseline.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10533v1</guid>
      <category>cs.NI</category>
      <category>cs.GT</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Mengyao Li, Sebastian Troia, Yingqian Zhang, Guido Maier</dc:creator>
    </item>
    <item>
      <title>Choice Paralysis in Evolutionary Games</title>
      <link>https://arxiv.org/abs/2509.10567</link>
      <description>arXiv:2509.10567v1 Announce Type: cross 
Abstract: In this paper, we consider finite-strategy approximations of infinite-strategy evolutionary games. We prove that such approximations converge to the true dynamics over finite-time intervals, under mild regularity conditions which are satisfied by classical examples, e.g., the replicator dynamics. We identify and formalize novel characteristics in evolutionary games: choice mobility, and its complement choice paralysis. Choice mobility is shown to be a key sufficient condition for the long-time limiting behavior of finite-strategy approximations to coincide with that of the true infinite-strategy game. An illustrative example is constructed to showcase how choice paralysis may lead to the infinite-strategy game getting "stuck," even though every finite approximation converges to equilibrium.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10567v1</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <category>math.DS</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Brendon G. Anderson</dc:creator>
    </item>
    <item>
      <title>Dual Reinforcement Learning Synergy in Resource Allocation: Emergence of Self-Organized Momentum Strategy</title>
      <link>https://arxiv.org/abs/2509.11161</link>
      <description>arXiv:2509.11161v1 Announce Type: cross 
Abstract: In natural ecosystems and human societies, self-organized resource allocation and policy synergy are ubiquitous and significant. This work focuses on the synergy between Dual Reinforcement Learning Policies in the Minority Game (DRLP-MG) to optimize resource allocation. Our study examines a mixed-structured population with two sub-populations: a Q-subpopulation using Q-learning policy and a C-subpopulation adopting the classical policy. We first identify a synergy effect between these subpopulations. A first-order phase transition occurs as the mixing ratio of the subpopulations changes. Further analysis reveals that the Q-subpopulation consists of two internal synergy clusters (IS-clusters) and a single external synergy cluster (ES-cluster). The former contribute to the internal synergy within the Q-subpopulation through synchronization and anti-synchronization, whereas the latter engages in the inter-subpopulation synergy. Within the ES-cluster, the classical momentum strategy in the financial market manifests and assumes a crucial role in the inter-subpopulation synergy. This particular strategy serves to prevent long-term under-utilization of resources. However, it also triggers trend reversals and leads to a decrease in rewards for those who adopt it. Our research reveals that the frozen effect, in either the C- or Q-subpopulation, is a crucial prerequisite for synergy, consistent with previous studies. We also conduct mathematical analyses on subpopulation synergy effects and the synchronization and anti-synchronization forms of IS-clusters in the Q-subpopulation. Overall, our work comprehensively explores the complex resource-allocation dynamics in DRLP-MG, uncovers multiple synergy mechanisms and their conditions, enriching the theoretical understanding of reinforcement-learning-based resource allocation and offering valuable practical insights</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11161v1</guid>
      <category>nlin.AO</category>
      <category>cs.GT</category>
      <category>physics.soc-ph</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhen-Na Zhang, Guo-Zhong Zhen, Sheng-Feng Deng, Li Chen, Chao-Ran Cai, Ji-Qiang Zhang</dc:creator>
    </item>
    <item>
      <title>Online Omniprediction with Long-Term Constraints</title>
      <link>https://arxiv.org/abs/2509.11357</link>
      <description>arXiv:2509.11357v1 Announce Type: cross 
Abstract: We introduce and study the problem of online omniprediction with long-term constraints. At each round, a forecaster is tasked with generating predictions for an underlying (adaptively, adversarially chosen) state that are broadcast to a collection of downstream agents, who must each choose an action. Each of the downstream agents has both a utility function mapping actions and state to utilities, and a vector-valued constraint function mapping actions and states to vector-valued costs. The utility and constraint functions can arbitrarily differ across downstream agents. Their goal is to choose actions that guarantee themselves no regret while simultaneously guaranteeing that they do not cumulatively violate the constraints across time. We show how to make a single set of predictions so that each of the downstream agents can guarantee this by acting as a simple function of the predictions, guaranteeing each of them $\tilde{O}(\sqrt{T})$ regret and $O(1)$ cumulative constraint violation. We also show how to extend our guarantees to arbitrary intersecting contextually defined \emph{subsequences}, guaranteeing each agent both regret and constraint violation bounds not just marginally, but simultaneously on each subsequence, against a benchmark set of actions simultaneously tailored to each subsequence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11357v1</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yahav Bechavod, Jiuyao Lu, Aaron Roth</dc:creator>
    </item>
    <item>
      <title>Nash Equilibrium and Belief Evolution in Differential Games</title>
      <link>https://arxiv.org/abs/2509.11739</link>
      <description>arXiv:2509.11739v1 Announce Type: cross 
Abstract: This study investigates differential games with motion-payoff uncertainty in continuous-time settings. We propose a framework where players update their beliefs about uncertain parameters using continuous Bayesian updating. Theoretical proofs leveraging key probability theorems demonstrate that players' beliefs converge to the true parameter values, ensuring stability and accuracy in long-term estimations. We further derive Nash Equilibrium strategies with continuous Bayesian updating for players, emphasizing the role of belief updates in decision-making processes. Additionally, we establish the convergence of Nash Equilibrium strategies with continuous Bayesian updating. The efficacy of both continuous and dynamic Bayesian updating is examined in the context of pollution control games, showing convergence in players' estimates under small time intervals in discrete scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11739v1</guid>
      <category>cs.MA</category>
      <category>cs.GT</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiangjing Zhou, Ovanes Petrosian, Ye Zhang, Hongwei Gao</dc:creator>
    </item>
    <item>
      <title>Collusion-Resilience in Transaction Fee Mechanism Design</title>
      <link>https://arxiv.org/abs/2402.09321</link>
      <description>arXiv:2402.09321v3 Announce Type: replace 
Abstract: Users bid in a transaction fee mechanism (TFM) to get their transactions included and confirmed by a blockchain protocol. Roughgarden (EC'21) initiated the formal treatment of TFMs and proposed three requirements: user incentive compatibility (UIC), miner incentive compatibility (MIC), and a form of collusion-resilience called OCA-proofness. Ethereum's EIP-1559 mechanism satisfies all three properties simultaneously when there is no contention between transactions, but loses the UIC property when there are too many eligible transactions to fit in a single block. Chung and Shi (SODA'23) considered an alternative notion of collusion-resilience, called $c$-side-contract-proofness ($c$-SCP), and showed that, when there is contention between transactions, no TFM can satisfy UIC, MIC, and $c$-SCP for any $c\geq 1$. OCA-proofness asserts that the users and a miner should not be able to "steal from the protocol." On the other hand, the $c$-SCP condition requires that a coalition of a miner and a subset of users should not be able to profit through strategic deviations (whether at the expense of the protocol or of the users outside the coalition).
  Our main result is the first proof that, when there is contention between transactions, no (possibly randomized) TFM in which users are expected to bid truthfully satisfies UIC, MIC, and OCA-proofness.This result resolves the main open question in Roughgarden (EC'21). We also suggest several relaxations of the basic model that allow our impossibility result to be circumvented.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.09321v3</guid>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3670865.3673550</arxiv:DOI>
      <dc:creator>Hao Chung, Tim Roughgarden, Elaine Shi</dc:creator>
    </item>
    <item>
      <title>Mechanism Design for Automated Market Makers</title>
      <link>https://arxiv.org/abs/2402.09357</link>
      <description>arXiv:2402.09357v3 Announce Type: replace 
Abstract: Blockchains have popularized automated market makers (AMMs). An AMM exchange is an application running on a blockchain which maintains a pool of crypto-assets and automatically trades assets with users governed by some pricing function that prices the assets based on their relative demand/supply. AMMs have created an important challenge commonly known as the Miner Extractable Value (MEV). In particular, the miners who control the contents and ordering of transactions in a block can extract value by front-running and back-running users' transactions, leading to arbitrage opportunities that guarantee them risk-free returns.
  In this paper, we consider how to design AMM mechanisms that eliminate MEV opportunities. Specifically, we propose a new AMM mechanism that processes all transactions contained within a block in a batch. We show that our new mechanism satisfies two tiers of guarantees. First, for legacy blockchains where each block is proposed by a single (possibly rotating) miner, we prove that our mechanism satisfies arbitrage resilience, i.e., a miner cannot gain risk-free profit. Moreover, we also guarantee fair treatment among all transactions within the same block, such that the miner is unable to sell off favorable positions in the block to users or arbitragers. Second, for blockchains where the block proposal process is decentralized and offers sequencing-fairness, we prove a stronger notion called incentive compatibility -- roughly speaking, we guarantee that any individual user's best response is to follow the honest strategy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.09357v3</guid>
      <category>cs.GT</category>
      <category>cs.CG</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>T-H. Hubert Chan, Ke Wu, Elaine Shi</dc:creator>
    </item>
    <item>
      <title>Optimizing Preventive and Reactive Defense Resource Allocation with Uncertain Sensor Signals</title>
      <link>https://arxiv.org/abs/2508.02881</link>
      <description>arXiv:2508.02881v3 Announce Type: replace-cross 
Abstract: Cyber attacks continue to be a cause of concern despite advances in cyber defense techniques. Although cyber attacks cannot be fully prevented, standard decision-making frameworks typically focus on how to prevent them from succeeding, without considering the cost of cleaning up the damages incurred by successful attacks. This motivates us to investigate a new resource allocation problem formulated in this paper: The defender must decide how to split its investment between preventive defenses, which aim to harden nodes from attacks, and reactive defenses, which aim to quickly clean up the compromised nodes. This encounters a challenge imposed by the uncertainty associated with the observation, or sensor signal, whether a node is truly compromised or not; this uncertainty is real because attack detectors are not perfect. We investigate how the quality of sensor signals impacts the defender's strategic investment in the two types of defense, and ultimately the level of security that can be achieved. In particular, we show that the optimal investment in preventive resources increases, and thus reactive resource investment decreases, with higher sensor quality. We also show that the defender's performance improvement, relative to a baseline of no sensors employed, is maximal when the attacker can only achieve low attack success probabilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.02881v3</guid>
      <category>eess.SY</category>
      <category>cs.CR</category>
      <category>cs.GT</category>
      <category>cs.SY</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Faezeh Shojaeighadikolaei, Shouhuai Xu, Keith Paarporn</dc:creator>
    </item>
    <item>
      <title>The Implicit Barrier from Utility Maximization: Lightweight Interior-Point Methods for Market Equilibrium</title>
      <link>https://arxiv.org/abs/2508.04822</link>
      <description>arXiv:2508.04822v2 Announce Type: replace-cross 
Abstract: We study the computation of the market equilibrium in Fisher exchange markets with divisible goods and players endowed with heterogeneous utilities. In particular, we consider the decentralized polynomial-time interior-point strategies that update \emph{only} the prices, mirroring the t\^atonnement process. The key ingredient is the \emph{implicit barrier} inherent from utility maximization, which induces unbounded demand when the goods are almost free of charge. Focusing on a ubiquitous class of utilities, we formalize this observation. A companion result suggests that no additional effort is required for computing high-order derivatives; all the necessary information is readily available when collecting the best responses. To tackle the Newton systems in the interior-point methods, we present an explicitly invertible approximation of the Hessian operator with high probability guarantees, and a scaling matrix that minimizes the condition number of the linear system. Building on these tools, we design two inexact lightweight interior-point methods. One such method has $\cO(\log(\tfrac{1}{\epsilon}))$ complexity rate. Under mild conditions, the other method achieves a non-asymptotic superlinear convergence rate. Preliminary experiments are presented to justify the capability of the proposed methods for large-scale problems. Extensions of our approach are also discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.04822v2</guid>
      <category>math.OC</category>
      <category>cs.GT</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Chuwen Zhang, Chang He, Bo Jiang, Yinyu Ye</dc:creator>
    </item>
    <item>
      <title>Axiomatizations of a simple Condorcet voting method for Final Four and Final Five elections</title>
      <link>https://arxiv.org/abs/2508.17095</link>
      <description>arXiv:2508.17095v2 Announce Type: replace-cross 
Abstract: Proponents of Condorcet voting face the question of what to do in the rare case when no Condorcet winner exists. Recent work provides compelling arguments for the rule that should be applied in three-candidate elections, but already with four candidates, many rules appear reasonable. In this paper, we consider a recent proposal of a simple Condorcet voting method for Final Four political elections. Our question is what normative principles could support this simple form of Condorcet voting. When there is no Condorcet winner, one natural principle is to pick the candidate who is closest to being a Condorcet winner. Yet there are multiple plausible ways to define closeness, leading to different results. Here we take the following approach: identify a relatively uncontroversial sufficient condition for one candidate to be closer than another to being a Condorcet winner; then use other principles to help settle who wins in cases when that condition alone does not. We prove that our principles uniquely characterize the simple Condorcet voting method for Final Four elections. This analysis also points to a new way of extending the method to elections with five or more candidates that is simpler than an extension previously considered. The new proposal is to elect the candidate with the most head-to-head wins, and if multiple candidates tie for the most wins, then elect the one who has the smallest head-to-head loss. We provide additional principles sufficient to characterize this simple method for Final Five elections.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.17095v2</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wesley H. Holliday</dc:creator>
    </item>
    <item>
      <title>Strategic Tradeoffs Between Humans and AI in Multi-Agent Bargaining</title>
      <link>https://arxiv.org/abs/2509.09071</link>
      <description>arXiv:2509.09071v2 Announce Type: replace-cross 
Abstract: Coordination tasks traditionally performed by humans are increasingly being delegated to autonomous agents. As this pattern progresses, it becomes critical to evaluate not only these agents' performance but also the processes through which they negotiate in dynamic, multi-agent environments. Furthermore, different agents exhibit distinct advantages: traditional statistical agents, such as Bayesian models, may excel under well-specified conditions, whereas large language models (LLMs) can generalize across contexts. In this work, we compare humans (N = 216), LLMs (GPT-4o, Gemini 1.5 Pro), and Bayesian agents in a dynamic negotiation setting that enables direct, identical-condition comparisons across populations, capturing both outcomes and behavioral dynamics. Bayesian agents extract the highest surplus through aggressive optimization, at the cost of frequent trade rejections. Humans and LLMs can achieve similar overall surplus, but through distinct behaviors: LLMs favor conservative, concessionary trades with few rejections, while humans employ more strategic, risk-taking, and fairness-oriented behaviors. Thus, we find that performance parity -- a common benchmark in agent evaluation -- can conceal fundamental differences in process and alignment, which are critical for practical deployment in real-world coordination tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.09071v2</guid>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>cs.HC</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Crystal Qian, Kehang Zhu, John Horton, Benjamin S. Manning, Vivian Tsai, James Wexler, Nithum Thain</dc:creator>
    </item>
  </channel>
</rss>
