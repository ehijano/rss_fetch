<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 27 May 2024 04:01:11 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 27 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>ADMM for Nonsmooth Composite Optimization under Orthogonality Constraints</title>
      <link>https://arxiv.org/abs/2405.15129</link>
      <description>arXiv:2405.15129v1 Announce Type: new 
Abstract: We consider a class of structured, nonconvex, nonsmooth optimization problems under orthogonality constraints, where the objectives combine a smooth function, a nonsmooth concave function, and a nonsmooth weakly convex function. This class of problems finds diverse applications in statistical learning and data science. Existing ADMMs for addressing these problems often fail to exploit the specific structure of orthogonality constraints, struggle with nonsmooth functions and nonconvex constraint sets, or result in suboptimal oracle complexity. We propose {\sf OADMM}, an Alternating Direction Method of Multipliers (ADMM) designed to solve this class of problems using efficient proximal linearized strategies. Two specific variants of {\sf OADMM} are explored: one based on Euclidean Projection ({\sf OADMM-EP}) and the other on Riemannian retraction ({\sf OADMM-RR}). We integrate a Nesterov extrapolation strategy into {\sf OADMM-EP} and a monotone Barzilai-Borwein strategy into {\sf OADMM-RR} to potentially accelerate primal convergence. Additionally, we adopt an over-relaxation strategy in both {\sf OADMM-EP} and {\sf OADMM-RR} for rapid dual convergence. Under mild assumptions, we prove that {\sf OADMM} converges to the critical point of the problem with a provable convergence rate of $\mathcal{O}(1/\epsilon^{3})$. We also establish the convergence rate of {\sf OADMM} under the Kurdyka-Lojasiewicz (KL) inequality. Numerical experiments are conducted to demonstrate the advantages of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15129v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ganzhao Yuan</dc:creator>
    </item>
    <item>
      <title>Computational analysis on a linkage between generalized logit dynamic and discounted mean field game</title>
      <link>https://arxiv.org/abs/2405.15180</link>
      <description>arXiv:2405.15180v1 Announce Type: new 
Abstract: Logit dynamics are dynamical systems describing transitions and equilibria of actions of interacting players under uncertainty. An uncertainty is embodied in logit dynamic as a softmax type function often called a logit function originating from a maximization problem subjected to an entropic penalization. This study provides another explanation for the generalized logit dynamic, particularly its logit function and player's heterogeneity, based on a discounted mean field game subjected to the costly decision making of a representative player. A large discount limit of the mean field game is argued to yield a logit dynamic. Further, mean field games that lead to classical and generalized logit dynamics are clarified and their well posedness is discussed. Additionally, numerical methods based on a finite difference discretization for computing generalized logit dynamics and corresponding mean field games are presented. Numerical methods are applied to two problems arising in the management of resources and environment; one involves an inland fisheries management problem with legal and illegal anglers, while the other is a sustainable tourism problem. Particularly, cases that possibly lack the regularity condition to be satisfied for the unique existence of stationary solutions are computationally discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15180v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hidekazu Yoshioka</dc:creator>
    </item>
    <item>
      <title>Learning to optimize: A tutorial for continuous and mixed-integer optimization</title>
      <link>https://arxiv.org/abs/2405.15251</link>
      <description>arXiv:2405.15251v1 Announce Type: new 
Abstract: Learning to Optimize (L2O) stands at the intersection of traditional optimization and machine learning, utilizing the capabilities of machine learning to enhance conventional optimization techniques. As real-world optimization problems frequently share common structures, L2O provides a tool to exploit these structures for better or faster solutions. This tutorial dives deep into L2O techniques, introducing how to accelerate optimization algorithms, promptly estimate the solutions, or even reshape the optimization problem itself, making it more adaptive to real-world applications. By considering the prerequisites for successful applications of L2O and the structure of the optimization problems at hand, this tutorial provides a comprehensive guide for practitioners and researchers alike.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15251v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaohan Chen, Jialin Liu, Wotao Yin</dc:creator>
    </item>
    <item>
      <title>On relationships between vector variational inequalities and optimization problems using convexificators on Hadamard manifold</title>
      <link>https://arxiv.org/abs/2405.15402</link>
      <description>arXiv:2405.15402v1 Announce Type: new 
Abstract: An important concept of convexificators has been extended to Hadamard manifolds in this paper. The mean value theorem for convexificators on the Hadamard manifold has also been derived. Monotonicity of the bounded convexificators has been discussed and an important characterization for the bounded convexificators to be $\partial_{*}^{*}$-geodesic convexity has been derived. Furthermore, a vector variational inequalities problem using convexificators on Hadamard manifold has been considered. In addition, the necessary and sufficient conditions for vector optimization problems in terms of Stampacchia and Minty type partial vector variational inequality problem ($\partial_{*}^{*}$-VVIP) have been derived.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15402v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nagendra Singh, Akhlad Iqbal, Shahid Ali</dc:creator>
    </item>
    <item>
      <title>Relations between nonsmooth vector variational inequalities and nonsmooth vector optimization problems on Hadamard manifold in terms of bifunction</title>
      <link>https://arxiv.org/abs/2405.15404</link>
      <description>arXiv:2405.15404v1 Announce Type: new 
Abstract: In this paper, we discuss the concepts of bifunction and geodesic convexity for vector valued functions on Hadamard manifold. The Hadamard manifold is a particular type of Riemannian manifold with non-positive sectional curvature. Using bifunction, we introduce a definition of generalized geodesic convexity in the context of the Hadamard manifold. To support the definition, we construct a non-trivial example that demonstrates the property of geodesic convexity on Hadamard manifold. Additionally, we define the geodesic $h$-convexity, geodesic $h$-pseudoconvexity and geodesic $h$-quasiconvexity for vector valued function using bifunction and study their several properties. Furthermore, we demonstrate the uniqueness of the solution for nonsmooth vector variational inequality problem (NVVIP) and prove the characterization property for the solution of NVVIP and the Minty type NVVIP (MNVVIP) on Hadamard manifold in terms of bifunction. Afterward, we consider a nonsmooth vector optimization problem (NVOP) and investigate the relationships among the solutions of NVOP, NVVIP, and MNVVIP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15404v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nagendra Singh, Akhlad Iqbal, Shahid Ali</dc:creator>
    </item>
    <item>
      <title>Counterfactual Explanations for Linear Optimization</title>
      <link>https://arxiv.org/abs/2405.15431</link>
      <description>arXiv:2405.15431v1 Announce Type: new 
Abstract: The concept of counterfactual explanations (CE) has emerged as one of the important concepts to understand the inner workings of complex AI systems. In this paper, we translate the idea of CEs to linear optimization and propose, motivate, and analyze three different types of CEs: strong, weak, and relative. While deriving strong and weak CEs appears to be computationally intractable, we show that calculating relative CEs can be done efficiently. By detecting and exploiting the hidden convex structure of the optimization problem that arises in the latter case, we show that obtaining relative CEs can be done in the same magnitude of time as solving the original linear optimization problem. This is confirmed by an extensive numerical experiment study on the NETLIB library.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15431v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jannis Kurtz, \c{S}. \.Ilker Birbil, Dick den Hertog</dc:creator>
    </item>
    <item>
      <title>A note about a transition of Ratliff and Rosenthal's order picking algorithm for rectangular warehouses</title>
      <link>https://arxiv.org/abs/2405.15464</link>
      <description>arXiv:2405.15464v1 Announce Type: new 
Abstract: In the order picking problem, a picker has to collect a number of products in a warehouse with a minimum length tour. Ratliff and Rosenthal gave a linear algorithm solving the order picking problem in the case where the warehouse has two cross aisles. Their algorithm allow the tour to double cross an entire aisle. We prove that, in rectangular warehouses, there always exists a minimum length tour which doesn't double cross an aisle.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15464v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Paul Revenant (ENS de Lyon), Hadrien Cambazard (G-SCOP), Nicolas Catusse (G-SCOP)</dc:creator>
    </item>
    <item>
      <title>Randomized algorithms and PAC bounds for inverse reinforcement learning in continuous spaces</title>
      <link>https://arxiv.org/abs/2405.15509</link>
      <description>arXiv:2405.15509v1 Announce Type: new 
Abstract: This work studies discrete-time discounted Markov decision processes with continuous state and action spaces and addresses the inverse problem of inferring a cost function from observed optimal behavior. We first consider the case in which we have access to the entire expert policy and characterize the set of solutions to the inverse problem by using occupation measures, linear duality, and complementary slackness conditions. To avoid trivial solutions and ill-posedness, we introduce a natural linear normalization constraint. This results in an infinite-dimensional linear feasibility problem, prompting a thorough analysis of its properties. Next, we use linear function approximators and adopt a randomized approach, namely the scenario approach and related probabilistic feasibility guarantees, to derive epsilon-optimal solutions for the inverse problem. We further discuss the sample complexity for a desired approximation accuracy. Finally, we deal with the more realistic case where we only have access to a finite set of expert demonstrations and a generative model and provide bounds on the error made when working with samples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15509v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Angeliki Kamoutsi, Peter Schmitt-F\"orster, Tobias Sutter, Volkan Cevher, John Lygeros</dc:creator>
    </item>
    <item>
      <title>Freya PAGE: First Optimal Time Complexity for Large-Scale Nonconvex Finite-Sum Optimization with Heterogeneous Asynchronous Computations</title>
      <link>https://arxiv.org/abs/2405.15545</link>
      <description>arXiv:2405.15545v1 Announce Type: new 
Abstract: In practical distributed systems, workers are typically not homogeneous, and due to differences in hardware configurations and network conditions, can have highly varying processing times. We consider smooth nonconvex finite-sum (empirical risk minimization) problems in this setup and introduce a new parallel method, Freya PAGE, designed to handle arbitrarily heterogeneous and asynchronous computations. By being robust to "stragglers" and adaptively ignoring slow computations, Freya PAGE offers significantly improved time complexity guarantees compared to all previous methods, including Asynchronous SGD, Rennala SGD, SPIDER, and PAGE, while requiring weaker assumptions. The algorithm relies on novel generic stochastic gradient collection strategies with theoretical guarantees that can be of interest on their own, and may be used in the design of future optimization methods. Furthermore, we establish a lower bound for smooth nonconvex finite-sum problems in the asynchronous setup, providing a fundamental time complexity limit. This lower bound is tight and demonstrates the optimality of Freya PAGE in the large-scale regime, i.e., when $\sqrt{m} \geq n$, where $n$ is # of workers, and $m$ is # of data samples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15545v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Alexander Tyurin, Kaja Gruntkowska, Peter Richt\'arik</dc:creator>
    </item>
    <item>
      <title>Stability and Performance Analysis of Model Predictive Control of Uncertain Linear Systems</title>
      <link>https://arxiv.org/abs/2405.15552</link>
      <description>arXiv:2405.15552v1 Announce Type: new 
Abstract: Model mismatch often poses challenges in model-based controller design. This paper investigates model predictive control (MPC) of uncertain linear systems with input constraints, focusing on stability and closed-loop infinite-horizon performance. The uncertainty arises from a parametric mismatch between the true and the estimated system under the matrix Frobenius norm. We examine a simple MPC controller that exclusively uses the estimated system model and establishes sufficient conditions under which the MPC controller can stabilize the true system. Moreover, we derive a theoretical performance bound based on relaxed dynamic programming, elucidating the impact of prediction horizon and modeling errors on the suboptimality gap between the MPC controller and the Oracle infinite-horizon optimal controller with knowledge of the true system. Simulations of a numerical example validate the theoretical results. Our theoretical analysis offers guidelines for obtaining the desired modeling accuracy and choosing a proper prediction horizon to develop certainty-equivalent MPC controllers for uncertain linear systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15552v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Changrui Liu, Shengling Shi, Bart De Schutter</dc:creator>
    </item>
    <item>
      <title>An analysis of Wardrop equilibrium and social optimum in congested transit networks</title>
      <link>https://arxiv.org/abs/2405.15631</link>
      <description>arXiv:2405.15631v1 Announce Type: new 
Abstract: The effective design and management of public transport systems are essential to ensure the best service for users. The performance of a transport system will depend heavily on user behaviour. In the common-lines problem approach, users choose which lines to use based on the best strategy for them. While Wardrop equilibrium has been studied for the common-lines problem, no contributions have been made towards achieving the social optimum. In this work, we propose two optimisation problems to obtain this optimum, using strategy flow and line flow formulations. We prove that both optimisation problems are equivalent, and we obtain a characterisation of the social optimum flows. The social optimum makes it possible to compute the price of anarchy (PoA), which quantifies the system's efficiency. The study of the PoA enables the effective design and management of public transport systems, guaranteeing the best service to users.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15631v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Victoria M. Orlandob, Iv\'an L. Degano, Pablo A. Lotito</dc:creator>
    </item>
    <item>
      <title>A Variable Neighborhood Search approach for solving the Rank Pricing Problem</title>
      <link>https://arxiv.org/abs/2405.15702</link>
      <description>arXiv:2405.15702v1 Announce Type: new 
Abstract: The Rank Pricing Problem (RPP) is a challenging bilevel optimization problem with binary variables whose objective is to determine the optimal pricing strategy for a set of products to maximize the total benefit, given that customer preferences influence the price for each product. Traditional methods for solving RPP are based on exact approaches which may be computationally expensive. In contrast, this paper presents a novel approach utilizing Variable Neighborhood Search (VNS), a popular heuristic known for its effectiveness in solving combinatorial optimization problems. Our proposed VNS algorithm introduces problem-specific neighborhood operators designed to effectively explore the solution space of the RPP. Even though our methodology does not have optimality guarantees, our computational experiments show that it outperforms Mixed Integer Program solvers regarding solution quality and computational burden.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15702v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Asunci\'on Jim\'enez-Cordero, Salvador Pineda, Juan Miguel Morales</dc:creator>
    </item>
    <item>
      <title>Multi-objective control for stochastic parabolic equations with dynamic boundary conditions</title>
      <link>https://arxiv.org/abs/2405.15730</link>
      <description>arXiv:2405.15730v1 Announce Type: new 
Abstract: This paper deals with a hierarchical multi-objective control problem for forward stochastic parabolic equations with dynamic boundary conditions. The controls are divided into two classes: leaders and followers. The goal of the leaders is of null controllability type while the followers are in charge of letting the state close to prescribed targets in fixed observation regions. To solve the problem, Nash and Stackelberg strategies are used. To implement these strategies, we combine some appropriate Carleman estimates and the well-known control duality approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15730v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Omar Oukdach, Said Boulite, Abdellatif Elgrou, Lahcen Maniar</dc:creator>
    </item>
    <item>
      <title>Sliding-Mode Nash Equilibrium Seeking for a Quadratic Duopoly Game</title>
      <link>https://arxiv.org/abs/2405.15762</link>
      <description>arXiv:2405.15762v1 Announce Type: new 
Abstract: This paper introduces a new method to achieve stable convergence to Nash equilibrium in duopoly noncooperative games. Inspired by the recent fixed-time Nash Equilibrium seeking (NES) as well as prescribed-time extremum seeking (ES) and source seeking schemes, our approach employs a distributed sliding mode control (SMC) scheme, integrating extremum seeking with sinusoidal perturbation signals to estimate the pseudogradients of quadratic payoff functions. Notably, this is the first attempt to address noncooperative games without relying on models, combining classical extremum seeking with relay components instead of proportional control laws. We prove finite-time convergence of the closed-loop average system to Nash equilibrium using stability analysis techniques such as time-scaling, Lyapunov's direct method, and averaging theory for discontinuous systems. Additionally, we quantify the size of residual sets around the Nash equilibrium and validate our theoretical results through simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15762v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Victor Hugo Pereira Rodrigues, Tiago Roux Oliveira, Miroslav Krsti\'c, Tamer Ba\c{s}ar</dc:creator>
    </item>
    <item>
      <title>Interpretable Price Bounds Estimation with Shape Constraints in Price Optimization</title>
      <link>https://arxiv.org/abs/2405.14909</link>
      <description>arXiv:2405.14909v1 Announce Type: cross 
Abstract: This paper addresses the interpretable estimation of price bounds within the context of price optimization. In recent years, price optimization methods have become indispensable for maximizing revenues and profits. However, effectively applying these methods to real-world pricing operations remains a significant challenge. It is crucial for operators, who are responsible for setting prices, to utilize reasonable price bounds that are not only interpretable but also acceptable. Despite this necessity, most studies assume that price bounds are given constant values, and few have explored the reasonable determination of these bounds. In response, we propose a comprehensive framework for determining price bounds, which includes both the estimation and adjustment of these bounds. Specifically, we first estimate the price bounds using three distinct approaches based on historical pricing data. We then adjust the estimated price bounds by solving an optimization problem that incorporates shape constraints. This method allows for the implementation of price optimization under practical and reasonable price bounds, suitable for real-world applications. We report the effectiveness of our proposed method through numerical experiments conducted with historical pricing data from actual services.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14909v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shunnosuke Ikeda, Naoki Nishimura, Shunji Umetani</dc:creator>
    </item>
    <item>
      <title>On Robust Controlled Invariants for Continuous-time Monotone Systems</title>
      <link>https://arxiv.org/abs/2405.14920</link>
      <description>arXiv:2405.14920v1 Announce Type: cross 
Abstract: This paper delves into the problem of computing robust controlled invariants for monotone continuous-time systems, with a specific focus on lower-closed specifications. We consider the classes of state monotone (SM) and control-state monotone (CSM) systems, we provide the structural properties of robust controlled invariants for these classes of systems and show how these classes significantly impact the computation of invariants. Additionally, we introduce a notion of feasible points, demonstrating that their existence is sufficient to characterize robust controlled invariants for the considered class of systems. The study further investigates the necessity of reducing the feasibility condition for CSM and Lipschitz systems, unveiling conditions that guide this reduction. Leveraging these insights, we construct an algorithm for the computation of robust controlled invariants. To demonstrate the practicality of our approach, we applied the developed algorithm to the coupled tank problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14920v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Emmanuel Junior Wafo Wembe, Adnane Saoud</dc:creator>
    </item>
    <item>
      <title>Two-Stage ML-Guided Decision Rules for Sequential Decision Making under Uncertainty</title>
      <link>https://arxiv.org/abs/2405.14973</link>
      <description>arXiv:2405.14973v1 Announce Type: cross 
Abstract: Sequential Decision Making under Uncertainty (SDMU) is ubiquitous in many domains such as energy, finance, and supply chains. Some SDMU applications are naturally modeled as Multistage Stochastic Optimization Problems (MSPs), but the resulting optimizations are notoriously challenging from a computational standpoint. Under assumptions of convexity and stage-wise independence of the uncertainty, the resulting optimization can be solved efficiently using Stochastic Dual Dynamic Programming (SDDP). Two-stage Linear Decision Rules (TS-LDRs) have been proposed to solve MSPs without the stage-wise independence assumption. TS-LDRs are computationally tractable, but using a policy that is a linear function of past observations is typically not suitable for non-convex environments arising, for example, in energy systems. This paper introduces a novel approach, Two-Stage General Decision Rules (TS-GDR), to generalize the policy space beyond linear functions, making them suitable for non-convex environments. TS-GDR is a self-supervised learning algorithm that trains the nonlinear decision rules using stochastic gradient descent (SGD); its forward passes solve the policy implementation optimization problems, and the backward passes leverage duality theory to obtain closed-form gradients. The effectiveness of TS-GDR is demonstrated through an instantiation using Deep Recurrent Neural Networks named Two-Stage Deep Decision Rules (TS-DDR). The method inherits the flexibility and computational performance of Deep Learning methodologies to solve SDMU problems generally tackled through large-scale optimization techniques. Applied to the Long-Term Hydrothermal Dispatch (LTHD) problem using actual power system data from Bolivia, the TS-DDR not only enhances solution quality but also significantly reduces computation times by several orders of magnitude.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14973v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Andrew Rosemberg, Alexandre Street, Davi M. Vallad\~ao, Pascal Van Hentenryck</dc:creator>
    </item>
    <item>
      <title>Metabelian distributions and sub-Riemannian geodesics</title>
      <link>https://arxiv.org/abs/2405.14997</link>
      <description>arXiv:2405.14997v1 Announce Type: cross 
Abstract: We begin by characterizing metabelian distributions in terms of principal bundle structures. Then, we prove that in sub-Riemannian manifolds with metabelian distributions of rank $r$, the projection of strictly singular trajectories to some $r$-dimensional manifold must remain within an analytic variety. As a consequence, for rank-2 metabelian distributions, geodesics are of class $C^1$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14997v1</guid>
      <category>math.DG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Enrico Le Donne, Nicola Paddeu, Alessandro Socionovo</dc:creator>
    </item>
    <item>
      <title>Polyak Meets Parameter-free Clipped Gradient Descent</title>
      <link>https://arxiv.org/abs/2405.15010</link>
      <description>arXiv:2405.15010v1 Announce Type: cross 
Abstract: Gradient descent and its variants are de facto standard algorithms for training machine learning models. As gradient descent is sensitive to its hyperparameters, we need to tune the hyperparameters carefully using a grid search, but it is time-consuming, especially when multiple hyperparameters exist. Recently, parameter-free methods that adjust the hyperparameters on the fly have been studied. However, the existing work only studied parameter-free methods for the stepsize, and parameter-free methods for other hyperparameters have not been explored. For instance, the gradient clipping threshold is also a crucial hyperparameter in addition to the stepsize to prevent gradient explosion issues, but none of the existing studies investigated the parameter-free methods for clipped gradient descent. In this work, we study the parameter-free methods for clipped gradient descent. Specifically, we propose Inexact Polyak Stepsize, which converges to the optimal solution without any hyperparameters tuning, and its convergence rate is asymptotically independent of L under L-smooth and $(L_0, L_1)$-smooth assumptions of the loss function as that of clipped gradient descent with well-tuned hyperparameters. We numerically validated our convergence results using a synthetic function and demonstrated the effectiveness of our proposed methods using LSTM, Nano-GPT, and T5.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15010v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuki Takezawa, Han Bao, Ryoma Sato, Kenta Niwa, Makoto Yamada</dc:creator>
    </item>
    <item>
      <title>4+3 Phases of Compute-Optimal Neural Scaling Laws</title>
      <link>https://arxiv.org/abs/2405.15074</link>
      <description>arXiv:2405.15074v1 Announce Type: cross 
Abstract: We consider the three parameter solvable neural scaling model introduced by Maloney, Roberts, and Sully. The model has three parameters: data complexity, target complexity, and model-parameter-count. We use this neural scaling model to derive new predictions about the compute-limited, infinite-data scaling law regime. To train the neural scaling model, we run one-pass stochastic gradient descent on a mean-squared loss. We derive a representation of the loss curves which holds over all iteration counts and improves in accuracy as the model parameter count grows. We then analyze the compute-optimal model-parameter-count, and identify 4 phases (+3 subphases) in the data-complexity/target-complexity phase-plane. The phase boundaries are determined by the relative importance of model capacity, optimizer noise, and embedding of the features. We furthermore derive, with mathematical proof and extensive numerical evidence, the scaling-law exponents in all of these phases, in particular computing the optimal model-parameter-count as a function of floating point operation budget.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15074v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Elliot Paquette, Courtney Paquette, Lechao Xiao, Jeffrey Pennington</dc:creator>
    </item>
    <item>
      <title>Minimizing UCB: a Better Local Search Strategy in Local Bayesian Optimization</title>
      <link>https://arxiv.org/abs/2405.15285</link>
      <description>arXiv:2405.15285v1 Announce Type: cross 
Abstract: Local Bayesian optimization is a promising practical approach to solve the high dimensional black-box function optimization problem. Among them is the approximated gradient class of methods, which implements a strategy similar to gradient descent. These methods have achieved good experimental results and theoretical guarantees. However, given the distributional properties of the Gaussian processes applied on these methods, there may be potential to further exploit the information of the Gaussian processes to facilitate the BO search. In this work, we develop the relationship between the steps of the gradient descent method and one that minimizes the Upper Confidence Bound (UCB), and show that the latter can be a better strategy than direct gradient descent when a Gaussian process is applied as a surrogate. Through this insight, we propose a new local Bayesian optimization algorithm, MinUCB, which replaces the gradient descent step with minimizing UCB in GIBO. We further show that MinUCB maintains a similar convergence rate with GIBO. We then improve the acquisition function of MinUCB further through a look ahead strategy, and obtain a more efficient algorithm LA-MinUCB. We apply our algorithms on different synthetic and real-world functions, and the results show the effectiveness of our method. Our algorithms also illustrate improvements on local search strategies from an upper bound perspective in Bayesian optimization, and provides a new direction for future algorithm design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15285v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zheyi Fan, Wenyu Wang, Szu Hui Ng, Qingpei Hu</dc:creator>
    </item>
    <item>
      <title>Using covariance extension equation to solve the Nevanlinna-Pick interpolation with degree constraint</title>
      <link>https://arxiv.org/abs/2405.15533</link>
      <description>arXiv:2405.15533v1 Announce Type: cross 
Abstract: Nevanlinna-Pick interpolation problem has been widely studied in recent decades, however, the known algorithm is not simplistic and robust enough. This paper provide a new method to solve the Nevanlinna-Pick interpolation problem with degree constraint. It is based on the covariance extension equation proposed by Byrnes and Lindquist. A reformulation of the Nevanlinna-Pick interpolation problem is achieved and then solved by continuation method. This method need not calculate the initial value and a numerical example illustrates robustness and effciency of the proposed procedure</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15533v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cui Yufang</dc:creator>
    </item>
    <item>
      <title>Balanced truncation with conformal maps</title>
      <link>https://arxiv.org/abs/2405.15656</link>
      <description>arXiv:2405.15656v1 Announce Type: cross 
Abstract: We consider the problem of constructing reduced models for large scale systems with poles in general domains in the complex plane (as opposed to, e.g., the open left-half plane or the open unit disk). Our goal is to design a model reduction scheme, building upon theoretically established methodologies, yet encompassing this new class of models. To this aim, we develop a balanced truncation framework through conformal maps to handle poles in general domains. The major difference from classical balanced truncation resides in the formulation of the Gramians. We show that these new Gramians can still be computed by solving modified Lyapunov equations for specific conformal maps. A numerical algorithm to perform balanced truncation with conformal maps is developed and is tested on three numerical examples, namely a heat model, the Schr\"odinger equation, and the undamped linear wave equation, the latter two having spectra on the imaginary axis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15656v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alessandro Borghi, Tobias Breiten, Serkan Gugercin</dc:creator>
    </item>
    <item>
      <title>The Road Less Scheduled</title>
      <link>https://arxiv.org/abs/2405.15682</link>
      <description>arXiv:2405.15682v1 Announce Type: cross 
Abstract: Existing learning rate schedules that do not require specification of the optimization stopping step T are greatly out-performed by learning rate schedules that depend on T. We propose an approach that avoids the need for this stopping time by eschewing the use of schedules entirely, while exhibiting state-of-the-art performance compared to schedules across a wide family of problems ranging from convex problems to large-scale deep learning problems. Our Schedule-Free approach introduces no additional hyper-parameters over standard optimizers with momentum. Our method is a direct consequence of a new theory we develop that unifies scheduling and iterate averaging. An open source implementation of our method is available (https://github.com/facebookresearch/schedule_free).</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15682v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aaron Defazio (Alice),  Xingyu (Alice),  Yang, Harsh Mehta, Konstantin Mishchenko, Ahmed Khaled, Ashok Cutkosky</dc:creator>
    </item>
    <item>
      <title>A nonsmooth primal-dual method with interwoven PDE constraint solver</title>
      <link>https://arxiv.org/abs/2211.04807</link>
      <description>arXiv:2211.04807v3 Announce Type: replace 
Abstract: We introduce an efficient first-order primal-dual method for the solution of nonsmooth PDE-constrained optimization problems. We achieve this efficiency through not solving the PDE or its linearisation on each iteration of the optimization method. Instead, we run the method interwoven with a simple conventional linear system solver (Jacobi, Gauss-Seidel, conjugate gradients), always taking only one step of the linear system solver for each step of the optimization method. The control parameter is updated on each iteration as determined by the optimization method. We prove linear convergence under a second-order growth condition, and numerically demonstrate the performance on a variety of PDEs related to inverse problems involving boundary measurements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.04807v3</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bj{\o}rn Jensen, Tuomo Valkonen</dc:creator>
    </item>
    <item>
      <title>Nurse Scheduling Problem via PyQUBO</title>
      <link>https://arxiv.org/abs/2302.09459</link>
      <description>arXiv:2302.09459v2 Announce Type: replace 
Abstract: The nurse scheduling problem is a critical optimization challenge in healthcare management. It aims to balance staffing demands, nurse satisfaction, and patient care quality. Corresponding to the constraints inherent in this scheduling problem, we detail the mathematical formulation step-by-step. We then utilize a quantum-inspired technique, the simulated annealing algorithm, and a quadratic unconstrained binary optimization model to optimize workload and increase nurse preferences. Numerical experiments are implemented to show the capacity of our proposed techniques. Our findings indicate a promising direction for future research, with potential applications extending beyond nurse scheduling to other complex optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.09459v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matthew M. Lin, Yu-Chen Shu, Bing-Ze Lu, Pei-Shan Fang</dc:creator>
    </item>
    <item>
      <title>First-order methods for Stochastic Variational Inequality problems with Function Constraints</title>
      <link>https://arxiv.org/abs/2304.04778</link>
      <description>arXiv:2304.04778v3 Announce Type: replace 
Abstract: The monotone Variational Inequality (VI) is a general model with important applications in various engineering and scientific domains. In numerous instances, the VI problems are accompanied by function constraints that can be data-driven, making the usual projection operator challenging to compute. This paper presents novel first-order methods for the function-constrained Variational Inequality (FCVI) problem in smooth or nonsmooth settings with possibly stochastic operators and constraints. We introduce the AdOpEx method, which employs an operator extrapolation on the KKT operator of the FCVI in a smooth deterministic setting. Since this operator is not uniformly Lipschitz continuous in the Lagrange multipliers, we employ an adaptive two-timescale algorithm leading to bounded multipliers and achieving the optimal $O(1/T)$ convergence rate. For the nonsmooth and stochastic VIs, we introduce design changes to the AdOpEx method and propose a novel P-OpEx method that takes partial extrapolation. It converges at the rate of $O(1/\sqrt{T})$ when both the operator and constraints are stochastic or nonsmooth. This method has suboptimal dependence on the noise and Lipschitz constants of function constraints. We propose a constraint extrapolation approach leading to the OpConEx method that improves this dependence by an order of magnitude. All our algorithms easily extend to saddle point problems with function constraints that couple the primal and dual variables while maintaining the same complexity results. To the best of our knowledge, all our complexity results are new in the literature</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.04778v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Digvijay Boob, Qi Deng, Mohammad Khalafi</dc:creator>
    </item>
    <item>
      <title>Soft Robust MDPs and Risk-Sensitive MDPs: Equivalence, Policy Gradient, and Sample Complexity</title>
      <link>https://arxiv.org/abs/2306.11626</link>
      <description>arXiv:2306.11626v4 Announce Type: replace 
Abstract: Robust Markov Decision Processes (MDPs) and risk-sensitive MDPs are both powerful tools for making decisions in the presence of uncertainties. Previous efforts have aimed to establish their connections, revealing equivalences in specific formulations. This paper introduces a new formulation for risk-sensitive MDPs, which assesses risk in a slightly different manner compared to the classical Markov risk measure (Ruszczy\'nski 2010), and establishes its equivalence with a class of soft robust MDP (RMDP) problems, including the standard RMDP as a special case. Leveraging this equivalence, we further derive the policy gradient theorem for both problems, proving gradient domination and global convergence of the exact policy gradient method under the tabular setting with direct parameterization. This forms a sharp contrast to the Markov risk measure, known to be potentially non-gradient-dominant (Huang et al. 2021). We also propose a sample-based offline learning algorithm, namely the robust fitted-Z iteration (RFZI), for a specific soft RMDP problem with a KL-divergence regularization term (or equivalently the risk-sensitive MDP with an entropy risk measure). We showcase its streamlined design and less stringent assumptions due to the equivalence and analyze its sample complexity</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.11626v4</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Runyu Zhang, Yang Hu, Na Li</dc:creator>
    </item>
    <item>
      <title>Dual Lagrangian Learning for Conic Optimization</title>
      <link>https://arxiv.org/abs/2402.03086</link>
      <description>arXiv:2402.03086v2 Announce Type: replace 
Abstract: This paper presents Dual Lagrangian Learning (DLL), a principled learning methodology for dual conic optimization proxies. DLL leverages conic duality and the representation power of ML models to provide high-duality, dual-feasible solutions, and therefore valid Lagrangian dual bounds, for linear and nonlinear conic optimization problems. The paper introduces a systematic dual completion procedure, differentiable conic projection layers, and a self-supervised learning framework based on Lagrangian duality. It also provides closed-form dual completion formulae for broad classes of conic problems, which eliminate the need for costly implicit layers. The effectiveness of DLL is demonstrated on linear and nonlinear conic optimization problems. The proposed methodology significantly outperforms a state-of-the-art learning-based method, and achieves 1000x speedups over commercial interior-point solvers with optimality gaps under 0.5\% on average.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.03086v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mathieu Tanneau, Pascal Van Hentenryck</dc:creator>
    </item>
    <item>
      <title>Acceleration Exists! Optimization Problems When Oracle Can Only Compare Objective Function Values</title>
      <link>https://arxiv.org/abs/2402.09014</link>
      <description>arXiv:2402.09014v2 Announce Type: replace 
Abstract: Frequently, the burgeoning field of black-box optimization encounters challenges due to a limited understanding of the mechanisms of the objective function. To address such problems, in this work we focus on the deterministic concept of Order Oracle, which only utilizes order access between function values (possibly with some bounded noise), but without assuming access to their values. As theoretical results, we propose a new approach to create non-accelerated optimization algorithms (obtained by integrating Order Oracle into existing optimization "tools") in non-convex, convex, and strongly convex settings that are as good as both SOTA coordinate algorithms with first-order oracle and SOTA algorithms with Order Oracle up to logarithm factor. Moreover, using the proposed approach, we provide the first accelerated optimization algorithm using the Order Oracle. And also, using an already different approach we provide the asymptotic convergence of the first algorithm with the stochastic Order Oracle concept. Finally, our theoretical results demonstrate effectiveness of proposed algorithms through numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.09014v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aleksandr Lobanov, Alexander Gasnikov, Andrei Krasnov</dc:creator>
    </item>
    <item>
      <title>ADMM for Nonconvex Optimization under Minimal Continuity Assumption</title>
      <link>https://arxiv.org/abs/2405.03233</link>
      <description>arXiv:2405.03233v2 Announce Type: replace 
Abstract: This paper introduces a novel approach to solving multi-block nonconvex composite optimization problems through a proximal linearized Alternating Direction Method of Multipliers (ADMM). This method incorporates an Increasing Penalization and Decreasing Smoothing (IPDS) strategy. Distinguishing itself from existing ADMM-style algorithms, our approach (denoted IPDS-ADMM) imposes a less stringent condition, specifically requiring continuity in just one block of the objective function. IPDS-ADMM requires that the penalty increases and the smoothing parameter decreases, both at a controlled pace. When the associated linear operator is bijective, IPDS-ADMM uses an over-relaxation stepsize for faster convergence; however, when the linear operator is surjective, IPDS-ADMM uses an under-relaxation stepsize for global convergence. We devise a novel potential function to facilitate our convergence analysis and prove an oracle complexity $\mathcal{O}(\epsilon^{-3})$ to achieve an $\epsilon$-approximate critical point. To the best of our knowledge, this is the first complexity result for using ADMM to solve this class of nonsmooth nonconvex problems. Finally, some experiments on the sparse PCA problem are conducted to demonstrate the effectiveness of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03233v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ganzhao Yuan</dc:creator>
    </item>
    <item>
      <title>On the convergence of discrete dynamic unbalanced transport models</title>
      <link>https://arxiv.org/abs/2310.09420</link>
      <description>arXiv:2310.09420v2 Announce Type: replace-cross 
Abstract: A generalized unbalanced optimal transport distance ${\rm WB}_{\Lambda}$ on matrix-valued measures $\mathcal{M}(\Omega,\mathbb{S}_+^n)$ was defined in [arXiv:2011.05845] \`{a} la Benamou-Brenier, which extends the Kantorovich-Bures and the Wasserstein-Fisher-Rao distances. In this work, we investigate the convergence properties of the discrete transport problems associated with ${\rm WB}_{\Lambda}$. We first present a convergence framework for abstract discretization. Then, we propose a specific discretization scheme that aligns with this framework, under the assumption that the initial and final distributions are absolutely continuous with respect to the Lebesgue measure. Moreover, thanks to the static formulation, we show that such an assumption can be removed for the Wasserstein-Fisher-Rao distance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.09420v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bowen Li, Jun Zou</dc:creator>
    </item>
    <item>
      <title>Optimal Algorithms for Online Convex Optimization with Adversarial Constraints</title>
      <link>https://arxiv.org/abs/2310.18955</link>
      <description>arXiv:2310.18955v2 Announce Type: replace-cross 
Abstract: A well-studied generalization of the standard online convex optimization (OCO) is constrained online convex optimization (COCO). In COCO, on every round, a convex cost function and a convex constraint function are revealed to the learner after the action for that round is chosen. The objective is to design an online policy that simultaneously achieves a small regret while ensuring a small cumulative constraint violation (CCV) against an adaptive adversary interacting over a horizon of length $T$. A long-standing open question in COCO is whether an online policy can simultaneously achieve $O(\sqrt{T})$ regret and $O(\sqrt{T})$ CCV without any restrictive assumptions. For the first time, we answer this in the affirmative and show that an online policy can simultaneously achieve $O(\sqrt{T})$ regret and $\tilde{O}(\sqrt{T})$ CCV. Furthermore, in the case of strongly convex cost and convex constraint functions, the regret guarantee can be improved to $O(\log T)$ while keeping the CCV bound the same as above. We establish these results by effectively combining the adaptive regret bound of the AdaGrad algorithm with Lyapunov optimization - a classic tool from control theory. Surprisingly, the analysis is short and elegant.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.18955v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Abhishek Sinha, Rahul Vaze</dc:creator>
    </item>
    <item>
      <title>MetaOptimize: A Framework for Optimizing Step Sizes and Other Meta-parameters</title>
      <link>https://arxiv.org/abs/2402.02342</link>
      <description>arXiv:2402.02342v3 Announce Type: replace-cross 
Abstract: This paper addresses the challenge of optimizing meta-parameters (i.e., hyperparameters) in machine learning algorithms, a critical factor influencing training efficiency and model performance. Moving away from the computationally expensive traditional meta-parameter search methods, we introduce MetaOptimize framework that dynamically adjusts meta-parameters, particularly step sizes (also known as learning rates), during training. More specifically, MetaOptimize can wrap around any first-order optimization algorithm, tuning step sizes on the fly to minimize a specific form of regret that accounts for long-term effect of step sizes on training, through a discounted sum of future losses. We also introduce low complexity variants of MetaOptimize that, in conjunction with its adaptability to multiple optimization algorithms, demonstrate performance competitive to those of best hand-crafted learning rate schedules across various machine learning applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.02342v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arsalan Sharifnassab, Saber Salehkaleybar, Richard Sutton</dc:creator>
    </item>
    <item>
      <title>Principled Penalty-based Methods for Bilevel Reinforcement Learning and RLHF</title>
      <link>https://arxiv.org/abs/2402.06886</link>
      <description>arXiv:2402.06886v2 Announce Type: replace-cross 
Abstract: Bilevel optimization has been recently applied to many machine learning tasks. However, their applications have been restricted to the supervised learning setting, where static objective functions with benign structures are considered. But bilevel problems such as incentive design, inverse reinforcement learning (RL), and RL from human feedback (RLHF) are often modeled as dynamic objective functions that go beyond the simple static objective structures, which pose significant challenges of using existing bilevel solutions. To tackle this new class of bilevel problems, we introduce the first principled algorithmic framework for solving bilevel RL problems through the lens of penalty formulation. We provide theoretical studies of the problem landscape and its penalty-based (policy) gradient algorithms. We demonstrate the effectiveness of our algorithms via simulations in the Stackelberg Markov game, RL from human feedback and incentive design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.06886v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Han Shen, Zhuoran Yang, Tianyi Chen</dc:creator>
    </item>
    <item>
      <title>Toward TransfORmers: Revolutionizing the Solution of Mixed Integer Programs with Transformers</title>
      <link>https://arxiv.org/abs/2402.13380</link>
      <description>arXiv:2402.13380v3 Announce Type: replace-cross 
Abstract: In this study, we introduce an innovative deep learning framework that employs a transformer model to address the challenges of mixed-integer programs, specifically focusing on the Capacitated Lot Sizing Problem (CLSP). Our approach, to our knowledge, is the first to utilize transformers to predict the binary variables of a mixed-integer programming (MIP) problem. Specifically, our approach harnesses the encoder decoder transformer's ability to process sequential data, making it well-suited for predicting binary variables indicating production setup decisions in each period of the CLSP. This problem is inherently dynamic, and we need to handle sequential decision making under constraints. We present an efficient algorithm in which CLSP solutions are learned through a transformer neural network. The proposed post-processed transformer algorithm surpasses the state-of-the-art solver, CPLEX and Long Short-Term Memory (LSTM) in solution time, optimal gap, and percent infeasibility over 240K benchmark CLSP instances tested. After the ML model is trained, conducting inference on the model, reduces the MIP into a linear program (LP). This transforms the ML-based algorithm, combined with an LP solver, into a polynomial-time approximation algorithm to solve a well-known NP-Hard problem, with almost perfect solution quality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.13380v3</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.CO</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Joshua F. Cooper, Seung Jin Choi, I. Esra Buyuktahtakin</dc:creator>
    </item>
    <item>
      <title>Extended Flow Matching: a Method of Conditional Generation with Generalized Continuity Equation</title>
      <link>https://arxiv.org/abs/2402.18839</link>
      <description>arXiv:2402.18839v3 Announce Type: replace-cross 
Abstract: The task of conditional generation is one of the most important applications of generative models, and numerous methods have been developed to date based on the celebrated flow-based models. However, many flow-based models in use today are not built to allow one to introduce an explicit inductive bias to how the conditional distribution to be generated changes with respect to conditions. This can result in unexpected behavior in the task of style transfer, for example. In this research, we introduce extended flow matching (EFM), a direct extension of flow matching that learns a ``matrix field'' corresponding to the continuous map from the space of conditions to the space of distributions. We show that we can introduce inductive bias to the conditional generation through the matrix field and demonstrate this fact with MMOT-EFM, a version of EFM that aims to minimize the Dirichlet energy or the sensitivity of the distribution with respect to conditions. We will present our theory along with experimental results that support the competitiveness of EFM in conditional generation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.18839v3</guid>
      <category>cs.LG</category>
      <category>math.AP</category>
      <category>math.FA</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Noboru Isobe, Masanori Koyama, Kohei Hayashi, Kenji Fukumizu</dc:creator>
    </item>
    <item>
      <title>Cross-Diffusion Theory for Overcrowding Dispersal in Interacting Species System</title>
      <link>https://arxiv.org/abs/2403.06464</link>
      <description>arXiv:2403.06464v2 Announce Type: replace-cross 
Abstract: This work introduces a new class of cross-diffusion systems for studying overcrowding dispersal of two species. The approach, based on proximal minimization energy through a minimum flow process, offers a potential generalization of existing segregation models. Unlike prior methods using PDEs or $W_2$-Wasserstein flows, it establishes a well-posed PDE framework for capturing the interplay between diffusion and concentration gradients. This framework has the potential to significantly improve our understanding of how cross-diffusion shapes spatial patterns, coexistence, and overall distribution of multiple species. Notably, for homogeneous cases, the approach definitely leads to a well-defined PDE grounded in a new general $H^{-1}$-theory specifically developed for overcrowding dispersal. This theory provides a robust foundation for further analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06464v2</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Noureddine Igbida</dc:creator>
    </item>
    <item>
      <title>Tackling Prevalent Conditions in Unsupervised Combinatorial Optimization: Cardinality, Minimum, Covering, and More</title>
      <link>https://arxiv.org/abs/2405.08424</link>
      <description>arXiv:2405.08424v2 Announce Type: replace-cross 
Abstract: Combinatorial optimization (CO) is naturally discrete, making machine learning based on differentiable optimization inapplicable. Karalias &amp; Loukas (2020) adapted the probabilistic method to incorporate CO into differentiable optimization. Their work ignited the research on unsupervised learning for CO, composed of two main components: probabilistic objectives and derandomization. However, each component confronts unique challenges. First, deriving objectives under various conditions (e.g., cardinality constraints and minimum) is nontrivial. Second, the derandomization process is underexplored, and the existing derandomization methods are either random sampling or naive rounding. In this work, we aim to tackle prevalent (i.e., commonly involved) conditions in unsupervised CO. First, we concretize the targets for objective construction and derandomization with theoretical justification. Then, for various conditions commonly involved in different CO problems, we derive nontrivial objectives and derandomization to meet the targets. Finally, we apply the derivations to various CO problems. Via extensive experiments on synthetic and real-world graphs, we validate the correctness of our derivations and show our empirical superiority w.r.t. both optimization quality and speed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.08424v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fanchen Bu, Hyeonsoo Jo, Soo Yong Lee, Sungsoo Ahn, Kijung Shin</dc:creator>
    </item>
    <item>
      <title>PDE Control Gym: A Benchmark for Data-Driven Boundary Control of Partial Differential Equations</title>
      <link>https://arxiv.org/abs/2405.11401</link>
      <description>arXiv:2405.11401v2 Announce Type: replace-cross 
Abstract: Over the last decade, data-driven methods have surged in popularity, emerging as valuable tools for control theory. As such, neural network approximations of control feedback laws, system dynamics, and even Lyapunov functions have attracted growing attention. With the ascent of learning based control, the need for accurate, fast, and easy-to-use benchmarks has increased. In this work, we present the first learning-based environment for boundary control of PDEs. In our benchmark, we introduce three foundational PDE problems - a 1D transport PDE, a 1D reaction-diffusion PDE, and a 2D Navier-Stokes PDE - whose solvers are bundled in an user-friendly reinforcement learning gym. With this gym, we then present the first set of model-free, reinforcement learning algorithms for solving this series of benchmark problems, achieving stability, although at a higher cost compared to model-based PDE backstepping. With the set of benchmark environments and detailed examples, this work significantly lowers the barrier to entry for learning-based PDE control - a topic largely unexplored by the data-driven control community. The entire benchmark is available on Github along with detailed documentation and the presented reinforcement learning models are open sourced.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.11401v2</guid>
      <category>eess.SY</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luke Bhan, Yuexin Bian, Miroslav Krstic, Yuanyuan Shi</dc:creator>
    </item>
    <item>
      <title>An 808 Line Phasor-Based Dehomogenisation Matlab Code For Multi-Scale Topology Optimisation</title>
      <link>https://arxiv.org/abs/2405.14321</link>
      <description>arXiv:2405.14321v2 Announce Type: replace-cross 
Abstract: This work presents an 808-line Matlab educational code for combined multi-scale topology optimisation and phasor-based dehomogenisation titled deHomTop808. The multi-scale formulation utilises homogenisation of optimal microstructures to facilitate efficient coarse-scale optimisation. Dehomogenisation allows for a high-resolution single-scale reconstruction of the optimised multi-scale structure, achieving minor losses in structural performance, at a fraction of the computational cost, compared to its large-scale topology optimisation counterpart. The presented code utilises stiffness optimal Rank-2 microstructures to minimise the compliance of a single-load case problem, subject to a volume fraction constraint. By exploiting the inherent efficiency benefits of the phasor-based dehomogenisation procedure, on-the-fly dehomogenisation to a single-scale structure is obtained. The presented code includes procedures for structural verification of the final dehomogenised structure by comparison to the multi-scale solution. The code is introduced in terms of the underlying theory and its major components, including examples and potential extensions, and can be downloaded from https://github.com/peterdorffler/deHomTop808.git.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14321v2</guid>
      <category>cs.MS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rebekka Varum Woldseth, Ole Sigmund, Peter D{\o}rffler Ladegaard Jensen</dc:creator>
    </item>
  </channel>
</rss>
