<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DB updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DB</link>
    <description>cs.DB updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DB" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 15 Aug 2025 04:00:03 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Privacy-Preserving Approximate Nearest Neighbor Search on High-Dimensional Data</title>
      <link>https://arxiv.org/abs/2508.10373</link>
      <description>arXiv:2508.10373v1 Announce Type: new 
Abstract: In the era of cloud computing and AI, data owners outsource ubiquitous vectors to the cloud, which furnish approximate $k$-nearest neighbors ($k$-ANNS) services to users. To protect data privacy against the untrusted server, privacy-preserving $k$-ANNS (PP-ANNS) on vectors has been a fundamental and urgent problem. However, existing PP-ANNS solutions fall short of meeting the requirements of data privacy, efficiency, accuracy, and minimal user involvement concurrently. To tackle this challenge, we introduce a novel solution that primarily executes PP-ANNS on a single cloud server to avoid the heavy communication overhead between the cloud and the user. To ensure data privacy, we introduce a novel encryption method named distance comparison encryption, facilitating secure, efficient, and exact distance comparisons. To optimize the trade-off between data privacy and search performance, we design a privacy-preserving index that combines the state-of-the-art $k$-ANNS method with an approximate distance computation method. Then, we devise a search method using a filter-and-refine strategy based on the index. Moreover, we provide the security analysis of our solution and conduct extensive experiments to demonstrate its superiority over existing solutions. Based on our experimental results, our method accelerates PP-ANNS by up to 3 orders of magnitude compared to state-of-the-art methods, while not compromising the accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10373v1</guid>
      <category>cs.DB</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/ICDE65448.2025.00226</arxiv:DOI>
      <dc:creator>Yingfan Liu, Yandi Zhang, Jiadong Xie, Hui Li, Jeffrey Xu Yu, Jiangtao Cui</dc:creator>
    </item>
    <item>
      <title>Cross-Organizational Analysis of Parliamentary Processes: A Case Study</title>
      <link>https://arxiv.org/abs/2508.10381</link>
      <description>arXiv:2508.10381v1 Announce Type: new 
Abstract: Process Mining has been widely adopted by businesses and has been shown to help organizations analyze and optimize their processes. However, so far, little attention has gone into the cross-organizational comparison of processes, since many companies are hesitant to share their data. In this paper, we explore the processes of German state parliaments that are often legally required to share their data and run the same type of processes for different geographical regions. This paper is the first attempt to apply process mining to parliamentary processes and, therefore, contributes toward a novel interdisciplinary research area that combines political science and process mining. In our case study, we analyze legislative processes of three German state parliaments and generate insights into their differences and best practices. We provide a discussion of the relevance of our results that are based on knowledge exchange with a political scientist and a domain expert from the German federal parliament.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10381v1</guid>
      <category>cs.DB</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Paul-Julius Hillmann, Stephan A. Fahrenkrog-Petersen, Jan Mendling</dc:creator>
    </item>
    <item>
      <title>Efficient Methods for Accurate Sparse Trajectory Recovery and Map Matching</title>
      <link>https://arxiv.org/abs/2508.10460</link>
      <description>arXiv:2508.10460v1 Announce Type: new 
Abstract: Real-world trajectories are often sparse with low-sampling rates (i.e., long intervals between consecutive GPS points) and misaligned with road networks, yet many applications demand high-quality data for optimal performance. To improve data quality with sparse trajectories as input, we systematically study two related research problems: trajectory recovery on road network, which aims to infer missing points to recover high-sampling trajectories, and map matching, which aims to map GPS points to road segments to determine underlying routes. In this paper, we present efficient methods TRMMA and MMA for accurate trajectory recovery and map matching, respectively, where MMA serves as the first step of TRMMA. In MMA, we carefully formulate a classification task to map a GPS point from sparse trajectories to a road segment over a small candidate segment set, rather than the entire road network. We develop techniques in MMA to generate effective embeddings that capture the patterns of GPS data, directional information, and road segments, to accurately align sparse trajectories to routes. For trajectory recovery, TRMMA focuses on the segments in the route returned by MMA to infer missing points with position ratios on road segments, producing high-sampling trajectories efficiently by avoiding evaluation of all road segments. Specifically, in TRMMA, we design a dual-transformer encoding process to cohesively capture latent patterns in trajectories and routes, and an effective decoding technique to sequentially predict the position ratios and road segments of missing points. We conduct extensive experiments to compare TRMMA and MMA with numerous existing methods for trajectory recovery and map matching, respectively, on 4 large real-world datasets. TRMMA and MMA consistently achieve the best result quality, often by a significant margin.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10460v1</guid>
      <category>cs.DB</category>
      <category>cs.LG</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1109/ICDE65448.2025.00034</arxiv:DOI>
      <dc:creator>Wei Tian, Jieming Shi, Man Lung Yiu</dc:creator>
    </item>
    <item>
      <title>Advances in Logic-Based Entity Resolution: Enhancing ASPEN with Local Merges and Optimality Criteria</title>
      <link>https://arxiv.org/abs/2508.10504</link>
      <description>arXiv:2508.10504v1 Announce Type: new 
Abstract: In this paper, we present ASPEN+, which extends an existing ASP-based system, ASPEN,for collective entity resolution with two important functionalities: support for local merges and new optimality criteria for preferred solutions. Indeed, ASPEN only supports so-called global merges of entity-referring constants (e.g. author ids), in which all occurrences of matched constants are treated as equivalent and merged accordingly. However, it has been argued that when resolving data values, local merges are often more appropriate, as e.g. some instances of 'J. Lee' may refer to 'Joy Lee', while others should be matched with 'Jake Lee'. In addition to allowing such local merges, ASPEN+ offers new optimality criteria for selecting solutions, such as minimizing rule violations or maximising the number of rules supporting a merge. Our main contributions are thus (1) the formalisation and computational analysis of various notions of optimal solution, and (2) an extensive experimental evaluation on real-world datasets, demonstrating the effect of local merges and the new optimality criteria on both accuracy and runtime.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10504v1</guid>
      <category>cs.DB</category>
      <category>cs.AI</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Zhliang Xiang, Meghyn Bienvenu, Gianluca Cima, V\'ictor Guti\'errez-Basulto, Yazm\'in Ib\'a\~nez-Garc\'ia</dc:creator>
    </item>
    <item>
      <title>Emerging Skycube</title>
      <link>https://arxiv.org/abs/2508.10516</link>
      <description>arXiv:2508.10516v1 Announce Type: new 
Abstract: Combining multi-criteria decision analysis and trend reversal discovery make it possible to extract globally optimal, or non-dominated, data in relation to several criteria, and then to observe their evolution according to a decision-making property. Thus, we introduce Emerging Skycube, a concept associating Skycube and emerging datacube. As far as we know, no DBMS-integrated solution exists to compute an emerging Skycube, and hence taking advantage of ROLAP analysis tools. An emerging datacube has only one measure: we propose to use several to comply to multi-criteria decision analysis constraints which requires multiple attributes. A datacube is expensive to compute. An emerging datacube is about twice as expensive. On the other hand, an emerging Skycube is cheaper as the trend reversal is computed after two Skycube calculations, which considerably reduces the relation volume in comparison with the initial one. It is possible to save even more computing time and storage space. To this end, we propose two successive reductions. First, a Skycube lossless partial materialisation using Skylines concepts lattice, based on the agree concepts lattice and partitions lattice. Then, either the closed emerging Skycube for an information-loss reduction, or the closed emerging L-Skycube for a smaller but lossless reduction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10516v1</guid>
      <category>cs.DB</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s10115-024-02320-2</arxiv:DOI>
      <dc:creator>Micka\"el Martin Nevot (LIS, AMU, IACD)</dc:creator>
    </item>
    <item>
      <title>MAPS: A Multilingual Benchmark for Global Agent Performance and Security</title>
      <link>https://arxiv.org/abs/2505.15935</link>
      <description>arXiv:2505.15935v2 Announce Type: replace 
Abstract: Agentic AI systems, which build on Large Language Models (LLMs) and interact with tools and memory, have rapidly advanced in capability and scope. Yet, since LLMs have been shown to struggle in multilingual settings, typically resulting in lower performance and reduced safety, agentic systems risk inheriting these limitations. This raises concerns about the accessibility of such systems, as users interacting in languages other than English may encounter unreliable or security-critical agent behavior. Despite growing interest in evaluating agentic AI, existing benchmarks focus exclusively on English, leaving multilingual settings unexplored. To address this gap, we propose MAPS, a multilingual benchmark suite designed to evaluate agentic AI systems across diverse languages and tasks. MAPS builds on four widely used agentic benchmarks - GAIA (real-world tasks), SWE-bench (code generation), MATH (mathematical reasoning), and the Agent Security Benchmark (security). We translate each dataset into eleven diverse languages, resulting in 805 unique tasks and 9,660 total language-specific instances - enabling a systematic analysis of the multilingual effect on AI agents' performance and robustness. Empirically, we observe degradation in both performance and security when transitioning from English to other languages, with severity varying by task and correlating with the amount of translated input. Building on these findings, we provide actionable recommendations to guide agentic AI systems development and assessment under multilingual settings. This work establishes the first standardized evaluation framework for multilingual agentic AI, encouraging future research towards equitable, reliable, and accessible agentic AI. MAPS benchmark suite is publicly available at https://huggingface.co/datasets/Fujitsu-FRE/MAPS</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.15935v2</guid>
      <category>cs.DB</category>
      <category>cs.CL</category>
      <category>cs.CR</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Omer Hofman, Jonathan Brokman, Oren Rachmil, Shamik Bose, Vikas Pahuja, Toshiya Shimizu, Trisha Starostina, Kelly Marchisio, Seraphina Goldfarb-Tarrant, Roman Vainshtein</dc:creator>
    </item>
    <item>
      <title>Leveraging large language models for SQL behavior-based database intrusion detection</title>
      <link>https://arxiv.org/abs/2508.05690</link>
      <description>arXiv:2508.05690v2 Announce Type: replace-cross 
Abstract: Database systems are extensively used to store critical data across various domains. However, the frequency of abnormal database access behaviors, such as database intrusion by internal and external attacks, continues to rise. Internal masqueraders often have greater organizational knowledge, making it easier to mimic employee behavior effectively. In contrast, external masqueraders may behave differently due to their lack of familiarity with the organization. Current approaches lack the granularity needed to detect anomalies at the operational level, frequently misclassifying entire sequences of operations as anomalies, even though most operations are likely to represent normal behavior. On the other hand, some anomalous behaviors often resemble normal activities, making them difficult for existing detection methods to identify. This paper introduces a two-tiered anomaly detection approach for Structured Query Language (SQL) using the Bidirectional Encoder Representations from Transformers (BERT) model, specifically DistilBERT, a more efficient, pre-trained version. Our method combines both unsupervised and supervised machine learning techniques to accurately identify anomalous activities while minimizing the need for data labeling. First, the unsupervised method uses ensemble anomaly detectors that flag embedding vectors distant from learned normal patterns of typical user behavior across the database (out-of-scope queries). Second, the supervised method uses fine-tuned transformer-based models to detect internal attacks with high precision (in-scope queries), using role-labeled classification, even on limited labeled SQL data. Our findings make a significant contribution by providing an effective solution for safeguarding critical database systems from sophisticated threats.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.05690v2</guid>
      <category>cs.CR</category>
      <category>cs.DB</category>
      <category>cs.LG</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Meital Shlezinger, Shay Akirav, Lei Zhou, Liang Guo, Avi Kessel, Guoliang Li</dc:creator>
    </item>
    <item>
      <title>Columbo: Expanding Abbreviated Column Names for Tabular Data Using Large Language Models</title>
      <link>https://arxiv.org/abs/2508.09403</link>
      <description>arXiv:2508.09403v2 Announce Type: replace-cross 
Abstract: Expanding the abbreviated column names of tables, such as "esal" to "employee salary", is critical for numerous downstream data tasks. This problem arises in enterprises, domain sciences, government agencies, and more. In this paper we make three contributions that significantly advances the state of the art. First, we show that synthetic public data used by prior work has major limitations, and we introduce 4 new datasets in enterprise/science domains, with real-world abbreviations. Second, we show that accuracy measures used by prior work seriously undercount correct expansions, and we propose new synonym-aware measures that capture accuracy much more accurately. Finally, we develop Columbo, a powerful LLM-based solution that exploits context, rules, chain-of-thought reasoning, and token-level analysis. Extensive experiments show that Columbo significantly outperforms NameGuess, the current most advanced solution, by 4-29%, over 5 datasets. Columbo has been used in production on EDI, a major data portal for environmental sciences.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.09403v2</guid>
      <category>cs.CL</category>
      <category>cs.DB</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ting Cai, Stephen Sheen, AnHai Doan</dc:creator>
    </item>
  </channel>
</rss>
