<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.FL updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.FL</link>
    <description>cs.FL updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.FL" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 02 May 2025 01:30:32 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 01 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Statistical process discovery</title>
      <link>https://arxiv.org/abs/2504.21390</link>
      <description>arXiv:2504.21390v1 Announce Type: new 
Abstract: Stochastic process discovery is concerned with deriving a model capable of reproducing the stochastic character of observed executions of a given process, stored in a log. This leads to an optimisation problem in which the model's parameter space is searched for, driven by the resemblance between the log's and the model's stochastic languages. The bottleneck of such optimisation problem lay in the determination of the model's stochastic language which existing approaches deal with through, hardly scalable, exact computation approaches. In this paper we introduce a novel framework in which we combine a simulation-based Bayesian parameter inference scheme, used to search for the ``optimal'' instance of a stochastic model, with an expressive statistical model checking engine, used (during inference) to approximate the language of the considered model's instance. Because of its simulation-based nature, the payoff is that, the runtime for discovering of the optimal instance of a model can be easily traded in for accuracy, hence allowing to treat large models which would result in a prohibitive runtime with non-simulation based alternatives. We validate our approach on several popular event logs concerning real-life systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.21390v1</guid>
      <category>cs.FL</category>
      <pubDate>Thu, 01 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pierre Cry, Paolo Ballarini, Andr\'as Horv\'ath, Pascale Le Gall</dc:creator>
    </item>
    <item>
      <title>Active learning of upward-closed sets of words</title>
      <link>https://arxiv.org/abs/2504.21429</link>
      <description>arXiv:2504.21429v1 Announce Type: new 
Abstract: We give a new proof of a result from well quasi-order theory on the computability of bases for upwards-closed sets of words. This new proof is based on Angluin's $L^*$ algorithm, that learns an automaton from a minimally adequate teacher. This relates in particular two results from the 1980s: Angluin's $L^*$ algorithm, and a result from Valk and Jantzen on the computability of bases for upwards-closed sets of tuples of integers. Along the way, we describe an algorithm for learning quasi-ordered automata from a minimally adequate teacher, and extend a generalization of Valk and Jantzen's result, encompassing both words and integers, to finitely generated monoids.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.21429v1</guid>
      <category>cs.FL</category>
      <pubDate>Thu, 01 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Quentin Aristote (UPCit\'e, IRIF, PICUBE)</dc:creator>
    </item>
    <item>
      <title>Efficiently Finding All Minimal and Shortest Absent Subsequences in a String</title>
      <link>https://arxiv.org/abs/2504.21471</link>
      <description>arXiv:2504.21471v1 Announce Type: cross 
Abstract: Given a string $w$, another string $v$ is said to be a subsequence of $w$ if $v$ can be obtained from $w$ by removing some of its letters; on the other hand, $v$ is called an absent subsequence of $w$ if $v$ is not a subsequence of $w$. The existing literature on absent subsequences focused on understanding, for a string $w$, the set of its shortest absent subsequences (i.e., the shortest strings which are absent subsequences of $w$) and that of its minimal absent subsequences (i.e., those strings which are absent subsequences of $w$ but whose every proper subsequence occurs in $w$). Our contributions to this area of research are the following. Firstly, we present optimal algorithms (with linear time preprocessing and output-linear delay) for the enumeration of the shortest and, respectively, minimal absent subsequences. Secondly, we present optimal algorithms for the incremental enumeration of these strings with linear time preprocessing and constant delay; in this setting, we only output short edit-scripts showing how the currently enumerated string differs from the previous one. Finally, we provide an efficient algorithm for identifying a longest minimal absent subsequence of a string. All our algorithms improve the state-of-the-art results for the aforementioned problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.21471v1</guid>
      <category>cs.DS</category>
      <category>cs.FL</category>
      <pubDate>Thu, 01 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Florin Manea, Tina Ringleb, Stefan Siemer, Maximilian Winkler</dc:creator>
    </item>
    <item>
      <title>Neuro-Symbolic Generation of Explanations for Robot Policies with Weighted Signal Temporal Logic</title>
      <link>https://arxiv.org/abs/2504.21841</link>
      <description>arXiv:2504.21841v1 Announce Type: cross 
Abstract: Neural network-based policies have demonstrated success in many robotic applications, but often lack human-explanability, which poses challenges in safety-critical deployments. To address this, we propose a neuro-symbolic explanation framework that generates a weighted signal temporal logic (wSTL) specification to describe a robot policy in a interpretable form. Existing methods typically produce explanations that are verbose and inconsistent, which hinders explainability, and loose, which do not give meaningful insights into the underlying policy. We address these issues by introducing a simplification process consisting of predicate filtering, regularization, and iterative pruning. We also introduce three novel explainability evaluation metrics -- conciseness, consistency, and strictness -- to assess explanation quality beyond conventional classification metrics. Our method is validated in three simulated robotic environments, where it outperforms baselines in generating concise, consistent, and strict wSTL explanations without sacrificing classification accuracy. This work bridges policy learning with formal methods, contributing to safer and more transparent decision-making in robotics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.21841v1</guid>
      <category>cs.RO</category>
      <category>cs.FL</category>
      <pubDate>Thu, 01 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mikihisa Yuasa, Ramavarapu S. Sreenivas, Huy T. Tran</dc:creator>
    </item>
    <item>
      <title>Mining Diamonds in labeled Transition Systems</title>
      <link>https://arxiv.org/abs/2501.08689</link>
      <description>arXiv:2501.08689v2 Announce Type: replace 
Abstract: Labeled transition systems can be a great way to visualize the complex behavior of parallel and communicating systems. However, if, during a particular timeframe, no synchronization or communication between processes occurs, then multiple parallel sequences of actions are able to interleave arbitrarily, and the resulting graph quickly becomes too complex for the human eye to understand easily. With that in mind, we propose an exact formalization of these arbitrary interleavings, and an algorithm to find all said interleavings in deterministic LTSs, to reduce the visual complexity of labeled transition systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08689v2</guid>
      <category>cs.FL</category>
      <pubDate>Thu, 01 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>P. H. M. van Spaendonck, K. H. J. Jilissen</dc:creator>
    </item>
    <item>
      <title>Nondeterminism makes unary 1-limited automata concise</title>
      <link>https://arxiv.org/abs/2504.08464</link>
      <description>arXiv:2504.08464v2 Announce Type: replace 
Abstract: We investigate the descriptional complexity of different variants of 1-limited automata (1-las), an extension of two-way finite automata (2nfas) characterizing regular languages. In particular, we consider 2nfas with common-guess (2nfas+cg), which are 2nfas equipped with a new kind of nondeterminism that allows the device to initially annotate each input symbol, before performing a read-only computation over the resulting annotated word. Their deterministic counterparts, namely two-way deterministic finite automata with common-guess (2dfas+cg), still have a nondeterministic annotation phase and can be considered as a restriction of 1-las. We prove exponential lower bounds for the simulations of 2dfas+cg (and thus of 1-las) by deterministic 1-las and by 2nfas. These results are derived from a doubly exponential lower bound for the simulation of 2dfas+cg by one-way deterministic finite automata (1dfas). Our lower bounds are witnessed by unary languages, namely languages defined over a singleton alphabet. As a consequence, we close a question left open in [Pighizzini and Prigioniero. Limited automata and unary languages. Inf. Comput., 266:60-74], about the existence of a double exponential gap between 1-las and 1dfas in the unary case. Lastly, we prove an exponential lower bound for complementing unary 2dfas+cg (and thus unary 1-las).</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.08464v2</guid>
      <category>cs.FL</category>
      <pubDate>Thu, 01 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bruno Guillon (UCA, INP Clermont Auvergne, LIMOS), Luca Prigioniero (UCA, INP Clermont Auvergne, LIMOS), Javad Taheri (UCA, INP Clermont Auvergne, LIMOS)</dc:creator>
    </item>
    <item>
      <title>Beyond Winning Strategies: Admissible and Admissible Winning Strategies for Quantitative Reachability Games</title>
      <link>https://arxiv.org/abs/2408.13369</link>
      <description>arXiv:2408.13369v2 Announce Type: replace-cross 
Abstract: Classical reactive synthesis approaches aim to synthesize a reactive system that always satisfies a given specifications. These approaches often reduce to playing a two-player zero-sum game where the goal is to synthesize a winning strategy. However, in many pragmatic domains, such as robotics, a winning strategy does not always exist, yet it is desirable for the system to make an effort to satisfy its requirements instead of "giving up". To this end, this paper investigates the notion of admissible strategies, which formalize "doing-your-best", in quantitative reachability games. We show that, unlike the qualitative case, quantitative admissible strategies are history-dependent even for finite payoff functions, making synthesis a challenging task. In addition, we prove that admissible strategies always exist but may produce undesirable optimistic behaviors. To mitigate this, we propose admissible winning strategies, which enforce the best possible outcome while being admissible. We show that both strategies always exist but are not memoryless. We provide necessary and sufficient conditions for the existence of both strategies and propose synthesis algorithms. Finally, we illustrate the strategies on gridworld and robot manipulator domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.13369v2</guid>
      <category>cs.GT</category>
      <category>cs.FL</category>
      <category>cs.LO</category>
      <category>cs.RO</category>
      <pubDate>Thu, 01 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Karan Muvvala, Qi Heng Ho, Morteza Lahijanian</dc:creator>
    </item>
    <item>
      <title>Intrinsic Verification of Parsers and Formal Grammar Theory in Dependent Lambek Calculus (Extended Version)</title>
      <link>https://arxiv.org/abs/2504.03995</link>
      <description>arXiv:2504.03995v3 Announce Type: replace-cross 
Abstract: We present Dependent Lambek Calculus, a domain-specific dependent type theory for verified parsing and formal grammar theory. In $\textrm{Lambek}^D$, linear types are used as a syntax for formal grammars,and parsers can be written as linear terms. The linear typing restriction provides a form of intrinsic verification that a parser yields only valid parse trees for the input string. We demonstrate the expressivity of this system by showing that the combination of inductive linear types and dependency on non-linear data can be used to encode commonly used grammar formalisms such as regular and context-free grammars as well as traces of various types of automata. Using these encodings, we define parsers for regular expressions using deterministic automata, as well as examples of verified parsers of context-free grammars.
  We present a denotational semantics of our type theory that interprets the linear types as functions from strings to sets of abstract parse trees and terms as parse transformers. Based on this denotational semantics, we have made a prototype implementation of $\textrm{Lambek}^D$ using a shallow embedding in the Agda proof assistant. All of our examples parsers have been implemented in this prototype implementation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03995v3</guid>
      <category>cs.PL</category>
      <category>cs.FL</category>
      <pubDate>Thu, 01 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Steven Schaefer, Nathan Varner, Pedro H. Azevedo de Amorim, Max S. New</dc:creator>
    </item>
  </channel>
</rss>
