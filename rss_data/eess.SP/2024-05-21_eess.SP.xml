<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>eess.SP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/eess.SP</link>
    <description>eess.SP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/eess.SP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 21 May 2024 04:02:14 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 21 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>TVCondNet: A Conditional Denoising Neural Network for NMR Spectroscopy</title>
      <link>https://arxiv.org/abs/2405.11064</link>
      <description>arXiv:2405.11064v1 Announce Type: new 
Abstract: Nuclear Magnetic Resonance (NMR) spectroscopy is a widely-used technique in the fields of bio-medicine, chemistry, and biology for the analysis of chemicals and proteins. The signals from NMR spectroscopy often have low signal-to-noise ratio (SNR) due to acquisition noise, which poses significant challenges for subsequent analysis. Recent work has explored the potential of deep learning (DL) for NMR denoising, showing significant performance gains over traditional methods such as total variation (TV) denoising. This paper shows that the performance of DL denoising for NMR can be further improved by combining data-driven training with traditional TV denoising. The proposed TVCondNet method outperforms both traditional TV and DL methods by including the TV solution as a condition during DL training. Our validation on experimentally collected NMR data shows the superior denoising performance and faster inference speed of TVCondNet compared to existing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.11064v1</guid>
      <category>eess.SP</category>
      <category>cs.CV</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Zihao Zou, Shirin Shoushtari, Jiaming Liu, Jialiang Zhang, Patrick Judge, Emilia Santana, Alison Lim, Marcus Foston, Ulugbek S. Kamilov</dc:creator>
    </item>
    <item>
      <title>FeMLoc: Federated Meta-learning for Adaptive Wireless Indoor Localization Tasks in IoT Networks</title>
      <link>https://arxiv.org/abs/2405.11079</link>
      <description>arXiv:2405.11079v1 Announce Type: new 
Abstract: The rapid growth of the Internet of Things fosters collaboration among connected devices for tasks like indoor localization. However, existing indoor localization solutions struggle with dynamic and harsh conditions, requiring extensive data collection and environment-specific calibration. These factors impede cooperation, scalability, and the utilization of prior research efforts. To address these challenges, we propose FeMLoc, a federated meta-learning framework for localization. FeMLoc operates in two stages: (i) collaborative meta-training where a global meta-model is created by training on diverse localization datasets from edge devices. (ii) Rapid adaptation for new environments, where the pre-trained global meta-model initializes the localization model, requiring only minimal fine-tuning with a small amount of new data. In this paper, we provide a detailed technical overview of FeMLoc, highlighting its unique approach to privacy-preserving meta-learning in the context of indoor localization. Our performance evaluation demonstrates the superiority of FeMLoc over state-of-the-art methods, enabling swift adaptation to new indoor environments with reduced calibration effort. Specifically, FeMLoc achieves up to 80.95% improvement in localization accuracy compared to the conventional baseline neural network (NN) approach after only 100 gradient steps. Alternatively, for a target accuracy of around 5m, FeMLoc achieves the same level of accuracy up to 82.21% faster than the baseline NN approach. This translates to FeMLoc requiring fewer training iterations, thereby significantly reducing fingerprint data collection and calibration efforts. Moreover, FeMLoc exhibits enhanced scalability, making it well-suited for location-aware massive connectivity driven by emerging wireless communication technologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.11079v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yaya Etiabi, Wafa Njima, El Mehdi Amhoud</dc:creator>
    </item>
    <item>
      <title>Meta Reinforcement Learning for Resource Allocation in Unmanned Aerial Vehicles with MIMO Visible Light Communication</title>
      <link>https://arxiv.org/abs/2405.11161</link>
      <description>arXiv:2405.11161v1 Announce Type: new 
Abstract: This paper centers around a multiple-input-multiple-output (MIMO) visible light communication (VLC) system, where an unmanned aerial vehicle (UAV) benefits from a light emitting diode (LED) array to serve photo-diode (PD)-equipped users for illumination and communication simultaneously. Concerning the battery limitation of the UAV and considerable energy consumption of the LED array, a hybrid dimming control scheme is devised at the UAV that effectively controls the number of glared LEDs and thereby mitigates the overall energy consumption. To assess the performance of this system, a radio resource allocation problem is accordingly formulated for jointly optimizing the motion trajectory, transmit beamforming and LED selection at the UAV, assuming that channel state information (CSI) is partially available. By reformulating the optimization problem in Markov decision process (MDP) form, we propose a soft actor-critic (SAC) mechanism that captures the dynamics of the problem and optimizes its parameters. Additionally, regarding the frequent mobility of the UAV and thus remarkable rearrangement of the system, we enhance the trained SAC model by integrating a meta-learning strategy that enables more adaptation to system variations. According to simulations, upgrading a single-LED UAV by an array of 10 LEDs, exhibits 47% and 34% improvements in data rate and energy efficiency, albeit at the expense of 8% more power consumption.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.11161v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hosein Zarini, Amir Mohammadi, Maryam Farajzadeh Dehkordi, Mohammad Robat Mili, Bardia Safaei, Ali Movaghar, Merouane Debbah</dc:creator>
    </item>
    <item>
      <title>Learning-based Block-wise Planar Channel Estimation for Time-Varying MIMO OFDM</title>
      <link>https://arxiv.org/abs/2405.11218</link>
      <description>arXiv:2405.11218v1 Announce Type: new 
Abstract: In this paper, we propose a learning-based block-wise planar channel estimator (LBPCE) with high accuracy and low complexity to estimate the time-varying frequency-selective channel of a multiple-input multiple-output (MIMO) orthogonal frequency-division multiplexing (OFDM) system. First, we establish a block-wise planar channel model (BPCM) to characterize the correlation of the channel across subcarriers and OFDM symbols. Specifically, adjacent subcarriers and OFDM symbols are divided into several sub-blocks, and an affine function (i.e., a plane) with only three variables (namely, mean, time-domain slope, and frequency-domain slope) is used to approximate the channel in each sub-block, which significantly reduces the number of variables to be determined in channel estimation. Second, we design a 3D dilated residual convolutional network (3D-DRCN) that leverages the time-frequency-space-domain correlations of the channel to further improve the channel estimates of each user. Numerical results demonstrate that the proposed significantly outperforms the state-of-the-art estimators and maintains a relatively low computational complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.11218v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chenchen Liu, Wenjun Jiang, Xiaojun Yuan</dc:creator>
    </item>
    <item>
      <title>Advancing fNIRS Neuroimaging through Synthetic Data Generation and Machine Learning Applications</title>
      <link>https://arxiv.org/abs/2405.11242</link>
      <description>arXiv:2405.11242v1 Announce Type: new 
Abstract: This study presents an integrated approach for advancing functional Near-Infrared Spectroscopy (fNIRS) neuroimaging through the synthesis of data and application of machine learning models. By addressing the scarcity of high-quality neuroimaging datasets, this work harnesses Monte Carlo simulations and parametric head models to generate a comprehensive synthetic dataset, reflecting a wide spectrum of conditions. We developed a containerized environment employing Docker and Xarray for standardized and reproducible data analysis, facilitating meaningful comparisons across different signal processing modalities. Additionally, a cloud-based infrastructure is established for scalable data generation and processing, enhancing the accessibility and quality of neuroimaging data. The combination of synthetic data generation with machine learning techniques holds promise for improving the accuracy, efficiency, and applicability of fNIRS tomography, potentially revolutionizing diagnostics and treatment strategies for neurological conditions. The methodologies and infrastructure developed herein set new standards in data simulation and analysis, paving the way for future research in neuroimaging and the broader biomedical engineering field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.11242v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <category>physics.med-ph</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eitan Waks</dc:creator>
    </item>
    <item>
      <title>MAMCA -- Optimal on Accuracy and Efficiency for Automatic Modulation Classification with Extended Signal Length</title>
      <link>https://arxiv.org/abs/2405.11263</link>
      <description>arXiv:2405.11263v1 Announce Type: new 
Abstract: With the rapid growth of the Internet of Things ecosystem, Automatic Modulation Classification (AMC) has become increasingly paramount. However, extended signal lengths offer a bounty of information, yet impede the model's adaptability, introduce more noise interference, extend the training and inference time, and increase storage overhead. To bridge the gap between these requisites, we propose a novel AMC framework, designated as the Mamba-based Automatic Modulation ClassificAtion (MAMCA). Our method adeptly addresses the accuracy and efficiency requirements for long-sequence AMC. Specifically, we introduce the Selective State Space Model as the backbone, enhancing the model efficiency by reducing the dimensions of the state matrices and diminishing the frequency of information exchange across GPU memories. We design a denoising-capable unit to elevate the network's performance under low signal-to-noise radio. Rigorous experimental evaluations on the publicly available dataset RML2016.10, along with our synthetic dataset within multiple quadrature amplitude modulations and lengths, affirm that MAMCA delivers superior recognition accuracy while necessitating minimal computational time and memory occupancy. Codes are available on https://github.com/ZhangYezhuo/MAMCA.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.11263v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yezhuo Zhang, Zinan Zhou, Yichao Cao, Guangyu Li, Xuanpeng Li</dc:creator>
    </item>
    <item>
      <title>Meta Reinforcement Learning for Resource Allocation in Multi-Antenna UAV Network with Rate Splitting Multiple Access</title>
      <link>https://arxiv.org/abs/2405.11306</link>
      <description>arXiv:2405.11306v1 Announce Type: new 
Abstract: Unmanned aerial vehicles (UAVs) with multiple antennas have recently been explored to improve capacity in wireless networks. However, the strict energy constraint of UAVs, given their simultaneous flying and communication tasks, renders the exploration of energy-efficient multi-antenna techniques indispensable for UAVs. Meanwhile, lens antenna subarray (LAS) emerges as a promising energy-efficient solution that has not been previously harnessed for this purpose. In this paper, we propose a LAS-aided multi-antenna UAV to serve ground users in the downlink transmission of the terahertz (THz) band, utilizing rate splitting multiple access (RSMA) for effective beam division multiplexing. We formulate an optimization problem of maximizing the total system spectral efficiency (SE). This involves optimizing the UAV's transmit beamforming and the common rate of RSMA. By recasting the optimization problem into a Markov decision process (MDP), we propose a deep deterministic policy gradient (DDPG)-based resource allocation mechanism tailored to capture problem dynamics and optimize its variables. Moreover, given the UAV's frequent mobility and consequential system reconfigurations, we fortify the trained DDPG model with a meta-learning strategy, enhancing its adaptability to system variations. Numerically, more than 20\% energy efficiency gain is achieved by our proposed LAS-aided multi-antenna UAV equipped with 4 lenses, compared to a single-lens UAV. Simulations also demonstrate that at a signal-to-noise (SNR) of 10 dB, the incorporation of RSMA results in a 22\% SE enhancement over conventional orthogonal beam division multiple access. Furthermore, the overall system SE improves by 27\%, when meta-learning is employed for fine-tuning the conventional DDPG method in literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.11306v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hosein Zarini, Maryam Farajzadeh Dehkordi, Armin Farhadi, Mohammad Robat Mili, Ali Movaghar, Mehdi Rasti, Yonghui Li, Kai-Kit Wong</dc:creator>
    </item>
    <item>
      <title>Du-IN: Discrete units-guided mask modeling for decoding speech from Intracranial Neural signals</title>
      <link>https://arxiv.org/abs/2405.11459</link>
      <description>arXiv:2405.11459v1 Announce Type: new 
Abstract: Invasive brain-computer interfaces have garnered significant attention due to their high performance. The current intracranial stereoElectroEncephaloGraphy (sEEG) foundation models typically build univariate representations based on a single channel. Some of them further use Transformer to model the relationship among channels. However, due to the locality and specificity of brain computation, their performance on more difficult tasks, e.g., speech decoding, which demands intricate processing in specific brain regions, is yet to be fully investigated. We hypothesize that building multi-variate representations within certain brain regions can better capture the specific neural processing. To explore this hypothesis, we collect a well-annotated Chinese word-reading sEEG dataset, targeting language-related brain networks, over 12 subjects. Leveraging this benchmark dataset, we developed the Du-IN model that can extract contextual embeddings from specific brain regions through discrete codebook-guided mask modeling. Our model achieves SOTA performance on the downstream 61-word classification task, surpassing all baseline models. Model comparison and ablation analysis reveal that our design choices, including (i) multi-variate representation by fusing channels in vSMC and STG regions and (ii) self-supervision by discrete codebook-guided mask modeling, significantly contribute to these performances. Collectively, our approach, inspired by neuroscience findings, capitalizing on multi-variate neural representation from specific brain regions, is suitable for invasive brain modeling. It marks a promising neuro-inspired AI approach in BCI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.11459v1</guid>
      <category>eess.SP</category>
      <category>cs.CL</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hui Zheng, Hai-Teng Wang, Wei-Bang Jiang, Zhong-Tao Chen, Li He, Pei-Yang Lin, Peng-Hu Wei, Guo-Guang Zhao, Yun-Zhe Liu</dc:creator>
    </item>
    <item>
      <title>Non-Invasive Monitoring of Vital Signs in Calves Using Thermal Imaging Technology</title>
      <link>https://arxiv.org/abs/2405.11532</link>
      <description>arXiv:2405.11532v1 Announce Type: new 
Abstract: This study presents a non-invasive method using thermal imaging to estimate heart and respiration rates in calves, avoiding the stress from wearables. Using Kernelised Correlation Filters (KCF) for movement tracking and advanced signal processing, we targeted one ROI for respiration and four for heart rate based on their thermal correlation. Achieving Mean Absolute Percentage Errors (MAPE) of 3.08% for respiration and 3.15% for heart rate validates the efficacy of thermal imaging in vital signs monitoring, offering a practical, less intrusive tool for Precision Livestock Farming (PLF), improving animal welfare and management.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.11532v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ehsan Sadeghi, Zinan Guo, Alessandro Chiumento, Paul Havinga</dc:creator>
    </item>
    <item>
      <title>Transfer Learning for CSI-based Positioning with Multi-environment Meta-learning</title>
      <link>https://arxiv.org/abs/2405.11816</link>
      <description>arXiv:2405.11816v1 Announce Type: new 
Abstract: Utilizing deep learning (DL) techniques for radio-based positioning of user equipment (UE) through channel state information (CSI) fingerprints has demonstrated significant potential. DL models can extract complex characteristics from the CSI fingerprints of a particular environment and accurately predict the position of a UE. Nonetheless, the effectiveness of the DL model trained on CSI fingerprints is highly dependent on the particular training environment, limiting the trained model's applicability across different environments. This paper proposes a novel DL model structure consisting of two parts, where the first part aims at identifying features that are independent from any specific environment, while the second part combines those features in an environment specific way with the goal of positioning. To train such a two-part model, we propose the multi-environment meta-learning (MEML) approach for the first part to facilitate training across various environments, while the second part of the model is trained solely on data from a specific environment. Our findings indicate that employing the MEML approach for initializing the weights of the DL model for a new unseen environment significantly boosts the accuracy of UE positioning in the new target environment as well the reliability of its uncertainty estimation. This method outperforms traditional transfer learning methods, whether direct transfer learning (DTL) between environments or completely training from scratch with data from a new environment. The proposed approach is verified with real measurements for both line-of-sight (LOS) and non-LOS (NLOS) environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.11816v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anastasios Foliadis, Mario H. Casta\~neda, Richard A. Stirling-Gallacher, Reiner S. Thom\"a</dc:creator>
    </item>
    <item>
      <title>3D Reconfigurable Intelligent Surfaces for Satellite-Terrestrial Networks</title>
      <link>https://arxiv.org/abs/2405.11909</link>
      <description>arXiv:2405.11909v1 Announce Type: new 
Abstract: This letter proposes a three-dimensional (3D) satellite-terrestrial communication network assisted with reconfigurable intelligent surfaces (RISs). Using stochastic geometry models, we present an original framework to derive tractable yet accurate closed-form expressions for coverage probability and ergodic capacity in the presence of fading. A homogeneous Poisson point process models the satellites on a sphere, while RISs are randomly deployed in a 3D cylindrical region. We consider nonidentical channels that correspond to different RISs and follow the \kappa-\mu fading distribution. We verify the accuracy of the adopted approach through Monte Carlo simulations, demonstrating the significant improvement in system performance due to using RISs. Furthermore, we show that increasing the number of reflecting elements or RISs and placing them closer to the user improves performance considerably.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.11909v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Islam M. Tanash, Risto Wichman</dc:creator>
    </item>
    <item>
      <title>Complex Principle Kurtosis Analysis</title>
      <link>https://arxiv.org/abs/2405.12053</link>
      <description>arXiv:2405.12053v1 Announce Type: new 
Abstract: Independent component analysis (ICA) is a fundamental problem in the field of signal processing, and numerous algorithms have been developed to address this issue. The core principle of these algorithms is to find a transformation matrix that maximizes the non-Gaussianity of the separated signals. Most algorithms typically assume that the source signals are mutually independent (orthogonal to each other), thereby imposing an orthogonal constraint on the transformation matrix. However, this assumption is not always valid in practical scenarios, where the orthogonal constraint can lead to inaccurate results. Recently, tensor-based algorithms have attracted much attention due to their ability to reduce computational complexity and enhance separation performance. In these algorithms, ICA is reformulated as an eigenpair problem of a statistical tensor. Importantly, the eigenpairs of a tensor are not inherently orthogonal, making tensor-based algorithms more suitable for nonorthogonal cases. Despite this advantage, finding exact solutions to the tensor's eigenpair problem remains a challenging task. In this paper, we introduce a non-zero volume constraint and a Riemannian gradient-based algorithm to solve the tensor's eigenpair problem. The proposed algorithm can find exact solutions under nonorthogonal conditions, making it more effective for separating nonorthogonal sources. Additionally, existing tensor-based algorithms typically rely on third-order statistics and are limited to real-valued data. To overcome this limitation, we extend tensor-based algorithms to the complex domain by constructing a fourth-order statistical tensor. Experiments conducted on both synthetic and real-world datasets demonstrate the effectiveness of the proposed algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12053v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liangliang Zhu, Zhebin Song, Xuesen Zhang, Meibin Qi</dc:creator>
    </item>
    <item>
      <title>Approximating Multi-Dimensional and Multiband Signals</title>
      <link>https://arxiv.org/abs/2405.12064</link>
      <description>arXiv:2405.12064v1 Announce Type: new 
Abstract: We study the problem of representing a discrete tensor that comes from finite uniform samplings of a multi-dimensional and multiband analog signal. Particularly, we consider two typical cases in which the shape of the subbands is cubic or parallelepipedic. For the cubic case, by examining the spectrum of its corresponding time- and band-limited operators, we obtain a low-dimensional optimal dictionary to represent the original tensor. We further prove that the optimal dictionary can be approximated by the famous \ac{dpss} with certain modulation, leading to an efficient constructing method. For the parallelepipedic case, we show that there also exists a low-dimensional dictionary to represent the original tensor. We present rigorous proof that the numbers of atoms in both dictionaries are approximately equal to the dot of the total number of samplings and the total volume of the subbands. Our derivations are mainly focused on the \ac{2d} scenarios but can be naturally extended to high dimensions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12064v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuhan Li, Tianyao Huang, Yimin Liu, Xiqin Wang</dc:creator>
    </item>
    <item>
      <title>Discrete approximations of Gaussian smoothing and Gaussian derivatives</title>
      <link>https://arxiv.org/abs/2311.11317</link>
      <description>arXiv:2311.11317v7 Announce Type: cross 
Abstract: This paper develops an in-depth treatment concerning the problem of approximating the Gaussian smoothing and Gaussian derivative computations in scale-space theory for application on discrete data. With close connections to previous axiomatic treatments of continuous and discrete scale-space theory, we consider three main ways discretizing these scale-space operations in terms of explicit discrete convolutions, based on either (i) sampling the Gaussian kernels and the Gaussian derivative kernels, (ii) locally integrating the Gaussian kernels and the Gaussian derivative kernels over each pixel support region and (iii) basing the scale-space analysis on the discrete analogue of the Gaussian kernel, and then computing derivative approximations by applying small-support central difference operators to the spatially smoothed image data.
  We study the properties of these three main discretization methods both theoretically and experimentally, and characterize their performance by quantitative measures, including the results they give rise to with respect to the task of scale selection, investigated for four different use cases, and with emphasis on the behaviour at fine scales. The results show that the sampled Gaussian kernels and derivatives as well as the integrated Gaussian kernels and derivatives perform very poorly at very fine scales. At very fine scales, the discrete analogue of the Gaussian kernel with its corresponding discrete derivative approximations performs substantially better. The sampled Gaussian kernel and the sampled Gaussian derivatives do, on the other hand, lead to numerically very good approximations of the corresponding continuous results, when the scale parameter is sufficiently large, in the experiments presented in the paper, when the scale parameter is greater than a value of about 1, in units of the grid spacing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.11317v7</guid>
      <category>cs.CV</category>
      <category>cs.NA</category>
      <category>eess.IV</category>
      <category>eess.SP</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tony Lindeberg</dc:creator>
    </item>
    <item>
      <title>Approximation properties relative to continuous scale space for hybrid discretizations of Gaussian derivative operators</title>
      <link>https://arxiv.org/abs/2405.05095</link>
      <description>arXiv:2405.05095v2 Announce Type: cross 
Abstract: This paper presents an analysis of properties of two hybrid discretization methods for Gaussian derivatives, based on convolutions with either the normalized sampled Gaussian kernel or the integrated Gaussian kernel followed by central differences. The motivation for studying these discretization methods is that in situations when multiple spatial derivatives of different order are needed at the same scale level, they can be computed significantly more efficiently compared to more direct derivative approximations based on explicit convolutions with either sampled Gaussian kernels or integrated Gaussian kernels.
  While these computational benefits do also hold for the genuinely discrete approach for computing discrete analogues of Gaussian derivatives, based on convolution with the discrete analogue of the Gaussian kernel followed by central differences, the underlying mathematical primitives for the discrete analogue of the Gaussian kernel, in terms of modified Bessel functions of integer order, may not be available in certain frameworks for image processing, such as when performing deep learning based on scale-parameterized filters in terms of Gaussian derivatives, with learning of the scale levels.
  In this paper, we present a characterization of the properties of these hybrid discretization methods, in terms of quantitative performance measures concerning the amount of spatial smoothing that they imply, as well as the relative consistency of scale estimates obtained from scale-invariant feature detectors with automatic scale selection, with an emphasis on the behaviour for very small values of the scale parameter, which may differ significantly from corresponding results obtained from the fully continuous scale-space theory, as well as between different types of discretization methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.05095v2</guid>
      <category>math.NA</category>
      <category>cs.CV</category>
      <category>cs.NA</category>
      <category>eess.IV</category>
      <category>eess.SP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tony Lindeberg</dc:creator>
    </item>
    <item>
      <title>Next-slot OFDM-CSI Prediction: Multi-head Self-attention or State Space Model?</title>
      <link>https://arxiv.org/abs/2405.11072</link>
      <description>arXiv:2405.11072v1 Announce Type: cross 
Abstract: The ongoing fifth-generation (5G) standardization is exploring the use of deep learning (DL) methods to enhance the new radio (NR) interface. Both in academia and industry, researchers are investigating the performance and complexity of multiple DL architecture candidates for specific one-sided and two-sided use cases such as channel state estimation (CSI) feedback, CSI prediction, beam management, and positioning. In this paper, we set focus on the CSI prediction task and study the performance and generalization of the two main DL layers that are being extensively benchmarked within the DL community, namely, multi-head self-attention (MSA) and state-space model (SSM). We train and evaluate MSA and SSM layers to predict the next slot for uplink and downlink communication scenarios over urban microcell (UMi) and urban macrocell (UMa) OFDM 5G channel models. Our numerical results demonstrate that SSMs exhibit better prediction and generalization capabilities than MSAs only for SISO cases. For MIMO scenarios, however, the MSA layer outperforms the SSM one. While both layers represent potential DL architectures for future DL-enabled 5G use cases, the overall investigation of this paper favors MSAs over SSMs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.11072v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohamed Akrout, Faouzi Bellili, Amine Mezghani, Robert W. Heath</dc:creator>
    </item>
    <item>
      <title>Domain Generalization for Zero-calibration BCIs with Knowledge Distillation-based Phase Invariant Feature Extraction</title>
      <link>https://arxiv.org/abs/2405.11163</link>
      <description>arXiv:2405.11163v1 Announce Type: cross 
Abstract: The distribution shift of electroencephalography (EEG) data causes poor generalization of braincomputer interfaces (BCIs) in unseen domains. Some methods try to tackle this challenge by collecting a portion of user data for calibration. However, it is time-consuming, mentally fatiguing, and user-unfriendly. To achieve zerocalibration BCIs, most studies employ domain generalization (DG) techniques to learn invariant features across different domains in the training set. However, they fail to fully explore invariant features within the same domain, leading to limited performance. In this paper, we present an novel method to learn domain-invariant features from both interdomain and intra-domain perspectives. For intra-domain invariant features, we propose a knowledge distillation framework to extract EEG phase-invariant features within one domain. As for inter-domain invariant features, correlation alignment is used to bridge distribution gaps across multiple domains. Experimental results on three public datasets validate the effectiveness of our method, showcasing stateof-the-art performance. To the best of our knowledge, this is the first domain generalization study that exploit Fourier phase information as an intra-domain invariant feature to facilitate EEG generalization. More importantly, the zerocalibration BCI based on inter- and intra-domain invariant features has significant potential to advance the practical applications of BCIs in real world.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.11163v1</guid>
      <category>cs.HC</category>
      <category>eess.SP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zilin Liang, Zheng Zheng, Weihai Chen, Xinzhi Ma, Zhongcai Pei, Xiantao Sun</dc:creator>
    </item>
    <item>
      <title>Hierarchical Reinforcement Learning Empowered Task Offloading in V2I Networks</title>
      <link>https://arxiv.org/abs/2405.11352</link>
      <description>arXiv:2405.11352v1 Announce Type: cross 
Abstract: Edge computing plays an essential role in the vehicle-to-infrastructure (V2I) networks, where vehicles offload their intensive computation tasks to the road-side units for saving energy and reduce the latency. This paper designs the optimal task offloading policy to address the concerns involving processing delay, energy consumption and edge computing cost. Each computation task consisting of some interdependent sub-tasks is characterized as a directed acyclic graph (DAG). In such dynamic networks, a novel hierarchical Offloading scheme is proposed by leveraging deep reinforcement learning (DRL). The inter-dependencies among the DAGs of the computation tasks are extracted using a graph neural network with attention mechanism. A parameterized DRL algorithm is developed to deal with the hierarchical action space containing both discrete and continuous actions. Simulation results with a real-world car speed dataset demonstrate that the proposed scheme can effectively reduce the system overhead.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.11352v1</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xinyu You, Haojie Yan, Yuedong Xu, Lifeng Wang, Liangui Dai</dc:creator>
    </item>
    <item>
      <title>Quantum Neural Networks for Solving Power System Transient Simulation Problem</title>
      <link>https://arxiv.org/abs/2405.11427</link>
      <description>arXiv:2405.11427v1 Announce Type: cross 
Abstract: Quantum computing, leveraging principles of quantum mechanics, represents a transformative approach in computational methodologies, offering significant enhancements over traditional classical systems. This study tackles the complex and computationally demanding task of simulating power system transients through solving differential algebraic equations (DAEs). We introduce two novel Quantum Neural Networks (QNNs): the Sinusoidal-Friendly QNN and the Polynomial-Friendly QNN, proposing them as effective alternatives to conventional simulation techniques. Our application of these QNNs successfully simulates two small power systems, demonstrating their potential to achieve good accuracy. We further explore various configurations, including time intervals, training points, and the selection of classical optimizers, to optimize the solving of DAEs using QNNs. This research not only marks a pioneering effort in applying quantum computing to power system simulations but also expands the potential of quantum technologies in addressing intricate engineering challenges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.11427v1</guid>
      <category>quant-ph</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohammadreza Soltaninia, Junpeng Zhan</dc:creator>
    </item>
    <item>
      <title>Point Cloud Compression with Implicit Neural Representations: A Unified Framework</title>
      <link>https://arxiv.org/abs/2405.11493</link>
      <description>arXiv:2405.11493v1 Announce Type: cross 
Abstract: Point clouds have become increasingly vital across various applications thanks to their ability to realistically depict 3D objects and scenes. Nevertheless, effectively compressing unstructured, high-precision point cloud data remains a significant challenge. In this paper, we present a pioneering point cloud compression framework capable of handling both geometry and attribute components. Unlike traditional approaches and existing learning-based methods, our framework utilizes two coordinate-based neural networks to implicitly represent a voxelized point cloud. The first network generates the occupancy status of a voxel, while the second network determines the attributes of an occupied voxel. To tackle an immense number of voxels within the volumetric space, we partition the space into smaller cubes and focus solely on voxels within non-empty cubes. By feeding the coordinates of these voxels into the respective networks, we reconstruct the geometry and attribute components of the original point cloud. The neural network parameters are further quantized and compressed. Experimental results underscore the superior performance of our proposed method compared to the octree-based approach employed in the latest G-PCC standards. Moreover, our method exhibits high universality when contrasted with existing learning-based techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.11493v1</guid>
      <category>cs.CV</category>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongning Ruan, Yulin Shao, Qianqian Yang, Liang Zhao, Dusit Niyato</dc:creator>
    </item>
    <item>
      <title>On Performance of FAS-aided Wireless Powered NOMA Communication Systems</title>
      <link>https://arxiv.org/abs/2405.11520</link>
      <description>arXiv:2405.11520v1 Announce Type: cross 
Abstract: This paper studies the performance of a wireless powered communication network (WPCN) under the non-orthogonal multiple access (NOMA) scheme, where users take advantage of an emerging fluid antenna system (FAS). More precisely, we consider a scenario where a transmitter is powered by a remote power beacon (PB) to send information to the planar NOMA FAS-equipped users through Rayleigh fading channels. After introducing the distribution of the equivalent channel coefficients to the users, we derive compact analytical expressions for the outage probability (OP) in order to evaluate the system performance. Additionally, we present asymptotic OP in the high signal-to-noise ratio (SNR) regime. Eventually, results reveal that deploying the FAS with only one activated port in NOMA users can significantly enhance the WPCN performance compared with using traditional antenna systems (TAS).</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.11520v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Farshad Rostami Ghadi, Masoud Kaveh, Kai-Kit Wong, Riku Jantti, Zheng Yan</dc:creator>
    </item>
    <item>
      <title>R-NeRF: Neural Radiance Fields for Modeling RIS-enabled Wireless Environments</title>
      <link>https://arxiv.org/abs/2405.11541</link>
      <description>arXiv:2405.11541v1 Announce Type: cross 
Abstract: Recently, ray tracing has gained renewed interest with the advent of Reflective Intelligent Surfaces (RIS) technology, a key enabler of 6G wireless communications due to its capability of intelligent manipulation of electromagnetic waves. However, accurately modeling RIS-enabled wireless environments poses significant challenges due to the complex variations caused by various environmental factors and the mobility of RISs. In this paper, we propose a novel modeling approach using Neural Radiance Fields (NeRF) to characterize the dynamics of electromagnetic fields in such environments. Our method utilizes NeRF-based ray tracing to intuitively capture and visualize the complex dynamics of signal propagation, effectively modeling the complete signal pathways from the transmitter to the RIS, and from the RIS to the receiver. This two-stage process accurately characterizes multiple complex transmission paths, enhancing our understanding of signal behavior in real-world scenarios. Our approach predicts the signal field for any specified RIS placement and receiver location, facilitating efficient RIS deployment. Experimental evaluations using both simulated and real-world data validate the significant benefits of our methodology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.11541v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Huiying Yang, Zihan Jin, Chenhao Wu, Rujing Xiong, Robert Caiming Qiu, Zenan Ling</dc:creator>
    </item>
    <item>
      <title>Permittivity Characterization of Human Skin Based on a Quasi-optical System at Sub-THz</title>
      <link>https://arxiv.org/abs/2405.11863</link>
      <description>arXiv:2405.11863v1 Announce Type: cross 
Abstract: This paper introduces a novel approach to experimentally characterize effective human skin permittivity at sub-Terahertz (sub-THz) frequencies, specifically from $140$~to $210$~GHz, utilizing a quasi-optical measurement system. To ensure accurate measurement of the reflection coefficients of human skin, a planar, rigid, and thick reference plate with a low-loss dielectric is utilized to flatten the human skin surface. A permittivity characterization method is proposed to reduce permittivity estimation deviations resulting from the pressure effects on the phase displacements of skins under the measurements but also to ensure repeatability of the measurement. In practical permittivity characterizations, the complex permittivities of the finger, palm, and arm of seven volunteers show small standard deviations for the repeated measurements, respectively, while those show significant variations across different regions of the skins and for different persons. The proposed measurement system holds significant potential for future skin permittivity estimation in sub-THz bands, facilitating further studies on human-electromagnetic-wave interactions based on the measured permittivity values.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.11863v1</guid>
      <category>physics.med-ph</category>
      <category>eess.SP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bing Xue, Juha Tuomela, Katsuyuki Haneda, Clemens Icheln, Juha Ala-Laurinaho</dc:creator>
    </item>
    <item>
      <title>Asynchronous MIMO-OFDM Massive Unsourced Random Access with Codeword Collisions</title>
      <link>https://arxiv.org/abs/2405.11883</link>
      <description>arXiv:2405.11883v1 Announce Type: cross 
Abstract: This paper investigates asynchronous MIMO massive unsourced random access in an orthogonal frequency division multiplexing (OFDM) system over frequency-selective fading channels, with the presence of both timing and carrier frequency offsets (TO and CFO) and non-negligible codeword collisions. The proposed coding framework segregates the data into two components, namely, preamble and coding parts, with the former being tree-coded and the latter LDPC-coded. By leveraging the dual sparsity of the equivalent channel across both codeword and delay domains (CD and DD), we develop a message passing-based sparse Bayesian learning algorithm, combined with belief propagation and mean field, to iteratively estimate DD channel responses, TO, and delay profiles. Furthermore, we establish a novel graph-based algorithm to iteratively separate the superimposed channels and compensate for the phase rotations. Additionally, the proposed algorithm is applied to the flat fading scenario to estimate both TO and CFO, where the channel and offset estimation is enhanced by leveraging the geometric characteristics of the signal constellation. Simulations reveal that the proposed algorithm achieves superior performance and substantial complexity reduction in both channel and offset estimation compared to the codebook enlarging-based counterparts, and enhanced data recovery performances compared to state-of-the-art URA schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.11883v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tianya Li, Yongpeng Wu, Junyuan Gao, Wenjun Zhang, Xiang-Gen Xia, Derrick Wing Kwan Ng, Chengshan Xiao</dc:creator>
    </item>
    <item>
      <title>Energy-Efficient Federated Edge Learning with Streaming Data: A Lyapunov Optimization Approach</title>
      <link>https://arxiv.org/abs/2405.12046</link>
      <description>arXiv:2405.12046v1 Announce Type: cross 
Abstract: Federated learning (FL) has received significant attention in recent years for its advantages in efficient training of machine learning models across distributed clients without disclosing user-sensitive data. Specifically, in federated edge learning (FEEL) systems, the time-varying nature of wireless channels introduces inevitable system dynamics in the communication process, thereby affecting training latency and energy consumption. In this work, we further consider a streaming data scenario where new training data samples are randomly generated over time at edge devices. Our goal is to develop a dynamic scheduling and resource allocation algorithm to address the inherent randomness in data arrivals and resource availability under long-term energy constraints. To achieve this, we formulate a stochastic network optimization problem and use the Lyapunov drift-plus-penalty framework to obtain a dynamic resource management design. Our proposed algorithm makes adaptive decisions on device scheduling, computational capacity adjustment, and allocation of bandwidth and transmit power in every round. We provide convergence analysis for the considered setting with heterogeneous data and time-varying objective functions, which supports the rationale behind our proposed scheduling design. The effectiveness of our scheme is verified through simulation results, demonstrating improved learning performance and energy efficiency as compared to baseline schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12046v1</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chung-Hsuan Hu, Zheng Chen, Erik G. Larsson</dc:creator>
    </item>
    <item>
      <title>GAN-GRID: A Novel Generative Attack on Smart Grid Stability Prediction</title>
      <link>https://arxiv.org/abs/2405.12076</link>
      <description>arXiv:2405.12076v1 Announce Type: cross 
Abstract: The smart grid represents a pivotal innovation in modernizing the electricity sector, offering an intelligent, digitalized energy network capable of optimizing energy delivery from source to consumer. It hence represents the backbone of the energy sector of a nation. Due to its central role, the availability of the smart grid is paramount and is hence necessary to have in-depth control of its operations and safety. To this aim, researchers developed multiple solutions to assess the smart grid's stability and guarantee that it operates in a safe state. Artificial intelligence and Machine learning algorithms have proven to be effective measures to accurately predict the smart grid's stability. Despite the presence of known adversarial attacks and potential solutions, currently, there exists no standardized measure to protect smart grids against this threat, leaving them open to new adversarial attacks. In this paper, we propose GAN-GRID a novel adversarial attack targeting the stability prediction system of a smart grid tailored to real-world constraints. Our findings reveal that an adversary armed solely with the stability model's output, devoid of data or model knowledge, can craft data classified as stable with an Attack Success Rate (ASR) of 0.99. Also by manipulating authentic data and sensor values, the attacker can amplify grid issues, potentially undetected due to a compromised stability prediction system. These results underscore the imperative of fortifying smart grid security mechanisms against adversarial manipulation to uphold system stability and reliability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12076v1</guid>
      <category>cs.CR</category>
      <category>eess.SP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Emad Efatinasab, Alessandro Brighente, Mirco Rampazzo, Nahal Azadi, Mauro Conti</dc:creator>
    </item>
    <item>
      <title>How Can Optical Communications Shape the Future of Deep Space Communications? A Survey</title>
      <link>https://arxiv.org/abs/2212.04933</link>
      <description>arXiv:2212.04933v4 Announce Type: replace 
Abstract: With a large number of deep space (DS) missions anticipated by the end of this decade, reliable and high-capacity DS communications are needed more than ever. Nevertheless, existing technologies are far from meeting such a goal. Improving current systems does not only require engineering leadership, but also, very crucially, investigating potential technologies that overcome the unique challenges of ultra-long DS links. To the best of our knowledge, there has not been any comprehenive surveys of DS communications technologies over the last decade. Free space optical (FSO) is an emerging DS technology, proven to acquire lower communications systems size weight and power (SWaP) and achieve a very high capacity compared to its counterpart radio frequency (RF), the currently used DS technology. In this survey, we discuss the pros and cons of deep space optical communications (DSOC) and review their physical and networking characteristics. Furthermore, we provide, for the first time, thoughtful discussions about implementing orbital angular momentum (OAM) and quantum communications (QC) for DS. We elaborate on how these technologies among other field advances including interplanetary network (IPN) and RF/FSO systems improve reliability, capacity, and security. This paper provides a holistic survey of DSOC technologies gathering 247 fragmented pieces of literature and including novel perspectives aiming to set the stage for more developments in the field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.04933v4</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sarah Karmous, Nadia Adem, Mohammed Atiquzzaman, Sumudu Samarakoon</dc:creator>
    </item>
    <item>
      <title>Unsupervised Statistical Feature-Guided Diffusion Model for Sensor-based Human Activity Recognition</title>
      <link>https://arxiv.org/abs/2306.05285</link>
      <description>arXiv:2306.05285v2 Announce Type: replace 
Abstract: Human activity recognition (HAR) from on-body sensors is a core functionality in many AI applications: from personal health, through sports and wellness to Industry 4.0. A key problem holding up progress in wearable sensor-based HAR, compared to other ML areas, such as computer vision, is the unavailability of diverse and labeled training data. Particularly, while there are innumerable annotated images available in online repositories, freely available sensor data is sparse and mostly unlabeled. We propose an unsupervised statistical feature-guided diffusion model specifically optimized for wearable sensor-based human activity recognition with devices such as inertial measurement unit (IMU) sensors. The method generates synthetic labeled time-series sensor data without relying on annotated training data. Thereby, it addresses the scarcity and annotation difficulties associated with real-world sensor data. By conditioning the diffusion model on statistical information such as mean, standard deviation, Z-score, and skewness, we generate diverse and representative synthetic sensor data. We conducted experiments on public human activity recognition datasets and compared the method to conventional oversampling and state-of-the-art generative adversarial network methods. Experimental results demonstrate that this can improve the performance of human activity recognition and outperform existing techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.05285v2</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Si Zuo, Vitor Fortes Rey, Sungho Suh, Stephan Sigg, Paul Lukowicz</dc:creator>
    </item>
    <item>
      <title>Near and Far Field Model Mismatch: Implications on 6G Communications, Localization, and Sensing</title>
      <link>https://arxiv.org/abs/2310.06604</link>
      <description>arXiv:2310.06604v2 Announce Type: replace 
Abstract: The upcoming 6G technology is expected to operate in near-field (NF) radiating conditions thanks to high-frequency and electrically large antenna arrays. Although several studies have already addressed this possibility, it is worth noting that NF models introduce higher complexity, the justification for which is not always evident in terms of performance improvements. This article investigates the implications of the mismatch between NF and far-field (FF) models concerning communication, localization, and sensing systems. Such disparity can lead to a degradation of performance metrics such as sensing and localization accuracy and communication efficiency. By exploring the effects of mismatches between NF and FF models, this study seeks to revolve around the challenges faced by system designers, offering insights about the balance between model accuracy and achievable performance. Finally, we conduct a numerical performance analysis to verify the impact of the mismatch between NF and FF models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.06604v2</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ahmed Elzanaty, Jiuyu Liu, Anna Guerra, Francesco Guidi, Yi Ma, Rahim Tafazolli</dc:creator>
    </item>
    <item>
      <title>Semantic-aware Sampling and Transmission in Energy Harvesting Systems: A POMDP Approach</title>
      <link>https://arxiv.org/abs/2311.06522</link>
      <description>arXiv:2311.06522v3 Announce Type: replace 
Abstract: We address the problem of real-time remote tracking of a partially observable Markov source in an energy harvesting system with an unreliable communication channel. We consider both sampling and transmission costs. Different from most prior studies that assume the source is fully observable, the sampling cost renders the source partially observable. The goal is to jointly optimize sampling and transmission policies for two semantic-aware metrics: i) a general distortion measure and ii) the age of incorrect information (AoII). We formulate a stochastic control problem. To solve the problem for each metric, we cast a partially observable Markov decision process (POMDP), which is transformed into a belief MDP. Then, for both AoII under the perfect channel setup and distortion, we express the belief as a function of the age of information (AoI). This expression enables us to effectively truncate the corresponding belief space and formulate a finite-state MDP problem, which is solved using the relative value iteration algorithm. For the AoII metric in the general setup, a deep reinforcement learning policy is proposed to solve the belief MDP problem. Simulation results show the effectiveness of the derived policies and, in particular, reveal a non-monotonic switching-type structure of the real-time optimal policy with respect to AoI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.06522v3</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Abolfazl Zakeri, Mohammad Moltafet, Marian Codreanu</dc:creator>
    </item>
    <item>
      <title>Millimeter-wave Radio SLAM: End-to-End Processing Methods and Experimental Validation</title>
      <link>https://arxiv.org/abs/2312.13741</link>
      <description>arXiv:2312.13741v2 Announce Type: replace 
Abstract: In this article, we address the timely topic of cellular bistatic simultaneous localization and mapping (SLAM) with specific focus on end-to-end processing solutions, from raw I/Q samples, via channel parameter estimation to user equipment (UE) and landmark location information in millimeter-wave (mmWave) networks, with minimal prior knowledge. Firstly, we propose a new multipath channel parameter estimation solution that operates directly with beam reference signal received power (BRSRP) measurements, alleviating the need to know the true antenna beam-patterns or the underlying beamforming weights. Additionally, the method has built-in robustness against unavoidable antenna sidelobes. Secondly, we propose new snapshot SLAM algorithms that have increased robustness and identifiability compared to prior art, in practical built environments with complex clutter and multi-bounce propagation scenarios, and do not rely on any a priori motion model. The performance of the proposed methods is assessed at the 60 GHz mmWave band, via both realistic ray-tracing evaluations as well as true experimental measurements, in an indoor environment. A wide set of offered results demonstrate the improved performance, compared to the relevant prior art, in terms of the channel parameter estimation as well as the end-to-end SLAM performance. Finally, the article provides the measured 60 GHz data openly available for the research community, facilitating results reproducibility as well as further algorithm development.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.13741v2</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Elizaveta Rastorgueva-Foi, Ossi Kaltiokallio, Yu Ge, Matias Turunen, Jukka Talvitie, Bo Tan, Musa Furkan Keskin, Henk Wymeersch, Mikko Valkama</dc:creator>
    </item>
    <item>
      <title>Computational Offloading in Semantic-Aware Cloud-Edge-End Collaborative Networks</title>
      <link>https://arxiv.org/abs/2402.18183</link>
      <description>arXiv:2402.18183v2 Announce Type: replace 
Abstract: The trend of massive connectivity pushes forward the explosive growth of end devices. The emergence of various applications has prompted a demand for pervasive connectivity and more efficient computing paradigms. On the other hand, the lack of computational capacity of the end devices restricts the implementation of the intelligent applications, and becomes a bottleneck of the multiple access for supporting massive connectivity. Mobile cloud computing (MCC) and mobile edge computing (MEC) techniques enable end devices to offload local computation-intensive tasks to servers by networks. In this paper, we consider the cloud-edge-end collaborative networks to utilize distributed computing resources. Furthermore, we apply task-oriented semantic communications to tackle the fast-varying channel between the end devices and MEC servers and reduce the communication cost. To minimize long-term energy consumption on constraints queue stability and computational delay, a Lyapunov-guided deep reinforcement learning hybrid (DRLH) framework is proposed to solve the mixed integer non-linear programming (MINLP) problem. The long-term energy consumption minimization problem is transformed into the deterministic problem in each time frame. The DRLH framework integrates a model-free deep reinforcement learning algorithm with a model-based mathematical optimization algorithm to mitigate computational complexity and leverage the scenario information, so that improving the convergence performance. Numerical results demonstrate that the proposed DRLH framework achieves near-optimal performance on energy consumption while stabilizing all queues.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.18183v2</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Zelin Ji, Zhijin Qin</dc:creator>
    </item>
    <item>
      <title>LiDAR Point Cloud-based Multiple Vehicle Tracking with Probabilistic Measurement-Region Association</title>
      <link>https://arxiv.org/abs/2403.06423</link>
      <description>arXiv:2403.06423v3 Announce Type: replace 
Abstract: Multiple extended target tracking (ETT) has gained increasing attention due to the development of high-precision LiDAR and radar sensors in automotive applications. For LiDAR point cloud-based vehicle tracking, this paper presents a probabilistic measurement-region association (PMRA) ETT model, which can describe the complex measurement distribution by partitioning the target extent into different regions. The PMRA model overcomes the drawbacks of previous data-region association (DRA) models by eliminating the approximation error of constrained estimation and using continuous integrals to more reliably calculate the association probabilities. Furthermore, the PMRA model is integrated with the Poisson multi-Bernoulli mixture (PMBM) filter for tracking multiple vehicles. Simulation results illustrate the superior estimation accuracy of the proposed PMRA-PMBM filter in terms of both positions and extents of the vehicles comparing with PMBM filters using the gamma Gaussian inverse Wishart and DRA implementations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06423v3</guid>
      <category>eess.SP</category>
      <category>cs.RO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guanhua Ding, Jianan Liu, Yuxuan Xia, Tao Huang, Bing Zhu, Jinping Sun</dc:creator>
    </item>
    <item>
      <title>EEGDiR: Electroencephalogram denoising network for temporal information storage and global modeling through Retentive Network</title>
      <link>https://arxiv.org/abs/2404.15289</link>
      <description>arXiv:2404.15289v2 Announce Type: replace 
Abstract: Electroencephalogram (EEG) signals play a pivotal role in clinical medicine, brain research, and neurological disease studies. However, susceptibility to various physiological and environmental artifacts introduces noise in recorded EEG data, impeding accurate analysis of underlying brain activity. Denoising techniques are crucial to mitigate this challenge. Recent advancements in deep learningbased approaches exhibit substantial potential for enhancing the signal-to-noise ratio of EEG data compared to traditional methods. In the realm of large-scale language models (LLMs), the Retentive Network (Retnet) infrastructure, prevalent for some models, demonstrates robust feature extraction and global modeling capabilities. Recognizing the temporal similarities between EEG signals and natural language, we introduce the Retnet from natural language processing to EEG denoising. This integration presents a novel approach to EEG denoising, opening avenues for a profound understanding of brain activities and accurate diagnosis of neurological diseases. Nonetheless, direct application of Retnet to EEG denoising is unfeasible due to the one-dimensional nature of EEG signals, while natural language processing deals with two-dimensional data. To facilitate Retnet application to EEG denoising, we propose the signal embedding method, transforming one-dimensional EEG signals into two dimensions for use as network inputs. Experimental results validate the substantial improvement in denoising effectiveness achieved by the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15289v2</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bin Wang, Fei Deng, Peifan Jiang</dc:creator>
    </item>
    <item>
      <title>Towards Bi-Hemispheric Emotion Mapping through EEG: A Dual-Stream Neural Network Approach</title>
      <link>https://arxiv.org/abs/2405.09551</link>
      <description>arXiv:2405.09551v3 Announce Type: replace 
Abstract: Emotion classification through EEG signals plays a significant role in psychology, neuroscience, and human-computer interaction. This paper addresses the challenge of mapping human emotions using EEG data in the Mapping Human Emotions through EEG Signals FG24 competition. Subjects mimic the facial expressions of an avatar, displaying fear, joy, anger, sadness, disgust, and surprise in a VR setting. EEG data is captured using a multi-channel sensor system to discern brain activity patterns. We propose a novel two-stream neural network employing a Bi-Hemispheric approach for emotion inference, surpassing baseline methods and enhancing emotion recognition accuracy. Additionally, we conduct a temporal analysis revealing that specific signal intervals at the beginning and end of the emotion stimulus sequence contribute significantly to improve accuracy. Leveraging insights gained from this temporal analysis, our approach offers enhanced performance in capturing subtle variations in the states of emotions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.09551v3</guid>
      <category>eess.SP</category>
      <category>cs.HC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David Freire-Obreg\'on, Daniel Hern\'andez-Sosa, Oliverio J. Santana, Javier Lorenzo-Navarro, Modesto Castrill\'on-Santana</dc:creator>
    </item>
    <item>
      <title>Surrogate-based cross-correlation for particle image velocimetry</title>
      <link>https://arxiv.org/abs/2112.05303</link>
      <description>arXiv:2112.05303v2 Announce Type: replace-cross 
Abstract: This paper presents a novel surrogate-based cross-correlation (SBCC) framework to improve the correlation performance for practical particle image velocimetry~(PIV). The basic idea is that an optimized surrogate filter/image, replacing one raw image, will produce a more accurate and robust correlation signal. Specifically, the surrogate image is encouraged to generate perfect Gaussian-shaped correlation map to tracking particles (PIV image pair) while producing zero responses to image noise (context images). And the problem is formularized with an objective function composed of surrogate loss and consistency loss. As a result, the closed-form solution provides an efficient multivariate operator that could consider other negative context images. Compared with the state-of-the-art baseline methods (background subtraction, robust phase correlation, etc.), our SBCC method exhibits significant performance improvement (accuracy and robustness) on the synthetic dataset and several challenging experimental PIV cases. Besides, our implementation with experimental details (\url{https://github.com/yongleex/SBCC}) is also available for interested researchers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2112.05303v2</guid>
      <category>eess.IV</category>
      <category>cs.CV</category>
      <category>eess.SP</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yong Lee, Fuqiang Gu, Zeyu Gong, Ding Pan, Wenhui Zeng</dc:creator>
    </item>
    <item>
      <title>Toward the application of XAI methods in EEG-based systems</title>
      <link>https://arxiv.org/abs/2210.06554</link>
      <description>arXiv:2210.06554v4 Announce Type: replace-cross 
Abstract: An interesting case of the well-known Dataset Shift Problem is the classification of Electroencephalogram (EEG) signals in the context of Brain-Computer Interface (BCI). The non-stationarity of EEG signals can lead to poor generalisation performance in BCI classification systems used in different sessions, also from the same subject. In this paper, we start from the hypothesis that the Dataset Shift problem can be alleviated by exploiting suitable eXplainable Artificial Intelligence (XAI) methods to locate and transform the relevant characteristics of the input for the goal of classification. In particular, we focus on an experimental analysis of explanations produced by several XAI methods on an ML system trained on a typical EEG dataset for emotion recognition. Results show that many relevant components found by XAI methods are shared across the sessions and can be used to build a system able to generalise better. However, relevant components of the input signal also appear to be highly dependent on the input itself.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.06554v4</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>eess.SP</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>3rd Italian Workshop on Explainable Artificial Intelligence, XAI.it 2022; Conference date: 28 November 2022 through 3 December 2022</arxiv:journal_reference>
      <dc:creator>Andrea Apicella, Francesco Isgr\`o, Andrea Pollastro, Roberto Prevete</dc:creator>
    </item>
    <item>
      <title>MARS: Message Passing for Antenna and RF Chain Selection for Hybrid Beamforming in MIMO Communication Systems</title>
      <link>https://arxiv.org/abs/2211.03584</link>
      <description>arXiv:2211.03584v4 Announce Type: replace-cross 
Abstract: In this paper, we consider a prospective receiving hybrid beamforming structure consisting of several radio frequency (RF) chains and abundant antenna elements in multi-input multi-output (MIMO) systems. Due to conventional costly full connections, we design an enhanced partially connected beamformer employing a low-density parity-check (LDPC)-based structure. As a benefit of the LDPC-based structure, information can be exchanged among clustered RF/antenna groups, which results in a low computational complexity order. Advanced message passing (MP) capable of inferring and transferring information among different paths is designed to support the LDPC-based hybrid beamformer. We propose a message-passing enhanced antenna and RF chain selection (MARS) scheme for minimizing the operational power of antennas and RF chains of the receiver as well as hybrid beamforming. Furthermore, sequential and parallel MP schemes for MARS are designed, namely, MARS-S and MARS-P, respectively, to address the convergence speed issue. A heuristic genetic algorithm is designed for receiving hybrid beamforming, comprising gene generation initialization, elite selection, crossover, and mutation. Simulations validate the convergence of both the MARS-P and the MARS-S algorithms. Due to the asynchronous information transfer of MARS-P, it requires higher power than MARS-S, which strikes a compelling balance among power consumption, convergence, and computational complexity. It is also demonstrated that the proposed MARS scheme outperforms the existing benchmarks using the heuristic method of fully/partially connected architectures in the open literature by requiring the lowest power and realizing the highest energy efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.03584v4</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Li-Hsiang Shen, Yen-Chun Lo, Kai-Ten Feng, Sau-Hsuan Wu, Lie-Liang Yang</dc:creator>
    </item>
    <item>
      <title>SI-SD: Sleep Interpreter through awake-guided cross-subject Semantic Decoding</title>
      <link>https://arxiv.org/abs/2309.16457</link>
      <description>arXiv:2309.16457v3 Announce Type: replace-cross 
Abstract: Understanding semantic content from brain activity during sleep represents a major goal in neuroscience. While studies in rodents have shown spontaneous neural reactivation of memories during sleep, capturing the semantic content of human sleep poses a significant challenge due to the absence of well-annotated sleep datasets and the substantial differences in neural patterns between wakefulness and sleep. To address these challenges, we designed a novel cognitive neuroscience experiment and collected a comprehensive, well-annotated electroencephalography (EEG) dataset from 134 subjects during both wakefulness and sleep. Leveraging this benchmark dataset, we developed SI-SD that enhances sleep semantic decoding through the position-wise alignment of neural latent sequence between wakefulness and sleep. In the 15-way classification task, our model achieves 24.12% and 21.39% top-1 accuracy on unseen subjects for NREM 2/3 and REM sleep, respectively, surpassing all other baselines. With additional fine-tuning, decoding performance improves to 30.32% and 31.65%, respectively. Besides, inspired by previous neuroscientific findings, we systematically analyze how the "Slow Oscillation" event impacts decoding performance in NREM 2/3 sleep -- decoding performance on unseen subjects further improves to 40.02%. Together, our findings and methodologies contribute to a promising neuro-AI framework for decoding brain activity during sleep.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.16457v3</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hui Zheng, Zhong-Tao Chen, Hai-Teng Wang, Jian-Yang Zhou, Lin Zheng, Pei-Yang Lin, Yun-Zhe Liu</dc:creator>
    </item>
    <item>
      <title>The Perception-Robustness Tradeoff in Deterministic Image Restoration</title>
      <link>https://arxiv.org/abs/2311.09253</link>
      <description>arXiv:2311.09253v3 Announce Type: replace-cross 
Abstract: We study the behavior of deterministic methods for solving inverse problems in imaging. These methods are commonly designed to achieve two goals: (1) attaining high perceptual quality, and (2) generating reconstructions that are consistent with the measurements. We provide a rigorous proof that the better a predictor satisfies these two requirements, the larger its Lipschitz constant must be, regardless of the nature of the degradation involved. In particular, to approach perfect perceptual quality and perfect consistency, the Lipschitz constant of the model must grow to infinity. This implies that such methods are necessarily more susceptible to adversarial attacks. We demonstrate our theory on single image super-resolution algorithms, addressing both noisy and noiseless settings. We also show how this undesired behavior can be leveraged to explore the posterior distribution, thereby allowing the deterministic model to imitate stochastic methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.09253v3</guid>
      <category>eess.IV</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guy Ohayon, Tomer Michaeli, Michael Elad</dc:creator>
    </item>
    <item>
      <title>Data-driven Semi-supervised Machine Learning with Surrogate Safety Measures for Abnormal Driving Behavior Detection</title>
      <link>https://arxiv.org/abs/2312.04610</link>
      <description>arXiv:2312.04610v4 Announce Type: replace-cross 
Abstract: Detecting abnormal driving behavior is critical for road traffic safety and the evaluation of drivers' behavior. With the advancement of machine learning (ML) algorithms and the accumulation of naturalistic driving data, many ML models have been adopted for abnormal driving behavior detection. Most existing ML-based detectors rely on (fully) supervised ML methods, which require substantial labeled data. However, ground truth labels are not always available in the real world, and labeling large amounts of data is tedious. Thus, there is a need to explore unsupervised or semi-supervised methods to make the anomaly detection process more feasible and efficient. To fill this research gap, this study analyzes large-scale real-world data revealing several abnormal driving behaviors (e.g., sudden acceleration, rapid lane-changing) and develops a Hierarchical Extreme Learning Machines (HELM) based semi-supervised ML method using partly labeled data to accurately detect the identified abnormal driving behaviors. Moreover, previous ML-based approaches predominantly utilize basic vehicle motion features (such as velocity and acceleration) to label and detect abnormal driving behaviors, while this study seeks to introduce Surrogate Safety Measures (SSMs) as the input features for ML models to improve the detection performance. Results from extensive experiments demonstrate the effectiveness of the proposed semi-supervised ML model with the introduced SSMs serving as important features. The proposed semi-supervised ML method outperforms other baseline semi-supervised or unsupervised methods regarding various metrics, e.g., delivering the best accuracy at 99.58% and the best F-1 measure at 0.9913. The ablation study further highlights the significance of SSMs for advancing detection performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.04610v4</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>eess.SP</category>
      <category>stat.OT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yongqi Dong, Lanxin Zhang, Haneen Farah, Arkady Zgonnikov, Bart van Arem</dc:creator>
    </item>
    <item>
      <title>Joint User Association and Power Control for Cell-Free Massive MIMO</title>
      <link>https://arxiv.org/abs/2401.02701</link>
      <description>arXiv:2401.02701v2 Announce Type: replace-cross 
Abstract: This work proposes novel approaches that jointly design user equipment (UE) association and power control (PC) in a downlink user-centric cell-free massive multiple-input multiple-output (CFmMIMO) network, where each UE is only served by a set of access points (APs) for reducing the fronthaul signalling and computational complexity. In order to maximize the sum spectral efficiency (SE) of the UEs, we formulate a mixed-integer nonconvex optimization problem under constraints on the per-AP transmit power, quality-of-service rate requirements, maximum fronthaul signalling load, and maximum number of UEs served by each AP. In order to solve the formulated problem efficiently, we propose two different schemes according to the different sizes of the CFmMIMO systems. For small-scale CFmMIMO systems, we present a successive convex approximation (SCA) method to obtain a stationary solution and also develop a learning-based method (JointCFNet) to reduce the computational complexity. For large-scale CFmMIMO systems, we propose a low-complexity suboptimal algorithm using accelerated projected gradient (APG) techniques. Numerical results show that our JointCFNet can yield similar performance and significantly decrease the run time compared with the SCA algorithm in small-scale systems. The presented APG approach is confirmed to run much faster than the SCA algorithm in the large-scale system while obtaining an SE performance close to that of the SCA approach. Moreover, the median sum SE of the APG method is up to about 2.8 fold higher than that of the heuristic baseline scheme.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.02701v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chongzheng Hao, Tung Thanh Vu, Hien Quoc Ngo, Minh N. Dao, Xiaoyu Dang, Chenghua Wang, Michail Matthaiou</dc:creator>
    </item>
    <item>
      <title>When to Preempt in a Status Update System?</title>
      <link>https://arxiv.org/abs/2402.00845</link>
      <description>arXiv:2402.00845v2 Announce Type: replace-cross 
Abstract: We consider a time-slotted status update system with an error-free preemptive queue. The goal of the sampler-scheduler pair is to minimize the age of information at the monitor by sampling and transmitting the freshly sampled update packets to the monitor. The sampler-scheduler pair also has a choice to preempt an old update packet from the server and transmit a new update packet to the server. We formulate this problem as a Markov decision process (MDP) and find the optimal sampling policy. We find a sufficient, and also separately a necessary, condition for the always preemption policy to be an optimal policy. We show that it is optimal for the sampler-scheduler pair to sample a new packet immediately upon the reception of an update packet at the monitor. We propose a double-threshold sampling policy which we show to be an optimal policy under some assumptions on the queue statistic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.00845v2</guid>
      <category>cs.IT</category>
      <category>cs.GT</category>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>eess.SY</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Subhankar Banerjee, Sennur Ulukus</dc:creator>
    </item>
    <item>
      <title>RSCNet: Dynamic CSI Compression for Cloud-based WiFi Sensing</title>
      <link>https://arxiv.org/abs/2402.04888</link>
      <description>arXiv:2402.04888v2 Announce Type: replace-cross 
Abstract: WiFi-enabled Internet-of-Things (IoT) devices are evolving from mere communication devices to sensing instruments, leveraging Channel State Information (CSI) extraction capabilities. Nevertheless, resource-constrained IoT devices and the intricacies of deep neural networks necessitate transmitting CSI to cloud servers for sensing. Although feasible, this leads to considerable communication overhead. In this context, this paper develops a novel Real-time Sensing and Compression Network (RSCNet) which enables sensing with compressed CSI; thereby reducing the communication overheads. RSCNet facilitates optimization across CSI windows composed of a few CSI frames. Once transmitted to cloud servers, it employs Long Short-Term Memory (LSTM) units to harness data from prior windows, thus bolstering both the sensing accuracy and CSI reconstruction. RSCNet adeptly balances the trade-off between CSI compression and sensing precision, thus streamlining real-time cloud-based WiFi sensing with reduced communication costs. Numerical findings demonstrate the gains of RSCNet over the existing benchmarks like SenseFi, showcasing a sensing accuracy of 97.4% with minimal CSI reconstruction error. Numerical results also show a computational analysis of the proposed RSCNet as a function of the number of CSI frames.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.04888v2</guid>
      <category>cs.IT</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Borna Barahimi, Hakam Singh, Hina Tabassum, Omer Waqar, Mohammad Omer</dc:creator>
    </item>
    <item>
      <title>Simplifying Hypergraph Neural Networks</title>
      <link>https://arxiv.org/abs/2402.05569</link>
      <description>arXiv:2402.05569v2 Announce Type: replace-cross 
Abstract: Hypergraphs, with hyperedges connecting multiple nodes, are crucial for modelling higher-order interactions in real-world data. In frameworks utilising hypergraphs for downstream tasks, a task-specific model is typically paired with a hypergraph neural network (HNN). HNNs enhance the task-specific model by generating node features with hypergraph structural information via message passing. However, the training for HNNs is often computationally intensive, which limits their practical use. To tackle this challenge, we propose an alternative approach by integrating hypergraph structural information into node features using a training-free model called simplified hypergraph neural network (SHNN) that only contains a predefined propagation step. We theoretically show the efficiency and effectiveness of SHNN by showing that: 1) It largely reduces the training complexity when solving hypergraph-related downstream tasks compared to existing HNNs; 2) It utilises as much information as existing HNNs for node feature generation; and 3) It is robust against the oversmoothing issue while using long-range interactions. Experiments in node classification and hyperedge prediction showcase that, compared to state-of-the-art HNNs, SHNN leads to both competitive performance and superior training efficiency. Notably, on Cora-CA, the SHNN-based framework achieves the highest node classification accuracy with just 2% training time of the best baseline.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.05569v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>eess.SP</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bohan Tang, Zexi Liu, Keyue Jiang, Siheng Chen, Xiaowen Dong</dc:creator>
    </item>
    <item>
      <title>Safeguarding Next Generation Multiple Access Using Physical Layer Security Techniques: A Tutorial</title>
      <link>https://arxiv.org/abs/2403.16477</link>
      <description>arXiv:2403.16477v2 Announce Type: replace-cross 
Abstract: Driven by the ever-increasing requirements of ultra-high spectral efficiency, ultra-low latency, and massive connectivity, the forefront of wireless research calls for the design of advanced next generation multiple access schemes to facilitate provisioning of these stringent demands. This inspires the embrace of non-orthogonal multiple access (NOMA) in future wireless communication networks. Nevertheless, the support of massive access via NOMA leads to additional security threats, due to the open nature of the air interface, the broadcast characteristic of radio propagation as well as intertwined relationship among paired NOMA users. To address this specific challenge, the superimposed transmission of NOMA can be explored as new opportunities for security aware design, for example, multiuser interference inherent in NOMA can be constructively engineered to benefit communication secrecy and privacy. The purpose of this tutorial is to provide a comprehensive overview on the state-of-the-art physical layer security techniques that guarantee wireless security and privacy for NOMA networks, along with the opportunities, technical challenges, and future research trends.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16477v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lu Lv, Dongyang Xu, Rose Qingyang Hu, Yinghui Ye, Long Yang, Xianfu Lei, Xianbin Wang, Dong In Kim, Arumugam Nallanathan</dc:creator>
    </item>
    <item>
      <title>Electromagnetic Information Theory for Holographic MIMO Communications</title>
      <link>https://arxiv.org/abs/2405.10496</link>
      <description>arXiv:2405.10496v2 Announce Type: replace-cross 
Abstract: Holographic multiple-input multiple-output (HMIMO) utilizes a compact antenna array to form a nearly continuous aperture, thereby enhancing higher capacity and more flexible configurations compared with conventional MIMO systems, making it attractive in current scientific research. Key questions naturally arise regarding the potential of HMIMO to surpass Shannon's theoretical limits and how far its capabilities can be extended. However, the traditional Shannon information theory falls short in addressing these inquiries because it only focuses on the information itself while neglecting the underlying carrier, electromagnetic (EM) waves, and environmental interactions. To fill up the gap between the theoretical analysis and the practical application for HMIMO systems, we introduce electromagnetic information theory (EIT) in this paper. This paper begins by laying the foundation for HMIMO-oriented EIT, encompassing EM wave equations and communication regions. In the context of HMIMO systems, the resultant physical limitations are presented, involving Chu's limit, Harrington's limit, Hannan's limit, and the evaluation of coupling effects. Field sampling and HMIMO-assisted oversampling are also discussed to guide the optimal HMIMO design within the EIT framework. To comprehensively depict the EM-compliant propagation process, we present the approximate and exact channel modeling approaches in near-/far-field zones. Furthermore, we discuss both traditional Shannon's information theory, employing the probabilistic method, and Kolmogorov information theory, utilizing the functional analysis, for HMIMO-oriented EIT systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10496v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Li Wei, Tierui Gong, Chongwen Huang, Zhaoyang Zhang, Wei E. I. Sha, Zhi Ning Chen, Linglong Dai, Merouane Debbah, Chau Yuen</dc:creator>
    </item>
  </channel>
</rss>
