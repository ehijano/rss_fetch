<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.OT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.OT</link>
    <description>stat.OT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.OT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 17 Jan 2025 05:02:25 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 17 Jan 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Generative AI Takes a Statistics Exam: A Comparison of Performance between ChatGPT3.5, ChatGPT4, and ChatGPT4o-mini</title>
      <link>https://arxiv.org/abs/2501.09171</link>
      <description>arXiv:2501.09171v1 Announce Type: new 
Abstract: Many believe that use of generative AI as a private tutor has the potential to shrink access and achievement gaps between students and schools with abundant resources versus those with fewer resources. Shrinking the gap is possible only if paid and free versions of the platforms perform with the same accuracy. In this experiment, we investigate the performance of GPT versions 3.5, 4.0, and 4o-mini on the same 16-question statistics exam given to a class of first-year graduate students. While we do not advocate using any generative AI platform to complete an exam, the use of exam questions allows us to explore aspects of ChatGPT's responses to typical questions that students might encounter in a statistics course. Results on accuracy indicate that GPT 3.5 would fail the exam, GPT4 would perform well, and GPT4o-mini would perform somewhere in between. While we acknowledge the existence of other Generative AI/LLMs, our discussion concerns only ChatGPT because it is the most widely used platform on college campuses at this time. We further investigate differences among the AI platforms in the answers for each problem using methods developed for text analytics, such as reading level evaluation and topic modeling. Results indicate that GPT3.5 and 4o-mini have characteristics that are more similar than either of them have with GPT4.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.09171v1</guid>
      <category>stat.OT</category>
      <category>cs.LG</category>
      <pubDate>Fri, 17 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Monnie McGee, Bivin Sadler</dc:creator>
    </item>
    <item>
      <title>Towards Socially Responsible Forecasting: Identifying and Typifying Forecasting Harms</title>
      <link>https://arxiv.org/abs/2411.16531</link>
      <description>arXiv:2411.16531v2 Announce Type: replace 
Abstract: Data-driven organizations around the world routinely use forecasting methods to improve their planning and decision-making capabilities. Although much research exists on the harms resulting from traditional machine learning applications, little has specifically focused on the ethical impact of time series forecasting. Yet forecasting raises unique ethical issues due to the way it is used in different organizational contexts, supports different goals, and involves different data processing, model development, and evaluation pipelines. These differences make it difficult to apply machine learning harm taxonomies to common forecasting contexts. We leverage multiple interviews with expert industry practitioners and academic researchers to remedy this knowledge gap by cataloguing and analysing under-explored domains, applications, and scenarios where forecasting may cause harm, with the goal of developing a novel taxonomy of forecasting-specific harms. Inspired by the Microsoft Azure taxonomy for responsible innovation, we combined a human-led inductive coding scheme with an AI-driven analysis centered on the extraction of key taxonomies of harm in forecasting. The taxonomy is designed to guide researchers and practitioners and encourage ethical reflection on the impact of their decisions during the forecasting process. A secondary objective is to create a research agenda focused on possible forecasting-related measures to mitigate harm. Our work extends the growing literature on machine learning harms by identifying unique forms of harm that may occur in forecasting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.16531v2</guid>
      <category>stat.OT</category>
      <pubDate>Fri, 17 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bahman Rostami-Tabar, Travis Greene, Galit Shmueli, Rob J. Hyndman</dc:creator>
    </item>
    <item>
      <title>My Statistics is Better than Yours</title>
      <link>https://arxiv.org/abs/2412.10296</link>
      <description>arXiv:2412.10296v2 Announce Type: replace 
Abstract: Statistical schools-such as Bayesianism and Frequentism-are often presented as competing frameworks, each claiming technical rigour and superiority. Frequentism emphasizes objective inferences through repeated sampling, while Bayesianism incorporates prior beliefs and updates them with new evidence. Despite their strengths, neither school proves universally applicable, and the pursuit of a single "correct" statistical framework is ultimately misguided. Instead, this essay advocates for a context-dependent approach to statistical norms, drawing on Douglas (2004)'s concept of "operational objectivity". The idea is that by aligning the context of the research question with the value judgments inherent to its field, a certain statistical paradigm is warranted. The essay delves into the decision-theoretic foundations of Bayesianism, evaluates its descriptive limitations as highlighted by the Ellsberg paradox, and examines the difficulty of comparing normative systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.10296v2</guid>
      <category>stat.OT</category>
      <pubDate>Fri, 17 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Simon Benha\"iem</dc:creator>
    </item>
  </channel>
</rss>
