<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.NA</link>
    <description>math.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 05 Nov 2025 02:38:59 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>An unconditionally stable numerical approach for solving a nonlinear distributed delay Sobolev model</title>
      <link>https://arxiv.org/abs/2511.00003</link>
      <description>arXiv:2511.00003v1 Announce Type: new 
Abstract: This paper proposes an unconditionally stable numerical method for solving a nonlinear Sobolev model with distributed delay. The proposed computational approach approximates the time derivative by interpolation technique whereas the spatial derivatives are approximated using the finite element approximation. This combination is simple and easy to implement. Both stability and error estimates of the constructed method are deeply analyzed in a strong norm which is equivalent to the $H^{1}$-norm. The theoretical results indicate that the constructed approach is unconditionally stable, spatial fourth-order accurate, second-order convergent in time and more efficient than a large class of numerical methods discussed in the literature for solving a general class of delay Sobolev problems. Some numerical examples are carried out to confirm the theory and demonstrate the applicability and validity of the developed technique.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00003v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Eric Ngondiep</dc:creator>
    </item>
    <item>
      <title>Uncertainty Quantification in Forward Problems: Balancing Accuracy and Robustness Using CWENO Interpolations</title>
      <link>https://arxiv.org/abs/2511.00005</link>
      <description>arXiv:2511.00005v1 Announce Type: new 
Abstract: In this paper, we study uncertainty quantification (UQ) in forward problems. Our objective is to construct accurate and robust surrogate models by incorporating the seventh-order central weighted essentially non-oscillatory (CWENO7) scheme into the stochastic collocation framework. A key focus is on mitigating the oscillatory behavior often encountered in traditional spectral methods while retaining high-order accuracy in smooth regions. We present a systematic comparison between CWENO7-based and generalized polynomial chaos (gPC)-based approaches. Although gPC methods achieve spectral convergence, they are prone to Gibbs-type oscillations in nonsmooth settings. By contrast, CWENO7 utilizes local stencils to achieve a balance: non-oscillatory behavior near discontinuities and high-order convergence in smooth regions. To validate the approach, we conduct numerical experiments on a range of one- and two-dimensional smooth and nonsmooth problems, including shallow water equations with random inputs. The results demonstrate that CWENO7 interpolation provides accurate estimates of probability density functions, mean values, and standard deviations, particularly in regimes where gPC expansions exhibit strong oscillations. Furthermore, computational tests confirm that CWENO7 interpolation is efficient and scalable, establishing it as a reliable alternative to conventional stochastic collocation techniques for UQ in the presence of discontinuities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00005v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Alina Chertock, Arsen S. Iskhakov, Alexander Kurganov</dc:creator>
    </item>
    <item>
      <title>Numerical Study of Random Kelvin-Helmholtz Instability</title>
      <link>https://arxiv.org/abs/2511.00008</link>
      <description>arXiv:2511.00008v1 Announce Type: new 
Abstract: In this paper, we study random dissipative weak solutions of the compressible Euler equations in the Kelvin-Helmholtz (KH) instability. Motivated by the fact that weak entropy solutions are not unique and can be viewed as inviscid limits of Navier-Stokes flows, we take a statistical approach following ideas from turbulence theory. Our aim is to identify solution features that remain consistent across different realizations and mesh resolutions. For this purpose, we compute stable numerical solutions using a stochastic collocation method implemented with the help of a fifth-order alternative weighted essentially non-oscillatory (A-WENO) scheme and seventh-order central weighted essentially non-oscillatory (CWENO) interpolation in the random space. The obtained solutions are averaged over several embedded uniform grids, resulting in Ces\'aro averages, which are studied using stochastic tools. The analysis includes Reynolds stress and energy defects, probability density functions of averaged quantities, and reduced-order representations using proper orthogonal decomposition. The presented numerical experiments illustrate that random KH instabilities can be systematically described using statistical methods, averaging, and reduced-order modeling, providing a robust methodology for capturing the complex and chaotic dynamics of inviscid compressible flows.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00008v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Alina Chertock, Michael Herty, Arsen S. Iskhakov, Anna Iskhakova, Alexander Kurganov, M\'aria Luk\'a\v{c}ov\'a-Medvid'ov\'a</dc:creator>
    </item>
    <item>
      <title>Matrix Phylogeny: Compact Spectral Fingerprints for Trap-Robust Preconditioner Selection</title>
      <link>https://arxiv.org/abs/2511.00012</link>
      <description>arXiv:2511.00012v1 Announce Type: new 
Abstract: Matrix Phylogeny introduces compact spectral fingerprints (CSF/ASF) that characterize matrices at the family level. These fingerprints are low-dimensional, eigendecomposition-free descriptors built from Chebyshev trace moments estimated by Hutchinson sketches. A simple affine rescaling to [-1,1] makes them permutation/similarity invariant and robust to global scaling.
  Across synthetic and real tests, we observe phylogenetic compactness: only a few moments are needed. CSF with K=3-5 already yields perfect clustering (ARI=1.0; silhouettes ~0.89) on four synthetic families and a five-family set including BA vs ER, while ASF adapts the dimension on demand (median K*~9). On a SuiteSparse mini-benchmark (Hutchinson p~100), both CSF-H and ASF-H reach ARI=1.0. Against strong alternatives (eigenvalue histograms + Wasserstein, heat-kernel traces, WL-subtree), CSF-K=5 matches or exceeds accuracy while avoiding eigendecompositions and using far fewer features (K&lt;=10 vs 64/9153).
  The descriptors are stable to noise (log-log slope ~1.03, R^2~0.993) and support a practical trap-&gt;recommend pipeline for automated preconditioner selection. In an adversarial E6+ setting with a probe-and-switch mechanism, our physics-guided recommender attains near-oracle iteration counts (p90 regret=0), whereas a Frobenius 1-NN baseline exhibits large spikes (p90~34-60).
  CSF/ASF deliver compact (K&lt;=10), fast, invariant fingerprints that enable scalable, structure-aware search and recommendation over large matrix repositories. We recommend CSF with K=5 by default, and ASF when domain-specific adaptivity is desired.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00012v1</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jinwoo Baek</dc:creator>
    </item>
    <item>
      <title>Gamma convergence for a phase-field cohesive energy</title>
      <link>https://arxiv.org/abs/2511.00016</link>
      <description>arXiv:2511.00016v1 Announce Type: new 
Abstract: Reproducing the key features of fracture behavior under multiaxial stress states is essential for accurate modeling. Experimental evidence indicates that three intrinsic material properties govern fracture nucleation in elastic materials: elasticity, strength, and fracture toughness. Among these, strength remains the most often misunderstood, as it is not a single scalar quantity but rather a full surface in stress space. The flexibility in defining this strength envelope in phase-field models poses significant challenges, especially under complex loading conditions. Existing models in the literature often fail to capture both the qualitative shape and the quantitative fit of experimentally observed strength surfaces. To address this limitation, recent work introduces a new energy functional within a cohesive phase-field framework, specifically designed to control the shape of elastic domains. This model introduces an internal variable to describe the inelastic response. Notably, the strength is decoupled from the internal length, that is not interpreted as a material length scale, as often done in literature, but rather as a purely variational tool. The proposed functional allows for a rigorous variational framework, enabling the use of tools from the calculus of variations. We investigate the Gamma-convergence of the model to a sharp cohesive fracture energy in the one- and two-dimensional (anti-plane) setting, using a finite element discrete formulation and exploiting the strong localization of the damage variable. Notably, unlike classical models where the elastic and fracture energies converge independently, this model exhibits a coupling of all energy terms. We also present numerical simulations exploring the sensitivity of the model to mesh anisotropy, offering insight into both its theoretical robustness and its practical implementation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00016v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.AP</category>
      <category>math.MP</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eleonora Maggiorelli, Matteo Negri, Francesco Vicentini, Laura De Lorenzis</dc:creator>
    </item>
    <item>
      <title>Two-dimensional Gauss--Jacobi Quadrature for Multiscale Boltzmann Solvers</title>
      <link>https://arxiv.org/abs/2511.00017</link>
      <description>arXiv:2511.00017v1 Announce Type: new 
Abstract: The discretization of velocity space plays a crucial role in the accuracy and efficiency of multiscale Boltzmann solvers. Conventional velocity space discretization methods suffer from uneven node distribution and mismatch issues, limiting the performance of numerical simulations. To address this, a Gaussian quadrature scheme with a parameterized weight function is proposed, combined with a polar coordinate transformation for flexible discretization of velocity space. This method effectively mitigates node mismatch problems encountered in traditional approaches. Numerical results demonstrate that the proposed scheme significantly improves accuracy while reducing computational cost. Under highly rarefied conditions, the proposed method achieves a speed-up of up to 50 times compared to the conventional Newton-Cotes quadrature, offering an efficient tool with broad applicability for numerical simulations of rarefied and multiscale gas flows.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00017v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.flu-dyn</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shanshan Dong, Lu Wang, Xiangxiang Chen, Guanqing Wang</dc:creator>
    </item>
    <item>
      <title>Branched Signature Model</title>
      <link>https://arxiv.org/abs/2511.00018</link>
      <description>arXiv:2511.00018v1 Announce Type: new 
Abstract: In this paper, we introduce the branched signature model, motivated by the branched rough path framework of [Gubinelli, Journal of Differential Equations, 248(4), 2010], which generalizes the classical geometric rough path. We establish a universal approximation theorem for the branched signature model and demonstrate that iterative compositions of lower-level signature maps can approximate higher-level signatures. Furthermore, building on the existence of the extension map proposed in [Hairer-Kelly. Annales de l'Institue Henri Poincar\'e, Probabilit\'es et Statistiques 51, no. 1 (2015)], we show how to explicitly construct the extension of the original paths into higher-dimensional spaces via a map $\Psi$, so that the branched signature can be realized as the classical geometric signature of the extended path. This framework not only provides an efficient computational scheme for branched signatures but also opens new avenues for data-driven modeling and applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00018v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.PR</category>
      <category>q-fin.CP</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Munawar Ali, Qi Feng</dc:creator>
    </item>
    <item>
      <title>On the Structure of Floating-Point Noise in Batch-Invariant GPU Matrix Multiplication</title>
      <link>https://arxiv.org/abs/2511.00025</link>
      <description>arXiv:2511.00025v1 Announce Type: new 
Abstract: Floating-point non-associativity makes fundamental deep learning operations, such as matrix multiplication (matmul) on GPUs, inherently non-deterministic. Despite this, the statistical structure of the resulting numerical error remains poorly understood. A common working assumption is that these errors behave as independent and identically distributed (i.i.d.) Gaussian noise. In this paper, we empirically test this assumption and show that it fails to describe real GPU behavior. By comparing outputs of single-input and batched matmuls, we find that while the i.i.d. model predicts non-zero output instability, empirical results show a 0.00% prediction flip rate. Through covariance analysis, we uncover the cause: the floating-point error is structured and highly correlated. For float16, nearly 50% of the total error variance lies in off-diagonal terms, revealing that the noise behaves as a coordinated, directional perturbation rather than random static. This result challenges the prevailing stochastic view of numerical noise and provides a principled foundation for analyzing deep learning reliability under hardware non-determinism.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00025v1</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tadisetty Sai Yashwanth</dc:creator>
    </item>
    <item>
      <title>Convergence analysis for a tree-based nonlinear reduced basis method</title>
      <link>https://arxiv.org/abs/2511.00226</link>
      <description>arXiv:2511.00226v1 Announce Type: new 
Abstract: We develop and analyze a nonlinear reduced basis (RB) method for parametrized elliptic partial differential equations based on a binary-tree partition of the parameter domain into tensor-product structured subdomains. Each subdomain is associated with a local RB space of prescribed dimension, constructed via a greedy algorithm. A splitting strategy along the longest edge of the parameter subdomains ensures geometric control of the subdomains and enables a rigorous convergence analysis. Under the assumption that the parameter-to-solution map admits a holomorphic extension and that the resulting domain partition is quasi-uniform, we establish explicit bounds on the number of subdomains required to achieve a given tolerance for arbitrary parameter domain dimension and RB spaces size. Numerical experiments for diffusion and convection-diffusion problems confirm the theoretical predictions, demonstrating that the proposed approach, which has low storage requirements, achieves the expected convergence rates and in several cases outperforms an existing nonlinear RB method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00226v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohamed Barakat, Diane Guignard</dc:creator>
    </item>
    <item>
      <title>Approximating Young Measures With Deep Neural Networks</title>
      <link>https://arxiv.org/abs/2511.00233</link>
      <description>arXiv:2511.00233v1 Announce Type: new 
Abstract: Parametrized measures (or Young measures) enable to reformulate non-convex variational problems as convex problems at the cost of enlarging the search space from space of functions to space of measures. To benefit from such machinery, we need powerful tools for approximating measures. We develop a deep neural network approximation of Young measures in this paper. The key idea is to write the Young measure as push-forward of Gaussian measures, and reformulate the problem of finding Young measures to finding the corresponding push-forward. We approximate the push-forward map using deep neural networks by encoding the reformulated variational problem in the loss function. After developing the framework, we demonstrate the approach in several numerical examples. We hope this framework and our illustrative computational experiments provide a pathway for approximating Young measures in their wide range of applications from modeling complex microstructure in materials to non-cooperative games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00233v1</guid>
      <category>math.NA</category>
      <category>cond-mat.mtrl-sci</category>
      <category>cs.NA</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rayehe Karimi Mahabadi, Jianfeng Lu, Hossein Salahshoor</dc:creator>
    </item>
    <item>
      <title>An introduction to the a posteriori error analysis of parabolic partial differential equations</title>
      <link>https://arxiv.org/abs/2511.00245</link>
      <description>arXiv:2511.00245v1 Announce Type: new 
Abstract: This article provides a brief introduction to the a posteriori error analysis of parabolic partial differential equations, with an emphasis on challenges distinct from those of steady-state problems. Using the heat equation as a model problem, we examine the crucial influence of the choice of error norm, as well as the choice of notion of reconstruction of the discrete solution, on the analytical properties of the resulting estimators, especially in terms of the efficiency of the estimators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00245v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Iain Smears</dc:creator>
    </item>
    <item>
      <title>Learning and Leveraging Anisotropy Parameters in ANOVA Approximation</title>
      <link>https://arxiv.org/abs/2511.00251</link>
      <description>arXiv:2511.00251v1 Announce Type: new 
Abstract: We present a Fourier-based approach for high-dimensional function approximation. To this end, we analyze the truncated ANOVA (analysis of variance) decomposition and learn the anisotropic smoothness properties of the target function from scattered data. This smoothness information is then incorporated into our approximation algorithm to improve the accuracy. Specifically, we employ least squares approximation using trigonometric polynomials in combination with frequency boxes of optimized aspect ratios. These frequency boxes allow for the application of the Nonequispaced Fast Fourier Transform (NFFT), which significantly accelerates the computation of the method. Our approach enables the efficient optimization of dozens of parameters to achieve high approximation accuracy with minimal overhead. Numerical experiments demonstrate the practical effectiveness of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00251v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Felix Bartel, Pascal Schr\"oter</dc:creator>
    </item>
    <item>
      <title>Numerically stable evaluation of closed-form expressions for eigenvalues of $3 \times 3$ matrices</title>
      <link>https://arxiv.org/abs/2511.00292</link>
      <description>arXiv:2511.00292v1 Announce Type: new 
Abstract: Trigonometric formulas for eigenvalues of $3 \times 3$ matrices that build on Cardano's and Vi\`ete's work on algebraic solutions of the cubic are numerically unstable for matrices with repeated eigenvalues. This work presents numerically stable, closed-form evaluation of eigenvalues of real, diagonalizable $3 \times 3$ matrices via four invariants: the trace $I_1$, the deviatoric invariants $J_2$ and $J_3$, and the discriminant $\Delta$. We analyze the conditioning of these invariants and derive tight forward error bounds. For $J_2$ we propose an algorithm and prove its accuracy. We benchmark all invariants and the resulting eigenvalue formulas, relating observed forward errors to the derived bounds. In particular, we show that, for the special case of matrices with a well-conditioned eigenbasis, the newly proposed algorithms have errors within the forward stability bounds. Performance benchmarks show that the proposed algorithm is approximately ten times faster than the highly optimized LAPACK library for a challenging test case, while maintaining comparable accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00292v1</guid>
      <category>math.NA</category>
      <category>cs.MS</category>
      <category>cs.NA</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michal Habera, Andreas Zilian</dc:creator>
    </item>
    <item>
      <title>A computational inverse random source problem for elastic waves</title>
      <link>https://arxiv.org/abs/2511.00367</link>
      <description>arXiv:2511.00367v1 Announce Type: new 
Abstract: This paper investigates the inverse random source problem for elastic waves in three dimensions, where the source is assumed to be driven by an additive white noise. A novel computational method is proposed for reconstructing the variance of the random source from the correlation boundary measurement of the wave field. Compared with existing multi-frequency iterative approaches, our method is non-iterative and requires data at only a single frequency. As a result, the computational cost is significantly reduced. Furthermore, rigorous error analysis is conducted for the proposed method, which gives a quantitative error estimate. Numerical examples are presented to demonstrate effectiveness of the proposed method. Moreover, this method can to be directly applied to stochastic Maxwell equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00367v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Hao Gu, Tianjiao Wang, Xiang Xu, Yue Zhao</dc:creator>
    </item>
    <item>
      <title>Trust-Region Methods with Low-Fidelity Objective Models</title>
      <link>https://arxiv.org/abs/2511.00434</link>
      <description>arXiv:2511.00434v1 Announce Type: new 
Abstract: We introduce two multifidelity trust-region methods based on the Magical Trust Region (MTR) framework. MTR augments the classical trust-region step with a secondary, informative direction. In our approaches, the secondary ``magical'' directions are determined by solving coarse trust-region subproblems based on low-fidelity objective models. The first proposed method, Sketched Trust-Region (STR), constructs this secondary direction using a sketched matrix to reduce the dimensionality of the trust-region subproblem. The second method, SVD Trust-Region (SVDTR), defines the magical direction via a truncated singular value decomposition of the dataset, capturing the leading directions of variability. Several numerical examples illustrate the potential gain in efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00434v1</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>stat.ML</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Andrea Angino, Matteo Aurina, Alena Kopani\v{c}\'akov\'a, Matthias Voigt, Marco Donatelli, Rolf Krause</dc:creator>
    </item>
    <item>
      <title>Three-dimensional narrow volume reconstruction method with unconditional stability based on a phase-field Lagrange multiplier approach</title>
      <link>https://arxiv.org/abs/2511.00508</link>
      <description>arXiv:2511.00508v1 Announce Type: new 
Abstract: Reconstruction of an object from points cloud is essential in prosthetics, medical imaging, computer vision, etc. We present an effective algorithm for an Allen--Cahn-type model of reconstruction, employing the Lagrange multiplier approach. Utilizing scattered data points from an object, we reconstruct a narrow shell by solving the governing equation enhanced with an edge detection function derived from the unsigned distance function. The specifically designed edge detection function ensures the energy stability. By reformulating the governing equation through the Lagrange multiplier technique and implementing a Crank--Nicolson time discretization, we can update the solutions in a stable and decoupled manner. The spatial operations are approximated using the finite difference method, and we analytically demonstrate the unconditional stability of the fully discrete scheme. Comprehensive numerical experiments, including reconstructions of complex 3D volumes such as characters from \textit{Star Wars}, validate the algorithm's accuracy, stability, and effectiveness. Additionally, we analyze how specific parameter selections influence the level of detail and refinement in the reconstructed volumes. To facilitate the interested readers to understand our algorithm, we share the computational codes and data in https://github.com/cfdyang521/C-3PO/tree/main.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00508v1</guid>
      <category>math.NA</category>
      <category>cs.CG</category>
      <category>cs.CV</category>
      <category>cs.NA</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Renjun Gao, Xiangjie Kong, Dongting Cai, Boyi Fu, Junxiang Yang</dc:creator>
    </item>
    <item>
      <title>Accuracy and stability of the hyperbolic model time integration scheme revisited</title>
      <link>https://arxiv.org/abs/2511.00557</link>
      <description>arXiv:2511.00557v1 Announce Type: new 
Abstract: The hyperbolic model (HM) time integration scheme tackles parabolic problems by adding a small artificial second order time derivative term. Described by Samarskii in his 1971 book, the scheme reappeared as the generalized Du Fort-Frankel scheme in a 1976 paper by Gottlieb and Gustafsson. In this note we revisit accuracy and stability properties of the scheme. In particular, we show that the stability condition, formulated by Samarskii based on operator inequalities, coincides with the requirement that the eigenvalues of the amplification matrix (the stability function operator) are smaller than one in absolute value. However, under this condition, the norm of this matrix may exceed one and this, as recently pointed out by Corem and Ditkowski (2012), may corrupt convergence of the scheme. Hence, we also discuss whether this eventual stability lack can be detected and mitigated in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00557v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mikhail A. Botchev</dc:creator>
    </item>
    <item>
      <title>Filtered Neural Galerkin model reduction schemes for efficient propagation of initial condition uncertainties in digital twins</title>
      <link>https://arxiv.org/abs/2511.00670</link>
      <description>arXiv:2511.00670v1 Announce Type: new 
Abstract: Uncertainty quantification in digital twins is critical to enable reliable and credible predictions beyond available data. A key challenge is that ensemble-based approaches can become prohibitively expensive when embedded in control and data assimilation loops in digital twins, even when reduced models are used. We introduce a reduced modeling approach that advances in time the mean and covariance of the reduced solution distribution induced by the initial condition uncertainties, which eliminates the need to maintain and propagate a costly ensemble of reduced solutions. The mean and covariance dynamics are obtained as a moment closure from Neural Galerkin schemes on pre-trained neural networks, which can be interpreted as filtered Neural Galerkin dynamics analogous to Gaussian filtering and the extended Kalman filter. Numerical experiments demonstrate that filtered Neural Galerkin schemes achieve more than one order of magnitude speedup compared to ensemble-based uncertainty propagation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00670v1</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhiyang Ning, Benjamin Peherstorfer</dc:creator>
    </item>
    <item>
      <title>Towards a Multigrid Preconditioner Interpretation of Hierarchical Poincar\'e-Steklov Solvers</title>
      <link>https://arxiv.org/abs/2511.00735</link>
      <description>arXiv:2511.00735v1 Announce Type: new 
Abstract: We revisit the Hierarchical Poincar\'e--Steklov (HPS) method within a preconditioned iterative framework. Originally introduced as a direct solver for elliptic boundary-value problems, the HPS method combines nested dissection with tensor-product spectral element discretizations, even though it has been shown in other contexts[8]. Building on the iterative variant proposed in[1], we reinterpret the hierarchical merge structure of HPS as a natural multigrid preconditioner. This perspective unifies direct and iterative formulations of HPS connecting it to multigrid domain decomposition. The resulting formulation preserves the high accuracy of spectral discretizations while enabling flexible iterative solution strategies. Numerical experiments in two dimensions demonstrate the performance and convergence behavior of the proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00735v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>J. P. Lucero Lorca</dc:creator>
    </item>
    <item>
      <title>Generalized singular value decompositions of dual quaternion matrices and beyond</title>
      <link>https://arxiv.org/abs/2511.00761</link>
      <description>arXiv:2511.00761v2 Announce Type: new 
Abstract: In high-dimensional data processing and data analysis related to dual quaternion statistics, generalized singular value decomposition (GSVD) of a dual quaternion matrix pair is an essential numerical linear algebra tool for an elegant problem formulation and numerical implementation. In this paper, building upon the existing singular value decomposition (SVD) of a dual quaternion matrix, we put forward several types of GSVD of dual quaternion data matrices in accordance with their dimensions. Explicitly, for a given dual quaternion matrix pair $\{{\boldsymbol A}, {\boldsymbol B}\}$, if ${\boldsymbol A}$ and ${\boldsymbol B}$ have the same number of columns, we investigate two forms of their quotient-type SVD (DQGSVD) through different strategies, which can be selected to use in different scenarios. Three artificial examples are presented to illustrate the principle of the DQGSVD.
  Alternatively, if ${\boldsymbol A}$ and ${\boldsymbol B}$ have the same number of rows, we consider their canonical correlation decomposition (DQCCD). If ${\boldsymbol A}$ and ${\boldsymbol B}$ are consistent for dual quaternion matrix multiplication, we present their product-type SVD (DQPSVD). As a preparation, we also study the QR decomposition of a dual quaternion matrix based on the dual quaternion Householder transformation, and introduce the CS decomposition of an 2-by-2 blocked unitary dual quaternion matrix. Due to the peculiarity of containing dual part for dual quaternion matrices, the obtained series of GSVD of dual quaternion matrices dramatically distinguish from those in the real number field, the complex number field, and even the quaternion ring, but can be treated as an extension of them to some extent.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00761v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sitao Ling, Wenxuan Ma, Musheng Wei</dc:creator>
    </item>
    <item>
      <title>HEATNETs: Explainable Random Feature Neural Networks for High-Dimensional Parabolic PDEs</title>
      <link>https://arxiv.org/abs/2511.00886</link>
      <description>arXiv:2511.00886v1 Announce Type: new 
Abstract: We deal with the solution of the forward problem for high-dimensional parabolic PDEs with random feature (projection) neural networks (RFNNs). We first prove that there exists a single-hidden layer neural network with randomized heat-kernels arising from the fundamental solution (Green's functions) of the heat operator, that we call HEATNET, that provides an unbiased universal approximator to the solution of parabolic PDEs in arbitrary (high) dimensions, with the rate of convergence being analogous to the ${O}(N^{-1/2})$, where $N$ is the size of HEATNET. Thus, HEATNETs are explainable schemes, based on the analytical framework of parabolic PDEs, exploiting insights from physics-informed neural networks aided by numerical and functional analysis, and the structure of the corresponding solution operators. Importantly, we show how HEATNETs can be scaled up for the efficient numerical solution of arbitrary high-dimensional parabolic PDEs using suitable transformations and importance Monte Carlo sampling of the integral representation of the solution, in order to deal with the singularities of the heat kernel around the collocation points. We evaluate the performance of HEATNETs through benchmark linear parabolic problems up to 2,000 dimensions. We show that HEATNETs result in remarkable accuracy with the order of the approximation error ranging from $1.0E-05$ to $1.0E-07$ for problems up to 500 dimensions, and of the order of $1.0E-04$ to $1.0E-03$ for 1,000 to 2,000 dimensions, with a relatively low number (up to 15,000) of features.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00886v1</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kyriakos Georgiou, Gianluca Fabiani, Constantinos Siettos, Athanasios N. Yannacopoulos</dc:creator>
    </item>
    <item>
      <title>Convergence analysis for a finite volume evolution Galerkin method for multidimensional hyperbolic systems</title>
      <link>https://arxiv.org/abs/2511.00957</link>
      <description>arXiv:2511.00957v1 Announce Type: new 
Abstract: We study the convergence of a finite volume method based on the method of bicharacteristics for multidimensional hyperbolic conservation laws. In particular, we concentrate on the linear wave equation system and nonlinear Euler equations of gas dynamics. We show the stability and the consistency of the numerical approximations. By means of the generalized Lax equivalence principle we prove the convergence of numerical solutions to the strong solution on the lifespan.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00957v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>M\'aria Luk\'a\v{c}ov\'a-Medvidov\'a, Zhuyan Tang, Yuhuan Yuan</dc:creator>
    </item>
    <item>
      <title>A Stable Loosely-Coupled Dirichlet-Neumann Scheme for Fluid-Structure Interaction with Large Added Mass</title>
      <link>https://arxiv.org/abs/2511.01035</link>
      <description>arXiv:2511.01035v1 Announce Type: new 
Abstract: Solving fluid-structure interaction (FSI) problems when the densities are similar (large added mass), such as in hemodynamics, is challenging since the stability and convergence of the adopted numerical scheme could be compromised. In particular, while loosely coupled (LC) partitioned approaches are appealing due to their computational efficiency, the stability issues arising in high added mass regimes limit their applicability.
  In this work, we present a new strongly-coupled (SC) partitioning strategy for the solution of the FSI problem, from which we derive a stable LC scheme based on Dirichlet and Neumann interface conditions. We analyse the convergence of the new SC scheme on a benchmark problem, demonstrating enhanced behaviour over the standard DN method for specific ranges of a parameter $\alpha$, without additional relaxation. Building on this, we introduce a new LC scheme by performing a single iteration per time step. Stability analysis on a benchmark problem proves that the proposed LC scheme is conditionally stable in large added mass regimes, under a constraint on a parameter $\alpha$.
  Numerical experiments in large added mass settings confirm the theoretical results, demonstrating the effectiveness and applicability of the proposed schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01035v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Francesca Renzi, Christian Vergara</dc:creator>
    </item>
    <item>
      <title>A parallel-in-time Newton's method-based ODE solver</title>
      <link>https://arxiv.org/abs/2511.01465</link>
      <description>arXiv:2511.01465v1 Announce Type: new 
Abstract: In this article, we introduce a novel parallel-in-time solver for nonlinear ordinary differential equations (ODEs). We state the numerical solution of an ODE as a root-finding problem that we solve using Newton's method. The affine recursive operations arising in Newton's step are parallelized in time by using parallel prefix sums, that is, parallel scan operations, which leads to a logarithmic span complexity. This yields an improved runtime compared to the previously proposed Parareal method. We demonstrate the computational advantage through numerical simulations of various systems of ODEs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01465v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Casian Iacob, Hassan Razavi, Simo S\"arkk\"a</dc:creator>
    </item>
    <item>
      <title>SCOUT: Semi-Lagrangian COnservative and Unconditionally sTable schemes for nonlinear advection-diffusion problems</title>
      <link>https://arxiv.org/abs/2511.01477</link>
      <description>arXiv:2511.01477v2 Announce Type: new 
Abstract: In this work, we propose a new semi-Lagrangian (SL) finite difference scheme for nonlinear advection-diffusion problems. To ensure conservation, which is fundamental for achieving physically consistent solutions, the governing equations are integrated over a space-time control volume constructed along the characteristic curves originating from each computational point. By applying Gauss theorem, all space-time surface integrals can be evaluated. For nonlinear problems, a nonlinear equation must be solved to find the foot of the characteristic, while this is not needed in linear cases. This formulation yields SL schemes that are fully conservative and unconditionally stable, as verified by numerical experiments with CFL numbers up to 100. Moreover, the diffusion terms are, for the first time, directly incorporated within a conservative semi-Lagrangian framework, leading to the development of a novel characteristic-based Crank-Nicolson discretization in which the diffusion contribution is implicitly evaluated at the foot of the characteristic. A broad set of benchmark tests demonstrates the accuracy, robustness, and strict conservation property of the proposed method, as well as its unconditional stability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01477v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Silvia Preda, Walter Boscheri, Matteo Semplice, Maurizio Tavelli</dc:creator>
    </item>
    <item>
      <title>Enhancing Non-Terrestrial Network Performance with Free Space Optical Links and Intelligent Reflecting Surfaces</title>
      <link>https://arxiv.org/abs/2511.01484</link>
      <description>arXiv:2511.01484v1 Announce Type: new 
Abstract: The integration of non-terrestrial networks (NTNs), which include high altitude platform (HAP) stations and intelligent reflecting surfaces (IRS) into communication infrastructures has become a crucial area of research to address the increasing requirements for connectivity and performance in the post-5G era. This paper presents a comprehensive performance study of a new NTN architecture, which enables communication from the optical ground station (OGS) to end users through the utilization of HAP and terrestrial IRS nodes. In this configuration, the HAP acts as an amplify-and-forward (AF) relay terminal between the free-space optical (FSO) link and the RF links.
  Specifically, the RF links are modeled using the Shadowed Rician and the generalized Nakagami-$m$ models, where the FSO link is characterized by the Gamma-Gamma distribution with generalized pointing errors. The FSO system operates under either intensity modulation with direct detection or heterodyne detection. Using the mixture Gamma model, we approximate the non-centered chi-square distribution that describes the total fading of the RF link, and we assess the performance of the end-to-end system by analyzing the ergodic capacity, the average bit-error rate (BER), and the outage probability, calculated using the bivariate Fox-H function. We also provide simple asymptotic expressions for the average BER and the outage probability at high signal-to-noise ratio (SNR). Finally, the proposed analysis is validated with numerical and Monte-Carlo simulation results, showing an exact match.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01484v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shunyuan Shang, Emna Zedini, Mohamed-Slim Alouini</dc:creator>
    </item>
    <item>
      <title>Optical Intelligent Reflecting Surfaces Empowering Non-Terrestrial Communications</title>
      <link>https://arxiv.org/abs/2511.01488</link>
      <description>arXiv:2511.01488v1 Announce Type: new 
Abstract: In this work, we propose an innovative system that combines high-altitude platforms (HAPs) and optical intelligent reflecting surfaces (OIRS) to address line-of-sight (LOS) challenges in urban environments. Our three-hops system setup includes an optical ground station (OGS), a HAP, an OIRS, and a user. Signals are transmitted from the OGS to the HAP via a free space optical (FSO) link, with the HAP functioning as an amplify-and-forward (AF) relay that redirects signals through an OIRS, effectively bypassing obstacles such as buildings and trees to improve connectivity for non-line-of-sight (NLOS) User. For the OIRS link, we address key channel impairments, including atmospheric turbulence, pointing errors, attenuation, and geometric and misalignment losses (GML). An accurate approximation for the Hoyt-distributed GML model is derived, enabling us to obtain closed-form expressions for outage probability (OP) and various performance metrics, such as average bit error rate (BER) and channel capacity of the OIRS-assisted FSO link. Furthermore, we analyze the end-to-end signal-to-noise ratio (SNR) and derive closed-form expressions for OP and performance metrics. Asymptotic expressions are provided for high-SNR regimes, allowing the system's diversity order to be calculated.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01488v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shunyuan Shang, Emna Zedini, Abla Kammoun, Mohamed-Slim Alouini</dc:creator>
    </item>
    <item>
      <title>On the optimality of dimension truncation error rates for a class of parametric partial differential equations</title>
      <link>https://arxiv.org/abs/2511.01492</link>
      <description>arXiv:2511.01492v1 Announce Type: new 
Abstract: In uncertainty quantification for parametric partial differential equations (PDEs), it is common to model uncertain random field inputs using countably infinite sequences of independent and identically distributed random variables. The lognormal random field is a prime example of such a model. While there have been many studies assessing the error in the PDE response that occurs when an infinite-dimensional random field input is replaced with a finite-dimensional random field, there do not seem to be any analyses in the existing literature discussing the sharpness of these bounds. This work seeks to remedy the situation. Specifically, we investigate two model problems where the existing dimension truncation error rates can be shown to be sharp.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01492v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Philipp A. Guth, Vesa Kaarnioja</dc:creator>
    </item>
    <item>
      <title>Numerically Efficient and Stable Algorithms for Kernel-Based Regularized System Identification Using Givens-Vector Representation</title>
      <link>https://arxiv.org/abs/2511.01534</link>
      <description>arXiv:2511.01534v1 Announce Type: new 
Abstract: Numerically efficient and stable algorithms are essential for kernel-based regularized system identification. The state of art algorithms exploit the semiseparable structure of the kernel and are based on the generator representation of the kernel matrix. However, as will be shown from both the theory and the practice, the algorithms based on the generator representation are sometimes numerically unstable, which limits their application in practice. This paper aims to address this issue by deriving and exploiting an alternative Givens-vector representation of some widely used kernel matrices. Based on the Givens-vector representation, we derive algorithms that yield more accurate results than existing algorithms without sacrificing efficiency. We demonstrate their usage for the kernel-based regularized system identification. Monte Carlo simulations show that the proposed algorithms admit the same order of computational complexity as the state-of-the-art ones based on generator representation, but without issues with numerical stability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01534v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>eess.SP</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhuohua Shen, Junpeng Zhang, Martin S. Andersen, Tianshi Chen</dc:creator>
    </item>
    <item>
      <title>An Adaptive Flux Reconstruction Scheme for Robust Shock Capturing</title>
      <link>https://arxiv.org/abs/2511.01564</link>
      <description>arXiv:2511.01564v1 Announce Type: new 
Abstract: In the case of hyperbolic conservation laws, high-order methods, such as the classical DG method, experience the phenomenon of unwanted high-frequency oscillations in the vicinity of a shock. Shock-capturing methods such as artificial dissipation, solution, flux, or TVD limiting are generally used to eliminate non-physical oscillations and provide bounds on physical quantities. For entropy-stable schemes, the additional objective would be to retain provable entropy dissipation guarantees of the underlying scheme, i.e. subcell limiting or entropy filtering [1, 2, 3, 4]. The nonlinearly-stable flux reconstruction (NSFR) semi-discretization given in Eq. 7 with a suitable flux reconstruction scheme has been demonstrated to mitigate spurious oscillations in the presence of shock discontinuities and at CFL values substantially larger than the DG variant of the NSFR scheme whilst retaining the property of entropy stability [5]. NSFR schemes achieve this by introducing an alternative lifting operator for surface numerical flux penalization, albeit at the expense of accuracy. In this technical note, we present an adaptive approach to the choice of the lifting operator employed, which maintains higher accuracy and allows for larger CFL values while retaining the underlying provable attributes of the scheme. While it cannot eliminate oscillations such as the aforementioned shock-capturing methods, together with a positivity-preserving limiter, the scheme provides for solutions that are essentially oscillation-free.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01564v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.flu-dyn</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sai Shruthi Srinivasan, Siva Nadarajah</dc:creator>
    </item>
    <item>
      <title>Numerical methods for solving PIDEs arising in swing option pricing under a two-factor mean-reverting model with jumps</title>
      <link>https://arxiv.org/abs/2511.01587</link>
      <description>arXiv:2511.01587v1 Announce Type: new 
Abstract: This paper concerns the numerical valuation of swing options with discrete action times under a linear two-factor mean-reverting model with jumps. The resulting sequence of two-dimensional partial integro-differential equations (PIDEs) are convection-dominated and possess a nonlocal integral term due to the presence of jumps. Further, the initial function is nonsmooth. We propose various second-order numerical methods that can adequately handle these challenging features. The stability and convergence of these numerical methods are analysed theoretically. By ample numerical experiments, we confirm their second-order convergence behaviour.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01587v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>q-fin.CP</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mustapha Regragui, Karel J. in 't Hout, Mich\`ele Vanmaele, Fred Espen Benth</dc:creator>
    </item>
    <item>
      <title>Analysis of a Schwarz-Fourier domain decomposition method</title>
      <link>https://arxiv.org/abs/2511.01616</link>
      <description>arXiv:2511.01616v1 Announce Type: new 
Abstract: The Schwarz domain decomposition method can be used for approximately solving a Laplace equation on a domain formed by the union of two overlapping discs. We consider an inexact variant of this method in which the subproblems on the discs are solved approximately using the projection on a Fourier subspace of the $L^2$ space on the boundary. This model problem is relevant for better understanding of the ddCOSMO solver that is used in computational chemistry. We analyze convergence properties of this Schwarz-Fourier domain decomposition method. The analysis is based on maximum principle arguments. We derive a new variant of the maximum principle and contraction number bounds in the maximum norm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01616v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arnold Reusken</dc:creator>
    </item>
    <item>
      <title>Sufficient conditions for QMC analysis of finite elements for parametric differential equations</title>
      <link>https://arxiv.org/abs/2511.01703</link>
      <description>arXiv:2511.01703v1 Announce Type: new 
Abstract: Parametric regularity of discretizations of flux vector fields satisfying a balance law is studied under some assumptions on a random parameter that links the flux with an unknown primal variable (often through a constitutive law). In the primary example of the stationary diffusion equation, the parameter corresponds to the inverse of the diffusivity. The random parameter is modeled here as a Gevrey-regular random field. Specific focus is on random fields expressible as functions of countably infinite sequences of independent random variables, which may be uniformly or normally distributed. Quasi-Monte Carlo (QMC) error bounds for some quantity of interest that depends on the flux are then derived using the parametric regularity. It is shown that the QMC method converges optimally if the quantity of interest depends continuously on the primal variable, its flux, or its gradient. A series of assumptions are introduced with the goal of encompassing a broad class of discretizations by various finite element methods. The assumptions are verified for the diffusion equation discretized using conforming finite elements, mixed methods, and hybridizable discontinuous Galerkin schemes. Numerical experiments confirm the analytical findings, highlighting the role of accurate flux approximation in QMC methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01703v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vesa Kaarnioja, Andreas Rupp, Jay Gopalakrishnan</dc:creator>
    </item>
    <item>
      <title>Finite Elements with weighted bases for the fractional Laplacian</title>
      <link>https://arxiv.org/abs/2511.01727</link>
      <description>arXiv:2511.01727v1 Announce Type: new 
Abstract: This work presents a numerical study of the Dirichlet problem for the fractional Laplacian $(-\Delta)^s$ with $s\in(0,1)$ using Finite Element methods with non-standard bases. Classical approaches based on piece-wise linear basis yield $h^{\frac 1 2}$ convergence rates in the Sobolev-Slobodeckij norm $H^s$ due to the limited boundary regularity of the solution $u(x)$, which behaves like $\operatorname{dist}(x,\mathbb{R}^d\setminus \Omega)^s$, where $h$ is the diameter of the mesh elements. To overcome this limitation, we propose a novel Finite Element basis of the form $\delta^s \times ($piece-wise linear functions$)$, where $\delta$ is any suitably smooth approximation of $\operatorname{dist}(x,\mathbb{R}^d\setminus \Omega)$. This exploits the improved regularity of $u/\delta^s$, achieving higher convergence rates. Under standard smoothness assumptions the method attains an order $h^{2-s}$ on quasi-uniform meshes, improving the rates with the piece-wise linear basis. We provide a rigorous theoretical error analysis with explicit rates and validate it through numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01727v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>F\'elix del Teso, Stefano Fronzoni, David G\'omez-Castro</dc:creator>
    </item>
    <item>
      <title>A Low-Rank BUG Method for Sylvester-Type Equations</title>
      <link>https://arxiv.org/abs/2511.01735</link>
      <description>arXiv:2511.01735v1 Announce Type: new 
Abstract: We introduce a low-rank algorithm inspired by the Basis-Update and Galerkin (BUG) integrator to efficiently approximate solutions to Sylvester-type equations. The algorithm can exploit both the low-rank structure of the solution as well as any sparsity present to reduce computational complexity. Even when a standard dense solver, such as the Bartels-Stewart algorithm, is used for the reduced Sylvester equations generated by our approach, the overall computational complexity for constructing and solving the associated linear systems reduces to O(kr(n^2+m^2 +mn + r^2)), for X in R^{m \times n}, where k is the number of iterations and r the rank of the approximation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01735v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Georgios Vretinaris</dc:creator>
    </item>
    <item>
      <title>Variational Data-Consistent Assimilation</title>
      <link>https://arxiv.org/abs/2511.01759</link>
      <description>arXiv:2511.01759v1 Announce Type: new 
Abstract: This work introduces a new class of four-dimensional variational data assimilation (4D-Var) methods grounded in data-consistent inversion (DCI) theory. The methods extend classical 4D-Var by incorporating a predictability-aware regularization term. The first method formulated is referred to as Data-Consistent 4D-Var (DC-4DVar), which is then enhanced using a Weighted Mean Error (WME) quantity-of-interest map to construct the DC-WME 4D-Var method. While the DC and DC-WME cost functions both involve a predictability-aware regularization term, the DC-WME function includes a modification to the model-data misfit, thereby improving estimation accuracy, robustness, and theoretical consistency in nonlinear and partially observed dynamical systems. Proofs are provided that establish the existence and uniqueness of the minimizer and analyze how a predictability assumption that is common within the DCI framework helps to promote solution stability. Numerical experiments are presented on benchmark dynamical systems (Lorenz-63 and Lorenz-96) as well as for the shallow water equations (SWE). In the benchmark dynamical systems, the DC-WME 4D-Var formulation is shown to consistently outperform standard 4D-Var in reducing both error and bias while maintaining robustness under high observation noise and short assimilation windows. Despite introducing modest computational overhead, DC-WME 4D-Var delivers improvements in estimation performance and forecast skill, demonstrating its potential practicality and scalability for high-dimensional data assimilation problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01759v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <category>stat.AP</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rylan Spence, Troy Butler, Clint Dawson</dc:creator>
    </item>
    <item>
      <title>Stochastic Multigrid Method for Blind Ptychographic Phase Retrieval</title>
      <link>https://arxiv.org/abs/2511.01793</link>
      <description>arXiv:2511.01793v1 Announce Type: new 
Abstract: We present eMAGPIE (extended Multilevel-Adaptive-Guided Ptychographic Iterative Engine), a stochastic multigrid method for blind ptychographic phase retrieval that jointly recovers the object and the probe. We recast the task as the iterative minimization of a quadratic surrogate that majorizes the exit-wave misfit. From this surrogate, we derive closed-form updates, combined in a geometric-mean, phase-aligned joint step, yielding a simultaneous update of the object and probe with guaranteed descent of the sampled surrogate. This formulation naturally admits a multigrid acceleration that speeds up convergence. In experiments, eMAGPIE attains lower data misfit and phase error at comparable compute budgets and produces smoother, artifact-reduced phase reconstructions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01793v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Borong Zhang, Junjing Deng, Yi Jiang, Zichao Wendy Di</dc:creator>
    </item>
    <item>
      <title>Projected Subgradient Ascent for Convex Maximization</title>
      <link>https://arxiv.org/abs/2511.00741</link>
      <description>arXiv:2511.00741v1 Announce Type: cross 
Abstract: We consider the problem of maximizing a convex function over a closed convex set. Classical methods solve such problems using iterative schemes that repeatedly improve a solution. For linear maximization, we show that a single orthogonal projection suffices to obtain an approximate solution. For general convex functions over convex sets, we show that projected subgradient ascent converges to a first-order stationary point when using arbitrarily large step sizes. Taking the step size to infinity leads to the conditional gradient algorithm, and iterated linear optimization as a special case. We illustrate numerical experiments using a single projection for linear optimization in the elliptope, reducing the problem to the computation of a nearest correlation matrix.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00741v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pedro Felzenszwalb, Heon Lee</dc:creator>
    </item>
    <item>
      <title>Stochastic representation of solutions for the parabolic Cauchy problem with variable exponent coefficients</title>
      <link>https://arxiv.org/abs/2511.00773</link>
      <description>arXiv:2511.00773v1 Announce Type: cross 
Abstract: In this work, we prove existence and uniqueness of a bounded viscosity solution for the Cauchy problem of degenerate parabolic equations with variable exponents coefficients. We construct the solution directly using the stochastic representation, then verify it satisfies the Cauchy problem. The corresponding SDE, on the other hand, allows the drift and diffusion coefficients to respond nonlinearly to the current state through the state-dependent variable exponents, and thus, extends the expressive power of classical SDEs to better capture complex dynamics. To validate our theoretical framework, we conduct comprehensive numerical experiments comparing finite difference solutions (Crank-Nicolson on logarithmic grids) with Monte Carlo simulations of the SDE.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00773v1</guid>
      <category>math.AP</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mustafa Avci</dc:creator>
    </item>
    <item>
      <title>Training with Fewer Bits: Unlocking Edge LLMs Training with Stochastic Rounding</title>
      <link>https://arxiv.org/abs/2511.00874</link>
      <description>arXiv:2511.00874v1 Announce Type: cross 
Abstract: LLM training is resource-intensive. Quantized training improves computational and memory efficiency but introduces quantization noise, which can hinder convergence and degrade model accuracy. Stochastic Rounding (SR) has emerged as a theoretically attractive alternative to deterministic rounding, offering unbiased gradient estimates. However, its interaction with other training factors -- especially batch size -- remains under explored. In this paper, we present a theoretical and empirical study of mini-batch stochastic gradient descent (SGD) with SR, showing that increased batch sizes can compensate for reduced precision during back-propagation. Furthermore, we show that quantizing weights and activations impacts gradient variance in distinct ways. Our experiments validate these theoretical insights.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00874v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Taowen Liu, Marta Andronic, Deniz G\"und\"uz, George A. Constantinides</dc:creator>
    </item>
    <item>
      <title>T-MLA: A Targeted Multiscale Log--Exponential Attack Framework for Neural Image Compression</title>
      <link>https://arxiv.org/abs/2511.01079</link>
      <description>arXiv:2511.01079v1 Announce Type: cross 
Abstract: Neural image compression (NIC) has become the state-of-the-art for rate-distortion performance, yet its security vulnerabilities remain significantly less understood than those of classifiers. Existing adversarial attacks on NICs are often naive adaptations of pixel-space methods, overlooking the unique, structured nature of the compression pipeline. In this work, we propose a more advanced class of vulnerabilities by introducing T-MLA, the first targeted multiscale log--exponential attack framework. Our approach crafts adversarial perturbations in the wavelet domain by directly targeting the quality of the attacked and reconstructed images. This allows for a principled, offline attack where perturbations are strategically confined to specific wavelet subbands, maximizing distortion while ensuring perceptual stealth. Extensive evaluation across multiple state-of-the-art NIC architectures on standard image compression benchmarks reveals a large drop in reconstruction quality while the perturbations remain visually imperceptible. Our findings reveal a critical security flaw at the core of generative and content delivery pipelines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01079v1</guid>
      <category>cs.CV</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nikolay I. Kalmykov, Razan Dibo, Kaiyu Shen, Xu Zhonghan, Anh-Huy Phan, Yipeng Liu, Ivan Oseledets</dc:creator>
    </item>
    <item>
      <title>One model to solve them all: 2BSDE families via neural operators</title>
      <link>https://arxiv.org/abs/2511.01125</link>
      <description>arXiv:2511.01125v1 Announce Type: cross 
Abstract: We introduce a mild generative variant of the classical neural operator model, which leverages Kolmogorov--Arnold networks to solve infinite families of second-order backward stochastic differential equations ($2$BSDEs) on regular bounded Euclidean domains with random terminal time. Our first main result shows that the solution operator associated with a broad range of $2$BSDE families is approximable by appropriate neural operator models. We then identify a structured subclass of (infinite) families of $2$BSDEs whose neural operator approximation requires only a polynomial number of parameters in the reciprocal approximation rate, as opposed to the exponential requirement in general worst-case neural operator guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01125v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <category>q-fin.CP</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Takashi Furuya, Anastasis Kratsios, Dylan Possama\"i, Bogdan Raoni\'c</dc:creator>
    </item>
    <item>
      <title>Stochastic Regret Guarantees for Online Zeroth- and First-Order Bilevel Optimization</title>
      <link>https://arxiv.org/abs/2511.01126</link>
      <description>arXiv:2511.01126v1 Announce Type: cross 
Abstract: Online bilevel optimization (OBO) is a powerful framework for machine learning problems where both outer and inner objectives evolve over time, requiring dynamic updates. Current OBO approaches rely on deterministic \textit{window-smoothed} regret minimization, which may not accurately reflect system performance when functions change rapidly. In this work, we introduce a novel search direction and show that both first- and zeroth-order (ZO) stochastic OBO algorithms leveraging this direction achieve sublinear {stochastic bilevel regret without window smoothing}. Beyond these guarantees, our framework enhances efficiency by: (i) reducing oracle dependence in hypergradient estimation, (ii) updating inner and outer variables alongside the linear system solution, and (iii) employing ZO-based estimation of Hessians, Jacobians, and gradients. Experiments on online parametric loss tuning and black-box adversarial attacks validate our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01126v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Parvin Nazari, Bojian Hou, Davoud Ataee Tarzanagh, Li Shen, George Michailidis</dc:creator>
    </item>
    <item>
      <title>Trade Execution Flow as the Underlying Source of Market Dynamics</title>
      <link>https://arxiv.org/abs/2511.01471</link>
      <description>arXiv:2511.01471v1 Announce Type: cross 
Abstract: In this work, we demonstrate experimentally that the execution flow, $I = dV/dt$, is the fundamental driving force of market dynamics. We develop a numerical framework to calculate execution flow from sampled moments using the Radon-Nikodym derivative. A notable feature of this approach is its ability to automatically determine thresholds that can serve as actionable triggers. The technique also determines the characteristic time scale directly from the corresponding eigenproblem. The methodology has been validated on actual market data to support these findings. Additionally, we introduce a framework based on the Christoffel function spectrum, which is invariant under arbitrary non-degenerate linear transformations of input attributes and offers an alternative to traditional principal component analysis (PCA), which is limited to unitary invariance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01471v1</guid>
      <category>q-fin.CP</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>q-fin.TR</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mikhail Gennadievich Belov, Victor Victorovich Dubov, Vadim Konstantinovich Ivanov, Alexander Yurievich Maslov, Olga Vladimirovna Proshina, Vladislav Gennadievich Malyshkin</dc:creator>
    </item>
    <item>
      <title>Shortest Geodesic Loops, Sectional Curvature, and Injectivity Radius of the Stiefel Manifold</title>
      <link>https://arxiv.org/abs/2511.01563</link>
      <description>arXiv:2511.01563v1 Announce Type: cross 
Abstract: We determine the length of the shortest nontrivial geodesic loops on the Stiefel manifold endowed with any member of the one-parameter family of Riemannian metrics introduced by H\"uper et al. (2021). This family includes, in particular, the canonical and Euclidean metrics. By combining existing and new bounds on the sectional curvature, we determine the exact value of the injectivity radius of the Stiefel manifold under a wide range of members of the metric family.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01563v1</guid>
      <category>math.DG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jakob Stoye, Simon Mataigne, P. -A. Absil, Ralf Zimmermann</dc:creator>
    </item>
    <item>
      <title>Mutual Consensus and its Application in Minimum Cost Consensus Models</title>
      <link>https://arxiv.org/abs/2511.01614</link>
      <description>arXiv:2511.01614v1 Announce Type: cross 
Abstract: This paper introduces the concept of {mutual consensus} as a novel non-compensatory consensus measure that accounts for the maximum disparity among opinions to ensure robust consensus evaluation. Incorporating this concept, several new Minimum Cost Consensus (MCC) models are proposed, and their properties are analyzed. To show their applicability, these mutual consensus-based MCC models are then considered in the context of the {OWA-MCC} model, which employs Ordered Weighted Averaging (OWA) operators for preference aggregation. Concretely, we include a linearized formulation under symmetry conditions as well as examples of the non-convexity of the feasible region in the general case. Finally, mutual consensus is utilized to obtain approximate solutions for the OWA-MCC model, demonstrating its practical effectiveness and advancing the theoretical and applied dimensions of consensus modeling in group decision-making.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01614v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Diego Garc\'ia-Zamora, Bapi Dutta, Luis Mart\'inez</dc:creator>
    </item>
    <item>
      <title>Parallel-in-time solution of scalar nonlinear conservation laws</title>
      <link>https://arxiv.org/abs/2401.04936</link>
      <description>arXiv:2401.04936v2 Announce Type: replace 
Abstract: We consider the parallel-in-time solution of scalar nonlinear conservation laws in one spatial dimension. The equations are discretized in space with a conservative finite-volume method using weighted essentially non-oscillatory (WENO) reconstructions, and in time with high-order explicit Runge-Kutta methods. The solution of the global, discretized space-time problem is sought via a nonlinear iteration that uses a novel linearization strategy in cases of non-differentiable equations. Under certain choices of discretization and algorithmic parameters, the nonlinear iteration coincides with Newton's method, although, more generally, it is a preconditioned residual correction scheme. At each nonlinear iteration, the linearized problem takes the form of a certain discretization of a linear conservation law over the space-time domain in question. An approximate parallel-in-time solution of the linearized problem is computed with a single multigrid reduction-in-time (MGRIT) iteration, however, any other effective parallel-in-time method could be used in its place. The MGRIT iteration employs a novel coarse-grid operator that is a modified conservative semi-Lagrangian discretization and generalizes those we have developed previously for non-conservative scalar linear hyperbolic problems. Numerical tests are performed for the inviscid Burgers and Buckley--Leverett equations. For many test problems, the solver converges in just a handful of iterations with convergence rate independent of mesh resolution, including problems with (interacting) shocks and rarefactions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.04936v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1137/24M1630268</arxiv:DOI>
      <dc:creator>O. A. Krzysik, H. De Sterck, R. D. Falgout, J. B. Schroder</dc:creator>
    </item>
    <item>
      <title>Can Symmetric Positive Definite (SPD) coarse spaces perform well for indefinite Helmholtz problems?</title>
      <link>https://arxiv.org/abs/2403.18378</link>
      <description>arXiv:2403.18378v4 Announce Type: replace 
Abstract: Wave propagation problems governed by the Helmholtz equation remain among the most challenging in scientific computing, due to their indefinite nature. Domain decomposition methods with spectral coarse spaces have emerged as some of the most effective preconditioners, yet their theoretical guarantees often lag behind practical performance. In this work, we introduce and analyse the $\Delta_k$-GenEO coarse space within the two-level additive Schwarz preconditioners for heterogeneous Helmholtz problems. This is an adaptation of the $\Delta$-GenEO coarse space. Our results sharpen the $k$-explicit conditions for GMRES convergence, reducing the restrictions on the subdomain size and eigenvalue threshold. This narrows the long-standing gap between pessimistic theory and empirical evidence, and reveals why GenEO spaces based on SPD (symmetric positive definite) eigenvalue problems remain surprisingly effective despite their apparent limitations. Numerical experiments confirm the theory, demonstrating scalability, robustness to heterogeneity for low to moderate frequencies (while experiencing limitations in the high frequency cases), and significantly milder coarse-space growth than conservative estimates predict.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.18378v4</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Victorita Dolean, Mark Fry, Matthias Langer</dc:creator>
    </item>
    <item>
      <title>Statistical Rounding Error Analysis for Random Matrix Computations</title>
      <link>https://arxiv.org/abs/2405.07537</link>
      <description>arXiv:2405.07537v4 Announce Type: replace 
Abstract: The conventional rounding error analysis provides worst-case bounds with an associated failure probability and ignores the statistical property of the rounding errors. In this paper, we develop a new statistical rounding error analysis for random matrix computations. Such computations have numerous applications in the field of wireless communications, signal processing, and machine learning. By assuming the relative errors are independent random variables, we derive the approximate closed-form expressions for the expectation and variance of the rounding errors in various key computations for random matrices. Numerical experiments validate the accuracy of our derivations and demonstrate that our analytical expressions are generally at least two orders of magnitude tighter than alternative worst-case bounds, exemplified through the inner products.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07537v4</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yiming Fang, Li Chen</dc:creator>
    </item>
    <item>
      <title>Geometrical mixed finite element methods for fourth order obstacle problems in linearised elasticity</title>
      <link>https://arxiv.org/abs/2405.20338</link>
      <description>arXiv:2405.20338v3 Announce Type: replace 
Abstract: This paper is devoted to the study of a novel mixed Finite Element Method for approximating the solutions of fourth order variational problems subjected to a constraint.
  The first problem we consider consists in establishing the convergence of the error of the numerical approximation of the solution of a biharmonic obstacle problem. The contents of this section are meant to generalise the approach originally proposed by Ciarlet \&amp; Raviart, and then complemented by Ciarlet \&amp; Glowinski. The second problem we consider amounts to studying a two-dimensional variational problem for linearly elastic shallow shells subjected to remaining confined in a prescribed half-space. We first study the case where the parametrisation of the middle surface for the linearly elastic shallow shell under consideration has non-zero curvature, and we observe that the numerical approximation of this model via a mixed Finite Element Method based on conforming elements requires the implementation of the additional constraint according to which the gradient matrix of the dual variable has to be symmetric. However, differently from the biharmonic obstacle problem previously studied, we show that the numerical implementation of this result cannot be implemented by solely resorting to Courant triangles. Finally, we show that if the middle surface of the linearly elastic shallow shell under consideration is flat, the symmetry constraint required for formulating the constrained mixed variational problem announced in the second part of the paper is not required, and the solution can thus be approximated by solely resorting to Courant triangles.
  The theoretical results we derived are complemented by a series of numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20338v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Paolo Piersanti, Tianyu Sun</dc:creator>
    </item>
    <item>
      <title>Convergence of Random Batch Method with replacement for interacting particle systems</title>
      <link>https://arxiv.org/abs/2407.19315</link>
      <description>arXiv:2407.19315v2 Announce Type: replace 
Abstract: The Random Batch Method (RBM) proposed in [Jin et al. J Comput Phys, 2020] is an efficient algorithm for simulating interacting particle systems (IPS). In this paper, we investigate the Random Batch Method with replacement (RBM-r), which is the same as the kinetic Monte Carlo (KMC) method for the pairwise interacting particle system of size $N$. In the RBM-r algorithm, one randomly picks a small batch of size $p \ll N$, and only the particles in the picked batch interact among each other within the batch for a short time, where the weak interaction (of strength $\frac{1}{N-1}$) in the original system is replaced by a strong interaction (of strength $\frac{1}{p-1}$). Then one repeats this pick-interact process. This KMC algorithm dramatically reduces the computational cost from $O(N^2)$ to $O(pN)$ per time step, and provides an unbiased approximation of the original force/velocity field of the interacting particle system. We give a rigorous proof of this approximation with an explicit convergence rate. In detail, we show that the Wasserstein-2 distance between first marginal distributions of IPS and RBM-r has an $O(\kappa^{1/4})$ upper bound, where $\kappa$ is the time step for choosing the random batch and the bound is independent of $N$. An improved $O(\kappa^{1/2})$ rate is also obtained when there is no diffusion in the system. Notably, the techniques in our analysis can potentially be applied to study KMC for other systems, including the stochastic Ising spin system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.19315v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.DS</category>
      <category>math.PR</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhenhao Cai, Jian-Guo Liu, Yuliang Wang</dc:creator>
    </item>
    <item>
      <title>Finite element-based space-time total variation-type regularization of the inverse problem in electrocardiographic imaging</title>
      <link>https://arxiv.org/abs/2408.11573</link>
      <description>arXiv:2408.11573v2 Announce Type: replace 
Abstract: Reconstructing cardiac electrical activity from body surface electric potential measurements results in the severely ill-posed inverse problem in electrocardiography. Many different regularization approaches have been proposed to improve numerical results and provide unique results. This work presents a novel approach for reconstructing the epicardial potential from body surface potential maps based on a space-time total variation-type regularization using finite elements, where a first-order primal-dual algorithm solves the underlying convex optimization problem. In several numerical experiments, the superior performance of this method and the benefit of space-time regularization for the reconstruction of epicardial potential on two-dimensional torso data and a three-dimensional rabbit heart compared to state-of-the-art methods are demonstrated.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.11573v2</guid>
      <category>math.NA</category>
      <category>cs.CV</category>
      <category>cs.NA</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Manuel Haas, Thomas Grandits, Thomas Pinetz, Thomas Beiert, Simone Pezzuto, Alexander Effland</dc:creator>
    </item>
    <item>
      <title>$L_2$-approximation using median lattice algorithms</title>
      <link>https://arxiv.org/abs/2501.15331</link>
      <description>arXiv:2501.15331v3 Announce Type: replace 
Abstract: In this paper, we study the problem of multivariate $L_2$-approximation of functions belonging to a weighted Korobov space. We propose and analyze a median lattice-based algorithm, inspired by median integration rules, which have attracted significant attention in the theory of quasi-Monte Carlo methods. Our algorithm approximates the Fourier coefficients associated with a suitably chosen frequency index set, where each coefficient is estimated by taking the median over approximations from randomly shifted rank-1 lattice rules with independently chosen generating vectors. We prove that the algorithm achieves, with high probability, a convergence rate of the $L_2$-approximation error that is arbitrarily close to optimal with respect to the number of function evaluations. Furthermore, we show that the error bound depends only polynomially on the dimension, or is even independent of the dimension, under certain summability conditions on the weights. Numerical experiments illustrate the performance of the proposed median lattice-based algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.15331v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zexin Pan, Peter Kritzer, Takashi Goda</dc:creator>
    </item>
    <item>
      <title>High-dimensional stochastic finite volumes using the tensor train format</title>
      <link>https://arxiv.org/abs/2502.04868</link>
      <description>arXiv:2502.04868v2 Announce Type: replace 
Abstract: A method for the uncertainty quantification of nonlinear hyperbolic equations with many uncertain parameters is presented. The method combines the stochastic finite volume method and tensor trains in a novel way: the physical space and time dimensions are kept as full tensors, while all stochastic dimensions are compressed together into a tensor train. The resulting hybrid format has one tensor train for each spatial cell and each time step. The MUSCL scheme is adapted to this hybrid format and the feasibility of the approach using several classical test cases is shown. For the Burgers' equation a convergence study and a comparison with the full tensor train format are done with three stochastic parameters. The equation is then solved for an increasing number of stochastic dimensions. The Euler equations are then considered. A parameter study and a comparison with the full tensor train format are performed with the Sod problem. For a complex application we consider the Shu-Osher problem. The presented method opens new avenues for combining uncertainty quantification with well-known numerical schemes for conservation laws.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04868v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Juliette Dubois, Michael Herty, Siegfried M\"uller</dc:creator>
    </item>
    <item>
      <title>Quasi-Monte Carlo methods for uncertainty quantification of wave propagation and scattering problems modelled by the Helmholtz equation</title>
      <link>https://arxiv.org/abs/2502.12451</link>
      <description>arXiv:2502.12451v2 Announce Type: replace 
Abstract: We analyse and implement a quasi-Monte Carlo (QMC) finite element method (FEM) for the forward problem of uncertainty quantification (UQ) for the Helmholtz equation with random coefficients, both in the second-order and zero-order terms of the equation, thus modelling wave scattering in random media. The problem is formulated on the infinite propagation domain, after scattering by the heterogeneity, and also (possibly) a bounded impenetrable scatterer. The spatial discretization scheme includes truncation to a bounded domain via a perfectly matched layer (PML) technique and then FEM approximation. A special case is the problem of an incident plane wave being scattered by a bounded sound-soft impenetrable obstacle surrounded by a random heterogeneous medium, or more simply, just scattering by the random medium. The random coefficients are assumed to be affine separable expansions with infinitely many independent uniformly distributed and bounded random parameters. As quantities of interest for the UQ, we consider the expectation of general linear functionals of the solution, with a special case being the far-field pattern of the scattered field. The numerical method consists of (a) dimension truncation in parameter space, (b) application of an adapted QMC method to compute expected values, and (c) computation of samples of the PDE solution via PML truncation and FEM approximation. Our error estimates are explicit in $s$ (the dimension truncation parameter), $N$ (the number of QMC points), $h$ (the FEM grid size) and (most importantly), $k$ (the Helmholtz wavenumber). The method is also exponentially accurate with respect to the PML truncation radius. Illustrative numerical experiments are given.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12451v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ivan G. Graham, Frances Y. Kuo, Dirk Nuyens, Ian H. Sloan, Euan A. Spence</dc:creator>
    </item>
    <item>
      <title>Matrix-Free Ghost Penalty Evaluation via Tensor Product Factorization</title>
      <link>https://arxiv.org/abs/2503.00246</link>
      <description>arXiv:2503.00246v2 Announce Type: replace 
Abstract: We present a matrix-free approach for implementing ghost penalty stabilization in Cut Finite Element Methods (CutFEM). While matrix-free methods for CutFEM have been developed, the efficient evaluation of high-order, face-based ghost penalties remains a significant challenge, which this work addresses. By exploiting the tensor-product structure of the ghost penalty operator, we reduce its evaluation to a series of one-dimensional matrix-vector products using precomputed 1D matrices, avoiding the need to evaluate high-order derivatives directly. This approach achieves $O(k^{d+1})$ complexity for elements of degree $k$ in $d$ dimensions, significantly reducing implementation effort while maintaining accuracy. The derivation relies on the fact that the cells are aligned with the coordinate axes. The method is implemented within the \texttt{deal.II} library.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00246v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Micha{\l} Wichrowski</dc:creator>
    </item>
    <item>
      <title>Implicit dual time-stepping positivity-preserving entropy-stable schemes for the compressible Navier-Stokes equations</title>
      <link>https://arxiv.org/abs/2504.11333</link>
      <description>arXiv:2504.11333v2 Announce Type: replace 
Abstract: We generalize the explicit high-order positivity-preserving entropy-stable spectral collocation schemes developed in [30, 34] for the three-dimensional (3D) compressible Navier Stokes equations to a time implicit formulation. The time derivative terms are discretized by using the first- and second-order implicit backward difference formulas (BDF1 and BDF2) that are well suited for solving steady-state and time-dependent viscous flows at high Reynolds numbers, respectively. The nonlinear system of discrete equations at each physical timestep is solved by using a dual time-stepping technique. The proposed scheme is provably entropy-stable and positivity-preserving and provides unconditional stability properties in the physical time. Numerical results demonstrating accuracy and positivity-preserving properties of the new dual time-stepping scheme are presented for supersonic viscous flows with strong shock waves and contact discontinuities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.11333v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohammed Sayyari, Nail K. Yamaleev</dc:creator>
    </item>
    <item>
      <title>Arbitrary High-Order Maximum Principle-Preserving and Energy Dissipating Schemes for Gradient Flows</title>
      <link>https://arxiv.org/abs/2506.12402</link>
      <description>arXiv:2506.12402v3 Announce Type: replace 
Abstract: For gradient flows, the existing structure-preserving schemes are difficult to achieve arbitrary high-order accuracy in time while preserving maximum-principle (MBP) and energy dissipating simultaneously. In this paper, we develop a new framework for constructing structure-preserving schemes which shall preserve those nice properties. By introducing KKT-conditions for energy dissipating and bound-preserving, we rewrite the original gradient flow into an expanded and coupled system. We shall utilize a novel predictor-corrector-corrector framework, termed the PCC method, which consists of a prediction from any numerical scheme to the user's favor, followed by two correction steps designed to enforce energy stability and MBP, respectively. We take the exponential time differencing Runge-Kutta scheme (ETDRK) as an example and establish the unique solvability and robust error analysis for our new framework. Extensive numerical experiments are provided to validate the efficiency and accuracy of our new approach. Enough numerical comparisons with the existing popular schemes are shown that our structure-preserving schemes can avoid numerical oscillations and capture the exact evolution of energy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.12402v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qing Cheng, Tingfeng Wang, Xiaofei Zhao</dc:creator>
    </item>
    <item>
      <title>$\textit{A Priori}$ Error Analysis for the $p$-Stokes Equations with Slip Boundary Conditions: A Discrete Leray Projection Framework</title>
      <link>https://arxiv.org/abs/2507.15016</link>
      <description>arXiv:2507.15016v2 Announce Type: replace 
Abstract: We present an $\textit{a priori}$ error analysis for the kinematic pressure in a fully-discrete finite-differences/-elements discretization of the unsteady $p$-Stokes equations, modelling non-Newtonian fluids. This system is subject to both impermeability and perfect Navier slip boundary conditions, which are incorporated either weakly via Lagrange multipliers or strongly in the discrete velocity space. A central aspect of the $\textit{a priori}$ error analysis is the discrete Leray projection, constructed to quantitatively approximate its continuous counterpart. The discrete Leray projection enables a Helmholtz-type decomposition at the discrete level and plays a key role in deriving error decay rates for the kinematic pressure. We derive (in some cases optimal) error decay rates for both the velocity vector field and kinematic pressure, with the error for the kinematic pressure measured in an $\textit{ad hoc}$ norm informed by the projection framework. The $\textit{a priori}$ error analysis remains robust even under reduced regularity of the velocity vector field and the kinematic pressure, and illustrates how the interplay of boundary conditions and projection stability governs the accuracy of pressure approximations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.15016v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alex Kaltenbach, J\"orn Wichmann</dc:creator>
    </item>
    <item>
      <title>Best weighted approximation of some kernels on the real axis</title>
      <link>https://arxiv.org/abs/2509.23890</link>
      <description>arXiv:2509.23890v2 Announce Type: replace 
Abstract: We calculate the exact value and find the polynomial of the best weighted polynomial approximation of kernels of the form $\frac {A+Bt}{(t^2+\lambda^2)^{s+1}}$, where $A$ and $B$ are fixed complex numbers, $\lambda&gt;0$, $s\in {\mathbb N}$, in the mean square metric.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.23890v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.CA</category>
      <category>math.OC</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stanislav Chaichenko, Viktor Savchuk, Andrii Shidlich</dc:creator>
    </item>
    <item>
      <title>Universal $L_2$-approximation using median lattice algorithms</title>
      <link>https://arxiv.org/abs/2509.24582</link>
      <description>arXiv:2509.24582v2 Announce Type: replace 
Abstract: We study the problem of multivariate $L_2$-approximation of functions in a weighted Korobov space using a median lattice-based algorithm recently proposed by the authors. In the original work, the algorithm requires knowledge of the smoothness and weights of the Korobov space to construct the hyperbolic cross index set, where each coefficient is estimated via the median of approximations obtained from randomly shifted, randomly chosen rank-1 lattice rules. In this paper, we introduce a \emph{universal median lattice-based algorithm}, which eliminates the need for any prior information on smoothness and weights. Although the tractability property of the algorithm slightly deteriorates, we prove that, for individual functions in the Korobov space with arbitrary smoothness and (downward-closed) weights, it achieves an $L_2$-approximation error arbitrarily close to the optimal rate with respect to the number of function evaluations. Numerical experiments are conducted to support our theoretical claim.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24582v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zexin Pan, Takashi Goda, Peter Kritzer</dc:creator>
    </item>
    <item>
      <title>Sharp Lower Bounds for Linearized ReLU^k Approximation on the Sphere</title>
      <link>https://arxiv.org/abs/2510.04060</link>
      <description>arXiv:2510.04060v2 Announce Type: replace 
Abstract: We prove a saturation theorem for linearized shallow ReLU$^k$ neural networks on the unit sphere $\mathbb S^d$. For any antipodally quasi-uniform set of centers, if the target function has smoothness $r&gt;\tfrac{d+2k+1}{2}$, then the best $\mathcal{L}^2(\mathbb S^d)$ approximation cannot converge faster than order $n^{-\frac{d+2k+1}{2d}}$. This lower bound matches existing upper bounds, thereby establishing the exact saturation order $\tfrac{d+2k+1}{2d}$ for such networks. Our results place linearized neural-network approximation firmly within the classical saturation framework and show that, although ReLU$^k$ networks outperform finite elements under equal degrees $k$, this advantage is intrinsically limited.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.04060v2</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tong Mao, Jinchao Xu</dc:creator>
    </item>
    <item>
      <title>On the maximum bound principle and energy dissipation of exponential time differencing methods for the chiral liquid crystal blue phases</title>
      <link>https://arxiv.org/abs/2510.12499</link>
      <description>arXiv:2510.12499v2 Announce Type: replace 
Abstract: The blue phases are fascinating and complex states of chiral liquid crystals which can be modeled by a comprehensive framework of the Landau-de theory, satisfying energy dissipation and maximum bound principle.
  In this paper, we develop and analyze first and second order exponential time differencing numerical schemes for the gradient flow of the chiral liquid crystal blue phases, which preserve the maximum bound principle and energy dissipation unconditionally at the semi-discrete level.
  The fully discrete schemes are obtained coupled with the Fourier spectral method in space.
  And we propose a novel matrix-form Helmholtz basis transformation method to diagonalize the combined operator of the Laplacian and the curl operator, which is a key step in the implementation of the proposed schemes.
  Then by constructing auxiliary functions, we drive the $L^\infty$ boundedness of the numerical solutions and obtain the energy dissipation and the error estimates in $L^2$ and $L^\infty$ norm.
  Various numerical experiments are presented to validate the theoretical results and demonstrate the effectiveness of the proposed methods in simulating the dynamics of blue phases in chiral liquid crystals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.12499v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenshuai Hu, Guanghua Ji</dc:creator>
    </item>
    <item>
      <title>3-Dimensional Adaptive Unstructured Tessellated Look-up Tables for the Approximation of Compton Form Factors</title>
      <link>https://arxiv.org/abs/2510.25699</link>
      <description>arXiv:2510.25699v2 Announce Type: replace 
Abstract: We describe an iterative algorithm to construct an unstructured tessellation of simplices (irregular tetrahedra in 3-dimensions) to approximate an arbitrary function to a desired precision by interpolation. The method is applied to the generation of Compton Form Factors for simulation and analysis of nuclear femtography, as enabled by high energy exclusive processes such as electron-proton scattering producing just an electron, proton, and gamma-ray in the final state. While producing tessellations with only a 1% mean interpolation error, our results show that the use of such tessellations can significantly decrease the computation time for Monte Carlo event generation by $\sim23$ times for $10^{7}$ events (and using extrapolation, by $\sim955$ times for $10^{10}$ events).</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25699v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Charles Hyde, Mitch Kerver, Christos Tsolakis, Polykarpos Thomadakis, Spiros Tsalikis, Kevin Garner, Angelos Angelopoulos, Wirawan Purwanto, Gagik Gavalian, Christian Weiss, Nikos Chrisochoides</dc:creator>
    </item>
    <item>
      <title>The evolving surface morphochemical reaction-diffusion system for battery modeling</title>
      <link>https://arxiv.org/abs/2510.26437</link>
      <description>arXiv:2510.26437v2 Announce Type: replace 
Abstract: It is well known that phase formation by electrodeposition yields films of poorly controllable morphology. This typically leads to a range of technological issues in many fields of electrochemical technology. Presently, a particularly relevant case is that of high-energy density next-generation batteries with metal anodes, that cannot yet reach practical cyclability targets, owing to uncontrolled elelctrode shape evolution. In this scenario, mathematical modelling is a key tool to lay the knowledge-base for materials-science advancements liable to lead to concretely stable battery material architectures. In this work, we introduce the Evolving Surface DIB (ESDIB) model, a reaction-diffusion system posed on a dynamically evolving electrode surface. Unlike previous fixed-surface formulations, the ESDIB model couples surface evolution to the local concentration of electrochemical species, allowing the geometry of the electrode itself to adapt in response to deposition. To handle the challenges related to the coupling between surface motion and species transport, we numerically solve the system by proposing an extension of the Lumped Evolving Surface Finite Element Method (LESFEM) for spatial discretisation, combined with an IMEX Euler scheme for time integration. The model is validated through six numerical experiments, each compared with laboratory images of electrodeposition. Results demonstrate that the ESDIB framework accurately captures branching and dendritic growth, providing a predictive and physically consistent tool for studying metal deposition phenomena in energy storage devices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.26437v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Benedetto Bozzini, Massimo Frittelli, Anotida Madzvamuse, Ivonne Sgura</dc:creator>
    </item>
    <item>
      <title>A monotone finite element method for an elliptic distributed optimal control problem with a convection-dominated state equation</title>
      <link>https://arxiv.org/abs/2510.27167</link>
      <description>arXiv:2510.27167v2 Announce Type: replace 
Abstract: We propose and analyze a monotone finite element method for an elliptic distributed optimal control problem constrained by a convection-diffusion-reaction equation in the convection-dominated regime. The method is based on the edge-averaged finite element (EAFE) scheme, which is known to preserve the discrete maximum principle for convection-diffusion problems. We show that the EAFE discretization inherits the monotonicity property of the continuous problem and consequently preserves the desired-state bounds at the discrete level, ensuring that the numerical optimal state remains stable and free of nonphysical oscillations. The discrete formulation is analyzed using a combination of the EAFE consistency result and a discrete inf-sup condition, which together guarantee well-posedness and yield the optimal convergence order. Comprehensive numerical experiments are presented to confirm the theoretical findings and to demonstrate the robustness of the proposed scheme in the convection-dominated regimes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.27167v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>SeongHee Jeong, Seulip Lee, Sijing Liu</dc:creator>
    </item>
    <item>
      <title>What Can One Expect When Solving PDEs Using Shallow Neural Networks?</title>
      <link>https://arxiv.org/abs/2510.27658</link>
      <description>arXiv:2510.27658v2 Announce Type: replace 
Abstract: We use elliptic partial differential equations (PDEs) as examples to show various properties and behaviors when shallow neural networks (SNNs) are used to represent the solutions. In particular, we study the numerical ill-conditioning, frequency bias, and the balance between the differential operator and the shallow network representation for different formulations of the PDEs and with various activation functions. Our study shows that the performance of Physics-Informed Neural Networks (PINNs) or Deep Ritz Method (DRM) using linear SNNs with power ReLU activation is dominated by their inherent ill-conditioning and spectral bias against high frequencies. Although this can be alleviated by using non-homogeneous activation functions with proper scaling, achieving such adaptivity for nonlinear SNNs remains costly due to ill-conditioning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.27658v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Roy Y. He, Ying Liang, Hongkai Zhao, Yimin Zhong</dc:creator>
    </item>
    <item>
      <title>Inducing Riesz and orthonormal bases in $L^2$ via composition operators</title>
      <link>https://arxiv.org/abs/2406.18613</link>
      <description>arXiv:2406.18613v3 Announce Type: replace-cross 
Abstract: Let $C_h$ be a composition operator mapping $L^2(\Omega_1)$ into $L^2(\Omega_2)$ for some open sets $\Omega_1, \Omega_2 \subseteq \mathbb{R}^n$. We characterize the mappings $h$ that transform Riesz bases of $L^2(\Omega_1)$ into Riesz bases of $L^2(\Omega_2)$. Restricting our analysis to differentiable mappings, we demonstrate that mappings $h$ that preserve Riesz bases have Jacobian determinants that are bounded away from zero and infinity. We discuss implications of these results for approximation theory, highlighting the potential of using bijective neural networks to construct Riesz bases with favorable approximation properties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.18613v3</guid>
      <category>math.FA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yahya Saleh, Armin Iske</dc:creator>
    </item>
    <item>
      <title>On a nonlinear nonlocal reaction-diffusion system applied to image restoration</title>
      <link>https://arxiv.org/abs/2407.04347</link>
      <description>arXiv:2407.04347v2 Announce Type: replace-cross 
Abstract: This paper deals with a novel nonlinear coupled nonlocal reaction-diffusion system proposed for image restoration, characterized by the advantages of preserving low gray level features and textures.The gray level indicator in the proposed model is regularized using a new method based on porous media type equations, which is suitable for recovering noisy blurred images. The well-posedness, regularity, and other properties of the model are investigated, addressing the lack of theoretical analysis in those existing similar types of models. Numerical experiments conducted on texture and satellite images demonstrate the effectiveness of the proposed model in denoising and deblurring tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04347v2</guid>
      <category>math.AP</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuhang Li, Zhichang Guo, Jingfeng Shao, Boying Wu</dc:creator>
    </item>
    <item>
      <title>Strong convergence and Mittag-Leffler stability of stochastic theta method for time-changed stochastic differential equations</title>
      <link>https://arxiv.org/abs/2503.21653</link>
      <description>arXiv:2503.21653v3 Announce Type: replace-cross 
Abstract: We propose the first $\alpha$-parameterized framework for solving time-changed stochastic differential equations (TCSDEs), explicitly linking convergence rates to the driving parameter of the underlying stochastic processes. Theoretically, we derive exact moment estimates and exponential moment estimates of inverse $\alpha$-stable subordinator $E$ using Mittag-Leffler functions. The stochastic theta (ST) method is investigated for a class of SDEs driven by a time-changed Brownian motion, whose coefficients are time-space-dependent and satisfy the local Lipschitz condition. We prove that the convergence order dynamically responds to the stability index $\alpha$ of stable subordinator $D$, filling a gap in traditional methods that treat these factors independently. We also introduce the notion of Mittag-Leffler stability for TCSDEs, and investigate the criterion of Mittag-Leffler stability for both the exact and numerical solutions. Finally, some numerical simulations are presented to illustrate the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.21653v3</guid>
      <category>math.PR</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jingwei Chen, Jun Ye, Jinwen Chen, Zhidong Wang</dc:creator>
    </item>
    <item>
      <title>Automotive Crash Dynamics Modeling Accelerated with Machine Learning</title>
      <link>https://arxiv.org/abs/2510.15201</link>
      <description>arXiv:2510.15201v3 Announce Type: replace-cross 
Abstract: Crashworthiness assessment is a critical aspect of automotive design, traditionally relying on high-fidelity finite element (FE) simulations that are computationally expensive and time-consuming. This work presents an exploratory comparative study on developing machine learning-based surrogate models for efficient prediction of structural deformation in crash scenarios using the NVIDIA PhysicsNeMo framework. Given the limited prior work applying machine learning to structural crash dynamics, the primary contribution lies in demonstrating the feasibility and engineering utility of the various modeling approaches explored in this work. We investigate two state-of-the-art neural network architectures for modeling crash dynamics: MeshGraphNet, and Transolver. Additionally, we examine three strategies for modeling transient dynamics: time-conditional, the standard Autoregressive approach, and a stability-enhanced Autoregressive scheme incorporating rollout-based training. The models are evaluated on a comprehensive Body-in-White (BIW) crash dataset comprising 150 detailed FE simulations using LS-DYNA. The dataset represents a structurally rich vehicle assembly with over 200 components, including 38 key components featuring variable thickness distributions to capture realistic manufacturing variability. Each model utilizes the undeformed mesh geometry and component characteristics as inputs to predict the spatiotemporal evolution of the deformed mesh during the crash sequence. Evaluation results show that the models capture the overall deformation trends with reasonable fidelity, demonstrating the feasibility of applying machine learning to structural crash dynamics. Although not yet matching full FE accuracy, the models achieve orders-of-magnitude reductions in computational cost, enabling rapid design exploration and early-stage optimization in crashworthiness evaluation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.15201v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.app-ph</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohammad Amin Nabian, Sudeep Chavare, Deepak Akhare, Rishikesh Ranade, Ram Cherukuri, Srinivas Tadepalli</dc:creator>
    </item>
    <item>
      <title>Model-Adaptive Simulation of Hierarchical Shallow Water Moment Equations in One Dimension</title>
      <link>https://arxiv.org/abs/2510.25351</link>
      <description>arXiv:2510.25351v2 Announce Type: replace-cross 
Abstract: Shallow free surface flows are often characterized by both subdomains that require high modeling complexity and subdomains that can be sufficiently accurately modeled with low modeling complexity. Moreover, these subdomains may change in time as the water flows through the domain. This motivates the need for space and time adaptivity in the simulation of shallow free surface flows. In this paper, we develop the first adaptive simulations using the recently developed Shallow Water Moment Equations, which are an extension of the standard Shallow Water Equations that allow for vertically changing velocity profiles by including additional variables and equations. The model-specific modeling complexity of a shallow water moment model is determined by its order. The higher the order of the model, the more variables and equations are included in the model. Shallow water moment models are ideally suited for adaptivity because they are hierarchical such that low-order models and high-order models share the same structure. To enable adaptive simulations, we propose two approaches for the coupling of the varying-order shallow water moment equations at their boundary interfaces. The first approach dynamically updates padded state variables but cannot be written in conservative form, while the second approach uses fixed padded state variable values of zero and reduces to conservative form for conservative moment equations. The switching procedure between high-order models and low-order models is based on a new set of model error estimators, originating from a decomposition of the high-order models. Numerical results of the collision of a dam-break wave with a smooth wave yield accurate results, while achieving speedups up to 60 percent compared to a non-adaptive model with fixed modeling complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25351v2</guid>
      <category>physics.flu-dyn</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Rik Verbiest, Julian Koellermeier</dc:creator>
    </item>
  </channel>
</rss>
