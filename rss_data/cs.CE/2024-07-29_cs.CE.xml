<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CE</link>
    <description>cs.CE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 29 Jul 2024 04:01:40 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 29 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Agent-Based Insight into Eco-Choices: Simulating the Fast Fashion Shift</title>
      <link>https://arxiv.org/abs/2407.18814</link>
      <description>arXiv:2407.18814v1 Announce Type: new 
Abstract: Fashion is a powerful force in the modern world. It is one of the most accessible means of self-expression, thereby playing a significant role in our society. Yet, it is plagued by well-documented issues of waste and human rights abuses. Fast fashion in particular, characterized by its disposable nature, contributes extensively to environmental degradation and CO$_2$ emissions, surpassing the combined outputs of France, Germany, and the UK, but its economic contributions have somewhat shielded it from criticism. In this paper, we examine the demand for fast fashion, with a focus on Spain. We explore the individual decision-making process involved in choosing to buy fast fashion and the role of awareness regarding working conditions, environmental consequences, and education on sustainable fashion in influencing consumer behavior. By employing Agent-Based Modeling, we investigate the factors influencing garment consumption patterns and how shifts in public opinion can be achieved through peer pressure, social media influence, and government interventions. Our study revealed that government interventions are pivotal, with the state's campaigns setting the overall tone for progress, although its success is conditioned by social media and polarization levels of the population. Importantly, the state does not need to adopt an extremely proactive stance or continue the campaigns indefinitely to achieve optimal results, as excessive interventions yield diminishing returns.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18814v1</guid>
      <category>cs.CE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daria Soboleva, Angel S\'anchez</dc:creator>
    </item>
    <item>
      <title>Efficient computational homogenization via tensor train format</title>
      <link>https://arxiv.org/abs/2407.18870</link>
      <description>arXiv:2407.18870v1 Announce Type: new 
Abstract: Real-world physical systems, like composite materials and porous media, exhibit complex heterogeneities and multiscale nature, posing significant computational challenges. Computational homogenization is useful for predicting macroscopic properties from the microscopic material constitution. It involves defining a representative volume element (RVE), solving governing equations, and evaluating its properties such as conductivity and elasticity. Despite its effectiveness, the approach can be computationally expensive. This study proposes a tensor-train (TT)-based asymptotic homogenization method to address these challenges. By deriving boundary value problems at the microscale and expressing them in the TT format, the proposed method estimates material properties efficiently. We demonstrate its validity and effectiveness through numerical experiments applying the proposed method for homogenization of thermal conductivity and elasticity in two- and three-dimensional materials, offering a promising solution for handling the multiscale nature of heterogeneous systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18870v1</guid>
      <category>cs.CE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuki Sato, Yuto Lewis Terashima, Ruho Kondo</dc:creator>
    </item>
    <item>
      <title>Using high-fidelity discrete element simulation to calibrate an expeditious terramechanics model in a multibody dynamics framework</title>
      <link>https://arxiv.org/abs/2407.18903</link>
      <description>arXiv:2407.18903v1 Announce Type: new 
Abstract: The wheel-soil interaction has great impact on the dynamics of off-road vehicles in terramechanics applications. The Soil Contact Model (SCM), which anchors an empirical method to characterize the frictional contact between a wheel and soil, has been widely used in off-road vehicle dynamics simulations because it quickly produces adequate results for many terramechanics applications. The SCM approach calls for a set of model parameters that are obtained via a bevameter test. This test is expensive and time consuming to carry out, and in some cases difficult to set up, e.g., in extraterrestrial applications. We propose an approach to address these concerns by conducting the bevameter test in simulation, using a model that captures the physics of the actual experiment with high fidelity. To that end, we model the bevameter test rig as a multibody system, while the dynamics of the soil is captured using a discrete element model (DEM). The multibody dynamics--soil dynamics co-simulation is used to replicate the bevameter test, producing high-fidelity ground truth test data that is subsequently used to calibrate the SCM parameters within a Bayesian inference framework. To test the accuracy of the resulting SCM terramechanics, we run single wheel and full rover simulations using both DEM and SCM terrains. The SCM results match well with those produced by the DEM solution, and the simulation time for SCM is two to three orders of magnitude lower than that of DEM. All simulations in this work are performed using Chrono, an open-source, publicly available simulator. The scripts and models used are available in a public repository for reproducibility studies and further research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18903v1</guid>
      <category>cs.CE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuemin Zhang, Junpeng Dai, Wei Hu, Dan Negrut</dc:creator>
    </item>
    <item>
      <title>The Structure of Financial Equity Research Reports -- Identification of the Most Frequently Asked Questions in Financial Analyst Reports to Automate Equity Research Using Llama 3 and GPT-4</title>
      <link>https://arxiv.org/abs/2407.18327</link>
      <description>arXiv:2407.18327v1 Announce Type: cross 
Abstract: This research dissects financial equity research reports (ERRs) by mapping their content into categories.
  There is insufficient empirical analysis of the questions answered in ERRs. In particular, it is not understood how frequently certain information appears, what information is considered essential, and what information requires human judgment to distill into an ERR.
  The study analyzes 72 ERRs sentence-by-sentence, classifying their 4940 sentences into 169 unique question archetypes. We did not predefine the questions but derived them solely from the statements in the ERRs. This approach provides an unbiased view of the content of the observed ERRs. Subsequently, we used public corporate reports to classify the questions' potential for automation. Answers were labeled "text-extractable" if the answers to the question were accessible in corporate reports.
  78.7% of the questions in ERRs can be automated. Those automatable question consist of 48.2% text-extractable (suited to processing by large language models, LLMs) and 30.5% database-extractable questions. Only 21.3% of questions require human judgment to answer.
  We empirically validate using Llama-3-70B and GPT-4-turbo-2024-04-09 that recent advances in language generation and information extraction enable the automation of approximately 80% of the statements in ERRs. Surprisingly, the models complement each other's strengths and weaknesses well.
  The research confirms that the current writing process of ERRs can likely benefit from additional automation, improving quality and efficiency. The research thus allows us to quantify the potential impacts of introducing large language models in the ERR writing process.
  The full question list, including the archetypes and their frequency, will be made available online after peer review.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18327v1</guid>
      <category>cs.CY</category>
      <category>cs.CE</category>
      <category>cs.IR</category>
      <category>q-fin.CP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Adria Pop, Jan Sp\"orer, Siegfried Handschuh</dc:creator>
    </item>
    <item>
      <title>Dihedral Angle Adherence: Evaluating Protein Structure Predictions in the Absence of Experimental Data</title>
      <link>https://arxiv.org/abs/2407.18336</link>
      <description>arXiv:2407.18336v1 Announce Type: cross 
Abstract: Determining the 3D structures of proteins is essential in understanding their behavior in the cellular environment. Computational methods of predicting protein structures have advanced, but assessing prediction accuracy remains a challenge. The traditional method, RMSD, relies on experimentally determined structures and lacks insight into improvement areas of predictions. We propose an alternative: analyzing dihedral angles, bypassing the need for the reference structure of an evaluated protein. Our method segments proteins into amino acid subsequences and searches for matches, comparing dihedral angles across numerous proteins to compute a metric using Mahalanobis distance. Evaluated on many predictions, our approach correlates with RMSD and identifies areas for prediction enhancement. This method offers a promising route for accurate protein structure prediction assessment and improvement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18336v1</guid>
      <category>q-bio.BM</category>
      <category>cs.CE</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Musa Azeem, Homayoun Valafar</dc:creator>
    </item>
    <item>
      <title>Graph Neural Networks for Virtual Sensing in Complex Systems: Addressing Heterogeneous Temporal Dynamics</title>
      <link>https://arxiv.org/abs/2407.18691</link>
      <description>arXiv:2407.18691v1 Announce Type: cross 
Abstract: Real-time condition monitoring is crucial for the reliable and efficient operation of complex systems. However, relying solely on physical sensors can be limited due to their cost, placement constraints, or inability to directly measure certain critical parameters. Virtual sensing addresses these limitations by leveraging readily available sensor data and system knowledge to estimate inaccessible parameters or infer system states. The increasing complexity of industrial systems necessitates deployments of sensors with diverse modalities to provide a comprehensive understanding of system states. These sensors capture data at varying frequencies to monitor both rapid and slowly varying system dynamics, as well as local and global state evolutions of the systems. This leads to heterogeneous temporal dynamics, which, particularly under varying operational end environmental conditions, pose a significant challenge for accurate virtual sensing. To address this, we propose a Heterogeneous Temporal Graph Neural Network (HTGNN) framework. HTGNN explicitly models signals from diverse sensors and integrates operating conditions into the model architecture. We evaluate HTGNN using two newly released datasets: a bearing dataset with diverse load conditions for bearing load prediction and a year-long simulated dataset for predicting bridge live loads. Our results demonstrate that HTGNN significantly outperforms established baseline methods in both tasks, particularly under highly varying operating conditions. These results highlight HTGNN's potential as a robust and accurate virtual sensing approach for complex systems, paving the way for improved monitoring, predictive maintenance, and enhanced system performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18691v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mengjie Zhao, Cees Taal, Stephan Baggerohr, Olga Fink</dc:creator>
    </item>
  </channel>
</rss>
