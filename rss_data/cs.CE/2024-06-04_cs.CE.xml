<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CE</link>
    <description>cs.CE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 05 Jun 2024 01:55:23 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 04 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Topology optimization of contact-aided thermo-mechanical regulators</title>
      <link>https://arxiv.org/abs/2406.00865</link>
      <description>arXiv:2406.00865v1 Announce Type: new 
Abstract: Topology optimization is used to systematically design contact-aided thermo-mechanical regulators, i.e. components whose effective thermal conductivity is tunable by mechanical deformation and contact. The thermo-mechanical interactions are modeled using a fully coupled non-linear thermo-mechanical finite element framework. To obtain the intricate heat transfer response, the components leverage self-contact, which is modeled using a third medium contact method. The effective heat transfer properties of the regulators are tuned by solving a topology optimization problem using a traditional gradient based algorithm. Several designs of thermo-mechanical regulators in the form of switches, diodes and triodes are presented.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00865v1</guid>
      <category>cs.CE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anna Dalklint, Joe Alexandersen, Andreas Henrik Frederiksen, Konstantinos Poulios, Ole Sigmund</dc:creator>
    </item>
    <item>
      <title>Statistical analysis of geoinformation data for increasing railway safety</title>
      <link>https://arxiv.org/abs/2406.01083</link>
      <description>arXiv:2406.01083v1 Announce Type: new 
Abstract: The impact of rail transport on the environment is one of the crucial factors for the sustainable development of this form of mass transport. We present a data-driven analysis of wild animal railway accidents in the region of southern Poland, a step to create the train driver warning system. We built our method by harnessing the Bayesian approach to the statistical analysis of information about the geolocation of the accidents. The implementation of the proposed a model does not require advanced knowledge of data mining and can be applied even in less developed railway systems with small IT support. Furthermore, we have discovered unusual patterns of accidents while considering the number of trains and their speed and time at particular geographical location of the railway network. We test the developed approach using data from southern Poland, compromising wildlife habitats and one of the most urbanised regions in Central Europe.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01083v1</guid>
      <category>cs.CE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Katarzyna Gawlak, Jaros{\l}aw Konieczny, Krzysztof Domino, Jaros{\l}aw Adam Miszczak</dc:creator>
    </item>
    <item>
      <title>A Theoretical Framework for an Efficient Normalizing Flow-Based Solution to the Schrodinger Equation</title>
      <link>https://arxiv.org/abs/2406.00047</link>
      <description>arXiv:2406.00047v1 Announce Type: cross 
Abstract: A central problem in quantum mechanics involves solving the Electronic Schrodinger Equation for a molecule or material. The Variational Monte Carlo approach to this problem approximates a particular variational objective via sampling, and then optimizes this approximated objective over a chosen parameterized family of wavefunctions, known as the ansatz. Recently neural networks have been used as the ansatz, with accompanying success. However, sampling from such wavefunctions has required the use of a Markov Chain Monte Carlo approach, which is inherently inefficient. In this work, we propose a solution to this problem via an ansatz which is cheap to sample from, yet satisfies the requisite quantum mechanical properties. We prove that a normalizing flow using the following two essential ingredients satisfies our requirements: (a) a base distribution which is constructed from Determinantal Point Processes; (b) flow layers which are equivariant to a particular subgroup of the permutation group. We then show how to construct both continuous and discrete normalizing flows which satisfy the requisite equivariance. We further demonstrate the manner in which the non-smooth nature ("cusps") of the wavefunction may be captured, and how the framework may be generalized to provide induction across multiple molecules. The resulting theoretical framework entails an efficient approach to solving the Electronic Schrodinger Equation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00047v1</guid>
      <category>physics.chem-ph</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>physics.comp-ph</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniel Freedman, Eyal Rozenberg, Alex Bronstein</dc:creator>
    </item>
    <item>
      <title>From Structured to Unstructured:A Comparative Analysis of Computer Vision and Graph Models in solving Mesh-based PDEs</title>
      <link>https://arxiv.org/abs/2406.00081</link>
      <description>arXiv:2406.00081v1 Announce Type: cross 
Abstract: This article investigates the application of computer vision and graph-based models in solving mesh-based partial differential equations within high-performance computing environments. Focusing on structured, graded structured, and unstructured meshes, the study compares the performance and computational efficiency of three computer vision-based models against three graph-based models across three data\-sets. The research aims to identify the most suitable models for different mesh topographies, particularly highlighting the exploration of graded meshes, a less studied area. Results demonstrate that computer vision-based models, notably U-Net, outperform the graph models in prediction performance and efficiency in two (structured and graded) out of three mesh topographies. The study also reveals the unexpected effectiveness of computer vision-based models in handling unstructured meshes, suggesting a potential shift in methodological approaches for data-driven partial differential equation learning. The article underscores deep learning as a viable and potentially sustainable way to enhance traditional high-performance computing methods, advocating for informed model selection based on the topography of the mesh.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00081v1</guid>
      <category>cs.LG</category>
      <category>cs.CE</category>
      <category>cs.CV</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jens Decke, Olaf W\"unsch, Bernhard Sick, Christian Gruhl</dc:creator>
    </item>
    <item>
      <title>Non-destructive Degradation Pattern Decoupling for Ultra-early Battery Prototype Verification Using Physics-informed Machine Learning</title>
      <link>https://arxiv.org/abs/2406.00276</link>
      <description>arXiv:2406.00276v1 Announce Type: cross 
Abstract: Manufacturing complexities and uncertainties have impeded the transition from material prototypes to commercial batteries, making prototype verification critical to quality assessment. A fundamental challenge involves deciphering intertwined chemical processes to characterize degradation patterns and their quantitative relationship with battery performance. Here we show that a physics-informed machine learning approach can quantify and visualize temporally resolved losses concerning thermodynamics and kinetics only using electric signals. Our method enables non-destructive degradation pattern characterization, expediting temperature-adaptable predictions of entire lifetime trajectories, rather than end-of-life points. The verification speed is 25 times faster yet maintaining 95.1% accuracy across temperatures. Such advances facilitate more sustainable management of defective prototypes before massive production, establishing a 19.76 billion USD scrap material recycling market by 2060 in China. By incorporating stepwise charge acceptance as a measure of the initial manufacturing variability of normally identical batteries, we can immediately identify long-term degradation variations. We attribute the predictive power to interpreting machine learning insights using material-agnostic featurization taxonomy for degradation pattern decoupling. Our findings offer new possibilities for dynamic system analysis, such as battery prototype degradation, demonstrating that complex pattern evolutions can be accurately predicted in a non-destructive and data-driven fashion by integrating physics-informed machine learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00276v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>physics.data-an</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shengyu Tao, Mengtian Zhang, Zixi Zhao, Haoyang Li, Ruifei Ma, Yunhong Che, Xin Sun, Lin Su, Xiangyu Chen, Zihao Zhou, Heng Chang, Tingwei Cao, Xiao Xiao, Yaojun Liu, Wenjun Yu, Zhongling Xu, Yang Li, Han Hao, Xuan Zhang, Xiaosong Hu, Guangmin ZHou</dc:creator>
    </item>
    <item>
      <title>RoBERTa-BiLSTM: A Context-Aware Hybrid Model for Sentiment Analysis</title>
      <link>https://arxiv.org/abs/2406.00367</link>
      <description>arXiv:2406.00367v1 Announce Type: cross 
Abstract: Effectively analyzing the comments to uncover latent intentions holds immense value in making strategic decisions across various domains. However, several challenges hinder the process of sentiment analysis including the lexical diversity exhibited in comments, the presence of long dependencies within the text, encountering unknown symbols and words, and dealing with imbalanced datasets. Moreover, existing sentiment analysis tasks mostly leveraged sequential models to encode the long dependent texts and it requires longer execution time as it processes the text sequentially. In contrast, the Transformer requires less execution time due to its parallel processing nature. In this work, we introduce a novel hybrid deep learning model, RoBERTa-BiLSTM, which combines the Robustly Optimized BERT Pretraining Approach (RoBERTa) with Bidirectional Long Short-Term Memory (BiLSTM) networks. RoBERTa is utilized to generate meaningful word embedding vectors, while BiLSTM effectively captures the contextual semantics of long-dependent texts. The RoBERTa-BiLSTM hybrid model leverages the strengths of both sequential and Transformer models to enhance performance in sentiment analysis. We conducted experiments using datasets from IMDb, Twitter US Airline, and Sentiment140 to evaluate the proposed model against existing state-of-the-art methods. Our experimental findings demonstrate that the RoBERTa-BiLSTM model surpasses baseline models (e.g., BERT, RoBERTa-base, RoBERTa-GRU, and RoBERTa-LSTM), achieving accuracies of 80.74%, 92.36%, and 82.25% on the Twitter US Airline, IMDb, and Sentiment140 datasets, respectively. Additionally, the model achieves F1-scores of 80.73%, 92.35%, and 82.25% on the same datasets, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00367v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Md. Mostafizer Rahman, Ariful Islam Shiplu, Yutaka Watanobe, Md. Ashad Alam</dc:creator>
    </item>
    <item>
      <title>Scaffold Splits Overestimate Virtual Screening Performance</title>
      <link>https://arxiv.org/abs/2406.00873</link>
      <description>arXiv:2406.00873v1 Announce Type: cross 
Abstract: Virtual Screening (VS) of vast compound libraries guided by Artificial Intelligence (AI) models is a highly productive approach to early drug discovery. Data splitting is crucial for the reliable benchmarking of such AI models. Traditional random data splits produce similar molecules between training and test sets, conflicting with the reality of VS libraries which mostly contain structurally distinct compounds. Scaffold split, grouping molecules by shared core structure, is widely considered to reflect this real-world scenario. However, here we show that this split also overestimates VS performance. Our study examined three representative AI models on 60 datasets from NCI-60 using scaffold split and a more realistic Uniform Manifold Approximation and Projection (UMAP)-based clustering split. We found models perform substantially worse under UMAP splits. These results highlight the need for improved benchmarks to tune, compare, and select models for VS. Our code is available at https://github.com/ScaffoldSplitsOverestimateVS/Scaffold SplitsOverestimateVS.git</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00873v1</guid>
      <category>q-bio.QM</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>q-bio.BM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Qianrong Guo, Saiveth Hernandez-Hernandez, Pedro J Ballester</dc:creator>
    </item>
    <item>
      <title>Inverse design of photonic surfaces on Inconel via multi-fidelity machine learning ensemble framework and high throughput femtosecond laser processing</title>
      <link>https://arxiv.org/abs/2406.01471</link>
      <description>arXiv:2406.01471v1 Announce Type: cross 
Abstract: We demonstrate a multi-fidelity (MF) machine learning ensemble framework for the inverse design of photonic surfaces, trained on a dataset of 11,759 samples that we fabricate using high throughput femtosecond laser processing. The MF ensemble combines an initial low fidelity model for generating design solutions, with a high fidelity model that refines these solutions through local optimization. The combined MF ensemble can generate multiple disparate sets of laser-processing parameters that can each produce the same target input spectral emissivity with high accuracy (root mean squared errors &lt; 2%). SHapley Additive exPlanations analysis shows transparent model interpretability of the complex relationship between laser parameters and spectral emissivity. Finally, the MF ensemble is experimentally validated by fabricating and evaluating photonic surface designs that it generates for improved efficiency energy harvesting devices. Our approach provides a powerful tool for advancing the inverse design of photonic surfaces in energy harvesting applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01471v1</guid>
      <category>cs.LG</category>
      <category>cs.CE</category>
      <category>physics.optics</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luka Grbcic, Minok Park, Mahmoud Elzouka, Ravi Prasher, Juliane M\"uller, Costas P. Grigoropoulos, Sean D. Lubner, Vassilia Zorba, Wibe Albert de Jong</dc:creator>
    </item>
    <item>
      <title>Efficient Inverse Design Optimization through Multi-fidelity Simulations, Machine Learning, and Search Space Reduction Strategies</title>
      <link>https://arxiv.org/abs/2312.03654</link>
      <description>arXiv:2312.03654v2 Announce Type: replace 
Abstract: This paper introduces a methodology designed to augment the inverse design optimization process in scenarios constrained by limited compute, through the strategic synergy of multi-fidelity evaluations, machine learning models, and optimization algorithms. The proposed methodology is analyzed on two distinct engineering inverse design problems: airfoil inverse design and the scalar field reconstruction problem. It leverages a machine learning model trained with low-fidelity simulation data, in each optimization cycle, thereby proficiently predicting a target variable and discerning whether a high-fidelity simulation is necessitated, which notably conserves computational resources. Additionally, the machine learning model is strategically deployed prior to optimization to compress the design space boundaries, thereby further accelerating convergence toward the optimal solution. The methodology has been employed to enhance two optimization algorithms, namely Differential Evolution and Particle Swarm Optimization. Comparative analyses illustrate performance improvements across both algorithms. Notably, this method is adaptable across any inverse design application, facilitating a synergy between a representative low-fidelity ML model, and high-fidelity simulation, and can be seamlessly applied across any variety of population-based optimization algorithms.}</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.03654v2</guid>
      <category>cs.CE</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luka Grbcic, Juliane M\"uller, Wibe Albert de Jong</dc:creator>
    </item>
    <item>
      <title>Optimal market-neutral currency trading on the cryptocurrency platform</title>
      <link>https://arxiv.org/abs/2405.15461</link>
      <description>arXiv:2405.15461v2 Announce Type: replace 
Abstract: This research proposes a novel arbitrage approach with respect to multivariate pair trading called Optimal Trading Technique (OTT). We introduce the method to selectively form a "bucket" of fiat currencies anchored to cryptocurrency for simultaneously monitoring and exploiting trading opportunities. To handle the quantitative conflicts that arise when receiving multiple trading signals, a bi-objective convex optimization process is designed to cater to the investor's preference between profitability and risk tolerance. This process includes tunable parameters such as volatility punishment, action thresholds. During our experiments in the cryptocurrency market from 2020 to 2022 when the market was experiencing a vigorous bull-run immediately followed by a bear-run, the OTT realized an annualized profit of 15.49%. We further carried out the experiments in bull, bear, and full-cycle market conditions separately, and found that OTT is capable of achieving stable profit under various market conditions. Apart from the profitability side of the OTT, the arbitrage operation provides a new perspective of trading, which requires no external shorting and never hold intermediate cryptocurrency during the arbitrage period.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15461v2</guid>
      <category>cs.CE</category>
      <category>q-fin.MF</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongshen Yang, Avinash Malik</dc:creator>
    </item>
    <item>
      <title>Not feeling the buzz: Correction study of mispricing and inefficiency in online sportsbooks</title>
      <link>https://arxiv.org/abs/2306.01740</link>
      <description>arXiv:2306.01740v3 Announce Type: replace-cross 
Abstract: We present a replication and correction of a recent article (Ramirez, P., Reade, J.J., Singleton, C., Betting on a buzz: Mispricing and inefficiency in online sportsbooks, International Journal of Forecasting, 39:3, 2023, pp. 1413-1423, doi: 10.1016/j.ijforecast.2022.07.011). RRS measure profile page views on Wikipedia to generate a "buzz factor" metric for tennis players and show that it can be used to form a profitable gambling strategy by predicting bookmaker mispricing. Here, we use the same dataset as RRS to reproduce their results exactly, thus confirming the robustness of their mispricing claim. However, we discover that the published betting results are significantly affected by a single bet (the "Hercog" bet), which returns substantial outlier profits based on erroneously long odds. When this data quality issue is resolved, the majority of reported profits disappear and only one strategy, which bets on "competitive" matches, remains significantly profitable in the original out-of-sample period. While one profitable strategy offers weaker support than the original study, it still provides an indication that market inefficiencies may exist, as originally claimed by RRS. As an extension, we continue backtesting after 2020 on a cleaned dataset. Results show that (a) the "competitive" strategy generates no further profits, potentially suggesting markets have become more efficient, and (b) model coefficients estimated over this more recent period are no longer reliable predictors of bookmaker mispricing. We present this work as a case study demonstrating the importance of replication studies in sports forecasting, and the necessity to clean data. We open-source release comprehensive datasets and code.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.01740v3</guid>
      <category>stat.AP</category>
      <category>cs.CE</category>
      <category>q-fin.GN</category>
      <category>q-fin.ST</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lawrence Clegg, John Cartlidge</dc:creator>
    </item>
    <item>
      <title>Incorporating Memory into Propagation of 1-Electron Reduced Density Matrices</title>
      <link>https://arxiv.org/abs/2403.15596</link>
      <description>arXiv:2403.15596v2 Announce Type: replace-cross 
Abstract: For any linear system where the unreduced dynamics are governed by unitary propagators, we derive a closed, time-delayed, linear system for a reduced-dimensional quantity of interest. We apply this method to understand the memory-dependence of $1$-electron reduced density matrices in time-dependent configuration interaction (TDCI), a scheme to solve for the correlated dynamics of electrons in molecules. Though time-dependent density functional theory has established that the $1$-electron reduced density possesses memory-dependence, the precise nature of this memory-dependence has not been understood. We derive a self-contained, symmetry/constraint-preserving method to propagate reduced TDCI electron density matrices. Our method preserves properties of density matrices such as Hermitian symmetry and constant trace. In numerical tests on two model systems ($\text{H}_2$ and $\text{HeH}^+$), we show that with sufficiently large time-delay (or memory-dependence), our method propagates reduced TDCI density matrices with high quantitative accuracy. We study the dependence of our results on time step and basis set. To implement our method, we derive the $4$-index tensor that relates reduced and full TDCI density matrices. Our derivation applies to any TDCI system, regardless of basis set, number of electrons, or choice of Slater determinants in the wave function. This derivation enables a proof that the trace of the reduced TDCI density matrix is constant and equals the number of electrons.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15596v2</guid>
      <category>math.DS</category>
      <category>cs.CE</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>physics.chem-ph</category>
      <category>quant-ph</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Harish S. Bhat, Hardeep Bassi, Karnamohit Ranka, Christine M. Isborn</dc:creator>
    </item>
    <item>
      <title>A finite operator learning technique for mapping the elastic properties of microstructures to their mechanical deformations</title>
      <link>https://arxiv.org/abs/2404.00074</link>
      <description>arXiv:2404.00074v2 Announce Type: replace-cross 
Abstract: To obtain fast solutions for governing physical equations in solid mechanics, we introduce a method that integrates the core ideas of the finite element method with physics-informed neural networks and concept of neural operators. This approach generalizes and enhances each method, learning the parametric solution for mechanical problems without relying on data from other resources (e.g. other numerical solvers). We propose directly utilizing the available discretized weak form in finite element packages to construct the loss functions algebraically, thereby demonstrating the ability to find solutions even in the presence of sharp discontinuities. Our focus is on micromechanics as an example, where knowledge of deformation and stress fields for a given heterogeneous microstructure is crucial for further design applications. The primary parameter under investigation is the Young's modulus distribution within the heterogeneous solid system. Our investigations reveal that physics-based training yields higher accuracy compared to purely data-driven approaches for unseen microstructures. Additionally, we offer two methods to directly improve the process of obtaining high-resolution solutions, avoiding the need to use basic interpolation techniques. First is based on an autoencoder approach to enhance the efficiency for calculation on high resolution grid point. Next, Fourier-based parametrization is utilized to address complex 2D and 3D problems in micromechanics. The latter idea aims to represent complex microstructures efficiently using Fourier coefficients. Comparisons with other well-known operator learning algorithms, further emphasize the advantages of the newly proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00074v2</guid>
      <category>cs.LG</category>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shahed Rezaei, Reza Najian Asl, Shirko Faroughi, Mahdi Asgharzadeh, Ali Harandi, Rasoul Najafi Koopas, Gottfried Laschet, Stefanie Reese, Markus Apel</dc:creator>
    </item>
    <item>
      <title>Impact of Traffic-Following on Order of Autonomous Airspace Operations</title>
      <link>https://arxiv.org/abs/2404.17627</link>
      <description>arXiv:2404.17627v2 Announce Type: replace-cross 
Abstract: In this paper, we investigate the dynamic emergence of traffic order in a distributed multi-agent system, aiming to minimize inefficiencies that stem from unnecessary structural impositions. We introduce a methodology for developing a dynamically-updating traffic pattern map of the airspace by leveraging information about the consistency and frequency of flow directions used by current as well as preceding traffic. Informed by this map, an agent can discern the degree to which it is advantageous to follow traffic by trading off utilities such as time and order. We show that for the traffic levels studied, for low degrees of traffic-following behavior, there is minimal penalty in terms of aircraft travel times while improving the overall orderliness of the airspace. On the other hand, heightened traffic-following behavior may result in increased aircraft travel times, while marginally reducing the overall entropy of the airspace. Ultimately, the methods and metrics presented in this paper can be used to optimally and dynamically adjust an agent's traffic-following behavior based on these trade-offs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17627v2</guid>
      <category>cs.MA</category>
      <category>cs.CE</category>
      <category>cs.ET</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Anahita Jain, Husni R. Idris, John-Paul Clarke</dc:creator>
    </item>
    <item>
      <title>Functional Programming Paradigm of Python for Scientific Computation Pipeline Integration</title>
      <link>https://arxiv.org/abs/2405.16956</link>
      <description>arXiv:2405.16956v2 Announce Type: replace-cross 
Abstract: The advent of modern data processing has led to an increasing tendency towards interdisciplinarity, which frequently involves the importation of different technical approaches. Consequently, there is an urgent need for a unified data control system to facilitate the integration of varying libraries. This integration is of profound significance in accelerating prototype verification, optimising algorithm performance and minimising maintenance costs. This paper presents a novel functional programming (FP) paradigm based on the Python architecture and associated suites in programming practice, designed for the integration of pipelines of different data mapping operations. In particular, the solution is intended for the integration of scientific computation flows, which affords a robust yet flexible solution for the aforementioned challenges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16956v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.PL</category>
      <category>cs.SE</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Chen Zhang, Lecheng Jia, Wei Zhang, Ning Wen</dc:creator>
    </item>
  </channel>
</rss>
