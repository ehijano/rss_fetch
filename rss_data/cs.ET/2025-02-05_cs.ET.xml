<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.ET updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.ET</link>
    <description>cs.ET updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.ET" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 06 Feb 2025 02:49:54 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Exploring Quantum-Enhanced Estimation of Financial Risk Metrics with Quantum RNG</title>
      <link>https://arxiv.org/abs/2502.02125</link>
      <description>arXiv:2502.02125v1 Announce Type: new 
Abstract: In this paper, we present an approach for estimating significant financial metrics within risk management by utilizing quantum phenomena for random number generation. We explore Quantum-Enhanced Monte Carlo, a method that combines traditional and quantum techniques for enhanced precision through Quantum Random Numbers Generation (QRNG). The proposed methods can be based on the use of photonic phenomena or quantum processing units to generate random numbers. The results are promising, hinting at improved accuracy with the proposed methods and slightly lower estimates (both for VaR and CVaR estimation) using the quantum-based methodology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02125v1</guid>
      <category>cs.ET</category>
      <category>q-fin.RM</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Emanuele Dri, Achille Yomi, Muthumanimaran Vetrivelan, Cedric Kuassivi, Iv\`an Diego Exposito</dc:creator>
    </item>
    <item>
      <title>Privacy by Design for Self-Sovereign Identity Systems: An in-depth Component Analysis completed by a Design Assistance Dashboard</title>
      <link>https://arxiv.org/abs/2502.02520</link>
      <description>arXiv:2502.02520v1 Announce Type: new 
Abstract: The use of Self-Sovereign Identity (SSI) systems for digital identity management is gaining traction and interest. Countries such as Bhutan have already implemented an SSI infrastructure to manage the identity of their citizens. The EU, thanks to the revised eIDAS regulation, is opening the door for SSI vendors to develop SSI systems for the planned EU digital identity wallet. These developments, which fall within the sovereign domain, raise questions about individual privacy.
  The purpose of this article is to help SSI solution designers make informed choices to ensure that the designed solution is privacy-friendly. The observation is that the range of possible solutions is very broad, from DID and DID resolution methods to verifiable credential types, publicly available information (e.g. in a blockchain), type of infrastructure, etc. As a result, the article proposes (1) to group the elementary building blocks of a SSI system into 5 structuring layers, (2) to analyze for each layer the privacy implications of using the chosen building block, and (3) to provide a design assistance dashboard that gives the complete picture of the SSI, and shows the interdependencies between architectural choices and technical building blocks, allowing designers to make informed choices and graphically achieve a SSI solution that meets their need for privacy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02520v1</guid>
      <category>cs.ET</category>
      <category>cs.CY</category>
      <category>cs.SE</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Montassar Naghmouchi, Maryline Laurent</dc:creator>
    </item>
    <item>
      <title>A Hardware-Efficient Photonic Tensor Core: Accelerating Deep Neural Networks with Structured Compression</title>
      <link>https://arxiv.org/abs/2502.01670</link>
      <description>arXiv:2502.01670v1 Announce Type: cross 
Abstract: Recent advancements in artificial intelligence (AI) and deep neural networks (DNNs) have revolutionized numerous fields, enabling complex tasks by extracting intricate features from large datasets. However, the exponential growth in computational demands has outstripped the capabilities of traditional electrical hardware accelerators. Optical computing offers a promising alternative due to its inherent advantages of parallelism, high computational speed, and low power consumption. Yet, current photonic integrated circuits (PICs) designed for general matrix multiplication (GEMM) are constrained by large footprints, high costs of electro-optical (E-O) interfaces, and high control complexity, limiting their scalability. To overcome these challenges, we introduce a block-circulant photonic tensor core (CirPTC) for a structure-compressed optical neural network (StrC-ONN) architecture. By applying a structured compression strategy to weight matrices, StrC-ONN significantly reduces model parameters and hardware requirements while preserving the universal representability of networks and maintaining comparable expressivity. Additionally, we propose a hardware-aware training framework to compensate for on-chip nonidealities to improve model robustness and accuracy. We experimentally demonstrate image processing and classification tasks, achieving up to a 74.91% reduction in trainable parameters while maintaining competitive accuracies. Performance analysis expects a computational density of 5.84 tera operations per second (TOPS) per mm^2 and a power efficiency of 47.94 TOPS/W, marking a 6.87-times improvement achieved through the hardware-software co-design approach. By reducing both hardware requirements and control complexity across multiple dimensions, this work explores a new pathway to push the limits of optical computing in the pursuit of high efficiency and scalability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01670v1</guid>
      <category>cs.AR</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shupeng Ning, Hanqing Zhu, Chenghao Feng, Jiaqi Gu, David Z. Pan, Ray T. Chen</dc:creator>
    </item>
    <item>
      <title>Optimizing Spot Instance Reliability and Security Using Cloud-Native Data and Tools</title>
      <link>https://arxiv.org/abs/2502.01966</link>
      <description>arXiv:2502.01966v1 Announce Type: cross 
Abstract: This paper represents "Cloudlab", a comprehensive, cloud - native laboratory designed to support network security research and training. Built on Google Cloud and adhering to GitOps methodologies, Cloudlab facilitates the the creation, testing, and deployment of secure, containerized workloads using Kubernetes and serverless architectures. The lab integrates tools like Palo Alto Networks firewalls, Bridgecrew for "Security as Code," and automated GitHub workflows to establish a robust Continuous Integration/Continuous Machine Learning pipeline. By providing an adaptive and scalable environment, Cloudlab supports advanced security concepts such as role-based access control, Policy as Code, and container security. This initiative enables data scientists and engineers to explore cutting-edge practices in a dynamic cloud-native ecosystem, fostering innovation and improving operational resilience in modern IT infrastructures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01966v1</guid>
      <category>cs.CR</category>
      <category>cs.DC</category>
      <category>cs.ET</category>
      <category>cs.SE</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shubham Malhotra</dc:creator>
    </item>
    <item>
      <title>Evaluating Fault Tolerance and Scalability in Distributed File Systems: A Case Study of GFS, HDFS, and MinIO</title>
      <link>https://arxiv.org/abs/2502.01981</link>
      <description>arXiv:2502.01981v1 Announce Type: cross 
Abstract: Distributed File Systems (DFS) are essential for managing vast datasets across multiple servers, offering benefits in scalability, fault tolerance, and data accessibility. This paper presents a comprehensive evaluation of three prominent DFSs - Google File System (GFS), Hadoop Distributed File System (HDFS), and MinIO - focusing on their fault tolerance mechanisms and scalability under varying data loads and client demands. Through detailed analysis, how these systems handle data redundancy, server failures, and client access protocols, ensuring reliability in dynamic, large-scale environments is assessed. In addition, the impact of system design on performance, particularly in distributed cloud and computing architectures is assessed. By comparing the strengths and limitations of each DFS, the paper provides practical insights for selecting the most appropriate system for different enterprise needs, from high availability storage to big data analytics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01981v1</guid>
      <category>cs.DC</category>
      <category>cs.ET</category>
      <category>cs.PF</category>
      <category>cs.SE</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shubham Malhotra</dc:creator>
    </item>
    <item>
      <title>PALQA: A Novel Parameterized Position-Aware Lossy Quantum Autoencoder using LSB Control Qubit for Efficient Image Compression</title>
      <link>https://arxiv.org/abs/2502.02188</link>
      <description>arXiv:2502.02188v1 Announce Type: cross 
Abstract: With the growing interest in quantum computing, quantum image processing technology has become a vital research field due to its versatile applications and ability to outperform classical computing. A quantum autoencoder approach has been used for compression purposes. However, existing autoencoders are limited to small-scale images, and the mechanisms of state compression remain unclear. There is also a need for efficient quantum autoencoders using standard representation approaches and for studying parameterized position-aware control qubits and their corresponding quality measurement metrics. This work introduces a novel parameterized position-aware lossy quantum autoencoder (PALQA) circuit that utilizes the least significant bit control qubit for image compression. The PALQA circuit employs a transformed coefficient block-based modified state connection approach to efficiently compress images at various resolutions. The method leverages compression opportunities in the state-label connection by applying position-aware least significant control qubit. Compared to JPEG and other enhanced quantum representation-based quantum autoencoders, the PALQA circuit demonstrates superior performance in terms of the number of gates required and PSNR metrics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02188v1</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ershadul Haque, Manoranjan Paul, Faranak Tohidi, Anwaar Ulhaq, Tanmoy Debnath</dc:creator>
    </item>
    <item>
      <title>Can You Move These Over There? An LLM-based VR Mover for Supporting Object Manipulation</title>
      <link>https://arxiv.org/abs/2502.02201</link>
      <description>arXiv:2502.02201v1 Announce Type: cross 
Abstract: In our daily lives, we can naturally convey instructions for the spatial manipulation of objects using words and gestures. Transposing this form of interaction into virtual reality (VR) object manipulation can be beneficial. We propose VR Mover, an LLM-empowered solution that can understand and interpret the user's vocal instruction to support object manipulation. By simply pointing and speaking, the LLM can manipulate objects without structured input. Our user study demonstrates that VR Mover enhances user usability, overall experience and performance on multi-object manipulation, while also reducing workload and arm fatigue. Users prefer the proposed natural interface for broad movements and may complementarily switch to gizmos or virtual hands for finer adjustments. These findings are believed to contribute to design implications for future LLM-based object manipulation interfaces, highlighting the potential for more intuitive and efficient user interactions in VR environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02201v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.ET</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiangzhi Eric Wang, Zackary P. T. Sin, Ye Jia, Daniel Archer, Wynonna H. Y. Fong, Qing Li, Chen Li</dc:creator>
    </item>
  </channel>
</rss>
