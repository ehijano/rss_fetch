<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NA</link>
    <description>cs.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 15 Sep 2025 04:04:02 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 15 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>The high-order Hermite discrete correction function method for surface-driven electromagnetic problems</title>
      <link>https://arxiv.org/abs/2509.09857</link>
      <description>arXiv:2509.09857v1 Announce Type: new 
Abstract: The Hermite-Taylor method evolves all the variables and their derivatives through order $m$ in time to achieve a $2m+1$ order rate of convergence. The data required at each node of the staggered Cartesian meshes used by this method makes the enforcement of boundary and interface conditions challenging. In this work, we propose a novel correction function method, referred to as the discrete correction function method, which provides all the data required by the Hermite method near the surface where a condition is enforced. The flexibility of the resulting Hermite-Taylor discrete correction function method is demonstrated by considering a wide range of problems, including those with variable coefficients, discontinuous solutions at the interface, and generalized sheet transition conditions. Although the focus of this work is on Maxwell's equations, this high-order method can be adapted to other linear wave systems. Several numerical examples in two space dimensions are performed to verify the properties of the proposed method, including long-time simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.09857v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 15 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yann-Meing Law</dc:creator>
    </item>
    <item>
      <title>A streamline upwind/Petrov-Galerkin method for the magnetic advection-diffusion problem</title>
      <link>https://arxiv.org/abs/2509.09913</link>
      <description>arXiv:2509.09913v1 Announce Type: new 
Abstract: This paper presents the development and analysis of a streamline upwind/Petrov-Galerkin (SUPG) method for the magnetic advection-diffusion problem. A key feature of the method is an SUPG-type stabilization term based on the residuals and weighted advection terms of the test function. By introducing a lifting operator to characterize the jumps of finite element functions across element interfaces, we define a discrete magnetic advection operator, which subsequently enables the formulation of the desired SUPG method. Under mild assumptions, we establish the stability of the scheme and derive optimal error estimates. Furthermore, by introducing a stabilization term that depends on the residual, we propose a nonlinear extension aimed at more effectively reducing numerical oscillations in sharp layers. Numerical examples in both two and three dimensions are provided to demonstrate the theoretical convergence and stabilization properties of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.09913v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 15 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haochen Li, Yangfan Luo, Jindong Wang, Shuonan Wu</dc:creator>
    </item>
    <item>
      <title>Perfectly transparent boundary conditions and wave propagation in lattice Boltzmann schemes</title>
      <link>https://arxiv.org/abs/2509.10066</link>
      <description>arXiv:2509.10066v1 Announce Type: new 
Abstract: Systems of N = 1, 2, . . . first-order hyperbolic conservation laws feature N undamped waves propagating at finite speeds. On their own hand, multi-step Finite Difference and lattice Boltzmann schemes with q = N + 1, N + 2, . . . unknowns involve N ''physical'' waves, which are aimed at being as closely-looking as possible to the ones of the PDEs, and q-N ''numerical-spurious-parasitic'' waves, which are subject to their own speed of propagation, and either damped or undamped. The whole picture is even more complicated in the discrete setting-as numerical schemes act as dispersive media, thus propagate different harmonics at different phase (and group) velocities. For compelling practical reasons, simulations must always be conducted on bounded domains, even when the target problem is unbounded in space. The importance of transparent boundary conditions, preventing artificial boundaries from acting as mirrors producing polluting ricochets, naturally follows. This work presents, building on Besse, Coulombel, and Noble [ESAIM: M2AN, 55 (2021)], a systematic way of developing perfectly transparent boundary conditions for lattice Boltzmann schemes tackling linear problems in one and two space dimensions. Our boundary conditions are ''perfectly'' transparent, at least for 1D problems, as they absorb both physical and spurious waves regardless of their frequency. After presenting, in a simple framework, several approaches to handle the fact that q &gt; N , we elect the so-called ''scalar'' approach (which despite its name, also works when N &gt; 1) as method of choice for more involved problems. This method solely relies on computing the coefficients of the Laurent series at infinity of the roots of the dispersion relation of the bulk scheme. We insist on asymptotics for these coefficients in the spirit of analytic combinatorics. The reason is two-fold: asymptotics guide truncation of boundary conditions to make them depending on a fixed number of past time-steps, and make it clearduring the process of computing coefficients-whether intermediate quantities can be safely stored using floating-point arithmetic or not. Numerous numerical investigations in 1D and 2D with N = 1 and 2 are carried out, and show the effectiveness of the proposed boundary conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10066v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.CA</category>
      <pubDate>Mon, 15 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas Bellotti (EM2C)</dc:creator>
    </item>
    <item>
      <title>A Spectral Localization Method for Time-Fractional Integro-Differential Equations with Nonsmooth Data</title>
      <link>https://arxiv.org/abs/2509.10091</link>
      <description>arXiv:2509.10091v1 Announce Type: new 
Abstract: In this work, we develop a localized numerical scheme with low regularity requirements for solving time-fractional integro-differential equations. First, a fully discrete numerical scheme is constructed. Specifically, for temporal discretization, we employ the contour integral method (CIM) with parameterized hyperbolic contours to approximate the nonlocal operators. For spatial discretization, the standard piecewise linear Galerkin finite element method (FEM) is used. We then provide a rigorous error analysis, demonstrating that the proposed scheme achieves high accuracy even for problems with nonsmooth/vanishing initial values or low-regularity solutions, featuring spectral accuracy in time and second-order convergence in space. Finally, a series of numerical experiments in both 1-D and 2-D validate the theoretical findings and confirm that the algorithm combines the advantages of spectral accuracy, low computational cost, and efficient memory usage.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10091v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <pubDate>Mon, 15 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lijing Zhao, Rui Zhao, Wenyi Tian, Yufeng Nie</dc:creator>
    </item>
    <item>
      <title>Neural network-based singularity detection and applications</title>
      <link>https://arxiv.org/abs/2509.10110</link>
      <description>arXiv:2509.10110v1 Announce Type: new 
Abstract: We present a method for constructing a special type of shallow neural network that learns univariate meromorphic functions with pole-type singularities. Our method is based on using a finite set of Laurent coefficients as input information, which we compute by FFT, employing values of the investigated function on some contour $\Gamma$ in the complex plane. The primary components of our methodology are the following: (1) the adaptive construction of rational polynomial activation functions, (2) a novel backpropagation-free method for determining the weights and biases of the hidden layer, and (3) the computation of the weights and biases of the output layer through least-squares fitting. Breaking with the idea of "safe" rational activation functions, we introduce a rational activation function as a meromorphic function with a single pole situated within the domain of investigation. Employing the weights and biases of the hidden layer, we then scale and shift the pole of the activation function to find the estimated locations of the singularities; this implies that the number of neurons in the hidden layer is determined by the number of singularities of the function that is being approximated. While the weights and biases of the hidden layer are tuned so as to capture the singularities, the least-squares fitting for the computation of weights and biases of the output layer ensures approximation of the function in the rest of the domain. Through the use of Laurent-Pad\'e rational approximation concepts, we prove locally uniform convergence of our method. We illustrate the effectiveness of our method through numerical experiments, including the construction of extensions of the time-dependent solutions of nonlinear autonomous PDEs into the complex plane, and study the dynamics of their singularities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10110v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 15 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nadiia Derevianko, Ioannis G. Kevrekidis, Felix Dietrich</dc:creator>
    </item>
    <item>
      <title>The low-rank tensor-train finite difference method for three-dimensional parabolic equations</title>
      <link>https://arxiv.org/abs/2509.10142</link>
      <description>arXiv:2509.10142v1 Announce Type: new 
Abstract: This paper presents a numerical framework for the low-rank approximation of the solution to three-dimensional parabolic problems. The key contribution of this work is the tensorization process based on a tensor-train reformulation of the second-order accurate finite difference method. We advance the solution in time by combining the finite difference method with an explicit and implicit Euler method and with the Crank-Nicolson method. We solve the linear system arising at each time step from the implicit and semi-implicit time-marching schemes through a matrix-free preconditioned conjugate gradient (PCG) method, appositely designed to exploit the separation of variables induced by the tensor-train format. We assess the performance of our method through extensive numerical experimentation, demonstrating that the tensor-train design offers a robust and highly efficient alternative to the traditional approach. Indeed, the usage of this type of representation leads to massive time and memory savings while guaranteeing almost identical accuracy with respect to the traditional one. These features make the method particularly suitable to tackle challenging high-dimensional problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10142v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 15 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Gianmarco Manzini, Tommaso Sorgente</dc:creator>
    </item>
    <item>
      <title>The unified gas kinetic wave-particle method for the neutron transport equation</title>
      <link>https://arxiv.org/abs/2509.10178</link>
      <description>arXiv:2509.10178v1 Announce Type: new 
Abstract: The unified gas-kinetic wave-particle (UGKWP) method is proposed for the neutron transport equation, addressing the inherent multiscale nature of neutron propagation in both optically thin and thick regimes. UGKWP couples macroscopic diffusion and microscopic transport processes within a unified time-dependent framework, allowing a smooth transition between the free transport and diffusion regimes. This method is readily extended to multi-group neutron transport models and is applicable to both steady-state and eigenvalue problems. Several numerical examples, including the 1D and 3D single-group and 3D multi-group problems, are studied, indicating UGKWP a promising framework for scalable and accurate simulation of multigroup neutron transport in complex geometries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10178v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 15 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guangwei Liu, Shuang Tan, Yanli Wang</dc:creator>
    </item>
    <item>
      <title>Convergence to equilibrium for fully discretizations of nonlocal Cahn-Hilliard equation</title>
      <link>https://arxiv.org/abs/2509.10180</link>
      <description>arXiv:2509.10180v1 Announce Type: new 
Abstract: The study of long-term dynamics for numerical solutions of nonlinear evolution equations, particularly phase field models, has consistently garnered considerable attention. The Cahn-Hilliard (CH) equation is one of the most important phase field models and is widely applied in materials science. In order to more accurately describe the practical phenomena in material microstructural phase transitions, the Nonlocal Cahn-Hilliard (N-CH) equation incorporates a finite range of spatial nonlocal interactions is introduced, which is a generalization of the classic CH equation. However, compared to its classic counterpart, it is very challenging to investigate the long-term asymptotic behavior of solution to the N-CH equation due to the complexity of the nonlocal integral term and the lack of high-order diffusion term. In this paper, we consider first-order and second-order temporal discretization methods for the N-CH equation, respectively, while utilizing a second-order finite difference method for spatial approximation to construct the energy stable fully discrete numerical schemes. Based on energy stability and the {\L}ojasiewicz inequality, we rigorously prove that the numerical solutions of these fully discrete numerical schemes converge to equilibrium as time goes to infinity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10180v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 15 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Danni Zhang, Dongling Wang</dc:creator>
    </item>
    <item>
      <title>Matrix-Free Evaluation Strategies for Continuous and Discontinuous Galerkin Discretizations on Unstructured Tetrahedral Grids</title>
      <link>https://arxiv.org/abs/2509.10226</link>
      <description>arXiv:2509.10226v1 Announce Type: new 
Abstract: This study presents novel strategies for improving the node-level performance of matrix-free evaluation of continuous and discontinuous Galerkin spatial discretizations on unstructured tetrahedral grids. In our approach the underlying integrals of a generic finite-element operator are computed cell-by-cell through numerical quadrature using tabulated dense local matrices of shape functions, achieving high throughput for low to moderate-order polynomial degrees. By employing dense matrix-matrix products instead of matrix-vector products for the cell-wise interpolation, the method reaches over $60\%$ of peak performance. The optimization strategies exploit explicit data parallelism to enhance computational efficiency, complemented by a hierarchical mesh reordering algorithm that improves data locality. The matrix-free implementation achieves up to a $6\times$ speedup compared to a global sparse matrix-based approach at a polynomial degree of three. The effectiveness of the method is demonstrated through numerical experiments on the Poisson and Navier--Stokes equations. The Poisson operator is preconditioned by a hybrid multigrid scheme that combines auxiliary continuous finite-element spaces, polynomial and geometric coarsening where possible while employing algebraic multigrid on the coarse mesh. Within the preconditioner, the implementation transitions between the matrix-free and matrix-based strategies for optimal efficiency. Finally, we analyze the strong scaling behavior of the Poisson and Helmholtz operators, demonstrating the method's potential to solve large real-world problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10226v1</guid>
      <category>math.NA</category>
      <category>cs.MS</category>
      <category>cs.NA</category>
      <category>cs.PF</category>
      <pubDate>Mon, 15 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dominik Still, Niklas Fehn, Wolfgang A. Wall, Martin Kronbichler</dc:creator>
    </item>
    <item>
      <title>Near-Optimal Recovery Performance of PhaseLift for Phase Retrieval from Coded Diffraction Patterns</title>
      <link>https://arxiv.org/abs/2509.10300</link>
      <description>arXiv:2509.10300v1 Announce Type: new 
Abstract: The PhaseLift algorithm is an effective convex method for solving the phase retrieval problem from Fourier measurements with coded diffraction patterns (CDP). While exact reconstruction guarantees are well-established in the noiseless case, the stability of recovery under noise remains less well understood. In particular, when the measurements are corrupted by an additive noise vector $\mathbf{w} \in \mathbb{R}^m$, existing recovery bounds scale on the order of $\|\mathbf{w}\|_2$, which is conjectured to be suboptimal. More recently, Soltanolkotabi conjectured that the optimal PhaseLift recovery bound should scale with the average noise magnitude, that is, on the order of $\|\mathbf{w}\|_2/\sqrt m$. However, establishing this theoretically is considerably more challenging and has remained an open problem. In this paper, we focus on this conjecture and provide a nearly optimal recovery bound for it. We prove that under adversarial noise, the recovery error of PhaseLift is bounded by $O(\log n \cdot \|\mathbf{w}\|_2/\sqrt m)$, and further show that there exists a noise vector for which the error lower bound exceeds $O\bigl(\frac{1}{\sqrt{\log n}} \cdot \frac{\|\mathbf{w}\|_2}{\sqrt m}\bigr)$. Here, $n$ is the dimension of the signals we aim to recover. Moreover, for mean-zero sub-Gaussian noise vector $\mathbf{w} \in \mathbb R^m$ with sub-Gaussian norm $\sigma$, we establish a bound of order $O\bigl(\sigma \sqrt{\frac{n \log^4 n}{m}}\bigr)$, and also provide a corresponding minimax lower bound. Our results affirm Soltanolkotabi's conjecture up to logarithmic factors, providing a new insight into the stability of PhaseLift under noisy CDP measurements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10300v1</guid>
      <category>math.NA</category>
      <category>cs.IT</category>
      <category>cs.NA</category>
      <category>math.IT</category>
      <pubDate>Mon, 15 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Meng Huang, Jinming Wen, Ran Zhang</dc:creator>
    </item>
    <item>
      <title>Structure-Preserving High-Order Methods for the Compressible Euler Equations in Potential Temperature Formulation for Atmospheric Flows</title>
      <link>https://arxiv.org/abs/2509.10311</link>
      <description>arXiv:2509.10311v1 Announce Type: new 
Abstract: We develop structure-preserving numerical methods for the compressible Euler equations, employing potential temperature as a prognostic variable.We construct three numerical fluxes designed to ensure the conservation of entropy and total energy within the discontinuous Galerkin framework on general curvilinear meshes.Furthermore, we introduce a generalization for the kinetic energy preservation property and total energy conservation in the presence of a gravitational potential term. To this end, we adopt a flux-differencing approach for the discretization of the source term, treated as non-conservative product. We present well-balanced schemes for different constant background states for both formulations (total energy and potential temperature) on curvilinear meshes. Finally, we validate the methods by comparing the potential temperature formulation with the traditional Euler equations formulation across a range of classical atmospheric scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10311v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.ao-ph</category>
      <category>physics.comp-ph</category>
      <pubDate>Mon, 15 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marco Artiano, Oswald Knoth, Peter Spichtinger, Hendrik Ranocha</dc:creator>
    </item>
    <item>
      <title>Numerical analysis of the large deviation regime of a kinetic equation with a nonlocal Hamilton-Jacobi limit</title>
      <link>https://arxiv.org/abs/2509.10323</link>
      <description>arXiv:2509.10323v1 Announce Type: new 
Abstract: We develop and study an asymptotic-preserving (AP) numerical scheme for a linear kinetic equation in a large deviation regime. After applying a Hopf-Cole transform to the distribution function, the system exhibits the behavior of rare events, which in the limit is governed by a non-standard, nonlocal Hamilton-Jacobi equation, as identified in [E. Bouin et al., J. Lond. Math. Soc., II. Ser., 2023].
  The proposed scheme efficiently handles the stiffness introduced by scaling, with a computational cost that remains uniform with respect to the small parameter. It takes advantage of the conservation properties of the original kinetic model to overcome the numerical challenges posed by stiffness. The scheme satisfies a discrete maximum principle, preserves equilibrium states, and correctly captures the asymptotic limit, recovering the viscosity solution of the limit nonlocal Hamilton-Jacobi equation.
  As the limit problem is non-standard, convergence results from the literature are not directly applicable. We introduce new analytical tools based on a discrete representation formula that links the numerical scheme with the continuous setting. This allows us to prove the convergence and establish key structural properties of the method. Numerical tests support the analysis and illustrate the robustness of the scheme and the original behavior of the limit system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10323v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 15 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>H\'el\`ene Hivert, Tino Laidin</dc:creator>
    </item>
    <item>
      <title>Mathematical and numerical study of symmetry and positivity of the tensor-valued spring constant defined from P1-FEM for two- and three-dimensional linear elasticity</title>
      <link>https://arxiv.org/abs/2509.10335</link>
      <description>arXiv:2509.10335v1 Announce Type: new 
Abstract: In this study, we consider a spring-block system that approximates a $d$-dimensional linear elastic body, where $d=2$ or $d=3$. We derive a $d\times d$ matrix as the spring constant using the P1 finite element method with a triangular mesh for the linear elasticity equations. We mathematically analyze the symmetry and positive-definiteness of the spring constant. Even if we assume full symmetry of the elasticity tensor, the symmetry of the matrix obtained as the spring constant is not trivial. However, we have succeeded in proving this in a unified manner for both 2D and 3D cases. This is an alternative proof for the 2D case in Notsu-Kimura (2014) and is a new result for the 3D case. We provide a necessary and sufficient condition for the spring constant to be positive-definite in the case of an isotropic elasticity tensor, along with a sufficient condition in terms of mesh regularity and the Poisson ratio. These theoretical results are supported by several numerical experiments. The positive-definiteness of the spring constant derived from the finite element method plays a vital role in fracture simulations of elastic bodies using the spring-block system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10335v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 15 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Oussama Ounissi, Masato Kimura, Hirofumi Notsu</dc:creator>
    </item>
    <item>
      <title>Multiscaling in Wasserstein Spaces</title>
      <link>https://arxiv.org/abs/2509.10415</link>
      <description>arXiv:2509.10415v1 Announce Type: new 
Abstract: We present a novel multiscale framework for analyzing sequences of probability measures in Wasserstein spaces over Euclidean domains. Exploiting the intrinsic geometry of optimal transport, we construct a multiscale transform applicable to both absolutely continuous and discrete measures. Central to our approach is a refinement operator based on McCann's interpolants, which preserves the geodesic structure of measure flows and serves as an upsampling mechanism. Building on this, we introduce the optimality number, a scalar that quantifies deviations of a sequence from Wasserstein geodesicity across scales, enabling the detection of irregular dynamics and anomalies. We establish key theoretical guarantees, including stability of the transform and geometric decay of coefficients, ensuring robustness and interpretability of the multiscale representation. Finally, we demonstrate the versatility of our methodology through numerical experiments: denoising and anomaly detection in Gaussian flows, analysis of point cloud dynamics under vector fields, and the multiscale characterization of neural network learning trajectories.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10415v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 15 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wael Mattar, Nir Sharon</dc:creator>
    </item>
    <item>
      <title>Data-driven approximation of transfer operators for mean-field stochastic differential equations</title>
      <link>https://arxiv.org/abs/2509.09891</link>
      <description>arXiv:2509.09891v1 Announce Type: cross 
Abstract: Mean-field stochastic differential equations, also called McKean--Vlasov equations, are the limiting equations of interacting particle systems with fully symmetric interaction potential. Such systems play an important role in a variety of fields ranging from biology and physics to sociology and economics. Global information about the behavior of complex dynamical systems can be obtained by analyzing the eigenvalues and eigenfunctions of associated transfer operators such as the Perron--Frobenius operator and the Koopman operator. In this paper, we extend transfer operator theory to McKean--Vlasov equations and show how extended dynamic mode decomposition and the Galerkin projection methodology can be used to compute finite-dimensional approximations of these operators, which allows us to compute spectral properties and thus to identify slowly evolving spatiotemporal patterns or to detect metastable sets. The results will be illustrated with the aid of several guiding examples and benchmark problems including the Cormier model, the Kuramoto model, and a three-dimensional generalization of the Kuramoto model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.09891v1</guid>
      <category>math.DS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <pubDate>Mon, 15 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eirini Ioannou, Stefan Klus, Gon\c{c}alo dos Reis</dc:creator>
    </item>
    <item>
      <title>SciML Agents: Write the Solver, Not the Solution</title>
      <link>https://arxiv.org/abs/2509.09936</link>
      <description>arXiv:2509.09936v1 Announce Type: cross 
Abstract: Recent work in scientific machine learning aims to tackle scientific tasks directly by predicting target values with neural networks (e.g., physics-informed neural networks, neural ODEs, neural operators, etc.), but attaining high accuracy and robustness has been challenging. We explore an alternative view: use LLMs to write code that leverages decades of numerical algorithms. This shifts the burden from learning a solution function to making domain-aware numerical choices. We ask whether LLMs can act as SciML agents that, given a natural-language ODE description, generate runnable code that is scientifically appropriate, selecting suitable solvers (stiff vs. non-stiff), and enforcing stability checks. There is currently no benchmark to measure this kind of capability for scientific computing tasks. As such, we first introduce two new datasets: a diagnostic dataset of adversarial "misleading" problems; and a large-scale benchmark of 1,000 diverse ODE tasks. The diagnostic set contains problems whose superficial appearance suggests stiffness, and that require algebraic simplification to demonstrate non-stiffness; and the large-scale benchmark spans stiff and non-stiff ODE regimes. We evaluate open- and closed-source LLM models along two axes: (i) unguided versus guided prompting with domain-specific knowledge; and (ii) off-the-shelf versus fine-tuned variants. Our evaluation measures both executability and numerical validity against reference solutions. We find that with sufficient context and guided prompts, newer instruction-following models achieve high accuracy on both criteria. In many cases, recent open-source systems perform strongly without fine-tuning, while older or smaller models still benefit from fine-tuning. Overall, our preliminary results indicate that careful prompting and fine-tuning can yield a specialized LLM agent capable of reliably solving simple ODE problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.09936v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 15 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Saarth Gaonkar, Xiang Zheng, Haocheng Xi, Rishabh Tiwari, Kurt Keutzer, Dmitriy Morozov, Michael W. Mahoney, Amir Gholami</dc:creator>
    </item>
    <item>
      <title>Intrinsic Dimension Estimating Autoencoder (IDEA) Using CancelOut Layer and a Projected Loss</title>
      <link>https://arxiv.org/abs/2509.10011</link>
      <description>arXiv:2509.10011v1 Announce Type: cross 
Abstract: This paper introduces the Intrinsic Dimension Estimating Autoencoder (IDEA), which identifies the underlying intrinsic dimension of a wide range of datasets whose samples lie on either linear or nonlinear manifolds. Beyond estimating the intrinsic dimension, IDEA is also able to reconstruct the original dataset after projecting it onto the corresponding latent space, which is structured using re-weighted double CancelOut layers. Our key contribution is the introduction of the projected reconstruction loss term, guiding the training of the model by continuously assessing the reconstruction quality under the removal of an additional latent dimension. We first assess the performance of IDEA on a series of theoretical benchmarks to validate its robustness. These experiments allow us to test its reconstruction ability and compare its performance with state-of-the-art intrinsic dimension estimators. The benchmarks show good accuracy and high versatility of our approach. Subsequently, we apply our model to data generated from the numerical solution of a vertically resolved one-dimensional free-surface flow, following a pointwise discretization of the vertical velocity profile in the horizontal direction, vertical direction, and time. IDEA succeeds in estimating the dataset's intrinsic dimension and then reconstructs the original solution by working directly within the projection space identified by the network.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10011v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 15 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Antoine Orioua, Philipp Krah, Julian Koellermeier</dc:creator>
    </item>
    <item>
      <title>Physics-informed sensor coverage through structure preserving machine learning</title>
      <link>https://arxiv.org/abs/2509.10363</link>
      <description>arXiv:2509.10363v1 Announce Type: cross 
Abstract: We present a machine learning framework for adaptive source localization in which agents use a structure-preserving digital twin of a coupled hydrodynamic-transport system for real-time trajectory planning and data assimilation. The twin is constructed with conditional neural Whitney forms (CNWF), coupling the numerical guarantees of finite element exterior calculus (FEEC) with transformer-based operator learning. The resulting model preserves discrete conservation, and adapts in real time to streaming sensor data. It employs a conditional attention mechanism to identify: a reduced Whitney-form basis; reduced integral balance equations; and a source field, each compatible with given sensor measurements. The induced reduced-order environmental model retains the stability and consistency of standard finite-element simulation, yielding a physically realizable, regular mapping from sensor data to the source field. We propose a staggered scheme that alternates between evaluating the digital twin and applying Lloyd's algorithm to guide sensor placement, with analysis providing conditions for monotone improvement of a coverage functional. Using the predicted source field as an importance function within an optimal-recovery scheme, we demonstrate recovery of point sources under continuity assumptions, highlighting the role of regularity as a sufficient condition for localization. Experimental comparisons with physics-agnostic transformer architectures show improved accuracy in complex geometries when physical constraints are enforced, indicating that structure preservation provides an effective inductive bias for source identification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10363v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 15 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Benjamin David Shaffer, Brooks Kinch, Joseph Klobusicky, M. Ani Hsieh, Nathaniel Trask</dc:creator>
    </item>
    <item>
      <title>A Power Method for Computing Singular Value Decomposition</title>
      <link>https://arxiv.org/abs/2410.23999</link>
      <description>arXiv:2410.23999v3 Announce Type: replace 
Abstract: The singular value decomposition (SVD) allows to write a matrix as a product of a left singular vectors matrix, a nonnegative singular values diagonal matrix and a right singular vectors matrix. Among the applications of the SVD are the principal component analysis, the low-rank matrix approximation and the solving of a linear system of equations. The methods used for computing this decomposition allow to get the complete or partial result. For very large size matrix, the probabilistic methods allow to get partial result by using less computational load. A power method is proposed in this paper for computing all or the $k$ first largest SVD subspaces for a real-valued matrix. The $k$ first right singular vectors of this method are the $k$ columns of a neural network encoder weight matrix. The accuracy of this iterative search method depends on the behavior of the singular values and the settings of the gradient search optimizer used. A R package implementing the proposed method is available at https://cran.r-project.org/web/packages/psvd/index.html.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.23999v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 15 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Doulaye Dembele</dc:creator>
    </item>
    <item>
      <title>Stable fully discrete finite element methods with BGN tangential motion for Willmore flow of planar curves</title>
      <link>https://arxiv.org/abs/2503.23152</link>
      <description>arXiv:2503.23152v2 Announce Type: replace 
Abstract: We propose and analyze stable finite element approximations for Willmore flow of planar curves. The presented schemes are based on a novel weak formulation which combines an evolution equation for curvature with the curvature formulation originally proposed by Barrett, Garcke and N\"urnberg (BGN) in \cite{BGN07}. Under discretization in space with piecewise linear elements this leads to a stable continuous-in-time semidiscrete scheme, which retains the equidistribution property from the BGN methods. Furthermore, two fully discrete schemes can be shown to satisfy unconditional energy stability estimates. Numerical examples are presented to showcase the good properties of the introduced schemes, including an asymptotic equidistribution of vertices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.23152v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 15 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Harald Garcke, Robert N\"urnberg, Quan Zhao</dc:creator>
    </item>
    <item>
      <title>Per-antenna power constraints: constructing Pareto-optimal precoders with cubic complexity under non-negligible noise conditions</title>
      <link>https://arxiv.org/abs/2508.09646</link>
      <description>arXiv:2508.09646v2 Announce Type: replace 
Abstract: Precoding matrix construction is a key element of the wireless signal processing using the multiple-input and multiple-output model. It is established that the problem of global throughput optimization under per-antenna power constraints belongs, in general, to the class of monotonic optimization problems, and is unsolvable in real-time. The most widely used real-time baseline is the suboptimal solution of Zero-Forcing, which achieves a cubic complexity by discarding the background noise coefficients. This baseline, however, is not readily adapted to per-antenna power constraints, and performs poorly if background noise coefficients are not negligible. In this paper, we are going to present a computational algorithm which constructs a precoder that is SINR multiobjective Pareto-optimal under per-antenna power constraints - with a complexity that differs from that of Zero-Forcing only by a constant factor. The algorithm has a set of input parameters, changing which skews the importance of particular user throughputs: these parameters make up an efficient parameterization of the entire Pareto boundary.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.09646v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>eess.SP</category>
      <pubDate>Mon, 15 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Sergey Petrov, Samson Lasaulce, Merouane Debbah</dc:creator>
    </item>
    <item>
      <title>PCGBandit: One-shot acceleration of transient PDE solvers via online-learned preconditioners</title>
      <link>https://arxiv.org/abs/2509.08765</link>
      <description>arXiv:2509.08765v2 Announce Type: replace-cross 
Abstract: Data-driven acceleration of scientific computing workflows has been a high-profile aim of machine learning (ML) for science, with numerical simulation of transient partial differential equations (PDEs) being one of the main applications. The focus thus far has been on methods that require classical simulations to train, which when combined with the data-hungriness and optimization challenges of neural networks has caused difficulties in demonstrating a convincing advantage against strong classical baselines. We consider an alternative paradigm in which the learner uses a classical solver's own data to accelerate it, enabling a one-shot speedup of the simulation. Concretely, since transient PDEs often require solving a sequence of related linear systems, the feedback from repeated calls to a linear solver such as preconditioned conjugate gradient (PCG) can be used by a bandit algorithm to online-learn an adaptive sequence of solver configurations (e.g. preconditioners). The method we develop, PCGBandit, is implemented directly on top of the popular open source software OpenFOAM, which we use to show its effectiveness on a set of fluid and magnetohydrodynamics (MHD) problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.08765v2</guid>
      <category>physics.comp-ph</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.ML</category>
      <pubDate>Mon, 15 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mikhail Khodak, Min Ki Jung, Brian Wynne, Edmond Chow, Egemen Kolemen</dc:creator>
    </item>
  </channel>
</rss>
