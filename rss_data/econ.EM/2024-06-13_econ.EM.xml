<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.EM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.EM</link>
    <description>econ.EM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.EM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 13 Jun 2024 04:04:23 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 13 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Optimizing Sales Forecasts through Automated Integration of Market Indicators</title>
      <link>https://arxiv.org/abs/2406.07564</link>
      <description>arXiv:2406.07564v1 Announce Type: new 
Abstract: Recognizing that traditional forecasting models often rely solely on historical demand, this work investigates the potential of data-driven techniques to automatically select and integrate market indicators for improving customer demand predictions. By adopting an exploratory methodology, we integrate macroeconomic time series, such as national GDP growth, from the \textit{Eurostat} database into \textit{Neural Prophet} and \textit{SARIMAX} forecasting models. Suitable time series are automatically identified through different state-of-the-art feature selection methods and applied to sales data from our industrial partner. It could be shown that forecasts can be significantly enhanced by incorporating external information. Notably, the potential of feature selection methods stands out, especially due to their capability for automation without expert knowledge and manual selection effort. In particular, the Forward Feature Selection technique consistently yielded superior forecasting accuracy for both SARIMAX and Neural Prophet across different company sales datasets. In the comparative analysis of the errors of the selected forecasting models, namely Neural Prophet and SARIMAX, it is observed that neither model demonstrates a significant superiority over the other.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.07564v1</guid>
      <category>econ.EM</category>
      <category>cs.LG</category>
      <category>q-fin.GN</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lina D\"oring, Felix Grumbach, Pascal Reusch</dc:creator>
    </item>
    <item>
      <title>Did Harold Zuercher Have Time-Separable Preferences?</title>
      <link>https://arxiv.org/abs/2406.07809</link>
      <description>arXiv:2406.07809v1 Announce Type: new 
Abstract: This paper proposes an empirical model of dynamic discrete choice to allow for non-separable time preferences, generalizing the well-known Rust (1987) model. Under weak conditions, we show the existence of value functions and hence well-defined optimal choices. We construct a contraction mapping of the value function and propose an estimation method similar to Rust's nested fixed point algorithm. Finally, we apply the framework to the bus engine replacement data. We improve the fit of the data with our general model and reject the null hypothesis that Harold Zuercher has separable time preferences. Misspecifying an agent's preference as time-separable when it is not leads to biased inferences about structure parameters (such as the agent's risk attitudes) and misleading policy recommendations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.07809v1</guid>
      <category>econ.EM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jay Lu, Yao Luo, Kota Saito, Yi Xin</dc:creator>
    </item>
    <item>
      <title>Positive and negative word of mouth in the United States</title>
      <link>https://arxiv.org/abs/2406.08279</link>
      <description>arXiv:2406.08279v1 Announce Type: new 
Abstract: Word of mouth is a process by which consumers transmit positive or negative sentiment to other consumers about a business. While this process has long been recognized as a type of promotion for businesses, the value of word of mouth is questionable. This study will examine the various correlates of word of mouth to demographic variables, including the role of the trust of business owners. Education level, region of residence, and income level were found to be significant predictors of positive word of mouth. Although the results generally suggest that the majority of respondents do not engage in word of mouth, there are valuable insights to be learned.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.08279v1</guid>
      <category>econ.EM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Shawn Berry</dc:creator>
    </item>
    <item>
      <title>Identification and Inference on Treatment Effects under Covariate-Adaptive Randomization and Imperfect Compliance</title>
      <link>https://arxiv.org/abs/2406.08419</link>
      <description>arXiv:2406.08419v1 Announce Type: new 
Abstract: Randomized controlled trials (RCTs) frequently utilize covariate-adaptive randomization (CAR) (e.g., stratified block randomization) and commonly suffer from imperfect compliance. This paper studies the identification and inference for the average treatment effect (ATE) and the average treatment effect on the treated (ATT) in such RCTs with a binary treatment.
  We first develop characterizations of the identified sets for both estimands. Since data are generally not i.i.d. under CAR, these characterizations do not follow from existing results. We then provide consistent estimators of the identified sets and asymptotically valid confidence intervals for the parameters. Our asymptotic analysis leads to concrete practical recommendations regarding how to estimate the treatment assignment probabilities that enter in estimated bounds. In the case of the ATE, using sample analog assignment frequencies is more efficient than using the true assignment probabilities. On the contrary, using the true assignment probabilities is preferable for the ATT.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.08419v1</guid>
      <category>econ.EM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Federico A. Bugni, Mengsi Gao, Filip Obradovic, Amilcar Velez</dc:creator>
    </item>
    <item>
      <title>HARd to Beat: The Overlooked Impact of Rolling Windows in the Era of Machine Learning</title>
      <link>https://arxiv.org/abs/2406.08041</link>
      <description>arXiv:2406.08041v1 Announce Type: cross 
Abstract: We investigate the predictive abilities of the heterogeneous autoregressive (HAR) model compared to machine learning (ML) techniques across an unprecedented dataset of 1,455 stocks. Our analysis focuses on the role of fitting schemes, particularly the training window and re-estimation frequency, in determining the HAR model's performance. Despite extensive hyperparameter tuning, ML models fail to surpass the linear benchmark set by HAR when utilizing a refined fitting approach for the latter. Moreover, the simplicity of HAR allows for an interpretable model with drastically lower computational costs. We assess performance using QLIKE, MSE, and realized utility metrics, finding that HAR consistently outperforms its ML counterparts when both rely solely on realized volatility and VIX as predictors. Our results underscore the importance of a correctly specified fitting scheme. They suggest that properly fitted HAR models provide superior forecasting accuracy, establishing robust guidelines for their practical application and use as a benchmark. This study not only reaffirms the efficacy of the HAR model but also provides a critical perspective on the practical limitations of ML approaches in realized volatility forecasting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.08041v1</guid>
      <category>q-fin.ST</category>
      <category>econ.EM</category>
      <category>q-fin.CP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Francesco Audrino, Jonathan Chassot</dc:creator>
    </item>
    <item>
      <title>Claim Reserving via Inverse Probability Weighting: A Micro-Level Chain-Ladder Method</title>
      <link>https://arxiv.org/abs/2307.10808</link>
      <description>arXiv:2307.10808v3 Announce Type: replace 
Abstract: Claim reserving primarily relies on macro-level models, with the Chain-Ladder method being the most widely adopted. These methods were heuristically developed without minimal statistical foundations, relying on oversimplified data assumptions and neglecting policyholder heterogeneity, often resulting in conservative reserve predictions. Micro-level reserving, utilizing stochastic modeling with granular information, can improve predictions but tends to involve less attractive and complex models for practitioners. This paper aims to strike a practical balance between aggregate and individual models by introducing a methodology that enables the Chain-Ladder method to incorporate individual information. We achieve this by proposing a novel framework, formulating the claim reserving problem within a population sampling context. We introduce a reserve estimator in a frequency and severity distribution-free manner that utilizes inverse probability weights (IPW) driven by individual information, akin to propensity scores. We demonstrate that the Chain-Ladder method emerges as a particular case of such an IPW estimator, thereby inheriting a statistically sound foundation based on population sampling theory that enables the use of granular information, and other extensions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.10808v3</guid>
      <category>econ.EM</category>
      <category>stat.AP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sebastian Calcetero-Vanegas, Andrei L. Badescu, X. Sheldon Lin</dc:creator>
    </item>
    <item>
      <title>Non-robustness of diffusion estimates on networks with measurement error</title>
      <link>https://arxiv.org/abs/2403.05704</link>
      <description>arXiv:2403.05704v4 Announce Type: replace 
Abstract: Network diffusion models are used to study things like disease transmission, information spread, and technology adoption. However, small amounts of mismeasurement are extremely likely in the networks constructed to operationalize these models. We show that estimates of diffusions are highly non-robust to this measurement error. First, we show that even when measurement error is vanishingly small, such that the share of missed links is close to zero, forecasts about the extent of diffusion will greatly underestimate the truth. Second, a small mismeasurement in the identity of the initial seed generates a large shift in the locations of expected diffusion path. We show that both of these results still hold when the vanishing measurement error is only local in nature. Such non-robustness in forecasting exists even under conditions where the basic reproductive number is consistently estimable. Possible solutions, such as estimating the measurement error or implementing widespread detection efforts, still face difficulties because the number of missed links are so small. Finally, we conduct Monte Carlo simulations on simulated networks, and real networks from three settings: travel data from the COVID-19 pandemic in the western US, a mobile phone marketing campaign in rural India, and in an insurance experiment in China.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05704v4</guid>
      <category>econ.EM</category>
      <category>cs.SI</category>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Arun G. Chandrasekhar, Paul Goldsmith-Pinkham, Tyler H. McCormick, Samuel Thau, Jerry Wei</dc:creator>
    </item>
    <item>
      <title>Testing Sign Congruence Between Two Parameters</title>
      <link>https://arxiv.org/abs/2405.11759</link>
      <description>arXiv:2405.11759v2 Announce Type: replace 
Abstract: We test the null hypothesis that two parameters $(\mu_1,\mu_2)$ have the same sign, assuming that (asymptotically) normal estimators $(\hat{\mu}_1,\hat{\mu}_2)$ are available. Examples of this problem include the analysis of heterogeneous treatment effects, causal interpretation of reduced-form estimands, meta-studies, and mediation analysis. A number of tests were recently proposed. We recommend a test that is simple and rejects more often than many of these recent proposals. Like all other tests in the literature, it is conservative if the truth is near $(0,0)$ and therefore also biased. To clarify whether these features are avoidable, we also provide a test that is unbiased and has exact size control on the boundary of the null hypothesis, but which has counterintuitive properties and hence we do not recommend. We use the test to improve p-values in Kowalski (2022) from information contained in that paper's main text and to establish statistical significance of some key estimates in Dippel et al. (2021).</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.11759v2</guid>
      <category>econ.EM</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Douglas L. Miller, Francesca Molinari, J\"org Stoye</dc:creator>
    </item>
  </channel>
</rss>
