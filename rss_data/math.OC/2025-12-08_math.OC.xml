<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 09 Dec 2025 03:40:02 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>On Circuit Imbalance and 0/1 Circuits for Coloring and Spanning Forest Problems</title>
      <link>https://arxiv.org/abs/2512.05223</link>
      <description>arXiv:2512.05223v1 Announce Type: new 
Abstract: Circuits are fundamental objects in linear programming and oriented matroid theory, representing the elementary difference vectors of a polyhedron between points in its affine space. A recent concept introduced by Ekbatani, Natura, and V\'egh, the circuit imbalance, serves as a complexity measure relevant to iteration bounds for circuit-based augmentation and circuit diameters, as well as the general interpretability of circuits in terms of the underlying application. In this paper, we analyze linear programming formulations of relaxed combinatorial optimization problems to prove two contrasting types of results related to the circuit imbalance.
  On one hand, we identify simple and common constraint structures, in particular arising in graph-theoretic problems, that inherently lead to an exponential circuit imbalance. These constructions show that, in quite general situations, working with the entire set of circuits poses significant challenges for an application of circuit augmentation or the study of circuit diameters.
  On the other hand, through a case study of two classic graph-theoretic problems with exponential imbalance, the vertex graph coloring problem and the maximum weight forest problem, we exhibit the existence of sets and subsets of highly interpretable circuits of (best-case) imbalance 1. These sets correspond to the recoloring of vertices or to the addition or removal of edges, respectively, for example generalizing classic concepts of Kempe dynamics in coloring. Their interpretability in terms of the underlying application facilitates a study of circuit walks in the corresponding polytopes. We prove that a restriction of circuit walks to these sets suffices to not only guarantee reachability of the integral extreme-points of the skeleton, but leads to linear and constant circuit diameter bounds, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05223v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Steffen Borgwardt, Nicholas Crawford, Sean Kafer, Jon Lee, Angela Morrison</dc:creator>
    </item>
    <item>
      <title>Entropic selection for optimal transport on the line with distance cost</title>
      <link>https://arxiv.org/abs/2512.05282</link>
      <description>arXiv:2512.05282v1 Announce Type: new 
Abstract: We study the small-regularisation limit of the entropic optimal transport problem on the line with distance cost. While convergence of entropic minimizers is well understood in the discrete setting and in the case where the cost is continuous and there is a unique optimal transport plan, the question of existence and characterization outside these settings remains largely open. We propose a natural candidate for the limiting object and establish its convergence under mutual singularity of the marginals. For arbitrary marginals, we moreover prove that every limit point of entropic minimizers obeys a structural condition known as weak multiplicativity. The construction of our candidate relies on a decomposition theorem for optimal transport plan that we believe is of independent interest. This article complements the previous work of Di Marino and Louet.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05282v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Armand Ley</dc:creator>
    </item>
    <item>
      <title>Polyak-{\L}ojasiewicz inequality is essentially no more general than strong convexity for $C^2$ functions</title>
      <link>https://arxiv.org/abs/2512.05285</link>
      <description>arXiv:2512.05285v1 Announce Type: new 
Abstract: The Polyak-{\L}ojasiewicz (P{\L}) inequality extends the favorable optimization properties of strongly convex functions to a broader class of functions. In this paper, we show that the richness of the class of P{\L} functions is rooted in the nonsmooth case since sufficient regularity forces them to be essentially strongly convex. More precisely, we prove that if $f$ is a $C^2$ P{\L} function having a bounded set of minimizers, then it has a unique minimizer and is strongly convex on a sublevel set of the form $\{f\leq a\}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05285v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Aziz Ben Nejma</dc:creator>
    </item>
    <item>
      <title>Deep Centralization for the Circumcentered Reflection Method</title>
      <link>https://arxiv.org/abs/2512.05324</link>
      <description>arXiv:2512.05324v1 Announce Type: new 
Abstract: We introduce the extended centralized circumcentered reflection method (ecCRM), a framework for two-set convex feasibility that encompasses the classical centralized CRM (cCRM) of Behling, Bello-Cruz, Iusem and Santos as a special case. Our method replaces the fixed centralization step of cCRM with an admissible operator $T$ and a parameter $\alpha$, allowing control over computational cost and step quality. We show that ecCRM retains global convergence, linear rates under mild regularity, and superlinearity for smooth manifolds. Numerical experiments on large-scale matrix completion indicate that deeper operators can dramatically reduce overall runtime, and tests on high-dimensional ellipsoids show that vanishing step sizes can yield significant acceleration, validating the practical utility of both algorithmic components of ecCRM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05324v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pablo Barros</dc:creator>
    </item>
    <item>
      <title>OpenSQP: A Reconfigurable Open-Source SQP Algorithm in Python for Nonlinear Optimization</title>
      <link>https://arxiv.org/abs/2512.05392</link>
      <description>arXiv:2512.05392v1 Announce Type: new 
Abstract: Sequential quadratic programming (SQP) methods have been remarkably successful in solving a broad range of nonlinear optimization problems. These methods iteratively construct and solve quadratic programming (QP) subproblems to compute directions that converge to a local minimum. While numerous open-source and commercial SQP algorithms are available, their implementations lack the transparency and modularity necessary to adapt and fine-tune them for specific applications or to swap out different modules to create a new optimizer. To address this gap, we present OpenSQP, a modular and reconfigurable SQP algorithm implemented in Python that achieves robust performance comparable to leading algorithms. We implement OpenSQP in a manner that allows users to easily modify or replace components such as merit functions, line search procedures, Hessian approximations, and QP solvers. This flexibility enables the creation of tailored variants of the algorithm for specific needs. To demonstrate reliability, we present numerical results using the standard configuration of OpenSQP that employs a smooth augmented Lagrangian merit function for the line search and a quasi-Newton BFGS method for approximating the Hessians. We benchmark this configuration on a comprehensive set of problems from the CUTEst test suite. The results demonstrate performance that is competitive with proven nonlinear optimization algorithms such as SLSQP, SNOPT, and IPOPT.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05392v1</guid>
      <category>math.OC</category>
      <category>cs.MS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anugrah Jo Joshy, John T. Hwang</dc:creator>
    </item>
    <item>
      <title>Stochastic Zeroth-Order Method for Computing Generalized Rayleigh Quotients</title>
      <link>https://arxiv.org/abs/2512.05520</link>
      <description>arXiv:2512.05520v1 Announce Type: new 
Abstract: The maximization of the (generalized) Rayleigh quotient is a central problem in numerical linear algebra. Conventional algorithms for its computation typically rely on matrix-adjoint products, making them sensitive to errors arising from adjoint mismatches. To address this issue, we introduce a stochastic zeroth-order Riemannian algorithm that maximizes the generalized Rayleigh quotient without requiring adjoint or matrix inverse computations. We provide theoretical convergence guarantees showing that the iterates converge to the set of global maximizers of the (generalized) Rayleigh quotient at a sublinear rate with probability one. Our theoretical results are supported by numerical experiments, which demonstrate the excellent performance of the proposed method compared to state-of-the-art algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05520v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jonas Bresch, Oleh Melnyk, Martin Schoen, Gabriele Steidl</dc:creator>
    </item>
    <item>
      <title>Opportunities for Hybrid Modeling Approaches in Energy Systems optimization</title>
      <link>https://arxiv.org/abs/2512.05585</link>
      <description>arXiv:2512.05585v1 Announce Type: new 
Abstract: This paper surveys the primary computational hurdles of Energy Systems optimization coming from different sources: model-induced complexity, optimization algorithm requirements, and uncertainties handling (both aleatoric and epistemic). Techniques to reduce complexity such as time-series and spatial aggregation, model order reduction, and specialized optimization strategies are reviewed for their effectiveness in balancing computational feasibility and model fidelity. Furthermore, Various uncertainty-management frameworks, including scenario-based approaches, robust optimization, and distributionally robust methods, are reviewed and their limitations in scaling and data requirements are discussed. The potential of hybrid modeling emerges as a key avenue: by fusing mechanistic and machine learning elements, hybrid techniques for modelling and optimization can harness the strengths of both worlds while mitigating their respective drawbacks. The paper highlights several directions for further research to develop advanced methods to tackle the complexity of MES.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05585v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohamed Tahar Mabrouk (IMT Atlantique, UL, LEMTA, GEPEA, GEPEA-OSE), Shri Balaji Padmanabhan (IMT Atlantique - DSEE, GEPEA-OSE), Bruno Lacarri\`ere (IMT Atlantique, GEPEA, GEPEA-OSE, GEPEA, IMT Atlantique, IMT Atlantique - DSEE), Benoit Delinchant (G2Elab-MAGE), Sacha Hodencq (LAPLACE-GENESYS), Xavier Roboam (LAPLACE-GENESYS), Bruno Sareni (LAPLACE-GENESYS), Mathieu Vallee (DTCH)</dc:creator>
    </item>
    <item>
      <title>Density, Determinacy, Duality and a Regularized Moment-SOS Hierarchy</title>
      <link>https://arxiv.org/abs/2512.05612</link>
      <description>arXiv:2512.05612v1 Announce Type: new 
Abstract: The standard moment-sum-of-squares (SOS) hierarchy is a powerful method for solving global polynomial optimization problems. However, its convergence relies on Putinar's Positivstellensatz, which requires the feasible set to satisfy the algebraic Archimedean property. In this paper, we introduce a regularized moment-SOS hierarchy capable of handling problems on unbounded sets or bounded sets violating the Archimedean property. Adopting a functional analysis viewpoint, we rely on the multivariate Carleman condition for measure determinacy rather than algebraic compactness. We prove that finite degree projections of the quadratic module are dense in the cone of positive polynomials with respect to the square norm induced by the measure. Based on these density results, we prove the convergence of a regularized hierarchy without invoking any Positivstellensatz. Furthermore, we propose a penalized formulation of the hierarchy which, combined with Bernstein-Markov inequalities, provides a monotonically non-decreasing sequence of certified lower bounds on the global minimum. The approach is illustrated on several benchmark problems known to be difficult or ill-posed for the standard hierarchy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05612v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Didier Henrion (LAAS-POP)</dc:creator>
    </item>
    <item>
      <title>Quantification of Errors of the Performance Estimators in the Linear-Quantized Precoding Models for Massive MIMO Systems</title>
      <link>https://arxiv.org/abs/2512.05675</link>
      <description>arXiv:2512.05675v1 Announce Type: new 
Abstract: Massive MIMO (Multiple-Input Multiple-Output) is a key enabler for 5G and future wireless systems, boosting channel capacity, energy efficiency, and spectral efficiency. However, high power consumption and hardware costs of Digital-to-Analog Converters (DACs) in massive MIMO create practical challenges. To mitigate these, recent work proposes low-resolution DACs-restricting transmitted signals to finite voltage levels-to cut power and costs. This requires studying quantized precoding: signals are processed via a linear precoding matrix, then quantized by DACs. In this paper, we explore the linear-quantized precoding model and its statistically or asymptotically equivalent variants. We derive error bounds for two key metrics:Signal-to-Interference-plus-Noise Ratio (SINR) and Symbol Error Probability (SEP), based on the linear-quantized model and its equivalent counterparts. We also formulate and analyze the SINR maximization problem in both asymptotic and finite-dimensional scenarios. Our analysis shows that as system dimensions scale, finite-dimensional problem solutions/values converge to their asymptotic equivalents-underscoring the practical value of asymptotic insights with stability guarantees. These findings theoretically support robust precoding design under hardware constraints, enabling efficient massive MIMO implementation with low-resolution DACs. Beyond validating asymptotic predictions in finite regimes, our framework offers practical optimization guidelines for real-world systems, linking theory and applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05675v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jie Zhang, Huifu Xu</dc:creator>
    </item>
    <item>
      <title>$\alpha$-Potential Games for Decentralized Control of Connected and Automated Vehicles</title>
      <link>https://arxiv.org/abs/2512.05712</link>
      <description>arXiv:2512.05712v1 Announce Type: new 
Abstract: Designing scalable and safe control strategies for large populations of connected and automated vehicles (CAVs) requires accounting for strategic interactions among heterogeneous agents under decentralized information. While dynamic games provide a natural modeling framework, computing Nash equilibria (NEs) in large-scale settings remains challenging, and existing mean-field game approximations rely on restrictive assumptions that fail to capture collision avoidance and heterogeneous behaviors. This paper proposes an $\alpha$-potential game framework for decentralized CAV control. We show that computing $\alpha$-NE reduces to solving a decentralized control problem, and derive tight bounds of the parameter $\alpha$ based on interaction intensity and asymmetry. We further develop scalable policy gradient algorithms for computing $\alpha$-NEs using decentralized neural-network policies. Numerical experiments demonstrate that the proposed framework accommodates diverse traffic flow models and effectively captures collision avoidance, obstacle avoidance, and agent heterogeneity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05712v1</guid>
      <category>math.OC</category>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xuan Di, Anran Hu, Zhexin Wang, Yufei Zhang</dc:creator>
    </item>
    <item>
      <title>Taylor Approximation Variance Reduction for Approximation Errors in PDE-constrained Bayesian Inverse Problems</title>
      <link>https://arxiv.org/abs/2512.05723</link>
      <description>arXiv:2512.05723v1 Announce Type: new 
Abstract: In numerous applications, surrogate models are used as a replacement for accurate parameter-to-observable mappings when solving large-scale inverse problems governed by partial differential equations (PDEs). The surrogate model may be a computationally cheaper alternative to the accurate parameter-to-observable mappings and/or may ignore additional unknowns or sources of uncertainty. The Bayesian approximation error (BAE) approach provides a means to account for the induced uncertainties and approximation errors (between the accurate parameter-to-observable mapping and the surrogate). The statistics of these errors are in general unknown a priori, and are thus calculated using Monte Carlo sampling. Although the sampling is typically carried out offline the process can still represent a computational bottleneck. In this work, we develop a scalable computational approach for reducing the costs associated with the sampling stage of the BAE approach. Specifically, we consider the Taylor expansion of the accurate and surrogate forward models with respect to the uncertain parameter fields either as a control variate for variance reduction or as a means to efficiently approximate the mean and covariance of the approximation errors. We propose efficient methods for evaluating the expressions for the mean and covariance of the Taylor approximations based on linear(-ized) PDE solves. Furthermore, the proposed approach is independent of the dimension of the uncertain parameter, depending instead on the intrinsic dimension of the data, ensuring scalability to high-dimensional problems. The potential benefits of the proposed approach are demonstrated for two high-dimensional inverse problems governed by PDE examples, namely for the estimation of a distributed Robin boundary coefficient in a linear diffusion problem, and for a coefficient estimation problem governed by a nonlinear diffusion problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05723v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.CO</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruanui Nicholson, Radoslav Vuchkov, Umberto Villa, Noemi Petra</dc:creator>
    </item>
    <item>
      <title>Modified global finite-time quasi-continuous second-order robust feedback control</title>
      <link>https://arxiv.org/abs/2512.05727</link>
      <description>arXiv:2512.05727v1 Announce Type: new 
Abstract: A non-overshooting quasi-continuous sliding mode control with sub-optimal damping was recently introduced in Ruderman and Efimov (2025) for perturbed second-order systems. The present work proposes an essential modification of the nonlinear control law which (i) allows for a parameterizable control amplitude limitation in a large subset of the initial values, (ii) admits an entire state-space R2 (that was not given in Ruderman and Efimov (2025)) for the finite-time control, and finally (iii) enables for the found analytic solution of the state trajectories in the unperturbed case. The latter allows also for an exact estimation of the finite convergence time, and open an avenue for other potentially interesting analysis of the control properties in the future. For a perturbed case, the solution-based and Lyapunov function-based approaches are developed to show the uniform global asymptotic stability. The proposed robustness and convergence analysis are accompanied by several illustrative numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05727v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Ruderman, Denis Efimov</dc:creator>
    </item>
    <item>
      <title>Distributed Online Randomized Gradient-Free Optimization with Compressed Communication</title>
      <link>https://arxiv.org/abs/2512.05775</link>
      <description>arXiv:2512.05775v1 Announce Type: new 
Abstract: This paper addresses two fundamental challenges in distributed online convex optimization: communication efficiency and optimization under limited feedback. We propose a unified framework named Online Compressed Gradient Tracking (OCGT), which includes two variants: One-point Bandit Feedback (OCGT-BF) and Stochastic Gradient Feedback (OCSGT). The proposed algorithms harness data compression and either gradient-free or stochastic gradient optimization techniques within distributed networks. The proposed framework incorporates a compression scheme with error compensation mechanisms to reduce communication overhead while maintaining convergence guarantees. Unlike traditional approaches that assume perfect communication and full gradient access, OCGT operates effectively under practical constraints by combining gradient-like tracking with one-point or stochastic gradient feedback estimation. We provide a theoretical analysis demonstrating dynamic regret bounds for both variants. Finally, extensive experiments validate that OCGT achieves low dynamic regret while significantly reducing communication requirements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05775v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Longkang Zhu, Xinli Shi, Xiangping Xu, Jinde Cao, Xiangyong Chen</dc:creator>
    </item>
    <item>
      <title>Stochastic Passivity in Stochastic Differential Equations: A Port-Hamiltonian Perspective</title>
      <link>https://arxiv.org/abs/2512.05838</link>
      <description>arXiv:2512.05838v1 Announce Type: new 
Abstract: We extend deterministic port-Hamiltonian systems (PHS) to a stochastic framework by means of stochastic differential equations. As the dissipation inequality plays a crucial role for deterministic PHS, we develop several passivity concepts for stochastic input-state-output systems and characterize these in terms of the parameters of the system. Afterwards, we examine properties of a certain class of linear stochastic systems that can be regarded as an extension of linear deterministic PHS to a stochastic passivity framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05838v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Julia Ackermann, Thomas Kruse, Stefan Tappe</dc:creator>
    </item>
    <item>
      <title>Numerically Reliable Brunovsky Transformations</title>
      <link>https://arxiv.org/abs/2512.05910</link>
      <description>arXiv:2512.05910v1 Announce Type: new 
Abstract: The Brunovsky canonical form provides sparse structural representations that are beneficial for computational optimal control, yet existing methods fail to compute it reliably. We propose a technique that produces Brunovsky transformations with substantially lower construction errors and improved conditioning. A controllable linear system is first reduced to staircase form via an orthogonal similarity transformation. We then derive a simple linear parametrization of the transformations yielding the unique Brunovsky form. Numerical stability is further enhanced by applying a deadbeat gain before computing system matrix powers and by optimizing the linear parameters to minimize condition numbers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05910v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shaohui Yang, Colin N. Jones</dc:creator>
    </item>
    <item>
      <title>Competition, stability, and functionality in excitatory-inhibitory neural circuits</title>
      <link>https://arxiv.org/abs/2512.05252</link>
      <description>arXiv:2512.05252v1 Announce Type: cross 
Abstract: Energy-based models have become a central paradigm for understanding computation and stability in both theoretical neuroscience and machine learning. However, the energetic framework typically relies on symmetry in synaptic or weight matrices - a constraint that excludes biologically realistic systems such as excitatory-inhibitory (E-I) networks. When symmetry is relaxed, the classical notion of a global energy landscape fails, leaving the dynamics of asymmetric neural systems conceptually unanchored. In this work, we extend the energetic framework to asymmetric firing rate networks, revealing an underlying game-theoretic structure for the neural dynamics in which each neuron is an agent that seeks to minimize its own energy. In addition, we exploit rigorous stability principles from network theory to study regulation and balancing of neural activity in E-I networks. We combine the novel game-energetic interpretation and the stability results to revisit standard frameworks in theoretical neuroscience, such as the Wilson-Cowan and lateral inhibition models. These insights allow us to study cortical columns of lateral inhibition microcircuits as contrast enhancer - with the ability to selectively sharpen subtle differences in the environment through hierarchical excitation-inhibition interplay. Our results bridge energetic and game-theoretic views of neural computation, offering a pathway toward the systematic engineering of biologically grounded, dynamically stable neural architectures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05252v1</guid>
      <category>q-bio.NC</category>
      <category>cond-mat.dis-nn</category>
      <category>math.OC</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Simone Betteti, William Retnaraj, Alexander Davydov, Jorge Cort\'es, Francesco Bullo</dc:creator>
    </item>
    <item>
      <title>Non-Convex Federated Optimization under Cost-Aware Client Selection</title>
      <link>https://arxiv.org/abs/2512.05327</link>
      <description>arXiv:2512.05327v1 Announce Type: cross 
Abstract: Different federated optimization algorithms typically employ distinct client-selection strategies: some methods communicate only with a randomly sampled subset of clients at each round, while others need to periodically communicate with all clients or use a hybrid scheme that combines both strategies. However, existing metrics for comparing optimization methods typically do not distinguish between these strategies, which often incur different communication costs in practice. To address this disparity, we introduce a simple and natural model of federated optimization that quantifies communication and local computation complexities. This new model allows for several commonly used client-selection strategies and explicitly associates each with a distinct cost. Within this setting, we propose a new algorithm that achieves the best-known communication and local complexities among existing federated optimization methods for non-convex optimization. This algorithm is based on the inexact composite gradient method with a carefully constructed gradient estimator and a special procedure for solving the auxiliary subproblem at each iteration. The gradient estimator is based on SAGA, a popular variance-reduced gradient estimator. We first derive a new variance bound for it, showing that SAGA can exploit functional similarity. We then introduce the Recursive-Gradient technique as a general way to potentially improve the error bound of a given conditionally unbiased gradient estimator, including both SAGA and SVRG. By applying this technique to SAGA, we obtain a new estimator, RG-SAGA, which has an improved error bound compared to the original one.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05327v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaowen Jiang, Anton Rodomanov, Sebastian U. Stich</dc:creator>
    </item>
    <item>
      <title>Symmetric Linear Dynamical Systems are Learnable from Few Observations</title>
      <link>https://arxiv.org/abs/2512.05337</link>
      <description>arXiv:2512.05337v1 Announce Type: cross 
Abstract: We consider the problem of learning the parameters of a $N$-dimensional stochastic linear dynamics under both full and partial observations from a single trajectory of time $T$. We introduce and analyze a new estimator that achieves a small maximum element-wise error on the recovery of symmetric dynamic matrices using only $T=\mathcal{O}(\log N)$ observations, irrespective of whether the matrix is sparse or dense. This estimator is based on the method of moments and does not rely on problem-specific regularization. This is especially important for applications such as structure discovery.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05337v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Minh Vu, Andrey Y. Lokhov, Marc Vuffray</dc:creator>
    </item>
    <item>
      <title>Normal sub-Riemannian geodesics related to filtrations of Lie algebras</title>
      <link>https://arxiv.org/abs/2512.05553</link>
      <description>arXiv:2512.05553v1 Announce Type: cross 
Abstract: There is a natural way to construct sub-Riemannian structures that depend on $n$ parameters on compact Lie groups. These structures are related to the filtrations of Lie subalgebras $\mathfrak g_0 &lt; \mathfrak g_1 &lt; \mathfrak g_2 &lt; \dots &lt; \mathfrak g_{n-1}&lt;\mathfrak g_n=\mathfrak g=Lie(G)$. In the case where $n=1$, the explicit solution for normal sub-Riemannian geodesics was provided by Agrachev, Brockett, and Jurjdevic. We extend their solution to apply to general chains of Lie subgroups. Additionally, we describe normal geodesic lines of the induced sub-Riemannian structures on homogeneous spaces $G/K$, where $\mathfrak g_0=Lie(K)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05553v1</guid>
      <category>math.DG</category>
      <category>math.OC</category>
      <category>nlin.SI</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bozidar Jovanovic, Tijana Sukilovic, Srdjan Vukmirovic</dc:creator>
    </item>
    <item>
      <title>Measurement-based Initial Point Smoothing and Control Approach to Quantum Memory Systems</title>
      <link>https://arxiv.org/abs/2512.05586</link>
      <description>arXiv:2512.05586v1 Announce Type: cross 
Abstract: This paper is concerned with a quantum memory system for storing quantum information in the form of its initial dynamic variables in the presence of environmental noise. In order to compensate for the deviation from the initial conditions, the classical parameters of the system Hamiltonian are affected by the actuator output of a measurement-based classical controller. The latter uses an observation process produced by a measuring apparatus from the quantum output field of the memory system. The underlying system is modelled as an open quantum harmonic oscillator whose Heisenberg evolution is governed by linear Hudson-Parthasarathy quantum stochastic differential equations. The controller is organised as a classical linear time-varying system, so that the resulting closed-loop system has quantum and classical dynamic variables. We apply linear-quadratic-Gaussian control and fixed-point smoothing at the level of the first two moments and consider controllers with a separation structure which involve a continuously updated estimate for the initial quantum variables. The initial-point smoother is used for actuator signal formation so as to minimise the sum of a mean-square deviation of the quantum memory system variables at a given time horizon from their initial values and an integral quadratic penalty on the control signal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05586v1</guid>
      <category>quant-ph</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Igor G. Vladimirov, Ian R. Petersen, Guodong Shi</dc:creator>
    </item>
    <item>
      <title>Feedback stabilization of some fourth-order nonlinear parabolic equations with saturated controlsEQUATIONS WITH SATURATED CONTROLS</title>
      <link>https://arxiv.org/abs/2512.05606</link>
      <description>arXiv:2512.05606v1 Announce Type: cross 
Abstract: In this work, we analyze the internal and boundary stabilization of the Cahn-Hilliard and Kuramoto-Sivashinsky equations under saturated feedback control. We conduct our study through the spectral analysis of the associated linear operator. We identify a finite number of eigenvalues related to the unstable part of the system and then design a stabilization strategy based on modal decomposition, linear matrix inequalities (LMIs), and geometric conditions on the saturation function. Local exponential stabilization in $H^{2}$ is established.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05606v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Patricio Guzm\'an (SPHINX, IECL), Felipe Labra (SPHINX, IECL), Hugo Parada (SPHINX, IECL)</dc:creator>
    </item>
    <item>
      <title>BalLOT: Balanced $k$-means clustering with optimal transport</title>
      <link>https://arxiv.org/abs/2512.05926</link>
      <description>arXiv:2512.05926v1 Announce Type: cross 
Abstract: We consider the fundamental problem of balanced $k$-means clustering. In particular, we introduce an optimal transport approach to alternating minimization called BalLOT, and we show that it delivers a fast and effective solution to this problem. We establish this with a variety of numerical experiments before proving several theoretical guarantees. First, we prove that for generic data, BalLOT produces integral couplings at each step. Next, we perform a landscape analysis to provide theoretical guarantees for both exact and partial recoveries of planted clusters under the stochastic ball model. Finally, we propose initialization schemes that achieve one-step recovery of planted clusters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05926v1</guid>
      <category>stat.ML</category>
      <category>cs.DS</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wenyan Luo, Dustin G. Mixon</dc:creator>
    </item>
    <item>
      <title>Median Clipping for Zeroth-order Non-Smooth Convex Optimization and Multi-Armed Bandit Problem with Heavy-tailed Symmetric Noise</title>
      <link>https://arxiv.org/abs/2402.02461</link>
      <description>arXiv:2402.02461v5 Announce Type: replace 
Abstract: In this paper, we consider non-smooth convex optimization with a zeroth-order oracle corrupted by symmetric stochastic noise. Unlike the existing high-probability results requiring the noise to have bounded $\kappa$-th moment with $\kappa \in (1,2]$, our results allow even heavier noise with any $\kappa &gt; 0$, e.g., the noise distribution can have unbounded expectation. Our convergence rates match the best-known ones for the case of the bounded variance, namely, to achieve function accuracy $\varepsilon$ our methods with Lipschitz oracle require $\tilde{O}(d^2\varepsilon^{-2})$ iterations for any $\kappa &gt; 0$. We build the median gradient estimate with bounded second moment as the mini-batched median of the sampled gradient differences. We apply this technique to the stochastic multi-armed bandit problem with heavy-tailed distribution of rewards and achieve $\tilde{O}(\sqrt{dT})$ regret. We demonstrate the performance of our zeroth-order and MAB algorithms for various $\kappa \in (0,2]$ on synthetic and real-world data. Our methods do not lose to SOTA approaches and dramatically outperform them for $\kappa \leq 1$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.02461v5</guid>
      <category>math.OC</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nikita Kornilov, Yuriy Dorn, Aleksandr Lobanov, Nikolay Kutuzov, Innokentiy Shibaev, Eduard Gorbunov, Alexander Nazin, Alexander Gasnikov</dc:creator>
    </item>
    <item>
      <title>A Parallel-in-Time Multigrid Preconditioner for Optimal Control</title>
      <link>https://arxiv.org/abs/2405.04808</link>
      <description>arXiv:2405.04808v2 Announce Type: replace 
Abstract: We develop a parallel-in-time multigrid preconditioner for augmented systems. These saddle-point systems are foundational to numerical optimization. Our preconditioner, when paired with a suitable optimization method, accelerates the solution of optimal control problems. We construct the preconditioner by introducing virtual interface variables that enable time-domain decomposition. After permuting the resulting augmented system into block tridiagonal form, we develop a geometric multigrid scheme with a block Jacobi smoother, which parallelizes trivially in time. As the coarse grid solver we use GMRES preconditioned with a symmetric Gauss-Seidel iteration. We use the multigrid scheme to precondition a flexible GMRES [1] iteration for the solution of the augmented system. We combine our preconditioner with the matrix-free sequential quadratic programming (SQP) algorithm [2] to solve optimal control problems involving the van der Pol oscillator and the viscous Burgers' equation. We find that the preconditioner is remarkably effective when the problems are suitably scaled.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04808v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Radoslav Vuchkov, Eric C. Cyr, Aurya Javeed, Denis Ridzal</dc:creator>
    </item>
    <item>
      <title>Curves of Minimax Spirality</title>
      <link>https://arxiv.org/abs/2409.08644</link>
      <description>arXiv:2409.08644v2 Announce Type: replace 
Abstract: We study the problem of finding curves of minimum pointwise-maximum arc-length derivative of curvature, here simply called curves of minimax spirality, among planar curves of fixed length with prescribed endpoints and tangents at the endpoints. We consider the case when simple bounds (constraints) are also imposed on the curvature along the curve. The curvature at the endpoints may or may not be specified. We prove via optimal control theory that the optimal curve is some concatenation of Euler spiral arcs, circular arcs, and straight line segments. When the curvature is not constrained (or when the curvature constraint does not become active), an optimal curve is only made up of a concatenation of Euler spiral arcs, unless the oriented endpoints lie in a line segment or a circular arc of the prescribed length, in which case the whole curve is either a straight line segment or a circular arc segment, respectively. We propose numerical methods and illustrate these methods and the results by means of three example problems of finding such curves.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08644v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>C. Yal\c{c}{\i}n Kaya, Lyle Noakes, Philip Schrader</dc:creator>
    </item>
    <item>
      <title>A Linear Convergence Result for the Jacobi-Proximal Alternating Direction Method of Multipliers</title>
      <link>https://arxiv.org/abs/2503.18601</link>
      <description>arXiv:2503.18601v4 Announce Type: replace 
Abstract: In this paper, we analyze the convergence rate of the Jacobi-Proximal Alternating Direction Method of Multipliers (ADMM) initially introduced by Deng et al. for the block-structured optimization problem with linear constraint. The algorithm is well-suited for parallel implementation and widely used for large-scale multi-block optimization problems. While the o(1/k) convergence of the Jacobi-Proximal ADMM for the case $N \geq 3$ has been well-established in the previous work, to the best of our knowledge, its linear convergence for $N \geq 3$ remains unproven. We establish the linear convergence of the algorithm when the cost functions are strongly convex and smooth. Numerical experiments are presented supporting the convergence result.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.18601v4</guid>
      <category>math.OC</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hyelin Choi, Woocheol Choi</dc:creator>
    </item>
    <item>
      <title>Risk-Aware Adaptive Control Barrier Functions for Safe Control of Nonlinear Systems under Stochastic Uncertainty</title>
      <link>https://arxiv.org/abs/2503.19205</link>
      <description>arXiv:2503.19205v5 Announce Type: replace 
Abstract: This paper addresses the challenge of ensuring safety in stochastic control systems with high-relative-degree constraints, while maintaining feasibility and mitigating conservatism in risk evaluation. Control Barrier Functions (CBFs) provide an effective framework for enforcing safety constraints in nonlinear systems. However, existing methods struggle with feasibility issues and multi-step uncertainties. To address these challenges, we introduce Risk-aware Adaptive CBFs (RACBFs), which integrate Discrete-time Auxiliary-Variable adaptive CBFs (DAVCBFs) with coherent risk measures. DAVCBFs introduce auxiliary variables to improve the feasibility of the optimal control problem, while RACBFs incorporate risk-aware formulations to balance safety and risk evaluation performance. By extending discrete-time high-order CBF constraints over multiple steps, RACBFs effectively handle multi-step uncertainties that propagate through the system dynamics. We demonstrate the effectiveness of our approach on a stochastic unicycle system, showing that RACBFs maintain safety and feasibility while reducing unnecessary conservatism compared to standard robust formulations of discrete-time CBF methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.19205v5</guid>
      <category>math.OC</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuo Liu, Calin A. Belta</dc:creator>
    </item>
    <item>
      <title>ICNN-enhanced 2SP: Leveraging input convex neural networks for solving two-stage stochastic programming</title>
      <link>https://arxiv.org/abs/2505.05261</link>
      <description>arXiv:2505.05261v2 Announce Type: replace 
Abstract: Two-stage stochastic programming (2SP) offers a basic framework for modelling decision-making under uncertainty, yet scalability remains a challenge due to the computational complexity of recourse function evaluation. Existing learning-based methods like Neural Two-Stage Stochastic Programming (Neur2SP) employ neural networks (NNs) as recourse function surrogates but rely on computationally intensive mixed-integer programming (MIP) formulations. We propose ICNN-enhanced 2SP, a method that leverages Input Convex Neural Networks (ICNNs) to exploit linear programming (LP) representability in convex 2SP problems. By architecturally enforcing convexity and enabling exact inference through LP, our approach eliminates the need for integer variables inherent to the conventional MIP-based formulation while retaining an exact embedding of the ICNN surrogate within the 2SP framework. This results in a more computationally efficient alternative, and we show that good solution quality can be maintained. Comprehensive experiments reveal that ICNNs incur only marginally longer training times while achieving validation accuracy on par with their standard NN counterparts. Across benchmark problems, ICNN-enhanced 2SP often exhibits considerably faster solution times than the MIP-based formulations while preserving solution quality, with these advantages becoming significantly more pronounced as problem scale increases. For the most challenging instances, the method achieves speedups of up to 100$\times$ and solution quality superior to MIP-based formulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.05261v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yu Liu, Fabricio Oliveira, Jan Kronqvist</dc:creator>
    </item>
    <item>
      <title>PDPO: Parametric Density Path Optimization</title>
      <link>https://arxiv.org/abs/2505.18473</link>
      <description>arXiv:2505.18473v3 Announce Type: replace 
Abstract: We introduce Parametric Density Path Optimization (PDPO), a novel method for computing action-minimizing paths between probability densities. The core idea is to represent the target probability path as the pushforward of a reference density through a parametric map, transforming the original infinite-dimensional optimization over densities to a finite-dimensional one over the parameters of the map. We derive a static formulation of the dynamic problem of action minimization and propose cubic spline interpolation of the path in parameter space to solve the static problem. Theoretically, we establish an error bound of the action under proper assumptions on the regularity of the parameter path. Empirically, we find that using 3-5 control points of the spline interpolation suffices to accurately resolve both multimodal and high-dimensional problems. We demonstrate that PDPO can flexibly accommodate a wide range of potential terms, including those modeling obstacles, mean-field interactions, stochastic control, and higher-order dynamics. Our method outperforms existing state-of-the-art approaches in benchmark tasks, demonstrating superior computational efficiency and solution quality. The source code will be publically available after the revision process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18473v3</guid>
      <category>math.OC</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>NeurIPS 2025</arxiv:journal_reference>
      <dc:creator>Sebastian Gutierrez Hernandez, Peng Chen, Haomin Zhou</dc:creator>
    </item>
    <item>
      <title>Computational Hardness of Static Distributionally Robust Markov Decision Processes</title>
      <link>https://arxiv.org/abs/2511.02224</link>
      <description>arXiv:2511.02224v3 Announce Type: replace 
Abstract: We present some hardness results on finding the optimal policy for the static formulation of distributionally robust Markov decision processes. We construct problem instances such that when the considered policy class is Markovian and non-randomized, finding the optimal policy is NP-hard, and when the considered policy class is Markovian and randomized, the robust value function possesses sub-optimal strict local minima. The considered hard instances involve an ambiguity set with only two transition kernels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.02224v3</guid>
      <category>math.OC</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Yan Li</dc:creator>
    </item>
    <item>
      <title>A Note on Optimal Product Pricing</title>
      <link>https://arxiv.org/abs/2511.06156</link>
      <description>arXiv:2511.06156v3 Announce Type: replace 
Abstract: We consider the problem of choosing prices of a set of products so as to maximize profit, taking into account self-elasticity and cross-elasticity, subject to constraints on the prices. We show that this problem can be formulated as maximizing the sum of a convex and concave function. We compare three methods for finding a locally optimal approximate solution. The first is based on the convex-concave procedure, and involves solving a short sequence of convex problems. Another one uses a custom minorize-maximize method, and involves solving a sequence of quadratic programs. The final method is to use a general purpose nonlinear programming method. In numerical examples all three converge reliably to the same local maximum, independent of the starting prices, leading us to believe that the prices found are likely globally optimal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06156v3</guid>
      <category>math.OC</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maximilian Schaller, Stephen Boyd</dc:creator>
    </item>
    <item>
      <title>TSP integrality gap via 2-edge-connected multisubgraph problem under coincident IP optima</title>
      <link>https://arxiv.org/abs/2511.11215</link>
      <description>arXiv:2511.11215v2 Announce Type: replace 
Abstract: Determining the integrality gap of the linear programming (LP) relaxation of the metric traveling salesman problem (TSP) remains a long-standing open problem. We introduce a transfer principle: when the integer optimum of the 2-edge-connected multisubgraph problem (2ECM) is a unique Hamiltonian cycle $T$, any $\alpha$-approximation algorithm for 2ECM that outputs a Hamiltonian cycle yields an $\alpha$-approximation for TSP. We further develop a cut-margin stability framework that certifies $T$ as the unique integer optimum for both problems and is stable under $\ell_\infty$-bounded perturbations. We show that, if instances exist where the 2ECM has both a unique Hamiltonian cycle integer optimum and a half-integral LP solution, then the TSP integrality gap is at most 4/3 by the algorithm of Boyd et al. (SIAM Journal on Discrete Mathematics 36:1730--1747, 2022). Constructing such instances remains an open problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.11215v2</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Toshiaki Yamanaka</dc:creator>
    </item>
    <item>
      <title>Wasserstein Distributionally Robust Nash Equilibrium Seeking with Heterogeneous Data: A Lagrangian Approach</title>
      <link>https://arxiv.org/abs/2511.14048</link>
      <description>arXiv:2511.14048v2 Announce Type: replace 
Abstract: We study a class of distributionally robust games where agents are allowed to heterogeneously choose their risk aversion with respect to distributional shifts of the uncertainty. In our formulation, heterogeneous Wasserstein ball constraints on each distribution are enforced through a penalty function leveraging a Lagrangian formulation. We then formulate the distributionally robust Nash equilibrium problem and show that under certain assumptions it is equivalent to a finite-dimensional variational inequality problem with a strongly monotone mapping. We then design an approximate Nash equilibrium seeking algorithm and prove convergence of the average regret to a quantity that diminishes with the number of iterations, thus learning the desired equilibrium up to an a priori specified accuracy. Numerical simulations corroborate our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14048v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zifan Wang, Georgios Pantazis, Sergio Grammatico, Michael M. Zavlanos, Karl H. Johansson</dc:creator>
    </item>
    <item>
      <title>Accelerated ADMM: Automated Parameter Tuning and Improved Linear Convergence</title>
      <link>https://arxiv.org/abs/2511.21210</link>
      <description>arXiv:2511.21210v2 Announce Type: replace 
Abstract: This work studies the linear convergence of an accelerated scheme of the Alternating Direction Method of Multipliers (ADMM) for strongly convex and Lipschitz-smooth problems. We use the methodology of expressing the accelerated ADMM as a Lur'e system, i.e., an interconnection of a linear dynamical system in feedback with a slope-restricted operator, and we use Integral Quadratic Constraints to establish linear convergence. In addition, we propose several parameter tuning heuristics and their impact on the convergence rate through numerical analyses. Our new bounds show improved linear convergence rates compared to the vanilla algorithm and previous proposed accelerated variants, which is also empirically validated on a LASSO regression benchmark.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.21210v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Meisam Tavakoli, Fabian Jakob, Guido Carnevale, Giuseppe Notarstefano, Andrea Iannelli</dc:creator>
    </item>
    <item>
      <title>Implicit Bias of Spectral Descent and Muon on Multiclass Separable Data</title>
      <link>https://arxiv.org/abs/2502.04664</link>
      <description>arXiv:2502.04664v4 Announce Type: replace-cross 
Abstract: Different gradient-based methods for optimizing overparameterized models can all achieve zero training error yet converge to distinctly different solutions inducing different generalization properties. We provide the first complete characterization of implicit optimization bias for p-norm normalized steepest descent (NSD) and momentum steepest descent (NMD) algorithms in multi-class linear classification with cross-entropy loss. Our key theoretical contribution is proving that these algorithms converge to solutions maximizing the margin with respect to the classifier matrix's p-norm, with established convergence rates. These results encompass important special cases including Spectral Descent and Muon, which we show converge to max-margin solutions with respect to the spectral norm. A key insight of our contribution is that the analysis of general entry-wise and Schatten p-norms can be reduced to the analysis of NSD/NMD with max-norm by exploiting a natural ordering property between all p-norms relative to the max-norm and its dual sum-norm. For the specific case of descent with respect to the max-norm, we further extend our analysis to include preconditioning, showing that Adam converges to the matrix's max-norm solution. Our results demonstrate that the multi-class linear setting, which is inherently richer than the binary counterpart, provides the most transparent framework for studying implicit biases of matrix-parameter optimization algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04664v4</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chen Fan, Mark Schmidt, Christos Thrampoulidis</dc:creator>
    </item>
    <item>
      <title>Stochastic Orthogonal Regularization for deep projective priors</title>
      <link>https://arxiv.org/abs/2505.13078</link>
      <description>arXiv:2505.13078v3 Announce Type: replace-cross 
Abstract: Many crucial tasks of image processing and computer vision are formulated as inverse problems. Thus, it is of great importance to design fast and robust algorithms to solve these problems. In this paper, we focus on generalized projected gradient descent (GPGD) algorithms where generalized projections are realized with learned neural networks and provide state-of-the-art results for imaging inverse problems. Indeed, neural networks allow for projections onto unknown low-dimensional sets that model complex data, such as images. We call these projections deep projective priors. In generic settings, when the orthogonal projection onto a lowdimensional model set is used, it has been shown, under a restricted isometry assumption, that the corresponding orthogonal PGD converges with a linear rate, yielding near-optimal convergence (within the class of GPGD methods) in the classical case of sparse recovery. However, for deep projective priors trained with classical mean squared error losses, there is little guarantee that the hypotheses for linear convergence are satisfied. In this paper, we propose a stochastic orthogonal regularization of the training loss for deep projective priors. This regularization is motivated by our theoretical results: a sufficiently good approximation of the orthogonal projection guarantees linear stable recovery with performance close to orthogonal PGD. We show experimentally, using two different deep projective priors (based on autoencoders and on denoising networks), that our stochastic orthogonal regularization yields projections that improve convergence speed and robustness of GPGD in challenging inverse problem settings, in accordance with our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13078v3</guid>
      <category>eess.IV</category>
      <category>cs.NE</category>
      <category>math.OC</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ali Joundi (UB), Yann Traonmilin (UB), Alasdair Newson (ISIR)</dc:creator>
    </item>
    <item>
      <title>Communication-Aware Dissipative Control for Networks of Heterogeneous Nonlinear Agents</title>
      <link>https://arxiv.org/abs/2511.21962</link>
      <description>arXiv:2511.21962v2 Announce Type: replace-cross 
Abstract: Communication-aware control is essential to reduce costs and complexity in large-scale networks. However, it is challenging to simultaneously determine a sparse communication topology and achieve high performance and robustness. This work achieves all three objectives through dissipativity-based, sparsity-promoting controller synthesis. The approach identifies an optimal sparse structure using either weighted l1 penalties or alternating direction methods of multipliers (ADMM) with a cardinality term, and iteratively solves a convexified version of the NP hard structured optimal control problem. The proposed methods are demonstrated on heterogeneous networks with uncertain and unstable agents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.21962v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ingyu Jang, Leila J. Bridgeman</dc:creator>
    </item>
    <item>
      <title>Accelerating shape optimization by deep neural networks with on-the-fly determined architecture</title>
      <link>https://arxiv.org/abs/2512.03555</link>
      <description>arXiv:2512.03555v2 Announce Type: replace-cross 
Abstract: In component shape optimization, the component properties are often evaluated by computationally expensive simulations. Such optimization becomes unfeasible when it is focused on a global search requiring thousands of simulations to be evaluated. Here, we present a viable global shape optimization methodology based on multi-objective evolutionary algorithms accelerated by deep neural networks (DNNs). Our methodology alternates between evaluating simulations and utilizing the generated data to train DNNs with various architectures. When a suitable DNN architecture is identified, the DNN replaces the simulation in the rest of the global search. Our methodology was tested on five ZDT benchmark functions, showing itself at the level of and sometimes more flexible than other state-of-the-art acceleration approaches. Then, it was applied to a real-life optimization problem, namely the shape optimization of a single-phase ejector. Compared with a non-accelerated methodology, ours was able to save weeks of CPU time in solving this problem. To experimentally confirm the performance of the optimized ejector shapes, four of them were 3D printed and tested on the lab scale confirming the predicted performance. This suggests that our methodology could be used for acceleration of other real-life shape optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.03555v2</guid>
      <category>cs.CE</category>
      <category>math.OC</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lucie Kub\'i\v{c}kov\'a, On\v{r}ej Gebousk\'y, Jan Haidl, Martin Isoz</dc:creator>
    </item>
    <item>
      <title>Convergence for Discrete Parameter Update Schemes</title>
      <link>https://arxiv.org/abs/2512.04051</link>
      <description>arXiv:2512.04051v2 Announce Type: replace-cross 
Abstract: Modern deep learning models require immense computational resources, motivating research into low-precision training. Quantised training addresses this by representing training components in low-bit integers, but typically relies on discretising real-valued updates. We introduce an alternative approach where the update rule itself is discrete, avoiding the quantisation of continuous updates by design. We establish convergence guarantees for a general class of such discrete schemes, and present a multinomial update rule as a concrete example, supported by empirical evaluation. This perspective opens new avenues for efficient training, particularly for models with inherently discrete structure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.04051v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Paul Wilson, Fabio Zanasi, George Constantinides</dc:creator>
    </item>
    <item>
      <title>Optimal cost for the null controllability of the Stokes system with controls having $n-1$ components and applications</title>
      <link>https://arxiv.org/abs/2512.04721</link>
      <description>arXiv:2512.04721v2 Announce Type: replace-cross 
Abstract: In this work, we investigate the optimal cost of null controllability for the $n$-dimensional Stokes system when the control acts on $n-1$ scalar components. We establish a novel spectral estimate for low frequencies of the Stokes operator, involving solely $n-1$ components, and use it to show that the cost of controllability with controls having $n-1$ components remains of the same order in time as in the case of controls with $n$ components, namely $O(e^{C/T})$, i.e. the cost of null controllability is not affected by the absence of one component of the control. We also give several applications of our results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.04721v2</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Mon, 08 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Felipe W. Chaves-Silva, Marcos G. Ferreira-Silva, Diego A. Souza</dc:creator>
    </item>
  </channel>
</rss>
