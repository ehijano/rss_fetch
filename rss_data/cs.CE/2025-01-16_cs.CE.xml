<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CE</link>
    <description>cs.CE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 17 Jan 2025 02:33:49 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Dynamic Portfolio Optimization via Augmented DDPG with Quantum Price Levels-Based Trading Strategy</title>
      <link>https://arxiv.org/abs/2501.08528</link>
      <description>arXiv:2501.08528v1 Announce Type: new 
Abstract: With the development of deep learning, Dynamic Portfolio Optimization (DPO) problem has received a lot of attention in recent years, not only in the field of finance but also in the field of deep learning. Some advanced research in recent years has proposed the application of Deep Reinforcement Learning (DRL) to the DPO problem, which demonstrated to be more advantageous than supervised learning in solving the DPO problem. However, there are still certain unsolved issues: 1) DRL algorithms usually have the problems of slow learning speed and high sample complexity, which is especially problematic when dealing with complex financial data. 2) researchers use DRL simply for the purpose of obtaining high returns, but pay little attention to the problem of risk control and trading strategy, which will affect the stability of model returns. In order to address these issues, in this study we revamped the intrinsic structure of the model based on the Deep Deterministic Policy Gradient (DDPG) and proposed the Augmented DDPG model. Besides, we also proposed an innovative risk control strategy based on Quantum Price Levels (QPLs) derived from Quantum Finance Theory (QFT). Our experimental results revealed that our model has better profitability as well as risk control ability with less sample complexity in the DPO problem compared to the baseline models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08528v1</guid>
      <category>cs.CE</category>
      <category>cs.AI</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/IJCNN54540.2023.10191785</arxiv:DOI>
      <arxiv:journal_reference>Proceedings of the 2023 International Joint Conference on Neural Networks (IJCNN), pp. 1-8, 2023</arxiv:journal_reference>
      <dc:creator>Runsheng Lin, Zihan Xing, Mingze Ma, Raymond S. T. Lee</dc:creator>
    </item>
    <item>
      <title>Research on stock price forecast of general electric based on mixed CNN-LSTM model</title>
      <link>https://arxiv.org/abs/2501.08539</link>
      <description>arXiv:2501.08539v1 Announce Type: new 
Abstract: Accurate stock price prediction is crucial for investors and financial institutions, yet the complexity of the stock market makes it highly challenging. This study aims to construct an effective model to enhance the prediction ability of General Electric's stock price trend. The CNN - LSTM model is adopted, combining the feature extraction ability of CNN with the long - term dependency handling ability of LSTM, and the Adam optimizer is used to adjust the parameters. In the data preparation stage, historical trading data of General Electric's stock is collected. After cleaning, handling missing values, and feature engineering, features with strong correlations to the closing price are selected and dimensionality reduction is performed. During model training, the data is divided into training, validation, and testing sets in a ratio of 7:2:1. The Stochastic Gradient Descent algorithm is used with a dynamic learning rate adjustment and L2 regularization, and the Mean Squared Error is used as the loss function, evaluated by variance, R - squared score, and maximum error. Experimental results show that the model loss decreases steadily, and the predicted values align well with the actual values, providing a powerful tool for investment decisions. However, the model's performance in real - time and extreme market conditions remains to be tested, and future improvements could consider incorporating more data sources.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08539v1</guid>
      <category>cs.CE</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zi-xi Hu, Bao Shen, Yiwen Hu, Chen Zhao</dc:creator>
    </item>
    <item>
      <title>Heat transfer simulation of window frames with SPHinXsys</title>
      <link>https://arxiv.org/abs/2501.08795</link>
      <description>arXiv:2501.08795v1 Announce Type: new 
Abstract: Maintaining a comfortable temperature inside a building requires appropriate thermal insulation of windows, which can be optimised iteratively with numerical simulation. Smoothed particle hydrodynamics(SPH) is a fully Lagrangian method widely used for simulating multi-physics applications with high computational efficiency and accuracy. It is advantageous in physically coupled problems such as heat-fluid-solid or any other type of physically coupled simulations. The focus of this study is to simulate the heat transfer process in various window frames under convective boundary conditions according to ISO10077-2:2012. This paper demonstrates the accuracy and compatibility of SPH when dealing with heat transfer problems, which ensures further development of thermal coupling with other physical fields. The results and methods used in this paper provide some guidance on how to properly handle heat transfer simulations using SPH, which can be extended to multi-physics coupled simulations in the future.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08795v1</guid>
      <category>cs.CE</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haotian Ji, Dong Wu, Chi Zhang, Xiangyu Hu</dc:creator>
    </item>
    <item>
      <title>Operator Learning for Reconstructing Flow Fields from Sparse Measurements: an Energy Transformer Approach</title>
      <link>https://arxiv.org/abs/2501.08339</link>
      <description>arXiv:2501.08339v1 Announce Type: cross 
Abstract: Machine learning methods have shown great success in various scientific areas, including fluid mechanics. However, reconstruction problems, where full velocity fields must be recovered from partial observations, remain challenging. In this paper, we propose a novel operator learning framework for solving reconstruction problems by using the Energy Transformer (ET), an architecture inspired by associative memory models. We formulate reconstruction as a mapping from incomplete observed data to full reconstructed fields. The method is validated on three fluid mechanics examples using diverse types of data: (1) unsteady 2D vortex street in flow past a cylinder using simulation data; (2) high-speed under-expanded impinging supersonic jets impingement using Schlieren imaging; and (3) 3D turbulent jet flow using particle tracking. The results demonstrate the ability of ET to accurately reconstruct complex flow fields from highly incomplete data (90\% missing), even for noisy experimental measurements, with fast training and inference on a single GPU. This work provides a promising new direction for tackling reconstruction problems in fluid mechanics and other areas in mechanics, geophysics, weather prediction, and beyond.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08339v1</guid>
      <category>physics.flu-dyn</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qian Zhang, Dmitry Krotov, George Em Karniadakis</dc:creator>
    </item>
    <item>
      <title>GRAPPA - A Hybrid Graph Neural Network for Predicting Pure Component Vapor Pressures</title>
      <link>https://arxiv.org/abs/2501.08729</link>
      <description>arXiv:2501.08729v1 Announce Type: cross 
Abstract: Although the pure component vapor pressure is one of the most important properties for designing chemical processes, no broadly applicable, sufficiently accurate, and open-source prediction method has been available. To overcome this, we have developed GRAPPA - a hybrid graph neural network for predicting vapor pressures of pure components. GRAPPA enables the prediction of the vapor pressure curve of basically any organic molecule, requiring only the molecular structure as input. The new model consists of three parts: A graph attention network for the message passing step, a pooling function that captures long-range interactions, and a prediction head that yields the component-specific parameters of the Antoine equation, from which the vapor pressure can readily and consistently be calculated for any temperature. We have trained and evaluated GRAPPA on experimental vapor pressure data of almost 25,000 pure components. We found excellent prediction accuracy for unseen components, outperforming state-of-the-art group contribution methods and other machine learning approaches in applicability and accuracy. The trained model and its code are fully disclosed, and GRAPPA is directly applicable via the interactive website ml-prop.mv.rptu.de.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08729v1</guid>
      <category>cs.LG</category>
      <category>cs.CE</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marco Hoffmann, Hans Hasse, Fabian Jirasek</dc:creator>
    </item>
    <item>
      <title>SimLOB: Learning Representations of Limited Order Book for Financial Market Simulation</title>
      <link>https://arxiv.org/abs/2406.19396</link>
      <description>arXiv:2406.19396v3 Announce Type: replace 
Abstract: Financial market simulation (FMS) serves as a promising tool for understanding market anomalies and the underlying trading behaviors. To ensure high-fidelity simulations, it is crucial to calibrate the FMS model for generating data closely resembling the observed market data. Previous efforts primarily focused on calibrating the mid-price data, leading to essential information loss of the market activities and thus biasing the calibrated model. The Limit Order Book (LOB) data is the fundamental data fully capturing the market micro-structure and is adopted by worldwide exchanges. However, LOB is not applicable to existing calibration objective functions due to its tabular structure not suitable for the vectorized input requirement. This paper proposes to explicitly learn the vectorized representations of LOB with a Transformer-based autoencoder. Then the latent vector, which captures the major information of LOB, can be applied for calibration. Extensive experiments show that the learned latent representation not only preserves the non-linear auto-correlation in the temporal axis, but the precedence between successive price levels of LOB. Besides, it is verified that the performance of the representation learning stage is consistent with the downstream calibration tasks. Thus, this work also progresses the FMS on LOB data, for the first time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19396v3</guid>
      <category>cs.CE</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuanzhe Li, Yue Wu, Muyao Zhong, Shengcai Liu, Peng Yang</dc:creator>
    </item>
    <item>
      <title>A Discrete-sequence Dataset for Evaluating Online Unsupervised Anomaly Detection Approaches for Multivariate Time Series</title>
      <link>https://arxiv.org/abs/2411.13951</link>
      <description>arXiv:2411.13951v3 Announce Type: replace-cross 
Abstract: Benchmarking anomaly detection approaches for multivariate time series is challenging due to the lack of high-quality datasets. Current publicly available datasets are too small, not diverse and feature trivial anomalies, which hinders measurable progress in this research area. We propose a solution: a diverse, extensive, and non-trivial dataset generated via state-of-the-art simulation tools that reflects realistic behaviour of an automotive powertrain, including its multivariate, dynamic and variable-state properties. To cater for both unsupervised and semi-supervised anomaly detection settings, as well as time series generation and forecasting, we make different versions of the dataset available, where training and test subsets are offered in contaminated and clean versions, depending on the task. We also provide baseline results from a small selection of approaches based on deterministic and variational autoencoders, as well as a non-parametric approach. As expected, the baseline experimentation shows that the approaches trained on the semi-supervised version of the dataset outperform their unsupervised counterparts, highlighting a need for approaches more robust to contaminated training data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.13951v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lucas Correia, Jan-Christoph Goos, Thomas B\"ack, Anna V. Kononova</dc:creator>
    </item>
    <item>
      <title>Data-driven inventory management for new products: A warm-start and adjusted Dyna-$Q$ approach</title>
      <link>https://arxiv.org/abs/2501.08109</link>
      <description>arXiv:2501.08109v2 Announce Type: replace-cross 
Abstract: In this paper, we propose a novel reinforcement learning algorithm for inventory management of newly launched products with no or limited historical demand information. The algorithm follows the classic Dyna-$Q$ structure, balancing the model-based and model-free approaches, while accelerating the training process of Dyna-$Q$ and mitigating the model discrepancy generated by the model-based feedback. Warm-start information from the demand data of existing similar products can be incorporated into the algorithm to further stabilize the early-stage training and reduce the variance of the estimated optimal policy. Our approach is validated through a case study of bakery inventory management with real data. The adjusted Dyna-$Q$ shows up to a 23.7% reduction in average daily cost compared with $Q$-learning, and up to a 77.5% reduction in training time within the same horizon compared with classic Dyna-$Q$. By incorporating the warm-start information, it can be found that the adjusted Dyna-$Q$ has the lowest total cost, lowest variance in total cost, and relatively low shortage percentages among all the algorithms under a 30-day testing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08109v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xinye Qu, Longxiao Liu, Wenjie Huang</dc:creator>
    </item>
    <item>
      <title>A Multi-Modal AI Copilot for Single-Cell Analysis with Instruction Following</title>
      <link>https://arxiv.org/abs/2501.08187</link>
      <description>arXiv:2501.08187v2 Announce Type: replace-cross 
Abstract: Large language models excel at interpreting complex natural language instructions, enabling them to perform a wide range of tasks. In the life sciences, single-cell RNA sequencing (scRNA-seq) data serves as the "language of cellular biology", capturing intricate gene expression patterns at the single-cell level. However, interacting with this "language" through conventional tools is often inefficient and unintuitive, posing challenges for researchers. To address these limitations, we present InstructCell, a multi-modal AI copilot that leverages natural language as a medium for more direct and flexible single-cell analysis. We construct a comprehensive multi-modal instruction dataset that pairs text-based instructions with scRNA-seq profiles from diverse tissues and species. Building on this, we develop a multi-modal cell language architecture capable of simultaneously interpreting and processing both modalities. InstructCell empowers researchers to accomplish critical tasks-such as cell type annotation, conditional pseudo-cell generation, and drug sensitivity prediction-using straightforward natural language commands. Extensive evaluations demonstrate that InstructCell consistently meets or exceeds the performance of existing single-cell foundation models, while adapting to diverse experimental conditions. More importantly, InstructCell provides an accessible and intuitive tool for exploring complex single-cell data, lowering technical barriers and enabling deeper biological insights.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08187v2</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <category>q-bio.CB</category>
      <pubDate>Thu, 16 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yin Fang, Xinle Deng, Kangwei Liu, Ningyu Zhang, Jingyang Qian, Penghui Yang, Xiaohui Fan, Huajun Chen</dc:creator>
    </item>
  </channel>
</rss>
