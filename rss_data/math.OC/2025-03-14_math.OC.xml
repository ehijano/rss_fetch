<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 14 Mar 2025 04:00:21 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Exploiting Edited Large Language Models as General Scientific Optimizers</title>
      <link>https://arxiv.org/abs/2503.09620</link>
      <description>arXiv:2503.09620v1 Announce Type: new 
Abstract: Large language models (LLMs) have been widely adopted in mathematical optimization in scientific scenarios for their extensive knowledge and advanced reasoning capabilities. Existing methods mainly focus on utilizing LLMs to solve optimization problems in a prompt-based manner, which takes observational feedback as additional textual descriptions. However, due to LLM's \textbf{high sensitivity to the prompts} and \textbf{tendency to get lost in lengthy prompts}, these methods struggle to effectively utilize the {observational} feedback from each optimization step, which severely hinders the applications for real-world scenarios. To address these challenges, we propose a conceptually simple and general {bi-level} optimization method, namely \textbf{G}eneral \textbf{S}cientific \textbf{O}ptimizers (GSO). Specifically, GSO first utilizes inner-level simulators as experimental platforms to evaluate the current solution and provide observational feedback. Then, LLMs serve as knowledgeable and versatile scientists, generating new solutions by refining potential errors from the feedback as the outer-level optimization. Finally, simulations together with the expert knowledge in LLMs are jointly updated with bi-level interactions via model editing. Extensive experiments show that GSO consistently outperforms existing state-of-the-art methods using \textit{six} different LLM backbones on \textit{seven} different tasks, demonstrating the effectiveness and a wide range of applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09620v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qitan Lv, Tianyu Liu, Hong Wang</dc:creator>
    </item>
    <item>
      <title>Hardware-Compatible Single-Shot Feasible-Space Heuristics for Solving the Quadratic Assignment Problem</title>
      <link>https://arxiv.org/abs/2503.09676</link>
      <description>arXiv:2503.09676v1 Announce Type: new 
Abstract: Research into the development of special-purpose computing architectures designed to solve quadratic unconstrained binary optimization (QUBO) problems has flourished in recent years. It has been demonstrated in the literature that such special-purpose solvers can outperform traditional CMOS architectures by orders of magnitude with respect to timing metrics on synthetic problems. However, they face challenges with constrained problems such as the quadratic assignment problem (QAP), where mapping to binary formulations such as QUBO introduces overhead and limits parallelism. In-memory computing (IMC) devices, such as memristor-based analog Ising machines, offer significant speedups and efficiency gains over traditional CPU-based solvers, particularly for solving combinatorial optimization problems. In this work, we present a novel local search heuristic designed for IMC hardware to tackle the QAP. Our approach enables massive parallelism that allows for computing of full neighbourhoods simultaneously to make update decisions. We ensure binary solutions remain feasible by selecting local moves that lead to neighbouring feasible solutions, leveraging feasible-space search heuristics and the underlying structure of a given problem. Our approach is compatible with both digital computers and analog hardware. We demonstrate its effectiveness in CPU implementations by comparing it with state-of-the-art heuristics for solving the QAP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09676v1</guid>
      <category>math.OC</category>
      <category>cs.AR</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haesol Im, Chan-Woo Yang, Moslem Noori, Dmitrii Dobrynin, Elisabetta Valiante, Giacomo Pedretti, Arne Heittmann, Thomas Van Vaerenbergh, Masoud Mohseni, John Paul Strachan, Dmitri Strukov, Ray Beausoleil, Ignacio Rozada</dc:creator>
    </item>
    <item>
      <title>Aerocapture Guidance for Augmented Bank Angle Modulation</title>
      <link>https://arxiv.org/abs/2503.09806</link>
      <description>arXiv:2503.09806v1 Announce Type: new 
Abstract: This paper presents an optimal control solution for an aerocapture vehicle with two control inputs, bank angle and angle of attack, referred to as augmented bank angle modulation (ABAM). We derive the optimal control profiles using Pontryagin's Minimum Principle, validate the result numerically using the Gauss pseudospectral method (implemented in GPOPS), and introduce a novel guidance algorithm, ABAMGuid, for in-flight decision making. High-fidelity Monte Carlo simulations of a Uranus aerocapture mission demonstrate that ABAMGuid can greatly improve capture success rates and reduce the propellant needed for orbital correction following the atmospheric pass.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09806v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kyle Sonandres, Thomas Palazzo, Jonathan P. How</dc:creator>
    </item>
    <item>
      <title>Passivity-Based Local Design Conditions for Global Optimality in Distributed Convex Optimization</title>
      <link>https://arxiv.org/abs/2503.09854</link>
      <description>arXiv:2503.09854v1 Announce Type: new 
Abstract: In recent times, various distributed optimization algorithms have been proposed for whose specific agent dynamics global optimality and convergence is proven. However, there exist no general conditions for the design of such algorithms. In this paper, we leverage passivity theory to fi rst establish a distributed optimization framework with local design requirements for the agent dynamics in both unconstrained and constrained problems with undirected communication topologies. Under the roof of these requirements, the agents may use heterogeneous optimization algorithms without compromising global optimality and convergence. Subsequently, we propose some exemplary agent systems that comply with the established requirements. Compared to existing approaches, our algorithms do not require any global initialization nor communication of multiple variables. Consequently, the agents may leave or rejoin the networked optimization without compromising convergence to the correct global optimizer. Furthermore, we show that for unconstrained optimization, an extension to directed communication topologies is possible. Simulation results illustrate the plug-and-play capabilities and interoperability of the proposed agent dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09854v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pol Jane-Soneira, Charles Muller, Felix Strehle, S\"oren Hohmann</dc:creator>
    </item>
    <item>
      <title>Adaptive Moment Estimation Optimization Algorithm Using Projection Gradient for Deep Learning</title>
      <link>https://arxiv.org/abs/2503.10005</link>
      <description>arXiv:2503.10005v1 Announce Type: new 
Abstract: Training deep neural networks is challenging. To accelerate training and enhance performance, we propose PadamP, a novel optimization algorithm. PadamP is derived by applying the adaptive estimation of the p-th power of the second-order moments under scale invariance, enhancing projection adaptability by modifying the projection discrimination condition. It is integrated into Adam-type algorithms, accelerating training, boosting performance, and improving generalization in deep learning. Combining projected gradient benefits with adaptive moment estimation, PadamP tackles unconstrained non-convex problems. Convergence for the non-convex case is analyzed, focusing on the decoupling of first-order moment estimation coefficients and second-order moment estimation coefficients. Unlike prior work relying on , our proof generalizes the convergence theorem, enhancing practicality. Experiments using VGG-16 and ResNet-18 on CIFAR-10 and CIFAR-100 show PadamP's effectiveness, with notable performance on CIFAR-10/100, especially for VGG-16. The results demonstrate that PadamP outperforms existing algorithms in terms of convergence speed and generalization ability, making it a valuable addition to the field of deep learning optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.10005v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yongqi Li, Xiaowei Zhang</dc:creator>
    </item>
    <item>
      <title>On Persistently Resetting Learning Integrators: A Framework For Model-Free Feedback Optimization</title>
      <link>https://arxiv.org/abs/2503.10006</link>
      <description>arXiv:2503.10006v1 Announce Type: new 
Abstract: We study a novel class of algorithms for solving model-free feedback optimization problems in dynamical systems. The key novelty is the introduction of \emph{persistent resetting learning integrators} (PRLI), which are integrators that are reset at the same frequency at which the plant is dithered using exploratory signals for model-free optimization. It is shown that PRLIs can serve as core mechanisms for real-time gradient estimation in online feedback-optimization tasks where only cost function measurements are available. In particular, unlike existing approaches based on approximation theory, such as averaging or finite-differences, PRLIs can produce global real-time gradient estimates of cost functions, with uniformly bounded perturbations of arbitrarily small magnitude. In this sense, PRLIs function as robust \emph{hybrid} "Oracles" suitable for interconnection with discrete-time optimization algorithms that optimize the performance of continuous-time dynamical plants in closed-loop operation. Compared to existing methods, PRLIs yield \emph{global} stability properties for a broad class of cost functions, surpassing the local or semi-global guarantees offered by traditional approaches based on perturbation and approximation theory. The proposed framework naturally bridges physical systems, modeled as continuous-time plants where continuous exploration is essential, with digital algorithms, represented as discrete-time optimization methods. The main results are illustrated using different numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.10006v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mahmoud Abdelgalil, Jorge I. Poveda</dc:creator>
    </item>
    <item>
      <title>Are Convex Optimization Curves Convex?</title>
      <link>https://arxiv.org/abs/2503.10138</link>
      <description>arXiv:2503.10138v1 Announce Type: new 
Abstract: In this paper, we study when we might expect the optimization curve induced by gradient descent to be \emph{convex} -- precluding, for example, an initial plateau followed by a sharp decrease, making it difficult to decide when optimization should stop. Although such undesirable behavior can certainly occur when optimizing general functions, might it also occur in the benign and well-studied case of smooth convex functions? As far as we know, this question has not been tackled in previous work. We show, perhaps surprisingly, that the answer crucially depends on the choice of the step size. In particular, for the range of step sizes which are known to result in monotonic convergence to an optimal value, there is a regime where the optimization curve will be provably convex, and there is a regime where the curve can be non-convex. We also extend our results to gradient flow, and to the closely-related but different question of whether the gradient norm decreases monotonically.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.10138v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guy Barzilai, Ohad Shamir</dc:creator>
    </item>
    <item>
      <title>Asymmetric Long-Step Primal-Dual Interior-Point Methods with Dual Centering</title>
      <link>https://arxiv.org/abs/2503.10155</link>
      <description>arXiv:2503.10155v1 Announce Type: new 
Abstract: In this paper, we develop a new asymmetric framework for solving primal-dual problems of Conic Optimization by Interior-Point Methods (IPMs). It allows development of efficient methods for problems, where the dual formulation is simpler than the primal one. The problems of this type arise, in particular, in Semidefinite Optimization (SDO), for which we propose a new method with very attractive computational cost. Our long-step predictor-corrector scheme is based on centering in the dual space. It computes the affine-scaling predicting direction by the use of the dual barrier function, controlling the tangent step size by a functional proximity measure. We show that for symmetric cones, the search procedure at the predictor step is very cheap.
  In general, we do not need sophisticated Linear Algebra, restricting ourselves only by Cholesky factorization. However, our complexity bounds correspond to the best known polynomial-time results. Moreover, for symmetric cones the bounds automatically depend on the minimal barrier parameter between the primal or the dual feasible sets. We show by SDO-examples that the corresponding gain can be very big.
  We argue that the dual framework is more suitable for adjustment to the actual complexity of the problem. As an example, we discuss some classes of SDO-problems, where the number of iterations is proportional to the square root of the number of linear equality constraints. Moreover, the computational cost of one iteration there is similar to that one for Linear Optimization. We support our theoretical developments by preliminary but encouraging numerical results with randomly generated SDO-problems of different size.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.10155v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yurii Nesterov</dc:creator>
    </item>
    <item>
      <title>Safety Control of Impulsive Systems with Control Barrier Functions and Adaptive Gains</title>
      <link>https://arxiv.org/abs/2503.10164</link>
      <description>arXiv:2503.10164v1 Announce Type: new 
Abstract: This paper addresses the safety challenges in impulsive systems, where abrupt state jumps introduce significant complexities into system dynamics. A unified framework is proposed by integrating Quadratic Programming (QP), Control Barrier Functions (CBFs), and adaptive gain mechanisms to ensure system safety during impulsive events. The CBFs are constructed to enforce safety constraints by capturing the system's continuous dynamics and the effects of impulsive state transitions. An adaptive gain mechanism dynamically adjusts control inputs based on the magnitudes of the impulses and the system's proximity to safety boundaries, maintaining safety during instantaneous state jumps. A tailored QP formulation incorporates CBFs constraints and adaptive gain adjustments, optimizing control inputs while ensuring compliance with safety-critical requirements. Theoretical analysis establishes the boundedness, continuity, and feasibility of the adaptive gain and the overall framework. The effectiveness of the method is demonstrated through simulations on a robotic manipulator, showcasing its practical applicability to impulsive systems with state jumps.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.10164v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zihan Liu, Yuan-Hua Ni</dc:creator>
    </item>
    <item>
      <title>Sensitivity-Based Distributed Programming for Non-Convex Optimization</title>
      <link>https://arxiv.org/abs/2503.10174</link>
      <description>arXiv:2503.10174v1 Announce Type: new 
Abstract: This paper presents a novel sensitivity-based distributed programming (SBDP) approach for non-convex, large-scale nonlinear programs (NLP). The algorithm relies on first-order sensitivities to cooperatively solve the central NLP in a distributed manner with only neighbor-to-neighbor communication and parallelizable local computations. The scheme is based on primal decomposition and offers minimal algorithmic complexity. We derive sufficient local convergence conditions for non-convex problems. Furthermore, we consider the SBDP method in a distributed optimal control context and derive favorable convergence properties in this setting. We illustrate these theoretical findings and the performance of the proposed algorithm with simulations of various distributed optimization and control problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.10174v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maximilian Pierer von Esch, Andreas V\"olz, Knut Graichen</dc:creator>
    </item>
    <item>
      <title>On relationships between symmetric and non-symmetric cone separation based on Bishop-Phelps separating cones in real normed spaces</title>
      <link>https://arxiv.org/abs/2503.10184</link>
      <description>arXiv:2503.10184v1 Announce Type: new 
Abstract: In this paper, we study relationships between symmetric and non-symmetric separation of (not necessarily convex) cones by using separating cones of Bishop-Phelps type in real normed spaces. Besides extending some known results for the non-symmetric cone separation approach, we propose a new symmetric cone separation approach and establish cone separation results for it by using some cone separation results obtained for the non-symmetric cone separation approach twice (by swapping the roles of the cones). In addition to specifically emphasizing the results for the convex case, we also present some existence results for (bounded) convex bases of convex cones. Finally, we highlight some applications of symmetric and non-symmetric cone separation in optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.10184v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fernando Garc\'ia-Casta\~no, Christian G\"unther, M. A. Melguizo-Padial, Christiane Tammer</dc:creator>
    </item>
    <item>
      <title>Theorems of nonlinear separation of co-radiant sets and optimality conditions for approximate and proper approximate solutions of vector optimization problems</title>
      <link>https://arxiv.org/abs/2503.10193</link>
      <description>arXiv:2503.10193v1 Announce Type: new 
Abstract: This paper deals with \(\epsilon\)-efficient and \(\epsilon\)-proper efficient points with respect to a co-radiant set in a vector optimization problem. In the first part of the paper, we establish a new nonlinear separation theorem for co-radiant sets in normed spaces. Subsequently, we obtain necessary and sufficient conditions by means of scalarization for both \(\epsilon\)-efficient and \(\epsilon\)-proper efficient points in a general framework, without any requirements on the co-radiant set or any convexity assumption on the sets under consideration.Consequently, our results have a wider range of applicability than previously stated in the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.10193v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fernando Garc\'ia-Casta\~no, Miguel \'Angel Melguizo-Padial</dc:creator>
    </item>
    <item>
      <title>A Spectral Projected Gradient Method for Computational Protein Design problem</title>
      <link>https://arxiv.org/abs/2503.10203</link>
      <description>arXiv:2503.10203v1 Announce Type: new 
Abstract: In this paper, we consider the computational protein design (CPD) problem, which is usually modeled as 0/1 programming and is extremely challenging due to its combinatorial properties. As a quadratic semi-assignment problem (QSAP), the CPD problem has been proved to be equivalent to its continuous relaxation problem (RQSAP), in terms of sharing the same optimal objective value. However, since the current algorithm for solving this RQSAP uses the projected Newton method, which requires direct computation of the Hessian matrix, its computational cost remains quite high. Precisely for this reason, we choose to employ the spectral projected gradient (SPG) method to solve the CPD problem, whose effectiveness relies on choosing the step lengths according to novel ideas that are related to the spectrum of the underlying local Hessian. Specifically, we apply the SPG method in two distinct ways: direct solving the relaxation problem and applying a penalty method. Numerical results on benchmark instances verify the superior performance of our approach over the current algorithms in both quality and efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.10203v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Yukai Zheng, Qingna Li</dc:creator>
    </item>
    <item>
      <title>Efficient Diffusion Posterior Sampling for Noisy Inverse Problems</title>
      <link>https://arxiv.org/abs/2503.10237</link>
      <description>arXiv:2503.10237v1 Announce Type: new 
Abstract: The pretrained diffusion model as a strong prior has been leveraged to address inverse problems in a zero-shot manner without task-specific retraining. Different from the unconditional generation, the measurement-guided generation requires estimating the expectation of clean image given the current image and the measurement. With the theoretical expectation expression, the crucial task of solving inverse problems is to estimate the noisy likelihood function at the intermediate image sample. Using the Tweedie's formula and the known noise model, the existing diffusion posterior sampling methods perform gradient descent step with backpropagation through the pretrained diffusion model. To alleviate the costly computation and intensive memory consumption of the backpropagation, we propose an alternative maximum-a-posteriori (MAP)-based surrogate estimator to the expectation. With this approach and further density approximation, the MAP estimator for linear inverse problem is the solution to a traditional regularized optimization, of which the loss comprises of data fidelity term and the diffusion model related prior term. Integrating the MAP estimator into a general denoising diffusion implicit model (DDIM)-like sampler, we achieve the general solving framework for inverse problems. Our approach highly resembles the existing $\Pi$GDM without the manifold projection operation of the gradient descent direction. The developed method is also extended to nonlinear JPEG decompression. The performance of the proposed posterior sampling is validated across a series of inverse problems, where both VP and VE SDE-based pretrained diffusion models are taken into consideration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.10237v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ji Li, Chao Wang</dc:creator>
    </item>
    <item>
      <title>Low-precision first-order method-based fix-and-propagate heuristics for large-scale mixed-integer linear optimization</title>
      <link>https://arxiv.org/abs/2503.10344</link>
      <description>arXiv:2503.10344v1 Announce Type: new 
Abstract: We investigate the use of low-precision first-order methods (FOMs) within a fix-and-propagate (FP) framework for solving mixed-integer programming problems (MIPs). FOMs, using only matrix-vector products instead of matrix factorizations, are well suited for GPU acceleration and have recently gained more attention for their application to large-scale linear programming problems (LPs). We employ PDLP, a variant of the Primal-Dual Hybrid Gradient (PDHG) method specialized to LP problems, to solve the LP-relaxation of our MIPs to low accuracy. This solution is used to motivate fixings within our fix-and-propagate framework. We implemented four different FP variants using primal and dual LP solution information. We evaluate the performance of our heuristics on MIPLIB 2017, showcasing that the low-accuracy LP solution produced by the FOM does not lead to a loss in quality of the FP heuristic solutions when compared to a high-accuracy interior-point method LP solution. Further, we use our FP framework to produce high-accuracy solutions for large-scale (up to 243 million non-zeros and 8 million decision variables) unit-commitment energy-system optimization models created with the modeling framework REMix. For the largest problems, we can generate solutions with under 2% primal-dual gap in less than 4 hours, whereas commercial solvers cannot generate feasible solutions within two days of runtime. This study represents the first successful application of FOMs in large-scale mixed-integer optimization, demonstrating their efficacy and establishing a foundation for future research in this domain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.10344v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nils-Christian Kempke, Thorsten Koch</dc:creator>
    </item>
    <item>
      <title>Stochastic Gradient Descent for Constrained Optimization based on Adaptive Relaxed Barrier Functions</title>
      <link>https://arxiv.org/abs/2503.10384</link>
      <description>arXiv:2503.10384v1 Announce Type: new 
Abstract: This paper presents a novel stochastic gradient descent algorithm for constrained optimization. The proposed algorithm randomly samples constraints and components of the finite sum objective function and relies on a relaxed logarithmic barrier function that is appropriately adapted in each optimization iteration. For a strongly convex objective function and affine inequality constraints, step-size rules and barrier adaptation rules are established that guarantee asymptotic convergence with probability one. The theoretical results in the paper are complemented by numerical studies which highlight potential advantages of the proposed algorithm for optimization problems with a large number of constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.10384v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Naum Dimitrieski, Jing Cao, Christian Ebenbauer</dc:creator>
    </item>
    <item>
      <title>State-Dependent Uncertainty Modeling in Robust Optimal Control Problems through Generalized Semi-Infinite Programming</title>
      <link>https://arxiv.org/abs/2503.10389</link>
      <description>arXiv:2503.10389v1 Announce Type: new 
Abstract: Generalized semi-infinite programs (generalized SIPs) are problems featuring a finite number of decision variables but an infinite number of constraints. They differ from standard SIPs in that their constraint set itself depends on the choice of the decision variable. Generalized SIPs can be used to model robust optimal control problems where the uncertainty itself is a function of the state or control input, allowing for a less conservative alternative to assuming a uniform uncertainty set over the entire decision space. In this work, we demonstrate how any generalized SIP can be converted to an existence-constrained SIP through a reformulation of the constraints and solved using a local reduction approach, which approximates the infinite constraint set by a finite number of scenarios. This transformation is then exploited to solve nonlinear robust optimal control problems with state-dependent uncertainties. We showcase our proposed approach on a planar quadrotor simulation where it recovers the true generalized SIP solution and outperforms a SIP-based approach with uniform uncertainty bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.10389v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>J. Wehbeh, E. C. Kerrigan</dc:creator>
    </item>
    <item>
      <title>Optimization techniques for modeling with piecewise-linear functions</title>
      <link>https://arxiv.org/abs/2503.10405</link>
      <description>arXiv:2503.10405v1 Announce Type: new 
Abstract: In this paper we aim to construct piecewise-linear (PWL) approximations for functions of multiple variables and to build compact mixed-integer linear programming (MILP) formulations to represent the resulting PWL function. On the one hand, we describe a simple heuristic to iteratively construct a triangulation with a small number of triangles, while decreasing the error of the piecewise-linear approximation. On the other hand, we extend known techniques for modeling PWLs in MILPs more efficiently than state-of-the-art methods permit. The crux of our method is that the MILP model is a result of solving some hard combinatorial optimization problems, for which we present heuristic algorithms. The effectiveness of our techniques is demonstrated by a series of computational experiments including a short-term hydropower scheduling problem</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.10405v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>P\'eter Dobrovoczki, Tam\'as Kis</dc:creator>
    </item>
    <item>
      <title>A Rank-One-Update Method for the Training of Support Vector Machines</title>
      <link>https://arxiv.org/abs/2503.10482</link>
      <description>arXiv:2503.10482v1 Announce Type: new 
Abstract: This paper considers convex quadratic programs
  associated with the training of support vector machines (SVM).
  Exploiting the special structure of the SVM problem a new
  type of active set method with long cycles and stable rank-one-updates
  is proposed and tested (CMU: cycling method with updates).
  The structure of the problem allows for a repeated simple increase
  of the set of inactive constraints while controlling its size. This is
  followed by minimization steps with cheap updates of a matrix factorization.
  A widely used approach for solving SVM problems is the
  alternating direction method SMO,
  a method that is very efficient for low accuracy.
  The new active set approach allows for higher accuracy
  results at moderate computational cost. To relate both approaches,
  the effect of the accuracy on the running time and on the
  predictive quality of the SVM is compared with some numerical examples.
  A surprising result of the numerical examples is that only a
  very small number of cycles (each consisting of less than 2n
  steps) was used for CMU.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.10482v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Florian Jarre</dc:creator>
    </item>
    <item>
      <title>A Unified Dual Consensus Approach to Distributed Optimization with Globally-Coupled Constraints</title>
      <link>https://arxiv.org/abs/2503.10534</link>
      <description>arXiv:2503.10534v1 Announce Type: new 
Abstract: This article explores distributed convex optimization with globally-coupled constraints, where the objective function is a general nonsmooth convex function, the constraints include nonlinear inequalities and affine equalities, and the feasible region is possibly unbounded. To address such problems, a unified DUal Consensus Algorithm (DUCA) and its proximal variant (Pro-DUCA) are proposed, which are unified frameworks that approximate the method of multipliers applied to the corresponding dual problem in no need of a closed-form dual objective. With varied parameter settings, DUCA and Pro-DUCA not only extend a collection of existing consensus optimization methods to solve the dual problem that they used to be inapplicable to, but also aid in offering new efficient algorithms to the literature. The proposed unified algorithms are shown to achieve $O(1/k)$ convergence rates in terms of optimality and feasibility, providing new or enhanced convergence results for a number of existing methods. Simulations demonstrate that these algorithms outperform several state-of-the-art alternatives in terms of objective and feasibility errors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.10534v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zixuan Liu, Xuyang Wu, Dandan Wang, Jie Lu</dc:creator>
    </item>
    <item>
      <title>The Lagrangian Method for Solving Constrained Markov Games</title>
      <link>https://arxiv.org/abs/2503.10561</link>
      <description>arXiv:2503.10561v1 Announce Type: new 
Abstract: We propose the concept of a Lagrangian game to solve constrained Markov games. Such games model scenarios where agents face cost constraints in addition to their individual rewards, that depend on both agent joint actions and the evolving environment state over time. Constrained Markov games form the formal mechanism behind safe multiagent reinforcement learning, providing a structured model for dynamic multiagent interactions in a multitude of settings, such as autonomous teams operating under local energy and time constraints, for example. We develop a primal-dual approach in which agents solve a Lagrangian game associated with the current Lagrange multiplier, simulate cost and reward trajectories over a fixed horizon, and update the multiplier using accrued experience. This update rule generates a new Lagrangian game, initiating the next iteration. Our key result consists in showing that the sequence of solutions to these Lagrangian games yields a nonstationary Nash solution for the original constrained Markov game.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.10561v1</guid>
      <category>math.OC</category>
      <category>cs.GT</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Soham Das, Santiago Paternain, Luiz F. O. Chamon, Ceyhun Eksin</dc:creator>
    </item>
    <item>
      <title>Representation Theorems for Convex Expectations and Semigroups on Path Space</title>
      <link>https://arxiv.org/abs/2503.10572</link>
      <description>arXiv:2503.10572v1 Announce Type: new 
Abstract: The objective of this paper is to investigate the connection between penalty functions from stochastic optimal control, convex semigroups from analysis and convex expectations from probability theory. Our main result provides a one-to-one relation between these objects. As an application, we use the representation via penality functions and duality arguments to show that convex expectations are determined by their finite dimensional distributions. To illustrate this structural result, we show that Hu and Peng's axiomatic description of $G$-L\'evy processes in terms of finite dimensional distributions extends uniquely to the control approach introduced by Neufeld and Nutz. Finally, we show that convex expectations with a Markovian structure are fully determined by their one-dimensional distributions, which give rise to a classical semigroup on the state space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.10572v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David Criens, Michael Kupper</dc:creator>
    </item>
    <item>
      <title>Data-driven geometric parameter optimization for PD-GMRES</title>
      <link>https://arxiv.org/abs/2503.09728</link>
      <description>arXiv:2503.09728v1 Announce Type: cross 
Abstract: Restarted GMRES is a robust and widely used iterative solver for linear systems. The control of the restart parameter is a key task to accelerate convergence and to prevent the well-known stagnation phenomenon. We focus on the Proportional-Derivative GMRES (PD-GMRES), which has been derived using control-theoretic ideas in [Cuevas N\'u\~nez, Schaerer, and Bhaya (2018)] as a versatile method for modifying the restart parameter. Several variants of a quadtree-based geometric optimization approach are proposed to find a best choice of PD-GMRES parameters. We show that the optimized PD-GMRES performs well across a large number of matrix types and we observe superior performance as compared to major other GMRES-based iterative solvers. Moreover, we propose an extension of the PD-GMRES algorithm to further improve performance by controlling the range of values for the restart parameter.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09728v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lennart Duvenbeck, Cedric Riethm\"uller, Christian Rohde</dc:creator>
    </item>
    <item>
      <title>Unveiling Hidden Pivotal Players with GoalNet: A GNN-Based Soccer Player Evaluation System</title>
      <link>https://arxiv.org/abs/2503.09737</link>
      <description>arXiv:2503.09737v1 Announce Type: cross 
Abstract: Soccer analysis tools emphasize metrics such as expected goals, leading to an overrepresentation of attacking players' contributions and overlooking players who facilitate ball control and link attacks. Examples include Rodri from Manchester City and Palhinha who just transferred to Bayern Munich. To address this bias, we aim to identify players with pivotal roles in a soccer team, incorporating both spatial and temporal features.
  In this work, we introduce a GNN-based framework that assigns individual credit for changes in expected threat (xT), thus capturing overlooked yet vital contributions in soccer. Our pipeline encodes both spatial and temporal features in event-centric graphs, enabling fair attribution of non-scoring actions such as defensive or transitional plays. We incorporate centrality measures into the learned player embeddings, ensuring that ball-retaining defenders and defensive midfielders receive due recognition for their overall impact. Furthermore, we explore diverse GNN variants-including Graph Attention Networks and Transformer-based models-to handle long-range dependencies and evolving match contexts, discussing their relative performance and computational complexity. Experiments on real match data confirm the robustness of our approach in highlighting pivotal roles that traditional attacking metrics typically miss, underscoring the model's utility for more comprehensive soccer analytics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09737v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jacky Hao Jiang, Jerry Cai, Anastasios Kyrillidis</dc:creator>
    </item>
    <item>
      <title>Achieving constant regret for dynamic matching via state-independent policies</title>
      <link>https://arxiv.org/abs/2503.09762</link>
      <description>arXiv:2503.09762v1 Announce Type: cross 
Abstract: We study a centralized discrete-time dynamic two-way matching model with finitely many agent types. Agents arrive stochastically over time and join their type-dedicated queues waiting to be matched. We focus on state-independent greedy policies that achieve constant regret at all times by making matching decisions based solely on agent availability across types, rather than requiring complete queue-length information. Such policies are particularly appealing for life-saving applications such as kidney exchange, as they require less information and provide more transparency compared to state-dependent policies.
  First, for acyclic matching networks, we analyze a deterministic priority policy proposed by Kerimov et al. [2023] that follows a static priority order over matches. We derive the first explicit regret bound in terms of the general position gap (GPG) parameter $\epsilon$, which measures the distance of the fluid relaxation from degeneracy. Second, for general two-way matching networks, we design a randomized state-independent greedy policy that achieves constant regret with optimal scaling $O(\epsilon^{-1})$, matching the existing lower bound established by Kerimov et al. [2024].</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09762v1</guid>
      <category>cs.DS</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>S\"uleyman Kerimov, Mingwei Yang, Sophie H. Yu</dc:creator>
    </item>
    <item>
      <title>Data-Driven Distributionally Robust Control for Interacting Agents under Logical Constraints</title>
      <link>https://arxiv.org/abs/2503.09816</link>
      <description>arXiv:2503.09816v1 Announce Type: cross 
Abstract: In this paper, we propose a distributionally robust control synthesis for an agent with stochastic dynamics that interacts with other agents under uncertainties and constraints expressed by signal temporal logic (STL). We formulate the control synthesis as a chance-constrained program (CCP) with STL specifications that must be satisfied with high probability under all uncertainty tubes induced by the other agents. To tackle the CCP, we propose two methods based on concentration of measure (CoM) theory and conditional value at risk (CVaR) and compare the required assumptions and resulting optimizations. These approaches convert the CCP into an expectation-constrained program (ECP), which is simpler to solve than the original CCP. To estimate the expectation using a finite set of observed data, we adopt a distributionally robust optimization (DRO) approach. The underlying DRO can be approximated as a robust data-driven optimization that provides a probabilistic under-approximation to the original ECP, where the probability depends on the number of samples. Therefore, under feasibility, the original STL constraints are satisfied with two layers of designed confidence: the confidence of the chance constraint and the confidence of the approximated data-driven optimization, which depends on the number of samples. We then provide details on solving the resulting robust data-driven optimization numerically. Finally, we compare the two proposed approaches through case studies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09816v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arash Bahari Kordabad, Eleftherios E. Vlahakis, Lars Lindemann, Sebastien Gros, Dimos V. Dimarogonas, Sadegh Soudjani</dc:creator>
    </item>
    <item>
      <title>A second order numerical scheme for optimal control of non-linear Fokker-Planck equations and applications in social dynamics</title>
      <link>https://arxiv.org/abs/2503.09848</link>
      <description>arXiv:2503.09848v1 Announce Type: cross 
Abstract: In this work, we present a second-order numerical scheme to address the solution of optimal control problems constrained by the evolution of nonlinear Fokker-Planck equations arising from socio-economic dynamics. In order to design an appropriate numerical scheme for control realization, a coupled forward-backward system is derived based on the associated optimality conditions. The forward equation, corresponding to the Fokker-Planck dynamics, is discretized using a structure preserving scheme able to capture steady states. On the other hand, the backward equation, modeled as a Hamilton-Jacobi-Bellman problem, is solved via a semi-Lagrangian scheme that supports large time steps while preserving stability. Coupling between the forward and backward problems is achieved through a gradient descent optimization strategy, ensuring convergence to the optimal control. Numerical experiments demonstrate second-order accuracy, computational efficiency, and effectiveness in controlling different examples across various scenarios in social dynamics. This approach provides a reliable computational tool for the study of opinion manipulation and consensus formation in socially structured systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09848v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Giacomo Albi, Elisa Calzola</dc:creator>
    </item>
    <item>
      <title>A Heterogeneous Multiscale Method for Efficient Simulation of Power Systems with Inverter-Based Resources</title>
      <link>https://arxiv.org/abs/2503.09892</link>
      <description>arXiv:2503.09892v1 Announce Type: cross 
Abstract: As inverter-based resources (IBRs) penetrate power systems, the dynamics become more complex, exhibiting multiple timescales, including electromagnetic transient (EMT) dynamics of power electronic controllers and electromechanical dynamics of synchronous generators. Consequently, the power system model becomes highly stiff, posing a challenge for efficient simulation using existing methods that focus on dynamics within a single timescale. This paper proposes a Heterogeneous Multiscale Method for highly efficient multi-timescale simulation of a power system represented by its EMT model. The new method alternates between the microscopic EMT model of the system and an automatically reduced macroscopic model, varying the step size accordingly to achieve significant acceleration while maintaining accuracy in both fast and slow dynamics of interests. It also incorporates a semi-analytical solution method to enable a more adaptive variable-step mechanism. The new simulation method is illustrated using a two-area system and is then tested on a detailed EMT model of the IEEE 39-bus system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09892v1</guid>
      <category>eess.SY</category>
      <category>cs.NA</category>
      <category>cs.SY</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TPWRS.2025.3539567</arxiv:DOI>
      <dc:creator>Kaiyang Huang, Min Xiong, Yang Liu, Kai Sun</dc:creator>
    </item>
    <item>
      <title>A Semantic-Loss Function Modeling Framework With Task-Oriented Machine Learning Perspectives</title>
      <link>https://arxiv.org/abs/2503.09903</link>
      <description>arXiv:2503.09903v1 Announce Type: cross 
Abstract: The integration of machine learning (ML) has significantly enhanced the capabilities of Earth Observation (EO) systems by enabling the extraction of actionable insights from complex datasets. However, the performance of data-driven EO applications is heavily influenced by the data collection and transmission processes, where limited satellite bandwidth and latency constraints can hinder the full transmission of original data to the receivers. To address this issue, adopting the concepts of Semantic Communication (SC) offers a promising solution by prioritizing the transmission of essential data semantics over raw information. Implementing SC for EO systems requires a thorough understanding of the impact of data processing and communication channel conditions on semantic loss at the processing center. This work proposes a novel data-fitting framework to empirically model the semantic loss using real-world EO datasets and domain-specific insights. The framework quantifies two primary types of semantic loss: (1) source coding loss, assessed via a data quality indicator measuring the impact of processing on raw source data, and (2) transmission loss, evaluated by comparing practical transmission performance against the Shannon limit. Semantic losses are estimated by evaluating the accuracy of EO applications using four task-oriented ML models, EfficientViT, MobileViT, ResNet50-DINO, and ResNet8-KD, on lossy image datasets under varying channel conditions and compression ratios. These results underpin a framework for efficient semantic-loss modeling in bandwidth-constrained EO scenarios, enabling more reliable and effective operations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09903v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ti Ti Nguyen, Thanh-Dung Le, Vu Nguyen Ha, Hong-fu Chou, Geoffrey Eappen, Duc-Dung Tran, Hung Nguyen-Kha, Prabhu Thiruvasagam, Luis M. Garces-Socarras, Jorge L. Gonzalez-Rios, Juan C. Merlano-Duncan, Symeon Chatzinotas</dc:creator>
    </item>
    <item>
      <title>Accuracy of Discretely Sampled Stochastic Policies in Continuous-time Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2503.09981</link>
      <description>arXiv:2503.09981v1 Announce Type: cross 
Abstract: Stochastic policies are widely used in continuous-time reinforcement learning algorithms. However, executing a stochastic policy and evaluating its performance in a continuous-time environment remain open challenges. This work introduces and rigorously analyzes a policy execution framework that samples actions from a stochastic policy at discrete time points and implements them as piecewise constant controls. We prove that as the sampling mesh size tends to zero, the controlled state process converges weakly to the dynamics with coefficients aggregated according to the stochastic policy. We explicitly quantify the convergence rate based on the regularity of the coefficients and establish an optimal first-order convergence rate for sufficiently regular coefficients. Additionally, we show that the same convergence rates hold with high probability concerning the sampling noise, and further establish a $1/2$-order almost sure convergence when the volatility is not controlled. Building on these results, we analyze the bias and variance of various policy evaluation and policy gradient estimators based on discrete-time observations. Our results provide theoretical justification for the exploratory stochastic control framework in [H. Wang, T. Zariphopoulou, and X.Y. Zhou, J. Mach. Learn. Res., 21 (2020), pp. 1-34].</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09981v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yanwei Jia, Du Ouyang, Yufei Zhang</dc:creator>
    </item>
    <item>
      <title>OR-LLM-Agent: Automating Modeling and Solving of Operations Research Optimization Problem with Reasoning Large Language Model</title>
      <link>https://arxiv.org/abs/2503.10009</link>
      <description>arXiv:2503.10009v1 Announce Type: cross 
Abstract: Operations Research (OR) has been widely applied in various fields such as resource allocation, production planning, and supply chain management. However, addressing real-world OR problems requires OR experts to perform mathematical modeling and programmers to develop solution algorithms. This traditional method, heavily reliant on experts, is costly and has long development cycles, severely limiting the widespread adoption of OR techniques. Few have considered using Artificial Intelligence (AI) to replace professionals to achieve fully automated solutions for OR problems. We propose OR-LLM-Agent, the first AI agent that enables end-to-end automation for solving real-world OR problems. OR-LLM-Agent leverages the Chain-of-Thought (CoT) reasoning capabilities of Large Language Models (LLMs) to translate natural language problem descriptions into formal mathematical models and automatically generate Gurobi solver code. In OR-LLM-Agent, OR-CodeAgent is designed to automate code execution and repair within a sandbox environment, facilitating the derivation of the final solution. Due to the lack of dedicated benchmark datasets for evaluating the automated solving of OR problems, we construct a benchmark dataset comprising 83 real-world OR problems described in natural language. We conduct comparative experiments with state-of-the-art (SOTA) reasoning LLMs, including GPT-o3-mini, DeepSeek-R1, and Gemini 2.0 Flash Thinking. The OR-LLM-Agent achieved the highest pass rate of 100% and the highest solution accuracy of 85%, demonstrating the feasibility of automated OR problem-solving. Data and code have been publicly available at https://github.com/bwz96sco/or_llm_agent.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.10009v1</guid>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bowen Zhang, Pengcheng Luo</dc:creator>
    </item>
    <item>
      <title>Revisiting Multi-Agent Asynchronous Online Optimization with Delays: the Strongly Convex Case</title>
      <link>https://arxiv.org/abs/2503.10013</link>
      <description>arXiv:2503.10013v1 Announce Type: cross 
Abstract: We revisit multi-agent asynchronous online optimization with delays, where only one of the agents becomes active for making the decision at each round, and the corresponding feedback is received by all the agents after unknown delays. Although previous studies have established an $O(\sqrt{dT})$ regret bound for this problem, they assume that the maximum delay $d$ is knowable or the arrival order of feedback satisfies a special property, which may not hold in practice. In this paper, we surprisingly find that when the loss functions are strongly convex, these assumptions can be eliminated, and the existing regret bound can be significantly improved to $O(d\log T)$ meanwhile. Specifically, to exploit the strong convexity of functions, we first propose a delayed variant of the classical follow-the-leader algorithm, namely FTDL, which is very simple but requires the full information of functions as feedback. Moreover, to handle the more general case with only the gradient feedback, we develop an approximate variant of FTDL by combining it with surrogate loss functions. Experimental results show that the approximate FTDL outperforms the existing algorithm in the strongly convex case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.10013v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lingchan Bao, Tong Wei, Yuanyu Wan</dc:creator>
    </item>
    <item>
      <title>An LiGME Regularizer of Designated Isolated Minimizers -- An Application to Discrete-Valued Signal Estimation</title>
      <link>https://arxiv.org/abs/2503.10126</link>
      <description>arXiv:2503.10126v1 Announce Type: cross 
Abstract: For a regularized least squares estimation of discrete-valued signals, we propose an LiGME regularizer, as a nonconvex regularizer, of designated isolated minimizers. The proposed regularizer is designed as a Generalized Moreau Enhancement (GME) of the so-called SOAV convex regularizer. Every candidate vector in the discrete-valued set is aimed to be assigned to an isolated local minimizer of the proposed regularizer while the overall convexity of the regularized least squares model is maintained. Moreover, a global minimizer of the proposed model can be approximated iteratively by using a variant of cLiGME algorithm. To enhance the accuracy of the proposed estimation, we also propose a pair of simple modifications, called respectively an iterative reweighting and a generalized superiorization. Numerical experiments demonstrate the effectiveness of the proposed model and algorithms in a scenario of MIMO signal detection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.10126v1</guid>
      <category>eess.SP</category>
      <category>math.OC</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Satoshi Shoji, Wataru Yata, Keita Kume, Isao Yamada</dc:creator>
    </item>
    <item>
      <title>Safe exploration in reproducing kernel Hilbert spaces</title>
      <link>https://arxiv.org/abs/2503.10352</link>
      <description>arXiv:2503.10352v1 Announce Type: cross 
Abstract: Popular safe Bayesian optimization (BO) algorithms learn control policies for safety-critical systems in unknown environments. However, most algorithms make a smoothness assumption, which is encoded by a known bounded norm in a reproducing kernel Hilbert space (RKHS). The RKHS is a potentially infinite-dimensional space, and it remains unclear how to reliably obtain the RKHS norm of an unknown function. In this work, we propose a safe BO algorithm capable of estimating the RKHS norm from data. We provide statistical guarantees on the RKHS norm estimation, integrate the estimated RKHS norm into existing confidence intervals and show that we retain theoretical guarantees, and prove safety of the resulting safe BO algorithm. We apply our algorithm to safely optimize reinforcement learning policies on physics simulators and on a real inverted pendulum, demonstrating improved performance, safety, and scalability compared to the state-of-the-art.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.10352v1</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Abdullah Tokmak, Kiran G. Krishnan, Thomas B. Sch\"on, Dominik Baumann</dc:creator>
    </item>
    <item>
      <title>Convex Chance-Constrained Programs with Wasserstein Ambiguity</title>
      <link>https://arxiv.org/abs/2111.02486</link>
      <description>arXiv:2111.02486v2 Announce Type: replace 
Abstract: Chance constraints yield non-convex feasible regions in general. In particular, when the uncertain parameters are modeled by a Wasserstein ball, arXiv:1806.07418 and arXiv:1809.00210 showed that the distributionally robust (pessimistic) chance constraint admits a mixed-integer conic representation. This paper identifies sufficient conditions that lead to convex feasible regions of chance constraints with Wasserstein ambiguity. First, when uncertainty arises from the right-hand side of a pessimistic joint chance constraint, we show that the ensuing feasible region is convex if the Wasserstein ball is centered around a log-concave distribution (or, more generally, an $\alpha$-concave distribution with $\alpha \geq -1$). In addition, we propose a block coordinate ascent algorithm and prove its convergence to global optimum, as well as the rate of convergence. Second, when uncertainty arises from the left-hand side of a pessimistic two-sided chance constraint, we show the convexity if the Wasserstein ball is centered around an elliptical and star-unimodal distribution. In addition, we propose a family of second-order conic inner approximations, and we bound their approximation error and prove their asymptotic exactness. Furthermore, we extend the convexity results to optimistic chance constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2111.02486v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1287/opre.2021.0709</arxiv:DOI>
      <dc:creator>Haoming Shen, Ruiwei Jiang</dc:creator>
    </item>
    <item>
      <title>Hovering Flight in Flapping Insects and Hummingbirds: A Natural Real-Time and Stable Extremum Seeking Feedback System</title>
      <link>https://arxiv.org/abs/2402.04985</link>
      <description>arXiv:2402.04985v3 Announce Type: replace 
Abstract: In this paper, we take an initial and novel step towards characterizing the physical phenomenon of hovering flight as an extremum seeking (ES) feedback system. We anticipate that said novel characterization may start a new line of research that can potentially solve all the puzzle pieces of hovering flight that existed for decades in previous literature. Is hovering flight stable? If so, what is the control mechanism utilized by insects/hummingbirds to achieve stable hovering? If such a mechanism exists, does it fit the biological constraints that insects/hummingbirds have limited computational abilities? Does it fit the experimental biology narrative that insects/hummingbirds rely mainly on their sensation to stabilize hovering? Our ES characterization and analysis provide for the first time a simple, model-free, real-time, stable feedback system of hovering. Consistent with natural observations and biological experiments, hovering via ES is simply achievable by the natural oscillations of the wing angle and measuring (sensing) altitude or acceleration. We provide simulation trials, including comparisons with some approaches from literature, to demonstrate the effectiveness of our results. We used literature data for hawkmoth, cranefly, bumblebee, dragonfly, hoverfly, and a hummingbird.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.04985v3</guid>
      <category>math.OC</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ahmed A. Elgohary, Sameh A. Eisa</dc:creator>
    </item>
    <item>
      <title>Complexity results and active-set identification of a derivative-free method for bound-constrained problems</title>
      <link>https://arxiv.org/abs/2402.10801</link>
      <description>arXiv:2402.10801v3 Announce Type: replace 
Abstract: In this paper, we analyze a derivative-free line search method designed for bound-constrained problems. Our analysis demonstrates that this method exhibits a worst-case complexity comparable to other derivative-free methods for unconstrained and linearly constrained problems. In particular, when minimizing a function with $n$ variables, we prove that at most ${\cal O(n\epsilon^{-2})}$ iterations are needed to drive a criticality measure below a predefined threshold $\epsilon$, requiring at most ${\cal O(n^2\epsilon^{-2})}$ function evaluations. We also show that the total number of iterations where the criticality measure is not below $\epsilon$ is upper bounded by ${\cal O(n^2\epsilon^{-2})}$. Moreover, we investigate the method capability to identify active constraints at the final solutions. We show that, after a finite number of iterations, all the active constraints satisfying the strict complementarity condition are correctly identified.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.10801v3</guid>
      <category>math.OC</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrea Brilli, Andrea Cristofari, Giampaolo Liuzzi, Stefano Lucidi</dc:creator>
    </item>
    <item>
      <title>Robust SGLD algorithm for solving non-convex distributionally robust optimisation problems</title>
      <link>https://arxiv.org/abs/2403.09532</link>
      <description>arXiv:2403.09532v2 Announce Type: replace 
Abstract: In this paper we develop a Stochastic Gradient Langevin Dynamics (SGLD) algorithm tailored for solving a certain class of non-convex distributionally robust optimisation (DRO) problems. By deriving non-asymptotic convergence bounds, we build an algorithm which for any prescribed accuracy $\varepsilon&gt;0$ outputs an estimator whose expected excess risk is at most $\varepsilon$. As a concrete application, we consider the problem of identifying the best non-linear estimator of a given regression model involving a neural network using adversarially corrupted samples. We formulate this problem as a DRO problem and demonstrate both theoretically and numerically the applicability of the proposed robust SGLD algorithm. Moreover, numerical experiments show that the robust SGLD estimator outperforms the estimator obtained using vanilla SGLD in terms of test accuracy, which highlights the advantage of incorporating model uncertainty when optimising with perturbed samples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.09532v2</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>q-fin.MF</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ariel Neufeld, Matthew Ng Cheng En, Ying Zhang</dc:creator>
    </item>
    <item>
      <title>Block cubic Newton with greedy selection</title>
      <link>https://arxiv.org/abs/2407.18150</link>
      <description>arXiv:2407.18150v3 Announce Type: replace 
Abstract: A second-order block coordinate descent method is proposed for the unconstrained minimization of an objective function with Lipschitz continuous Hessian. At each iteration, a block of variables is selected by means of a greedy (Gauss-Southwell) rule which considers the amount of first-order stationarity violation, then an approximate minimizer of a cubic model is computed for the block update. In the proposed scheme, blocks are not required to have a prefixed structure and their size is allowed to change during the iterations. For non-convex objective functions, global convergence to stationary points is proved and a worst-case iteration complexity analysis is provided. In particular, given a tolerance $\epsilon$, we show that at most ${\cal O(\epsilon^{-3/2})}$ iterations are needed to drive the stationarity violation with respect to the selected block of variables below $\epsilon$, while at most ${\cal O(\epsilon^{-2})}$ iterations are needed to drive the stationarity violation with respect to all variables below $\epsilon$. Numerical results are finally given.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18150v3</guid>
      <category>math.OC</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrea Cristofari</dc:creator>
    </item>
    <item>
      <title>Optimal Mechanisms for Demand Response: An Indifference Set Approach</title>
      <link>https://arxiv.org/abs/2409.07655</link>
      <description>arXiv:2409.07655v2 Announce Type: replace 
Abstract: The time at which renewable (e.g., solar or wind) energy resources produce electricity cannot generally be controlled. In many settings, however, consumers have some flexibility in their energy consumption needs, and there is growing interest in demand-response programs that leverage this flexibility to shift energy consumption to better match renewable production -- thus enabling more efficient utilization of these resources. We study optimal demand response in a setting where consumers use home energy management systems (HEMS) to autonomously adjust their electricity consumption. Our core assumption is that HEMS operationalize flexibility by querying the consumer for their preferences and computing the ``indifference set'' of all energy consumption profiles that can be used to satisfy these preferences. Then, given an indifference set, HEMS can respond to grid signals while guaranteeing user-defined comfort and functionality; e.g., if a consumer sets a temperature range, a HEMS can precool and preheat to align with peak renewable production, thus improving efficiency without sacrificing comfort. We show that while price-based mechanisms are not generally optimal for demand response, they become asymptotically optimal in large markets under a mean-field limit. Furthermore, we show that optimal dynamic prices can be efficiently computed in large markets by only querying HEMS about their planned consumption under different price signals. Using an OpenDSS-powered grid simulation for Phoenix, Arizona, we demonstrate that our approach enables meaningful demand response without creating grid instability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.07655v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammad Mehrabi, Omer Karaduman, Stefan Wager</dc:creator>
    </item>
    <item>
      <title>Underapproximating Safe Domains of Attraction for Discrete-Time Systems Using Implicit Representations of Backward Reachable Sets</title>
      <link>https://arxiv.org/abs/2409.10657</link>
      <description>arXiv:2409.10657v2 Announce Type: replace 
Abstract: Analyzing and certifying stability and attractivity of nonlinear systems is a topic of research interest that has been extensively investigated by control theorists and engineers for many years. Despite that, accurately estimating domains of attraction for nonlinear systems remains a challenging task, where available estimation approaches are either conservative or limited to low-dimensional systems. In this work, we propose an iterative approach to accurately underapproximate safe (i.e., state-constrained) domains of attraction for general discrete-time autonomous nonlinear systems. Our approach relies on implicit representations of safe backward reachable sets of safe regions of attraction, where such regions can be be easily constructed using, e.g., quadratic Lyapunov functions. The iterations of our approach are monotonic (in the sense of set inclusion), where each iteration results in a safe region of attraction, given as a sublevel set, that underapproximates the safe domain of attraction. The sublevel set representations of the resulting regions of attraction can be efficiently utilized in verifying the inclusion of given points of interest in the safe domain of attraction. We illustrate our approach through two numerical examples, involving two- and four-dimensional nonlinear systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.10657v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohamed Serry, Jun Liu</dc:creator>
    </item>
    <item>
      <title>Prevailing against Adversarial Noncentral Disturbances: Exact Recovery of Linear Systems with the $l_1$-norm Estimator</title>
      <link>https://arxiv.org/abs/2410.03218</link>
      <description>arXiv:2410.03218v5 Announce Type: replace 
Abstract: This paper studies the linear system identification problem in the general case where the disturbance is sub-Gaussian, correlated, and possibly adversarial. First, we consider the case with noncentral (nonzero-mean) disturbances for which the ordinary least-squares (OLS) method fails to correctly identify the system. We prove that the $l_1$-norm estimator accurately identifies the system under the condition that each disturbance has equal probabilities of being positive or negative. This condition restricts the sign of each disturbance but allows its magnitude to be arbitrary. Second, we consider the case where each disturbance is adversarial with the model that the attack times happen occasionally but the distributions of the attack values are arbitrary. We show that when the probability of having an attack at a given time is less than 0.5 and each attack spans the entire space in expectation, the $l_1$-norm estimator prevails against any adversarial noncentral disturbances and the exact recovery is achieved within a finite time. These results pave the way to effectively defend against arbitrarily large noncentral attacks in safety-critical systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03218v5</guid>
      <category>math.OC</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jihun Kim, Javad Lavaei</dc:creator>
    </item>
    <item>
      <title>A Barrier Function Approach for Bilevel Optimization with Coupled Lower-Level Constraints: Formulation, Approximation and Algorithms</title>
      <link>https://arxiv.org/abs/2410.10670</link>
      <description>arXiv:2410.10670v5 Announce Type: replace 
Abstract: In this paper, we consider bilevel optimization problem where the lower-level has coupled constraints, i.e. the constraints depend both on the upper- and lower-level variables. In particular, we consider two settings for the lower-level problem. The first is when the objective is strongly convex and the constraints are convex with respect to the lower-level variable; The second is when the lower-level is a linear program. We propose to utilize a barrier function reformulation to translate the problem into an unconstrained problem. By developing a series of new techniques, we proved that both the hyperfunction value and hypergradient of the barrier reformulated problem (uniformly) converge to those of the original problem under minimal assumptions. Further, to overcome the non-Lipschitz smoothness of hyperfunction and lower-level problem for barrier reformulated problems, we design an adaptive algorithm that ensures a non-asymptotic convergence guarantee. We also design an algorithm that converges to the stationary point of the original problem asymptotically under certain assumptions. The proposed algorithms require minimal assumptions, and to our knowledge, they are the first with convergence guarantees when the lower-level problem is a linear program. Numerical experiments are conducted to show the effectiveness of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10670v5</guid>
      <category>math.OC</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaotian Jiang, Jiaxiang Li, Mingyi Hong, Shuzhong Zhang</dc:creator>
    </item>
    <item>
      <title>Differentiation of inertial methods for optimizing smooth parametric function</title>
      <link>https://arxiv.org/abs/2502.00522</link>
      <description>arXiv:2502.00522v3 Announce Type: replace 
Abstract: In this paper, we consider the minimization of a $C^2-$smooth and strongly convex objective depending on a given parameter, which is usually found in many practical applications. We suppose that we desire to solve the problem with some inertial methods which cover a broader existing well-known inertial methods. Our main goal is to analyze the derivative of this algorithm as an infinite iterative process in the sense of ``automatic'' differentiation. This procedure is very common and has gain more attention recently. From a pure optimization perspective and under some mild premises, we show that any sequence generated by these inertial methods converge to the unique minimizer of the problem, which depends on the parameter. Moreover, we show a local linear convergence rate of the generated sequence. Concerning the differentiation of the scheme, we prove that the derivative of the sequence with respect to the parameter converges to the derivative of the limit of the sequence showing that any sequence is &lt;&lt;derivative stable&gt;&gt;. Finally, we investigate the rate at which the convergence occurs. We show that, this is locally linear with an error term tending to zero.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.00522v3</guid>
      <category>math.OC</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jean-Jacques Godeme</dc:creator>
    </item>
    <item>
      <title>On strategies for risk management and decision making under uncertainty shared across multiple fields</title>
      <link>https://arxiv.org/abs/2309.03133</link>
      <description>arXiv:2309.03133v2 Announce Type: replace-cross 
Abstract: Decision theory recognizes two principal approaches to solving problems under uncertainty: probabilistic models and cognitive heuristics. However, engineers, public planners and decision-makers in other fields seem to employ solution strategies that do not fall into either field, i.e., strategies such as robust design and contingency planning. In addition, identical strategies appear in several fields and disciplines, pointing to an important shared toolkit.
  The focus of this paper is to develop a systematic understanding of such strategies and develop a framework to better employ them in decision making and risk management. The paper finds more than 110 examples of such strategies and this approach to risk is termed RDOT: Risk-reducing Design and Operations Toolkit. RDOT strategies fall into six broad categories: structural, reactive, formal, adversarial, multi-stage and positive. RDOT strategies provide an efficient response even to radical uncertainty or unknown unknowns that are challenging to address with probabilistic methods. RDOT could be incorporated into decision theory using workflows, multi-objective optimization and multi-attribute utility theory.
  Overall, RDOT represents an overlooked class of versatile responses to uncertainty. Because RDOT strategies do not require precise estimation or forecasting, they are particularly helpful in decision problems affected by uncertainty and for resource-constrained decision making.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.03133v2</guid>
      <category>q-fin.RM</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexander Gutfraind</dc:creator>
    </item>
    <item>
      <title>Clipping Improves Adam-Norm and AdaGrad-Norm when the Noise Is Heavy-Tailed</title>
      <link>https://arxiv.org/abs/2406.04443</link>
      <description>arXiv:2406.04443v2 Announce Type: replace-cross 
Abstract: Methods with adaptive stepsizes, such as AdaGrad and Adam, are essential for training modern Deep Learning models, especially Large Language Models. Typically, the noise in the stochastic gradients is heavy-tailed for the later ones. Gradient clipping provably helps to achieve good high-probability convergence for such noises. However, despite the similarity between AdaGrad/Adam and Clip-SGD, the current understanding of the high-probability convergence of AdaGrad/Adam-type methods is limited in this case. In this work, we prove that AdaGrad/Adam (and their delayed version) can have provably bad high-probability convergence if the noise is heavy-tailed. We also show that gradient clipping fixes this issue, i.e., we derive new high-probability convergence bounds with polylogarithmic dependence on the confidence level for AdaGrad-Norm and Adam-Norm with clipping and with/without delay for smooth convex/non-convex stochastic optimization with heavy-tailed noise. Our empirical evaluations highlight the superiority of clipped versions of AdaGrad/Adam-Norm in handling the heavy-tailed noise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04443v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Savelii Chezhegov, Yaroslav Klyukin, Andrei Semenov, Aleksandr Beznosikov, Alexander Gasnikov, Samuel Horv\'ath, Martin Tak\'a\v{c}, Eduard Gorbunov</dc:creator>
    </item>
    <item>
      <title>Coalescing Force of Group Pressure: Consensus in Nonlinear Opinion Dynamics</title>
      <link>https://arxiv.org/abs/2410.04301</link>
      <description>arXiv:2410.04301v3 Announce Type: replace-cross 
Abstract: This work extends the recent opinion dynamics model from Cheng et al., emphasizing the role of group pressure in consensus formation. We generalize the findings to incorporate social influence algorithms with general time-varying, opinion-dependent weights and multidimensional opinions, beyond bounded confidence dynamics. We demonstrate that, with uniformly positive conformity levels, group pressure consistently drives consensus and provide a tighter estimate for the convergence rate. Unlike previous models, the common public opinion in our framework can assume arbitrary forms within the convex hull of current opinions, offering flexibility applicable to real-world scenarios such as opinion polls with random participant selection. This analysis provides deeper insights into how group pressure mechanisms foster consensus under diverse conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04301v3</guid>
      <category>physics.soc-ph</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Iryna Zabarianska, Anton V. Proskurnikov</dc:creator>
    </item>
    <item>
      <title>Safe and Dynamically-Feasible Motion Planning using Control Lyapunov and Barrier Functions</title>
      <link>https://arxiv.org/abs/2410.08364</link>
      <description>arXiv:2410.08364v2 Announce Type: replace-cross 
Abstract: This paper considers the problem of designing motion planning algorithms for control-affine systems that generate collision-free paths from an initial to a final destination and can be executed using safe and dynamically-feasible controllers. We introduce the C-CLF-CBF-RRT algorithm, which produces paths with such properties and leverages rapidly exploring random trees (RRTs), control Lyapunov functions (CLFs) and control barrier functions (CBFs). We show that C-CLF-CBF-RRT is computationally efficient for linear systems with polytopic and ellipsoidal constraints, and establish its probabilistic completeness. We showcase the performance of C-CLF-CBF-RRT in different simulation and hardware experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08364v2</guid>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pol Mestres, Carlos Nieto-Granda, Jorge Cort\'es</dc:creator>
    </item>
    <item>
      <title>An Optimistic Algorithm for Online Convex Optimization with Adversarial Constraints</title>
      <link>https://arxiv.org/abs/2412.08060</link>
      <description>arXiv:2412.08060v2 Announce Type: replace-cross 
Abstract: We study Online Convex Optimization (OCO) with adversarial constraints, where an online algorithm must make sequential decisions to minimize both convex loss functions and cumulative constraint violations. We focus on a setting where the algorithm has access to predictions of the loss and constraint functions. Our results show that we can improve the current best bounds of $ O(\sqrt{T}) $ regret and $ \tilde{O}(\sqrt{T}) $ cumulative constraint violations to $ O(\sqrt{E_T(f)}) $ and $ \tilde{O}(\sqrt{E_T(g^+)}) $, respectively, where $ E_T(f) $ and $E_T(g^+)$ represent the cumulative prediction errors of the loss and constraint functions. In the worst case, where $E_T(f) = O(T) $ and $ E_T(g^+) = O(T) $ (assuming bounded gradients of the loss and constraint functions), our rates match the prior $ O(\sqrt{T}) $ results. However, when the loss and constraint predictions are accurate, our approach yields significantly smaller regret and cumulative constraint violations. Finally, we apply this to the setting of adversarial contextual bandits with sequential risk constraints, obtaining optimistic bounds $O (\sqrt{E_T(f)} T^{1/3})$ regret and $O(\sqrt{E_T(g^+)} T^{1/3})$ constraints violation, yielding better performance than existing results when prediction quality is sufficiently high.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.08060v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jordan Lekeufack, Michael I. Jordan</dc:creator>
    </item>
    <item>
      <title>Exploring near-optimal energy systems with stakeholders: a novel approach for participatory modelling</title>
      <link>https://arxiv.org/abs/2501.05280</link>
      <description>arXiv:2501.05280v2 Announce Type: replace-cross 
Abstract: Involving people in energy systems planning can increase the legitimacy and socio-political feasibility of energy transitions. Participatory research in energy modelling offers the opportunity to engage with stakeholders in a comprehensive way, but is limited by how results can be generated and presented without imposing assumptions and discrete scenarios on the participants. To this end, we present a methodology and a framework, based on near-optimal modelling results, that can incorporate stakeholders in a holistic and engaging way. We confront stakeholders with a continuum of modelling-based energy system designs via an interactive interface allowing them to choose essentially any combination of components that meet the system requirements. Together with information on the implications of different technologies, it is possible to assess how participants prioritise different aspects in energy systems planning while also facilitating learning in an engaging and stimulating way. We showcase the methodology for the remote Arctic settlement of Longyearbyen and illustrate how participants deviate consistently from the cost optimum. At the same time, they manage to balance different priorities such as emissions, costs, and system vulnerability leading to a better understanding of the complexity and intertwined nature of decisions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.05280v2</guid>
      <category>cs.CY</category>
      <category>math.OC</category>
      <category>physics.soc-ph</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Oskar V{\aa}ger\"o, Koen van Greevenbroek, Aleksander Grochowicz, Maximilian Roithner</dc:creator>
    </item>
    <item>
      <title>Unified Feedback Linearization for Nonlinear Systems with Dexterous and Energy-Saving Modes</title>
      <link>https://arxiv.org/abs/2502.20524</link>
      <description>arXiv:2502.20524v2 Announce Type: replace-cross 
Abstract: Systems with a high number of inputs compared to the degrees of freedom (e.g. a mobile robot with Mecanum wheels) often have a minimal set of energy-efficient inputs needed to achieve a main task (e.g. position tracking) and a set of energy-intense inputs needed to achieve an additional auxiliary task (e.g. orientation tracking). This letter presents a unified control scheme, derived through feedback linearization, that can switch between two modes: an energy-saving mode, which tracks the main task using only the energy-efficient inputs while forcing the energy-intense inputs to zero, and a dexterous mode, which also uses the energy-intense inputs to track the auxiliary task as needed. The proposed control guarantees the exponential tracking of the main task and that the dynamics associated with the main task evolve independently of the a priori unknown switching signal. When the control is operating in dexterous mode, the exponential tracking of the auxiliary task is also guaranteed. Numerical simulations on an omnidirectional Mecanum wheel robot validate the effectiveness of the proposed approach and demonstrate the effect of the switching signal on the exponential tracking behavior of the main and auxiliary tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.20524v2</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mirko Mizzoni, Pieter van Goor, Antonio Franchi</dc:creator>
    </item>
  </channel>
</rss>
