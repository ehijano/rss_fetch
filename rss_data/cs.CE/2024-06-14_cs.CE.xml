<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CE</link>
    <description>cs.CE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 14 Jun 2024 04:01:03 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 14 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Knowledge Graphs in the Digital Twin: A Systematic Literature Review About the Combination of Semantic Technologies and Simulation in Industrial Automation</title>
      <link>https://arxiv.org/abs/2406.09042</link>
      <description>arXiv:2406.09042v1 Announce Type: new 
Abstract: The ongoing digitization of the industrial sector has reached a pivotal juncture with the emergence of Digital Twins, offering a digital representation of physical assets and processes. One key aspect of those digital representations are simulation models, enabling a deeper insight in the assets current state and its characteristics. This paper asserts that the next evolutionary step in this digitization journey involves the integration of intelligent linkages between diverse simulation models within the Digital Twin framework. Crucially, for the Digital Twin to be a scalable and cost-effective solution, there is a pressing need for automated adaption, (re-)configuration, and generation of simulation models. Recognizing the inherent challenges in achieving such automation, this paper analyses the utilization of knowledge graphs as a potentially very suitable technological solution. Knowledge graphs, acting as interconnected and interrelated databases, provide a means of seamlessly integrating different data sources, facilitating the efficient integration and automated adaption of data and (simulation) models in the Digital Twin. We conducted a comprehensive literature review to analyze the current landscape of knowledge graphs in the context of Digital Twins with focus on simulation models. By addressing the challenges associated with scalability and maintenance, this research contributes to the effective adaption of Digital Twins in the industrial sector, paving the way for enhanced efficiency, adaptability, and resilience in the face of evolving technological landscapes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.09042v1</guid>
      <category>cs.CE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Franz Georg Listl, Daniel Dittler, Gary Hildebrandt, Valentin Stegmaier, Nasser Jazdi, Michael Weyrich</dc:creator>
    </item>
    <item>
      <title>Generative AI-based Prompt Evolution Engineering Design Optimization With Vision-Language Model</title>
      <link>https://arxiv.org/abs/2406.09143</link>
      <description>arXiv:2406.09143v1 Announce Type: cross 
Abstract: Engineering design optimization requires an efficient combination of a 3D shape representation, an optimization algorithm, and a design performance evaluation method, which is often computationally expensive. We present a prompt evolution design optimization (PEDO) framework contextualized in a vehicle design scenario that leverages a vision-language model for penalizing impractical car designs synthesized by a generative model. The backbone of our framework is an evolutionary strategy coupled with an optimization objective function that comprises a physics-based solver and a vision-language model for practical or functional guidance in the generated car designs. In the prompt evolutionary search, the optimizer iteratively generates a population of text prompts, which embed user specifications on the aerodynamic performance and visual preferences of the 3D car designs. Then, in addition to the computational fluid dynamics simulations, the pre-trained vision-language model is used to penalize impractical designs and, thus, foster the evolutionary algorithm to seek more viable designs. Our investigations on a car design optimization problem show a wide spread of potential car designs generated at the early phase of the search, which indicates a good diversity of designs in the initial populations, and an increase of over 20\% in the probability of generating practical designs compared to a baseline framework without using a vision-language model. Visual inspection of the designs against the performance results demonstrates prompt evolution as a very promising paradigm for finding novel designs with good optimization performance while providing ease of use in specifying design specifications and preferences via a natural language interface.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.09143v1</guid>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Melvin Wong, Thiago Rios, Stefan Menzel, Yew Soon Ong</dc:creator>
    </item>
    <item>
      <title>PyHexTop: a compact Python code for topology optimization using hexagonal elements</title>
      <link>https://arxiv.org/abs/2310.01968</link>
      <description>arXiv:2310.01968v3 Announce Type: replace 
Abstract: Python serves as an open-source and cost-effective alternative to the MATLAB programming language. This paper introduces a concise topology optimization Python code, named ``\texttt{PyHexTop}," primarily intended for educational purposes. Code employs hexagonal elements to parameterize design domains as such elements provide checkerboard-free optimized design naturally. \texttt{PyHexTop} is developed based on the ``\texttt{HoneyTop90}" MATLAB code~\cite{kumar2023honeytop90} and uses the \texttt{NumPy} and \texttt{SciPy} libraries. Code is straightforward and easily comprehensible, proving a helpful tool that can help people new in the topology optimization field to learn and explore. \texttt{PyHexTop} is specifically tailored to address compliance minimization with specified volume constraints. The paper provides a detailed explanation of the code for solving the Messerschmitt-Bolkow-Blohm beam and extensions to solve problems different problems. The code is publicly shared at: \url{https://github.com/PrabhatIn/PyHexTop.}</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.01968v3</guid>
      <category>cs.CE</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aditi Agarwal, Anupam Saxena, Prabhat Kumar</dc:creator>
    </item>
    <item>
      <title>Mastering truss structure optimization with tree search</title>
      <link>https://arxiv.org/abs/2406.06145</link>
      <description>arXiv:2406.06145v2 Announce Type: replace 
Abstract: This study investigates the combined use of generative grammar rules and Monte Carlo Tree Search (MCTS) for optimizing truss structures. Our approach accommodates intermediate construction stages characteristic of progressive construction settings. We demonstrate the significant robustness and computational efficiency of our approach compared to alternative reinforcement learning frameworks from previous research activities, such as Q-learning or deep Q-learning. These advantages stem from the ability of MCTS to strategically navigate large state spaces, leveraging the upper confidence bound for trees formula to effectively balance exploitation-exploration trade-offs. We also emphasize the importance of early decision nodes in the search tree, reflecting design choices crucial for identifying the global optimum. Additionally, we show how MCTS dynamically adapts to complex and extensive state spaces without significantly affecting solution quality. While the focus of this paper is on truss optimization, our findings suggest MCTS as a powerful tool for addressing other increasingly complex engineering applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06145v2</guid>
      <category>cs.CE</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gabriel Garayalde, Luca Rosafalco, Matteo Torzoni, Alberto Corigliano</dc:creator>
    </item>
    <item>
      <title>ESM All-Atom: Multi-scale Protein Language Model for Unified Molecular Modeling</title>
      <link>https://arxiv.org/abs/2403.12995</link>
      <description>arXiv:2403.12995v4 Announce Type: replace-cross 
Abstract: Protein language models have demonstrated significant potential in the field of protein engineering. However, current protein language models primarily operate at the residue scale, which limits their ability to provide information at the atom level. This limitation prevents us from fully exploiting the capabilities of protein language models for applications involving both proteins and small molecules. In this paper, we propose ESM-AA (ESM All-Atom), a novel approach that enables atom-scale and residue-scale unified molecular modeling. ESM-AA achieves this by pre-training on multi-scale code-switch protein sequences and utilizing a multi-scale position encoding to capture relationships among residues and atoms. Experimental results indicate that ESM-AA surpasses previous methods in protein-molecule tasks, demonstrating the full utilization of protein language models. Further investigations reveal that through unified molecular modeling, ESM-AA not only gains molecular knowledge but also retains its understanding of proteins. The source codes of ESM-AA are publicly released at https://github.com/zhengkangjie/ESM-AA.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12995v4</guid>
      <category>q-bio.BM</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Kangjie Zheng (equal contribution), Siyu Long (equal contribution), Tianyu Lu, Junwei Yang, Xinyu Dai, Ming Zhang, Zaiqing Nie, Wei-Ying Ma, Hao Zhou</dc:creator>
    </item>
  </channel>
</rss>
