<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.data-an updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.data-an</link>
    <description>physics.data-an updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.data-an" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 09 Apr 2025 04:00:11 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Improved Inference of Inverse Ising Problems under Missing Observations in Restricted Boltzmann Machines</title>
      <link>https://arxiv.org/abs/2504.05643</link>
      <description>arXiv:2504.05643v1 Announce Type: cross 
Abstract: Restricted Boltzmann machines (RBMs) are energy-based models analogous to the Ising model and are widely applied in statistical machine learning. The standard inverse Ising problem with a complete dataset requires computing both data and model expectations and is computationally challenging because model expectations have a combinatorial explosion. Furthermore, in many applications, the available datasets are partially incomplete, making it difficult to compute even data expectations. In this study, we propose a approximation framework for these expectations in the practical inverse Ising problems that integrates mean-field approximation or persistent contrastive divergence to generate refined initial points and spatial Monte Carlo integration to enhance estimator accuracy. We demonstrate that the proposed method effectively and accurately tunes the model parameters in comparison to the conventional method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.05643v1</guid>
      <category>stat.ML</category>
      <category>cond-mat.dis-nn</category>
      <category>cs.LG</category>
      <category>physics.data-an</category>
      <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kaiji Sekimoto, Muneki Yasuda</dc:creator>
    </item>
    <item>
      <title>Quantifying uncertainty in inverse scattering problems set in layered environments</title>
      <link>https://arxiv.org/abs/2504.05776</link>
      <description>arXiv:2504.05776v1 Announce Type: cross 
Abstract: The attempt to solve inverse scattering problems often leads to optimization and sampling problems that require handling moderate to large amounts of partial differential equations acting as constraints. We focus here on determining inclusions in a layered medium from the measurement of wave fields on the surface, while quantifying uncertainty and addressing the effect of wave solver quality. Inclusions are characterized by a few parameters describing their material properties and shapes. We devise algorithms to estimate the most likely configurations by optimizing cost functionals with Bayesian regularizations and wave constraints. In particular, we design an automatic Levenberg-Marquardt-Fletcher type scheme based on the use of algorithmic differentiation and adaptive finite element meshes for time dependent wave equation constraints with changing inclusions. In synthetic tests with a single frequency, this scheme converges in few iterations for increasing noise levels. To attain a global view of other possible high probability configurations and asymmetry effects we resort to parallelizable affine invariant Markov Chain Monte Carlo methods, at the cost of solving a few million wave problems. This forces the use of prefixed meshes. While the optimal configurations remain similar, we encounter additional high probability inclusions influenced by the prior information, the noise level and the layered structure, effect that can be reduced by considering more frequencies. We analyze the effect on the calculations of working with adaptive and fixed meshes, under a simple choice of non-reflecting boundary conditions in truncated layered domains for which we establish wellposedness and convergence results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.05776v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <category>physics.comp-ph</category>
      <category>physics.data-an</category>
      <category>physics.geo-ph</category>
      <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.amc.2025.129453</arxiv:DOI>
      <arxiv:journal_reference>Applied Mathematics and Computation 500 (2025) 129453</arxiv:journal_reference>
      <dc:creator>Carolina Abugattas, Ana Carpio, Elena Cebri\'an, Gerardo Oleaga</dc:creator>
    </item>
    <item>
      <title>Greedy Emulators for Nuclear Two-Body Scattering</title>
      <link>https://arxiv.org/abs/2504.06092</link>
      <description>arXiv:2504.06092v1 Announce Type: cross 
Abstract: Applications of reduced basis method emulators are increasing in low-energy nuclear physics because they enable fast and accurate sampling of high-fidelity calculations, enabling robust uncertainty quantification. In this paper, we develop, implement, and test two model-driven emulators based on (Petrov-)Galerkin projection using the prototypical test case of two-body scattering with the Minnesota potential and a more realistic local chiral potential. The high-fidelity scattering equations are solved with the matrix Numerov method, a reformulation of the popular Numerov recurrence relation for solving special second-order differential equations as a linear system of coupled equations. A novel error estimator based on reduced-space residuals is applied to an active learning approach (a greedy algorithm) to choosing training samples ("snapshots") for the emulator and contrasted with a proper orthogonal decomposition (POD) approach. Both approaches allow for computationally efficient offline-online decompositions, but the greedy approach requires much fewer snapshot calculations. These developments set the groundwork for emulating scattering observables based on chiral nucleon-nucleon and three-nucleon interactions and optical models, where computational speed-ups are necessary for Bayesian uncertainty quantification. Our emulators and error estimators are widely applicable to linear systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.06092v1</guid>
      <category>nucl-th</category>
      <category>hep-ph</category>
      <category>nucl-ex</category>
      <category>physics.data-an</category>
      <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>J. M. Maldonado, C. Drischler, R. J. Furnstahl, P. Mlinari\'c</dc:creator>
    </item>
    <item>
      <title>Active and transfer learning with partially Bayesian neural networks for materials and chemicals</title>
      <link>https://arxiv.org/abs/2501.00952</link>
      <description>arXiv:2501.00952v2 Announce Type: replace-cross 
Abstract: Active learning, an iterative process of selecting the most informative data points for exploration, is crucial for efficient characterization of materials and chemicals property space. Neural networks excel at predicting these properties but lack the uncertainty quantification needed for active learning-driven exploration. Fully Bayesian neural networks, in which weights are treated as probability distributions inferred via advanced Markov Chain Monte Carlo methods, offer robust uncertainty quantification but at high computational cost. Here, we show that partially Bayesian neural networks (PBNNs), where only selected layers have probabilistic weights while others remain deterministic, can achieve accuracy and uncertainty estimates on active learning tasks comparable to fully Bayesian networks at lower computational cost. Furthermore, by initializing prior distributions with weights pre-trained on theoretical calculations, we demonstrate that PBNNs can effectively leverage computational predictions to accelerate active learning of experimental data. We validate these approaches on both molecular property prediction and materials science tasks, establishing PBNNs as a practical tool for active learning with limited, complex datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.00952v2</guid>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.mtrl-sci</category>
      <category>physics.data-an</category>
      <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sarah I. Allec, Maxim Ziatdinov</dc:creator>
    </item>
  </channel>
</rss>
