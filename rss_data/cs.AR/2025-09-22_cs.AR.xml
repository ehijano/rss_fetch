<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.AR updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.AR</link>
    <description>cs.AR updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.AR" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 22 Sep 2025 04:00:14 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Automatic Microarchitecture-Aware Custom Instruction Design for RISC-V Processors</title>
      <link>https://arxiv.org/abs/2509.15782</link>
      <description>arXiv:2509.15782v1 Announce Type: new 
Abstract: An Application-Specific Instruction Set Processor(ASIP) is a specialized microprocessor that provides a trade-off between the programmability of a General Purpose Processor (GPP) and the performance and energy-efficiency of dedicated hardware accelerators. ASIPs are often derived from off-the-shelf GPPs extended by custom instructions tailored towards a specific software workload. One of the most important challenges of designing an ASIP is to find said custom instructions that help to increase performance without being too costly in terms of area and power consumption. To date, solving this challenge is relatively labor-intensive and typically performed manually. Addressing the lack of automation, we present Custom Instruction Designer for RISC-V Extensions (CIDRE), a front-to-back tool for ASIP design. CIDRE automatically analyzes hotspots in RISC-V applications and generates custom instruction suggestions with a corresponding nML description. The nML description can be used with other electronic design automation tools to accurately assess the cost and benefits of the found suggestions. In a RISC-V benchmark study, we were able to accelerate embedded benchmarks from Embench and MiBench by up to 2.47x with less than 24% area increase. The entire process was conducted completely automatically.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.15782v1</guid>
      <category>cs.AR</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Evgenii Rezunov, Niko Zurstra{\ss}en, Lennart M. Reimann, Rainer Leupers</dc:creator>
    </item>
    <item>
      <title>CLASS: A Controller-Centric Layout Synthesizer for Dynamic Quantum Circuits</title>
      <link>https://arxiv.org/abs/2509.15742</link>
      <description>arXiv:2509.15742v1 Announce Type: cross 
Abstract: Layout Synthesis for Quantum Computing (LSQC) is a critical component of quantum design tools. Traditional LSQC studies primarily focus on optimizing for reduced circuit depth by adopting a device-centric design methodology. However, these approaches overlook the impact of classical processing and communication time, thereby being insufficient for Dynamic Quantum Circuits (DQC).
  To address this, we introduce CLASS, a controller-centric layout synthesizer designed to reduce inter-controller communication latency in a distributed control system. It consists of a two-stage framework featuring a hypergraph-based modeling and a heuristic-based graph partitioning algorithm. Evaluations demonstrate that CLASS effectively reduces communication latency by up to 100% with only a 2.10% average increase in the number of additional operations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.15742v1</guid>
      <category>quant-ph</category>
      <category>cs.AR</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yu Chen, Yilun Zhao, Bing Li, He Li, Mengdi Wang, Yinhe Han, Ying Wang</dc:creator>
    </item>
    <item>
      <title>JugglePAC: A Pipelined Accumulation Circuit</title>
      <link>https://arxiv.org/abs/2310.01336</link>
      <description>arXiv:2310.01336v3 Announce Type: replace 
Abstract: Reducing a set of numbers to a single value is a fundamental operation in applications such as signal processing, data compression, scientific computing, and neural networks. Accumulation, which involves summing a dataset to obtain a single result, is crucial for these tasks. Due to hardware constraints, large vectors or matrices often cannot be fully stored in memory and must be read sequentially, one item per clock cycle. For high-speed inputs, such as rapidly arriving floating-point numbers, pipelined adders are necessary to maintain performance. However, pipelining introduces multiple intermediate sums and requires delays between back-to-back datasets unless their processing is overlapped. In this paper, we present JugglePAC, a novel accumulation circuit designed to address these challenges. JugglePAC operates quickly, is area-efficient, and features a fully pipelined design. It effectively manages back-to-back variable-length datasets while consistently producing results in the correct input order. Compared to the state-of-the-art, JugglePAC achieves higher throughput and reduces area complexity, offering significant improvements in performance and efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.01336v3</guid>
      <category>cs.AR</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/LES.2025.3602852</arxiv:DOI>
      <arxiv:journal_reference>IEEE Embedded Systems Letters, Early Access, pp. 1-1, Aug. 27, 2025</arxiv:journal_reference>
      <dc:creator>Ahmad Houraniah, H. Fatih Ugurdag, Furkan Aydin</dc:creator>
    </item>
    <item>
      <title>DataMaestro: A Versatile and Efficient Data Streaming Engine Bringing Decoupled Memory Access To Dataflow Accelerators</title>
      <link>https://arxiv.org/abs/2504.14091</link>
      <description>arXiv:2504.14091v2 Announce Type: replace 
Abstract: Deep Neural Networks (DNNs) have achieved remarkable success across various intelligent tasks but encounter performance and energy challenges in inference execution due to data movement bottlenecks. We introduce DataMaestro, a versatile and efficient data streaming unit that brings the decoupled access/execute architecture to DNN dataflow accelerators to address this issue. DataMaestro supports flexible and programmable access patterns to accommodate diverse workload types and dataflows, incorporates fine-grained prefetch and addressing mode switching to mitigate bank conflicts, and enables customizable on-the-fly data manipulation to reduce memory footprints and access counts. We integrate five DataMaestros with a Tensor Core-like GeMM accelerator and a Quantization accelerator into a RISC-V host system for evaluation. The FPGA prototype and VLSI synthesis results demonstrate that DataMaestro helps the GeMM core achieve nearly 100% utilization, which is 1.05-21.39x better than state-of-the-art solutions, while minimizing area and energy consumption to merely 6.43% and 15.06% of the total system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14091v2</guid>
      <category>cs.AR</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaoling Yi, Yunhao Deng, Ryan Antonio, Fanchen Kong, Guilherme Paim, Marian Verhelst</dc:creator>
    </item>
    <item>
      <title>Testing and Fault Tolerance Techniques for CNT-Based FPGAs</title>
      <link>https://arxiv.org/abs/2508.20304</link>
      <description>arXiv:2508.20304v2 Announce Type: replace 
Abstract: As the semiconductor manufacturing process technology node shrinks into the nanometer-scale, the CMOS-based Field Programmable Gate Arrays (FPGAs) face big challenges in scalability of performance and power consumption. Multi-walled Carbon Nanotube (MWCNT) serves as a promising candidate for Cu interconnects thanks to the superior conductivity. Moreover, Carbon Nanotube Field Transistor (CNFET) also emerges as a prospective alternative to the conventional CMOS device because of high power efficiency and large noise margin. The combination of MWCNT and CNFET enables the promising CNT-based FPGAs. However, the MWCNT interconnects exhibit significant process variations due to immature fabrication process, leading to delay faults. Also, the non-ideal CNFET fabrication process may generate a few metallic CNTs (m-CNTs), rendering correlated faulty blocks. In this article, we propose a ring oscillator (RO) based testing technique to detect delay faults due to the process variation of MWCNT interconnects. Furthermore, we propose an effective testing technique for the carry chains in CLBs, and an improved circuit design based on the lookup table (LUT) is applied to speed up the fault testing of CNT-based FPGAs. In addition, we propose a testing algorithm to detect m-CNTs in CLBs. Finally, we propose a redundant spare row sharing architecture to improve the yield of CNT-based FPGA further. Experimental results show that the test time for a 6-input LUT can be reduced by 35.49% compared with conventional testing, and the proposed algorithm can achieve a high test coverage with little overhead. The proposed redundant architecture can repair the faulty segment effectively and efficiently.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.20304v2</guid>
      <category>cs.AR</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Siyuan Lu, Kangwei Xu, Peng Xie, Rui Wang, Yuanqing Cheng</dc:creator>
    </item>
    <item>
      <title>Automated CGRA Design with Multi-Agent LLMs: A Unified Hardware-Software Co-Design Framework</title>
      <link>https://arxiv.org/abs/2509.13557</link>
      <description>arXiv:2509.13557v3 Announce Type: replace 
Abstract: Coarse-grained Reconfigurable Arrays (CGRAs) are a promising computing architecture that can deliver high-performance, energy-efficient acceleration across diverse domains. By supporting reconfiguration at the functional unit level, CGRAs efficiently adapt to varying computational patterns and optimize resource utilization. However, designing CGRAs is highly challenging due to the vast design space, independent architectural parameters, and the time-consuming nature of manual design. Fortunately, the rapid advancement of large language models (LLMs) presents new opportunities to automate this process.
  In this work, we propose MACO -- an open-source multi-agent LLM-based framework for Hardware/Software (HW/SW) co-design of CGRAs. The framework employs LLM reasoning to generate CGRAs across four stages: HW/SW co-design, Design error correction, Best design selection, and Evaluation &amp; Feedback. Furthermore, MACO iteratively optimizes the generated CGRAs, leveraging agent reasoning and feedback to achieve higher PPA (that is, power, performance, and area) design points for a given domain. In addition, we introduce an LLM self-learning mechanism that employs LLM-driven decision making to select the optimal CGRA to accelerate the design process.
  We evaluate the framework with state-of-the-art LLM-based methods and manual CGRA design, in terms of performance, power consumption, and area. Experimental results show that MACO efficiently generates high-quality CGRA architectures, significantly reducing manual design effort and demonstrating the potential of our framework for real-world CGRA design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.13557v3</guid>
      <category>cs.AR</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zesong Jiang, Yuqi Sun, Qing Zhong, Mahathi Krishna, Deepak Patil, Cheng Tan, Sriram Krishnamoorthy, Jeff Zhang</dc:creator>
    </item>
    <item>
      <title>Analog In-memory Training on General Non-ideal Resistive Elements: The Impact of Response Functions</title>
      <link>https://arxiv.org/abs/2502.06309</link>
      <description>arXiv:2502.06309v3 Announce Type: replace-cross 
Abstract: As the economic and environmental costs of training and deploying large vision or language models increase dramatically, analog in-memory computing (AIMC) emerges as a promising energy-efficient solution. However, the training perspective, especially its training dynamic, is underexplored. In AIMC hardware, the trainable weights are represented by the conductance of resistive elements and updated using consecutive electrical pulses. While the conductance changes by a constant in response to each pulse, in reality, the change is scaled by asymmetric and non-linear \textit{response functions}, leading to a non-ideal training dynamic. This paper provides a theoretical foundation for gradient-based training on AIMC hardware with non-ideal response functions. We demonstrate that asymmetric response functions negatively impact Analog SGD by imposing an implicit penalty on the objective. To overcome the issue, we propose Residual Learning algorithm, which provably converges exactly to a critical point by solving a bilevel optimization problem. We demonstrate that the proposed method can be extended to address other hardware imperfections, such as limited response granularity. As we know, it is the first paper to investigate the impact of a class of generic non-ideal response functions. The conclusion is supported by simulations validating our theoretical insights.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06309v3</guid>
      <category>cs.LG</category>
      <category>cs.AR</category>
      <category>math.OC</category>
      <pubDate>Mon, 22 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhaoxian Wu, Quan Xiao, Tayfun Gokmen, Omobayode Fagbohungbe, Tianyi Chen</dc:creator>
    </item>
  </channel>
</rss>
