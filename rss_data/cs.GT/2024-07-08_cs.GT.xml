<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 09 Jul 2024 04:00:20 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 09 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Maximizing utility in multi-agent environments by anticipating the behavior of other learners</title>
      <link>https://arxiv.org/abs/2407.04889</link>
      <description>arXiv:2407.04889v1 Announce Type: new 
Abstract: Learning algorithms are often used to make decisions in sequential decision-making environments. In multi-agent settings, the decisions of each agent can affect the utilities/losses of the other agents. Therefore, if an agent is good at anticipating the behavior of the other agents, in particular how they will make decisions in each round as a function of their experience that far, it could try to judiciously make its own decisions over the rounds of the interaction so as to influence the other agents to behave in a way that ultimately benefits its own utility. In this paper, we study repeated two-player games involving two types of agents: a learner, which employs an online learning algorithm to choose its strategy in each round; and an optimizer, which knows the learner's utility function and the learner's online learning algorithm. The optimizer wants to plan ahead to maximize its own utility, while taking into account the learner's behavior. We provide two results: a positive result for repeated zero-sum games and a negative result for repeated general-sum games. Our positive result is an algorithm for the optimizer, which exactly maximizes its utility against a learner that plays the Replicator Dynamics -- the continuous-time analogue of Multiplicative Weights Update (MWU). Additionally, we use this result to provide an algorithm for the optimizer against MWU, i.e.~for the discrete-time setting, which guarantees an average utility for the optimizer that is higher than the value of the one-shot game. Our negative result shows that, unless P=NP, there is no Fully Polynomial Time Approximation Scheme (FPTAS) for maximizing the utility of an optimizer against a learner that best-responds to the history in each round. Yet, this still leaves open the question of whether there exists a polynomial-time algorithm that optimizes the utility up to $o(T)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04889v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Angelos Assos, Yuval Dagan, Constantinos Daskalakis</dc:creator>
    </item>
    <item>
      <title>Nash Incentive-compatible Online Mechanism Learning via Weakly Differentially Private Online Learning</title>
      <link>https://arxiv.org/abs/2407.04898</link>
      <description>arXiv:2407.04898v1 Announce Type: new 
Abstract: We study a multi-round mechanism design problem, where we interact with a set of agents over a sequence of rounds. We wish to design an incentive-compatible (IC) online learning scheme to maximize an application-specific objective within a given class of mechanisms, without prior knowledge of the agents' type distributions. Even if each mechanism in this class is IC in a single round, if an algorithm naively chooses from this class on each round, the entire learning process may not be IC against non-myopic buyers who appear over multiple rounds. On each round, our method randomly chooses between the recommendation of a weakly differentially private online learning algorithm (e.g., Hedge), and a commitment mechanism which penalizes non-truthful behavior. Our method is IC and achieves $O(T^{\frac{1+h}{2}})$ regret for the application-specific objective in an adversarial setting, where $h$ quantifies the long-sightedness of the agents. When compared to prior work, our approach is conceptually simpler,it applies to general mechanism design problems (beyond auctions), and its regret scales gracefully with the size of the mechanism class.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04898v1</guid>
      <category>cs.GT</category>
      <category>cs.CR</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joon Suk Huh, Kirthevasan Kandasamy</dc:creator>
    </item>
    <item>
      <title>Equitable Congestion Pricing under the Markovian Traffic Model: An Application to Bogota</title>
      <link>https://arxiv.org/abs/2407.05035</link>
      <description>arXiv:2407.05035v1 Announce Type: new 
Abstract: Congestion pricing is used to raise revenues and reduce traffic and pollution. However, people have heterogeneous spatial demand patterns and willingness (or ability) to pay tolls, and so pricing may have substantial equity implications. We develop a data-driven approach to design congestion pricing given policymakers' equity and efficiency objectives. First, algorithmically, we extend the Markovian traffic equilibrium setting introduced by Baillon &amp; Cominetti (2008) to model heterogeneous populations and incorporate prices and outside options such as public transit. Second, we empirically evaluate various pricing schemes using data collected by an industry partner in the city of Bogota, one of the most congested cities in the world. We find that pricing personalized to each economic stratum can be substantially more efficient and equitable than uniform pricing; however, non-personalized but area-based pricing can recover much of the gap.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.05035v1</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Alfredo Torrico, Natthawut Boonsiriphatthanajaroen, Nikhil Garg, Andrea Lodi, Hugo Mainguy</dc:creator>
    </item>
    <item>
      <title>Almost Envy-free Allocation of Indivisible Goods: A Tale of Two Valuations</title>
      <link>https://arxiv.org/abs/2407.05139</link>
      <description>arXiv:2407.05139v1 Announce Type: new 
Abstract: The existence of $\textsf{EFX}$ allocations stands as one of the main challenges in discrete fair division. In this paper, we present a collection of symmetrical results on the existence of $\textsf{EFX}$ notion and its approximate variations. These results pertain to two seemingly distinct valuation settings: the restricted additive valuations and $(p,q)$-bounded valuations recently introduced by Christodoulou \textit{et al.} \cite{christodoulou2023fair}. In a $(p,q)$-bonuded instance, each good holds relevance (i.e., has a non-zero marginal value) for at most $p$ agents, and any pair of agents share at most $q$ common relevant goods. The only known guarantees on $(p,q)$-bounded valuations is that $(2,1)$-bounded instances always admit $\textsf{EFX}$ allocations (EC'22) \cite{christodoulou2023fair}. Here we show that instances with $(\infty,1)$-bounded valuations always admit $\textsf{EF2X}$ allocations, and $\textsf{EFX}$ allocations with at most $\lfloor {n}/{2} \rfloor - 1$ discarded goods. These results mirror the existing results for the restricted additive setting \cite{akrami2023efx}. Moreover, we present $({\sqrt{2}}/{2})-\textsf{EFX}$ allocation algorithms for both the restricted additive and $(\infty,1)$-bounded settings.
  The symmetry of these results suggests that these valuations exhibit symmetric structures. Building on this observation, we conjectured that the $(2,\infty)$-bounded and restricted additive setting might admit $\textsf{EFX}$ guarantee. Intriguingly, our investigation confirms this conjecture. We propose a rather complex $\textsf{EFX}$ allocation algorithm for restricted additive valuations when $p=2$ and $q=\infty$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.05139v1</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alireza Kaviani, Masoud Seddighin, AmirMohammad Shahrezaei</dc:creator>
    </item>
    <item>
      <title>Neighborhood Stability in Assignments on Graphs</title>
      <link>https://arxiv.org/abs/2407.05240</link>
      <description>arXiv:2407.05240v1 Announce Type: new 
Abstract: We study the problem of assigning agents to the vertices of a graph such that no pair of neighbors can benefit from swapping assignments -- a property we term neighborhood stability. We further assume that agents' utilities are based solely on their preferences over the assignees of adjacent vertices and that those preferences are binary. Having shown that even this very restricted setting does not guarantee neighborhood stable assignments, we focus on special cases that provide such guarantees. We show that when the graph is a cycle or a path, a neighborhood stable assignment always exists for any preference profile. Furthermore, we give a general condition under which neighborhood stable assignments always exist. For each of these results, we give a polynomial-time algorithm to compute a neighborhood stable assignment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.05240v1</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haris Aziz, Grzegorz Lisowski, Mashbat Suzuki, Jeremy Vollen</dc:creator>
    </item>
    <item>
      <title>Hiring for An Uncertain Task: Joint Design of Information and Contracts</title>
      <link>https://arxiv.org/abs/2407.05459</link>
      <description>arXiv:2407.05459v1 Announce Type: new 
Abstract: In this paper, we initiate the computational problem of jointly designing information and contracts. We consider three possible classes of contracts with decreasing flexibility and increasing simplicity: ambiguous contracts, menus of explicit contracts and explicit single contract. Ambiguous contracts allow the principal to conceal the applied payment schemes through a contract that depends on the unknown state of nature, while explicit contracts reveal the contract prior to the agent's decision. Our results show a trade-off between the simplicity of the contracts and the computational complexity of the joint design. Indeed, we show that an approximately-optimal mechanism with ambiguous contracts can be computed in polynomial time. However, they are convoluted mechanisms and not well-suited for some real-world scenarios. Conversely, explicit menus of contracts and single contracts are simpler mechanisms, but they cannot be computed efficiently. In particular, we show that computing the optimal mechanism with explicit menus of contracts and single contracts is APX-Hard. We also characterize the structure of optimal mechanisms. Interestingly, direct mechanisms are optimal for both the most flexible ambiguous contracts and the least flexible explicit single contract, but they are suboptimal for that with menus of contracts. Finally, motivated by our hardness results, we turn our attention to menus of linear contracts and single linear contracts. We show that both the problem of computing the optimal mechanism with an explicit menu of linear contracts and an explicit single linear contract admits an FPTAS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.05459v1</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matteo Castiglioni, Junjie Chen</dc:creator>
    </item>
    <item>
      <title>Basins of Attraction in Two-Player Random Ordinal Potential Games</title>
      <link>https://arxiv.org/abs/2407.05460</link>
      <description>arXiv:2407.05460v1 Announce Type: new 
Abstract: We consider the class of two-person ordinal potential games where each player has the same number of actions $K$. Each game in this class admits at least one pure Nash equilibrium and the best-response dynamics converges to one of these pure Nash equilibria; which one depends on the starting point. So, each pure Nash equilibrium has a basin of attraction.
  We pick uniformly at random one game from this class and we study the joint distribution of the sizes of the basins of attraction. We provide an asymptotic exact value for the expected basin of attraction of each pure Nash equilibrium, when the number of actions $K$ goes to infinity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.05460v1</guid>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <category>math.PR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrea Collevecchio, Hlafo Alfie Mimun, Matteo Quattropani, Marco Scarsini</dc:creator>
    </item>
    <item>
      <title>Fair and Truthful Allocations Under Leveled Valuations</title>
      <link>https://arxiv.org/abs/2407.05891</link>
      <description>arXiv:2407.05891v1 Announce Type: new 
Abstract: We study the problem of fairly allocating indivisible goods among agents which are equipped with {\em leveled} valuation functions. Such preferences, that have been studied before in economics and fair division literature, capture a simple and intuitive economic behavior; larger bundles are always preferred to smaller ones. We provide a fine-grained analysis for various subclasses of leveled valuations focusing on two extensively studied notions of fairness, (approximate) MMS and EFX. In particular, we present a general positive result, showing the existence of $2/3$-MMS allocations under valuations that are both leveled and submodular. We also show how some of our ideas can be used beyond the class of leveled valuations; for the case of two submodular (not necessarily leveled) agents we show that there always exists a $2/3$-MMS allocation, complementing a recent impossibility result. Then, we switch to the case of subadditive and fractionally subadditive leveled agents, where we are able to show tight (lower and upper) bounds of $1/2$ on the approximation factor of MMS. Moreover, we show the existence of exact EFX allocations under general leveled valuations via a simple protocol that in addition satisfies several natural economic properties. Finally, we take a mechanism design approach and we propose protocols that are both truthful and approximately fair under leveled valuations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.05891v1</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>George Christodoulou, Vasilis Christoforidis</dc:creator>
    </item>
    <item>
      <title>What's the Best Seat in the Game Left, Center, Right?</title>
      <link>https://arxiv.org/abs/2407.05069</link>
      <description>arXiv:2407.05069v1 Announce Type: cross 
Abstract: Left, Center, Right is a popular dice game. We analyze the game using Markov chain and Monte Carlo methods. We compute the expected game length for two to eight players and determine the probability of winning for each player in the game. We discuss the surprising conclusions of which players have the highest and lowest chance of winning, and we propose a small rule change that makes the game a little more fair.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.05069v1</guid>
      <category>math.HO</category>
      <category>cs.GT</category>
      <category>math.PR</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Benjamin Richeson, David Richeson</dc:creator>
    </item>
    <item>
      <title>Collective Upkeep</title>
      <link>https://arxiv.org/abs/2407.05196</link>
      <description>arXiv:2407.05196v1 Announce Type: cross 
Abstract: We design mechanisms for maintaining public goods which require periodic non-monetary contributions. Utilitarian welfare is maximized by concentrating contributions among low-cost group members, but such policies generally induce some members to leave the group or misreport their preferences. To forestall exit, contributions must be shifted from members with intermediate costs to some high-cost members. To deter misreporting, members must be screened using up to two membership tiers, which reward larger contributions with increased access to the good. We apply our results to the design of platforms such as Netflix and TikTok hosting crowd-sourced recommendation engines, which function as public goods supported by user feedback about new content.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.05196v1</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Erik Madsen, Eran Shmaya</dc:creator>
    </item>
    <item>
      <title>Learning to Price Homogeneous Data</title>
      <link>https://arxiv.org/abs/2407.05484</link>
      <description>arXiv:2407.05484v1 Announce Type: cross 
Abstract: We study a data pricing problem, where a seller has access to $N$ homogeneous data points (e.g. drawn i.i.d. from some distribution). There are $m$ types of buyers in the market, where buyers of the same type $i$ have the same valuation curve $v_i:[N]\rightarrow [0,1]$, where $v_i(n)$ is the value for having $n$ data points. \textit{A priori}, the seller is unaware of the distribution of buyers, but can repeat the market for $T$ rounds so as to learn the revenue-optimal pricing curve $p:[N] \rightarrow [0, 1]$. To solve this online learning problem, we first develop novel discretization schemes to approximate any pricing curve. When compared to prior work, the size of our discretization schemes scales gracefully with the approximation parameter, which translates to better regret in online learning. Under assumptions like smoothness and diminishing returns which are satisfied by data, the discretization size can be reduced further. We then turn to the online learning problem, both in the stochastic and adversarial settings. On each round, the seller chooses an \emph{anonymous} pricing curve $p_t$. A new buyer appears and may choose to purchase some amount of data. She then reveals her type \emph{only if} she makes a purchase. Our online algorithms build on classical algorithms such as UCB and FTPL, but require novel ideas to account for the asymmetric nature of this feedback and to deal with the vastness of the space of pricing curves. Using the improved discretization schemes previously developed, we are able to achieve $\tilde{O}\left(m\sqrt{T}\right)$ regret in the stochastic setting and $\tilde{O}\left(m^{\frac{3}{2}}\sqrt{T}\right)$ regret in the adversarial setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.05484v1</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Keran Chen, Joon Suk Huh, Kirthevasan Kandasamy</dc:creator>
    </item>
    <item>
      <title>Learning-Augmented Metric Distortion via $(p,q)$-Veto Core</title>
      <link>https://arxiv.org/abs/2307.07495</link>
      <description>arXiv:2307.07495v2 Announce Type: replace 
Abstract: In the metric distortion problem there is a set of candidates $C$ and voters $V$ in the same metric space. The goal is to select a candidate minimizing the social cost: the sum of distances of the selected candidate from all the voters, and the challenge arises from the algorithm receiving only ordinaL input: each voter's ranking of candidate, while the objective function is cardinal, determined by the underlying metric. The distortion of an algorithm is its worst-case approximation factor of the optimal social cost.
  A key concept here is the (p,q)-veto core, with $p\in \Delta(V)$ and $q\in \Delta(C)$ being normalized weight vectors representing voters' veto power and candidates' support, respectively. The (p,q)-veto core corresponds to a set of winners from a specific class of deterministic algorithms. Notably, the optimal distortion of $3$ is obtained from this class, by selecting veto core candidates using uniform $p$ and $q$ proportional to candidates' plurality scores. Bounding the distortion of other algorithms from this class is an open problem.
  Our contribution is twofold. First, we establish upper bounds on the distortion of candidates from the (p,q)-veto core for arbitrary weight vectors $p$ and $q$. Second, we revisit the metric distortion problem through the \emph{learning-augmented} framework, which equips the algorithm with a (machine-learned) prediction regarding the optimal candidate. The quality of this prediction is unknown, and the goal is to optimize the algorithm's performance under accurate predictions (consistency), while simultaneously providing worst-case guarantees under arbitrarily inaccurate predictions (robustness). We propose an algorithm that chooses candidates from the (p,q)-veto core, using a prediction-guided q vector and, leveraging our distortion bounds, we prove that this algorithm achieves the optimal robustness-consistency trade-off.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.07495v2</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ben Berger, Michal Feldman, Vasilis Gkatzelis, Xizhi Tan</dc:creator>
    </item>
    <item>
      <title>Strategically-Robust Learning Algorithms for Bidding in First-Price Auctions</title>
      <link>https://arxiv.org/abs/2402.07363</link>
      <description>arXiv:2402.07363v2 Announce Type: replace 
Abstract: Learning to bid in repeated first-price auctions is a fundamental problem at the interface of game theory and machine learning, which has seen a recent surge in interest due to the transition of display advertising to first-price auctions. In this work, we propose a novel concave formulation for pure-strategy bidding in first-price auctions, and use it to analyze natural Gradient-Ascent-based algorithms for this problem. Importantly, our analysis goes beyond regret, which was the typical focus of past work, and also accounts for the strategic backdrop of online-advertising markets where bidding algorithms are deployed -- we provide the first guarantees of strategic-robustness and incentive-compatibility for Gradient Ascent.
  Concretely, we show that our algorithms achieve $O(\sqrt{T})$ regret when the highest competing bids are generated adversarially, and show that no online algorithm can do better. We further prove that the regret reduces to $O(\log T)$ when the competition is stationary and stochastic, which drastically improves upon the previous best of $O(\sqrt{T})$. Moving beyond regret, we show that a strategic seller cannot exploit our algorithms to extract more revenue on average than is possible under the optimal mechanism. Finally, we prove that our algorithm is also incentive compatible -- it is a (nearly) dominant strategy for the buyer to report her values truthfully to the algorithm as a whole. Altogether, these guarantees make our algorithms the first to simultaneously achieve both optimal regret and strategic-robustness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.07363v2</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rachitesh Kumar, Jon Schneider, Balasubramanian Sivan</dc:creator>
    </item>
    <item>
      <title>Safe Pareto Improvements for Expected Utility Maximizers in Program Games</title>
      <link>https://arxiv.org/abs/2403.05103</link>
      <description>arXiv:2403.05103v3 Announce Type: replace 
Abstract: Agents in mixed-motive coordination problems such as Chicken may fail to coordinate on a Pareto-efficient outcome. Safe Pareto improvements (SPIs) were originally proposed to mitigate miscoordination in cases where players lack probabilistic beliefs as to how their delegates will play a game; delegates are instructed to behave so as to guarantee a Pareto improvement on how they would play by default. More generally, SPIs may be defined as transformations of strategy profiles such that all players are necessarily better off under the transformed profile. In this work, we investigate the extent to which SPIs can reduce downsides of miscoordination between expected utility-maximizing agents. We consider games in which players submit computer programs that can condition their decisions on each other's code, and use this property to construct SPIs using programs capable of renegotiation. We first show that under mild conditions on players' beliefs, each player always prefers to use renegotiation. Next, we show that under similar assumptions, each player always prefers to be willing to renegotiate at least to the point at which they receive the lowest payoff they can attain in any efficient outcome. Thus subjectively optimal play guarantees players at least these payoffs, without the need for coordination on specific Pareto improvements. Lastly, we prove that renegotiation does not guarantee players any improvements on this bound.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05103v3</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anthony DiGiovanni, Jesse Clifton, Nicolas Mac\'e</dc:creator>
    </item>
    <item>
      <title>Strategy-Proof Auctions through Conformal Prediction</title>
      <link>https://arxiv.org/abs/2405.12016</link>
      <description>arXiv:2405.12016v3 Announce Type: replace 
Abstract: Auctions are key for maximizing sellers' revenue and ensuring truthful bidding among buyers. Recently, an approach known as differentiable economics based on deep learning shows promise in learning optimal auction mechanisms for multiple items and participants. However, this approach has no guarantee of strategy-proofness at test time. Strategy-proofness is crucial as it ensures that buyers are incentivized to bid their true valuations, leading to optimal and fair auction outcomes without the risk of manipulation. Building on conformal prediction, we introduce a novel approach to achieve strategy-proofness with rigorous statistical guarantees. The key novelties of our method are: (i) the formulation of a regret prediction model, used to quantify at test time violations of strategy-proofness; and (ii) an auction acceptance rule that leverages the predicted regret to ensure that for a new auction, the data-driven mechanism meets the strategy-proofness requirement with high probability (e.g., 99\%). Numerical experiments demonstrate the necessity for rigorous guarantees, the validity of our theoretical results, and the applicability of our proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12016v3</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Roy Maor Lotan, Inbal Talgam-Cohen, Yaniv Romano</dc:creator>
    </item>
    <item>
      <title>Specifying a Game-Theoretic Extensive Form as an Abstract 5-ary Relation</title>
      <link>https://arxiv.org/abs/2107.10801</link>
      <description>arXiv:2107.10801v5 Announce Type: replace-cross 
Abstract: This paper specifies an extensive form as a 5-ary relation (that is, as a set of quintuples) which satisfies eight abstract axioms. Each quintuple is understood to list a player, a situation (that is, a name for an information set), a decision node, an action, and a successor node. Accordingly, the axioms are understood to specify abstract relationships between players, situations, nodes, and actions. Such an extensive form is called a "pentaform". Finally, a "pentaform game" is defined to be a pentaform together with utility functions.
  To ground this new specification in the literature, the paper defines the concept of a "traditional game" to represent the literature's many specifications of finite-horizon and infinite-horizon games. The paper's main result is to construct an intuitive bijection between pentaform games and traditional games. Secondary results concern disaggregating pentaforms by subsets, constructing pentaforms by unions, and initial pentaform applications to Selten subgames and perfect-recall (an extensive application to dynamic programming is in Streufert 2023, arXiv:2302.03855).</description>
      <guid isPermaLink="false">oai:arXiv.org:2107.10801v5</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <category>cs.LO</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Peter A. Streufert</dc:creator>
    </item>
    <item>
      <title>An extension of May's Theorem to three alternatives: axiomatizing Minimax voting</title>
      <link>https://arxiv.org/abs/2312.14256</link>
      <description>arXiv:2312.14256v3 Announce Type: replace-cross 
Abstract: May's Theorem [K. O. May, Econometrica 20 (1952) 680-684] characterizes majority voting on two alternatives as the unique preferential voting method satisfying several simple axioms. Here we show that by adding some desirable axioms to May's axioms, we can uniquely determine how to vote on three alternatives (setting aside tiebreaking). In particular, we add two axioms stating that the voting method should mitigate spoiler effects and avoid the so-called strong no show paradox. We prove a theorem stating that any preferential voting method satisfying our enlarged set of axioms, which includes some weak homogeneity and preservation axioms, must choose from among the Minimax winners in all three-alternative elections. When applied to more than three alternatives, our axioms also distinguish Minimax from other known voting methods that coincide with or refine Minimax for three alternatives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.14256v3</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wesley H. Holliday, Eric Pacuit</dc:creator>
    </item>
    <item>
      <title>On Connected Strongly-Proportional Cake-Cutting</title>
      <link>https://arxiv.org/abs/2312.15326</link>
      <description>arXiv:2312.15326v3 Announce Type: replace-cross 
Abstract: We investigate the problem of fairly dividing a divisible heterogeneous resource, also known as a cake, among a set of agents who may have different entitlements. We characterize the existence of a connected strongly-proportional allocation -- one in which every agent receives a contiguous piece worth strictly more than their proportional share. The characterization is supplemented with an algorithm that determines its existence using O(n * 2^n) queries. We devise a simpler characterization for agents with strictly positive valuations and with equal entitlements, and present an algorithm to determine the existence of such an allocation using O(n^2) queries. We provide matching lower bounds in the number of queries for both algorithms. When a connected strongly-proportional allocation exists, we show that it can also be computed using a similar number of queries. We also consider the problem of deciding the existence of a connected allocation of a cake in which each agent receives a piece worth a small fixed value more than their proportional share, and the problem of deciding the existence of a connected strongly-proportional allocation of a pie.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.15326v3</guid>
      <category>math.CO</category>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zsuzsanna Jank\'o, Attila Jo\'o, Erel Segal-Halevi, Sheung Man Yuen</dc:creator>
    </item>
    <item>
      <title>Bandit Profit-maximization for Targeted Marketing</title>
      <link>https://arxiv.org/abs/2403.01361</link>
      <description>arXiv:2403.01361v2 Announce Type: replace-cross 
Abstract: We study a sequential profit-maximization problem, optimizing for both price and ancillary variables like marketing expenditures. Specifically, we aim to maximize profit over an arbitrary sequence of multiple demand curves, each dependent on a distinct ancillary variable, but sharing the same price. A prototypical example is targeted marketing, where a firm (seller) wishes to sell a product over multiple markets. The firm may invest different marketing expenditures for different markets to optimize customer acquisition, but must maintain the same price across all markets. Moreover, markets may have heterogeneous demand curves, each responding to prices and marketing expenditures differently. The firm's objective is to maximize its gross profit, the total revenue minus marketing costs.
  Our results are near-optimal algorithms for this class of problems in an adversarial bandit setting, where demand curves are arbitrary non-adaptive sequences, and the firm observes only noisy evaluations of chosen points on the demand curves. For $n$ demand curves (markets), we prove a regret upper bound of $\tilde{O}(nT^{3/4})$ and a lower bound of $\Omega((nT)^{3/4})$ for monotonic demand curves, and a regret bound of $\tilde{\Theta}(nT^{2/3})$ for demands curves that are monotonic in price and concave in the ancillary variables.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.01361v2</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <category>q-fin.GN</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joon Suk Huh, Ellen Vitercik, Kirthevasan Kandasamy</dc:creator>
    </item>
    <item>
      <title>Iterative Nash Policy Optimization: Aligning LLMs with General Preferences via No-Regret Learning</title>
      <link>https://arxiv.org/abs/2407.00617</link>
      <description>arXiv:2407.00617v2 Announce Type: replace-cross 
Abstract: Reinforcement Learning with Human Feedback (RLHF) has achieved great success in aligning large language models (LLMs) with human preferences. Prevalent RLHF approaches are reward-based, following the Bradley-Terry (BT) model assumption, which may not fully capture the complexity of human preferences. In this paper, we explore RLHF under a general preference framework and approach it from a game-theoretic perspective. Specifically, we formulate the problem as a two-player game and propose a novel algorithm, iterative Nash policy optimization (INPO). The key idea is to let the policy play against itself via no-regret learning, thereby approximating the Nash policy. Unlike previous methods, INPO bypasses the need for estimating the expected win rate for individual responses, which typically incurs high computational or annotation costs. Instead, we introduce a new loss objective that is directly minimized over a preference dataset. We provide theoretical analysis for our approach and demonstrate its effectiveness through experiments on various representative benchmarks. With an LLaMA-3-8B-based SFT model, INPO achieves a 41.5% length-controlled win rate on AlpacaEval 2.0 and a 38.3% win rate on Arena-Hard, showing substantial improvement over the state-of-the-art iterative algorithm [Dong et al., 2024] under the BT model assumption. Additionally, our ablation study highlights the benefits of incorporating KL regularization for response length control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00617v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.GT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuheng Zhang, Dian Yu, Baolin Peng, Linfeng Song, Ye Tian, Mingyue Huo, Nan Jiang, Haitao Mi, Dong Yu</dc:creator>
    </item>
    <item>
      <title>Enhancing Class Fairness in Classification with A Two-Player Game Approach</title>
      <link>https://arxiv.org/abs/2407.03146</link>
      <description>arXiv:2407.03146v2 Announce Type: replace-cross 
Abstract: Data augmentation is widely applied and has shown its benefits in different machine learning tasks. However, as recently observed in some downstream tasks, data augmentation may introduce an unfair impact on classifications. While it can improve the performance of some classes, it can actually be detrimental for other classes, which can be problematic in some application domains. In this paper, to counteract this phenomenon, we propose a FAir Classification approach with a Two-player game (FACT). We first formulate the training of a classifier with data augmentation as a fair optimization problem, which can be further written as an adversarial two-player game. Following this formulation, we propose a novel multiplicative weight optimization algorithm, for which we theoretically prove that it can converge to a solution that is fair over classes. Interestingly, our formulation also reveals that this fairness issue over classes is not due to data augmentation only, but is in fact a general phenomenon. Our empirical experiments demonstrate that the performance of our learned classifiers is indeed more fairly distributed over classes in five datasets, with only limited impact on the average accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03146v2</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yunpeng Jiang, Paul Weng, Yutong Ban</dc:creator>
    </item>
  </channel>
</rss>
