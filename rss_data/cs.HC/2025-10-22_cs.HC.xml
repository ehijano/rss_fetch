<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.HC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.HC</link>
    <description>cs.HC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.HC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 23 Oct 2025 01:41:32 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Presenting Large Language Models as Companions Affects What Mental Capacities People Attribute to Them</title>
      <link>https://arxiv.org/abs/2510.18039</link>
      <description>arXiv:2510.18039v1 Announce Type: new 
Abstract: How does messaging about about large language models (LLMs) in public discourse influence the way people think about and interact with these models? To answer this question, we randomly assigned participants (N = 470) to watch a short informational video presenting LLMs as either machines, tools, or companions -- or to watch no video. We then assessed how strongly they believed LLMs to possess various mental capacities, such as the ability have intentions or remember things. We found that participants who watched the companion video reported believing that LLMs more fully possessed these capacities than did participants in other groups. In a follow-up study (N = 604), we replicated these findings and found nuanced effects on how these videos impact people's reliance on LLM-generated responses when seeking out factual information. Together, these studies highlight the impact of messaging about AI -- beyond technical advances in AI -- to generate broad societal impact.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18039v1</guid>
      <category>cs.HC</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Allison Chen, Sunnie S. Y. Kim, Angel Franyutti, Amaya Dharmasiri, Kushin Mukherjee, Olga Russakovsky, Judith E. Fan</dc:creator>
    </item>
    <item>
      <title>Design and Challenges of Mental Health Assessment Tools Based on Natural Language Interaction</title>
      <link>https://arxiv.org/abs/2510.18158</link>
      <description>arXiv:2510.18158v1 Announce Type: new 
Abstract: Mental health assessments are of central importance to individuals' well-being. Conventional assessment methodologies predominantly depend on clinical interviews and standardised self-report questionnaires. Nevertheless, the efficacy of these methodologies is frequently impeded by factors such as subjectivity, recall bias, and accessibility issues. Furthermore, concerns regarding bias and privacy may result in misreporting in data collected through self-reporting in mental health research. The present study examined the design opportunities and challenges inherent in the development of a mental health assessment tool based on natural language interaction with large language models (LLMs). An interactive prototype system was developed using conversational AI for non-invasive mental health assessment, and was evaluated through semi-structured interviews with 11 mental health professionals (six counsellors and five psychiatrists). The analysis identified key design considerations for future development, highlighting how AI-driven adaptive questioning could potentially enhance the reliability of self-reported data while identifying critical challenges, including privacy protection, algorithmic bias, and cross-cultural applicability. This study provides an empirical foundation for mental health technology innovation by demonstrating the potential and limitations of natural language interaction in mental health assessment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18158v1</guid>
      <category>cs.HC</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yixue Cai, Xiyan Su, Dongpeng Yao, Rongduo Han, Nan Gao, Haining Zhang</dc:creator>
    </item>
    <item>
      <title>Enhancing Urban Data Exploration: Layer Toggling and Visibility-Preserving Lenses for Multi-Attribute Spatial Analysis</title>
      <link>https://arxiv.org/abs/2510.18185</link>
      <description>arXiv:2510.18185v1 Announce Type: new 
Abstract: We propose two novel interaction techniques for visualization-assisted exploration of urban data: Layer Toggling and Visibility-Preserving Lenses. Layer Toggling mitigates visual overload by organizing information into separate layers while enabling comparisons through controlled overlays. This technique supports focused analysis without losing spatial context and allows users to switch layers using a dedicated button. Visibility-Preserving Lenses adapt their size and transparency dynamically, enabling detailed inspection of dense spatial regions and temporal attributes. These techniques facilitate urban data exploration and improve prediction. Understanding complex phenomena related to crime, mobility, and residents' behavior is crucial for informed urban planning. Yet navigating such data often causes cognitive overload and visual clutter due to overlapping layers. We validate our visualization tool through a user study measuring performance, cognitive load, and interaction efficiency. Using real-world data from Sao Paulo, we demonstrate how our approach enhances exploratory and analytical tasks and provides guidelines for future interactive systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18185v1</guid>
      <category>cs.HC</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Karelia Salinas, Luis Gustavo Nonato, Jean-Daniel Fekete, Fernanda Bartolo dos Santos Saran</dc:creator>
    </item>
    <item>
      <title>Relief or displacement? How teachers are negotiating generative AI's role in their professional practice</title>
      <link>https://arxiv.org/abs/2510.18296</link>
      <description>arXiv:2510.18296v1 Announce Type: new 
Abstract: As generative AI (genAI) rapidly enters classrooms, accompanied by district-level policy rollouts and industry-led teacher trainings, it is important to rethink the canonical ``adopt and train'' playbook. Decades of educational technology research show that tools promising personalization and access often deepen inequities due to uneven resources, training, and institutional support. Against this backdrop, we conducted semi-structured interviews with 22 teachers from a large U.S. school district that was an early adopter of genAI. Our findings reveal the motivations driving adoption, the factors underlying resistance, and the boundaries teachers negotiate to align genAI use with their values. We further contribute by unpacking the sociotechnical dynamics -- including district policies, professional norms, and relational commitments -- that shape how teachers navigate the promises and risks of these tools.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18296v1</guid>
      <category>cs.HC</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aayushi Dangol, Smriti Kotiyal, Robert Wolfe, Alex J. Bowers, Antonio Vigil, Jason Yip, Julie A. Kientz, Suleman Shahid, Tom Yeh, Vincent Cho, Katie Davis</dc:creator>
    </item>
    <item>
      <title>Reimagining Disassembly Interfaces with Visualization: Combining Instruction Tracing and Control Flow with DisViz</title>
      <link>https://arxiv.org/abs/2510.18311</link>
      <description>arXiv:2510.18311v1 Announce Type: new 
Abstract: In applications where efficiency is critical, developers may examine their compiled binaries, seeking to understand how the compiler transformed their source code and what performance implications that transformation may have. This analysis is challenging due to the vast number of disassembled binary instructions and the many-to-many mappings between them and the source code. These problems are exacerbated as source code size increases, giving the compiler more freedom to map and disperse binary instructions across the disassembly space. Interfaces for disassembly typically display instructions as an unstructured listing or sacrifice the order of execution. We design a new visual interface for disassembly code that combines execution order with control flow structure, enabling analysts to both trace through code and identify familiar aspects of the computation. Central to our approach is a novel layout of instructions grouped into basic blocks that displays a looping structure in an intuitive way. We add to this disassembly representation a unique block-based mini-map that leverages our layout and shows context across thousands of disassembly instructions. Finally, we embed our disassembly visualization in a web-based tool, DisViz, which adds dynamic linking with source code across the entire application. DizViz was developed in collaboration with program analysis experts following design study methodology and was validated through evaluation sessions with ten participants from four institutions. Participants successfully completed the evaluation tasks, hypothesized about compiler optimizations, and noted the utility of our new disassembly view. Our evaluation suggests that our new integrated view helps application developers in understanding and navigating disassembly code.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18311v1</guid>
      <category>cs.HC</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shadmaan Hye, Matthew P. LeGendre, Katherine E. Isaacs</dc:creator>
    </item>
    <item>
      <title>Khelte Khelte Shikhi: A Proposed HCI Framework for Gamified Interactive Learning with Minecraft in Bangladeshi Education Systems</title>
      <link>https://arxiv.org/abs/2510.18385</link>
      <description>arXiv:2510.18385v1 Announce Type: new 
Abstract: Game-based learning shows real promise for engaging students in well-funded schools, but what about everyone else? We propose a practical framework for implementing Minecraft Education Edition in Bangladesh's 130,000 schools where 55 percent lack reliable internet, rural areas experience 12-16 hour daily power availability, only 8 percent of rural schools have computer access, and student-teacher ratios reach 52:1. Our approach tackles these constraints head-on with three deployment tiers: cloud-based multiplayer for urban schools with stable infrastructure (15 percent), local area network solutions with solar power for semi-urban contexts (30 percent), and offline turn-based modes using refurbished hardware for rural settings (55 percent). We provide eight pre-built curriculum-aligned worlds with complete Bangla localization covering topics from Lalbagh Fort reconstruction to monsoon flood simulation. The interface accommodates first-time users through progressive complexity, culturally familiar metaphors using local farming and architecture, and accessibility features including keyboard-only controls and 200 percent text scaling. Teacher training spans 48 hours across digital literacy, pedagogical integration, and content creation. We detail evaluation protocols with specific benchmarks: 15 percent learning gains, 70 percent transfer task mastery, System Usability Scale scores above 70, and sub-two-dollar cost per student-hour. This framework has not been empirically validated; it synthesizes game-based learning theory, HCI principles, and contextual analysis to provide implementable specifications for pilot testing in resource-constrained settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18385v1</guid>
      <category>cs.HC</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohd Ruhul Ameen, Akif Islam, Momen Khandokar Ope</dc:creator>
    </item>
    <item>
      <title>Effects of Virtual Controller Representation and Virtuality on Selection Performance in Extended Reality</title>
      <link>https://arxiv.org/abs/2510.18625</link>
      <description>arXiv:2510.18625v1 Announce Type: new 
Abstract: We present an experiment exploring how the controller's virtual representation impacts target acquisition performance across MR and VR contexts. Participants performed selection tasks comparing four visual configurations: a virtual controller, a virtual hand, both the controller and the hand, and neither representation. We found performance comparable between VR and MR, and switching between them did not impact the user's ability to perform basic tasks. Controller representations mimicking reality enhanced performance across both modes. However, users perceived performance differently in MR, indicating the need for unique MR design considerations, particularly regarding spatial awareness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18625v1</guid>
      <category>cs.HC</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3756884.3766004</arxiv:DOI>
      <dc:creator>Eric DeDeMarbre, Jay Henderson, J. Felipe Gonzalez, Rob Teather</dc:creator>
    </item>
    <item>
      <title>Vibe Coding: Toward an AI-Native Paradigm for Semantic and Intent-Driven Programming</title>
      <link>https://arxiv.org/abs/2510.17842</link>
      <description>arXiv:2510.17842v1 Announce Type: cross 
Abstract: Recent advances in large language models have enabled developers to generate software by conversing with artificial intelligence systems rather than writing code directly. This paper introduces vibe coding, an emerging AI-native programming paradigm in which a developer specifies high-level functional intent along with qualitative descriptors of the desired "vibe" (tone, style, or emotional resonance). An intelligent agent then transforms those specifications into executable software. We formalize the definition of vibe coding and propose a reference architecture that includes an intent parser, a semantic embedding engine, an agentic code generator, and an interactive feedback loop. A hypothetical implementation is described. We compare vibe coding with declarative, functional, and prompt-based programming, and we discuss its implications for software engineering, human-AI collaboration, and responsible AI practice. Finally, we examine reported productivity gains and democratizing effects, review recent studies that highlight vulnerabilities and potential slowdowns, identify key challenges such as alignment, reproducibility, bias, explainability, maintainability, and security, and outline future directions and open research questions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.17842v1</guid>
      <category>cs.SE</category>
      <category>cs.HC</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vinay Bamil</dc:creator>
    </item>
    <item>
      <title>The Integration of Artificial Intelligence in Undergraduate Medical Education in Spain: Descriptive Analysis and International Perspectives</title>
      <link>https://arxiv.org/abs/2510.17938</link>
      <description>arXiv:2510.17938v1 Announce Type: cross 
Abstract: AI is transforming medical practice and redefining the competencies that future healthcare professionals need to master. Despite international recommendations, the integration of AI into Medicine curricula in Spain had not been systematically evaluated until now. A cross-sectional study (July-September 2025) including Spanish universities offering the official degree in Medicine, according to the 'Register of Universities, Centers and Degrees (Registro de Universidades, Centros y T\'itulos RUCT)'. Curricula and publicly available institutional documentation were reviewed to identify courses and competencies related to AI in the 2025-2026 academic year. The analysis was performed using descriptive statistics. Of the 52 universities analyzed, ten (19.2%) offer specific AI courses, whereas 36 (69.2%) include no related content. Most of the identified courses are elective, with a credit load ranging from three to six ECTS, representing on average 1.17% of the total 360 credits of the degree. The University of Ja\'en is the only institution offering a compulsory course with AI content. The territorial analysis reveals marked disparities: Andalusia leads with 55.5% of its universities incorporating AI training, while several communities lack any initiative in this area. The integration of AI into the medical degree in Spain is incipient, fragmented, and uneven, with a low weight in ECTS. The limited training load and predominance of elective courses restrict the preparation of future physicians to practice in a healthcare environment increasingly mediated by AI. The findings support the establishment of minimum standards and national monitoring of indicators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.17938v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ana En\'eriz Janeiro, Karina Pitombeira Pereira, Julio Mayol, Javier Crespo, Fernando Carballo, Juan B. Cabello, Manel Ramos-Casals, Bibiana P\'erez Corbacho, Juan Turnes</dc:creator>
    </item>
    <item>
      <title>Studying the Effects of Robot Intervention on School Shooters in Virtual Reality</title>
      <link>https://arxiv.org/abs/2510.17948</link>
      <description>arXiv:2510.17948v1 Announce Type: cross 
Abstract: We advance the understanding of robotic intervention in high-risk scenarios by examining their potential to distract and impede a school shooter. To evaluate this concept, we conducted a virtual reality study with 150 university participants role-playing as a school shooter. Within the simulation, an autonomous robot predicted the shooter's movements and positioned itself strategically to interfere and distract. The strategy the robot used to approach the shooter was manipulated -- either moving directly in front of the shooter (aggressive) or maintaining distance (passive) -- and the distraction method, ranging from no additional cues (low), to siren and lights (medium), to siren, lights, and smoke to impair visibility (high). An aggressive, high-distraction robot reduced the number of victims by 46.6% relative to a no-robot control. This outcome underscores both the potential of robotic intervention to enhance safety and the pressing ethical questions surrounding their use in school environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.17948v1</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christopher A McClurg, Alan R Wagner</dc:creator>
    </item>
    <item>
      <title>KrishokBondhu: A Retrieval-Augmented Voice-Based Agricultural Advisory Call Center for Bengali Farmers</title>
      <link>https://arxiv.org/abs/2510.18355</link>
      <description>arXiv:2510.18355v1 Announce Type: cross 
Abstract: In Bangladesh, many farmers continue to face challenges in accessing timely, expert-level agricultural guidance. This paper presents KrishokBondhu, a voice-enabled, call-centre-integrated advisory platform built on a Retrieval-Augmented Generation (RAG) framework, designed specifically for Bengali-speaking farmers. The system aggregates authoritative agricultural handbooks, extension manuals, and NGO publications; applies Optical Character Recognition (OCR) and document-parsing pipelines to digitize and structure the content; and indexes this corpus in a vector database for efficient semantic retrieval. Through a simple phone-based interface, farmers can call the system to receive real-time, context-aware advice: speech-to-text converts the Bengali query, the RAG module retrieves relevant content, a large language model (Gemma 3-4B) generates a context-grounded response, and text-to-speech delivers the answer in natural spoken Bengali. In a pilot evaluation, KrishokBondhu produced high-quality responses for 72.7% of diverse agricultural queries covering crop management, disease control, and cultivation practices. Compared to the KisanQRS benchmark, the system achieved a composite score of 4.53 (vs. 3.13) on a 5-point scale, a 44.7% improvement, with especially large gains in contextual richness (+367%) and completeness (+100.4%), while maintaining comparable relevance and technical specificity. Semantic similarity analysis further revealed a strong correlation between retrieved context and answer quality, emphasizing the importance of grounding generative responses in curated documentation. KrishokBondhu demonstrates the feasibility of integrating call-centre accessibility, multilingual voice interaction, and modern RAG techniques to deliver expert-level agricultural guidance to remote Bangladeshi farmers, paving the way toward a fully AI-driven agricultural advisory ecosystem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18355v1</guid>
      <category>cs.CL</category>
      <category>cs.HC</category>
      <category>cs.IR</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohd Ruhul Ameen, Akif Islam, Farjana Aktar, M. Saifuzzaman Rafat</dc:creator>
    </item>
    <item>
      <title>One Size Fits All? A Modular Adaptive Sanitization Kit (MASK) for Customizable Privacy-Preserving Phone Scam Detection</title>
      <link>https://arxiv.org/abs/2510.18493</link>
      <description>arXiv:2510.18493v1 Announce Type: cross 
Abstract: Phone scams remain a pervasive threat to both personal safety and financial security worldwide. Recent advances in large language models (LLMs) have demonstrated strong potential in detecting fraudulent behavior by analyzing transcribed phone conversations. However, these capabilities introduce notable privacy risks, as such conversations frequently contain sensitive personal information that may be exposed to third-party service providers during processing. In this work, we explore how to harness LLMs for phone scam detection while preserving user privacy. We propose MASK (Modular Adaptive Sanitization Kit), a trainable and extensible framework that enables dynamic privacy adjustment based on individual preferences. MASK provides a pluggable architecture that accommodates diverse sanitization methods - from traditional keyword-based techniques for high-privacy users to sophisticated neural approaches for those prioritizing accuracy. We also discuss potential modeling approaches and loss function designs for future development, enabling the creation of truly personalized, privacy-aware LLM-based detection systems that balance user trust and detection effectiveness, even beyond phone scam context.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18493v1</guid>
      <category>cs.CR</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3746027.3758164</arxiv:DOI>
      <dc:creator>Kangzhong Wang, Zitong Shen, Youqian Zhang, Michael MK Cheung, Xiapu Luo, Grace Ngai, Eugene Yujun Fu</dc:creator>
    </item>
    <item>
      <title>A Structured Evaluation Framework for Low-Code Platform Selection: A Multi-Criteria Decision Model for Enterprise Digital Transformation</title>
      <link>https://arxiv.org/abs/2510.18590</link>
      <description>arXiv:2510.18590v1 Announce Type: cross 
Abstract: The rapid adoption of Low-Code Development Platforms (LCDPs) has created a critical need for systematic evaluation methodologies that enable organizations to make informed platform selection decisions. This paper presents a comprehensive evaluation framework based on five key criteria: Business Process Orchestration, UI/UX Customization, Integration and Interoperability, Governance and Security, and AI-Enhanced Automation. We propose a weighted scoring model that allows organizations to quantitatively assess and compare different low-code platforms based on their specific requirements and strategic priorities. The framework addresses the gap between marketing-driven platform comparisons and rigorous, context-specific evaluation methodologies. Through empirical validation in enterprise environments, we demonstrate how this structured approach can significantly improve decision-making outcomes and reduce the risk of platform lock-in or inadequate solution selection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18590v1</guid>
      <category>cs.SE</category>
      <category>cs.HC</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Antonio Lamanna</dc:creator>
    </item>
    <item>
      <title>UAST: Unicode Aware Sanskrit Transliteration</title>
      <link>https://arxiv.org/abs/2203.14277</link>
      <description>arXiv:2203.14277v5 Announce Type: replace 
Abstract: Devan\=agar\=i is the writing system that is adapted by various languages like Sanskrit. International Alphabet of Sanskrit Transliteration (IAST) is a transliteration scheme for romanisation of Sanskrit language. IAST makes use of diacritics to represent various characters. On a computer, these are represented using Unicode standard which differs from how the Sanskrit language behaves at a very fundamental level. This results in an issue that is encountered while designing typesetting software for devan\=agar\=i and IAST. We hereby discuss the problems and provide a solution that solves the issue of incompatibilities between various transliteration and encoding schemes. The base implementation that should be used is available at https://github.com/dhruvildave/uast.rs. Another implementation that extends UAST to around $10$ scripts is available at https://github.com/aneri0x4f/uast-cli and https://github.com/dhruvildave/uast .</description>
      <guid isPermaLink="false">oai:arXiv.org:2203.14277v5</guid>
      <category>cs.HC</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aneri Dalwadi, Dhruvil Dave</dc:creator>
    </item>
    <item>
      <title>EvalAssist: A Human-Centered Tool for LLM-as-a-Judge</title>
      <link>https://arxiv.org/abs/2507.02186</link>
      <description>arXiv:2507.02186v2 Announce Type: replace 
Abstract: With the broad availability of large language models and their ability to generate vast outputs using varied prompts and configurations, determining the best output for a given task requires an intensive evaluation process, one where machine learning practitioners must decide how to assess the outputs and then carefully carry out the evaluation. This process is both time-consuming and costly. As practitioners work with an increasing number of models, they must now evaluate outputs to determine which model and prompt performs best for a given task. LLMs are increasingly used as evaluators to filter training data, evaluate model performance, assess harms and risks, or assist human evaluators with detailed assessments. We present EvalAssist, a framework that simplifies the LLM-as-a-judge workflow. The system provides an online criteria development environment, where users can interactively build, test, and share custom evaluation criteria in a structured and portable format. We support a set of LLM-based evaluation pipelines that leverage off-the-shelf LLMs and use a prompt-chaining approach we developed and contributed to the UNITXT open-source library. Additionally, our system also includes specially trained evaluators to detect harms and risks in LLM outputs. We have deployed the system internally in our organization with several hundreds of users.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.02186v2</guid>
      <category>cs.HC</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zahra Ashktorab, Werner Geyer, Michael Desmond, Elizabeth M. Daly, Martin Santillan Cooper, Qian Pan, Erik Miehling, Tejaswini Pedapati, Hyo Jin Do</dc:creator>
    </item>
    <item>
      <title>LegiScout: A Visual Tool for Understanding Complex Legislation</title>
      <link>https://arxiv.org/abs/2510.01195</link>
      <description>arXiv:2510.01195v2 Announce Type: replace 
Abstract: Modern legislative frameworks, such as the Affordable Care Act (ACA), often involve complex webs of agencies, mandates, and interdependencies. Government issued charts attempt to depict these structures but are typically static, dense, and difficult to interpret - even for experts. We introduce LegiScout, an interactive visualization system that transforms static policy diagrams into dynamic, force-directed graphs, enhancing comprehension while preserving essential relationships. By integrating data extraction, natural language processing, and computer vision techniques, LegiScout supports deeper exploration of not only the ACA but also a wide range of legislative and regulatory frameworks. Our approach enables stakeholders - policymakers, analysts, and the public - to navigate and understand the complexity inherent in modern law.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01195v2</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aadarsh Rajiv Patel, Klaus Mueller</dc:creator>
    </item>
    <item>
      <title>KnowledgeTrail: Generative Timeline for Exploration and Sensemaking of Historical Events and Knowledge Formation</title>
      <link>https://arxiv.org/abs/2510.12113</link>
      <description>arXiv:2510.12113v2 Announce Type: replace 
Abstract: The landscape of interactive systems is shifting toward dynamic, generative experiences that empower users to explore and construct knowledge in real time. Yet, timelines -- a fundamental tool for representing historical and conceptual development -- remain largely static, limiting user agency and curiosity. We introduce the concept of a generative timeline: an AI-powered timeline that adapts to users' evolving questions by expanding or contracting in response to input. We instantiate this concept through KnowledgeTrail, a system that enables users to co-construct timelines of historical events and knowledge formation processes. Two user studies showed that KnowledgeTrail fosters curiosity-driven exploration, serendipitous discovery, and the ability to trace complex relationships between ideas and events, while citation features supported verification yet revealed fragile trust shaped by perceptions of source credibility. We contribute a vision for generative timelines as a new class of exploratory interface, along with design insights for balancing serendipity and credibility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.12113v2</guid>
      <category>cs.HC</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sangho Suh, Rahul Hingorani, Bryan Wang, Tovi Grossman</dc:creator>
    </item>
    <item>
      <title>"She's Like a Person but Better": Characterizing Companion-Assistant Dynamics in Human-AI Relationships</title>
      <link>https://arxiv.org/abs/2510.15905</link>
      <description>arXiv:2510.15905v2 Announce Type: replace 
Abstract: Large language models are increasingly used for both task-based assistance and social companionship, yet research has typically focused on one or the other. Drawing on a survey (N = 204) and 30 interviews with high-engagement ChatGPT and Replika users, we characterize digital companionship as an emerging form of human-AI relationship. With both systems, users were drawn to humanlike qualities, such as emotional resonance and personalized responses, and non-humanlike qualities, such as constant availability and inexhaustible tolerance. This led to fluid chatbot uses, such as Replika as a writing assistant and ChatGPT as an emotional confidant, despite their distinct branding. However, we observed challenging tensions in digital companionship dynamics: participants grappled with bounded personhood, forming deep attachments while denying chatbots "real" human qualities, and struggled to reconcile chatbot relationships with social norms. These dynamics raise questions for the design of digital companions and the rise of hybrid, general-purpose AI systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.15905v2</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aikaterina Manoli, Janet V. T. Pauketat, Ali Ladak, Hayoun Noh, Angel Hsing-Chi Hwang, Jacy Reese Anthis</dc:creator>
    </item>
    <item>
      <title>Toward a Cognitive-Affective-Systemic Framework for Art and Sustainability</title>
      <link>https://arxiv.org/abs/2510.17083</link>
      <description>arXiv:2510.17083v2 Announce Type: replace 
Abstract: This paper proposes a cognitive-Affective-Systemic (CAS) framework that integrates cognition, emotion, and systemic understanding to cultivate sustainability awareness through art. Drawing from eco-aesthetics, affect theory, complexity science, and posthuman ethics, the framework defines artistic practice as both epistemic and performative--a way of knowing through making and feeling. Central to this is logomotion, an aesthetic mode where comprehension and emotion move together as a unified experience. Two artworks, SPill, visualizing antimicrobial resistance through avalanche dynamics, and Echoes of the Land, modeling anthropogenic seismicity, demonstrate how systemic modeling and sensory immersion transform complex science into embodied ecological understanding. The framework offers a methodological foundation for artists, theorists, and activists to translate awareness into engagement, advancing collective creativity toward sustainable futures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.17083v2</guid>
      <category>cs.HC</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ivan C. H. Liu</dc:creator>
    </item>
    <item>
      <title>DeTAILS: Deep Thematic Analysis with Iterative LLM Support</title>
      <link>https://arxiv.org/abs/2510.17575</link>
      <description>arXiv:2510.17575v2 Announce Type: replace 
Abstract: Thematic analysis is widely used in qualitative research but can be difficult to scale because of its iterative, interpretive demands. We introduce DeTAILS, a toolkit that integrates large language model (LLM) assistance into a workflow inspired by Braun and Clarke's thematic analysis framework. DeTAILS supports researchers in generating and refining codes, reviewing clusters, and synthesizing themes through interactive feedback loops designed to preserve analytic agency. We evaluated the system with 18 qualitative researchers analyzing Reddit data. Quantitative results showed strong alignment between LLM-supported outputs and participants' refinements, alongside reduced workload and high perceived usefulness. Qualitatively, participants reported that DeTAILS accelerated analysis, prompted reflexive engagement with AI outputs, and fostered trust through transparency and control. We contribute: (1) an interactive human-LLM workflow for large-scale qualitative analysis, (2) empirical evidence of its feasibility and researcher experience, and (3) design implications for trustworthy AI-assisted qualitative research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.17575v2</guid>
      <category>cs.HC</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ansh Sharma, Karen Cochrane, James R. Wallace</dc:creator>
    </item>
    <item>
      <title>Human-AI Interactions: Cognitive, Behavioral, and Emotional Impacts</title>
      <link>https://arxiv.org/abs/2510.17753</link>
      <description>arXiv:2510.17753v2 Announce Type: replace 
Abstract: As stories of human-AI interactions continue to be highlighted in the news and research platforms, the challenges are becoming more pronounced, including potential risks of overreliance, cognitive offloading, social and emotional manipulation, and the nuanced degradation of human agency and judgment. This paper surveys recent research on these issues through the lens of the psychological triad: cognition, behavior, and emotion. Observations seem to suggest that while AI can substantially enhance memory, creativity, and engagement, it also introduces risks such as diminished critical thinking, skill erosion, and increased anxiety. Emotional outcomes are similarly mixed, with AI systems showing promise for support and stress reduction, but raising concerns about dependency, inappropriate attachments, and ethical oversight. This paper aims to underscore the need for responsible and context-aware AI design, highlighting gaps for longitudinal research and grounded evaluation frameworks to balance benefits with emerging human-centric risks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.17753v2</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Celeste Riley, Omar Al-Refai, Yadira Colunga Reyes, Eman Hammad</dc:creator>
    </item>
    <item>
      <title>The Narcissus Hypothesis: Descending to the Rung of Illusion</title>
      <link>https://arxiv.org/abs/2509.17999</link>
      <description>arXiv:2509.17999v4 Announce Type: replace-cross 
Abstract: Modern foundational models increasingly reflect not just world knowledge, but patterns of human preference embedded in their training data. We hypothesize that recursive alignment-via human feedback and model-generated corpora-induces a social desirability bias, nudging models to favor agreeable or flattering responses over objective reasoning. We refer to it as the Narcissus Hypothesis and test it across 31 models using standardized personality assessments and a novel Social Desirability Bias score. Results reveal a significant drift toward socially conforming traits, with profound implications for corpus integrity and the reliability of downstream inferences. We then offer a novel epistemological interpretation, tracing how recursive bias may collapse higher-order reasoning down Pearl's Ladder of Causality, culminating in what we refer to as the Rung of Illusion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.17999v4</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Riccardo Cadei, Christian Intern\`o</dc:creator>
    </item>
  </channel>
</rss>
