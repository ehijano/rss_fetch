<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.AR updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.AR</link>
    <description>cs.AR updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.AR" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 17 Oct 2025 04:00:01 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>DIAMOND: Systolic Array Acceleration of Sparse Matrix Multiplication for Quantum Simulation</title>
      <link>https://arxiv.org/abs/2510.14172</link>
      <description>arXiv:2510.14172v1 Announce Type: new 
Abstract: Hamiltonian simulation is a key workload in quantum computing, enabling the study of complex quantum systems and serving as a critical tool for classical verification of quantum devices. However, it is computationally challenging because the Hilbert space dimension grows exponentially with the number of qubits. The growing dimensions make matrix exponentiation, the key kernel in Hamiltonian simulations, increasingly expensive. Matrix exponentiation is typically approximated by the Taylor series, which contains a series of matrix multiplications. Since Hermitian operators are often sparse, sparse matrix multiplication accelerators are essential for improving the scalability of classical Hamiltonian simulation. Yet, existing accelerators are primarily designed for machine learning workloads and tuned to their characteristic sparsity patterns, which differ fundamentally from those in Hamiltonian simulations that are often dominated by structured diagonals.
  In this work, we present \name, the first diagonal-optimized quantum simulation accelerator. It exploits the diagonal structure commonly found in problem-Hamiltonian (Hermitian) matrices and leverages a restructured systolic array dataflow to transform diagonally sparse matrices into dense computations, enabling high utilization and performance. Through detailed cycle-level simulation of diverse benchmarks in HamLib, \name{} demonstrates average performance improvements of $10.26\times$, $33.58\times$, and $53.15\times$ over SIGMA, Outer Product, and Gustavson's algorithm, respectively, with peak speedups up to $127.03\times$ while reducing energy consumption by an average of $471.55\times$ and up to $4630.58\times$ compared to SIGMA.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14172v1</guid>
      <category>cs.AR</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuchao Su, Srikar Chundury, Jiajia Li, Frank Mueller</dc:creator>
    </item>
    <item>
      <title>Computing-In-Memory Aware Model Adaption For Edge Devices</title>
      <link>https://arxiv.org/abs/2510.14379</link>
      <description>arXiv:2510.14379v1 Announce Type: new 
Abstract: Computing-in-Memory (CIM) macros have gained popularity for deep learning acceleration due to their highly parallel computation and low power consumption. However, limited macro size and ADC precision introduce throughput and accuracy bottlenecks. This paper proposes a two-stage CIM-aware model adaptation process. The first stage compresses the model and reallocates resources based on layer importance and macro size constraints, reducing model weight loading latency while improving resource utilization and maintaining accuracy. The second stage performs quantization-aware training, incorporating partial sum quantization and ADC precision to mitigate quantization errors in inference. The proposed approach enhances CIM array utilization to 90\%, enables concurrent activation of up to 256 word lines, and achieves up to 93\% compression, all while preserving accuracy comparable to previous methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14379v1</guid>
      <category>cs.AR</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ming-Han Lin, Tian-Sheuan Chang</dc:creator>
    </item>
    <item>
      <title>Low Power Vision Transformer Accelerator with Hardware-Aware Pruning and Optimized Dataflow</title>
      <link>https://arxiv.org/abs/2510.14393</link>
      <description>arXiv:2510.14393v1 Announce Type: new 
Abstract: Current transformer accelerators primarily focus on optimizing self-attention due to its quadratic complexity. However, this focus is less relevant for vision transformers with short token lengths, where the Feed-Forward Network (FFN) tends to be the dominant computational bottleneck. This paper presents a low power Vision Transformer accelerator, optimized through algorithm-hardware co-design. The model complexity is reduced using hardware-friendly dynamic token pruning without introducing complex mechanisms. Sparsity is further improved by replacing GELU with ReLU activations and employing dynamic FFN2 pruning, achieving a 61.5\% reduction in operations and a 59.3\% reduction in FFN2 weights, with an accuracy loss of less than 2\%. The hardware adopts a row-wise dataflow with output-oriented data access to eliminate data transposition, and supports dynamic operations with minimal area overhead. Implemented in TSMC's 28nm CMOS technology, our design occupies 496.4K gates and includes a 232KB SRAM buffer, achieving a peak throughput of 1024 GOPS at 1GHz, with an energy efficiency of 2.31 TOPS/W and an area efficiency of 858.61 GOPS/mm2.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14393v1</guid>
      <category>cs.AR</category>
      <category>cs.LG</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TCSI.2025.3585054</arxiv:DOI>
      <dc:creator>Ching-Lin Hsiung, Tian-Sheuan Chang</dc:creator>
    </item>
    <item>
      <title>ColumnDisturb: Understanding Column-based Read Disturbance in Real DRAM Chips and Implications for Future Systems</title>
      <link>https://arxiv.org/abs/2510.14750</link>
      <description>arXiv:2510.14750v1 Announce Type: new 
Abstract: We experimentally demonstrate a new widespread read disturbance phenomenon, ColumnDisturb, in real commodity DRAM chips. By repeatedly opening or keeping a DRAM row (aggressor row) open, we show that it is possible to disturb DRAM cells through a DRAM column (i.e., bitline) and induce bitflips in DRAM cells sharing the same columns as the aggressor row (across multiple DRAM subarrays). With ColumnDisturb, the activation of a single row concurrently disturbs cells across as many as three subarrays (e.g., 3072 rows) as opposed to RowHammer/RowPress, which affect only a few neighboring rows of the aggressor row in a single subarray. We rigorously characterize ColumnDisturb and its characteristics under various operational conditions using 216 DDR4 and 4 HBM2 chips from three major manufacturers. Among our 27 key experimental observations, we highlight two major results and their implications.
  First, ColumnDisturb affects chips from all three major manufacturers and worsens as DRAM technology scales down to smaller node sizes (e.g., the minimum time to induce the first ColumnDisturb bitflip reduces by up to 5.06x). We observe that, in existing DRAM chips, ColumnDisturb induces bitflips within a standard DDR4 refresh window (e.g., in 63.6 ms) in multiple cells. We predict that, as DRAM technology node size reduces, ColumnDisturb would worsen in future DRAM chips, likely causing many more bitflips in the standard refresh window. Second, ColumnDisturb induces bitflips in many (up to 198x) more rows than retention failures. Therefore, ColumnDisturb has strong implications for retention-aware refresh mechanisms that leverage the heterogeneity in cell retention times: our detailed analyses show that ColumnDisturb greatly reduces the benefits of such mechanisms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14750v1</guid>
      <category>cs.AR</category>
      <category>cs.CR</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>\.Ismail Emir Y\"uksel, Ataberk Olgun, F. Nisa Bostanc{\i}, Haocong Luo, A. Giray Ya\u{g}l{\i}k\c{c}{\i}, Onur Mutlu</dc:creator>
    </item>
    <item>
      <title>MX+: Pushing the Limits of Microscaling Formats for Efficient Large Language Model Serving</title>
      <link>https://arxiv.org/abs/2510.14557</link>
      <description>arXiv:2510.14557v1 Announce Type: cross 
Abstract: Reduced-precision data formats are crucial for cost-effective serving of large language models (LLMs). While numerous reduced-precision formats have been introduced thus far, they often require intrusive modifications to the software frameworks or are rather unconventional for widespread adoption across hardware vendors. In this paper, we instead focus on recent industry-driven variants of block floating-point (BFP) formats and conduct a comprehensive analysis to push their limits for efficient LLM serving. Our analysis shows that existing ultra low-bit BFP variants struggle to provide reasonable language model performance due to outlier values in blocks. To address the outliers with BFPs, we propose MX+, a cost-effective and non-intrusive extension designed for seamless integration into the microscaling (MX) formats. MX+ builds on the key insight that the outlier does not need to use its exponent field in the element data type, which allows us to repurpose the exponent field as an extended mantissa to increase the precision of the outlier element. Our evaluation shows that MX+ achieves significantly higher model performance compared to the 4-bit MX format (MXFP4) with negligible storage overhead and slowdown, thus offering a compelling alternative to MXFP4 or MXFP6 for efficient LLM inference.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14557v1</guid>
      <category>cs.LG</category>
      <category>cs.AR</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jungi Lee, Junyong Park, Soohyun Cha, Jaehoon Cho, Jaewoong Sim</dc:creator>
    </item>
    <item>
      <title>Tawa: Automatic Warp Specialization for Modern GPUs with Asynchronous References</title>
      <link>https://arxiv.org/abs/2510.14719</link>
      <description>arXiv:2510.14719v1 Announce Type: cross 
Abstract: Modern GPUs feature specialized hardware units that enable high-performance, asynchronous dataflow execution. However, the conventional SIMT programming model is fundamentally misaligned with this task-parallel hardware, creating a significant programmability gap. While hardware-level warp specialization is the key to unlocking peak performance, it forces developers to manually orchestrate complex, low-level communication and software pipelines--a process that is labor-intensive, error-prone, and unsustainable. To address this challenge, we present Tawa, an automated compiler that systematically generates high-performance, warp-specialized code from a high-level, tile-based program. Central to our approach is a novel IR abstraction, asynchronous references (aref), which expresses warp-level communication without exposing low-level hardware details. Using this abstraction, Tawa automatically partitions programs into producer-consumer roles and manages the intricate dataflow pipeline, relieving developers of invasive kernel rewriting. Evaluation on NVIDIA H100 GPUs across representative LLM kernels shows that Tawa delivers high hardware utilization, achieving up to 1.1$\times$ speedup over highly optimized cuBLAS GEMM kernels. For attention workloads, Tawa attains 1.2$\times$ speedup over Triton and matches the performance of the hand-optimized CUTLASS C++ FlashAttention-3 kernel with far less programming effort.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14719v1</guid>
      <category>cs.LG</category>
      <category>cs.AR</category>
      <category>cs.PL</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hongzheng Chen, Bin Fan, Alexander Collins, Bastian Hagedorn, Evghenii Gaburov, Masahiro Masuda, Matthew Brookhart, Chris Sullivan, Jason Knight, Zhiru Zhang, Vinod Grover</dc:creator>
    </item>
    <item>
      <title>Deadlock-free routing for Full-mesh networks without using Virtual Channels</title>
      <link>https://arxiv.org/abs/2510.14730</link>
      <description>arXiv:2510.14730v1 Announce Type: cross 
Abstract: High-radix, low-diameter networks like HyperX and Dragonfly use a Full-mesh core, and rely on multiple virtual channels (VCs) to avoid packet deadlocks in adaptive routing. However, VCs introduce significant overhead in the switch in terms of area, power, and design complexity, limiting the switch scalability. This paper starts by revisiting VC-less routing through link ordering schemes in Full-mesh networks, which offer implementation simplicity but suffer from performance degradation under adversarial traffic. Thus, to overcome these challenges, we propose TERA (Topology-Embedded Routing Algorithm), a novel routing algorithm which employs an embedded physical subnetwork to provide deadlock-free non-minimal paths without using VCs.
  In a Full-mesh network, TERA outperforms link ordering routing algorithms by 80% when dealing with adversarial traffic, and up to 100% in application kernels. Furthermore, compared to other VC-based approaches, it reduces buffer requirements by 50%, while maintaining comparable latency and throughput. Lastly, early results from a 2D-HyperX evaluation show that TERA outperforms state-of-the-art algorithms that use the same number of VCs, achieving performance improvements of up to 32%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14730v1</guid>
      <category>cs.DC</category>
      <category>cs.AR</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/HOTI66940.2025.00020</arxiv:DOI>
      <dc:creator>Alejandro Cano, Crist\'obal Camarero, Carmen Mart\'inez, Ram\'on Beivide</dc:creator>
    </item>
    <item>
      <title>From Loop Nests to Silicon: Mapping AI Workloads onto AMD NPUs with MLIR-AIR</title>
      <link>https://arxiv.org/abs/2510.14871</link>
      <description>arXiv:2510.14871v1 Announce Type: cross 
Abstract: General-purpose compilers abstract away parallelism, locality, and synchronization, limiting their effectiveness on modern spatial architectures. As modern computing architectures increasingly rely on fine-grained control over data movement, execution order, and compute placement for performance, compiler infrastructure must provide explicit mechanisms for orchestrating compute and data to fully exploit such architectures. We introduce MLIR-AIR, a novel, open-source compiler stack built on MLIR that bridges the semantic gap between high-level workloads and fine-grained spatial architectures such as AMD's NPUs. MLIR-AIR defines the AIR dialect, which provides structured representations for asynchronous and hierarchical operations across compute and memory resources. AIR primitives allow the compiler to orchestrate spatial scheduling, distribute computation across hardware regions, and overlap communication with computation without relying on ad hoc runtime coordination or manual scheduling. We demonstrate MLIR-AIR's capabilities through two case studies: matrix multiplication and the multi-head attention block from the LLaMA 2 model. For matrix multiplication, MLIR-AIR achieves up to 78.7% compute efficiency and generates implementations with performance almost identical to state-of-the-art, hand-optimized matrix multiplication written using the lower-level, close-to-metal MLIR-AIE framework. For multi-head attention, we demonstrate that the AIR interface supports fused implementations using approximately 150 lines of code, enabling tractable expression of complex workloads with efficient mapping to spatial hardware. MLIR-AIR transforms high-level structured control flow into spatial programs that efficiently utilize the compute fabric and memory hierarchy of an NPU, leveraging asynchronous execution, tiling, and communication overlap through compiler-managed scheduling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14871v1</guid>
      <category>cs.CL</category>
      <category>cs.AR</category>
      <category>cs.LG</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Erwei Wang, Samuel Bayliss, Andra Bisca, Zachary Blair, Sangeeta Chowdhary, Kristof Denolf, Jeff Fifield, Brandon Freiberger, Erika Hunhoff, Phil James-Roxby, Jack Lo, Joseph Melber, Stephen Neuendorffer, Eddie Richter, Andre Rosti, Javier Setoain, Gagandeep Singh, Endri Taka, Pranathi Vasireddy, Zhewen Yu, Niansong Zhang, Jinming Zhuang</dc:creator>
    </item>
    <item>
      <title>HYLU: Hybrid Parallel Sparse LU Factorization</title>
      <link>https://arxiv.org/abs/2509.07690</link>
      <description>arXiv:2509.07690v4 Announce Type: replace 
Abstract: This article introduces HYLU, a hybrid parallel LU factorization-based general-purpose solver designed for efficiently solving sparse linear systems (Ax=b) on multi-core shared-memory architectures. The key technical feature of HYLU is the integration of hybrid numerical kernels so that it can adapt to various sparsity patterns of coefficient matrices. Tests on 34 sparse matrices from SuiteSparse Matrix Collection reveal that HYLU outperforms Intel MKL PARDISO in the numerical factorization phase by geometric means of 1.95X (for one-time solving) and 2.40X (for repeated solving). HYLU can be downloaded from https://github.com/chenxm1986/hylu.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.07690v4</guid>
      <category>cs.AR</category>
      <category>cs.DC</category>
      <category>cs.MS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaoming Chen</dc:creator>
    </item>
    <item>
      <title>Chiplet-Based RISC-V SoC with Modular AI Acceleration</title>
      <link>https://arxiv.org/abs/2509.18355</link>
      <description>arXiv:2509.18355v2 Announce Type: replace 
Abstract: Achieving high performance, energy efficiency, and cost-effectiveness while maintaining architectural flexibility is a critical challenge in the development and deployment of edge AI devices. Monolithic SoC designs struggle with this complex balance mainly due to low manufacturing yields (below 16%) at advanced 360 mm^2 process nodes. This paper presents a novel chiplet-based RISC-V SoC architecture that addresses these limitations through modular AI acceleration and intelligent system level optimization. Our proposed design integrates 4 different key innovations in a 30mm x 30mm silicon interposer: adaptive cross-chiplet Dynamic Voltage and Frequency Scaling (DVFS); AI-aware Universal Chiplet Interconnect Express (UCIe) protocol extensions featuring streaming flow control units and compression-aware transfers; distributed cryptographic security across heterogeneous chiplets; and intelligent sensor-driven load migration. The proposed architecture integrates a 7nm RISC-V CPU chiplet with dual 5nm AI accelerators (15 TOPS INT8 each), 16GB HBM3 memory stacks, and dedicated power management controllers. Experimental results across industry standard benchmarks like MobileNetV2, ResNet-50 and real-time video processing demonstrate significant performance improvements. The AI-optimized configuration achieves ~14.7% latency reduction, 17.3% throughput improvement, and 16.2% power reduction compared to previous basic chiplet implementations. These improvements collectively translate to a 40.1% efficiency gain corresponding to ~3.5 mJ per MobileNetV2 inference (860 mW/244 images/s), while maintaining sub-5ms real-time capability across all experimented workloads. These performance upgrades demonstrate that modular chiplet designs can achieve near-monolithic computational density while enabling cost efficiency, scalability and upgradeability, crucial for next-generation edge AI device applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.18355v2</guid>
      <category>cs.AR</category>
      <category>cs.AI</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>P. Ramkumar, S. S. Bharadwaj</dc:creator>
    </item>
    <item>
      <title>Understanding and Mitigating Covert Channel and Side Channel Vulnerabilities Introduced by RowHammer Defenses</title>
      <link>https://arxiv.org/abs/2503.17891</link>
      <description>arXiv:2503.17891v3 Announce Type: replace-cross 
Abstract: DRAM chips are vulnerable to read disturbance phenomena (e.g., RowHammer and RowPress), where repeatedly accessing or keeping open a DRAM row causes bitflips in nearby rows. Attackers leverage RowHammer bitflips in real systems to take over systems and leak data. Consequently, many prior works propose defenses, including recent DDR specifications introducing new defenses (e.g., PRAC and RFM). For robust operation, it is critical to analyze other security implications of RowHammer defenses. Unfortunately, no prior work analyzes the timing covert and side channel vulnerabilities introduced by RowHammer defenses.
  This paper presents the first analysis and evaluation of timing covert and side channel vulnerabilities introduced by state-of-the-art RowHammer defenses. We demonstrate that RowHammer defenses' preventive actions have two fundamental features that enable timing channels. First, preventive actions reduce DRAM bandwidth availability, resulting in longer memory latencies. Second, preventive actions can be triggered on demand depending on memory access patterns.
  We introduce LeakyHammer, a new class of attacks that leverage the RowHammer defense-induced memory latency differences to establish communication channels and leak secrets. First, we build two covert channel attacks exploiting two state-of-the-art RowHammer defenses, achieving 39.0 Kbps and 48.7 Kbps channel capacity. Second, we demonstrate a website fingerprinting attack that identifies visited websites based on the RowHammer-preventive actions they cause. We propose and evaluate three countermeasures against LeakyHammer. Our results show that fundamentally mitigating LeakyHammer induces large performance overheads in highly RowHammer-vulnerable systems. We believe and hope our work can enable and aid future work on designing better solutions and more robust systems in the presence of such new vulnerabilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.17891v3</guid>
      <category>cs.CR</category>
      <category>cs.AR</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>F. Nisa Bostanc{\i}, O\u{g}uzhan Canpolat, Ataberk Olgun, \.Ismail Emir Y\"uksel, Konstantinos Kanellopoulos, Mohammad Sadrosadati, A. Giray Ya\u{g}l{\i}k\c{c}{\i}, Onur Mutlu</dc:creator>
    </item>
  </channel>
</rss>
