<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DC</link>
    <description>cs.DC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 14 Aug 2024 04:00:17 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 14 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Runtime Verification Containers for Publish/Subscribe Networks</title>
      <link>https://arxiv.org/abs/2408.06380</link>
      <description>arXiv:2408.06380v1 Announce Type: new 
Abstract: Publish/subscribe (pub/sub) networks are a cornerstone of modern distributed systems, playing a crucial role in applications like the Internet of Things (IoT) and robotics. While runtime verification techniques seem ideal for ensuring the correctness of such highly dynamic and large-scale networks, integrating runtime monitors seamlessly into real-world industrial use cases presents significant challenges. This paper studies modern containerization technology to deploy runtime verification tools to monitor publish/subscribe networks with a performance focus. Runtime verification containers are lightweight and deployable alongside other containerized publisher and subscriber participants. Each runtime verification container monitors message flow, enabling runtime verification of network behavior. We comprehensively benchmark the container-based approach using several experiments and a real-world case study from the software-defined vehicle domain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06380v1</guid>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ali Mehran, Dogan Ulus</dc:creator>
    </item>
    <item>
      <title>BFTBrain: Adaptive BFT Consensus with Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2408.06432</link>
      <description>arXiv:2408.06432v1 Announce Type: new 
Abstract: This paper presents BFTBrain, a reinforcement learning (RL) based Byzantine fault-tolerant (BFT) system that provides significant operational benefits: a plug-and-play system suitable for a broad set of hardware and network configurations, and adjusts effectively in real-time to changing fault scenarios and workloads. BFTBrain adapts to system conditions and application needs by switching between a set of BFT protocols in real-time. Two main advances contribute to BFTBrain's agility and performance. First, BFTBrain is based on a systematic, thorough modeling of metrics that correlate the performance of the studied BFT protocols with varying fault scenarios and workloads. These metrics are fed as features to BFTBrain's RL engine in order to choose the best-performing BFT protocols in real-time. Second, BFTBrain coordinates RL in a decentralized manner which is resilient to adversarial data pollution, where nodes share local metering values and reach the same learning output by consensus. As a result, in addition to providing significant operational benefits, BFTBrain improves throughput over fixed protocols by $18\%$ to $119\%$ under dynamic conditions and outperforms state-of-the-art learning based approaches by $44\%$ to $154\%$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06432v1</guid>
      <category>cs.DC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chenyuan Wu, Haoyun Qin, Mohammad Javad Amiri, Boon Thau Loo, Dahlia Malkhi, Ryan Marcus</dc:creator>
    </item>
    <item>
      <title>Modeling and Simulation of Traffic on I-485 via Linear Systems and Iterative Methods</title>
      <link>https://arxiv.org/abs/2408.06511</link>
      <description>arXiv:2408.06511v1 Announce Type: new 
Abstract: Iterative methods such as Jacobi, Gauss-Seidel, and Successive Over-Relaxation (SOR) are fundamental tools in solving large systems of linear equations across various scientific fields, particularly in the field of data science which has become increasingly relevant in the past decade. Iterative methods' use of matrix multiplication rather than matrix inverses makes them ideal for solving large systems quickly. Our research explores the factors of each method that define their respective strengths, limitations, and convergence behaviors to understand how these methods address drawbacks encountered when performing matrix operations by hand, as well as how they can be used in real world applications. After implementing each method by hand to understand how the algorithms work, we developed a Python program that assesses a user-given matrix based on each method's specific convergence criteria. The program compares the spectral radii of all three methods and chooses to execute whichever will yield the fastest convergence rate. Our research revealed the importance of mathematical modeling and understanding specific properties of the coefficient matrix. We observed that Gauss-Seidel is usually the most efficient method because it is faster than Jacobi and doesn't have as strict requirements as SOR, however SOR is ideal in terms of computation speed. We applied the knowledge we gained to create a traffic flow model of the I-485 highway in Charlotte. After creating a program that generates the matrix for this model, we were able to iteratively approximate the flow of cars through neighboring exits using data from the N.C. Department of Transportation. This information identifies which areas are the most congested and can be used to inform future infrastructure development.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06511v1</guid>
      <category>cs.DC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Dominic Kealoha, Fabiola Rojas, Xingjie Li</dc:creator>
    </item>
    <item>
      <title>Architecture Specific Generation of Large Scale Lattice Boltzmann Methods for Sparse Complex Geometries</title>
      <link>https://arxiv.org/abs/2408.06880</link>
      <description>arXiv:2408.06880v1 Announce Type: new 
Abstract: We implement and analyse a sparse / indirect-addressing data structure for the Lattice Boltzmann Method to support efficient compute kernels for fluid dynamics problems with a high number of non-fluid nodes in the domain, such as in porous media flows. The data structure is integrated into a code generation pipeline to enable sparse Lattice Boltzmann Methods with a variety of stencils and collision operators and to generate efficient code for kernels for CPU as well as for AMD and NVIDIA accelerator cards. We optimize these sparse kernels with an in-place streaming pattern to save memory accesses and memory consumption and we implement a communication hiding technique to prove scalability. We present single GPU performance results with up to 99% of maximal bandwidth utilization. We integrate the optimized generated kernels in the high performance framework WALBERLA and achieve a scaling efficiency of at least 82% on up to 1024 NVIDIA A100 GPUs and up to 4096 AMD MI250X GPUs on modern HPC systems. Further, we set up three different applications to test the sparse data structure for realistic demonstrator problems. We show performance results for flow through porous media, free flow over a particle bed, and blood flow in a coronary artery. We achieve a maximal performance speed-up of 2 and a significantly reduced memory consumption by up to 75% with the sparse / indirect-addressing data structure compared to the direct-addressing data structure for these applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06880v1</guid>
      <category>cs.DC</category>
      <category>cs.PF</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Philipp Suffa, Markus Holzer, Harald K\"ostler, Ulrich R\"ude</dc:creator>
    </item>
    <item>
      <title>Heterogeneity: An Open Challenge for Federated On-board Machine Learning</title>
      <link>https://arxiv.org/abs/2408.06903</link>
      <description>arXiv:2408.06903v1 Announce Type: new 
Abstract: The design of satellite missions is currently undergoing a paradigm shift from the historical approach of individualised monolithic satellites towards distributed mission configurations, consisting of multiple small satellites. With a rapidly growing number of such satellites now deployed in orbit, each collecting large amounts of data, interest in on-board orbital edge computing is rising. Federated Learning is a promising distributed computing approach in this context, allowing multiple satellites to collaborate efficiently in training on-board machine learning models. Though recent works on the use of Federated Learning in orbital edge computing have focused largely on homogeneous satellite constellations, Federated Learning could also be employed to allow heterogeneous satellites to form ad-hoc collaborations, e.g. in the case of communications satellites operated by different providers. Such an application presents additional challenges to the Federated Learning paradigm, arising largely from the heterogeneity of such a system. In this position paper, we offer a systematic review of these challenges in the context of the cross-provider use case, giving a brief overview of the state-of-the-art for each, and providing an entry point for deeper exploration of each issue.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06903v1</guid>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maria Hartmann, Gr\'egoire Danoy, Pascal Bouvry</dc:creator>
    </item>
    <item>
      <title>Verifiable Decentralized IPFS Cluster: Unlocking Trustworthy Data Permanency for Off-Chain Storage</title>
      <link>https://arxiv.org/abs/2408.07023</link>
      <description>arXiv:2408.07023v1 Announce Type: new 
Abstract: In Decentralized Applications, off-chain storage solutions such as the InterPlanetary File System (IPFS) are crucial in overcoming Blockchain storage limitations. However, the assurance of data permanency in IPFS relies on the pinning of data, which comes with trust issues and potential single points of failure. This paper introduces Verifiable Decentralized IPFS Clusters (VDICs) to enhance off-chain storage reliability with verifiable data permanency guarantees. VDICs leverage Decentralized Identifier, Verifiable Credentials, and IPFS Clusters to create a trustworthy ecosystem where the storage of pinned data is transparent and verifiable. Performance evaluations demonstrate that VDICs are competitive with traditional pinning services. Real-life use cases validate their feasibility and practicality for providers of Decentralized Applications focused on ensuring data permanency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.07023v1</guid>
      <category>cs.DC</category>
      <category>cs.CR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Sid Lamichhane, Patrick Herbke</dc:creator>
    </item>
    <item>
      <title>FedRobo: Federated Learning Driven Autonomous Inter Robots Communication For Optimal Chemical Sprays</title>
      <link>https://arxiv.org/abs/2408.06382</link>
      <description>arXiv:2408.06382v1 Announce Type: cross 
Abstract: Federated Learning enables robots to learn from each other's experiences without relying on centralized data collection. Each robot independently maintains a model of crop conditions and chemical spray effectiveness, which is periodically shared with other robots in the fleet. A communication protocol is designed to optimize chemical spray applications by facilitating the exchange of information about crop conditions, weather, and other critical factors. The federated learning algorithm leverages this shared data to continuously refine the chemical spray strategy, reducing waste and improving crop yields. This approach has the potential to revolutionize the agriculture industry by offering a scalable and efficient solution for crop protection. However, significant challenges remain, including the development of a secure and robust communication protocol, the design of a federated learning algorithm that effectively integrates data from multiple sources, and ensuring the safety and reliability of autonomous robots. The proposed cluster-based federated learning approach also effectively reduces the computational load on the global server and minimizes communication overhead among clients.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06382v1</guid>
      <category>cs.LG</category>
      <category>cs.CV</category>
      <category>cs.DC</category>
      <category>cs.RO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jannatul Ferdaus, Sameera Pisupati, Mahedi Hasan, Sathwick Paladugu</dc:creator>
    </item>
    <item>
      <title>Prioritizing Modalities: Flexible Importance Scheduling in Federated Multimodal Learning</title>
      <link>https://arxiv.org/abs/2408.06549</link>
      <description>arXiv:2408.06549v1 Announce Type: cross 
Abstract: Federated Learning (FL) is a distributed machine learning approach that enables devices to collaboratively train models without sharing their local data, ensuring user privacy and scalability. However, applying FL to real-world data presents challenges, particularly as most existing FL research focuses on unimodal data. Multimodal Federated Learning (MFL) has emerged to address these challenges, leveraging modality-specific encoder models to process diverse datasets. Current MFL methods often uniformly allocate computational frequencies across all modalities, which is inefficient for IoT devices with limited resources. In this paper, we propose FlexMod, a novel approach to enhance computational efficiency in MFL by adaptively allocating training resources for each modality encoder based on their importance and training requirements. We employ prototype learning to assess the quality of modality encoders, use Shapley values to quantify the importance of each modality, and adopt the Deep Deterministic Policy Gradient (DDPG) method from deep reinforcement learning to optimize the allocation of training resources. Our method prioritizes critical modalities, optimizing model performance and resource utilization. Experimental results on three real-world datasets demonstrate that our proposed method significantly improves the performance of MFL models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06549v1</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jieming Bian, Lei Wang, Jie Xu</dc:creator>
    </item>
    <item>
      <title>Understanding Power Consumption Metric on Heterogeneous Memory Systems</title>
      <link>https://arxiv.org/abs/2408.06579</link>
      <description>arXiv:2408.06579v1 Announce Type: cross 
Abstract: Contemporary memory systems contain a variety of memory types, each possessing distinct characteristics. This trend empowers applications to opt for memory types aligning with developer's desired behavior. As a result, developers gain flexibility to tailor their applications to specific needs, factoring in attributes like latency, bandwidth, and power consumption. Our research centers on the aspect of power consumption within memory systems. We introduce an approach that equips developers with comprehensive insights into the power consumption of individual memory types. Additionally, we propose an ordered hierarchy of memory types. Through this methodology, developers can make informed decisions for efficient memory usage aligned with their unique requirements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06579v1</guid>
      <category>cs.PF</category>
      <category>cs.DC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/ICPADS60453.2023.00408</arxiv:DOI>
      <arxiv:journal_reference>2023 IEEE 29th International Conference on Parallel and Distributed Systems (ICPADS), Ocean Flower Island, China, 2023, pp. 2859-2862</arxiv:journal_reference>
      <dc:creator>Andr\`es Rubio Proa\~no, Kento Sato</dc:creator>
    </item>
    <item>
      <title>PayOff: A Regulated Central Bank Digital Currency with Private Offline Payments</title>
      <link>https://arxiv.org/abs/2408.06956</link>
      <description>arXiv:2408.06956v1 Announce Type: cross 
Abstract: The European Central Bank is preparing for the potential issuance of a central bank digital currency (CBDC), called the digital euro. A recent regulatory proposal by the European Commission defines several requirements for the digital euro, such as support for both online and offline payments. Offline payments are expected to enable cash-like privacy, local payment settlement, and the enforcement of holding limits. While other central banks have expressed similar desired functionality, achieving such offline payments poses a novel technical challenge. We observe that none of the existing research solutions, including offline E-cash schemes, are fully compliant. Proposed solutions based on secure elements offer no guarantees in case of compromise and can therefore lead to significant payment fraud.
  The main contribution of this paper is PayOff, a novel CBDC design motivated by the digital euro regulation, which focuses on offline payments. We analyze the security implications of local payment settlement and identify new security objectives. PayOff protects user privacy, supports complex regulations such as holding limits, and implements safeguards to increase robustness against secure element failure. Our analysis shows that PayOff provides strong privacy and identifies residual leakages that may arise in real-world deployments. Our evaluation shows that offline payments can be fast and that the central bank can handle high payment loads with moderate computing resources. However, the main limitation of PayOff is that offline payment messages and storage requirements grow in the number of payments that the sender makes or receives without going online in between.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06956v1</guid>
      <category>cs.CR</category>
      <category>cs.DC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Carolin Beer, Sheila Zingg, Kari Kostiainen, Karl W\"ust, Vedran Capkun, Srdjan Capkun</dc:creator>
    </item>
    <item>
      <title>Advancing Environmental Sustainability in Data Centers by Proposing Carbon Depreciation Models</title>
      <link>https://arxiv.org/abs/2403.04976</link>
      <description>arXiv:2403.04976v2 Announce Type: replace 
Abstract: The rising demand for on-demand, high-performance computing has led to the growth of data centers, which in turn presents both challenges and opportunities for addressing their environmental impact. Traditionally, sustainability efforts in data centers have focused on reducing energy consumption. However, with advancements in energy efficiency and the integration of renewable energy, the role of embodied carbon has become increasingly significant, necessitating a shift in data center provisioning strategies. This paper proposes the use of carbon depreciation models to encourage longer hardware lifecycles in data centers. These models allocate a higher share of embodied carbon to newly provisioned servers, thereby incentivizing the reduction of new server acquisitions for jobs with stringent quality-of-service (QoS) requirements and promoting the extended use of existing servers with largely recovered embodied carbon. Additionally, we argue that both embodied and operational carbon from server idle time should be considered and recovered during active job processing, which supports high utilization rates. Our analysis demonstrates that traditional carbon accounting methods, which favor new hardware under QoS constraints, are counterproductive to sustainability, as they undervalue the carbon impact of older equipment by pricing jobs 25% cheaper on new hardware. Our approach advocates for improved sustainability through our depreciation model, which ensures that jobs on new machines account for more than twice the carbon emissions compared to older machines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.04976v2</guid>
      <category>cs.DC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shixin Ji, Zhuoping Yang, Alex K. Jones, Peipei Zhou</dc:creator>
    </item>
    <item>
      <title>Building a Verifiable Logical Clock for P2P Networks</title>
      <link>https://arxiv.org/abs/2405.13349</link>
      <description>arXiv:2405.13349v2 Announce Type: replace 
Abstract: Logical clocks are a fundamental tool to establish causal ordering of events in a distributed system. They have been applied in weakly consistent storage systems, causally ordered broadcast, distributed snapshots, deadlock detection, and distributed system debugging. However, prior logical clock constructs fail to work in an open network with Byzantine participants. In this work, we present Chrono, a novel logical clock system that targets such challenging environment. We first redefine causality properties among distributed processes under the Byzantine failure model. To enforce these properties, Chrono defines a new validator abstraction for building fault-tolerant logical clocks. Furthermore, our validator abstraction is customizable: Chrono includes multiple backend implementations for the abstraction, each with different security-performance trade-offs. We have applied Chrono to build two decentralized applications, a mutual exclusive service and a weakly consistent key-value store. Chrono adds only marginal overhead compared to systems that tolerate no Byzantine faults. It also out-performs state-of-the-art BFT total order protocols by significant margins.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.13349v2</guid>
      <category>cs.DC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Guangda Sun, Tianyang Tao, Yanpei Guo, Michael Yiqing Hu, Jialin Li</dc:creator>
    </item>
    <item>
      <title>GraNNDis: Efficient Unified Distributed Training Framework for Deep GNNs on Large Clusters</title>
      <link>https://arxiv.org/abs/2311.06837</link>
      <description>arXiv:2311.06837v2 Announce Type: replace-cross 
Abstract: Graph neural networks (GNNs) are one of the rapidly growing fields within deep learning. While many distributed GNN training frameworks have been proposed to increase the training throughput, they face three limitations when applied to multi-server clusters. 1) They suffer from an inter-server communication bottleneck because they do not consider the inter-/intra-server bandwidth gap, a representative characteristic of multi-server clusters. 2) Redundant memory usage and computation hinder the scalability of the distributed frameworks. 3) Sampling methods, de facto standard in mini-batch training, incur unnecessary errors in multi-server clusters. We found that these limitations can be addressed by exploiting the characteristics of multi-server clusters. Here, we propose GraNNDis, a fast distributed GNN training framework for multi-server clusters. Firstly, we present Flexible Preloading, which preloads the essential vertex dependencies server-wise to reduce the low-bandwidth inter-server communications. Secondly, we introduce Cooperative Batching, which enables memory-efficient, less redundant mini-batch training by utilizing high-bandwidth intra-server communications. Thirdly, we propose Expansion-aware Sampling, a cluster-aware sampling method, which samples the edges that affect the system speedup. As sampling the intra-server dependencies does not contribute much to the speedup as they are communicated through fast intra-server links, it only targets a server boundary to be sampled. Lastly, we introduce One-Hop Graph Masking, a computation and communication structure to realize the above methods in multi-server environments. We evaluated GraNNDis on multi-server clusters, and it provided significant speedup over the state-of-the-art distributed GNN training frameworks. GraNNDis is open-sourced at https://github.com/AIS-SNU/GraNNDis_Artifact to facilitate its use.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.06837v2</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jaeyong Song, Hongsun Jang, Jaewon Jung, Youngsok Kim, Jinho Lee</dc:creator>
    </item>
    <item>
      <title>A large-scale particle system with independent jumps and distributed synchronization</title>
      <link>https://arxiv.org/abs/2311.17052</link>
      <description>arXiv:2311.17052v3 Announce Type: replace-cross 
Abstract: We study a system consisting of $n$ particles, moving forward in jumps on the real line. Each particle can make both independent jumps, whose sizes have some distribution, or ``synchronization'' jumps, which allow it to join a randomly chosen other particle if the latter happens to be ahead of it. System state is the empirical distribution of particle locations. The mean-field asymptotic regime, where $n\to\infty$, is considered. We prove that $v_n$, the steady-state speed of the particle system advance, converges, as $n\to\infty$, to a limit $v_{**}$ which can be easily found from a {\em minimum speed selection principle.} Also, as $n\to\infty$, we prove the convergence of the system dynamics to that of a deterministic mean-field limit (MFL). We show that the average speed of advance of any MFL is lower bounded by $v_{**}$, and the speed of a ``benchmark'' MFL, resulting from all particles initially co-located, is equal to $v_{**}$.
  In the special case of exponentially distributed independent jump sizes, we prove that a traveling wave MFL with speed $v$ exists if and only if $v\ge v_{**}$, with $v_{**}$ having simple explicit form; we also show the existence of traveling waves for the modified systems, with a left or right boundary moving at a constant speed $v$. Using these traveling wave existence results, we provide bounds on an MFL average speed of advance, depending on the right tail exponent of its initial state. We conjecture that these results for exponential jump sizes generalize to general jump sizes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.17052v3</guid>
      <category>math.PR</category>
      <category>cs.DC</category>
      <category>cs.MA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuliy Baryshnikov, Alexander Stolyar</dc:creator>
    </item>
    <item>
      <title>TraceFL: Achieving Interpretability in Federated Learning via Neuron Provenance</title>
      <link>https://arxiv.org/abs/2312.13632</link>
      <description>arXiv:2312.13632v2 Announce Type: replace-cross 
Abstract: In Federated Learning, clients train models on local data and send updates to a central server, which aggregates them into a global model using a fusion algorithm. This collaborative yet privacy-preserving training comes at a cost--FL developers face significant challenges in attributing global model predictions to specific clients. Localizing responsible clients is a crucial step towards (a) excluding clients primarily responsible for incorrect predictions and (b) encouraging clients who contributed high-quality models to continue participating in the future. Existing ML explainability approaches are inherently inapplicable as they are designed for single-model, centralized training.
  We introduce TraceFL, a fine-grained neuron provenance capturing mechanism that identifies clients responsible for the global model's prediction by tracking the flow of information from individual clients to the global model. Since inference on different inputs activates a different set of neurons of the global model, TraceFL dynamically quantifies the significance of the global model's neurons in a given prediction. It then selectively picks a slice of the most crucial neurons in the global model and maps them to the corresponding neurons in every participating client to determine each client's contribution, ultimately localizing the responsible client. We evaluate TraceFL on six datasets, including two real-world medical imaging datasets and four neural networks, including advanced models such as GPT. TraceFL achieves 99% accuracy in localizing the responsible client in FL tasks spanning both image and text classification tasks. At a time when state-of-the-art ML debugging approaches are mostly domain-specific (e.g., image classification only), TraceFL is the first technique to enable highly accurate automated reasoning across a wide range of FL applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.13632v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.DC</category>
      <category>cs.SE</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Waris Gill (Virginia Tech), Ali Anwar (University of Minnesota Twin Cities), Muhammad Ali Gulzar (Virginia Tech)</dc:creator>
    </item>
    <item>
      <title>etuner: Redundancy-Aware Efficient Continual Learning on Edge Devices</title>
      <link>https://arxiv.org/abs/2401.16694</link>
      <description>arXiv:2401.16694v4 Announce Type: replace-cross 
Abstract: Many emerging applications, such as robot-assisted eldercare and object recognition, generally employ deep learning neural networks (DNNs) and require the deployment of DNN models on edge devices. These applications naturally require i) handling streaming-in inference requests and ii) fine-tuning the deployed models to adapt to possible deployment scenario changes. Continual learning (CL) is widely adopted to satisfy these needs. CL is a popular deep learning paradigm that handles both continuous model fine-tuning and overtime inference requests. However, an inappropriate model fine-tuning scheme could involve significant redundancy and consume considerable time and energy, making it challenging to apply CL on edge devices. In this paper, we propose ETuner, an efficient edge continual learning framework that optimizes inference accuracy, fine-tuning execution time, and energy efficiency through both inter-tuning and intra-tuning optimizations. Experimental results show that, on average, ETuner reduces overall fine-tuning execution time by 64%, energy consumption by 56%, and improves average inference accuracy by 1.75% over the immediate model fine-tuning approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.16694v4</guid>
      <category>cs.LG</category>
      <category>cs.CV</category>
      <category>cs.DC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sheng Li, Geng Yuan, Yawen Wu, Yue Dai, Tianyu Wang, Chao Wu, Alex K. Jones, Jingtong Hu, Yanzhi Wang, Xulong Tang</dc:creator>
    </item>
    <item>
      <title>Decentralized Intelligence Network (DIN)</title>
      <link>https://arxiv.org/abs/2407.02461</link>
      <description>arXiv:2407.02461v4 Announce Type: replace-cross 
Abstract: Decentralized Intelligence Network (DIN) is a theoretical framework addressing data fragmentation and siloing challenges, enabling scalable AI through data sovereignty. It facilitates effective AI utilization within sovereign networks by overcoming barriers to accessing diverse data sources, leveraging: 1) personal data stores to ensure data sovereignty, where data remains securely within Participants' control; 2) a scalable federated learning protocol implemented on a public blockchain for decentralized AI training, where only model parameter updates are shared, keeping data within the personal data stores; and 3) a scalable, trustless cryptographic rewards mechanism on a public blockchain to incentivize participation and ensure fair reward distribution through a decentralized auditing protocol. This approach guarantees that no entity can prevent or control access to training data or influence financial benefits, as coordination and reward distribution are managed on the public blockchain with an immutable record. The framework supports effective AI training by allowing Participants to maintain control over their data, benefit financially, and contribute to a decentralized, scalable ecosystem that leverages collective AI to develop beneficial algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.02461v4</guid>
      <category>cs.CR</category>
      <category>cs.CY</category>
      <category>cs.DC</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Abraham Nash</dc:creator>
    </item>
    <item>
      <title>Decentralized Intelligence Health Network (DIHN)</title>
      <link>https://arxiv.org/abs/2408.06240</link>
      <description>arXiv:2408.06240v2 Announce Type: replace-cross 
Abstract: Decentralized Health Intelligence Network (DHIN) is a theoretical framework addressing significant challenges of health data sovereignty and AI utilization in healthcare caused by data fragmentation across providers and institutions. It establishes a sovereign architecture for healthcare provision as a prerequisite to a sovereign health network, then facilitates effective AI utilization by overcoming barriers to accessing diverse medical data sources. This comprehensive framework leverages: 1) self-sovereign identity architecture coupled with a personal health record (PHR) as a prerequisite for health data sovereignty; 2) a scalable federated learning (FL) protocol implemented on a public blockchain for decentralized AI training in healthcare, where health data remains with participants and only model parameter updates are shared; and 3) a scalable, trustless rewards mechanism to incentivize participation and ensure fair reward distribution. This framework ensures that no entity can prevent or control access to training on health data offered by participants or determine financial benefits, as these processes operate on a public blockchain with an immutable record and without a third party. It supports effective AI training in healthcare, allowing patients to maintain control over their health data, benefit financially, and contribute to a decentralized, scalable ecosystem that leverages collective AI to develop beneficial healthcare algorithms. Patients receive rewards into their digital wallets as an incentive to opt-in to the FL protocol, with a long-term roadmap to funding decentralized insurance solutions. This approach introduces a novel, self-financed healthcare model that adapts to individual needs, complements existing systems, and redefines universal coverage. It highlights the potential to transform healthcare data management and AI utilization while empowering patients.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06240v2</guid>
      <category>cs.CR</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.DC</category>
      <category>cs.ET</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Abraham Nash</dc:creator>
    </item>
  </channel>
</rss>
