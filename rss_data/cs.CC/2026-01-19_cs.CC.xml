<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CC</link>
    <description>cs.CC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 19 Jan 2026 05:00:16 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 19 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Minimizing the Cost of EFx Allocations</title>
      <link>https://arxiv.org/abs/2601.11372</link>
      <description>arXiv:2601.11372v1 Announce Type: cross 
Abstract: Ensuring fairness while limiting costs, such as transportation or storage, is an important challenge in resource allocation, yet most work has focused on cost minimization without fairness or fairness without explicit cost considerations. We introduce and formally define the minCost-EFx Allocation problem, where the objective is to compute an allocation that is envy-free up to any item (EFx) and has minimum cost. We investigate the algorithmic complexity of this problem, proving that it is NP-hard already with two agents. On the positive side, we show that the problem admits a polynomial kernel with respect to the number of items, implying that a core source of intractability lies in the number of items. Building on this, we identify parameter-restricted settings that are tractable, including cases with bounded valuations and a constant number of agents, or a limited number of item types under restricted cost models. Finally, we turn to cost approximation, proving that for any $\rho&gt;1$ the problem is not $\rho$-approximable in polynomial time (unless $P=NP$), while also identifying restricted cost models where costs are agent-specific and independent of the actual items received, which admit better approximation guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.11372v1</guid>
      <category>cs.GT</category>
      <category>cs.CC</category>
      <pubDate>Mon, 19 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eva Deltl</dc:creator>
    </item>
    <item>
      <title>Optimal learning of quantum channels in diamond distance</title>
      <link>https://arxiv.org/abs/2512.10214</link>
      <description>arXiv:2512.10214v2 Announce Type: replace-cross 
Abstract: Quantum process tomography, the task of estimating an unknown quantum channel, is a central problem in quantum information theory. A long-standing open question is to determine the optimal number of uses of an unknown channel required to learn it in diamond distance, the standard metric for distinguishing quantum processes. While the analogous problem of quantum state tomography has been settled over the past decades in both the pure- and mixed-state settings, for general quantum channels it remained largely open beyond the unitary case. Here we design an algorithm showing that any channel with input and output dimensions $d_{\mathrm{in}},d_{\mathrm{out}}$ and Kraus rank at most $k$ can be learned to constant accuracy in diamond distance using $\Theta(d_{\mathrm{in}}d_{\mathrm{out}}k)$ channel uses, and we prove that this scaling is optimal via a matching lower bound. More generally, achieving accuracy $\varepsilon$ is possible with $O(d_{\mathrm{in}}d_{\mathrm{out}}k/\varepsilon^{2})$ channel uses. Since quantum channels subsume states, unitaries, and isometries as special cases, our protocol provides a unified framework for the corresponding tomography tasks; in particular, it yields the first optimal protocols for isometries and for binary measurement tomography, and it recovers optimal trace-distance tomography for fixed-rank states. Our approach reduces channel tomography to pure-state tomography: we use the channel to prepare copies of its Choi state, purify them in parallel, and run sample-optimal pure-state tomography on the resulting purifications; we then show that the induced diamond-distance error scales essentially linearly with the trace-distance error in estimating the (purified) Choi state. We also resolve an open question by showing that adaptivity does not improve the dimension-optimal query complexity of quantum channel tomography.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.10214v2</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Mon, 19 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Antonio Anna Mele, Lennart Bittel</dc:creator>
    </item>
    <item>
      <title>Quantifier Elimination Meets Treewidth</title>
      <link>https://arxiv.org/abs/2601.00312</link>
      <description>arXiv:2601.00312v2 Announce Type: replace-cross 
Abstract: In this paper, we address the complexity barrier inherent in Fourier-Motzkin elimination (FME) and cylindrical algebraic decomposition (CAD) when eliminating a block of (existential) quantifiers. To mitigate this, we propose exploiting structural sparsity in the variable dependency graph of quantified formulas. Utilizing tools from parameterized algorithms, we investigate the role of treewidth, a parameter that measures the graph's tree-likeness, in the process of quantifier elimination. A novel dynamic programming framework, structured over a tree decomposition of the dependency graph, is developed for applying FME and CAD, and is also extensible to general quantifier elimination procedures. Crucially, we prove that when the treewidth is a constant, the framework achieves a significant exponential complexity improvement for both FME and CAD, reducing the worst-case complexity bound from doubly exponential to single exponential. Preliminary experiments on sparse linear real arithmetic (LRA) and nonlinear real arithmetic (NRA) benchmarks confirm that our algorithm outperforms the existing popular heuristic-based approaches on instances exhibiting low treewidth.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00312v2</guid>
      <category>cs.LO</category>
      <category>cs.CC</category>
      <category>cs.SC</category>
      <pubDate>Mon, 19 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hao Wu, Jiyu Zhu, Amir Kafshdar Goharshady, Jie An, Bican Xia, Naijun Zhan</dc:creator>
    </item>
  </channel>
</rss>
