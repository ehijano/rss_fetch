<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.HC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.HC</link>
    <description>cs.HC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.HC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 17 Oct 2025 04:00:50 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Choreographing Trash Cans: On Speculative Futures of Weak Robots in Public Spaces</title>
      <link>https://arxiv.org/abs/2510.13810</link>
      <description>arXiv:2510.13810v1 Announce Type: new 
Abstract: Delivering groceries or cleaning airports, mobile robots exist in public spaces. While these examples showcase robots that execute tasks, this paper explores mobile robots that encourage posthuman collaboration rather than managing environments independently. With feigned fragility, cuteness and incomplete functionalities, the so-called "weak robots" invite passersby to engage not only on a utilitarian level, but also through imaginative and emotional responses. After examining the workings of "weak robots" by queering notions of function and ability, we introduce two speculative design fiction vignettes that describe choreographies of such robots in future urban spaces -- one exploring a utopian weak robot and the other a dystopian weak robot. We introduce these speculations in order to discuss how different values may drive design decisions, and how such decisions may shape and drive different socio-technical futures in which robots and humans share public spaces that incentivise collaboration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.13810v1</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <category>cs.RO</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Minja Axelsson, Lea Luka Sikau</dc:creator>
    </item>
    <item>
      <title>Generative AI in Heritage Practice: Improving the Accessibility of Heritage Guidance</title>
      <link>https://arxiv.org/abs/2510.13811</link>
      <description>arXiv:2510.13811v1 Announce Type: new 
Abstract: This paper discusses the potential for integrating Generative Artificial Intelligence (GenAI) into professional heritage practice with the aim of enhancing the accessibility of public-facing guidance documents. We developed HAZEL, a GenAI chatbot fine-tuned to assist with revising written guidance relating to heritage conservation and interpretation. Using quantitative assessments, we compare HAZEL's performance to that of ChatGPT (GPT-4) in a series of tasks related to the guidance writing process. The results of this comparison indicate a slightly better performance of HAZEL over ChatGPT, suggesting that the GenAI chatbot is more effective once the underlying large language model (LLM) has been fine-tuned. However, we also note significant limitations, particularly in areas requiring cultural sensitivity and more advanced technical expertise. These findings suggest that, while GenAI cannot replace human heritage professionals in technical authoring tasks, its potential to automate and expedite certain aspects of guidance writing could offer valuable benefits to heritage organisations, especially in resource-constrained contexts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.13811v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jessica Witte, Edmund Lee, Lisa Brausem, Verity Shillabeer, Chiara Bonacchi</dc:creator>
    </item>
    <item>
      <title>MindBenchAI: An Actionable Platform to Evaluate the Profile and Performance of Large Language Models in a Mental Healthcare Context</title>
      <link>https://arxiv.org/abs/2510.13812</link>
      <description>arXiv:2510.13812v1 Announce Type: new 
Abstract: Individuals are increasingly utilizing large language model (LLM)based tools for mental health guidance and crisis support in place of human experts. While AI technology has great potential to improve health outcomes, insufficient empirical evidence exists to suggest that AI technology can be deployed as a clinical replacement; thus, there is an urgent need to assess and regulate such tools. Regulatory efforts have been made and multiple evaluation frameworks have been proposed, however,field-wide assessment metrics have yet to be formally integrated. In this paper, we introduce a comprehensive online platform that aggregates evaluation approaches and serves as a dynamic online resource to simplify LLM and LLM-based tool assessment: MindBenchAI. At its core, MindBenchAI is designed to provide easily accessible/interpretable information for diverse stakeholders (patients, clinicians, developers, regulators, etc.). To create MindBenchAI, we built off our work developing MINDapps.org to support informed decision-making around smartphone app use for mental health, and expanded the technical MINDapps.org framework to encompass novel large language model (LLM) functionalities through benchmarking approaches. The MindBenchAI platform is designed as a partnership with the National Alliance on Mental Illness (NAMI) to provide assessment tools that systematically evaluate LLMs and LLM-based tools with objective and transparent criteria from a healthcare standpoint, assessing both profile (i.e. technical features, privacy protections, and conversational style) and performance characteristics (i.e. clinical reasoning skills).</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.13812v1</guid>
      <category>cs.HC</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Bridget Dwyer, Matthew Flathers, Akane Sano, Allison Dempsey, Andrea Cipriani, Asim H. Gazi, Carla Gorban, Carolyn I. Rodriguez, Charles Stromeyer IV, Darlene King, Eden Rozenblit, Gillian Strudwick, Jake Linardon, Jiaee Cheong, Joseph Firth, Julian Herpertz, Julian Schwarz, Margaret Emerson, Martin P. Paulus, Michelle Patriquin, Yining Hua, Soumya Choudhary, Steven Siddals, Laura Ospina Pinillos, Jason Bantjes, Steven Scheuller, Xuhai Xu, Ken Duckworth, Daniel H. Gillison, Michael Wood, John Torous</dc:creator>
    </item>
    <item>
      <title>Puzzlegram: a Serious Game Designed for the Elderly in Group Settings</title>
      <link>https://arxiv.org/abs/2510.13813</link>
      <description>arXiv:2510.13813v1 Announce Type: new 
Abstract: An original serious game prototype named 'Puzzlegram' is created for the elderly demographic in group settings as the target players. Puzzlegram is precisely designed to accentuate memory, auditory interaction as well as haptic response to visual signals with the use of music. Music is introduced as a key component for establishing the game design that provides a source of meaningful contextualization (familiar music from the past) for setting the game mechanics, which facilitated the construction of the serious game design process. The discussion topics raised include the need to design serious games for fostering meaningful interactions, as well as developing a thorough framework for constructing purposeful design for serious games. A potential integral of artificial intelligence to Puzzlegram may involve assigning a novel dimension to its existing problem solving task by adapting to varying states of cognitive function for monitoring purposes based on an individual's interaction with the game.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.13813v1</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/978-3-031-74138-8_36</arxiv:DOI>
      <arxiv:journal_reference>Choi, S. (2025). Puzzlegram: A Serious Game Designed for the Elderly in Group Settings. In: Plass, J.L., Ochoa, X. (eds) Serious Games. JCSG 2024. Lecture Notes in Computer Science, vol 15259. Springer, Cham</arxiv:journal_reference>
      <dc:creator>Sunny Choi</dc:creator>
    </item>
    <item>
      <title>Reversing the Lens: Using Explainable AI to Understand Human Expertise</title>
      <link>https://arxiv.org/abs/2510.13814</link>
      <description>arXiv:2510.13814v1 Announce Type: new 
Abstract: Both humans and machine learning models learn from experience, particularly in safety- and reliability-critical domains. While psychology seeks to understand human cognition, the field of Explainable AI (XAI) develops methods to interpret machine learning models. This study bridges these domains by applying computational tools from XAI to analyze human learning. We modeled human behavior during a complex real-world task -- tuning a particle accelerator -- by constructing graphs of operator subtasks. Applying techniques such as community detection and hierarchical clustering to archival operator data, we reveal how operators decompose the problem into simpler components and how these problem-solving structures evolve with expertise. Our findings illuminate how humans develop efficient strategies in the absence of globally optimal solutions, and demonstrate the utility of XAI-based methods for quantitatively studying human cognition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.13814v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Roussel Rahman, Aashwin Ananda Mishra, Wan-Lin Hu</dc:creator>
    </item>
    <item>
      <title>Understanding Data Usage when Making High-Stakes Frontline Decisions in Homelessness Services</title>
      <link>https://arxiv.org/abs/2510.14141</link>
      <description>arXiv:2510.14141v1 Announce Type: new 
Abstract: Frontline staff of emergency shelters face challenges such as vicarious trauma, compassion fatigue, and burnout. The technology they use is often not designed for their unique needs, and can feel burdensome on top of their already cognitively and emotionally taxing work. While existing literature focuses on data-driven technologies that automate or streamline frontline decision-making about vulnerable individuals, we discuss scenarios in which staff may resist such automation. We then suggest how data-driven technologies can better align with their human-centred decision-making processes. This paper presents findings from a qualitative fieldwork study conducted from 2022 to 2024 at a large emergency shelter in Canada. The goal of this fieldwork was to co-design, develop, and deploy an interactive data-navigation interface that supports frontline staff when making collaborative, high-stakes decisions about individuals experiencing homelessness. By reflecting on this fieldwork, we contribute insight into the role that administrative shelter data play during decision-making, and unpack staff members' apparent reluctance to outsource decisions about vulnerable individuals to data systems. Our findings suggest a data-outsourcing continuum, which we discuss in terms of how designers may create technologies to support compassionate, data-driven decision-making in nonprofit domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14141v1</guid>
      <category>cs.HC</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Teale W. Masrani, Geoffrey Messier, Amy Voida, Gina Dimitropoulos, Helen Ai He</dc:creator>
    </item>
    <item>
      <title>VisAider: AI-Assisted Context-Aware Visualization Support for Data Presentations</title>
      <link>https://arxiv.org/abs/2510.14247</link>
      <description>arXiv:2510.14247v1 Announce Type: new 
Abstract: Effective real-time data presentation is essential in small-group interactive contexts, where discussions evolve dynamically and presenters must adapt visualizations to shifting audience interests. However, most existing interactive visualization systems rely on fixed mappings between user actions and visualization commands, limiting their ability to support richer operations such as changing visualization types, adjusting data transformations, or incorporating additional datasets on the fly during live presentations. This work-in-progress paper presents VisAider, an AI-assisted interactive data presentation prototype that continuously analyzes the live presentation context, including the available dataset, active visualization, ongoing conversation, and audience profile, to generate ranked suggestions for relevant visualization aids. Grounded in a formative study with experienced data analysts, we identified key challenges in adapting visual content in real time and distilled design considerations to guide system development. A prototype implementation demonstrates the feasibility of this approach in simulated scenarios, and preliminary testing highlights challenges in inferring appropriate data transformations, resolving ambiguous visualization tasks, and achieving low-latency responsiveness. Ongoing work focuses on addressing these limitations, integrating the system into presentation environments, and preparing a summative user study to evaluate usability and communicative impact.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14247v1</guid>
      <category>cs.HC</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kentaro Takahira, Yuki Ueno</dc:creator>
    </item>
    <item>
      <title>TapNav: Adaptive Spatiotactile Screen Readers for Tactually Guided Touchscreen Interactions for Blind and Low Vision People</title>
      <link>https://arxiv.org/abs/2510.14267</link>
      <description>arXiv:2510.14267v1 Announce Type: new 
Abstract: Screen readers are audio-based software that Blind and Low Vision (BLV) people use to interact with computing devices, such as tablets and smartphones. Although this technology has significantly improved the accessibility of touchscreen devices, the sequential nature of audio limits the bandwidth of information users can receive and process. We introduce TapNav, an adaptive spatiotactile screen reader prototype developed to interact with touchscreen interfaces spatially. TapNav's screen reader provides adaptive auditory feedback that, in combination with a tactile overlay, conveys spatial information and location of interface elements on-screen. We evaluated TapNav with 12 BLV users who interacted with TapNav to explore a data visualization and interact with a bank transactions application. Our qualitative findings show that touch points and spatially constrained navigation helped users anticipate outcomes for faster exploration, and offload cognitive load to touch. We provide design guidelines for creating tactile overlays for adaptive spatiotactile screen readers and discuss their generalizability beyond our exploratory data analysis and everyday application navigation scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14267v1</guid>
      <category>cs.HC</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3770654</arxiv:DOI>
      <dc:creator>Ricardo Gonzalez, Fannie Liu, Blair MacIntyre, David Saffo</dc:creator>
    </item>
    <item>
      <title>GenLARP: Enabling Immersive Live Action Role-Play through LLM-Generated Worlds and Characters</title>
      <link>https://arxiv.org/abs/2510.14277</link>
      <description>arXiv:2510.14277v1 Announce Type: new 
Abstract: We introduce GenLARP, a virtual reality (VR) system that transforms personalized stories into immersive live action role-playing (LARP) experiences. GenLARP enables users to act as both creators and players, allowing them to design characters based on their descriptions and live in the story world. Generative AI and agents powered by Large Language Models (LLMs) enrich these experiences.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14277v1</guid>
      <category>cs.HC</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yichen Yu, Yifan Jiang, Mandy Lui, Qiao Jin</dc:creator>
    </item>
    <item>
      <title>ReUseIt: Synthesizing Reusable AI Agent Workflows for Web Automation</title>
      <link>https://arxiv.org/abs/2510.14308</link>
      <description>arXiv:2510.14308v1 Announce Type: new 
Abstract: AI-powered web agents have the potential to automate repetitive tasks, such as form filling, information retrieval, and scheduling, but they struggle to reliably execute these tasks without human intervention, requiring users to provide detailed guidance during every run. We address this limitation by automatically synthesizing reusable workflows from an agent's successful and failed attempts. These workflows incorporate execution guards that help agents detect and fix errors while keeping users informed of progress and issues. Our approach enables agents to successfully complete repetitive tasks of the same type with minimal intervention, increasing the success rates from 24.2% to 70.1% across fifteen tasks. To evaluate this approach, we invited nine users and found that our agent helped them complete web tasks with a higher success rate and less guidance compared to two baseline methods, as well as allowed users to easily monitor agent behavior and understand failures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14308v1</guid>
      <category>cs.HC</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yimeng Liu, Misha Sra, Jeevana Priya Inala, Chenglong Wang</dc:creator>
    </item>
    <item>
      <title>State Your Intention to Steer Your Attention: An AI Assistant for Intentional Digital Living</title>
      <link>https://arxiv.org/abs/2510.14513</link>
      <description>arXiv:2510.14513v1 Announce Type: new 
Abstract: When working on digital devices, people often face distractions that can lead to a decline in productivity and efficiency, as well as negative psychological and emotional impacts. To address this challenge, we introduce a novel Artificial Intelligence (AI) assistant that elicits a user's intention, assesses whether ongoing activities are in line with that intention, and provides gentle nudges when deviations occur. The system leverages a large language model to analyze screenshots, application titles, and URLs, issuing notifications when behavior diverges from the stated goal. Its detection accuracy is refined through initial clarification dialogues and continuous user feedback. In a three-week, within-subjects field deployment with 22 participants, we compared our assistant to both a rule-based intent reminder system and a passive baseline that only logged activity. Results indicate that our AI assistant effectively supports users in maintaining focus and aligning their digital behavior with their intentions. Our source code is publicly available at this url https://intentassistant.github.io</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14513v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Juheon Choi, Juyoung Lee, Jian Kim, Chanyoung Kim, Taewon Min, W. Bradley Knox, Min Kyung Lee, Kimin Lee</dc:creator>
    </item>
    <item>
      <title>Just-In-Time Objectives: A General Approach for Specialized AI Interactions</title>
      <link>https://arxiv.org/abs/2510.14591</link>
      <description>arXiv:2510.14591v1 Announce Type: new 
Abstract: Large language models promise a broad set of functions, but when not given a specific objective, they default to milquetoast results such as drafting emails littered with cliches. We demonstrate that inferring the user's in-the-moment objective, then rapidly optimizing for that singular objective, enables LLMs to produce tools, interfaces, and responses that are more responsive and desired. We contribute an architecture for automatically inducing just-in-time objectives by passively observing user behavior, then steering downstream AI systems through generation and evaluation against this objective. Inducing just-in-time objectives (e.g., "Clarify the abstract's research contribution") enables automatic generation of tools, e.g., those that critique a draft based on relevant HCI methodologies, anticipate related researchers' reactions, or surface ambiguous terminology. In a series of experiments (N=14, N=205) on participants' own tasks, JIT objectives enable LLM outputs that achieve 66-86% win rates over typical LLMs, and in-person use sessions (N=17) confirm that JIT objectives produce specialized tools unique to each participant.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14591v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michelle S. Lam, Omar Shaikh, Hallie Xu, Alice Guo, Diyi Yang, Jeffrey Heer, James A. Landay, Michael S. Bernstein</dc:creator>
    </item>
    <item>
      <title>Two Explorative Studies on Tangible Augmented Reality for Neurodevelopmental Disorders</title>
      <link>https://arxiv.org/abs/2510.14598</link>
      <description>arXiv:2510.14598v1 Announce Type: new 
Abstract: Tangible Augmented Reality (TAR) is an interaction paradigm that integrates physical and digital worlds to create immersive, interactive experiences. This paper explores two TAR applications, Holomarket and Along the Oceanic Flow (ATOF), and presents insights from two exploratory studies evaluating their usability and likeability among individuals with neurodevelopmental disorders (NDD). Holomarket is designed to simulate a supermarket shopping experience, helping users develop essential life skills such as item selection, basic arithmetic, and money handling. Participants interacted with augmented food items and a smart cash register, navigating a virtual supermarket environment. While participants enjoyed the realistic setting and tangible interactions, some usability challenges, such as difficulty manipulating virtual objects and discomfort with prolonged headset use, were noted. ATOF transforms the user environment into an oceanic world, where participants use a dolphin-shaped smart object to complete tasks like collecting items and solving puzzles. This application aims to improve motor coordination and cognitive skills. Participants appreciated the immersive experience, the customizable tasks, and the tangible dolphin interface. However, some faced difficulties interacting with specific virtual elements. Overall, both applications demonstrated potential as therapeutic tools for NDD, offering engaging and immersive experiences. Despite some usability challenges and hardware limitations, the positive feedback suggests that TAR could play a crucial role in future therapeutic interventions. Further research is needed to refine these applications and enhance user interaction and comfort.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14598v1</guid>
      <category>cs.HC</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Francesco Vona, Giulia Valcamonica, Franca Garzotto</dc:creator>
    </item>
    <item>
      <title>Sales Skills Training in Virtual Reality: An evaluation utilizing CAVE and Virtual Avatars</title>
      <link>https://arxiv.org/abs/2510.14603</link>
      <description>arXiv:2510.14603v1 Announce Type: new 
Abstract: This study investigates the potential of virtual reality (VR) for enhancing sales skills training using a Cave Automatic Virtual Environment (CAVE). VR technology enables users to practice interpersonal and negotiation skills in controlled, immersive environments that mimic real-world scenarios. In this study, participants engaged in sales simulations set in a virtual dealership, interacting with avatars in different work settings and with various communication styles. The research employed a within-subjects experimental design involving 20 university students. Each participant experienced four distinct sales scenarios randomized for environmental and customer conditions. Training effectiveness was assessed using validated metrics alongside custom experience questions. Findings revealed consistent user experience and presence across all scenarios, with no significant differences detected based on communication styles or environmental conditions. The study highlights the advantages of semi-immersive VR systems for collaborative learning, peer feedback, and realistic training environments. However, further research is recommended to refine VR designs, improve engagement, and maximize skills transfer to real-world applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14603v1</guid>
      <category>cs.HC</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Francesco Vona, Michael Stern, Navid Ashrafi, Julia Schorlemmer, Jessica Stemann, Jan-Niklas Voigt-Antons</dc:creator>
    </item>
    <item>
      <title>Exploring the Effects of Different Asymmetric Game Designs on User Experience in Collaborative Virtual Reality</title>
      <link>https://arxiv.org/abs/2510.14607</link>
      <description>arXiv:2510.14607v1 Announce Type: new 
Abstract: The risk of isolation in virtual reality (VR) stems from the immersive nature of the technology. VR can transport users to entirely virtual environments, often disconnecting them from the physical world and real-life interactions. Asymmetric multiplayer options have been explored to address this issue and encourage social interaction by requiring players to communicate and collaborate to achieve common objectives. Nevertheless, research on implementing these designs and their effects is limited, mainly due to the novelty of multiplayer VR gaming. This article investigates how different game design approaches affect the player experience during an asymmetric multiplayer VR game. Four versions of a VR experience were created and tested in a study involving 74 participants. Each version differs in terms of the sharing of virtual environments (shared vs separated) and the players' dependency on the experience (mutual vs unidirectional). The results showed that variations in game design influenced aspects of the player experience, such as system usability, pragmatic UX quality, immersion control, and intrinsic motivation. Notably, the player roles and the co-presence in the virtual environment did not simultaneously impact these aspects, suggesting that the degree to which players depend on each other changes the player experience.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14607v1</guid>
      <category>cs.HC</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Francesco Vona, Evelyn Romanjuk, Sina Hinzmann, Julia Schorlemmer, Navid Ashrafi, Jan-Niklas Voigt-Antons</dc:creator>
    </item>
    <item>
      <title>An Active Inference Model of Mouse Point-and-Click Behaviour</title>
      <link>https://arxiv.org/abs/2510.14611</link>
      <description>arXiv:2510.14611v1 Announce Type: new 
Abstract: We explore the use of Active Inference (AIF) as a computational user model for spatial pointing, a key problem in Human-Computer Interaction (HCI). We present an AIF agent with continuous state, action, and observation spaces, performing one-dimensional mouse pointing and clicking. We use a simple underlying dynamic system to model the mouse cursor dynamics with realistic perceptual delay. In contrast to previous optimal feedback control-based models, the agent's actions are selected by minimizing Expected Free Energy, solely based on preference distributions over percepts, such as observing clicking a button correctly. Our results show that the agent creates plausible pointing movements and clicks when the cursor is over the target, with similar end-point variance to human users. In contrast to other models of pointing, we incorporate fully probabilistic, predictive delay compensation into the agent. The agent shows distinct behaviour for differing target difficulties without the need to retune system parameters, as done in other approaches. We discuss the simulation results and emphasize the challenges in identifying the correct configuration of an AIF agent interacting with continuous systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14611v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Markus Klar, Sebastian Stein, Fraser Paterson, John H. Williamson, Roderick Murray-Smith</dc:creator>
    </item>
    <item>
      <title>If You Hold Me Without Hurting Me: Pathways to Designing Game Audio for Healthy Escapism and Player Well-being</title>
      <link>https://arxiv.org/abs/2510.14691</link>
      <description>arXiv:2510.14691v1 Announce Type: new 
Abstract: Escapism in games can support recovery or lead to harmful avoidance. Self-regulation, understood as combining autonomy with positive outcomes, is key to this distinction. We argue that audio, often overlooked, plays a central role in regulation. It can modulate arousal, mark transitions, and provide closure, yet its contribution to well-being remains underexplored. This paper identifies methodological and accessibility gaps that limit recognition of audio's potential and outlines ways to address them. We aim to encourage researchers and developers to integrate audio more deliberately into the design and study of healthier escapist play.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14691v1</guid>
      <category>cs.HC</category>
      <category>cs.MM</category>
      <category>cs.SD</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Caio Nunes, Bosco Borges, Georgia Cruz, Ticianne Darin</dc:creator>
    </item>
    <item>
      <title>Dude, Where's My (Autonomous) Car? Defining an Accessible Description Logic for Blind and Low Vision Travelers Using Autonomous Vehicles</title>
      <link>https://arxiv.org/abs/2510.14911</link>
      <description>arXiv:2510.14911v1 Announce Type: new 
Abstract: Purpose: Autonomous vehicles (AVs) are becoming a promising transportation solution for blind and low-vision (BLV) travelers, offering the potential for greater independent mobility. This paper explores the information needs of BLV users across multiple steps of the transportation journey, including finding and navigating to, entering, and exiting vehicles independently.
  Methods: A survey with 202 BLV respondents and interviews with 12 BLV individuals revealed the perspectives of BLV end-users and informed the sequencing of natural language information required for successful travel. Whereas the survey identified key information needs across the three trip segments, the interviews helped prioritize how that information should be presented in a sequence of accessible descriptions to travelers.
  Results: Taken together, the survey and interviews reveal that BLV users prioritize knowing the vehicle's make and model and how to find the correct vehicle during the navigation phase. They also emphasize the importance of confirmations about the vehicle's destination and onboard safety features upon entering the vehicle. While exiting, BLV users value information about hazards and obstacles, as well as knowing which side of the vehicle to exit. Furthermore, results highlight that BLV travelers desire using their own smartphone devices when receiving information from AVs and prefer audio-based interaction.
  Conclusion: The findings from this research contribute a structured framework for delivering trip-related information to BLV users, useful for designers incorporating natural language descriptions tailored to each travel segment. This work offers important contributions for sequencing transportation-related descriptions throughout the AV journey, ultimately enhancing the mobility and independence of BLV individuals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14911v1</guid>
      <category>cs.HC</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Paul D. S. Fink, Justin R. Brown, Rachel Coombs, Emily A. Hamby, Kyle J. James, Aisha Harris, Jacob Bond, Morgan E. Andrulis, Nicholas A. Giudice</dc:creator>
    </item>
    <item>
      <title>Design of Paper Robot Building Kits</title>
      <link>https://arxiv.org/abs/2510.14914</link>
      <description>arXiv:2510.14914v1 Announce Type: new 
Abstract: Building robots is an engaging activity that provides opportunities for hands-on learning. However, traditional robot-building kits are usually costly with limited functionality due to material and technology constraints. To improve the accessibility and flexibility of such kits, we take paper as the building material and extensively explore the versatility of paper-based interactions. Based on an analysis of current robot-building kits and paper-based interaction research, we propose a design space for devising paper robots. We also analyzed our building kit designs using this design space, where these kits demonstrate the potential of paper as a cost-effective material for robot building. As a starting point, our design space and building kit examples provide a guideline that inspires and informs future research and development of novel paper robot-building kits.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14914v1</guid>
      <category>cs.HC</category>
      <category>cs.RO</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ruhan Yang, Ellen Yi-Luen Do</dc:creator>
    </item>
    <item>
      <title>GQVis: A Dataset of Genomics Data Questions and Visualizations for Generative AI</title>
      <link>https://arxiv.org/abs/2510.13816</link>
      <description>arXiv:2510.13816v1 Announce Type: cross 
Abstract: Data visualization is a fundamental tool in genomics research, enabling the exploration, interpretation, and communication of complex genomic features. While machine learning models show promise for transforming data into insightful visualizations, current models lack the training foundation for domain-specific tasks. In an effort to provide a foundational resource for genomics-focused model training, we present a framework for generating a dataset that pairs abstract, low-level questions about genomics data with corresponding visualizations. Building on prior work with statistical plots, our approach adapts to the complexity of genomics data and the specialized representations used to depict them. We further incorporate multiple linked queries and visualizations, along with justifications for design choices, figure captions, and image alt-texts for each item in the dataset. We use genomics data retrieved from three distinct genomics data repositories (4DN, ENCODE, Chromoscope) to produce GQVis: a dataset consisting of 1.14 million single-query data points, 628k query pairs, and 589k query chains. The GQVis dataset and generation code are available at https://huggingface.co/datasets/HIDIVE/GQVis and https://github.com/hms-dbmi/GQVis-Generation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.13816v1</guid>
      <category>q-bio.GN</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Skylar Sargent Walters, Arthea Valderrama, Thomas C. Smits, David Kou\v{r}il, Huyen N. Nguyen, Sehi L'Yi, Devin Lange, Nils Gehlenborg</dc:creator>
    </item>
    <item>
      <title>ConsistencyAI: A Benchmark to Assess LLMs' Factual Consistency When Responding to Different Demographic Groups</title>
      <link>https://arxiv.org/abs/2510.13852</link>
      <description>arXiv:2510.13852v1 Announce Type: cross 
Abstract: Is an LLM telling you different facts than it's telling me? This paper introduces ConsistencyAI, an independent benchmark for measuring the factual consistency of large language models (LLMs) for different personas. ConsistencyAI tests whether, when users of different demographics ask identical questions, the model responds with factually inconsistent answers. Designed without involvement from LLM providers, this benchmark offers impartial evaluation and accountability. In our experiment, we queried 19 LLMs with prompts that requested 5 facts for each of 15 topics. We repeated this query 100 times for each LLM, each time adding prompt context from a different persona selected from a subset of personas modeling the general population. We processed the responses into sentence embeddings, computed cross-persona cosine similarity, and computed the weighted average of cross-persona cosine similarity to calculate factual consistency scores. In 100-persona experiments, scores ranged from 0.9065 to 0.7896, and the mean was 0.8656, which we adopt as a benchmark threshold. xAI's Grok-3 is most consistent, while several lightweight models rank lowest. Consistency varies by topic: the job market is least consistent, G7 world leaders most consistent, and issues like vaccines or the Israeli-Palestinian conflict diverge by provider. These results show that both the provider and the topic shape the factual consistency. We release our code and interactive demo to support reproducible evaluation and encourage persona-invariant prompting strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.13852v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Peter Banyas, Shristi Sharma, Alistair Simmons, Atharva Vispute</dc:creator>
    </item>
    <item>
      <title>BenchPress: A Human-in-the-Loop Annotation System for Rapid Text-to-SQL Benchmark Curation</title>
      <link>https://arxiv.org/abs/2510.13853</link>
      <description>arXiv:2510.13853v1 Announce Type: cross 
Abstract: Large language models (LLMs) have been successfully applied to many tasks, including text-to-SQL generation. However, much of this work has focused on publicly available datasets, such as Fiben, Spider, and Bird. Our earlier work showed that LLMs are much less effective in querying large private enterprise data warehouses and released Beaver, the first private enterprise text-to-SQL benchmark. To create Beaver, we leveraged SQL logs, which are often readily available. However, manually annotating these logs to identify which natural language questions they answer is a daunting task. Asking database administrators, who are highly trained experts, to take on additional work to construct and validate corresponding natural language utterances is not only challenging but also quite costly. To address this challenge, we introduce BenchPress, a human-in-the-loop system designed to accelerate the creation of domain-specific text-to-SQL benchmarks. Given a SQL query, BenchPress uses retrieval-augmented generation (RAG) and LLMs to propose multiple natural language descriptions. Human experts then select, rank, or edit these drafts to ensure accuracy and domain alignment. We evaluated BenchPress on annotated enterprise SQL logs, demonstrating that LLM-assisted annotation drastically reduces the time and effort required to create high-quality benchmarks. Our results show that combining human verification with LLM-generated suggestions enhances annotation accuracy, benchmark reliability, and model evaluation robustness. By streamlining the creation of custom benchmarks, BenchPress offers researchers and practitioners a mechanism for assessing text-to-SQL models on a given domain-specific workload. BenchPress is freely available via our public GitHub repository at https://github.com/fabian-wenz/enterprise-txt2sql and is also accessible on our website at http://dsg-mcgraw.csail.mit.edu:5000.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.13853v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.DB</category>
      <category>cs.HC</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fabian Wenz, Omar Bouattour, Devin Yang, Justin Choi, Cecil Gregg, Nesime Tatbul, \c{C}a\u{g}atay Demiralp</dc:creator>
    </item>
    <item>
      <title>Ensembling Large Language Models to Characterize Affective Dynamics in Student-AI Tutor Dialogues</title>
      <link>https://arxiv.org/abs/2510.13862</link>
      <description>arXiv:2510.13862v1 Announce Type: cross 
Abstract: While recent studies have examined the leaning impact of large language model (LLM) in educational contexts, the affective dynamics of LLM-mediated tutoring remain insufficiently understood. This work introduces the first ensemble-LLM framework for large-scale affect sensing in tutoring dialogues, advancing the conversation on responsible pathways for integrating generative AI into education by attending to learners' evolving affective states. To achieve this, we analyzed two semesters' worth of 16,986 conversational turns exchanged between PyTutor, an LLM-powered AI tutor, and 261 undergraduate learners across three U.S. institutions. To investigate learners' emotional experiences, we generate zero-shot affect annotations from three frontier LLMs (Gemini, GPT-4o, Claude), including scalar ratings of valence, arousal, and learning-helpfulness, along with free-text emotion labels. These estimates are fused through rank-weighted intra-model pooling and plurality consensus across models to produce robust emotion profiles. Our analysis shows that during interaction with the AI tutor, students typically report mildly positive affect and moderate arousal. Yet learning is not uniformly smooth: confusion and curiosity are frequent companions to problem solving, and frustration, while less common, still surfaces in ways that can derail progress. Emotional states are short-lived--positive moments last slightly longer than neutral or negative ones, but they are fragile and easily disrupted. Encouragingly, negative emotions often resolve quickly, sometimes rebounding directly into positive states. Neutral moments frequently act as turning points, more often steering students upward than downward, suggesting opportunities for tutors to intervene at precisely these junctures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.13862v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Proceedings of the 11th International Conference on Affective Computing and Intelligent Interaction (ACII 2025), Late-Breaking Results Track, IEEE, 2025</arxiv:journal_reference>
      <dc:creator>Chenyu Zhang, Sharifa Alghowinem, Cynthia Breazeal</dc:creator>
    </item>
    <item>
      <title>From Binary to Bilingual: How the National Weather Service is Using Artificial Intelligence to Develop a Comprehensive Translation Program</title>
      <link>https://arxiv.org/abs/2510.14369</link>
      <description>arXiv:2510.14369v1 Announce Type: cross 
Abstract: To advance a Weather-Ready Nation, the National Weather Service (NWS) is developing a systematic translation program to better serve the 68.8 million people in the U.S. who do not speak English at home. This article outlines the foundation of an automated translation tool for NWS products, powered by artificial intelligence. The NWS has partnered with LILT, whose patented training process enables large language models (LLMs) to adapt neural machine translation (NMT) tools for weather terminology and messaging. Designed for scalability across Weather Forecast Offices (WFOs) and National Centers, the system is currently being developed in Spanish, Simplified Chinese, Vietnamese, and other widely spoken non-English languages. Rooted in best practices for multilingual risk communication, the system provides accurate, timely, and culturally relevant translations, significantly reducing manual translation time and easing operational workloads across the NWS. To guide the distribution of these products, GIS mapping was used to identify language needs across different NWS regions, helping prioritize resources for the communities that need them most. We also integrated ethical AI practices throughout the program's design, ensuring that transparency, fairness, and human oversight guide how automated translations are created, evaluated, and shared with the public. This work has culminated into a website featuring experimental multilingual NWS products, including translated warnings, 7-day forecasts, and educational campaigns, bringing the country one step closer to a national warning system that reaches all Americans.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14369v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joseph E. Trujillo-Falcon, Monica L. Bozeman, Liam E. Llewellyn, Samuel T. Halvorson, Meryl Mizell, Stuti Deshpande, Bob Manning, Todd Fagin</dc:creator>
    </item>
    <item>
      <title>Beyond Hallucinations: The Illusion of Understanding in Large Language Models</title>
      <link>https://arxiv.org/abs/2510.14665</link>
      <description>arXiv:2510.14665v1 Announce Type: cross 
Abstract: Large language models (LLMs) are becoming deeply embedded in human communication and decision-making, yet they inherit the ambiguity, bias, and lack of direct access to truth inherent in language itself. While their outputs are fluent, emotionally resonant, and coherent, they are generated through statistical prediction rather than grounded reasoning. This creates the risk of hallucination, responses that sound convincing but lack factual validity. Building on Geoffrey Hinton's observation that AI mirrors human intuition rather than reasoning, this paper argues that LLMs operationalize System 1 cognition at scale: fast, associative, and persuasive, but without reflection or falsification. To address this, we introduce the Rose-Frame, a three-dimensional framework for diagnosing cognitive and epistemic drift in human-AI interaction. The three axes are: (i) Map vs. Territory, which distinguishes representations of reality (epistemology) from reality itself (ontology); (ii) Intuition vs. Reason, drawing on dual-process theory to separate fast, emotional judgments from slow, reflective thinking; and (iii) Conflict vs. Confirmation, which examines whether ideas are critically tested through disagreement or simply reinforced through mutual validation. Each dimension captures a distinct failure mode, and their combination amplifies misalignment. Rose-Frame does not attempt to fix LLMs with more data or rules. Instead, it offers a reflective tool that makes both the model's limitations and the user's assumptions visible, enabling more transparent and critically aware AI deployment. It reframes alignment as cognitive governance: intuition, whether human or artificial, must remain governed by human reason. Only by embedding reflective, falsifiable oversight can we align machine fluency with human understanding.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14665v1</guid>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Rikard Rosenbacke, Carl Rosenbacke, Victor Rosenbacke, Martin McKee</dc:creator>
    </item>
    <item>
      <title>Detecting Early and Implicit Suicidal Ideation via Longitudinal and Information Environment Signals on Social Media</title>
      <link>https://arxiv.org/abs/2510.14889</link>
      <description>arXiv:2510.14889v1 Announce Type: cross 
Abstract: On social media, many individuals experiencing suicidal ideation (SI) do not disclose their distress explicitly. Instead, signs may surface indirectly through everyday posts or peer interactions. Detecting such implicit signals early is critical but remains challenging. We frame early and implicit SI as a forward-looking prediction task and develop a computational framework that models a user's information environment, consisting of both their longitudinal posting histories as well as the discourse of their socially proximal peers. We adopted a composite network centrality measure to identify top neighbors of a user, and temporally aligned the user's and neighbors' interactions -- integrating the multi-layered signals in a fine-tuned DeBERTa-v3 model. In a Reddit study of 1,000 (500 Case and 500 Control) users, our approach improves early and implicit SI detection by 15% over individual-only baselines. These findings highlight that peer interactions offer valuable predictive signals and carry broader implications for designing early detection systems that capture indirect as well as masked expressions of risk in online environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14889v1</guid>
      <category>cs.SI</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Soorya Ram Shimgekar, Ruining Zhao, Agam Goyal, Violeta J. Rodriguez, Paul A. Bloom, Hari Sundaram, Koustuv Saha</dc:creator>
    </item>
    <item>
      <title>Knowledge Prompting: How Knowledge Engineers Use Large Language Models</title>
      <link>https://arxiv.org/abs/2408.08878</link>
      <description>arXiv:2408.08878v2 Announce Type: replace 
Abstract: Despite many advances in knowledge engineering (KE), challenges remain in areas such as engineering knowledge graphs (KGs) at scale, keeping up with evolving domain knowledge, multilingualism, and multimodality. Recently, KE has used LLMs to support semi-automatic tasks, but the most effective use of LLMs to support knowledge engineers across the KE activites is still in its infancy. To explore the vision of LLM copilots for KE and change existing KE practices, we conducted a multimethod study during a KE hackathon. We investigated participants' views on the use of LLMs, the challenges they face, the skills they may need to integrate LLMs into their practices, and how they use LLMs responsibly. We found participants felt LLMs could contribute to improving efficiency when engineering KGs, but presented increased challenges around the already complex issues of evaluating the KE tasks. We discovered prompting to be a useful but undervalued skill for knowledge engineers working with LLMs, and note that natural language processing skills may become more relevant across more roles in KG construction. Integrating LLMs into KE tasks needs to be mindful of potential risks and harms related to responsible AI. Given the limited ethical training, most knowledge engineers receive solutions such as our suggested `KG cards' based on data cards could be a useful guide for KG construction. Our findings can support designers of KE AI copilots, KE researchers, and practitioners using advanced AI to develop trustworthy applications, propose new methodologies for KE and operate new technologies responsibly.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.08878v2</guid>
      <category>cs.HC</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Elisavet Koutsiana, Johanna Walker, Michelle Nwachukwu, Albert Mero\~no-Pe\~nuela, Elena Simperl</dc:creator>
    </item>
    <item>
      <title>An AI-Driven Multimodal Smart Home Platform for Continuous Monitoring and Assistance in Post-Stroke Motor Impairment</title>
      <link>https://arxiv.org/abs/2411.19000</link>
      <description>arXiv:2411.19000v4 Announce Type: replace 
Abstract: At-home rehabilitation for post-stroke patients presents significant challenges, as continuous, personalized care is often limited outside clinical settings. Moreover, the lack of integrated solutions capable of simultaneously monitoring motor recovery and providing intelligent assistance in home environments hampers rehabilitation outcomes. Here, we present a multimodal smart home platform designed for continuous, at-home rehabilitation of post-stroke patients, integrating wearable sensing, ambient monitoring, and adaptive automation. A plantar pressure insole equipped with a machine learning pipeline classifies users into motor recovery stages with up to 94\% accuracy, enabling quantitative tracking of walking patterns during daily activities. An optional head-mounted eye-tracking module, together with ambient sensors such as cameras and microphones, supports seamless hands-free control of household devices with a 100\% success rate and sub-second response time. These data streams are fused locally via a hierarchical Internet of Things (IoT) architecture, ensuring low latency and data privacy. An embedded large language model (LLM) agent, Auto-Care, continuously interprets multimodal data to provide real-time interventions -- issuing personalized reminders, adjusting environmental conditions, and notifying caregivers. Implemented in a post-stroke context, this integrated smart home platform increased mean user satisfaction from 3.9 $\pm$ 0.8 in conventional home environments to 8.4 $\pm$ 0.6 with the full system ($n=20$). Beyond stroke, the system offers a scalable, patient-centered framework with potential for long-term use in broader neurorehabilitation and aging-in-place applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19000v4</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chenyu Tang, Ruizhi Zhang, Shuo Gao, Zihe Zhao, Zibo Zhang, Jiaqi Wang, Cong Li, Junliang Chen, Yanning Dai, Shengbo Wang, Ruoyu Juan, Qiaoying Li, Ruimou Xie, Xuhang Chen, Xinkai Zhou, Yunjia Xia, Jianan Chen, Fanghao Lu, Xin Li, Ninglli Wang, Peter Smielewski, Yu Pan, Hubin Zhao, Luigi G. Occhipinti</dc:creator>
    </item>
    <item>
      <title>A comprehensive review of assistive technologies for children with dyslexia</title>
      <link>https://arxiv.org/abs/2412.13241</link>
      <description>arXiv:2412.13241v2 Announce Type: replace 
Abstract: Dyslexia is a neurological learning disability that primarily disrupts one's ability to read, write and spell, affecting an estimated~15-20\% of the global population. This high prevalence underscore the importance of developing effective interventions. This study presents a systematic literature review conducted between 2015 and 2024 to evaluate current trends in assistive technologies for children with dyslexia. This research shows that technological-based interventions are leading interventions, especially with the use of mobile apps and augmentative realities. More innovative technologies like virtual reality, NLP, haptic, and tangible user interfaces are emerging to provide unique solutions addressing the user's needs. While non-computing devices are generally less effective in comparison to modern digital solutions, they provide a promising alternative in settings with limited access to technology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13241v2</guid>
      <category>cs.HC</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sansrit Paudel, Subek Acharya, Piriyankan Kirupaharan, Bishal KC, Bipul Thapa</dc:creator>
    </item>
    <item>
      <title>RunPacer: A Smartwatch-Based Vibrotactile Feedback System for Symmetric Co-Running by Visually Impaired Individuals and Guides</title>
      <link>https://arxiv.org/abs/2507.04241</link>
      <description>arXiv:2507.04241v2 Announce Type: replace 
Abstract: Visually impaired individuals often require a guide runner to safely participate in outdoor running. However, maintaining synchronized pacing with verbal cues or tethers can be mentally taxing and physically restrictive. Existing solutions primarily focus on navigation or obstacle avoidance but overlook the importance of real-time interpersonal rhythm coordination during running. We introduce RunPacer, a smartwatch-based vibrotactile feedback system that delivers synchronized rhythmic pulses to both runners. In contrast to conventional guide-running systems that rely heavily on continuous verbal communication or mechanical tethering, RunPacer emphasizes interpersonal cadence alignment as its core interaction model. By pre-setting a target step frequency or dynamically adapting to the guide's natural pace, the system ensures that both runners receive identical haptic cues, enabling them to maintain coordinated motion intuitively and efficiently. This poster presents the system architecture, positions it within prior research on haptic entrainment, and outlines the vision for future field deployment, including potential multimodal feedback extensions. RunPacer contributes a lightweight, socially cooperative, and non-visual assistive framework that reimagines co-running as a shared, embodied, and accessible experience.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.04241v2</guid>
      <category>cs.HC</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3663547.3759738</arxiv:DOI>
      <dc:creator>Yichen Yu, Huan-Song Xu, Ming-Yen Lin</dc:creator>
    </item>
    <item>
      <title>The Agency Gap: How Generative AI Literacy Shapes Independent Writing after AI Support</title>
      <link>https://arxiv.org/abs/2507.04398</link>
      <description>arXiv:2507.04398v2 Announce Type: replace 
Abstract: Generative AI (GenAI) tools are rapidly transforming higher education, yet little is known about how students' GenAI literacy shapes their ability to perform independently once such support is removed. This study investigates what we term the agency gap, introduced as the extent to which GenAI literacy predicts student writing performance in contexts that require self-initiation and regulation. Seventy-nine medical and nursing students completed multimodal academic writing tasks based on visual data, supported either by a reactive or proactive GenAI chatbot, followed by a parallel task without AI support. Writing was evaluated across insightfulness, visual data integration, organisation, linguistic quality, and critical thinking. Results showed that GenAI literacy predicted independent writing performance only in the reactive condition, where students had to actively mobilise their own strategies. Mediation analyses revealed no indirect effect via in-task performance, indicating that GenAI literacy acts as a direct, task-general competence rather than a proxy for domain knowledge or other literacies. By contrast, proactive scaffolding equalised outcomes across literacy levels, reducing reliance on learners' GenAI literacy. The agency gap highlights when GenAI literacy matters most, with implications for designing equitable AI-supported learning environments that both leverage and mitigate differences in students' GenAI literacy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.04398v2</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yueqiao Jin, Kaixun Yang, Roberto Martinez-Maldonado, Dragan Ga\v{s}evi\'c, Lixiang Yan</dc:creator>
    </item>
    <item>
      <title>Unmasking Hiring Bias: Platform Data Analysis and Controlled Experiments on Bias in Online Freelance Marketplaces via RAG-LLM Generated Contents</title>
      <link>https://arxiv.org/abs/2510.13091</link>
      <description>arXiv:2510.13091v2 Announce Type: replace 
Abstract: Online freelance marketplaces, a rapidly growing part of the global labor market, are creating a fair environment where professional skills are the main factor for hiring. While these platforms can reduce bias from traditional hiring, the personal information in user profiles raises concerns about ongoing discrimination. Past studies on this topic have mostly used existing data, which makes it hard to control for other factors and clearly see the effect of things like gender or race. To solve these problems, this paper presents a new method that uses Retrieval-Augmented Generation (RAG) with a Large Language Model (LLM) to create realistic, artificial freelancer profiles for controlled experiments. This approach effectively separates individual factors, enabling a clearer statistical analysis of how different variables influence the freelancer project process. In addition to analyzing extracted data with traditional statistical methods for post-project stage analysis, our research utilizes a dataset with highly controlled variables, generated by an RAG-LLM, to conduct a simulated hiring experiment for pre-project stage analysis. The results of our experiments show that, regarding gender, while no significant preference emerged in initial hiring decisions, female freelancers are substantially more likely to receive imperfect ratings post-project stage. Regarding regional bias, a strong and consistent preference favoring US-based freelancers shows that people are more likely to be selected in the simulated experiments, perceived as more leader-like, and receive higher ratings on the live platform.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.13091v2</guid>
      <category>cs.HC</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wugeng Zheng, Guohou Shan</dc:creator>
    </item>
    <item>
      <title>Why do explanations fail? A typology and discussion on failures in XAI</title>
      <link>https://arxiv.org/abs/2405.13474</link>
      <description>arXiv:2405.13474v2 Announce Type: replace-cross 
Abstract: As Machine Learning models achieve unprecedented levels of performance, the XAI domain aims at making these models understandable by presenting end-users with intelligible explanations.
  Yet, some existing XAI approaches fail to meet expectations: several issues have been reported in the literature, generally pointing out either
  technical limitations or misinterpretations by users.
  In this paper, we argue that the resulting harms arise from a complex overlap of multiple failures in XAI, which existing ad-hoc studies fail to capture.
  This work therefore advocates for a holistic perspective, presenting a systematic investigation of limitations of current XAI methods and their impact on the interpretation of explanations. %
  By distinguishing between system-specific and user-specific failures,
  we propose a typological framework that helps revealing the nuanced complexities of explanation failures.
  Leveraging this typology, we discuss some research directions to help practitioners better understand the limitations of XAI systems and enhance the quality of ML explanations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.13474v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Clara Bove, Thibault Laugel, Marie-Jeanne Lesot, Charles Tijus, Marcin Detyniecki</dc:creator>
    </item>
    <item>
      <title>The Start Button Problem: a basis for human responsibility in artificial intelligence computation</title>
      <link>https://arxiv.org/abs/2501.12498</link>
      <description>arXiv:2501.12498v2 Announce Type: replace-cross 
Abstract: Recent advancements in artificial intelligence have reopened the question about the boundaries of AI autonomy, particularly in discussions around artificial general intelligence and its potential to act independently across varied purposes. This paper explores these boundaries through the analysis of the Alignment Research Center experiment on GPT-4 and introduces the Start Button Problem, a thought experiment that examines the origins and limits of AI autonomy. By examining the thought experiment and its counterarguments, it becomes clear that in its need for human activation and purpose definition lies the AI's inherent dependency on human-initiated actions, challenging the assumption of AI as an intelligent agent. Finally, the paper addresses the implications of this dependency on human responsibility, questioning the measure of the extension of human responsibility when using AI systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12498v2</guid>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vincenzo Calderonio</dc:creator>
    </item>
  </channel>
</rss>
