<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.med-ph updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.med-ph</link>
    <description>physics.med-ph updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.med-ph" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 28 Nov 2024 05:03:11 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 28 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Development and experimental validation of an in-house treatment planning system with greedy energy layer optimization for fast IMPT</title>
      <link>https://arxiv.org/abs/2411.18074</link>
      <description>arXiv:2411.18074v1 Announce Type: new 
Abstract: Background: Intensity-modulated proton therapy (IMPT) using pencil beam technique scans tumor in a layer by layer, then spot by spot manner. It can provide highly conformal dose to tumor targets and spare nearby organs-at-risk (OAR). Fast delivery of IMPT can improve patient comfort and reduce motion-induced uncertainties. Since energy layer switching time dominants the plan delivery time, reducing the number of energy layers is important for improving delivery efficiency. Although various energy layer optimization (ELO) methods exist, they are rarely experimentally validated or clinically implemented, since it is technically challenging to integrate these methods into commercially available treatment planning system (TPS) that is not open-source. Methods: The dose calculation accuracy of IH-TPS is verified against the measured beam data and the RayStation TPS. For treatment planning, a novel ELO method via greed selection algorithm is proposed to reduce energy layer switching time and total plan delivery time. To validate the planning accuracy of IH-TPS, the 3D gamma index is calculated between IH-TPS plans and RayStation plans for various scenarios. Patient-specific quality-assurance (QA) verifications are conducted to experimentally verify the delivered dose from the IH-TPS plans for several clinical cases. Results: Dose distributions in IH-TPS matched with those from RayStation TPS, with 3D gamma index results exceeding 95% (2mm, 2%). The ELO method significantly reduced the delivery time while maintaining plan quality. For instance, in a brain case, the number of energy layers was reduced from 78 to 40, leading to a 62% reduction in total delivery time. Patient-specific QA validation with the IBA Proteus ONE proton machine confirmed a &gt;95% pass rate for all cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.18074v1</guid>
      <category>physics.med-ph</category>
      <pubDate>Thu, 28 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Aoxiang Wang, Ya-Nan Zhu, Jufri Setianegara, Yuting Lin, Peng Xiao, Qingguo Xie, Hao Gao</dc:creator>
    </item>
    <item>
      <title>Genetic algorithm as a tool for detection setup optimisation: SiFi-CC case study</title>
      <link>https://arxiv.org/abs/2411.18239</link>
      <description>arXiv:2411.18239v1 Announce Type: new 
Abstract: Objective: Proton therapy is a precision-focused cancer treatment where accurate proton beam range monitoring is critical to ensure effective dose delivery. This can be achieved by prompt gamma detection with a Compton camera like the SiFi-CC. This study aims to show the feasibility of optimising the geometry of SiFi-CC Compton camera for verification of dose distribution via prompt gamma detection using a genetic algorithm (GA). Approach: The SiFi-CC key geometric parameters for optimisation with the GA are the source-to-scatterer and scatterer-to-absorber distances, and the module thicknesses. The optimisation process was conducted with a software framework based on the Geant4 toolkit, which included detailed and realistic modelling of gamma interactions, detector response, and further steps such as event selection and image reconstruction. The performance of each individual configuration was evaluated using a fitness function incorporating factors related to gamma detection efficiency and image resolution. Results: The GA-optimised SiFi-CC configuration demonstrated the capability to detect a 5 mm proton beam range shift with a 2 mm resolution using 5e8 protons. The best-performing geometry, with 16 fibre layers in the scatterer, 36 layers in the absorber, source-to-scatterer distance 150 mm and scatterer-to-absorber distance 120 mm, has an imaging sensitivity of 5.58(1)e-5. Significance: This study demonstrates that the SiFi-CC setup, optimised through a GA, can reliably detect clinically relevant proton beam range shifts, improving real-time range verification accuracy in proton therapy. The presented implementation of a GA is a systematic and feasible way of searching for a SiFi-CC geometry that shows the best performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.18239v1</guid>
      <category>physics.med-ph</category>
      <category>physics.ins-det</category>
      <pubDate>Thu, 28 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jonas Kasper, Aleksandra Wro\'nska, Awal Awal, Ronja Hetzel, Magdalena Ko{\l}odziej, Katarzyna Rusiecka, Achim Stahl, Ming-Liang Wong</dc:creator>
    </item>
    <item>
      <title>Overview of the Head and Neck Tumor Segmentation for Magnetic Resonance Guided Applications (HNTS-MRG) 2024 Challenge</title>
      <link>https://arxiv.org/abs/2411.18585</link>
      <description>arXiv:2411.18585v1 Announce Type: new 
Abstract: Magnetic resonance (MR)-guided radiation therapy (RT) is enhancing head and neck cancer (HNC) treatment through superior soft tissue contrast and longitudinal imaging capabilities. However, manual tumor segmentation remains a significant challenge, spurring interest in artificial intelligence (AI)-driven automation. To accelerate innovation in this field, we present the Head and Neck Tumor Segmentation for MR-Guided Applications (HNTS-MRG) 2024 Challenge, a satellite event of the 27th International Conference on Medical Image Computing and Computer Assisted Intervention. This challenge addresses the scarcity of large, publicly available AI-ready adaptive RT datasets in HNC and explores the potential of incorporating multi-timepoint data to enhance RT auto-segmentation performance. Participants tackled two HNC segmentation tasks: automatic delineation of primary gross tumor volume (GTVp) and gross metastatic regional lymph nodes (GTVn) on pre-RT (Task 1) and mid-RT (Task 2) T2-weighted scans. The challenge provided 150 HNC cases for training and 50 for testing, hosted on grand-challenge.org using a Docker submission framework. In total, 19 independent teams from across the world qualified by submitting both their algorithms and corresponding papers, resulting in 18 submissions for Task 1 and 15 submissions for Task 2. Evaluation using the mean aggregated Dice Similarity Coefficient showed top-performing AI methods achieved scores of 0.825 in Task 1 and 0.733 in Task 2. These results surpassed clinician interobserver variability benchmarks, marking significant strides in automated tumor segmentation for MR-guided radiation therapy applications in head and neck cancer.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.18585v1</guid>
      <category>physics.med-ph</category>
      <pubDate>Thu, 28 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kareem A. Wahid, Cem Dede, Dina M. El-Habashy, Serageldin Kamel, Michael K. Rooney, Yomna Khamis, Moamen R. A. Abdelaal, Sara Ahmed, Kelsey L. Corrigan, Enoch Chang, Stephanie O. Dudzinski, Travis C. Salzillo, Brigid A. McDonald, Samuel L. Mulder, Lucas McCullum, Qusai Alakayleh, Carlos Sjogreen, Renjie He, Abdallah S. R. Mohamed, Stephen Y. Lai, John P. Christodouleas, Andrew J. Schaefer, Mohamed A. Naser, Clifton D. Fuller</dc:creator>
    </item>
    <item>
      <title>Deep End-to-end Adaptive k-Space Sampling, Reconstruction, and Registration for Dynamic MRI</title>
      <link>https://arxiv.org/abs/2411.18249</link>
      <description>arXiv:2411.18249v1 Announce Type: cross 
Abstract: Dynamic MRI enables a range of clinical applications, including cardiac function assessment, organ motion tracking, and radiotherapy guidance. However, fully sampling the dynamic k-space data is often infeasible due to time constraints and physiological motion such as respiratory and cardiac motion. This necessitates undersampling, which degrades the quality of reconstructed images. Poor image quality not only hinders visualization but also impairs the estimation of deformation fields, crucial for registering dynamic (moving) images to a static reference image. This registration enables tasks such as motion correction, treatment planning, and quantitative analysis in applications like cardiac imaging and MR-guided radiotherapy. To overcome the challenges posed by undersampling and motion, we introduce an end-to-end deep learning (DL) framework that integrates adaptive dynamic k-space sampling, reconstruction, and registration. Our approach begins with a DL-based adaptive sampling strategy, optimizing dynamic k-space acquisition to capture the most relevant data for each specific case. This is followed by a DL-based reconstruction module that produces images optimized for accurate deformation field estimation from the undersampled moving data. Finally, a registration module estimates the deformation fields aligning the reconstructed dynamic images with a static reference. The proposed framework is independent of specific reconstruction and registration modules allowing for plug-and-play integration of these components. The entire framework is jointly trained using a combination of supervised and unsupervised loss functions, enabling end-to-end optimization for improved performance across all components. Through controlled experiments and ablation studies, we validate each component, demonstrating that each choice contributes to robust motion estimation from undersampled dynamic data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.18249v1</guid>
      <category>eess.IV</category>
      <category>cs.CV</category>
      <category>physics.med-ph</category>
      <pubDate>Thu, 28 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>George Yiasemis, Jan-Jakob Sonke, Jonas Teuwen</dc:creator>
    </item>
    <item>
      <title>Deep learning-based spatio-temporal fusion for high-fidelity ultra-high-speed x-ray radiography</title>
      <link>https://arxiv.org/abs/2411.18441</link>
      <description>arXiv:2411.18441v1 Announce Type: cross 
Abstract: Full-field ultra-high-speed (UHS) x-ray imaging experiments have been well established to characterize various processes and phenomena. However, the potential of UHS experiments through the joint acquisition of x-ray videos with distinct configurations has not been fully exploited. In this paper, we investigate the use of a deep learning-based spatio-temporal fusion (STF) framework to fuse two complementary sequences of x-ray images and reconstruct the target image sequence with high spatial resolution, high frame rate, and high fidelity. We applied a transfer learning strategy to train the model and compared the peak signal-to-noise ratio (PSNR), average absolute difference (AAD), and structural similarity (SSIM) of the proposed framework on two independent x-ray datasets with those obtained from a baseline deep learning model, a Bayesian fusion framework, and the bicubic interpolation method. The proposed framework outperformed the other methods with various configurations of the input frame separations and image noise levels. With 3 subsequent images from the low resolution (LR) sequence of a 4-time lower spatial resolution and another 2 images from the high resolution (HR) sequence of a 20-time lower frame rate, the proposed approach achieved an average PSNR of 37.57 dB and 35.15 dB, respectively. When coupled with the appropriate combination of high-speed cameras, the proposed approach will enhance the performance and therefore scientific value of the UHS x-ray imaging experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.18441v1</guid>
      <category>eess.IV</category>
      <category>physics.med-ph</category>
      <pubDate>Thu, 28 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Songyuan Tang, Tekin Bicer, Tao Sun, Kamel Fezzaa, Samuel J. Clark</dc:creator>
    </item>
    <item>
      <title>Segmentation-Free Outcome Prediction from Head and Neck Cancer PET/CT Images: Deep Learning-Based Feature Extraction from Multi-Angle Maximum Intensity Projections (MA-MIPs)</title>
      <link>https://arxiv.org/abs/2405.01756</link>
      <description>arXiv:2405.01756v2 Announce Type: replace 
Abstract: We introduce an innovative, simple, effective segmentation-free approach for outcome prediction in head \&amp; neck cancer (HNC) patients. By harnessing deep learning-based feature extraction techniques and multi-angle maximum intensity projections (MA-MIPs) applied to Fluorodeoxyglucose Positron Emission Tomography (FDG-PET) volumes, our proposed method eliminates the need for manual segmentations of regions-of-interest (ROIs) such as primary tumors and involved lymph nodes. Instead, a state-of-the-art object detection model is trained to perform automatic cropping of the head and neck region on the PET volumes. A pre-trained deep convolutional neural network backbone is then utilized to extract deep features from MA-MIPs obtained from 72 multi-angel axial rotations of the cropped PET volumes. These deep features extracted from multiple projection views of the PET volumes are then aggregated and fused, and employed to perform recurrence-free survival analysis on a cohort of 489 HNC patients. The proposed approach outperforms the best performing method on the target dataset for the task of recurrence-free survival analysis. By circumventing the manual delineation of the malignancies on the FDG PET-CT images, our approach eliminates the dependency on subjective interpretations and highly enhances the reproducibility of the proposed survival analysis method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.01756v2</guid>
      <category>physics.med-ph</category>
      <category>cs.AI</category>
      <pubDate>Thu, 28 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.3390/cancers16142538</arxiv:DOI>
      <arxiv:journal_reference>Cancers. 2024; 16(14):2538</arxiv:journal_reference>
      <dc:creator>Amirhosein Toosi, Isaac Shiri, Habib Zaidi, Arman Rahmim</dc:creator>
    </item>
    <item>
      <title>How to Segment in 3D Using 2D Models: Automated 3D Segmentation of Prostate Cancer Metastatic Lesions on PET Volumes Using Multi-angle Maximum Intensity Projections and Diffusion Models</title>
      <link>https://arxiv.org/abs/2407.18555</link>
      <description>arXiv:2407.18555v2 Announce Type: replace 
Abstract: Prostate specific membrane antigen (PSMA) positron emission tomography/computed tomography (PET/CT) imaging provides a tremendously exciting frontier in visualization of prostate cancer (PCa) metastatic lesions. However, accurate segmentation of metastatic lesions is challenging due to low signal-to-noise ratios and variable sizes, shapes, and locations of the lesions. This study proposes a novel approach for automated segmentation of metastatic lesions in PSMA PET/CT 3D volumetric images using 2D denoising diffusion probabilistic models (DDPMs). Instead of 2D trans-axial slices or 3D volumes, the proposed approach segments the lesions on generated multi-angle maximum intensity projections (MA-MIPs) of the PSMA PET images, then obtains the final 3D segmentation masks from 3D ordered subset expectation maximization (OSEM) reconstruction of 2D MA-MIPs segmentations. Our proposed method achieved superior performance compared to state-of-the-art 3D segmentation approaches in terms of accuracy and robustness in detecting and segmenting small metastatic PCa lesions. The proposed method has significant potential as a tool for quantitative analysis of metastatic burden in PCa patients.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18555v2</guid>
      <category>physics.med-ph</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <pubDate>Thu, 28 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/978-3-031-72744-3_21</arxiv:DOI>
      <arxiv:journal_reference>Deep Generative Models. DGM4MICCAI 2024. Lecture Notes in Computer Science, vol 15224. Springer, Cham</arxiv:journal_reference>
      <dc:creator>Amirhosein Toosi, Sara Harsini, Fran\c{c}ois B\'enard, Carlos Uribe, Arman Rahmim</dc:creator>
    </item>
  </channel>
</rss>
