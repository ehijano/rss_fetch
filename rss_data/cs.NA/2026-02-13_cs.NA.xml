<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NA</link>
    <description>cs.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 13 Feb 2026 05:01:05 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>The spectral fractional Laplacian with measure valued right hand sides: analysis and approximation</title>
      <link>https://arxiv.org/abs/2602.11423</link>
      <description>arXiv:2602.11423v1 Announce Type: new 
Abstract: We consider the spectral definition of the fractional Laplace operator and study a basic linear problem involving this operator and singular forcing. In two dimensions, we introduce an appropriate weak formulation in fractional Sobolev spaces and prove that it is well-posed. As an application of these results, we analyze a pointwise tracking optimal control problem for fractional diffusion. We also develop a finite element scheme for the linear problem using continuous, piecewise linear functions, prove a convergence result in energy norm, and derive an error bound in $L^2(\Omega)$. Finally, we propose a practical scheme based on a diagonalization technique and derive an error bound in $L^2(\Omega)$ using a regularization argument.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11423v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Enrique Otarola, Abner J. Salgado</dc:creator>
    </item>
    <item>
      <title>Adapting the Lanczos algorithm to matrices with almost continuous spectra</title>
      <link>https://arxiv.org/abs/2602.11449</link>
      <description>arXiv:2602.11449v1 Announce Type: new 
Abstract: We consider the approximation of $B^T (A+sI)^{-1} B$ where $A\in\mathbb{R}^{n\times n}$ is large, symmetric positive definite, and has a dense spectrum, and $B\in\mathbb{R}^{n\times p}$, $p\ll n$. Our target application is the computation of Multiple-Input Multiple-Output transfer functions arising from large-scale discretizations of problems with continuous spectral measures, such as linear time-invariant PDEs on unbounded domains. Traditional Krylov methods, such as Lanczos or conjugate gradients, focus on resolving individual eigenvalues of a dense discretization, while ignoring the underlying continuous spectral measure that these points approximate. We argue that it is more efficient to model the inherent branch cut of the original operator than to exhaustively resolve the artificial point spectrum induced by discretization. We place this problem in a framework, known in the physics literature as the square-root terminator. To overcome its limitations, we formulate a quadratic terminator using Kre\u{i}n--Nudelman semi-infinite strings, with parameters chosen adaptively to maximize relative energy outflow.
  This approach results in a low-rank modification to the (block) Lanczos matrix, dependent on $\sqrt{s}$, with an additional $O(n)$ cost. We demonstrate significant error reductions for large-scale self-adjoint PDE discretizations in unbounded domains, including two- and three-dimensional Maxwell's equations in diffusive regimes. The method proves particularly advantageous in computing state-space solutions for wave propagation, specifically for 2D wave and 3D Maxwell's operators. Implicitly replacing the conventional Lanczos spectral decomposition with a representation in terms of the continuous Kre\u{i}n--Nudelman spectrum, we obtain a qualitative improvement in finite-difference approximations, effectively transforming standing-wave artifacts into outgoing propagating waves.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11449v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>J\"orn Zimmerling, Vladimir Druskin</dc:creator>
    </item>
    <item>
      <title>On the Block-Diagonalization and Multiplicative Equivalence of Quaternion $Z$-Block Circulant Matrices with their Applications</title>
      <link>https://arxiv.org/abs/2602.11493</link>
      <description>arXiv:2602.11493v1 Announce Type: new 
Abstract: The motivation of this paper is twofold. First, we investigate the block-diagonalization of the $z$-block circulant matrix $\mathtt{bcirc_z}(\mathcal A)$, based on this block-diagonal structure, and develop the algorithm $\mathtt{bcirc_z}$-inv for computing the inverse of $\mathtt{bcirc_z}(\mathcal A)$. Second, we establish the equivalence between the QT-product of tensors and the product of the corresponding $z$-block circulant matrices. Based on this equivalence and in combination with the algorithm $\mathtt{bcirc_z}$-inv, large-scale tests and scalability analysis of the Tikhonov-regularized model are conducted.
  As a by-product of the analysis, some relevant and straightforward properties of the quaternion $z$-block circulant matrices are provided. As applications, a series of quaternion tensor decompositions under the QT-product and their corresponding $z$-block circulant matrices decompositions are obtained, including the QT-Polar decomposition, the QT-PLU decomposition, and the QT-LU decomposition. Meanwhile, the QT-SVD is rederived based on the relation between $\mathcal A$ and $\mathtt{bcirc_z}(\mathcal A)$. Furthermore, we develop corresponding algorithms and present several large-scale tests and scalability analysis. In addition, applications in video rotation are presented to evaluate several rotation strategies based on the QT-Polar decomposition, which shows the decomposition remains stable and inter-frame consistent while accurately maintaining color reproduction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11493v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daochang Zhang, Yue Zhao, Jingqian Li, Dijana Mosic</dc:creator>
    </item>
    <item>
      <title>On the convergence rates of generalized conditional gradient method for fully discretized Mean Field Games</title>
      <link>https://arxiv.org/abs/2602.11640</link>
      <description>arXiv:2602.11640v1 Announce Type: new 
Abstract: We study convergence rates of the generalized conditional gradient (GCG) method applied to fully discretized Mean Field Games (MFG) systems. While explicit convergence rates of the GCG method have been established at the continuous PDE level, a rigorous analysis that simultaneously accounts for time-space discretization and iteration errors has been missing. In this work, we discretize the MFG system using finite difference method and analyze the resulting fully discrete GCG scheme. Under suitable structural assumptions on the Hamiltonian and coupling terms, we establish discrete maximum principles and derive explicit error estimates that quantify both discretization errors and iteration errors within a unified framework. Our estimates show how the convergence rates depend on the mesh sizes and the iteration number, and they reveal a non-uniform behavior with respect to the iteration. Moreover, we prove that higher convergence rates can be achieved under additional regularity assumptions on the solution. Numerical experiments are presented to illustrate the theoretical results and to confirm the predicted convergence behavior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11640v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haruka Nakamura, Norikazu Saito</dc:creator>
    </item>
    <item>
      <title>Fast Evaluation of Truncated Neumann Series by Low-Product Radix Kernels</title>
      <link>https://arxiv.org/abs/2602.11843</link>
      <description>arXiv:2602.11843v1 Announce Type: new 
Abstract: Truncated Neumann series $S_k(A)=I+A+\cdots+A^{k-1}$ are used in
  approximate matrix inversion and polynomial preconditioning. In dense
  settings, matrix-matrix products dominate the cost of evaluating $S_k$.
  Naive evaluation needs $k-1$ products, while splitting methods reduce this
  to $O(\log k)$. Repeated squaring, for example, uses $2\log_2 k$
  products, so further gains require higher-radix kernels that extend the
  series by $m$ terms per update. Beyond the known radix-5 kernel, explicit
  higher-radix constructions were not available, and the existence of exact
  rational kernels was unclear.
  We construct radix kernels for $T_m(B)=I+B+\cdots+B^{m-1}$ and use them to
  build faster series algorithms. For radix 9, we derive an exact 3-product
  kernel with rational coefficients, which is the first exact construction
  beyond radix 5. This kernel yields $5\log_9 k=1.58\log_2 k$ products, a
  21% reduction from repeated squaring. For radix 15, numerical optimization
  yields a 4-product kernel that matches the target through degree 14 but
  has nonzero spillover (extra terms) at degrees $\ge 15$. Because spillover
  breaks the standard telescoping update, we introduce a residual-based
  radix-kernel framework that accommodates approximate kernels and retains
  coefficient $(\mu_m+2)/\log_2 m$. Within this framework, radix 15 attains
  $6/\log_2 15\approx 1.54$, the best known asymptotic rate. Numerical
  experiments support the predicted product-count savings and associated
  runtime trends.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11843v1</guid>
      <category>math.NA</category>
      <category>cs.MS</category>
      <category>cs.NA</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Piyush Sao</dc:creator>
    </item>
    <item>
      <title>Data-driven discovery of chemical reaction networks</title>
      <link>https://arxiv.org/abs/2602.11849</link>
      <description>arXiv:2602.11849v1 Announce Type: new 
Abstract: We propose a unified framework that allows for the full mechanistic reconstruction of chemical reaction networks (CRNs) from concentration data. The framework utilizes an integral formulation of the differential equations governing the chemical reactions, followed by an automatic procedure to recover admissible mass-action mechanisms from the equations. We provide theoretical justification for the use of integral formulations using analytical and numerical error bounds. The integral formulation is demonstrated to offer superior robustness to noise and improved accuracy in both rate-law and graph recovery when compared to other commonly used formulations. Together, our developments advance the goal of fully automated, data-driven chemical mechanism discovery.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11849v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Abraham Reyes-Velazquez, Stefan G\"uttel, Igor Larrosa, Jonas Latz</dc:creator>
    </item>
    <item>
      <title>Avoiding stabilization terms in virtual elements for eigenvalue problems: The Reduced Basis Virtual Element Method</title>
      <link>https://arxiv.org/abs/2602.11870</link>
      <description>arXiv:2602.11870v1 Announce Type: new 
Abstract: We present the novel Reduced Basis Virtual Element Method (rbVEM) for solving the Laplace eigenvalue problem. This approach is based on the virtual element method and exploits the reduced basis technique to obtain an explicit representation of the virtual (non-polynomial) contribution to the discrete space. rbVEM yields a fully conforming discretization of the considered problem, so that stabilization terms are avoided. We prove that rbVEM provides the correct spectral approximation with optimal error estimates. Theoretical results are supplemented by an exhaustive numerical investigation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11870v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Silvia Bertoluzza, Fabio Credali, Francesca Gardini</dc:creator>
    </item>
    <item>
      <title>Splitting Schemes for ODEs with Goal-Oriented Error Estimation</title>
      <link>https://arxiv.org/abs/2602.11972</link>
      <description>arXiv:2602.11972v1 Announce Type: new 
Abstract: We present a hybrid a-priori/a-posteriori goal oriented error estimator for a combination of dynamic iteration-based solution of ordinary differential equations discretized by finite elements. Our novel error estimator combines estimates from classical dynamic iteration methods, usually used to enable splitting-based distributed simulation, and from the dual weighted residual method to be able to evaluate and balance both, the dynamic iteration error and the discretization error in desired quantities of interest. The obtained error estimators are used to conduct refinements of the computational mesh and as a stopping criterion for the dynamic iteration. In particular, we allow for an adaptive and flexible discretization of the time domain, where variables can be discretized differently to match both goal and solution requirements, e.g. in view of multiple time scales. We endow the scheme with efficient solvers from numerical linear algebra to ensure its applicability to complex problems. Numerical experiments compare the adaptive approach to a uniform refinement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11972v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Erik Weyl, Andreas Bartel, Manuel Schaller</dc:creator>
    </item>
    <item>
      <title>Lambda admissible subspaces of self adjoint matrices</title>
      <link>https://arxiv.org/abs/2602.11976</link>
      <description>arXiv:2602.11976v1 Announce Type: new 
Abstract: Given a self-adjoint matrix $A$ and an index $h$ such that $\lambda_h(A)$ lies in a cluster of eigenvalues of $A$, we introduce the novel class of $\Lambda$-admissible subspaces of $A$ of dimension $h$. First, we show that the low-rank approximation of the form $P_{\mathcal{T}} A P_{\mathcal{T}}$, for a subspace $\mathcal{T}$ that is close to any $\Lambda$-admissible subspace of $A$, has nice properties. Then, we prove that some well-known iterative algorithms (such as the Subspace Iteration Method, or the Krylov subspace method) produce subspaces that become arbitrarily close to $\Lambda$-admissible subspaces. We obtain upper bounds for the distance between subspaces obtained by the Rayleigh-Ritz method applied to $A$ and the class of $\Lambda$-admissible subspaces. We also find upper bounds for the condition number of the (set-valued) map computing the class of $\Lambda$-admissible subspaces of $A$. Finally, we include numerical examples that show the advantage of considering this new class of subspaces in the clustered eigenvalue setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11976v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Francisco Arrieta Zuccalli, Pedro Massey</dc:creator>
    </item>
    <item>
      <title>Mesh-free numerical method for Dirichlet eigenpairs of the Laplacian with potential</title>
      <link>https://arxiv.org/abs/2602.12008</link>
      <description>arXiv:2602.12008v1 Announce Type: new 
Abstract: This paper is concerned with the numerical approximation of the $L^2$ Dirichlet eigenpairs of the operator $-\Delta + V$ on a simply connected $C^2$ bounded domain $\Omega \subset \mathbb{R}^2$ containing the origin, where $V$ is a radial potential.
  We propose a mesh-free method inspired by the Method of Particular Solutions for the Laplacian (i.e. $V=0$). Extending this approach to general $C^1$ radial potentials is challenging due to the lack of explicit basis functions analogous to Bessel functions. To overcome this difficulty, we consider the equation $-\Delta u + V u = \lambda u$ on a ball containing $\Omega$, without imposing boundary conditions, for a collection of values $\lambda$ forming a fine discretisation of the interval in which eigenvalues are sought. By rewriting the problem in polar coordinates and applying a Fourier expansion with respect to the angular variable, we obtain a decoupled system of ordinary differential equations. These equations are solved numerically using a one-dimensional Finite Element Method, yielding a family of basis functions that are solutions of the equation $-\Delta u + V u = \lambda u$ on the ball and are independent of the domain $\Omega$.
  Dirichlet eigenvalues of $-\Delta + V$ are then approximated by minimising the boundary values on $\partial \Omega$ among linear combinations of the basis functions and identifying those values of $\lambda$ for which the computed minimum is sufficiently small. The proposed method is highly memory-efficient compared to the standard Finite Element approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.12008v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Drago\c{s} Manea</dc:creator>
    </item>
    <item>
      <title>Low T-Phase Rank Approximation of Third Order Tensors</title>
      <link>https://arxiv.org/abs/2602.12121</link>
      <description>arXiv:2602.12121v1 Announce Type: new 
Abstract: We study low T-phase-rank approximation of sectorial third-order tensors $\mathscr{A}\in\mathbb{C}^{n\times n\times p}$ under the tensor T-product. We introduce canonical T-phases and T-phase rank, and formulate the approximation task as minimizing a symmetric gauge of the canonical phase vector under a T-phase-rank constraint. Our main tool is a tensor phase-majorization inequality for the geometric mean, obtained by lifting the matrix inequality through the block-circulant representation. In the positive-imaginary regime, this yields an exact optimal-value formula and an explicit optimal half-phase truncation family. We further establish tensor counterparts of classical matrix phase inequalities and derive a tensor small phase theorem for MIMO linear time-invariant systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.12121v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Taehyeong Kim, Hayoung Choi, Yimin Wei</dc:creator>
    </item>
    <item>
      <title>Toward Adaptive Non-Intrusive Reduced-Order Models: Design and Challenges</title>
      <link>https://arxiv.org/abs/2602.11378</link>
      <description>arXiv:2602.11378v1 Announce Type: cross 
Abstract: Projection-based Reduced Order Models (ROMs) are often deployed as static surrogates, which limits their practical utility once a system leaves the training manifold. We formalize and study adaptive non-intrusive ROMs that update both the latent subspace and the reduced dynamics online. Building on ideas from static non-intrusive ROMs, specifically, Operator Inference (OpInf) and the recently-introduced Non-intrusive Trajectory-based optimization of Reduced-Order Models (NiTROM), we propose three formulations: Adaptive OpInf (sequential basis/operator refits), Adaptive NiTROM (joint Riemannian optimization of encoder/decoder and polynomial dynamics), and a hybrid that initializes NiTROM with an OpInf update. We describe the online data window, adaptation window, and computational budget, and analyze cost scaling. On a transiently perturbed lid-driven cavity flow, static Galerkin/OpInf/NiTROM drift or destabilize when forecasting beyond training. In contrast, Adaptive OpInf robustly suppresses amplitude drift with modest cost; Adaptive NiTROM is shown to attain near-exact energy tracking under frequent updates but is sensitive to its initialization and optimization depth; the hybrid is most reliable under regime changes and minimal offline data, yielding physically coherent fields and bounded energy. We argue that predictive claims for ROMs must be cost-aware and transparent, with clear separation of training/adaptation/deployment regimes and explicit reporting of online budgets and full-order model queries. This work provides a practical template for building self-correcting, non-intrusive ROMs that remain effective as the dynamics evolve well beyond the initial manifold.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11378v1</guid>
      <category>cs.LG</category>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amirpasha Hedayat, Alberto Padovan, Karthik Duraisamy</dc:creator>
    </item>
    <item>
      <title>Quantifying the effect of graph structure on strong Feller property of SPDEs</title>
      <link>https://arxiv.org/abs/2602.11484</link>
      <description>arXiv:2602.11484v1 Announce Type: cross 
Abstract: This paper investigates how the structure of the underlying graph influences the behavior of stochastic partial differential equations (SPDEs) on finite tree graphs, where each edge is driven by space-time white noise. We first introduce a novel graph-based null decomposition approach to analyzing the strong Feller property of the Markov semigroup generated by SPDEs on tree graphs. By examining the positions of zero entries in eigenfunctions of the graph Laplacian operator, we establish a sharp upper bound on the number of noise-free edges that ensures both the strong Feller property and irreducibility. Interestingly, we find that the addition of noise to any single edge is sufficient for chain graphs, whereas for star graphs, at most one edge can remain noise-free without compromising the system's properties. Furthermore, under a dissipative condition, we prove the existence and exponential ergodicity of a unique invariant measure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11484v1</guid>
      <category>math.PR</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.NA</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jianbo Cui, Tonghe Dang, Jialin Hong, Zhengkai Wang</dc:creator>
    </item>
    <item>
      <title>From Consensus-Based Optimization to Evolution Strategies: Proof of Global Convergence</title>
      <link>https://arxiv.org/abs/2602.11677</link>
      <description>arXiv:2602.11677v1 Announce Type: cross 
Abstract: Consensus-based optimization (CBO) is a powerful and versatile zero-order multi-particle method designed to provably solve high-dimensional global optimization problems, including those that are genuinely nonconvex or nonsmooth. The method relies on a balance between stochastic exploration and contraction toward a consensus point, which is defined via the Laplace principle as a proxy for the global minimizer.
  In this paper, we introduce new CBO variants that address practical and theoretical limitations of the original formulation of this novel optimization methodology. First, we propose a model called $\delta$-CBO}, which incorporates nonvanishing diffusion to prevent premature collapse to suboptimal states. We also develop a numerically stable implementation, the Consensus Freezing scheme, that remains robust even for arbitrarily large time steps by freezing the consensus point over time intervals. We connect these models through appropriate asymptotic limits. Furthermore, we derive from the Consensus Freezing scheme by suitable time rescaling and asymptotics a further algorithm, the Consensus Hopping scheme, which can be interpreted as a form of $(1,\lambda)$-Evolution Strategy. For all these schemes, we characterize for the first time the invariant measures and establish global convergence results, including exponential convergence rates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11677v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Massimo Fornasier, Hui Huang, Jona Klemenc, Greta Malaspina</dc:creator>
    </item>
    <item>
      <title>Estimation of instrument and noise parameters for inverse problem based on prior diffusion model</title>
      <link>https://arxiv.org/abs/2602.11711</link>
      <description>arXiv:2602.11711v1 Announce Type: cross 
Abstract: This article addresses the issue of estimating observation parameters (response and error parameters) in inverse problems. The focus is on cases where regularization is introduced in a Bayesian framework and the prior is modeled by a diffusion process. In this context, the issue of posterior sampling is well known to be thorny, and a recent paper proposes a notably simple and effective solution. Consequently, it offers an remarkable additional flexibility when it comes to estimating observation parameters. The proposed strategy enables us to define an optimal estimator for both the observation parameters and the image of interest. Furthermore, the strategy provides a means of quantifying uncertainty. In addition, MCMC algorithms allow for the efficient computation of estimates and properties of posteriors, while offering some guarantees. The paper presents several numerical experiments that clearly confirm the computational efficiency and the quality of both estimates and uncertainties quantification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11711v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.AP</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jean-Fran\c{c}ois Giovannelli</dc:creator>
    </item>
    <item>
      <title>Global Convergence to Nash Equilibrium in Nonconvex General-Sum Games under the $n$-Sided PL Condition</title>
      <link>https://arxiv.org/abs/2602.11835</link>
      <description>arXiv:2602.11835v1 Announce Type: cross 
Abstract: We consider the problem of finding a Nash equilibrium (NE) in a general-sum game, where player $i$'s objective is $f_i(x)=f_i(x_1,...,x_n)$, with $x_j\in\mathbb{R}^{d_j}$ denoting the strategy variables of player $j$. Our focus is on investigating first-order gradient-based algorithms and their variations, such as the block coordinate descent (BCD) algorithm, for tackling this problem. We introduce a set of conditions, called the $n$-sided PL condition, which extends the well-established gradient dominance condition a.k.a Polyak-{\L}ojasiewicz (PL) condition and the concept of multi-convexity. This condition, satisfied by various classes of non-convex functions, allows us to analyze the convergence of various gradient descent (GD) algorithms. Moreover, our study delves into scenarios where the standard gradient descent methods fail to converge to NE. In such cases, we propose adapted variants of GD that converge towards NE and analyze their convergence rates. Finally, we evaluate the performance of the proposed algorithms through several experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11835v1</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>The 25th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2026)</arxiv:journal_reference>
      <dc:creator>Yutong Chao, Jalal Etesami</dc:creator>
    </item>
    <item>
      <title>Sub--Riemannian boundary value problems for Optimal Geometric Locomotion</title>
      <link>https://arxiv.org/abs/2602.12199</link>
      <description>arXiv:2602.12199v1 Announce Type: cross 
Abstract: We propose a geometric model for optimal shape-change-induced motions of slender locomotors, e.g., snakes slithering on sand. In these scenarios, the motion of a body in world coordinates is completely determined by the sequence of shapes it assumes. Specifically, we formulate Lagrangian least-dissipation principles as boundary value problems whose solutions are given by sub-Riemannian geodesics. Notably, our geometric model accounts not only for the energy dissipated by the body's displacement through the environment, but also for the energy dissipated by the animal's metabolism or a robot's actuators to induce shape changes such as bending and stretching, thus capturing overall locomotion efficiency. Our continuous model, together with a consistent time and space discretization, enables numerical computation of sub-Riemannian geodesics for three different types of boundary conditions, i.e., fixing initial and target body, restricting to cyclic motion, or solely prescribing body displacement and orientation. The resulting optimal deformation gaits qualitatively match observed motion trajectories of organisms such as snakes and spermatozoa, as well as known optimality results for low-dimensional systems such as Purcell's swimmers. Moreover, being geometrically less rigid than previous frameworks, our model enables new insights into locomotion mechanisms of, e.g., generalized Purcell's swimmers. The code is publicly available.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.12199v1</guid>
      <category>cs.RO</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Oliver Gross, Florine Hartwig, Martin Rumpf, Peter Schr\"oder</dc:creator>
    </item>
    <item>
      <title>Learning to Control: The iUzawa-Net for Nonsmooth Optimal Control of Linear PDEs</title>
      <link>https://arxiv.org/abs/2602.12273</link>
      <description>arXiv:2602.12273v1 Announce Type: cross 
Abstract: We propose an optimization-informed deep neural network approach, named iUzawa-Net, aiming for the first solver that enables real-time solutions for a class of nonsmooth optimal control problems of linear partial differential equations (PDEs). The iUzawa-Net unrolls an inexact Uzawa method for saddle point problems, replacing classical preconditioners and PDE solvers with specifically designed learnable neural networks. We prove universal approximation properties and establish the asymptotic $\varepsilon$-optimality for the iUzawa-Net, and validate its promising numerical efficiency through nonsmooth elliptic and parabolic optimal control problems. Our techniques offer a versatile framework for designing and analyzing various optimization-informed deep learning approaches to optimal control and other PDE-constrained optimization problems. The proposed learning-to-control approach synergizes model-based optimization algorithms and data-driven deep learning techniques, inheriting the merits of both methodologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.12273v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yongcun Song, Xiaoming Yuan, Hangrui Yue, Tianyou Zeng</dc:creator>
    </item>
    <item>
      <title>Neural numerical homogenization based on Deep Ritz corrections</title>
      <link>https://arxiv.org/abs/2411.14084</link>
      <description>arXiv:2411.14084v3 Announce Type: replace 
Abstract: Numerical homogenization methods aim at providing appropriate coarse-scale approximations of solutions to (elliptic) partial differential equations that involve highly oscillatory coefficients. The localized orthogonal decomposition (LOD) method is an effective way of dealing with such coefficients, especially if they are non-periodic and non-smooth. It modifies classical finite element basis functions by suitable fine-scale corrections. In this paper, we make use of the structure of the LOD method, but we propose to calculate the corrections based on a Deep Ritz approach involving a parametrization of the coefficients to tackle temporal variations or uncertainties. Numerical examples for a parabolic model problem are presented to assess the performance of the approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.14084v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mehdi Elasmi, Felix Krumbiegel, Roland Maier</dc:creator>
    </item>
    <item>
      <title>GMRES Convergence Analysis for Nonsymmetric Saddle-Point Systems When the Field of Values Contains the Origin</title>
      <link>https://arxiv.org/abs/2505.07156</link>
      <description>arXiv:2505.07156v2 Announce Type: replace 
Abstract: We present a field-of-values (FOV) analysis for preconditioned nonsymmetric saddle-point linear systems, where zero is included in the field of values of the matrix. We rely on recent results of Crouzeix and Greenbaum [Spectral sets: numerical range and beyond. SIAM Journal on Matrix Analysis and Applications, 40(3):1087-1101, 2019], showing that a convex region with a circular hole is a spectral set. Sufficient conditions are derived for convergence independent of the matrix dimensions. We apply our results to preconditioned nonsymmetric saddle-point systems, and show their applicability to families of block preconditioners that have not been previously covered by existing FOV analysis. A limitation of our theory is that the preconditioned matrix is required to have a small skew-symmetric part in norm. Consequently, our analysis may not be applicable, for example, to fluid flow problems characterized by a small viscosity coefficient. Some numerical results illustrate our findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07156v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hao Chen, Chen Greif</dc:creator>
    </item>
    <item>
      <title>Subspace-constrained randomized coordinate descent for linear systems with good low-rank matrix approximations</title>
      <link>https://arxiv.org/abs/2506.09394</link>
      <description>arXiv:2506.09394v3 Announce Type: replace 
Abstract: The randomized coordinate descent (RCD) method is a classical algorithm with simple, lightweight iterations that is widely used for various optimization problems, including the solution of positive semidefinite linear systems. As a linear solver, RCD is particularly effective when the matrix is well-conditioned; however, its convergence rate deteriorates rapidly in the presence of large spectral outliers. In this paper, we introduce the subspace-constrained randomized coordinate descent (SC-RCD) method, in which the dynamics of RCD are restricted to an affine subspace corresponding to a column Nystr\"{o}m approximation, efficiently computed using the recently analyzed RPCholesky algorithm. We prove that SC-RCD converges at a rate that is unaffected by large spectral outliers, making it an effective and memory-efficient solver for large-scale, dense linear systems with rapidly decaying spectra, such as those encountered in kernel ridge regression. Experimental validation and comparisons with related solvers based on coordinate descent and the conjugate gradient method demonstrate the efficiency of SC-RCD. Our theoretical results are derived by developing a more general subspace-constrained framework for the sketch-and-project method. This framework, which may be of independent interest, generalizes popular algorithms such as randomized Kaczmarz and coordinate descent, and provides a flexible, implicit preconditioning strategy for a variety of iterative solvers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.09394v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jackie Lok, Elizaveta Rebrova</dc:creator>
    </item>
    <item>
      <title>Surrogate to Poincar\'e inequalities on manifolds for structured dimension reduction in nonlinear feature spaces</title>
      <link>https://arxiv.org/abs/2602.01143</link>
      <description>arXiv:2602.01143v2 Announce Type: replace 
Abstract: This paper is concerned with the approximation of continuously differentiable functions with high-dimensional input by a composition of two functions: a feature map that extracts few features from the input space, and a profile function that approximates the target function taking the features as its low-dimensional input. We focus on the construction of structured nonlinear feature maps, that extract features on separate groups of variables, using a recently introduced gradient-based method that leverages Poincar\'e inequalities on nonlinear manifolds. This method consists in minimizing a non-convex loss functional, which can be a challenging task, especially for small training samples. We first investigate a collective setting, in which we construct a feature map suitable to a parametrized family of high-dimensional functions. In this setting we introduce a new quadratic surrogate to the non-convex loss function and show an upper bound on the latter. We then investigate a grouped setting, in which we construct separate feature maps for separate groups of inputs, and we show that this setting is almost equivalent to multiple collective settings, one for each group of variables.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01143v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexandre Pasco, Anthony Nouy</dc:creator>
    </item>
    <item>
      <title>Convex limiting for finite elements and its relationship to residual distribution</title>
      <link>https://arxiv.org/abs/2602.02095</link>
      <description>arXiv:2602.02095v2 Announce Type: replace 
Abstract: We review some recent advances in the field of element-based algebraic stabilization for continuous finite element discretizations of nonlinear hyperbolic problems. The main focus is on multidimensional convex limiting techniques designed to constrain antidiffusive element contributions rather than fluxes. We show that the resulting schemes can be interpreted as residual distribution methods. Two kinds of convex limiting can be used to enforce the validity of generalized discrete maximum principles in this context. The first approach has the structure of a localized flux-corrected transport (FCT) algorithm, in which the computation of a low-order predictor is followed by an antidiffusive correction stage. The second option is the use of a monolithic convex limiting (MCL) procedure at the level of spatial semi-discretization. In both cases, inequality constraints are imposed on scalar functions of intermediate states that are required to stay in convex invariant sets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.02095v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dmitri Kuzmin</dc:creator>
    </item>
    <item>
      <title>Successive randomized compression: A randomized algorithm for the compressed MPO-MPS product</title>
      <link>https://arxiv.org/abs/2504.06475</link>
      <description>arXiv:2504.06475v2 Announce Type: replace-cross 
Abstract: Tensor networks like matrix product states (MPSs) and matrix product operators (MPOs) are powerful tools for representing exponentially large states and operators, with applications in quantum many-body physics, machine learning, numerical analysis, and other areas. In these applications, computing a compressed representation of the MPO--MPS product is a fundamental computational primitive. For this operation, this paper introduces a new single-pass, randomized algorithm, called successive randomized compression (SRC), that improves on existing approaches in speed or in accuracy. The performance of the new algorithm is evaluated on synthetic problems and unitary time evolution problems for quantum spin systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.06475v2</guid>
      <category>quant-ph</category>
      <category>cond-mat.str-el</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chris Cama\~no, Ethan N. Epperly, Joel A. Tropp</dc:creator>
    </item>
    <item>
      <title>Maximum Principle of Optimal Probability Density Control</title>
      <link>https://arxiv.org/abs/2505.18362</link>
      <description>arXiv:2505.18362v2 Announce Type: replace-cross 
Abstract: We develop a general theoretical framework for optimal probability density control on standard measure spaces, aimed at addressing large-scale multi-agent control problems. In particular, we establish a maximum principle (MP) for control problems posed on infinite-dimensional spaces of probability distributions and control vector fields. We further derive the Hamilton--Jacobi--Bellman equation for the associated value functional defined on the space of probability distributions. Both results are presented in a concise form and supported by rigorous mathematical analysis, enabling efficient numerical treatment of these problems. Building on the proposed MP, we introduce a scalable numerical algorithm that leverages deep neural networks to handle high-dimensional settings. The effectiveness of the approach is demonstrated through several multi-agent control examples involving domain obstacles and inter-agent interactions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18362v2</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nathan Gaby, Xiaojing Ye</dc:creator>
    </item>
    <item>
      <title>Bayesian decomposition using Besov priors</title>
      <link>https://arxiv.org/abs/2506.18846</link>
      <description>arXiv:2506.18846v2 Announce Type: replace-cross 
Abstract: In many inverse problems, the unknown is composed of multiple components with different regularities, for example, in imaging problems, where the unknown can have both rough and smooth features. We investigate linear Bayesian inverse problems, where the unknown consists of two components: one smooth and one piecewise constant. We model the unknown as a sum of two components and assign individual priors on each component to impose the assumed behavior. We propose and compare two prior models: (i) a combination of a Haar wavelet-based Besov prior and a smoothing Besov prior, and (ii) a hierarchical Gaussian prior on the gradient coupled with a smoothing Besov prior. To achieve a balanced reconstruction, we place hyperpriors on the prior parameters and jointly infer both the components and the hyperparameters. We propose Gibbs sampling schemes for posterior inference in both prior models. We demonstrate the capabilities of our approach on 1D and 2D deconvolution problems, where the unknown consists of smooth parts with jumps. The numerical results indicate that our methods improve the reconstruction quality compared to single-prior approaches and that the prior parameters can be successfully estimated to yield a balanced decomposition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.18846v2</guid>
      <category>stat.CO</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andreas Horst, Babak Maboudi Afkham, Yiqiu Dong, Jakob Lemvig</dc:creator>
    </item>
    <item>
      <title>Distributional Computational Graphs: Error Bounds</title>
      <link>https://arxiv.org/abs/2601.16250</link>
      <description>arXiv:2601.16250v2 Announce Type: replace-cross 
Abstract: We study a general framework of distributional computational graphs: computational graphs whose inputs are probability distributions rather than point values. We analyze the discretization error that arises when these graphs are evaluated using finite approximations of continuous probability distributions. Such an approximation might be the result of representing a continuous real-valued distribution using a discrete representation or from constructing an empirical distribution from samples (or might be the output of another distributional computational graph). We establish non-asymptotic error bounds in terms of the Wasserstein-1 distance, without imposing structural assumptions on the computational graph.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.16250v2</guid>
      <category>stat.ML</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Olof Hallqvist Elias, Michael Selby, Phillip Stanley-Marbell</dc:creator>
    </item>
    <item>
      <title>Decoupled Diffusion Sampling for Inverse Problems on Function Spaces</title>
      <link>https://arxiv.org/abs/2601.23280</link>
      <description>arXiv:2601.23280v2 Announce Type: replace-cross 
Abstract: We propose a data-efficient, physics-aware generative framework in function space for inverse PDE problems. Existing plug-and-play diffusion posterior samplers represent physics implicitly through joint coefficient-solution modeling, requiring substantial paired supervision. In contrast, our Decoupled Diffusion Inverse Solver (DDIS) employs a decoupled design: an unconditional diffusion learns the coefficient prior, while a neural operator explicitly models the forward PDE for guidance. This decoupling enables superior data efficiency and effective physics-informed learning, while naturally supporting Decoupled Annealing Posterior Sampling (DAPS) to avoid over-smoothing in Diffusion Posterior Sampling (DPS). Theoretically, we prove that DDIS avoids the guidance attenuation failure of joint models when training data is scarce. Empirically, DDIS achieves state-of-the-art performance under sparse observation, improving $l_2$ error by 11% and spectral error by 54% on average; when data is limited to 1%, DDIS maintains accuracy with 40% advantage in $l_2$ error compared to joint models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.23280v2</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas Y. L. Lin, Jiachen Yao, Lufang Chiang, Julius Berner, Anima Anandkumar</dc:creator>
    </item>
  </channel>
</rss>
