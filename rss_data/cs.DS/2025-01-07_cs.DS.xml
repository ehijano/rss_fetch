<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 07 Jan 2025 05:00:09 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Locally computing edge orientations</title>
      <link>https://arxiv.org/abs/2501.02136</link>
      <description>arXiv:2501.02136v1 Announce Type: new 
Abstract: We consider the question of orienting the edges in a graph $G$ such that every vertex has bounded out-degree. For graphs of arboricity $\alpha$, there is an orientation in which every vertex has out-degree at most $\alpha$ and, moreover, the best possible maximum out-degree of an orientation is at least $\alpha - 1$. We are thus interested in algorithms that can achieve a maximum out-degree of close to $\alpha$. A widely studied approach for this problem in the distributed algorithms setting is a ``peeling algorithm'' that provides an orientation with maximum out-degree $\alpha(2+\epsilon)$ in a logarithmic number of iterations.
  We consider this problem in the local computation algorithm (LCA) model, which quickly answers queries of the form ``What is the orientation of edge $(u,v)$?'' by probing the input graph. When the peeling algorithm is executed in the LCA setting by applying standard techniques, e.g., the Parnas-Ron paradigm, it requires $\Omega(n)$ probes per query on an $n$-vertex graph. In the case where $G$ has unbounded degree, we show that any LCA that orients its edges to yield maximum out-degree $r$ must use $\Omega(\sqrt n/r)$ probes to $G$ per query in the worst case, even if $G$ is known to be a forest (that is, $\alpha=1$). We also show several algorithms with sublinear probe complexity when $G$ has unbounded degree. When $G$ is a tree such that the maximum degree $\Delta$ of $G$ is bounded, we demonstrate an algorithm that uses $\Delta n^{1-\log_\Delta r + o(1)}$ probes to $G$ per query. To obtain this result, we develop an edge-coloring approach that ultimately yields a graph-shattering-like result. We also use this shattering-like approach to demonstrate an LCA which $4$-colors any tree using sublinear probes per query.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.02136v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Slobodan Mitrovi\'c, Ronitt Rubinfeld, Mihir Singhal</dc:creator>
    </item>
    <item>
      <title>Optimal Bounds for Open Addressing Without Reordering</title>
      <link>https://arxiv.org/abs/2501.02305</link>
      <description>arXiv:2501.02305v1 Announce Type: new 
Abstract: In this paper, we revisit one of the simplest problems in data structures: the task of inserting elements into an open-addressed hash table so that elements can later be retrieved with as few probes as possible. We show that, even without reordering elements over time, it is possible to construct a hash table that achieves far better expected search complexities (both amortized and worst-case) than were previously thought possible. Along the way, we disprove the central conjecture left by Yao in his seminal paper ``Uniform Hashing is Optimal''. All of our results come with matching lower bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.02305v1</guid>
      <category>cs.DS</category>
      <category>math.CO</category>
      <pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Martin Farach-Colton, Andrew Krapivin, William Kuszmaul</dc:creator>
    </item>
    <item>
      <title>Efficient $d$-ary Cuckoo Hashing at High Load Factors by Bubbling Up</title>
      <link>https://arxiv.org/abs/2501.02312</link>
      <description>arXiv:2501.02312v1 Announce Type: new 
Abstract: A $d$-ary cuckoo hash table is an open-addressed hash table that stores each key $x$ in one of $d$ random positions $h_1(x), h_2(x), \ldots, h_d(x)$. In the offline setting, where all items are given and keys need only be matched to locations, it is possible to support a load factor of $1 - \epsilon$ while using $d = \lceil \ln \epsilon^{-1} + o(1) \rceil$ hashes. The online setting, where keys are moved as new keys arrive sequentially, has the additional challenge of the time to insert new keys, and it has not been known whether one can use $d = O(\ln \epsilon^{-1})$ hashes to support $\poly(\epsilon^{-1})$ expected-time insertions.
  In this paper, we introduce bubble-up cuckoo hashing, an implementation of $d$-ary cuckoo hashing that achieves all of the following properties simultaneously:
  (1) uses $d = \lceil \ln \epsilon^{-1} + \alpha \rceil$ hash locations per item for an arbitrarily small positive constant $\alpha$.
  (2) achieves expected insertion time $O(\delta^{-1})$ for any insertion taking place at load factor $1 - \delta \le 1 - \epsilon$.
  (3) achieves expected positive query time $O(1)$, independent of $d$ and $\epsilon$.
  The first two properties give an essentially optimal value of $d$ without compromising insertion time. The third property is interesting even in the offline setting: it says that, even though \emph{negative} queries must take time $d$, positive queries can actually be implemented in $O(1)$ expected time, even when $d$ is large.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.02312v1</guid>
      <category>cs.DS</category>
      <category>math.CO</category>
      <pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>William Kuszmaul, Michael Mitzenmacher</dc:creator>
    </item>
    <item>
      <title>A Faster Algorithm for Constrained Correlation Clustering</title>
      <link>https://arxiv.org/abs/2501.03154</link>
      <description>arXiv:2501.03154v1 Announce Type: new 
Abstract: In the Correlation Clustering problem we are given $n$ nodes, and a preference for each pair of nodes indicating whether we prefer the two endpoints to be in the same cluster or not. The output is a clustering inducing the minimum number of violated preferences. In certain cases, however, the preference between some pairs may be too important to be violated. The constrained version of this problem specifies pairs of nodes that must be in the same cluster as well as pairs that must not be in the same cluster (hard constraints). The output clustering has to satisfy all hard constraints while minimizing the number of violated preferences.
  Constrained Correlation Clustering is APX-Hard and has been approximated within a factor 3 by van Zuylen et al. [SODA '07] using $\Omega(n^{3\omega})$ time. In this work, using a more combinatorial approach, we show how to approximate this problem significantly faster at the cost of a slightly weaker approximation factor. In particular, our algorithm runs in $\widetilde{O}(n^3)$ time and approximates Constrained Correlation Clustering within a factor 16.
  To achieve our result we need properties guaranteed by a particular influential algorithm for (unconstrained) Correlation Clustering, the CC-PIVOT algorithm. This algorithm chooses a pivot node $u$, creates a cluster containing $u$ and all its preferred nodes, and recursively solves the rest of the problem. As a byproduct of our work, we provide a derandomization of the CC-PIVOT algorithm that still achieves the 3-approximation; furthermore, we show that there exist instances where no ordering of the pivots can give a $(3-\varepsilon)$-approximation, for any constant $\varepsilon$.
  Finally, we introduce a node-weighted version of Correlation Clustering, which can be approximated within factor 3 using our insights on Constrained Correlation Clustering.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.03154v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nick Fischer, Evangelos Kipouridis, Jonas Klausen, Mikkel Thorup</dc:creator>
    </item>
    <item>
      <title>An Optimal Algorithm for Half-plane Hitting Set</title>
      <link>https://arxiv.org/abs/2501.02195</link>
      <description>arXiv:2501.02195v1 Announce Type: cross 
Abstract: Given a set $ P $ of $n$ points and a set $ H $ of $n$ half-planes in the plane, we consider the problem of computing a smallest subset of points such that each half-plane contains at least one point of the subset. The previously best algorithm solves the problem in $O(n^3 \log n)$ time. It is also known that $\Omega(n \log n)$ is a lower bound for the problem under the algebraic decision tree model. In this paper, we present an $O(n \log n)$ time algorithm, which matches the lower bound and thus is optimal. Another virtue of the algorithm is that it is relatively simple.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.02195v1</guid>
      <category>cs.CG</category>
      <category>cs.DS</category>
      <pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gang Liu, Haitao Wang</dc:creator>
    </item>
    <item>
      <title>Chameleon2++: An Efficient Chameleon2 Clustering with Approximate Nearest Neighbors</title>
      <link>https://arxiv.org/abs/2501.02612</link>
      <description>arXiv:2501.02612v1 Announce Type: cross 
Abstract: Clustering algorithms are fundamental tools in data analysis, with hierarchical methods being particularly valuable for their flexibility. Chameleon is a widely used hierarchical clustering algorithm that excels at identifying high-quality clusters of arbitrary shapes, sizes, and densities. Chameleon2 is the most recent variant that has demonstrated significant improvements, but suffers from critical failings and there are certain improvements that can be made.
  The first failure we address is that the complexity of Chameleon2 is claimed to be $O(n^2)$, while we demonstrate that it is actually $O(n^2\log{n})$, with $n$ being the number of data points. Furthermore, we suggest improvements to Chameleon2 that ensure that the complexity remains $O(n^2)$ with minimal to no loss of performance. The second failing of Chameleon2 is that it lacks transparency and it does not provide the fine-tuned algorithm parameters used to obtain the claimed results. We meticulously provide all such parameter values to enhance replicability.
  The improvement which we make in Chameleon2 is that we replace the exact $k$-NN search with an approximate $k$-NN search. This further reduces the algorithmic complexity down to $O(n\log{n})$ without any performance loss. Here, we primarily configure three approximate nearest neighbor search algorithms (Annoy, FLANN and NMSLIB) to align with the overarching Chameleon2 clustering framework. Experimental evaluations on standard benchmark datasets demonstrate that the proposed Chameleon2++ algorithm is more efficient, robust, and computationally optimal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.02612v1</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Priyanshu Singh, Kapil Ahuja</dc:creator>
    </item>
    <item>
      <title>Local Enumeration: The Not-All-Equal Case</title>
      <link>https://arxiv.org/abs/2501.02886</link>
      <description>arXiv:2501.02886v1 Announce Type: cross 
Abstract: Gurumukhani et al. (CCC'24) proposed the local enumeration problem Enum(k, t) as an approach to break the Super Strong Exponential Time Hypothesis (SSETH): for a natural number $k$ and a parameter $t$, given an $n$-variate $k$-CNF with no satisfying assignment of Hamming weight less than $t(n)$, enumerate all satisfying assignments of Hamming weight exactly $t(n)$. Furthermore, they gave a randomized algorithm for Enum(k, t) and employed new ideas to analyze the first non-trivial case, namely $k = 3$. In particular, they solved Enum(3, n/2) in expected $1.598^n$ time. A simple construction shows a lower bound of $6^{\frac{n}{4}} \approx 1.565^n$.
  In this paper, we show that to break SSETH, it is sufficient to consider a simpler local enumeration problem NAE-Enum(k, t): for a natural number $k$ and a parameter $t$, given an $n$-variate $k$-CNF with no satisfying assignment of Hamming weight less than $t(n)$, enumerate all Not-All-Equal (NAE) solutions of Hamming weight exactly $t(n)$, i.e., those that satisfy and falsify some literal in every clause. We refine the algorithm of Gurumukhani et al. and show that it optimally solves NAE-Enum(3, n/2), namely, in expected time $poly(n) \cdot 6^{\frac{n}{4}}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.02886v1</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohit Gurumukhani, Ramamohan Paturi, Michael Saks, Navid Talebanfard</dc:creator>
    </item>
    <item>
      <title>The Multiplicative Version of Azuma's Inequality, with an Application to Contention Analysis</title>
      <link>https://arxiv.org/abs/2102.05077</link>
      <description>arXiv:2102.05077v2 Announce Type: replace 
Abstract: Azuma's inequality is a tool for proving concentration bounds on random variables. The inequality can be thought of as a natural generalization of additive Chernoff bounds. On the other hand, the analogous generalization of multiplicative Chernoff bounds does not appear to be widely known. We formulate a multiplicative-error version of Azuma's inequality.
  We then show how to apply this new inequality in order to greatly simplify (and correct) the analysis of contention delays in multithreaded systems managed by randomized work stealing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2102.05077v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>William Kuszmaul, Qi Qi</dc:creator>
    </item>
    <item>
      <title>Online matching with delays and stochastic arrival times</title>
      <link>https://arxiv.org/abs/2210.07018</link>
      <description>arXiv:2210.07018v3 Announce Type: replace 
Abstract: This paper presents a new research direction for the Min-cost Perfect Matching with Delays (MPMD) - a problem introduced by Emek et al. (STOC'16). In the original version of this problem, we are given an $n$-point metric space, where requests arrive in an online fashion. The goal is to minimise the matching cost for an even number of requests. However, contrary to traditional online matching problems, a request does not have to be paired immediately at the time of its arrival. Instead, the decision of whether to match a request can be postponed for time $t$ at a delay cost of $t$. For this reason, the goal of the MPMD is to minimise the overall sum of distance and delay costs. Interestingly, for adversarially generated requests, no online algorithm can achieve a competitive ratio better than $O(\log n/\log \log n)$ (Ashlagi et al., APPROX/RANDOM'17).
  Here, we consider a stochastic version of the MPMD problem where the input requests follow a Poisson arrival process. For such a problem, we show that the above lower bound can be improved by presenting two deterministic online algorithms, which, in expectation, are constant-competitive. The first one is a simple greedy algorithm that matches any two requests once the sum of their delay costs exceeds their connection cost, i.e., the distance between them. The second algorithm builds on the tools used to analyse the first one in order to obtain even better performance guarantees. This result is rather surprising as the greedy approach for the adversarial model achieves a competitive ratio of $\Omega(m^{\log \frac{3}{2}+\varepsilon})$, where $m$ denotes the number of requests served (Azar et al., TOCS'20). Finally, we prove that it is possible to obtain similar results for the general case when the delay cost follows an arbitrary positive and non-decreasing function, as well as for the MPMD variant with penalties to clear pending requests.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.07018v3</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mathieu Mari, Micha{\l} Paw{\l}owski, Runtian Ren, Piotr Sankowski</dc:creator>
    </item>
    <item>
      <title>Decremental $(1+\epsilon)$-Approximate Maximum Eigenvector: Dynamic Power Method</title>
      <link>https://arxiv.org/abs/2402.17929</link>
      <description>arXiv:2402.17929v2 Announce Type: replace 
Abstract: We present a dynamic algorithm for maintaining $(1+\epsilon)$-approximate maximum eigenvector and eigenvalue of a positive semi-definite matrix $A$ undergoing \emph{decreasing} updates, i.e., updates which may only decrease eigenvalues. Given a vector $v$ updating $A\gets A-vv^{\top}$, our algorithm takes $\tilde{O}(\mathrm{nnz}(v))$ amortized update time, i.e., polylogarithmic per non-zeros in the update vector.
  Our technique is based on a novel analysis of the influential power method in the dynamic setting. The two previous sets of techniques have the following drawbacks (1) algebraic techniques can maintain exact solutions but their update time is at least polynomial per non-zeros, and (2) sketching techniques admit polylogarithmic update time but suffer from a crude additive approximation.
  Our algorithm exploits an oblivious adversary. Interestingly, we show that any algorithm with polylogarithmic update time per non-zeros that works against an adaptive adversary and satisfies an additional natural property would imply a breakthrough for checking psd-ness of matrices in $\tilde{O}(n^{2})$ time, instead of $O(n^{\omega})$ time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.17929v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Deeksha Adil, Thatchaphol Saranurak</dc:creator>
    </item>
    <item>
      <title>Towards Metric DBSCAN: Exact, Approximate, and Streaming Algorithms</title>
      <link>https://arxiv.org/abs/2405.06899</link>
      <description>arXiv:2405.06899v3 Announce Type: replace 
Abstract: DBSCAN is a popular density-based clustering algorithm that has many different applications in practice. However, the running time of DBSCAN in high-dimensional space or general metric space ({\em e.g.,} clustering a set of texts by using edit distance) can be as large as quadratic in the input size. Moreover, most of existing accelerating techniques for DBSCAN are only available for low-dimensional Euclidean space. In this paper, we study the DBSCAN problem under the assumption that the inliers (the core points and border points) have a low intrinsic dimension (which is a realistic assumption for many high-dimensional applications), where the outliers can locate anywhere in the space without any assumption. First, we propose a $k$-center clustering based algorithm that can reduce the time-consuming labeling and merging tasks of DBSCAN to be linear. Further, we propose a linear time approximate DBSCAN algorithm, where the key idea is building a novel small-size summary for the core points. Also, our algorithm can be efficiently implemented for streaming data and the required memory is independent of the input size. Finally, we conduct our experiments and compare our algorithms with several popular DBSCAN algorithms. The experimental results suggest that our proposed approach can significantly reduce the computational complexity in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.06899v3</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3654981</arxiv:DOI>
      <dc:creator>Guanlin Mo, Shihong Song, Hu Ding</dc:creator>
    </item>
    <item>
      <title>Reducing Matroid Optimization to Basis Search</title>
      <link>https://arxiv.org/abs/2408.04118</link>
      <description>arXiv:2408.04118v3 Announce Type: replace 
Abstract: Matroids provide one of the most elegant structures for algorithm design. This is best identified by the Edmonds-Rado theorem relating the success of the simple greedy algorithm to the anatomy of the optimal basis of a matroid [Edm71; Rad57]. As a response, much energy has been devoted to understanding a matroid's computational properties. Yet, less is understood where parallel algorithms are concerned. In response, we initiate the study of parallel matroid optimization in the adaptive complexity model [BS18]. First, we reexamine Bor\r{u}vka's classical minimum weight spanning tree algorithm [Bor26b; Bor26a] in the abstract language of matroid theory, and identify a new certificate of optimality for the basis of any matroid as a result. In particular, a basis is optimal if and only if it contains the points of minimum weight in every circuit of the dual matroid. Hence, we can witnesses whether any specific point belongs to the optimal basis via a test for local optimality in a circuit of the dual matroid, thereby revealing a general design paradigm towards parallel matroid optimization. To instantiate this paradigm, we use the special structure of a binary matroid to identify an optimization scheme with low adaptivity. Here, our key technical step is reducing optimization to the simpler task of basis search in the binary matroid, using only logarithmic overhead of adaptive rounds of queries to independence oracles. Consequentially, we compose our reduction with the parallel basis search method of [KUW88] to obtain an algorithm for finding the optimal basis of a binary matroid terminating in sublinearly many adaptive rounds of queries to an independence oracle. To the authors' knowledge, this is the first algorithm for matroid optimization to outperform the greedy algorithm in terms of adaptive complexity in the independence query model without assuming the matroid is encoded by a graph.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04118v3</guid>
      <category>cs.DS</category>
      <category>cs.DC</category>
      <category>cs.DM</category>
      <category>math.OC</category>
      <pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Robert Streit, Vijay K. Garg</dc:creator>
    </item>
    <item>
      <title>Parallel and Distributed Expander Decomposition: Simple, Fast, and Near-Optimal</title>
      <link>https://arxiv.org/abs/2410.13451</link>
      <description>arXiv:2410.13451v2 Announce Type: replace 
Abstract: Expander decompositions have become one of the central frameworks in the design of fast algorithms. For an undirected graph $G=(V,E)$, a near-optimal $\phi$-expander decomposition is a partition $V_1, V_2, \ldots, V_k$ of the vertex set $V$ where each subgraph $G[V_i]$ is a $\phi$-expander, and only an $\widetilde{O}(\phi)$-fraction of the edges cross between partition sets.
  In this article, we give the first near-optimal parallel algorithm to compute $\phi$-expander decompositions in near-linear work $\widetilde{O}(m/\phi^2)$ and near-constant span $\widetilde{O}(1/\phi^4)$. Our algorithm is very simple and likely practical. Our algorithm can also be implemented in the distributed Congest model in $\tilde{O}(1/\phi^4)$ rounds.
  Our results surpass the theoretical guarantees of the current state-of-the-art parallel algorithms [Chang-Saranurak PODC'19, Chang-Saranurak FOCS'20], while being the first to ensure that only an $\tilde{O}(\phi)$ fraction of edges cross between partition sets. In contrast, previous algorithms [Chang-Saranurak PODC'19, Chang-Saranurak FOCS'20] admit at least an $O(\phi^{1/3})$ fraction of crossing edges, a polynomial loss in quality inherent to their random-walk-based techniques. Our algorithm, instead, leverages flow-based techniques and extends the popular sequential algorithm presented in [Saranurak-Wang SODA'19].</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.13451v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daoyuan Chen, Simon Meierhans, Maximilian Probst Gutenberg, Thatchaphol Saranurak</dc:creator>
    </item>
    <item>
      <title>Learning-Augmented Streaming Algorithms for Approximating MAX-CUT</title>
      <link>https://arxiv.org/abs/2412.09773</link>
      <description>arXiv:2412.09773v2 Announce Type: replace 
Abstract: We study learning-augmented streaming algorithms for estimating the value of MAX-CUT in a graph. In the classical streaming model, while a $1/2$-approximation for estimating the value of MAX-CUT can be trivially achieved with $O(1)$ words of space, Kapralov and Krachun [STOC'19] showed that this is essentially the best possible: for any $\epsilon &gt; 0$, any (randomized) single-pass streaming algorithm that achieves an approximation ratio of at least $1/2 + \epsilon$ requires $\Omega(n / 2^{\text{poly}(1/\epsilon)})$ space. We show that it is possible to surpass the $1/2$-approximation barrier using just $O(1)$ words of space by leveraging a (machine learned) oracle. Specifically, we consider streaming algorithms that are equipped with an $\epsilon$-accurate oracle that for each vertex in the graph, returns its correct label in $\{-1, +1\}$, corresponding to an optimal MAX-CUT solution in the graph, with some probability $1/2 + \epsilon$, and the incorrect label otherwise. Within this framework, we present a single-pass algorithm that approximates the value of MAX-CUT to within a factor of $1/2 + \Omega(\epsilon^2)$ with probability at least $2/3$ for insertion-only streams, using only $\text{poly}(1/\epsilon)$ words of space. We also extend our algorithm to fully dynamic streams while maintaining a space complexity of $\text{poly}(1/\epsilon,\log n)$ words.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.09773v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yinhao Dong, Pan Peng, Ali Vakilian</dc:creator>
    </item>
    <item>
      <title>Fully Dynamic Approximate Minimum Cut in Subpolynomial Time per Operation</title>
      <link>https://arxiv.org/abs/2412.15069</link>
      <description>arXiv:2412.15069v2 Announce Type: replace 
Abstract: Dynamically maintaining the minimum cut in a graph $G$ under edge insertions and deletions is a fundamental problem in dynamic graph algorithms for which no conditional lower bound on the time per operation exists. In an $n$-node graph the best known $(1+o(1))$-approximate algorithm takes $\tilde O(\sqrt{n})$ update time [Thorup 2007]. If the minimum cut is guaranteed to be $(\log n)^{o(1)}$, a deterministic exact algorithm with $n^{o(1)}$ update time exists [Jin, Sun, Thorup 2024]. We present the first fully dynamic algorithm for $(1+o(1))$-approximate minimum cut with $n^{o(1)}$ update time. Our main technical contribution is to show that it suffices to consider small-volume cuts in suitably contracted graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.15069v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Antoine El-Hayek, Monika Henzinger, Jason Li</dc:creator>
    </item>
    <item>
      <title>The Restricted Inverse Optimal Value Problem under Weighted Bottle-neck Hamming distance on trees</title>
      <link>https://arxiv.org/abs/2412.20703</link>
      <description>arXiv:2412.20703v2 Announce Type: replace 
Abstract: We consider the Restricted Inverse Optimal Value Problem (RIOVSP) on trees under weighted bottleneck Hamming distance, denoted as (RIOVSPT$_{BH}$). The problem aims to minimize the total cost under weighted bottle-neck Hamming distance such that the length of the shortest root-leaf path of the tree is lower-bounded by a given value by adjusting the length of some edges. Additionally, the specified lower bound must correspond to the length of a particular root-leaf path. Through careful analysis of the problem's structural properties, we develop an algorithm with $O(n\log n)$ time complexity to solve (RIOVSPT$_{BH}$). Furthermore, by removing the path-length constraint, we derive the Minimum Cost Shortest Path Interdiction Problem on Trees (MCSPIT), for which we present an $O(n\log n)$ time algorithm that operates under weighted bottleneck Hamming distance. Extensive computational experiments demonstrate the efficiency and effectiveness of both algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.20703v2</guid>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qiao Zhang, Xiao Li, Xiucui Guan</dc:creator>
    </item>
    <item>
      <title>On Approximate Reconfigurability of Label Cover</title>
      <link>https://arxiv.org/abs/2304.08746</link>
      <description>arXiv:2304.08746v2 Announce Type: replace-cross 
Abstract: Given a two-prover game $G$ and its two satisfying labelings $\psi_\mathsf{ini}$ and $\psi_\mathsf{tar}$, the Label Cover Reconfiguration problem asks whether $\psi_\mathsf{ini}$ can be transformed into $\psi_\mathsf{tar}$ by repeatedly changing the label of a single vertex while preserving any intermediate labeling satisfying $G$. We consider its optimization version by relaxing the feasibility of labelings, referred to as Maxmin Label Cover Reconfiguration: We are allowed to pass through any non-satisfying labelings, but required to maximize the ``soundness error,'' which is defined as the minimum fraction of satisfied edges during transformation from $\psi_\mathsf{ini}$ to $\psi_\mathsf{tar}$. Since the parallel repetition theorem of Raz (SIAM J. Comput., 1998), which implies $\mathbf{NP}$-hardness of approximating Label Cover within any constant factor, gives strong inapproximability results for many $\mathbf{NP}$-hard problems, one may think of using Maxmin Label Cover Reconfiguration to derive inapproximability results for reconfiguration problems. We prove the following results on Maxmin Label Cover Reconfiguration, which display different trends from those of Label Cover and the parallel repetition theorem:
  $\bullet$ Maxmin Label Cover Reconfiguration can be approximated within a factor of $\frac{1}{4} - o(1)$ for some restricted graph classes, including biregular graphs, balanced bipartite graphs with no isolated vertices, and superconstant average degree graphs.
  $\bullet$ A ``naive'' parallel repetition of Maxmin Label Cover Reconfiguration does not decrease the soundness error for every two-prover game.
  $\bullet$ Label Cover Reconfiguration on projection games can be decided in polynomial time.
  Our results suggest that a reconfiguration analogue of the parallel repetition theorem is unlikely.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.08746v2</guid>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.ipl.2024.106556</arxiv:DOI>
      <dc:creator>Naoto Ohsaka</dc:creator>
    </item>
    <item>
      <title>Computing Subset Vertex Covers in $H$-Free Graphs</title>
      <link>https://arxiv.org/abs/2307.05701</link>
      <description>arXiv:2307.05701v2 Announce Type: replace-cross 
Abstract: We consider a natural generalization of Vertex Cover: the Subset Vertex Cover problem, which is to decide for a graph $G=(V,E)$, a subset $T\subseteq V$ and integer $k$, if $V$ has a subset $S$ of size at most $k$, such that $S$ contains at least one end-vertex of every edge incident to a vertex of $T$. A graph is $H$-free if it does not contain $H$ as an induced subgraph. We solve two open problems from the literature by proving that Subset Vertex Cover is NP-complete on subcubic (claw,diamond)-free planar graphs and on $2$-unipolar graphs, a subclass of $2P_3$-free weakly chordal graphs. Our results show for the first time that Subset Vertex Cover is computationally harder than Vertex Cover (under P $\neq$ NP). We also prove new polynomial time results, some of which follow from a reduction to Vertex Cover restricted to classes of probe graphs. We first give a dichotomy on graphs where $G[T]$ is $H$-free. Namely, we show that Subset Vertex Cover is polynomial-time solvable on graphs $G$, for which $G[T]$ is $H$-free, if $H=sP_1+tP_2$ and NP-complete otherwise. Moreover, we prove that Subset Vertex Cover is polynomial-time solvable for $(sP_1+P_2+P_3)$-free graphs and bounded mim-width graphs. By combining our new results with known results we obtain a partial complexity classification for Subset Vertex Cover on $H$-free graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.05701v2</guid>
      <category>math.CO</category>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nick Brettell, Jelle J. Oostveen, Sukanya Pandey, Dani\"el Paulusma, Johannes Rauch, Erik Jan van Leeuwen</dc:creator>
    </item>
    <item>
      <title>An Algorithmic Approach to Finding Degree-Doubling Nodes in Oriented Graphs</title>
      <link>https://arxiv.org/abs/2501.00614</link>
      <description>arXiv:2501.00614v2 Announce Type: replace-cross 
Abstract: Seymour's Second Neighborhood Conjecture asserts that in the square of any oriented graph, there exists a node whose out-degree at least doubles. This paper presents a definitive proof of the conjecture by introducing the GLOVER (Graph Level Order) data structure, which facilitates a systematic partitioning of neighborhoods and an analysis of degree-doubling conditions. By leveraging this structure, we construct a decreasing sequence of subsets that establish a well-ordering of nodes, ensuring that no counterexample can exist. This approach not only confirms the conjecture for all oriented graphs but also provides a novel framework for analyzing degrees and arcs in complex networks. The findings have implications for theoretical graph studies and practical applications in network optimization and algorithm design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.00614v2</guid>
      <category>math.CO</category>
      <category>cs.DS</category>
      <pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Charles Glover</dc:creator>
    </item>
  </channel>
</rss>
