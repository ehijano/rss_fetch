<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.SE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.SE</link>
    <description>cs.SE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.SE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 29 Jul 2024 04:00:12 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 29 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Rusty Linux: Advances in Rust for Linux Kernel Development</title>
      <link>https://arxiv.org/abs/2407.18431</link>
      <description>arXiv:2407.18431v1 Announce Type: new 
Abstract: Context: The integration of Rust into kernel development is a transformative endeavor aimed at enhancing system security and reliability by leveraging Rust's strong memory safety guarantees. Objective: We aim to find the current advances in using Rust in Kernel development to reduce the number of memory safety vulnerabilities in one of the most critical pieces of software that underpins all modern applications. Method: By analyzing a broad spectrum of studies, we identify the advantages Rust offers, highlight the challenges faced, and emphasize the need for community consensus on Rust's adoption. Results: Our findings suggest that while the initial implementations of Rust in the kernel show promising results in terms of safety and stability, significant challenges remain. These challenges include achieving seamless interoperability with existing kernel components, maintaining performance, and ensuring adequate support and tooling for developers. Conclusions: This study underscores the need for continued research and practical implementation efforts to fully realize the benefits of Rust. By addressing these challenges, the integration of Rust could mark a significant step forward in the evolution of operating system development towards safer and more reliable systems</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18431v1</guid>
      <category>cs.SE</category>
      <category>cs.OS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shane K. Panter, Nasir U. Eisty</dc:creator>
    </item>
    <item>
      <title>Design Spaces and How Software Designers Use Them: a sampler</title>
      <link>https://arxiv.org/abs/2407.18502</link>
      <description>arXiv:2407.18502v1 Announce Type: new 
Abstract: Discussions of software design often refer to using "design spaces" to describe the spectrum of available design alternatives. This supports design thinking in many ways: to capture domain knowledge, to support a wide variety of design activity, to analyze or predict properties of alternatives, to understand interactions and dependencies among design choices. We present a sampling of what designers, especially software designers, mean when they say "design space" and provide examples of the roles their design spaces serve in their design activity. This shows how design spaces can serve designers as lenses to reduce the overall space of possibilities and support systematic design decision making.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18502v1</guid>
      <category>cs.SE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3643660.3643941</arxiv:DOI>
      <arxiv:journal_reference>In Proceedings of the 1st International Workshop on Designing Software (Designing '24), 2024. Association for Computing Machinery, New York, NY, USA, pp. 1-8</arxiv:journal_reference>
      <dc:creator>Mary Shaw (Carnegie Mellon University), Marian Petre (Open University)</dc:creator>
    </item>
    <item>
      <title>SPOLRE: Semantic Preserving Object Layout Reconstruction for Image Captioning System Testing</title>
      <link>https://arxiv.org/abs/2407.18512</link>
      <description>arXiv:2407.18512v1 Announce Type: new 
Abstract: Image captioning (IC) systems, such as Microsoft Azure Cognitive Service, translate image content into descriptive language but can generate inaccuracies leading to misinterpretations. Advanced testing techniques like MetaIC and ROME aim to address these issues but face significant challenges. These methods require intensive manual labor for detailed annotations and often produce unrealistic images, either by adding unrelated objects or failing to remove existing ones. Additionally, they generate limited test suites, with MetaIC restricted to inserting specific objects and ROME limited to a narrow range of variations. We introduce SPOLRE, a novel automated tool for semantic-preserving object layout reconstruction in IC system testing. SPOLRE leverages four transformation techniques to modify object layouts without altering the image's semantics. This automated approach eliminates the need for manual annotations and creates realistic, varied test suites. Our tests show that over 75% of survey respondents find SPOLRE-generated images more realistic than those from state-of-the-art methods. SPOLRE excels in identifying caption errors, detecting 31,544 incorrect captions across seven IC systems with an average precision of 91.62%, surpassing other methods which average 85.65% accuracy and identify 17,160 incorrect captions. Notably, SPOLRE identified 6,236 unique issues within Azure, demonstrating its effectiveness against one of the most advanced IC systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18512v1</guid>
      <category>cs.SE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yi Liu, Guanyu Wang, Xinyi Zheng, Gelei Deng, Kailong Wang, Yang Liu, Haoyu Wang</dc:creator>
    </item>
    <item>
      <title>Patched MOA: optimizing inference for diverse software development tasks</title>
      <link>https://arxiv.org/abs/2407.18521</link>
      <description>arXiv:2407.18521v1 Announce Type: new 
Abstract: This paper introduces Patched MOA (Mixture of Agents), an inference optimization technique that significantly enhances the performance of large language models (LLMs) across diverse software development tasks. We evaluate three inference optimization algorithms - Best of N, Mixture of Agents, and Monte Carlo Tree Search and demonstrate that Patched MOA can boost the performance of smaller models to surpass that of larger, more expensive models. Notably, our approach improves the gpt-4o-mini model's performance on the Arena-Hard-Auto benchmark by 15.52%, outperforming gpt-4-turbo at a fraction of the cost. We also apply Patched MOA to various software development workflows, showing consistent improvements in task completion rates. Our method is model-agnostic, transparent to end-users, and can be easily integrated into existing LLM pipelines. This work contributes to the growing field of LLM optimization, offering a cost-effective solution for enhancing model performance without the need for fine-tuning or larger models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18521v1</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Asankhaya Sharma</dc:creator>
    </item>
    <item>
      <title>Designing Secure AI-based Systems: a Multi-Vocal Literature Review</title>
      <link>https://arxiv.org/abs/2407.18584</link>
      <description>arXiv:2407.18584v1 Announce Type: new 
Abstract: AI-based systems leverage recent advances in the field of AI/ML by combining traditional software systems with AI components. Applications are increasingly being developed in this way. Software engineers can usually rely on a plethora of supporting information on how to use and implement any given technology. For AI-based systems, however, such information is scarce. Specifically, guidance on how to securely design the architecture is not available to the extent as for other systems. We present 16 architectural security guidelines for the design of AI-based systems that were curated via a multi-vocal literature review. The guidelines could support practitioners with actionable advice on the secure development of AI-based systems. Further, we mapped the guidelines to typical components of AI-based systems and observed a high coverage where 6 out of 8 generic components have at least one guideline associated to them.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18584v1</guid>
      <category>cs.SE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Simon Schneider, Ananya Saha, Emanuele Mezzi, Katja Tuma, Riccardo Scandariato</dc:creator>
    </item>
    <item>
      <title>Evaluating Human Trajectory Prediction with Metamorphic Testing</title>
      <link>https://arxiv.org/abs/2407.18756</link>
      <description>arXiv:2407.18756v1 Announce Type: new 
Abstract: The prediction of human trajectories is important for planning in autonomous systems that act in the real world, e.g. automated driving or mobile robots. Human trajectory prediction is a noisy process, and no prediction does precisely match any future trajectory. It is therefore approached as a stochastic problem, where the goal is to minimise the error between the true and the predicted trajectory. In this work, we explore the application of metamorphic testing for human trajectory prediction. Metamorphic testing is designed to handle unclear or missing test oracles. It is well-designed for human trajectory prediction, where there is no clear criterion of correct or incorrect human behaviour. Metamorphic relations rely on transformations over source test cases and exploit invariants. A setting well-designed for human trajectory prediction where there are many symmetries of expected human behaviour under variations of the input, e.g. mirroring and rescaling of the input data. We discuss how metamorphic testing can be applied to stochastic human trajectory prediction and introduce the Wasserstein Violation Criterion to statistically assess whether a follow-up test case violates a label-preserving metamorphic relation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18756v1</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3679006.3685071</arxiv:DOI>
      <dc:creator>Helge Spieker, Nassim Belmecheri, Arnaud Gotlieb, Nadjib Lazaar</dc:creator>
    </item>
    <item>
      <title>Foundation Models for the Digital Twin Creation of Cyber-Physical Systems</title>
      <link>https://arxiv.org/abs/2407.18779</link>
      <description>arXiv:2407.18779v1 Announce Type: new 
Abstract: Foundation models are trained on a large amount of data to learn generic patterns. Consequently, these models can be used and fine-tuned for various purposes. Naturally, studying such models' use in the context of digital twins for cyber-physical systems (CPSs) is a relevant area of investigation. To this end, we provide perspectives on various aspects within the context of developing digital twins for CPSs, where foundation models can be used to increase the efficiency of creating digital twins, improve the effectiveness of the capabilities they provide, and used as specialized fine-tuned foundation models acting as digital twins themselves. We also discuss challenges in using foundation models in a more generic context. We use the case of an autonomous driving system as a representative CPS to give examples. Finally, we provide discussions and open research directions that we believe are valuable for the digital twin community.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18779v1</guid>
      <category>cs.SE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shaukat Ali, Paolo Arcaini, Aitor Arrieta</dc:creator>
    </item>
    <item>
      <title>Code Structure-Aware through Line-level Semantic Learning for Code Vulnerability Detection</title>
      <link>https://arxiv.org/abs/2407.18877</link>
      <description>arXiv:2407.18877v1 Announce Type: new 
Abstract: Different from the flow semantics of natural languages, programming languages are inherently rigid in structure and grammar. Existing fine-tuning methodologies for code vulnerability detection generally treat code as long text sequences, stripping away structural elements such as newlines ('/n') and whitespace. However, this approach inadvertently results in the loss of crucial structural information, diminishing the distinct characteristics of code and impairing the accuracy of vulnerability detection. To address these challenges, we propose a novel network architecture method based on pre-trained code models, which incorporates structural information awareness. We propose an enhanced code text processing workflow that retains structural elements prior to modeling. This refinement allows the model to retain and exploit line-level structural information and semantic information during the modeling process. Furthermore, we introduce a new network architecture, the Code Structure-Aware Network through Line-level Semantic Learning (CSLS), which integrates three key components: global vulnerability awareness, line-structural awareness, and sensitive-line awareness. We have conducted comprehensive experiments using vulnerability detection datasets from real-world projects. Extensive experiments were conducted on vulnerability detection datasets derived from real-world projects. The results demonstrate that our new code pre-processing flow significantly improves existing baselines (e.g., a 3\% accuracy improvement on the Devign dataset when applied to popular models such as CoderBert and UniXcoder). The proposed network architecture also demonstrates superior accuracy in detecting vulnerabilities, surpassing newly established benchmarks. These findings underscore the importance of structural information in enhancing the efficacy of code vulnerability detection models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18877v1</guid>
      <category>cs.SE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Ziliang Wang, Ge Li, Jia Li, Yihong Dong, Yingfei Xiong, Zhi Jin</dc:creator>
    </item>
    <item>
      <title>Semistructured Merge with Language-Specific Syntactic Separators</title>
      <link>https://arxiv.org/abs/2407.18888</link>
      <description>arXiv:2407.18888v1 Announce Type: new 
Abstract: Structured merge tools exploit programming language syntactic structure to enhance merge accuracy by reducing spurious conflicts reported by unstructured tools. By creating and handling full ASTs, structured tools are language-specific and harder to implement. They can also be computationally expensive when merging large files.To reduce these drawbacks, semistructured merge tools work with partial ASTs that use strings to represent lower level syntactic structures such as method bodies, and rely on unstructured tools to merge them. This, however, results in merge accuracy loss. To improve accuracy without compromising semistructured merge benefits, we propose a tool that leverages language-specific syntactic separators to infer structure without parsing. We still resort to an unstructured tool to merge lower level structures, but only after preprocessing the code so that text in between separators such as curly braces appear in separate lines. This way we emulate the capabilities of structured merge tools while avoiding their drawbacks. By comparing our tool with a robust implementation of semistructured merge, we find that our tool substantially reduces the number of spurious conflicts. We also observe significant but less substantial reductions on the overall number of reported conflicts, and of files with conflicts. However, similar to structured tools, our tool lets more merge conflicts go undetected. Our tool shows significant improvements over unstructured tools widely used in practice. Finally we observe that exploiting language-specific syntactic separators introduces unique textual alignment challenges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18888v1</guid>
      <category>cs.SE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Guilherme Cavalcanti, Paulo Borba, Leonardo dos Anjos, Jonatas Clementino</dc:creator>
    </item>
    <item>
      <title>AppWorld: A Controllable World of Apps and People for Benchmarking Interactive Coding Agents</title>
      <link>https://arxiv.org/abs/2407.18901</link>
      <description>arXiv:2407.18901v1 Announce Type: new 
Abstract: Autonomous agents that address day-to-day digital tasks (e.g., ordering groceries for a household), must not only operate multiple apps (e.g., notes, messaging, shopping app) via APIs, but also generate rich code with complex control flow in an iterative manner based on their interaction with the environment. However, existing benchmarks for tool use are inadequate, as they only cover tasks that require a simple sequence of API calls.
  To remedy this gap, we built $\textbf{AppWorld Engine}$, a high-quality execution environment (60K lines of code) of 9 day-to-day apps operable via 457 APIs and populated with realistic digital activities simulating the lives of ~100 fictitious users. We then created $\textbf{AppWorld Benchmark}$ (40K lines of code), a suite of 750 natural, diverse, and challenging autonomous agent tasks requiring rich and interactive code generation. It supports robust programmatic evaluation with state-based unit tests, allowing for different ways of completing a task while also checking for unexpected changes, i.e., collateral damage. The state-of-the-art LLM, GPT-4o, solves only ~49% of our 'normal' tasks and ~30% of 'challenge' tasks, while other models solve at least 16% fewer. This highlights the benchmark's difficulty and AppWorld's potential to push the frontiers of interactive coding agents. The project website is available at https://appworld.dev/.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18901v1</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Harsh Trivedi, Tushar Khot, Mareike Hartmann, Ruskin Manku, Vinty Dong, Edward Li, Shashank Gupta, Ashish Sabharwal, Niranjan Balasubramanian</dc:creator>
    </item>
    <item>
      <title>SWARM-SLR -- Streamlined Workflow Automation for Machine-actionable Systematic Literature Reviews</title>
      <link>https://arxiv.org/abs/2407.18657</link>
      <description>arXiv:2407.18657v1 Announce Type: cross 
Abstract: Authoring survey or review articles still requires significant tedious manual effort, despite many advancements in research knowledge management having the potential to improve efficiency, reproducibility, and reuse. However, these advancements bring forth an increasing number of approaches, tools, and systems, which often cover only specific stages and lack a comprehensive workflow utilizing their task-specific strengths. We propose the Streamlined Workflow Automation for Machine-actionable Systematic Literature Reviews (SWARM-SLR) to crowdsource the improvement of SLR efficiency while maintaining scientific integrity in a state-of-the-art knowledge discovery and distribution process. The workflow aims to domain-independently support researchers in collaboratively and sustainably managing the rising scholarly knowledge corpus. By synthesizing guidelines from the literature, we have composed a set of 65 requirements, spanning from planning to reporting a review. Existing tools were assessed against these requirements and synthesized into the SWARM-SLR workflow prototype, a ready-for-operation software support tool. The SWARM-SLR was evaluated via two online surveys, which largely confirmed the validity of the 65 requirements and situated 11 tools to the different life-cycle stages. The SWARM-SLR workflow was similarly evaluated and found to be supporting almost the entire span of an SLR, excelling specifically in search and retrieval, information extraction, knowledge synthesis, and distribution. Our SWARM-SLR requirements and workflow support tool streamlines the SLR support for researchers, allowing sustainable collaboration by linking individual efficiency improvements to crowdsourced knowledge management. If these efforts are continued, we expect the increasing number of tools to be manageable and usable inside fully structured, (semi-)automated literature review workflows.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18657v1</guid>
      <category>cs.DL</category>
      <category>cs.SE</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tim Wittenborg, Oliver Karras, S\"oren Auer</dc:creator>
    </item>
    <item>
      <title>Designing and Implementing a Generator Framework for a SIMD Abstraction Library</title>
      <link>https://arxiv.org/abs/2407.18728</link>
      <description>arXiv:2407.18728v1 Announce Type: cross 
Abstract: The Single Instruction Multiple Data (SIMD) parallel paradigm is a well-established and heavily-used hardware-driven technique to increase the single-thread performance in different system domains such as database or machine learning. Depending on the hardware vendor and the specific processor generation/version, SIMD capabilities come in different flavors concerning the register size and the supported SIMD instructions. Due to this heterogeneity and the lack of standardized calling conventions, building high-performance and portable systems is a challenging task. To address this challenge, academia and industry have invested a remarkable effort into creating SIMD abstraction libraries that provide unified access to different SIMD hardware capabilities. However, those one-size-fits-all library approaches are inherently complex, which hampers maintainability and extensibility. Furthermore, they assume similar SIMD hardware designs, which may be invalidated through ARM SVE's emergence. Additionally, while existing SIMD abstraction libraries do a great job of hiding away the specifics of the underlying hardware, their lack of expressiveness impedes crucial algorithm design decisions for system developers. To overcome these limitations, we present TSLGen, a novel end-to-end framework approach for generating an SIMD abstraction library in this paper. We have implemented our TSLGen framework and used our generated Template SIMD Library (TSL) to program various system components from different domains. As we will show, the programming effort is comparable to existing libraries, and we achieve the same performance results. However, our framework is easy to maintain and to extend, which simultaneously supports disruptive changes to the interface by design and exposes valuable insights for assessing provided functionality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18728v1</guid>
      <category>cs.DB</category>
      <category>cs.SE</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Johannes Pietrzyk, Alexander Krause, Dirk Habich, Wolfgang Lehner</dc:creator>
    </item>
    <item>
      <title>Multi-Robot System Architecture design in SysML and BPMN</title>
      <link>https://arxiv.org/abs/2407.18749</link>
      <description>arXiv:2407.18749v1 Announce Type: cross 
Abstract: Multi-Robot System (MRS) is a complex system that contains many different software and hardware components. This main problem addressed in this article is the MRS design complexity. The proposed solution provides a modular modeling and simulation technique that is based on formal system engineering method, therefore the MRS design complexity is decomposed and reduced. Modeling the MRS has been achieved via two formal Architecture Description Languages (ADLs), which are Systems Modeling Language (SysML) and Business Process Model and Notation (BPMN), to design the system blueprints. By using those abstract design ADLs, the implementation of the project becomes technology agnostic. This allows to transfer the design concept from on programming language to another. During the simulation phase, a multi-agent environment is used to simulate the MRS blueprints. The simulation has been implemented in Java Agent Development (JADE) middleware. Therefore, its results can be used to analysis and verify the proposed MRS model in form of performance evaluation matrix.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18749v1</guid>
      <category>cs.AI</category>
      <category>cs.RO</category>
      <category>cs.SE</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>https://doi.org/10.25046/aj060421</arxiv:DOI>
      <arxiv:journal_reference>2022 Advances in Science, Technology and Engineering Systems Journal (ASTESJ) - Special Issue on Multidisciplinary Sciences and Engineering</arxiv:journal_reference>
      <dc:creator>Ahmed R. Sadik (Honda Research Institute Europe, Offenbach am Main, Germany), Christian Goerick (Honda Research Institute Europe, Offenbach am Main, Germany)</dc:creator>
    </item>
    <item>
      <title>Java-Class-Hijack: Software Supply Chain Attack for Java based on Maven Dependency Resolution and Java Classloading</title>
      <link>https://arxiv.org/abs/2407.18760</link>
      <description>arXiv:2407.18760v1 Announce Type: cross 
Abstract: We introduce Java-Class-Hijack, a novel software supply chain attack that enables an attacker to inject malicious code by crafting a class that shadows a legitimate class that is in the dependency tree. We describe the attack, provide a proof-of-concept demonstrating its feasibility, and replicate it in the German Corona-Warn-App server application. The proof-of-concept illustrates how a transitive dependency deep within the dependency tree can hijack a class from a direct dependency and entirely alter its behavior, posing a significant security risk to Java applications. The replication on the Corona-Warn-App demonstrates how compromising a small JSON validation library could result in a complete database takeover.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18760v1</guid>
      <category>cs.CR</category>
      <category>cs.SE</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Federico Bono, Frank Reyes, Aman Sharma, Benoit Baudry, Martin Monperrus</dc:creator>
    </item>
    <item>
      <title>RCAgent: Cloud Root Cause Analysis by Autonomous Agents with Tool-Augmented Large Language Models</title>
      <link>https://arxiv.org/abs/2310.16340</link>
      <description>arXiv:2310.16340v2 Announce Type: replace 
Abstract: Large language model (LLM) applications in cloud root cause analysis (RCA) have been actively explored recently. However, current methods are still reliant on manual workflow settings and do not unleash LLMs' decision-making and environment interaction capabilities. We present RCAgent, a tool-augmented LLM autonomous agent framework for practical and privacy-aware industrial RCA usage. Running on an internally deployed model rather than GPT families, RCAgent is capable of free-form data collection and comprehensive analysis with tools. Our framework combines a variety of enhancements, including a unique Self-Consistency for action trajectories, and a suite of methods for context management, stabilization, and importing domain knowledge. Our experiments show RCAgent's evident and consistent superiority over ReAct across all aspects of RCA -- predicting root causes, solutions, evidence, and responsibilities -- and tasks covered or uncovered by current rules, as validated by both automated metrics and human evaluations. Furthermore, RCAgent has already been integrated into the diagnosis and issue discovery workflow of the Real-time Compute Platform for Apache Flink of Alibaba Cloud.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.16340v2</guid>
      <category>cs.SE</category>
      <category>cs.CL</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3627673.3680016</arxiv:DOI>
      <dc:creator>Zefan Wang, Zichuan Liu, Yingying Zhang, Aoxiao Zhong, Jihong Wang, Fengbin Yin, Lunting Fan, Lingfei Wu, Qingsong Wen</dc:creator>
    </item>
    <item>
      <title>Automated Description Generation for Software Patches</title>
      <link>https://arxiv.org/abs/2402.03805</link>
      <description>arXiv:2402.03805v2 Announce Type: replace 
Abstract: Software patches are pivotal in refining and evolving codebases, addressing bugs, vulnerabilities, and optimizations. Patch descriptions provide detailed accounts of changes, aiding comprehension and collaboration among developers. However, manual description creation poses challenges in terms of time consumption and variations in quality and detail. In this paper, we propose PATCHEXPLAINER, an approach that addresses these challenges by framing patch description generation as a machine translation task. In PATCHEXPLAINER, we leverage explicit representations of critical elements, historical context, and syntactic conventions. Moreover, the translation model in PATCHEXPLAINER is designed with an awareness of description similarity. Particularly, the model is explicitly trained to recognize and incorporate similarities present in patch descriptions clustered into groups, improving its ability to generate accurate and consistent descriptions across similar patches. The dual objectives maximize similarity and accurately predict affiliating groups. Our experimental results on a large dataset of real-world software patches show that PATCHEXPLAINER consistently outperforms existing methods, with improvements up to 189% in BLEU, 5.7X in Exact Match rate, and 154% in Semantic Similarity, affirming its effectiveness in generating software patch descriptions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.03805v2</guid>
      <category>cs.SE</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thanh Trong Vu, Tuan-Dung Bui, Thanh-Dat Do, Thu-Trang Nguyen, Hieu Dinh Vo, Son Nguyen</dc:creator>
    </item>
    <item>
      <title>Cross-Language Dependencies: An Empirical Study of Kotlin-Java</title>
      <link>https://arxiv.org/abs/2405.04602</link>
      <description>arXiv:2405.04602v2 Announce Type: replace 
Abstract: Background: Since Google introduced Kotlin as an official programming language for developing Android apps in 2017, Kotlin has gained widespread adoption in Android development. The inter-operability of Java and Kotlin's design nature allows them to coexist and interact with each other smoothly within a project. Aims: However, there is limited research on how Java and Kotlin interact with each other in real-world projects and what challenges are faced during these interactions. The answers to these questions are key to understanding these kinds of cross-language software systems. Methods: In this paper, we implemented a tool named DependEx-tractor, which can extract 11 kinds of Kotlin-Java dependencies, and conducted an empirical study of 23 Kotlin-Java real-world projects with 3,227 Java and 8,630 Kotlin source files. Results: Our findings revealed that Java and Kotlin frequently interact with each other in these cross-language projects, with access and call dependency types being the most dominant. Compared to files interacting with other files in the same language, Java/Kotlin source files, which participate in the cross-language interactions, undergo more commits. Additionally, among all Kotlin-Java problematic interactions, we identified seven common mistakes, along with their fixing strategies. Conclusions: The findings of this study can help developers understand and address the challenges in Kotlin-Java projects.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04602v2</guid>
      <category>cs.SE</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qiong Feng, Huan Ji, Xiaotian Ma, Peng Liang</dc:creator>
    </item>
  </channel>
</rss>
