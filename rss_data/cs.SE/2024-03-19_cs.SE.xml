<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.SE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.SE</link>
    <description>cs.SE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.SE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 19 Mar 2024 04:00:10 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 19 Mar 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Exploring Language Model's Code Generation Ability with Auxiliary Functions</title>
      <link>https://arxiv.org/abs/2403.10575</link>
      <description>arXiv:2403.10575v1 Announce Type: new 
Abstract: Auxiliary function is a helpful component to improve language model's code generation ability. However, a systematic exploration of how they affect has yet to be done. In this work, we comprehensively evaluate the ability to utilize auxiliary functions encoded in recent code-pretrained language models. First, we construct a human-crafted evaluation set, called HumanExtension, which contains examples of two functions where one function assists the other. With HumanExtension, we design several experiments to examine their ability in a multifaceted way. Our evaluation processes enable a comprehensive understanding of including auxiliary functions in the prompt in terms of effectiveness and robustness. An additional implementation style analysis captures the models' various implementation patterns when they access the auxiliary function. Through this analysis, we discover the models' promising ability to utilize auxiliary functions including their self-improving behavior by implementing the two functions step-by-step. However, our analysis also reveals the model's underutilized behavior to call the auxiliary function, suggesting the future direction to enhance their implementation by eliciting the auxiliary function call ability encoded in the models. We release our code and dataset to facilitate this research direction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.10575v1</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Seonghyeon Lee, Sanghwan Jang, Seongbo Jang, Dongha Lee, Hwanjo Yu</dc:creator>
    </item>
    <item>
      <title>S3LLM: Large-Scale Scientific Software Understanding with LLMs using Source, Metadata, and Document</title>
      <link>https://arxiv.org/abs/2403.10588</link>
      <description>arXiv:2403.10588v1 Announce Type: new 
Abstract: The understanding of large-scale scientific software poses significant challenges due to its diverse codebase, extensive code length, and target computing architectures. The emergence of generative AI, specifically large language models (LLMs), provides novel pathways for understanding such complex scientific codes. This paper presents S3LLM, an LLM-based framework designed to enable the examination of source code, code metadata, and summarized information in conjunction with textual technical reports in an interactive, conversational manner through a user-friendly interface. S3LLM leverages open-source LLaMA-2 models to enhance code analysis through the automatic transformation of natural language queries into domain-specific language (DSL) queries. Specifically, it translates these queries into Feature Query Language (FQL), enabling efficient scanning and parsing of entire code repositories. In addition, S3LLM is equipped to handle diverse metadata types, including DOT, SQL, and customized formats. Furthermore, S3LLM incorporates retrieval augmented generation (RAG) and LangChain technologies to directly query extensive documents. S3LLM demonstrates the potential of using locally deployed open-source LLMs for the rapid understanding of large-scale scientific computing software, eliminating the need for extensive coding expertise, and thereby making the process more efficient and effective. S3LLM is available at https://github.com/ResponsibleAILab/s3llm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.10588v1</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Kareem Shaik, Dali Wang, Weijian Zheng, Qinglei Cao, Heng Fan, Peter Schwartz, Yunhe Feng</dc:creator>
    </item>
    <item>
      <title>The Impact Of Bug Localization Based on Crash Report Mining: A Developers' Perspective</title>
      <link>https://arxiv.org/abs/2403.10753</link>
      <description>arXiv:2403.10753v1 Announce Type: new 
Abstract: Developers often use crash reports to understand the root cause of bugs. However, locating the buggy source code snippet from such information is a challenging task, mainly when the log database contains many crash reports. To mitigate this issue, recent research has proposed and evaluated approaches for grouping crash report data and using stack trace information to locate bugs. The effectiveness of such approaches has been evaluated by mainly comparing the candidate buggy code snippets with the actual changed code in bug-fix commits -- which happens in the context of retrospective repository mining studies. Therefore, the existing literature still lacks discussing the use of such approaches in the daily life of a software company, which could explain the developers' perceptions on the use of these approaches. In this paper, we report our experience of using an approach for grouping crash reports and finding buggy code on a weekly basis for 18 months, within three development teams in a software company. We grouped over 750,000 crash reports, opened over 130 issues, and collected feedback from 18 developers and team leaders. Among other results, we observe that the amount of system logs related to a crash report group is not the only criteria developers use to choose a candidate bug to be analyzed. Instead, other factors were considered, such as the need to deliver customer-prioritized features and the difficulty of solving complex crash reports (e.g., architectural debts), to cite some. The approach investigated in this study correctly suggested the buggy file most of the time -- the approach's precision was around 80%. In this study, the developers also shared their perspectives on the usefulness of the suspicious files and methods extracted from crash reports to fix related bugs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.10753v1</guid>
      <category>cs.SE</category>
      <category>cs.IR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3639477.3639730</arxiv:DOI>
      <dc:creator>Marcos Medeiros, Uir\'a Kulesza, Roberta Coelho, Rodrigo Bonif\'acio, Christoph Treude, Eiji Adachi</dc:creator>
    </item>
    <item>
      <title>Developers' Perception: Fixed Bugs Often Overlooked as Quality Contributions</title>
      <link>https://arxiv.org/abs/2403.10806</link>
      <description>arXiv:2403.10806v1 Announce Type: new 
Abstract: High-quality software products rely on both well-written source code and timely detection and thorough reporting of bugs. However, some programmers view bug reports as negative assessments of their work, leading them to withhold reporting bugs, thereby detrimentally impacting projects. Through a survey of 102 programmers, we discovered that only a third of them perceive the quantity of bugs found and rectified in a repository as indicative of higher quality. This finding substantiates the notion that programmers often misinterpret the significance of testing and bug reporting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.10806v1</guid>
      <category>cs.SE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vitaly Alifanov, Kamil Almetov, Ivan Kornienko, Arsen Mutalapov, Yegor Bugayenko</dc:creator>
    </item>
    <item>
      <title>IPSynth: Interprocedural Program Synthesis for Software Security Implementation</title>
      <link>https://arxiv.org/abs/2403.10836</link>
      <description>arXiv:2403.10836v1 Announce Type: new 
Abstract: To implement important quality attributes of software such as architectural security tactics, developers incorporate API of software frameworks, as building blocks, to avoid re-inventing the wheel and improve their productivity. However, this is a challenging and error-prone task, especially for novice programmers. Despite the advances in the field of API-based program synthesis, the state-of-the-art suffers from a twofold shortcoming when it comes to architectural tactic implementation tasks. First, the specification of the desired tactic must be explicitly expressed, which is out of the knowledge of such programmers. Second, these approaches synthesize a block of code and leave the task of breaking it down into smaller pieces, adding each piece to the proper location in the code, and establishing correct dependencies between each piece and its surrounding environment as well as the other pieces, to the programmer.
  To mitigate these challenges, we introduce IPSynth, a novel inter-procedural program synthesis approach that automatically learns the specification of the tactic, synthesizes the tactic as inter-related code snippets, and adds them to an existing code base. We extend our first-place award-winning extended abstract recognized at the 36th IEEE/ACM International Conference on Automated Software Engineering (ASE'21) research competition track. In this paper, we provide the details of the approach, present the results of the experimental evaluation of IPSynth, and analyses and insights for a more comprehensive exploration of the research topic. Moreover, we compare the results of our approach to one of the most powerful code generator tools, ChatGPT. Our results show that our approach can accurately locate corresponding spots in the program, synthesize needed code snippets, add them to the program, and outperform ChatGPT in inter-procedural tactic synthesis tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.10836v1</guid>
      <category>cs.SE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ali Shokri, Ibrahim Jameel Mujhid, Mehdi Mirakhorli</dc:creator>
    </item>
    <item>
      <title>A Hypergraph-based Formalization of Hierarchical Reactive Modules and a Compositional Verification Method</title>
      <link>https://arxiv.org/abs/2403.10919</link>
      <description>arXiv:2403.10919v1 Announce Type: new 
Abstract: The compositional approach is important for reasoning about large and complex systems. In this work, we address synchronous systems with hierarchical structures, which are often used to model cyber-physical systems. We revisit the theory of reactive modules and reformulate it based on hypergraphs to clarify the parallel composition and the hierarchical description of modules. Then, we propose an automatic verification method for hierarchical systems. Given a system description annotated with assume-guarantee contracts, the proposed method divides the system into modules and verifies them separately to show that the top-level system satisfies its contract. Our method allows an input to be a circular system in which submodules mutually depend on each other. Experimental result shows our method can be effectively implemented using an SMT-based model checker.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.10919v1</guid>
      <category>cs.SE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daisuke Ishii</dc:creator>
    </item>
    <item>
      <title>Bridging Expert Knowledge with Deep Learning Techniques for Just-In-Time Defect Prediction</title>
      <link>https://arxiv.org/abs/2403.11079</link>
      <description>arXiv:2403.11079v1 Announce Type: new 
Abstract: Just-In-Time (JIT) defect prediction aims to automatically predict whether a commit is defective or not, and has been widely studied in recent years. In general, most studies can be classified into two categories: 1) simple models using traditional machine learning classifiers with hand-crafted features, and 2) complex models using deep learning techniques to automatically extract features from commit contents. Hand-crafted features used by simple models are based on expert knowledge but may not fully represent the semantic meaning of the commits. On the other hand, deep learning-based features used by complex models represent the semantic meaning of commits but may not reflect useful expert knowledge. Simple models and complex models seem complementary to each other to some extent. To utilize the advantages of both simple and complex models, we propose a model fusion framework that adopts both early fusions on the feature level and late fusions on the decision level. We propose SimCom++ by adopting the best early and late fusion strategies. The experimental results show that SimCom++ can significantly outperform the baselines by 5.7--26.9\%. In addition, our experimental results confirm that the simple model and complex model are complementary to each other.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11079v1</guid>
      <category>cs.SE</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xin Zhou, DongGyun Han, David Lo</dc:creator>
    </item>
    <item>
      <title>An Empirical Study on JIT Defect Prediction Based on BERT-style Model</title>
      <link>https://arxiv.org/abs/2403.11158</link>
      <description>arXiv:2403.11158v1 Announce Type: new 
Abstract: Previous works on Just-In-Time (JIT) defect prediction tasks have primarily applied pre-trained models directly, neglecting the configurations of their fine-tuning process. In this study, we perform a systematic empirical study to understand the impact of the settings of the fine-tuning process on BERT-style pre-trained model for JIT defect prediction. Specifically, we explore the impact of different parameter freezing settings, parameter initialization settings, and optimizer strategies on the performance of BERT-style models for JIT defect prediction. Our findings reveal the crucial role of the first encoder layer in the BERT-style model and the project sensitivity to parameter initialization settings. Another notable finding is that the addition of a weight decay strategy in the Adam optimizer can slightly improve model performance. Additionally, we compare performance using different feature extractors (FCN, CNN, LSTM, transformer) and find that a simple network can achieve great performance. These results offer new insights for fine-tuning pre-trained models for JIT defect prediction. We combine these findings to find a cost-effective fine-tuning method based on LoRA, which achieve a comparable performance with only one-third memory consumption than original fine-tuning process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11158v1</guid>
      <category>cs.SE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuxiang Guo, Xiaopeng Gao, Bo Jiang</dc:creator>
    </item>
    <item>
      <title>Efficiently Detecting Reentrancy Vulnerabilities in Complex Smart Contracts</title>
      <link>https://arxiv.org/abs/2403.11254</link>
      <description>arXiv:2403.11254v1 Announce Type: new 
Abstract: Reentrancy vulnerability as one of the most notorious vulnerabilities, has been a prominent topic in smart contract security research. Research shows that existing vulnerability detection presents a range of challenges, especially as smart contracts continue to increase in complexity. Existing tools perform poorly in terms of efficiency and successful detection rates for vulnerabilities in complex contracts. To effectively detect reentrancy vulnerabilities in contracts with complex logic, we propose a tool named SliSE. SliSE's detection process consists of two stages: Warning Search and Symbolic Execution Verification. In Stage I, SliSE utilizes program slicing to analyze the Inter-contract Program Dependency Graph (I-PDG) of the contract, and collects suspicious vulnerability information as warnings. In Stage II, symbolic execution is employed to verify the reachability of these warnings, thereby enhancing vulnerability detection accuracy. SliSE obtained the best performance compared with eight state-of-the-art detection tools. It achieved an F1 score of 78.65%, surpassing the highest score recorded by an existing tool of 9.26%. Additionally, it attained a recall rate exceeding 90% for detection of contracts on Ethereum. Overall, SliSE provides a robust and efficient method for detection of Reentrancy vulnerabilities for complex contracts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11254v1</guid>
      <category>cs.SE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zexu Wang, Jiachi Chen, Yanlin Wang, Yu Zhang, Weizhe Zhang, Zibin Zheng</dc:creator>
    </item>
    <item>
      <title>Java JIT Testing with Template Extraction</title>
      <link>https://arxiv.org/abs/2403.11281</link>
      <description>arXiv:2403.11281v1 Announce Type: new 
Abstract: We present LeJit, a template-based framework for testing Java just-in-time (JIT) compilers. Like recent template-based frameworks, LeJit executes a template -- a program with holes to be filled -- to generate concrete programs given as inputs to Java JIT compilers. LeJit automatically generates template programs from existing Java code by converting expressions to holes, as well as generating necessary glue code (i.e., code that generates instances of non-primitive types) to make generated templates executable. We have successfully used LeJit to test a range of popular Java JIT compilers, revealing five bugs in HotSpot, nine bugs in OpenJ9, and one bug in GraalVM. All of these bugs have been confirmed by Oracle and IBM developers, and 11 of these bugs were previously unknown, including two CVEs (Common Vulnerabilities and Exposures). Our comparison with several existing approaches shows that LeJit is complementary to them and is a powerful technique for ensuring Java JIT compiler correctness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11281v1</guid>
      <category>cs.SE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3643777</arxiv:DOI>
      <dc:creator>Zhiqiang Zang, Fu-Yao Yu, Aditya Thimmaiah, August Shi, Milos Gligoric</dc:creator>
    </item>
    <item>
      <title>Pattern-Based Peephole Optimizations with Java JIT Tests</title>
      <link>https://arxiv.org/abs/2403.11283</link>
      <description>arXiv:2403.11283v1 Announce Type: new 
Abstract: We present JOG, a framework that facilitates developing Java JIT peephole optimizations alongside JIT tests. JOG enables developers to write a pattern, in Java itself, that specifies desired code transformations by writing code before and after the optimization, as well as any necessary preconditions. Such patterns can be written in the same way that tests of the optimization are already written in OpenJDK. JOG translates each pattern into C/C++ code that can be integrated as a JIT optimization pass. JOG also generates Java tests for optimizations from patterns. Furthermore, JOG can automatically detect possible shadow relation between a pair of optimizations where the effect of the shadowed optimization is overridden by another. Our evaluation shows that JOG makes it easier to write readable JIT optimizations alongside tests without decreasing the effectiveness of JIT optimizations. We wrote 162 patterns, including 68 existing optimizations in OpenJDK, 92 new optimizations adapted from LLVM, and two new optimizations that we proposed. We opened eight pull requests (PRs) for OpenJDK, including six for new optimizations, one on removing shadowed optimizations, and one for newly generated JIT tests; seven PRs have already been integrated into the master branch of OpenJDK.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11283v1</guid>
      <category>cs.SE</category>
      <category>cs.PL</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3597926.3598038</arxiv:DOI>
      <dc:creator>Zhiqiang Zang, Aditya Thimmaiah, Milos Gligoric</dc:creator>
    </item>
    <item>
      <title>On the Integration of Spectrum-Based Fault Localization Tools into IDEs</title>
      <link>https://arxiv.org/abs/2403.11538</link>
      <description>arXiv:2403.11538v1 Announce Type: new 
Abstract: Spectrum-Based Fault Localization (SBFL) is a technique to be used during debugging, the premise of which is that, based on the test case outcomes and code coverage, faulty code elements can be automatically detected. SBFL is popular among researchers because it is lightweight and easy to implement, and there is a lot of potential in it when it comes to research that aims to improve its effectiveness. Despite this, the technique cannot be found in contemporary development and debugging tools, only a handful of research prototypes are available. Reasons for this can be multiple, including the algortihms' sub-optimal effectiveness and other technical weaknesses. But, also the lack of clear functional and non-functional requirements for such a tool, either standalone or integrated into IDEs. In this paper, we attempt to provide such a list in form of recommendations, based on surveying the most popular SBFL tools and on our own researchers' and tool builders' experience.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11538v1</guid>
      <category>cs.SE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Attila Szatm\'ari, Qusay Idrees Sarhan, Gerg\H{o} Balogh, P\'eter Attila Soha, \'Arp\'ad Besz\'edes</dc:creator>
    </item>
    <item>
      <title>Advancing Quantum Software Engineering: A Vision of Hybrid Full-Stack Iterative Model</title>
      <link>https://arxiv.org/abs/2403.11670</link>
      <description>arXiv:2403.11670v1 Announce Type: new 
Abstract: This paper introduces a vision for Quantum Software Develop- ment lifecycle, proposing a hybrid full-stack iterative model that integrates quantum and classical computing. Addressing the cur- rent challenges in Quantum Computing (QC) such as the need for integrating diverse programming languages and managing the complexities of quantum-classical systems, this model is rooted in the principles of DevOps and continuous software engineering. It presents a comprehensive lifecycle for quantum software develop- ment, encompassing quantum-agnostic coding, testing, deployment, cloud computing services, orchestration, translation, execution, and interpretation phases. Each phase is designed to accommodate the unique demands of QC, enabling traditional software developers to engage with QC environments without needing in-depth QC expertise. The paper presents a detailed implementation roadmap, utilizing a range of existing tools and frameworks, thereby making quantum software development more accessible and efficient. The proposed model not only addresses current challenges in quantum software development but also makes a substantial contribution to the field of Quantum Software Engineering (QSE). By propos- ing a structured and accessible model, it sets the stage for further advancements and research in QSE, enhancing its practicality and relevance in a wide range of applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11670v1</guid>
      <category>cs.SE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arif Ali Khan, Davide Taibi, C\'ecile M. Perrault, Asif Ali Khan</dc:creator>
    </item>
    <item>
      <title>Demystifying the DAO Governance Process</title>
      <link>https://arxiv.org/abs/2403.11758</link>
      <description>arXiv:2403.11758v1 Announce Type: new 
Abstract: Decentralized Autonomous Organization (DAO) becomes a popular governance solution for decentralized applications (dApps) to achieve decentralized governance. In the DAO, no single entity can arbitrarily control the dApps without approval from the majority of members. However, despite its advantages, DAO has also been targeted by several attacks, leading to the loss of millions of dollars. In this paper, we first provided an overview of the DAO governance process within the blockchain. Next, we identified the issues within three components of governance process: Governance Contract, Documentation, and Proposal. Each of these components is vulnerable to issues that could potentially result in substantial financial losses. Then we developed automated methods to detected above issues. To investigate the issues within the existing DAO ecosystem, we constructed a state-of-the-art dataset that includes 16,427 DAOs, 183 documentation, and 122,307 proposals across 9 different blockchains. Our analysis reveals that a majority of DAO developers and members have not given sufficient attention to these issues, especially in the area of proposal. The result shows that over 60% of the examined proposals fail to provide a consistent description and code for their members, highlighting a significant gap in ensuring transparency within the DAO governance process. For a better DAO governance ecosystem, DAO developers and members can utilize the methods to identify and address issues within governance process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11758v1</guid>
      <category>cs.SE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junjie Ma, Muhui Jiang, Jinan Jiang, Xiapu Luo, Yufeng Hu, Yajin Zhou, Qi Wang, Fengwei Zhang</dc:creator>
    </item>
    <item>
      <title>EmpowerAbility: A portal for employment &amp; scholarships for differently-abled</title>
      <link>https://arxiv.org/abs/2403.11769</link>
      <description>arXiv:2403.11769v1 Announce Type: new 
Abstract: The internet has become a vital resource for job seekers in today's technologically advanced world, particularly for those with impairments. They mainly rely on internet resources to find jobs that fit their particular requirements and skill set. Though some disabled candidates receive prompt responses and job offers, others find it difficult to traverse the intricate world of job portals, the efficacy of this process frequently varies. This discrepancy results from a typical error: a failure to completely comprehend and utilize the accessibility features and functions that can significantly expedite and simplify the job search process for people with impairments.This project is a job and scholarship portal that empowers individuals with diverse abilities. Through inspiring success stories, user-centric features, and practical opportunities, it fosters resilience and inclusivity while reshaping narratives. This platform's dual-pronged strategy instills pride and offers real-world solutions, making a lasting impact on the lives it touches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11769v1</guid>
      <category>cs.SE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Himanshu Raj, Shubham Kumar, Dr. J Kalaivani</dc:creator>
    </item>
    <item>
      <title>JaxDecompiler: Redefining Gradient-Informed Software Design</title>
      <link>https://arxiv.org/abs/2403.10571</link>
      <description>arXiv:2403.10571v1 Announce Type: cross 
Abstract: Among numerical libraries capable of computing gradient descent optimization, JAX stands out by offering more features, accelerated by an intermediate representation known as Jaxpr language. However, editing the Jaxpr code is not directly possible. This article introduces JaxDecompiler, a tool that transforms any JAX function into an editable Python code, especially useful for editing the JAX function generated by the gradient function. JaxDecompiler simplifies the processes of reverse engineering, understanding, customizing, and interoperability of software developed by JAX. We highlight its capabilities, emphasize its practical applications especially in deep learning and more generally gradient-informed software, and demonstrate that the decompiled code speed performance is similar to the original.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.10571v1</guid>
      <category>cs.PL</category>
      <category>cs.LG</category>
      <category>cs.SE</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pierrick Pochelu</dc:creator>
    </item>
    <item>
      <title>Linguacodus: A Synergistic Framework for Transformative Code Generation in Machine Learning Pipelines</title>
      <link>https://arxiv.org/abs/2403.11585</link>
      <description>arXiv:2403.11585v1 Announce Type: cross 
Abstract: In the ever-evolving landscape of machine learning, seamless translation of natural language descriptions into executable code remains a formidable challenge. This paper introduces Linguacodus, an innovative framework designed to tackle this challenge by deploying a dynamic pipeline that iteratively transforms natural language task descriptions into code through high-level data-shaping instructions. The core of Linguacodus is a fine-tuned large language model (LLM), empowered to evaluate diverse solutions for various problems and select the most fitting one for a given task. This paper details the fine-tuning process, and sheds light on how natural language descriptions can be translated into functional code. Linguacodus represents a substantial leap towards automated code generation, effectively bridging the gap between task descriptions and executable code. It holds great promise for advancing machine learning applications across diverse domains. Additionally, we propose an algorithm capable of transforming a natural description of an ML task into code with minimal human interaction. In extensive experiments on a vast machine learning code dataset originating from Kaggle, we showcase the effectiveness of Linguacodus. The investigations highlight its potential applications across diverse domains, emphasizing its impact on applied machine learning in various scientific fields.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11585v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.PL</category>
      <category>cs.SE</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ekaterina Trofimova, Emil Sataev, Andrey E. Ustyuzhanin</dc:creator>
    </item>
    <item>
      <title>HDLdebugger: Streamlining HDL debugging with Large Language Models</title>
      <link>https://arxiv.org/abs/2403.11671</link>
      <description>arXiv:2403.11671v1 Announce Type: cross 
Abstract: In the domain of chip design, Hardware Description Languages (HDLs) play a pivotal role. However, due to the complex syntax of HDLs and the limited availability of online resources, debugging HDL codes remains a difficult and time-intensive task, even for seasoned engineers. Consequently, there is a pressing need to develop automated HDL code debugging models, which can alleviate the burden on hardware engineers. Despite the strong capabilities of Large Language Models (LLMs) in generating, completing, and debugging software code, their utilization in the specialized field of HDL debugging has been limited and, to date, has not yielded satisfactory results. In this paper, we propose an LLM-assisted HDL debugging framework, namely HDLdebugger, which consists of HDL debugging data generation via a reverse engineering approach, a search engine for retrieval-augmented generation, and a retrieval-augmented LLM fine-tuning approach. Through the integration of these components, HDLdebugger can automate and streamline HDL debugging for chip design. Our comprehensive experiments, conducted on an HDL code dataset sourced from Huawei, reveal that HDLdebugger outperforms 13 cutting-edge LLM baselines, displaying exceptional effectiveness in HDL code debugging.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11671v1</guid>
      <category>cs.AR</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>cs.SE</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Xufeng Yao, Haoyang Li, Tsz Ho Chan, Wenyi Xiao, Mingxuan Yuan, Yu Huang, Lei Chen, Bei Yu</dc:creator>
    </item>
    <item>
      <title>ForzaETH Race Stack - Scaled Autonomous Head-to-Head Racing on Fully Commercial off-the-Shelf Hardware</title>
      <link>https://arxiv.org/abs/2403.11784</link>
      <description>arXiv:2403.11784v1 Announce Type: cross 
Abstract: Autonomous racing in robotics combines high-speed dynamics with the necessity for reliability and real-time decision-making. While such racing pushes software and hardware to their limits, many existing full-system solutions necessitate complex, custom hardware and software, and usually focus on Time-Trials rather than full unrestricted Head-to-Head racing, due to financial and safety constraints. This limits their reproducibility, making advancements and replication feasible mostly for well-resourced laboratories with comprehensive expertise in mechanical, electrical, and robotics fields. Researchers interested in the autonomy domain but with only partial experience in one of these fields, need to spend significant time with familiarization and integration. The ForzaETH Race Stack addresses this gap by providing an autonomous racing software platform designed for F1TENTH, a 1:10 scaled Head-to-Head autonomous racing competition, which simplifies replication by using commercial off-the-shelf hardware. This approach enhances the competitive aspect of autonomous racing and provides an accessible platform for research and development in the field. The ForzaETH Race Stack is designed with modularity and operational ease of use in mind, allowing customization and adaptability to various environmental conditions, such as track friction and layout. Capable of handling both Time-Trials and Head-to-Head racing, the stack has demonstrated its effectiveness, robustness, and adaptability in the field by winning the official F1TENTH international competition multiple times.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11784v1</guid>
      <category>cs.RO</category>
      <category>cs.SE</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicolas Baumann, Edoardo Ghignone, Jonas K\"uhne, Niklas Bastuck, Jonathan Becker, Nadine Imholz, Tobias Kr\"anzlin, Tian Yi Lim, Michael L\"otscher, Luca Schwarzenbach, Luca Tognoni, Christian Vogt, Andrea Carron, Michele Magno</dc:creator>
    </item>
    <item>
      <title>Investigating Markers and Drivers of Gender Bias in Machine Translations</title>
      <link>https://arxiv.org/abs/2403.11896</link>
      <description>arXiv:2403.11896v1 Announce Type: cross 
Abstract: Implicit gender bias in Large Language Models (LLMs) is a well-documented problem, and implications of gender introduced into automatic translations can perpetuate real-world biases. However, some LLMs use heuristics or post-processing to mask such bias, making investigation difficult. Here, we examine bias in LLMss via back-translation, using the DeepL translation API to investigate the bias evinced when repeatedly translating a set of 56 Software Engineering tasks used in a previous study. Each statement starts with 'she', and is translated first into a 'genderless' intermediate language then back into English; we then examine pronoun- choice in the back-translated texts. We expand prior research in the following ways: (1) by comparing results across five intermediate languages, namely Finnish, Indonesian, Estonian, Turkish and Hungarian; (2) by proposing a novel metric for assessing the variation in gender implied in the repeated translations, avoiding the over-interpretation of individual pronouns, apparent in earlier work; (3) by investigating sentence features that drive bias; (4) and by comparing results from three time-lapsed datasets to establish the reproducibility of the approach. We found that some languages display similar patterns of pronoun use, falling into three loose groups, but that patterns vary between groups; this underlines the need to work with multiple languages. We also identify the main verb appearing in a sentence as a likely significant driver of implied gender in the translations. Moreover, we see a good level of replicability in the results, and establish that our variation metric proves robust despite an obvious change in the behaviour of the DeepL translation API during the course of the study. These results show that the back-translation method can provide further insights into bias in language models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11896v1</guid>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <category>cs.SE</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Peter J Barclay (Edinburgh Napier University), Ashkan Sami (Edinburgh Napier University)</dc:creator>
    </item>
    <item>
      <title>Exploring Estonia's Open Government Data Development as a Journey towards Excellence: Unveiling the Progress of Local Governments in Open Data Provision</title>
      <link>https://arxiv.org/abs/2403.11952</link>
      <description>arXiv:2403.11952v1 Announce Type: cross 
Abstract: Estonia has a global reputation of a digital state or e-country. However, despite the success in digital governance, the country has faced challenges in the realm of Open Government Data (OGD) area, with significant advancements in its OGD ecosystem, as reflected in various open data rankings from 2020 and onwards, in the recent years being recognized among trend-setters. This paper aims to explore the evolution and positioning of Estonia's OGD development, encompassing national and local levels, through an integrated analysis of various indices, primary data from the Estonian OGD portal, and a thorough literature review. The research shows that Estonia has made progress in the national level open data ecosystem, primarily due to improvements in the OGD portal usability and legislation amendments. However, the local level is not as developed, with local governments lagging behind in OGD provision. The literature review highlights the lack of previous research focusing on Estonian and European local open data, emphasizing the need for future studies to explore the barriers and enablers of municipal OGD. This study contributes to a nuanced understanding of Estonia's dynamic journey in the OGD landscape, shedding light on both achievements and areas warranting further attention for establishing a sustainable open data ecosystem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11952v1</guid>
      <category>cs.CY</category>
      <category>cs.CE</category>
      <category>cs.DB</category>
      <category>cs.SE</category>
      <category>cs.SI</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Katrin Rajam\"ae-Soosaar, Anastasija Nikiforova</dc:creator>
    </item>
    <item>
      <title>A systematic mapping on quantum software development in the context of software engineering</title>
      <link>https://arxiv.org/abs/2106.00926</link>
      <description>arXiv:2106.00926v2 Announce Type: replace 
Abstract: Quantum Computing is a new paradigm that enables several advances which are impossible using classical technology. With the rise of quantum computers, the software is also invited to change so that it can better fit this new computation way. However, although a lot of research is being conducted in the quantum computing field, it is still scarce studies about the differences of the software and software engineering in this new context. Therefore, this article presents a systematic mapping study to present a wide review on the particularities and characteristics of software that are developed for quantum computers. A total of 24 papers were selected using digital libraries with the objective of answering three research questions elaborated in the conduct of this research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2106.00926v2</guid>
      <category>cs.SE</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Paulo Eduardo Zanni Junior, Valter Vieira de Camargo</dc:creator>
    </item>
    <item>
      <title>A Taxonomy of Testable HTML5 Canvas Issues</title>
      <link>https://arxiv.org/abs/2201.07351</link>
      <description>arXiv:2201.07351v5 Announce Type: replace 
Abstract: The HTML5 &lt;canvas&gt; is widely used to display high quality graphics in web applications. However, the combination of web, GUI, and visual techniques that are required to build &lt;canvas&gt; applications, together with the lack of testing and debugging tools, makes developing such applications very challenging. To help direct future research on testing &lt;canvas&gt; applications, in this paper we present a taxonomy of testable &lt;canvas&gt; issues. First, we extracted 2,403 &lt;canvas&gt;-related issue reports from 123 open-source GitHub projects that use the HTML5 &lt;canvas&gt;. Second, we constructed our taxonomy by manually classifying a random sample of 332 issue reports. Our manual classification identified five broad categories of testable &lt;canvas&gt; issues, such as Visual and Performance issues. We found that Visual issues are the most frequent (35%), while Performance issues are relatively infrequent (5%). We also found that many testable &lt;canvas&gt; issues that present themselves visually on the &lt;canvas&gt; are actually caused by other components of the web application. Our taxonomy of testable &lt;canvas&gt; issues can be used to steer future research into &lt;canvas&gt; issues and testing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2201.07351v5</guid>
      <category>cs.SE</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TSE.2023.3270740</arxiv:DOI>
      <dc:creator>Finlay Macklon, Markos Viggiato, Natalia Romanova, Chris Buzon, Dale Paas, Cor-Paul Bezemer</dc:creator>
    </item>
    <item>
      <title>L2MAC: Large Language Model Automatic Computer for Extensive Code Generation</title>
      <link>https://arxiv.org/abs/2310.02003</link>
      <description>arXiv:2310.02003v3 Announce Type: replace 
Abstract: Transformer-based large language models (LLMs) are constrained by the fixed context window of the underlying transformer architecture, hindering their ability to produce long and coherent outputs. Memory-augmented LLMs are a promising solution, but current approaches cannot handle long output generation tasks since they (1) only focus on reading memory and reduce its evolution to the concatenation of new memories or (2) use very specialized memories that cannot adapt to other domains. This paper presents L2MAC, the first practical LLM-based stored-program automatic computer (von Neumann architecture) framework, an LLM-based multi-agent system, for long and consistent output generation. Its memory has two components: the instruction registry, which is populated with a prompt program to solve the user-given task, and a file store, which will contain the final and intermediate outputs. Each instruction in turn is executed by a separate LLM agent, whose context is managed by a control unit capable of precise memory reading and writing to ensure effective interaction with the file store. These components enable L2MAC to generate extensive outputs, bypassing the constraints of the finite context window while producing outputs that fulfill a complex user-specified task. We empirically demonstrate that L2MAC achieves state-of-the-art performance in generating large codebases for system design tasks, significantly outperforming other coding methods in implementing the detailed user-specified task, and we provide valuable insights into the reasons for this performance gap.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.02003v3</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.PL</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Samuel Holt, Max Ruiz Luyten, Mihaela van der Schaar</dc:creator>
    </item>
    <item>
      <title>Redefining Developer Assistance: Through Large Language Models in Software Ecosystem</title>
      <link>https://arxiv.org/abs/2312.05626</link>
      <description>arXiv:2312.05626v3 Announce Type: replace 
Abstract: In this paper, we delve into the advancement of domain-specific Large Language Models (LLMs) with a focus on their application in software development. We introduce DevAssistLlama, a model developed through instruction tuning, to assist developers in processing software-related natural language queries. This model, a variant of instruction tuned LLM, is particularly adept at handling intricate technical documentation, enhancing developer capability in software specific tasks. The creation of DevAssistLlama involved constructing an extensive instruction dataset from various software systems, enabling effective handling of Named Entity Recognition (NER), Relation Extraction (RE), and Link Prediction (LP). Our results demonstrate DevAssistLlama's superior capabilities in these tasks, in comparison with other models including ChatGPT. This research not only highlights the potential of specialized LLMs in software development also the pioneer LLM for this domain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.05626v3</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Somnath Banerjee, Avik Dutta, Sayan Layek, Amruit Sahoo, Sam Conrad Joyce, Rima Hazra</dc:creator>
    </item>
    <item>
      <title>Can ChatGPT Support Developers? An Empirical Evaluation of Large Language Models for Code Generation</title>
      <link>https://arxiv.org/abs/2402.11702</link>
      <description>arXiv:2402.11702v2 Announce Type: replace 
Abstract: Large language models (LLMs) have demonstrated notable proficiency in code generation, with numerous prior studies showing their promising capabilities in various development scenarios. However, these studies mainly provide evaluations in research settings, which leaves a significant gap in understanding how effectively LLMs can support developers in real-world. To address this, we conducted an empirical analysis of conversations in DevGPT, a dataset collected from developers' conversations with ChatGPT (captured with the Share Link feature on platforms such as GitHub). Our empirical findings indicate that the current practice of using LLM-generated code is typically limited to either demonstrating high-level concepts or providing examples in documentation, rather than to be used as production-ready code. These findings indicate that there is much future work needed to improve LLMs in code generation before they can be integral parts of modern software development.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.11702v2</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3643991.3645074</arxiv:DOI>
      <dc:creator>Kailun Jin, Chung-Yu Wang, Hung Viet Pham, Hadi Hemmati</dc:creator>
    </item>
    <item>
      <title>RepoHyper: Better Context Retrieval Is All You Need for Repository-Level Code Completion</title>
      <link>https://arxiv.org/abs/2403.06095</link>
      <description>arXiv:2403.06095v2 Announce Type: replace 
Abstract: Code Large Language Models (CodeLLMs) have demonstrated impressive proficiency in code completion tasks. However, they often fall short of fully understanding the extensive context of a project repository, such as the intricacies of relevant files and class hierarchies, which can result in less precise completions. To overcome these limitations, we present \tool, a multifaceted framework designed to address the complex challenges associated with repository-level code completion. Central to \tool is the {\em Repo-level Semantic Graph} (RSG), a novel semantic graph structure that encapsulates the vast context of code repositories. Furthermore, RepoHyper leverages \textit{Expand and Refine} retrieval method, including a graph expansion and a link prediction algorithm applied to the RSG, enabling the effective retrieval and prioritization of relevant code snippets. Our evaluations show that \tool markedly outperforms existing techniques in repository-level code completion, showcasing enhanced accuracy across various datasets when compared to several strong baselines. Our implementation of RepoHyper can be found at~\url{https://github.com/FSoft-AI4Code/RepoHyper}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06095v2</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Huy N. Phan, Hoang N. Phan, Tien N. Nguyen, Nghi D. Q. Bui</dc:creator>
    </item>
    <item>
      <title>ACFIX: Guiding LLMs with Mined Common RBAC Practices for Context-Aware Repair of Access Control Vulnerabilities in Smart Contracts</title>
      <link>https://arxiv.org/abs/2403.06838</link>
      <description>arXiv:2403.06838v2 Announce Type: replace 
Abstract: Smart contracts are susceptible to various security issues, among which access control (AC) vulnerabilities are particularly critical. While existing research has proposed multiple detection tools, the automatic and appropriate repair of AC vulnerabilities in smart contracts remains a challenge. Unlike commonly supported vulnerability types by existing repair tools, such as reentrancy, which are usually fixed by template-based approaches, the main obstacle of AC lies in identifying the appropriate roles or permissions amid a long list of non-AC-related source code to generate proper patch code, a task that demands human-level intelligence.
  Leveraging recent advancements in large language models (LLMs), we employ the state-of-the-art GPT-4 model and enhance it with a novel approach called ACFIX. The key insight is that we can mine common AC practices for major categories of code functionality and use them to guide LLMs in fixing code with similar functionality. To this end, ACFIX involves both offline and online phases. First, during the offline phase, ACFIX mines a taxonomy of common Role-based Access Control (RBAC) practices from 344,251 on-chain contracts, categorizing 49 role-permission pairs from the top 1,000 pairs mined. Second, during the online phase, ACFIX tracks AC-related elements across the contract and uses this context information along with a Chain-of-Thought pipeline to guide LLMs in identifying the most appropriate role-permission pair for the subject contract and subsequently generating a suitable patch. This patch will then undergo a validity and effectiveness check. To evaluate ACFIX, we built the first benchmark dataset of 118 real-world AC vulnerabilities, and our evaluation revealed that ACFIX successfully repaired 94.92% of them. This represents a significant improvement compared to the baseline GPT-4, which achieved only 52.54%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06838v2</guid>
      <category>cs.SE</category>
      <category>cs.CR</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lyuye Zhang, Kaixuan Li, Kairan Sun, Daoyuan Wu, Ye Liu, Haoye Tian, Yang Liu</dc:creator>
    </item>
    <item>
      <title>QCSHQD: Quantum computing as a service for Hybrid classical-quantum software development: A Vision</title>
      <link>https://arxiv.org/abs/2403.08663</link>
      <description>arXiv:2403.08663v2 Announce Type: replace 
Abstract: Quantum Computing (QC) is transitioning from theoretical frameworks to an indispensable powerhouse of computational capability, resulting in extensive adoption across both industrial and academic domains. QC presents exceptional advantages, including unparalleled processing speed and the potential to solve complex problems beyond the capabilities of classical computers. Nevertheless, academic researchers and industry practitioners encounter various challenges in harnessing the benefits of this technology. The limited accessibility of QC resources for classical developers, and a general lack of domain knowledge and expertise, represent insurmountable barrier, hence to address these challenges, we introduce a framework- Quantum Computing as a Service for Hybrid Classical-Quantum Software Development (QCSHQD), which leverages service-oriented strategies. Our framework comprises three principal components: an Integrated Development Environment (IDE) for user interaction, an abstraction layer dedicated to orchestrating quantum services, and a service provider responsible for executing services on quantum computer. This study presents a blueprint for QCSHQD, designed to democratize access to QC resources for classical developers who want to seamless harness QC power. The vision of QCSHQD paves the way for groundbreaking innovations by addressing key challenges of hybridization between classical and quantum computers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.08663v2</guid>
      <category>cs.SE</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maryam Tavassoli Sabzevari, Matteo Esposito, Arif Ali Khan, Davide Taibi</dc:creator>
    </item>
    <item>
      <title>Bugs in Large Language Models Generated Code: An Empirical Study</title>
      <link>https://arxiv.org/abs/2403.08937</link>
      <description>arXiv:2403.08937v2 Announce Type: replace 
Abstract: Large Language Models (LLMs) for code have gained significant attention recently. They can generate code in different programming languages based on provided prompts, fulfilling a long-lasting dream in Software Engineering (SE), i.e., automatic code generation. Similar to human-written code, LLM-generated code is prone to bugs, and these bugs have not yet been thoroughly examined by the community. Given the increasing adoption of LLM-based code generation tools (e.g., GitHub Copilot) in SE activities, it is critical to understand the characteristics of bugs contained in code generated by LLMs. This paper examines a sample of 333 bugs collected from code generated using three leading LLMs (i.e., CodeGen, PanGu-Coder, and Codex) and identifies the following 10 distinctive bug patterns: Misinterpretations, Syntax Error, Silly Mistake, Prompt-biased code, Missing Corner Case, Wrong Input Type, Hallucinated Object, Wrong Attribute, Incomplete Generation, and Non-Prompted Consideration. The bug patterns are presented in the form of a taxonomy. The identified bug patterns are validated using an online survey with 34 LLM practitioners and researchers. The surveyed participants generally asserted the significance and prevalence of the bug patterns. Researchers and practitioners can leverage these findings to develop effective quality assurance techniques for LLM-generated code. This study sheds light on the distinctive characteristics of LLM-generated code.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.08937v2</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Florian Tambon, Arghavan Moradi Dakhel, Amin Nikanjam, Foutse Khomh, Michel C. Desmarais, Giuliano Antoniol</dc:creator>
    </item>
    <item>
      <title>A Logic for Veracity</title>
      <link>https://arxiv.org/abs/2302.06164</link>
      <description>arXiv:2302.06164v4 Announce Type: replace-cross 
Abstract: This paper shows the initial stages of development, from first principles, of a formal logic to characterise and then explore issues in a broadly defined idea of Veracity, which includes properties of demonstrability, truth, trust and authenticity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.06164v4</guid>
      <category>cs.LO</category>
      <category>cs.SE</category>
      <category>cs.SI</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Steve Reeves</dc:creator>
    </item>
  </channel>
</rss>
