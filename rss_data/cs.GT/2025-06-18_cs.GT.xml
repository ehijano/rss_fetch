<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 19 Jun 2025 01:29:28 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Dividing Conflicting Items Fairly</title>
      <link>https://arxiv.org/abs/2506.14149</link>
      <description>arXiv:2506.14149v1 Announce Type: new 
Abstract: We study the allocation of indivisible goods under conflicting constraints, represented by a graph. In this framework, vertices correspond to goods and edges correspond to conflicts between a pair of goods. Each agent is allocated an independent set in the graph. In a recent work of Kumar et al. (2024), it was shown that a maximal EF1 allocation exists for interval graphs and two agents with monotone valuations. We significantly extend this result by establishing that a maximal EF1 allocation exists for \emph{any graph} when the two agents have monotone valuations. To compute such an allocation, we present a polynomial-time algorithm for additive valuations, as well as a pseudo-polynomial time algorithm for monotone valuations. Moreover, we complement our findings by providing a counterexample demonstrating a maximal EF1 allocation may not exist for three agents with monotone valuations; further, we establish NP-hardness of determining the existence of such allocations for every fixed number $n \geq 3$ of agents. All of our results for goods also apply to the allocation of chores.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.14149v1</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ayumi Igarashi, Pasin Manurangsi, Hirotaka Yoneda</dc:creator>
    </item>
    <item>
      <title>Infinite lexicographic products of positional objectives</title>
      <link>https://arxiv.org/abs/2506.14544</link>
      <description>arXiv:2506.14544v1 Announce Type: new 
Abstract: This paper contributes to the study of positional determinacy of infinite duration games played on potentially infinite graphs. Recently, [Ohlmann, TheoretiCS 2023] established that positionality of prefix-independent objectives is preserved by finite lexicographic products. We propose two different notions of infinite lexicographic products indexed by arbitrary ordinals, and extend Ohlmann's result by proving that they also preserve positionality. In the context of one-player positionality, this extends positional determinacy results of [Gr\"adel and Walukiewicz, Logical Methods in Computer Science 2006] to edge-labelled games and arbitrarily many priorities for both Max-Parity and Min-Parity. Moreover, we show that the Max-Parity objectives over countable ordinals are complete for the infinite levels of the difference hierarchy over $\Sigma^0_2$ and that Min-Parity is complete for the class $\Sigma^0_3$. We obtain therefore positional languages that are complete for all those levels, as well as new insights about closure under unions and neutral letters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.14544v1</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Antonio Casares, Pierre Ohlmann, Micha{\l} Skrzypczak, Igor Walukiewicz</dc:creator>
    </item>
    <item>
      <title>Nonlinear Nonlocal Diffusion Equations for the Analysis of Continuous Coordination and Anti-Coordination Type Games</title>
      <link>https://arxiv.org/abs/2506.13929</link>
      <description>arXiv:2506.13929v1 Announce Type: cross 
Abstract: Coordination games with explicit spatial or relational structure are of interest to economists, ecologists, sociologists, and others studying emergent global properties in collective behavior. When assemblies of individuals seek to coordinate action with one another through myopic best response or other replicator dynamics, the resulting dynamical system can exhibit many rich behaviors. However, these behaviors have been studied only in the case where the number of players is countable and the relational structure is described discretely. By giving an extension of a general class of coordination-like games, including true coordination games themselves, into a continuous setting, we can begin to study coordination and cooperative behavior with a new host of tools from PDEs and nonlocal equations. In this study, we propose a rigorously supported extension of structured coordination-type games into a setting with continuous space and continuous strategies and show that, under certain hypotheses, the dynamics of these games are described through a nonlinear, nonlocal diffusion equation. We go on to prove existence and uniqueness for the initial value problem in the case where no boundary data are prescribed. For true coordination games, we go further and prove a maximum principle, weak regularity results, as well as some numerical results toward understanding how solutions to the coordination equation behave. We present several modeling results, characterizing stationary solutions both rigorously and through numerical experiments and conclude with a result towards the inhomogeneous problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.13929v1</guid>
      <category>math.DS</category>
      <category>cs.GT</category>
      <pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>John S. McAlister, Nina H. Fefferman, Tadele A. Mengesha</dc:creator>
    </item>
    <item>
      <title>Two-Player Zero-Sum Games with Bandit Feedback</title>
      <link>https://arxiv.org/abs/2506.14518</link>
      <description>arXiv:2506.14518v1 Announce Type: cross 
Abstract: We study a two-player zero-sum game (TPZSG) in which the row player aims to maximize their payoff against an adversarial column player, under an unknown payoff matrix estimated through bandit feedback. We propose and analyze two algorithms: ETC-TPZSG, which directly applies ETC to the TPZSG setting and ETC-TPZSG-AE, which improves upon it by incorporating an action pair elimination (AE) strategy that leverages the $\varepsilon$-Nash Equilibrium property to efficiently select the optimal action pair. Our objective is to demonstrate the applicability of ETC in a TPZSG setting by focusing on learning pure strategy Nash Equilibrium. A key contribution of our work is a derivation of instance-dependent upper bounds on the expected regret for both algorithms, has received limited attention in the literature on zero-sum games. Particularly, after $T$ rounds, we achieve an instance-dependent regret upper bounds of $O(\Delta + \sqrt{T})$ for ETC-TPZSG and $O(\frac{\log (T \Delta^2)}{\Delta})$ for ETC-TPZSG-AE, where $\Delta$ denotes the suboptimality gap. Therefore, our results indicate that ETC-based algorithms perform effectively in adversarial game settings, achieving regret bounds comparable to existing methods while providing insights through instance-dependent analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.14518v1</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Elif Y{\i}lmaz, Christos Dimitrakakis</dc:creator>
    </item>
    <item>
      <title>Market Making without Regret</title>
      <link>https://arxiv.org/abs/2411.13993</link>
      <description>arXiv:2411.13993v2 Announce Type: replace 
Abstract: We consider a sequential decision-making setting where, at every round $t$, a market maker posts a bid price $B_t$ and an ask price $A_t$ to an incoming trader (the taker) with a private valuation for one unit of some asset. If the trader's valuation is lower than the bid price, or higher than the ask price, then a trade (sell or buy) occurs. If a trade happens at round $t$, then letting $M_t$ be the market price (observed only at the end of round $t$), the maker's utility is $M_t - B_t$ if the maker bought the asset, and $A_t - M_t$ if they sold it. We characterize the maker's regret with respect to the best fixed choice of bid and ask pairs under a variety of assumptions (adversarial, i.i.d., and their variants) on the sequence of market prices and valuations. Our upper bound analysis unveils an intriguing connection relating market making to first-price auctions and dynamic pricing. Our main technical contribution is a lower bound for the i.i.d. case with Lipschitz distributions and independence between prices and valuations. The difficulty in the analysis stems from the unique structure of the reward and feedback functions, allowing an algorithm to acquire information by graduating the "cost of exploration" in an arbitrary way.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.13993v2</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>q-fin.TR</category>
      <pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicol\`o Cesa-Bianchi, Tommaso Cesari, Roberto Colomboni, Luigi Foscari, Vinayak Pathak</dc:creator>
    </item>
    <item>
      <title>Non-Monetary Mechanism Design without Distributional Information: Using Scarce Audits Wisely</title>
      <link>https://arxiv.org/abs/2502.08412</link>
      <description>arXiv:2502.08412v2 Announce Type: replace 
Abstract: We study a repeated resource allocation problem with strategic agents where monetary transfers are disallowed and the central planner has no prior information on agents' utility distributions. In light of Arrow's impossibility theorem, acquiring information about agent preferences through some form of feedback is necessary. We assume that the central planner can request powerful but expensive audits on the winner in any round, revealing the true utility of the winner in that round. We design a mechanism achieving $T$-independent $O(K^2)$ social welfare regret while only requesting $O(K^3 \log T)$ audits in expectation, where $K$ is the number of agents and $T$ is the number of rounds. We also show an $\Omega(K)$ lower bound on the regret and an $\Omega(1)$ lower bound on the number of audits when having low regret. Algorithmically, we show that incentive-compatibility can be mostly enforced via the imposition of adaptive future punishments, where the audit probability is inversely proportional to the winner's future winning probability. To accurately estimate such probabilities in presence of strategic agents, who may adversely react to any potential misestimate, we introduce a flagging component that allows agents to flag any biased estimate (we show that doing so aligns with individual incentives). On the technical side, without a unique and known distribution, one cannot apply the revelation principle and conclude that truthful reporting is exactly an equilibrium. Instead, we characterize the equilibrium via a reduction to a simpler auxiliary game, in which agents cannot strategize until close to the end of the game; we show equilibria in this game can induce equilibria in the actual, fully strategic game. The tools developed therein may be of independent interest for other mechanism design problems in which the revelation principle cannot be readily applied.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.08412v2</guid>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yan Dai, Moise Blanchard, Patrick Jaillet</dc:creator>
    </item>
    <item>
      <title>The Backfiring Effect of Weak AI Safety Regulation</title>
      <link>https://arxiv.org/abs/2503.20848</link>
      <description>arXiv:2503.20848v2 Announce Type: replace 
Abstract: Recent policy proposals aim to improve the safety of general-purpose AI, but there is little understanding of the efficacy of different regulatory approaches to AI safety. We present a strategic model that explores the interactions between safety regulation, the general-purpose AI creators, and domain specialists--those who adapt the technology for specific applications. Our analysis examines how different regulatory measures, targeting different parts of the AI development chain, affect the outcome of this game. In particular, we assume AI technology is characterized by two key attributes: safety and performance. The regulator first sets a minimum safety standard that applies to one or both players, with strict penalties for non-compliance. The general-purpose creator then invests in the technology, establishing its initial safety and performance levels. Next, domain specialists refine the AI for their specific use cases, updating the safety and performance levels and taking the product to market. The resulting revenue is then distributed between the specialist and generalist through a revenue-sharing parameter. Our analysis reveals two key insights: First, weak safety regulation imposed predominantly on domain specialists can backfire. While it might seem logical to regulate AI use cases, our analysis shows that weak regulations targeting domain specialists alone can unintentionally reduce safety. This effect persists across a wide range of settings. Second, in sharp contrast to the previous finding, we observe that stronger, well-placed regulation can in fact mutually benefit all players subjected to it. When regulators impose appropriate safety standards on both general-purpose AI creators and domain specialists, the regulation functions as a commitment device, leading to safety and performance gains, surpassing what is achieved under no regulation or regulating one player alone.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.20848v2</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>econ.TH</category>
      <pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Benjamin Laufer, Jon Kleinberg, Hoda Heidari</dc:creator>
    </item>
  </channel>
</rss>
