<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-fin.MF updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-fin.MF</link>
    <description>q-fin.MF updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-fin.MF" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 19 Dec 2024 02:52:30 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Pontryagin-Guided Neural Policy Optimization Framework for Merton's Portfolio Problem</title>
      <link>https://arxiv.org/abs/2412.13101</link>
      <description>arXiv:2412.13101v1 Announce Type: cross 
Abstract: We present a neural policy optimization framework for Merton's portfolio optimization problem that is rigorously aligned with Pontryagin's Maximum Principle (PMP). Our approach employs a discrete-time, backpropagation-through-time (BPTT)-based gradient method, but unlike conventional data-driven methods, we establish a direct connection to the underlying continuous-time optimality conditions. By approximating adjoint variables from a policy-fixed backward stochastic differential equation (BSDE), we obtain parameter gradients consistent with the PMP framework, all without explicitly solving the PMP-derived BSDE. As the policy parameters are iteratively updated, both the suboptimal adjoint variables and the neural network policies converge almost surely to their PMP-optimal counterparts. This ensures that the final learned policy is not only numerically robust but also provably optimal in the continuous-time sense. Hence, our method provides a theoretically grounded and practically implementable solution that bridges modern deep learning techniques and classical optimal control theory in stochastic settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13101v1</guid>
      <category>math.OC</category>
      <category>q-fin.MF</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jeonggyu Huh</dc:creator>
    </item>
    <item>
      <title>Herding Unmasked: Insights into Cryptocurrencies, Stocks and US ETFs</title>
      <link>https://arxiv.org/abs/2407.08069</link>
      <description>arXiv:2407.08069v2 Announce Type: replace 
Abstract: Herding behavior has become a familiar phenomenon to investors, with potential dangers of both undervaluing and overvaluing assets, while also threatening market stability. This study contributes to the literature on herding behavior by using a recent dataset, covering the most impactful events of recent years. To our knowledge, this is the first study examining herding behavior across three different types of investment vehicle and also the first study observing herding at a community (subset) level. Specifically, we first explore this phenomenon in each separate type of investment vehicle, namely stocks, US ETFs and cryptocurrencies, using the Cross-Sectional Absolute Deviation model. We find mostly similar herding patterns for stocks and US ETFs. Subsequently, the same experiment is implemented on a combination of all three investment vehicles. For a deeper investigation, we adopt graph-based techniques including the Minimum Spanning Tree and Louvain community detection to partition the combination into smaller subsets to detect herding behavior for each subset. We find that herding behavior exists at all times across all types of investment vehicle at a subset level, although perhaps not at the superset level, and that this herding behavior tends to stem from specific events that solely impact that subset of assets. Lastly, we explore herding by examining the financial contagion effects between these types of investment vehicle. Results show that US ETFs not only have a tendency to propagate similar trading behaviors in stocks and especially cryptocurrencies but also show self-reinforcing herding behavior, acting as drivers of their own trends.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.08069v2</guid>
      <category>q-fin.MF</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>An Pham Ngoc Nguyen, Martin Crane, Thomas Conlon, Marija Bezbradica</dc:creator>
    </item>
    <item>
      <title>Generative model for financial time series trained with MMD using a signature kernel</title>
      <link>https://arxiv.org/abs/2407.19848</link>
      <description>arXiv:2407.19848v3 Announce Type: replace 
Abstract: Generating synthetic financial time series data that accurately reflects real-world market dynamics holds tremendous potential for various applications, including portfolio optimization, risk management, and large scale machine learning. We present an approach for training generative models for financial time series using the maximum mean discrepancy (MMD) with a signature kernel. Our method leverages the expressive power of the signature transform to capture the complex dependencies and temporal structures inherent in financial data. We employ a moving average model to model the variance of the noise input, enhancing the model's ability to reproduce stylized facts such as volatility clustering. Through empirical experiments on S&amp;P 500 index data, we demonstrate that our model effectively captures key characteristics of financial time series and outperforms a comparable GAN-based approach. In addition, we explore the application of the synthetic data generated to train a reinforcement learning agent for portfolio management, achieving promising results. Finally, we propose a method to add robustness to the generative model by tweaking the noise input so that the generated sequences can be adjusted to different market environments with minimal data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.19848v3</guid>
      <category>q-fin.MF</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chung I Lu, Julian Sester</dc:creator>
    </item>
    <item>
      <title>Full error analysis of the random deep splitting method for nonlinear parabolic PDEs and PIDEs</title>
      <link>https://arxiv.org/abs/2405.05192</link>
      <description>arXiv:2405.05192v3 Announce Type: replace-cross 
Abstract: In this paper, we present a randomized extension of the deep splitting algorithm introduced in [Beck, Becker, Cheridito, Jentzen, and Neufeld (2021)] using random neural networks suitable to approximately solve both high-dimensional nonlinear parabolic PDEs and PIDEs with jumps having (possibly) infinite activity. We provide a full error analysis of our so-called random deep splitting method. In particular, we prove that our random deep splitting method converges to the (unique viscosity) solution of the nonlinear PDE or PIDE under consideration. Moreover, we empirically analyze our random deep splitting method by considering several numerical examples including both nonlinear PDEs and nonlinear PIDEs relevant in the context of pricing of financial derivatives under default risk. In particular, we empirically demonstrate in all examples that our random deep splitting method can approximately solve nonlinear PDEs and PIDEs in 10'000 dimensions within seconds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.05192v3</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.PR</category>
      <category>q-fin.MF</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ariel Neufeld, Philipp Schmocker, Sizhou Wu</dc:creator>
    </item>
  </channel>
</rss>
