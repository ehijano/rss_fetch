<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 04 Mar 2025 05:00:18 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Accelerated windowing for the crew rostering problem with machine learning</title>
      <link>https://arxiv.org/abs/2503.00160</link>
      <description>arXiv:2503.00160v1 Announce Type: new 
Abstract: The crew rostering problem (CRP) for pilots is a complex crew scheduling task assigning pairings, or sequences of flights starting and ending at the same airport, to pilots to create a monthly schedule. In this paper, we propose an innovative solution method for the CRP that uses a windowing approach. First, using a combination of machine learning (ML) and combinatorial optimisation (CO), we quickly generate an initial solution. The solution is obtained with a sequential assignment procedure (\textit{seqAsg}) based on a neural network trained by an evolutionary algorithm. Then, this initial solution is reoptimized using a branch-and-price algorithm that relies on a windowing scheme to quickly obtain a CRP solution. This windowing method consists of decomposing the optimization horizon into several overlapping windows, and then optimizing each one sequentially. Although windowing has been successfully used in other airline applications, it had never been implemented for the CRP, due to its large number of horizontal constraints involving the whole planning horizon. We test our approach on two large real-world instances, and show that our method is over ten times faster than the state-of-the-art branch-and-price CRP solver GENCOL while providing solutions on average less than 1% away from optimality. We show that our windowing approach greatly benefits from being initialized with good-quality ML-based solutions. This is because the initial solution provides reliable information on the following windows, allowing the solver to better optimize the current one. For this reason, this approach outperforms other naive heuristics, including stand-alone ML or windowing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00160v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Philippe Racette, Fr\'ed\'eric Quesnel, Andrea Lodi, Fran\c{c}ois Soumis</dc:creator>
    </item>
    <item>
      <title>Backstepping Control Laws for Higher-Dimensional PDEs: Spatial Invariance and Domain Extension Methods</title>
      <link>https://arxiv.org/abs/2503.00225</link>
      <description>arXiv:2503.00225v1 Announce Type: new 
Abstract: This paper extends backstepping to higher-dimensional PDEs by leveraging domain symmetries and structural properties. We systematically address three increasingly complex scenarios. First, for rectangular domains, we characterize boundary stabilization with finite-dimensional actuation by combining backstepping with Fourier analysis, deriving explicit necessary conditions. Second, for reaction-diffusion equations on sector domains, we use angular eigenfunction expansions to obtain kernel solutions in terms of modified Bessel functions. Finally, we outline a domain extension method for irregular domains, transforming the boundary control problem into an equivalent one on a target domain. This framework unifies and extends previous backstepping results, offering new tools for higher-dimensional domains where classical separation of variables is inapplicable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00225v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rafael Vazquez</dc:creator>
    </item>
    <item>
      <title>Solution of Uncertain Multiobjective Optimization Problems by Using Nonlinear Conjugate Gradient Method</title>
      <link>https://arxiv.org/abs/2503.00311</link>
      <description>arXiv:2503.00311v1 Announce Type: new 
Abstract: This paper introduces a nonlinear conjugate gradient method (NCGM) for addressing the robust counterpart of uncertain multiobjective optimization problems (UMOPs). Here, the robust counterpart is defined as the minimum across objective-wise worst-case scenarios. There are some drawbacks to using scalarization techniques to solve the robust counterparts of UMOPs, such as the pre-specification and restrictions of weights, and function importance that is unknown beforehand. NCGM is free from any kind of priori chosen scalars or ordering information of objective functions as accepted in scalarization methods. With the help of NCGM, we determine the critical point for the robust counterpart of UMOP, which is the robust critical point for UMOP. To tackle this robust counterpart using the NCGM, the approach involves constructing and solving a subproblem to determine a descent direction. Subsequently, a new direction is derived based on parameter selection methods such as Fletcher-Reeves, conjugate descent, Dai-Yuan, Polak-Ribi$\grave{e}$re-Polyak, and Hestenes-Stiefel. An Armijo-type inexact line search is employed to identify an appropriate step length. Utilizing descent direction and step length, a sequence is generated, and convergence of the proposed method is established. The effectiveness of the proposed method is verified and compared against an existing method using a set of test problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00311v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Shubham Kumar, Nihar Kumar Mahato, Debdas Ghosh</dc:creator>
    </item>
    <item>
      <title>Convergence of energy-based learning in linear resistive networks</title>
      <link>https://arxiv.org/abs/2503.00349</link>
      <description>arXiv:2503.00349v1 Announce Type: new 
Abstract: Energy-based learning algorithms are alternatives to backpropagation and are well-suited to distributed implementations in analog electronic devices. However, a rigorous theory of convergence is lacking. We make a first step in this direction by analysing a particular energy-based learning algorithm, Contrastive Learning, applied to a network of linear adjustable resistors. It is shown that, in this setup, Contrastive Learning is equivalent to projected gradient descent on a convex function, for any step size, giving a guarantee of convergence for the algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00349v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Anne-Men Huijzer, Thomas Chaffey, Bart Besselink, Henk J. van Waarde</dc:creator>
    </item>
    <item>
      <title>Linear-quadratic control for mean-field backward stochastic differential equations with random coefficients</title>
      <link>https://arxiv.org/abs/2503.00369</link>
      <description>arXiv:2503.00369v1 Announce Type: new 
Abstract: In this paper, we study the linear-quadratic control problem for mean-field backward stochastic differential equations (MF-BSDE) with random coefficients. We first derive a preliminary stochastic maximum principle to analyze the unique solvability of the optimality system for this control problem through the variational method. Subsequently, we reformulate the mean-field linear-quadratic (MF-BSLQ) problem as a constrained BSDE control problem by imposing constraints on the expectation processes, which we solve using the Extended Lagrange multiplier method. Finally, we derive an explicit expression for the optimal control associated with Problem (MF-BSLQ).</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00369v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jie Xiong, Wen Xu, Ying Yang</dc:creator>
    </item>
    <item>
      <title>Differential Game Strategies for Defending a Circular Target Under Perception Constraints</title>
      <link>https://arxiv.org/abs/2503.00434</link>
      <description>arXiv:2503.00434v1 Announce Type: new 
Abstract: This letter employs differential game theory to address the defense problem of a circular target area with perception constraints, involving a single defender and a single attacker. The defender is restricted to moving along the perimeter, while the mobile attacker aims to make itself to the edge of the circular target to win. We examine a scenario where both the attacker and defender face perception constraints, dividing the interaction into four distinct stages based on detection capabilities and deriving the corresponding optimal control strategies. Simulations are conducted to validate the proposed strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00434v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xinyi Zhu, Jiali Wang, Yang Tang, Fangfei Li, Yan Zhu</dc:creator>
    </item>
    <item>
      <title>A Bayesian Interpretation of the Internal Model Principle</title>
      <link>https://arxiv.org/abs/2503.00511</link>
      <description>arXiv:2503.00511v1 Announce Type: new 
Abstract: The internal model principle, originally proposed in the theory of control of linear systems, nowadays represents a more general class of results in control theory and cybernetics. The central claim of these results is that, under suitable assumptions, if a system (a controller) can regulate against a class of external inputs (from the environment), it is because the system contains a model of the system causing these inputs, which can be used to generate signals counteracting them. Similar claims on the role of internal models appear also in cognitive science, especially in modern Bayesian treatments of cognitive agents, often suggesting that a system (a human subject, or some other agent) models its environment to adapt against disturbances and perform goal-directed behaviour. It is however unclear whether the Bayesian internal models discussed in cognitive science bear any formal relation to the internal models invoked in standard treatments of control theory. Here, we first review the internal model principle and present a precise formulation of it using concepts inspired by categorical systems theory. This leads to a formal definition of `model' generalising its use in the internal model principle. Although this notion of model is not a priori related to the notion of Bayesian reasoning, we show that it can be seen as a special case of possibilistic Bayesian filtering. This result is based on a recent line of work formalising, using Markov categories, a notion of `interpretation', describing when a system can be interpreted as performing Bayesian filtering on an outside world in a consistent way.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00511v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.CT</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Manuel Baltieri, Martin Biehl, Matteo Capucci, Nathaniel Virgo</dc:creator>
    </item>
    <item>
      <title>A Novel Co-Evolutionary Algorithm for Solving a Bilevel Pricing and Hubs Location Problem under a Tree Topology</title>
      <link>https://arxiv.org/abs/2503.00561</link>
      <description>arXiv:2503.00561v1 Announce Type: new 
Abstract: This paper introduces the Bilevel Tree-of-Hubs Location Problem with Prices (BTHLPwP). The BTHLPwP is a multiple-allocation hub location problem in which, in addition to determining the nodes and links of a tree-shaped hub backbone network, the prices for using this network must also be set. We assume that two different types of agents make decisions in this problem. On the one hand, one agent (the leader) determines the structure and sets the prices for using the hub backbone network. On the other hand, the other agent (follower) decides on the optimal usage of the network. The leader seeks to maximize its profit, while the follower aims to minimize the costs incurred for using the network to ship their commodities. We present a bilevel optimization formulation for this problem, followed by an equivalent single-level reformulation. Then, we propose a novel Co-Evolutionary Algorithm (Co-EA) to solve three well-known datasets of instances adapted for our problem. The main novelty of the proposed Co-EA lies in the way the co-evolving populations are considered. While traditionally one population focuses on the leader's solutions and the other on the follower's, in our approach, each population is associated with a subset of the leader's decision variables. Consequently, the follower's optimal reaction is obtained for a specific decision made by the leader, resulting in bilevel feasible solutions. We then analyze the results obtained from extensive computational experimentation using the proposed Co-EA.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00561v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>V\'ictor Blanco, Jos\'e-Fernando Camacho-Vallejo, Carlos Corpus</dc:creator>
    </item>
    <item>
      <title>An Improved NSGA-II with local search for multi-objective energy-efficient flowshop scheduling problem</title>
      <link>https://arxiv.org/abs/2503.00588</link>
      <description>arXiv:2503.00588v1 Announce Type: new 
Abstract: There has been an increasing concern to reduce the energy consumption in manufacturing and other industries. Energy consumption in manufacturing industries is directly related to efficient schedules. The contribution of this paper includes: i) a permutation flowshop scheduling problem (PFLSP) mathematical model by considering energy consumed by each machine in the system. ii) an improved non-dominated sorted genetic algorithm with Taguchi method with further incorporating local search (NSGA-II_LS) is proposed for the multi-objective PFLSP model. iii) solved 90 benchmarks problems of Taillard (1993) for the minimisation of flowtime (FT) and energy consumption (EC). The performance of the proposed NSGA_LS algorithm is evaluated on the benchmark problems selected from the published literature Li et. al, (2018). From these results, it is noted that the proposed algorithm performed better on both the objectives i.e., FT and EC minimization in 5 out of 9 cases. On FT objective our algorithm performed better in 8 out of 9 cases and on EC objective 5 out of 9 cases. Overall, the proposed algorithm achieved 47% and 15.44% average improvement in FT and EC minimization respectively on the benchmark problems. From the results of 90 benchmark problems, it is observed that average difference in FT and EC between two solutions is decreasing as the problem size increases from 5 machines to 10 machines with an exception in one case. Further, it is observed that the performance of the proposed algorithm is better as the problem size increases in both jobs and machines. These results can act as standard solutions for further research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00588v1</guid>
      <category>math.OC</category>
      <category>cs.MS</category>
      <category>cs.NE</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vigneshwar Pesaru, Venkataramanaiah Saddikuti</dc:creator>
    </item>
    <item>
      <title>Real-Time Personalization with Simple Transformers</title>
      <link>https://arxiv.org/abs/2503.00608</link>
      <description>arXiv:2503.00608v1 Announce Type: new 
Abstract: Real-time personalization has advanced significantly in recent years, with platforms utilizing machine learning models to predict user preferences based on rich behavioral data on each individual user. Traditional approaches usually rely on embedding-based machine learning models to capture user preferences, and then reduce the final optimization task to nearest-neighbors, which can be performed extremely fast. However, these models struggle to capture complex user behaviors, which are essential for making accurate recommendations. Transformer-based models, on the other hand, are known for their practical ability to model sequential behaviors, and hence have been intensively used in personalization recently to overcome these limitations. However, optimizing recommendations under transformer-based models is challenging due to their complicated architectures. In this paper, we address this challenge by considering a specific class of transformers, showing its ability to represent complex user preferences, and developing efficient algorithms for real-time personalization.
  We focus on a particular set of transformers, called simple transformers, which contain a single self-attention layer. We show that simple transformers are capable of capturing complex user preferences. We then develop an algorithm that enables fast optimization of recommendation tasks based on simple transformers. Our algorithm achieves near-optimal performance in sub-linear time. Finally, we demonstrate the effectiveness of our approach through an empirical study on datasets from Spotify and Trivago. Our experiment results show that (1) simple transformers can model/predict user preferences substantially more accurately than non-transformer models and nearly as accurately as more complex transformers, and (2) our algorithm completes simple-transformer-based recommendation tasks quickly and effectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00608v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lin An, Andrew A. Li, Vaisnavi Nemala, Gabriel Visotsky</dc:creator>
    </item>
    <item>
      <title>Optimal Control of Nonconvex Sweeping Processes with Variable Time via Finite-Difference Approximations</title>
      <link>https://arxiv.org/abs/2503.00667</link>
      <description>arXiv:2503.00667v1 Announce Type: new 
Abstract: The paper is devoted to the study of a new class of optimal control problems for nonsmooth dynamical systems governed by nonconvex discontinuous differential inclusions of the sweeping type with involving variable time into optimization. We develop a novel version of the method of discrete approximations of its own qualitative and numerical importance with establishing its well-posedness and strong convergence to optimal solutions of the controlled sweeping process. Using advanced tools of variational analysis and generalized differentiation leads us to deriving new necessary conditions for optimal solutions to discrete approximation problems, which serve as suboptimality conditions for the original continuous-time controlled sweeping process. The obtained results are applied to a class of motion models of practical interest, where the established necessary conditions are used to investigate the agents' interactions and to develop an algorithm for calculating optimal solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00667v1</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tan H. Cao, Boris S. Mordukhovich, Dao Nguyen, Trang Nguyen, Nguyen N. Thieu</dc:creator>
    </item>
    <item>
      <title>Deep Learning for Energy Market Contracts: Dynkin Game with Doubly RBSDEs</title>
      <link>https://arxiv.org/abs/2503.00880</link>
      <description>arXiv:2503.00880v1 Announce Type: new 
Abstract: This paper examines a Contract for Difference (CfD) with early exit options, a widely used risk management instrument in electricity markets. The contract involves a producer and a regulatory entity, both of whom can strategically exit based on evolving market conditions. The problem is formulated as a two-player Dynkin game, where electricity prices follow a mean-reverting stochastic process, and contract terminations incur penalties. The strategic interaction is modeled using Doubly Reflected Backward Stochastic Differential Equations (DRBSDEs), which characterize the fair value of the contract and optimal exit strategies. To solve the DRBSDEs, we develop a deep learning-based numerical method, leveraging neural networks for efficient approximation. The results provide insights into the role of exit penalties, price volatility, and market dynamics in optimizing CfD agreements, offering practical implications for policymakers and market participants.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00880v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nacira Agram, Ihsan Arharas, Giulia Pucci, Jan Rems</dc:creator>
    </item>
    <item>
      <title>On second-order Karush--Kuhn--Tucker optimality conditions for $C^{1,1}$ vector optimization problems</title>
      <link>https://arxiv.org/abs/2503.00927</link>
      <description>arXiv:2503.00927v1 Announce Type: new 
Abstract: This paper focuses on optimality conditions for $C^{1,1}$ vector optimization problems with inequality constraints. By employing the limiting second-order subdifferential and the second-order tangent set, we introduce a new type of second-order constraint qualification in the sense of Abadie. Then we establish some second-order necessary optimality conditions of Karush--Kuhn--Tucker-type for local (weak) efficient solutions of the considered problem. In addition, we provide some sufficient conditions for a local efficient solution of the such problem. The obtained results improve existing ones in the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00927v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nguyen Van Tuyen</dc:creator>
    </item>
    <item>
      <title>Non Null-Controllability Properties of the Grushin-Like Heat Equation on 2D-Manifolds</title>
      <link>https://arxiv.org/abs/2503.00997</link>
      <description>arXiv:2503.00997v1 Announce Type: new 
Abstract: We study the internal non null-controllability properties of the heat equation on 2-dimensional almost-Riemannian manifolds with an interior singularity, and under the assumption that the closure of the control zone does not contain the whole singularity. We show that if locally, around the singularity, the sub-Riemannian metric can be written in a Grushin form, or equivalently the sub-Laplacian writes as a generalized Grushin operator, then, achieving null-controllability requires at least a minimal amount of time. As locally the manifold looks like a rectangular domain, we consequently focus ourselves on the non null-controllability properties of the generalized Grushin-like heat equation on various Euclidean domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00997v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Roman Vanlaere</dc:creator>
    </item>
    <item>
      <title>Combinatorial and Computational Insights about Patient-to-room Assignment under Consideration of Roommate Compatibility</title>
      <link>https://arxiv.org/abs/2503.01021</link>
      <description>arXiv:2503.01021v1 Announce Type: new 
Abstract: During a hospital stay, a roommate can significantly influence a patient's overall experience both positivly and negatively. Therefore, hospital staff tries to assign patients together to a room that are likely to be compatible. However, there are more conditions and objectives to be respected by the patient-to-room assignment (PRA), e.g., ensuring gender separated rooms and avoiding transfers. In this paper, we review the literature for reasons why roommate compatibility is important as well as for criteria that can help to increase the probability that two patients are suitable roommates. We further present combinatorial insights about computing patient-to-room assignments with optimal overall roommate compatibility. We then compare different IP-formulations for PRA as well as the influence of different scoring functions for patient compatibility on the runtime of PRA integer programming (IP) optimisation. Using these results and real-world data, we conclude this paper by developing and evaluating a fast IP-based solution approach for the dynamic PRA.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01021v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tabea Brandt, Christina B\"using, Felix Engelhard</dc:creator>
    </item>
    <item>
      <title>Continuous-time mean field games: a primal-dual characterization</title>
      <link>https://arxiv.org/abs/2503.01042</link>
      <description>arXiv:2503.01042v1 Announce Type: new 
Abstract: This paper establishes a primal-dual formulation for continuous-time mean field games (MFGs) and provides a complete analytical characterization of the set of all Nash equilibria (NEs). We first show that for any given mean field flow, the representative player's control problem with {\it measurable coefficients} is equivalent to a linear program over the space of occupation measures. We then establish the dual formulation of this linear program as a maximization problem over smooth subsolutions of the associated Hamilton-Jacobi-Bellman (HJB) equation, which plays a fundamental role in characterizing NEs of MFGs. Finally, a complete characterization of \emph{all NEs for MFGs} is established by the strong duality between the linear program and its dual problem. This strong duality is obtained by studying the solvability of the dual problem, and in particular through analyzing the regularity of the associated HJB equation.
  Compared with existing approaches for MFGs, the primal-dual formulation and its NE characterization do not require the convexity of the associated Hamiltonian or the uniqueness of its optimizer, and remain applicable when the HJB equation lacks classical or even continuous solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01042v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xin Guo, Anran Hu, Jiacheng Zhang, Yufei Zhang</dc:creator>
    </item>
    <item>
      <title>Complexity of Linearized Perturbed Augmented Lagrangian Methods for Nonsmooth Nonconvex Optimization with Nonlinear Equality Constraints</title>
      <link>https://arxiv.org/abs/2503.01056</link>
      <description>arXiv:2503.01056v1 Announce Type: new 
Abstract: This paper addresses a class of general nonsmooth and nonconvex composite optimization problems subject to nonlinear equality constraints. We assume that a part of the objective function and the functional constraints exhibit local smoothness. To tackle this challenging class of problems, we propose a novel linearized perturbed augmented Lagrangian method. This method incorporates a perturbation in the augmented Lagrangian function by scaling the dual variable with a sub-unitary parameter. Furthermore, we linearize the smooth components of the objective and the constraints within the perturbed Lagrangian function at the current iterate, while preserving the nonsmooth components. This approach, inspired by prox-linear (or Gauss-Newton) methods, results in a convex subproblem that is typically easy to solve. The solution of this subproblem then serves as the next primal iterate, followed by a perturbed ascent step to update the dual variables. Under a newly introduced constraint qualification condition, we establish the boundedness of the dual iterates. We derive convergence guarantees for the primal iterates, proving convergence to an $\epsilon$-first-order optimal solution within $\mathcal{O}(\epsilon^{-3})$ evaluations of the problem's functions and their first derivatives. Moreover, when the problem exhibits for example a semialgebraic property, we derive improved local convergence results. Finally, we validate the theoretical findings and assess the practical performance of our proposed algorithm through numerical comparisons with existing state-of-the-art methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01056v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lahcen El Bourkhissi, Ion Necoara, Panagiotis Patrinos, Quoc Tran-Dinh</dc:creator>
    </item>
    <item>
      <title>Convergence rates for an inexact linearized ADMM for nonsmooth nonconvex optimization with nonlinear equality constraints</title>
      <link>https://arxiv.org/abs/2503.01060</link>
      <description>arXiv:2503.01060v1 Announce Type: new 
Abstract: In this paper, we consider nonconvex optimization problems with nonsmooth nonconvex objective function and nonlinear equality constraints. We assume that both the objective function and the functional constraints can be separated into 2 blocks. To solve this problem, we introduce a new inexact linearized alternating direction method of multipliers (ADMM) algorithm. Specifically, at each iteration, we linearize the smooth part of the objective function and the nonlinear part of the functional constraints within the augmented Lagrangian and add a dynamic quadratic regularization. We then compute the new iterate of the block associated with nonlinear constraints inexactly. This strategy yields subproblems that are easily solvable and their (inexact) solutions become the next iterates. Using Lyapunov arguments, we establish convergence guarantees for the iterates of our method toward an $\epsilon$-first-order solution within $\mathcal{O}(\epsilon^{-2})$ iterations. Moreover, we demonstrate that in cases where the problem data exhibit e.g., semi-algebraic properties or more general the KL condition, the entire sequence generated by our algorithm converges, and we provide convergence rates. To validate both the theory and the performance of our algorithm, we conduct numerical simulations for several nonlinear model predictive control and matrix factorization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01060v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lahcen El Bourkhissi, Ion Necoara</dc:creator>
    </item>
    <item>
      <title>An adaptive forward-backward-forward splitting algorithm for solving pseudo-monotone inclusions</title>
      <link>https://arxiv.org/abs/2503.01070</link>
      <description>arXiv:2503.01070v1 Announce Type: new 
Abstract: In this paper, we propose an adaptive forward-backward-forward splitting algorithm for finding a zero of a pseudo-monotone operator which is split as a sum of three operators: the first is continuous single-valued, the second is Lipschitzian, and the third is maximally monotone. This setting covers, in particular, constrained minimization scenarios, such as problems having smooth and convex functional constraints (e.g., quadratically constrained quadratic programs) or problems with a pseudo-convex objective function minimized over a simple closed convex set (e.g., quadratic over linear fractional programs). For the general problem, we design a forward-backward-forward splitting type method based on novel adaptive stepsize strategies. Under an additional generalized Lipschitz property of the first operator, sublinear convergence rate is derived for the sequence generated by our adaptive algorithm. Moreover, if the sum is uniformly pseudo-monotone, linear/sublinear rates are derived depending on the parameter of uniform pseudo-monotonicity. Preliminary numerical experiments demonstrate the good performance of our method when compared to some existing optimization methods and software.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01070v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Flavia Chorobura, Ion Necoara, Jean-Christophe Pesquet</dc:creator>
    </item>
    <item>
      <title>Steepest Descent Algorithm for M-convex Function Minimization Using Long Step Length</title>
      <link>https://arxiv.org/abs/2503.01110</link>
      <description>arXiv:2503.01110v1 Announce Type: new 
Abstract: We consider the minimization of an M-convex function, which is a discrete convexity concept for functions on the integer lattice points. It is known that a minimizer of an Mconvex function can be obtained by the steepest descent algorithm. In this paper, we propose an effective use of long step length in the steepest descent algorithm, aiming at the reduction in the running time. In particular, we obtain an improved time bound by using long step length. We also consider the constrained M-convex function minimization and show that long step length can be applied to a variant of steepest descent algorithm as well.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01110v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Taihei Oki, Akiyoshi Shioura</dc:creator>
    </item>
    <item>
      <title>Nonmonotone higher-order Taylor approximation methods for composite problems</title>
      <link>https://arxiv.org/abs/2503.01182</link>
      <description>arXiv:2503.01182v1 Announce Type: new 
Abstract: We study composite optimization problems in which the smooth part of the objective function is \( p \)-times continuously differentiable, where \( p \geq 1 \) is an integer. Higher-order methods are known to be effective for solving such problems, as they speed up convergence rates. These methods often require, or implicitly ensure, a monotonic decrease in the objective function across iterations. Maintaining this monotonicity typically requires that the \( p \)-th derivative of the smooth part of the objective function is globally Lipschitz or that the generated iterates remain bounded. In this paper, we propose nonmonotone higher-order Taylor approximation (NHOTA) method for composite problems. Our method achieves the same nice global and rate of convergence properties as traditional higher-order methods while eliminating the need for global Lipschitz continuity assumptions, strict descent condition, or explicit boundedness of the iterates. Specifically, for nonconvex composite problems, we derive global convergence rate to a stationary point of order \( \mathcal{O}(k^{-\frac{p}{p+1}}) \), where \( k \) is the iteration counter. Moreover, when the objective function satisfies the Kurdyka-{\L}ojasiewicz (KL) property, we obtain improved rates that depend on the KL parameter. Furthermore, for convex composite problems, our method achieves sublinear convergence rate of order \( \mathcal{O}(k^{-p}) \) in function values. Finally, preliminary numerical experiments on nonconvex phase retrieval problems highlight the promising performance of the proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01182v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yassine Nabou</dc:creator>
    </item>
    <item>
      <title>On the convexity for the range set of two quadratic functions</title>
      <link>https://arxiv.org/abs/2503.01225</link>
      <description>arXiv:2503.01225v1 Announce Type: new 
Abstract: Given $n\times n$ symmetric matrices $A$ and $B$, Dines in 1941 proved that the joint range set $\{(x^TAx,x^TBx)|~x\in\mathbb{R}^n\}$ is always convex. Our paper is concerned with non-homogeneous extension of the Dines theorem for the range set $\mathbf{R}(f,g) = \{\left(f(x),g(x)\right)|~x \in \mathbb{R}^n \},$ $f(x) = x^T A x + 2a^T x + a_0$ and $g(x) = x^T B x + 2b^T x + b_0.$ We show that $\mathbf{R}(f,g)$ is convex if, and only if, any pair of level sets, $\{x\in\mathbb{R}^n|f(x)=\alpha\}$ and $\{x\in\mathbb{R}^n|g(x)=\beta\}$, do not separate each other. With the novel geometric concept about separation, we provide a polynomial-time procedure to practically check whether a given $\mathbf{R}(f,g)$ is convex or not.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01225v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.3934/jimo.2020169</arxiv:DOI>
      <arxiv:journal_reference>Journal of Industrial and Management Optimization, 18(1), pp. 575-592 (2022)</arxiv:journal_reference>
      <dc:creator>Huu-Quang Nguyen, Ya-Chi Chu, Ruey-Lin Sheu</dc:creator>
    </item>
    <item>
      <title>Towards net-zero manufacturing: carbon-aware scheduling for GHG emissions reduction</title>
      <link>https://arxiv.org/abs/2503.01325</link>
      <description>arXiv:2503.01325v1 Announce Type: new 
Abstract: Detailed scheduling has traditionally been optimized for the reduction of makespan and manufacturing costs. However, growing awareness of environmental concerns and increasingly stringent regulations are pushing manufacturing towards reducing the carbon footprint of its operations. Scope 2 emissions, which are the indirect emissions related to the production and consumption of grid electricity, are in fact estimated to be responsible for more than one-third of the global GHG emissions. In this context, carbon-aware scheduling can serve as a powerful way to reduce manufacturing's carbon footprint by considering the time-dependent carbon intensity of the grid and the availability of on-site renewable electricity.
  This study introduces a carbon-aware permutation flow-shop scheduling model designed to reduce scope 2 emissions. The model is formulated as a mixed-integer linear problem, taking into account the forecasted grid generation mix and available on-site renewable electricity, along with the set of jobs to be scheduled and their corresponding power requirements. The objective is to find an optimal day-ahead schedule that minimizes scope 2 emissions. The problem is addressed using a dedicated memetic algorithm, combining evolutionary strategy and local search.
  Results from computational experiments confirm that by considering the dynamic carbon intensity of the grid and on-site renewable electricity availability, substantial reductions in carbon emissions can be achieved.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01325v1</guid>
      <category>math.OC</category>
      <category>cs.NE</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Andrea Mencaroni, Pieter Leyman, Birger Raa, Stijn De Vuyst, Dieter Claeys</dc:creator>
    </item>
    <item>
      <title>Edge downgrades in the maximal covering location problem</title>
      <link>https://arxiv.org/abs/2503.01350</link>
      <description>arXiv:2503.01350v1 Announce Type: new 
Abstract: We tackle the downgrading maximal covering location problem within a network. In this problem, two actors with conflicting objectives are involved: (a) The location planner aims to determine the location of facilities to maximize the covered demand while anticipating that an attacker will attempt to reduce coverage by increasing the length of some edges (downgrade); (b) The attacker seeks to maximize the demand initially covered by the facilities but left uncovered after the downgrade. The attacker can increase the length of certain edges within a specified budget.
  We introduce a mixed-integer linear bilevel program to formulate the problem, followed by a preprocessing phase and a matheuristic algorithm designed to address it. Additionally, computational results are presented to illustrate the potential and limitations of the proposed algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01350v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.cor.2025.107003</arxiv:DOI>
      <arxiv:journal_reference>Computers &amp; Operations Research, Volume 178, June 2025, 107003</arxiv:journal_reference>
      <dc:creator>Marta Baldomero-Naranjo, J\"org Kalcsics, Antonio M. Rodr\'iguez-Ch\'ia</dc:creator>
    </item>
    <item>
      <title>A strong second-order sequential optimality condition for nonlinear programming problems</title>
      <link>https://arxiv.org/abs/2503.01430</link>
      <description>arXiv:2503.01430v1 Announce Type: new 
Abstract: Most numerical methods developed for solving nonlinear programming problems are designed to find points that satisfy certain optimality conditions. While the Karush-Kuhn-Tucker conditions are well-known, they become invalid when constraint qualifications (CQ) are not met. Recent advances in sequential optimality conditions address this limitation in both first- and second-order cases, providing genuine optimality guarantees at local optima, even when CQs do not hold. However, some second-order sequential optimality conditions still require some restrictive conditions on constraints in the recent literature. In this paper, we propose a new strong second-order sequential optimality condition without CQs. We also show that a penalty-type method and an augmented Lagrangian method generate points satisfying these new optimality conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01430v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Huimin Li, Yuya Yamakawa, Ellen H. Fukuda, Nobuo Yamashita</dc:creator>
    </item>
    <item>
      <title>Weak Proximal Newton Oracles for Composite Convex Optimization</title>
      <link>https://arxiv.org/abs/2503.01432</link>
      <description>arXiv:2503.01432v1 Announce Type: new 
Abstract: Second-order methods are of great importance for composite convex optimization problems due to their local super-linear convergence rates (under appropriate assumptions). However, the presence of even a simple nonsmooth function in the model most often renders the subproblems in proximal Newton methods computationally-difficult to solve in high-dimension. We introduce a novel approach based on a \textit{weak proximal Newton oracle} (WPNO), which only requires to solve such subproblems to accuracy that is comparable to that of the optimal solution of the global problem, while maintaining local super-linear convergence under standard assumptions. We show that when the optimal solution of the global problem admits some sparse structure, a WPNO could be implemented very efficiently using specialized first-order methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01432v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dan Garber</dc:creator>
    </item>
    <item>
      <title>A Linearly Convergent Frank-Wolfe-type Method for Smooth Convex Minimization over the Spectrahedron</title>
      <link>https://arxiv.org/abs/2503.01441</link>
      <description>arXiv:2503.01441v1 Announce Type: new 
Abstract: We consider the problem of minimizing a smooth and convex function over the $n$-dimensional spectrahedron -- the set of real symmetric $n\times n$ positive semidefinite matrices with unit trace, which underlies numerous applications in statistics, machine learning and additional domains. Standard first-order methods often require high-rank matrix computations which are prohibitive when the dimension $n$ is large. The well-known Frank-Wolfe method on the other hand, only requires efficient rank-one matrix computations, however suffers from worst-case slow convergence, even under conditions that enable linear convergence rates for standard methods. In this work we present the first Frank-Wolfe-based algorithm that only applies efficient rank-one matrix computations and, assuming quadratic growth and strict complementarity conditions, is guaranteed, after a finite number of iterations, to converges linearly, in expectation, and independently of the ambient dimension.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01441v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dan Garber</dc:creator>
    </item>
    <item>
      <title>Optimal Control of General Nonlocal Epidemic Models with Age and Space Structure</title>
      <link>https://arxiv.org/abs/2503.01466</link>
      <description>arXiv:2503.01466v1 Announce Type: new 
Abstract: We analyze a class of general nonlinear epidemic models with age and space structure, including a nonlocal infection term depending on age and space. After establishing the well-posedness of the state partial differential equation, we introduce a control parameter interpreted as a vaccination rate. Under certain conditions, we show that an optimal control exists and how it can be characterized by first-order optimality conditions. Finally, we present numerical examples of the optimal control problems governed by these models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01466v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Behzad Azmi, Nicolas Schlosser</dc:creator>
    </item>
    <item>
      <title>Numerical solving of an optimal control problem in large time horizon: the aerial vehicle guidance</title>
      <link>https://arxiv.org/abs/2503.01480</link>
      <description>arXiv:2503.01480v1 Announce Type: new 
Abstract: In this paper we consider an optimal control problem in large time horizon and solve it numerically. More precisely, we are interested in an aerial vehicle guidance problem: launched from a ground platform, the vehicle aims at reaching a ground/sea target under specified terminal conditions while minimizing a cost modelling some performance and constraint criteria. Our goal is to implement the indirect method based on the Pontryagin maximum principle (PMP) in order to solve such a problem. After modeling the problem, we implement continuations in order to ''connect'' a simple problem to the original one. Particularly, we exploit the turnpike property in order to enhance the efficiency of the shooting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01480v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Veljko Askovic (LJLL), Emmanuel Tr\'elat (LJLL), Hasnaa Zidani (LMI, NorMath)</dc:creator>
    </item>
    <item>
      <title>Solving Decision-Dependent Robust Problems as Bilevel Optimization Problems</title>
      <link>https://arxiv.org/abs/2503.01559</link>
      <description>arXiv:2503.01559v1 Announce Type: new 
Abstract: Both bilevel and robust optimization are established fields of mathematical optimization and operations research. However, only until recently, the similarities in their mathematical structure has neither been studied theoretically nor exploited computationally. Based on the recent results by \textcite{goerigk2025}, this paper is the first one that reformulates a given strictly robust optimization problem with a decision-dependent uncertainty set as an equivalent bilevel optimization problem and then uses solution techniques from the latter field to solve the robust problem at hand. If the uncertainty set can be dualized, the respective bilevel techniques to obtain a single-level reformulation are very similar compared to the classic dualization techniques used in robust optimization but lead to larger single-level problems to be solved. Our numerical study shows that this leads to larger computation times but may also slightly improve the dual bound. For the more challenging case of a decision-dependent uncertainty set that cannot be dualized because it is represented as a mixed-integer linear problem, we are not aware of any applicable robust optimization techniques. Fortunately, by exploiting the corresponding bilevel reformulation and recent bilevel solvers, we are able to present the first numerical results for this class of robust problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01559v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Henri Lefebvre, Martin Schmidt, Simon Stevens, Johannes Th\"urauf</dc:creator>
    </item>
    <item>
      <title>On Coupling Constraints in Pessimistic Linear Bilevel Optimization</title>
      <link>https://arxiv.org/abs/2503.01563</link>
      <description>arXiv:2503.01563v1 Announce Type: new 
Abstract: The literature on pessimistic bilevel optimization with coupling constraints is rather scarce and it has been common sense that these problems are harder to tackle than pessimistic bilevel problems without coupling constraints. In this note, we show that this is not the case. To this end, given a pessimistic problem with coupling constraints, we derive a pessimistic problem without coupling constraints that has the same set of globally optimal solutions. Moreover, our results also show that one can equivalently replace a pessimistic problem with such constraints with an optimistic problem without coupling constraints. This paves the way of both transferring theory and solution techniques from any type of these problems to any other one.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01563v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dorothee Henke, Henri Lefebvre, Martin Schmidt, Johannes Th\"urauf</dc:creator>
    </item>
    <item>
      <title>Cauchy-Schwarz Regularizers</title>
      <link>https://arxiv.org/abs/2503.01639</link>
      <description>arXiv:2503.01639v1 Announce Type: new 
Abstract: We introduce a novel class of regularization functions, called Cauchy-Schwarz (CS) regularizers, which can be designed to induce a wide range of properties in solution vectors of optimization problems. To demonstrate the versatility of CS regularizers, we derive regularization functions that promote discrete-valued vectors, eigenvectors of a given matrix, and orthogonal matrices. The resulting CS regularizers are simple, differentiable, and can be free of spurious stationary points, making them suitable for gradient-based solvers and large-scale optimization problems. In addition, CS regularizers automatically adapt to the appropriate scale, which is, for example, beneficial when discretizing the weights of neural networks. To demonstrate the efficacy of CS regularizers, we provide results for solving underdetermined systems of linear equations and weight quantization in neural networks. Furthermore, we discuss specializations, variations, and generalizations, which lead to an even broader class of new and possibly more powerful regularizers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01639v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sueda Taner, Ziyi Wang, Christoph Studer</dc:creator>
    </item>
    <item>
      <title>RecCrysFormer: Refined Protein Structural Prediction from 3D Patterson Maps via Recycling Training Runs</title>
      <link>https://arxiv.org/abs/2503.00143</link>
      <description>arXiv:2503.00143v1 Announce Type: cross 
Abstract: Determining protein structures at an atomic level remains a significant challenge in structural biology. We introduce $\texttt{RecCrysFormer}$, a hybrid model that exploits the strengths of transformers with the aim of integrating experimental and ML approaches to protein structure determination from crystallographic data. $\texttt{RecCrysFormer}$ leverages Patterson maps and incorporates known standardized partial structures of amino acid residues to directly predict electron density maps, which are essential for constructing detailed atomic models through crystallographic refinement processes. $\texttt{RecCrysFormer}$ benefits from a ``recycling'' training regimen that iteratively incorporates results from crystallographic refinements and previous training runs as additional inputs in the form of template maps. Using a preliminary dataset of synthetic peptide fragments based on Protein Data Bank, $\texttt{RecCrysFormer}$ achieves good accuracy in structural predictions and shows robustness against variations in crystal parameters, such as unit cell dimensions and angles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00143v1</guid>
      <category>q-bio.QM</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tom Pan, Evan Dramko, Mitchell D. Miller, George N. Phillips Jr., Anastasios Kyrillidis</dc:creator>
    </item>
    <item>
      <title>The Learning Approach to Games</title>
      <link>https://arxiv.org/abs/2503.00227</link>
      <description>arXiv:2503.00227v1 Announce Type: cross 
Abstract: This work provides a unified framework for exploring games. In existing literature, strategies of players are typically assigned scalar values, and the concept of Nash equilibrium is used to identify compatible strategies. However, this approach lacks the internal structure of a player, thereby failing to accurately model observed behaviors in reality. To address this limitation, we propose to characterize players by their learning algorithms, and as their estimations intrinsically induce a distribution over strategies, we introduced the notion of equilibrium in terms of characterizing the recurrent behaviors of the learning algorithms. This approach allows for a more nuanced understanding of players, and brings the focus to the challenge of learning that players face. While our explorations in discrete games, mean-field games, and reinforcement learning demonstrate the framework's broad applicability, they also set the stage for future research aimed at specific applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00227v1</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Melih \.I\c{s}eri, Erhan Bayraktar</dc:creator>
    </item>
    <item>
      <title>Armijo Line-search Makes (Stochastic) Gradient Descent Go Fast</title>
      <link>https://arxiv.org/abs/2503.00229</link>
      <description>arXiv:2503.00229v1 Announce Type: cross 
Abstract: Armijo line-search (Armijo-LS) is a standard method to set the step-size for gradient descent (GD). For smooth functions, Armijo-LS alleviates the need to know the global smoothness constant $L$ and adapts to the local smoothness, enabling GD to converge faster. However, existing theoretical analyses of GD with Armijo-LS (GD-LS) do not characterize this fast convergence. We show that if the objective function satisfies a certain non-uniform smoothness condition, GD-LS converges provably faster than GD with a constant $1/L$ step-size (denoted as GD(1/L)). Our results imply that for convex losses corresponding to logistic regression and multi-class classification, GD-LS can converge to the optimum at a linear rate and, hence, improve over the sublinear convergence of GD(1/L). Furthermore, for non-convex losses satisfying gradient domination (for example, those corresponding to the softmax policy gradient in RL or generalized linear models with a logistic link function), GD-LS can match the fast convergence of algorithms tailored for these specific settings. Finally, we prove that under the interpolation assumption, for convex losses, stochastic GD with a stochastic line-search can match the fast convergence of GD-LS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00229v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sharan Vaswani, Reza Babanezhad</dc:creator>
    </item>
    <item>
      <title>Hidden Convexity of Fair PCA and Fast Solver via Eigenvalue Optimization</title>
      <link>https://arxiv.org/abs/2503.00299</link>
      <description>arXiv:2503.00299v1 Announce Type: cross 
Abstract: Principal Component Analysis (PCA) is a foundational technique in machine learning for dimensionality reduction of high-dimensional datasets. However, PCA could lead to biased outcomes that disadvantage certain subgroups of the underlying datasets. To address the bias issue, a Fair PCA (FPCA) model was introduced by Samadi et al. (2018) for equalizing the reconstruction loss between subgroups. The semidefinite relaxation (SDR) based approach proposed by Samadi et al. (2018) is computationally expensive even for suboptimal solutions. To improve efficiency, several alternative variants of the FPCA model have been developed. These variants often shift the focus away from equalizing the reconstruction loss. In this paper, we identify a hidden convexity in the FPCA model and introduce an algorithm for convex optimization via eigenvalue optimization. Our approach achieves the desired fairness in reconstruction loss without sacrificing performance. As demonstrated in real-world datasets, the proposed FPCA algorithm runs $8\times$ faster than the SDR-based algorithm, and only at most 85% slower than the standard PCA.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00299v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Junhui Shen, Aaron J. Davis, Ding Lu, Zhaojun Bai</dc:creator>
    </item>
    <item>
      <title>Communication and Control Co-design in Non-cooperative Games</title>
      <link>https://arxiv.org/abs/2503.00313</link>
      <description>arXiv:2503.00313v1 Announce Type: cross 
Abstract: In this article, we revisit a communication-control co-design problem for a class of two-player stochastic differential games on an infinite horizon. Each 'player' represents two active decision makers, namely a scheduler and a remote controller, which cooperate to optimize over a global objective while competing with the other player. Each player's scheduler can only intermittently relay state information to its respective controller due to associated cost/constraint to communication. The scheduler's policy determines the information structure at the controller, thereby affecting the quality of the control inputs. Consequently, it leads to the classical communication-control trade-off problem. A high communication frequency improves the control performance of the player on account of a higher communication cost, and vice versa. Under suitable information structures of the players, we first compute the Nash controller policies for both players in terms of the conditional estimate of the state. Consequently, we reformulate the problem of computing Nash scheduler policies (within a class of parametrized randomized policies) into solving for the steady-state solution of a generalized Sylvester equation. Since the above-mentioned reformulation involves infinite sum of powers of the policy parameters, we provide a projected gradient descent-based algorithm to numerically compute a Nash equilibrium using a truncated polynomial approximation. Finally, we demonstrate the performance of the Nash control and scheduler policies using extensive numerical simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00313v1</guid>
      <category>eess.SY</category>
      <category>cs.GT</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shubham Aggarwal, Tamer Ba\c{s}ar, Dipankar Maity</dc:creator>
    </item>
    <item>
      <title>A physics-informed Bayesian optimization method for rapid development of electrical machines</title>
      <link>https://arxiv.org/abs/2503.00420</link>
      <description>arXiv:2503.00420v1 Announce Type: cross 
Abstract: Advanced slot and winding designs are imperative to create future high performance electrical machines (EM). As a result, the development of methods to design and improve slot filling factor (SFF) has attracted considerable research. Recent developments in manufacturing processes, such as additive manufacturing and alternative materials, has also highlighted a need for novel high-fidelity design techniques to develop high performance complex geometries and topologies. This study therefore introduces a novel physics-informed machine learning (PIML) design optimization process for improving SFF in traction electrical machines used in electric vehicles. A maximum entropy sampling algorithm (MESA) is used to seed a physics-informed Bayesian optimization (PIBO) algorithm, where the target function and its approximations are produced by Gaussian processes (GP)s. The proposed PIBO-MESA is coupled with a 2D finite element model (FEM) to perform a GP-based surrogate and provide the first demonstration of the optimal combination of complex design variables for an electrical machine. Significant computational gains were achieved using the new PIBO-MESA approach, which is 45% faster than existing stochastic methods, such as the non-dominated sorting genetic algorithm II (NSGA-II). The FEM results confirm that the new design optimization process and keystone shaped wires lead to a higher SFF (i.e. by 20%) and electromagnetic improvements (e.g. maximum torque by 12%) with similar resistivity. The newly developed PIBO-MESA design optimization process therefore presents significant benefits in the design of high-performance electric machines, with reduced development time and costs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00420v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1038/s41598-024-54965-2</arxiv:DOI>
      <dc:creator>Pedram Asef, Christopher Vagg</dc:creator>
    </item>
    <item>
      <title>Functional multi-armed bandit and the best function identification problems</title>
      <link>https://arxiv.org/abs/2503.00509</link>
      <description>arXiv:2503.00509v1 Announce Type: cross 
Abstract: Bandit optimization usually refers to the class of online optimization problems with limited feedback, namely, a decision maker uses only the objective value at the current point to make a new decision and does not have access to the gradient of the objective function. While this name accurately captures the limitation in feedback, it is somehow misleading since it does not have any connection with the multi-armed bandits (MAB) problem class. We propose two new classes of problems: the functional multi-armed bandit problem (FMAB) and the best function identification problem. They are modifications of a multi-armed bandit problem and the best arm identification problem, respectively, where each arm represents an unknown black-box function. These problem classes are a surprisingly good fit for modeling real-world problems such as competitive LLM training. To solve the problems from these classes, we propose a new reduction scheme to construct UCB-type algorithms, namely, the F-LCB algorithm, based on algorithms for nonlinear optimization with known convergence rates. We provide the regret upper bounds for this reduction scheme based on the base algorithms' convergence rates. We add numerical experiments that demonstrate the performance of the proposed scheme.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00509v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Yuriy Dorn, Aleksandr Katrutsa, Ilgam Latypov, Anastasiia Soboleva</dc:creator>
    </item>
    <item>
      <title>Computer Assisted Discovery of Integrability via SILO: Sparse Identification of Lax Operators</title>
      <link>https://arxiv.org/abs/2503.00645</link>
      <description>arXiv:2503.00645v1 Announce Type: cross 
Abstract: We formulate the discovery of Lax integrability of Hamiltonian dynamical systems as a symbolic regression problem, which, loosely speaking, seeks to maximize the compatibility between a pair of Lax operators and the known Hamiltonian of the dynamical system. Our approach is first tested on the simple harmonic oscillator. We then move on to the Henon-Heiles system, i.e. a two-degree-of-freedom system of nonlinear oscillators. The integrability of the Henon-Heiles system is critically dependent on a set of three parameters within its Hamiltonian, a fact that we leverage to assess the robustness of our approach in detecting the integrability of this system with respect to the parameter dependence of the Hamiltonian. We then adapt our method to canonical examples of Hamiltonian partial differential equations, including the Korteweg-de Vries and cubic nonlinear Schr\"odinger equations, again testing robustness against nonintegrable perturbations of their respective Hamiltonians. In all examples, our approach reliably confirms or denies the integrability of the equations of interest. Moreover, by appropriately adjusting the loss function and applying thresholded $l^0$ regularization to enforce sparsity in the operator weights, we successfully recover accurate forms of the Lax pairs despite wide initial hypotheses on the operators. Some of the relevant Lax pairs, notably for the Henon-Heiles system and the Korteweg-deVries equation, are distinct from the ones that are typically reported in the literature. The Lax pairs that our methodology discovers warrant further mathematical and computational investigation, and we discuss extensively the opportunities for further improvement of SILO as a viable tool for interpretable exploration of integrable Hamiltonian dynamical systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00645v1</guid>
      <category>nlin.SI</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jimmie Adriazola, Wei Zhu, Panayotis Kevrekidis, Alejandro Aceves</dc:creator>
    </item>
    <item>
      <title>Hybrid Metaheuristic Vehicle Routing Problem for Security Dispatch Operations</title>
      <link>https://arxiv.org/abs/2503.01121</link>
      <description>arXiv:2503.01121v1 Announce Type: cross 
Abstract: This paper investigates the optimization of the Vehicle Routing Problem for Security Dispatch (VRPSD). VRPSD focuses on security and patrolling applications which involve challenging constraints including precise timing and strict time windows. We propose three algorithms based on different metaheuristics, which are Adaptive Large Neighborhood Search (ALNS), Tabu Search (TS), and Threshold Accepting (TA). The first algorithm combines single-phase ALNS with TA, the second employs a multiphase ALNS with TA, and the third integrates multiphase ALNS, TS, and TA. Experiments are conducted on an instance comprising 251 customer requests. The results demonstrate that the third algorithm, the hybrid multiphase ALNS-TS-TA algorithm, delivers the best performance. This approach simultaneously leverages the large-area search capabilities of ALNS for exploration and effectively escapes local optima when the multiphase ALNS is coupled with TS and TA. Furthermore, in our experiments, the hybrid multiphase ALNS-TS-TA algorithm is the only one that shows potential for improving results with increased computation time across all attempts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01121v1</guid>
      <category>cs.AI</category>
      <category>cs.DM</category>
      <category>math.OC</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Nguyen Gia Hien Vu, Yifan Tang, Rey Lim, G. Gary Wang</dc:creator>
    </item>
    <item>
      <title>Building Interval Type-2 Fuzzy Membership Function: A Deck of Cards based Co-constructive Approach</title>
      <link>https://arxiv.org/abs/2503.01413</link>
      <description>arXiv:2503.01413v1 Announce Type: cross 
Abstract: Since its inception, Fuzzy Set has been widely used to handle uncertainty and imprecision in decision-making. However, conventional fuzzy sets, often referred to as type-1 fuzzy sets (T1FSs) have limitations in capturing higher levels of uncertainty, particularly when decision-makers (DMs) express hesitation or ambiguity in membership degree. To address this, Interval Type-2 Fuzzy Sets (IT2FSs) have been introduced by incorporating uncertainty in membership degree allocation, which enhanced flexibility in modelling subjective judgments. Despite their advantages, existing IT2FS construction methods often lack active involvement from DMs and that limits the interpretability and effectiveness of decision models. This study proposes a socio-technical co-constructive approach for developing IT2FS models of linguistic terms by facilitating the active involvement of DMs in preference elicitation and its application in multicriteria decision-making (MCDM) problems. Our methodology is structured in two phases. The first phase involves an interactive process between the DM and the decision analyst, in which a modified version of Deck-of-Cards (DoC) method is proposed to construct T1FS membership functions on a ratio scale. We then extend this method to incorporate ambiguity in subjective judgment and that resulted in an IT2FS model that better captures uncertainty in DM's linguistic assessments. The second phase formalizes the constructed IT2FS model for application in MCDM by defining an appropriate mathematical representation of such information, aggregation rules, and an admissible ordering principle. The proposed framework enhances the reliability and effectiveness of fuzzy decision-making not only by accurately representing DM's personalized semantics of linguistic information.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01413v1</guid>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bapi Dutta, Diego Garc\'ia-Zamora, Jos\'e Rui Figueira, Luis Mart\'inez</dc:creator>
    </item>
    <item>
      <title>The State-Dependent Riccati Equation in Nonlinear Optimal Control: Analysis, Error Estimation and Numerical Approximation</title>
      <link>https://arxiv.org/abs/2503.01587</link>
      <description>arXiv:2503.01587v1 Announce Type: cross 
Abstract: The State-Dependent Riccati Equation (SDRE) approach is extensively utilized in nonlinear optimal control as a reliable framework for designing robust feedback control strategies. This work provides an analysis of the SDRE approach, examining its theoretical foundations, error bounds, and numerical approximation techniques. We explore the relationship between SDRE and the Hamilton-Jacobi-Bellman (HJB) equation, deriving residual-based error estimates to quantify its suboptimality. Additionally, we introduce an optimal semilinear decomposition strategy to minimize the residual. From a computational perspective, we analyze two numerical methods for solving the SDRE: the offline-online approach and the Newton-Kleinman iterative method. Their performance is assessed through a numerical experiment involving the control of a nonlinear reaction-diffusion PDE. Results highlight the trade-offs between computational efficiency and accuracy, demonstrating the superiority of the Newton-Kleinman approach in achieving stable and cost-effective solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01587v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luca Saluzzi</dc:creator>
    </item>
    <item>
      <title>A systematic approach to general higher-order majorization-minimization algorithms for (non)convex optimization</title>
      <link>https://arxiv.org/abs/2010.13893</link>
      <description>arXiv:2010.13893v4 Announce Type: replace 
Abstract: Majorization-minimization algorithms consist of successively minimizing a sequence of upper bounds of the objective function so that along the iterations the objective function decreases. Such a simple principle allows to solve a large class of optimization problems, even nonconvex and nonsmooth. We propose a general higher-order majorization-minimization algorithmic framework for minimizing an objective function that admits an approximation (surrogate) such that the corresponding error function has a higher-order Lipschitz continuous derivative. We present convergence guarantees for our new method for general optimization problems with (non)convex and/or (non)smooth objective function. For convex (possibly nonsmooth) problems we provide global sublinear convergence rates, while for problems with uniformly convex objective function we obtain locally faster superlinear convergence rates. We also prove global stationary point guarantees for general nonconvex (possibly nonsmooth) problems and under Kurdyka-Lojasiewicz property of the objective function we derive local convergence rates ranging from sublinear to superlinear for our majorization-minimization algorithm. Moreover, for unconstrained nonconvex problems we derive convergence rates in terms of first- and second-order optimality conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2010.13893v4</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ion Necoara, Daniela Lupu</dc:creator>
    </item>
    <item>
      <title>Efficiency of higher-order algorithms for minimizing composite functions</title>
      <link>https://arxiv.org/abs/2203.13367</link>
      <description>arXiv:2203.13367v3 Announce Type: replace 
Abstract: Composite minimization involves a collection of functions which are aggregated in a nonsmooth manner. It covers, as a particular case, smooth approximation of minimax games, minimization of max-type functions, and simple composite minimization problems, where the objective function has a nonsmooth component. We design a higher-order majorization algorithmic framework for fully composite problems (possibly nonconvex). Our framework replaces each component with a higher-order surrogate such that the corresponding error function has a higher-order Lipschitz continuous derivative. We present convergence guarantees for our method for composite optimization problems with (non)convex and (non)smooth objective function. In particular, we prove stationary point convergence guarantees for general nonconvex (possibly nonsmooth) problems and under Kurdyka-Lojasiewicz (KL) property of the objective function we derive improved rates depending on the KL parameter. For convex (possibly nonsmooth) problems we also provide sublinear convergence rates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2203.13367v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/s10589-023-00533-9</arxiv:DOI>
      <arxiv:journal_reference>Computational Optimization and Applications, 2023</arxiv:journal_reference>
      <dc:creator>Yassine Nabou, Ion Necoara</dc:creator>
    </item>
    <item>
      <title>On the Smallest Support Size of Integer Solutions to Linear Equations</title>
      <link>https://arxiv.org/abs/2307.08826</link>
      <description>arXiv:2307.08826v2 Announce Type: replace 
Abstract: In this note, we study the size of the support of integer solutions to linear equations $Ax=b, ~x\in\Z^n$ where $A\in\Z^{m\times n}, b\in\Z^n$. We give an upper bound on the smallest support size as a function of $A$, taken as a worst case over all $b$ such that the above system has a solution. This bound is asymptotically tight, and in fact matches the bound given in Aliev, Averkov, De Loera and Oertel Mathematical Programming 2022, while the proof presented here is simpler, relying only on linear algebra.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.08826v2</guid>
      <category>math.OC</category>
      <category>math.NT</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/s10107-025-02202-7</arxiv:DOI>
      <dc:creator>Yatharth Dubey, Siyue Liu</dc:creator>
    </item>
    <item>
      <title>Adaptive Softassign via Hadamard-Equipped Sinkhorn</title>
      <link>https://arxiv.org/abs/2309.13855</link>
      <description>arXiv:2309.13855v3 Announce Type: replace 
Abstract: Softassign is a pivotal method in graph matching and other learning tasks. Many softassign-based algorithms exhibit performance sensitivity to a parameter in the softassign. However, tuning the parameter is challenging and almost done empirically. This paper proposes an adaptive softassign method for graph matching by analyzing the relationship between the objective score and the parameter. This method can automatically tune the parameter based on a given error bound to guarantee accuracy. The Hadamard-Equipped Sinkhorn formulas introduced in this study significantly enhance the efficiency and stability of the adaptive softassign. Moreover, these formulas can also be used in optimal transport problems. The resulting adaptive softassign graph matching algorithm enjoys significantly higher accuracy than previous state-of-the-art large graph matching algorithms while maintaining comparable efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.13855v3</guid>
      <category>math.OC</category>
      <category>math.CO</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Binrui Shen, Qiang Niu, Shengxin Zhu</dc:creator>
    </item>
    <item>
      <title>Robust Stability of Neural Network Control Systems with Interval Matrix Uncertainties</title>
      <link>https://arxiv.org/abs/2311.15109</link>
      <description>arXiv:2311.15109v2 Announce Type: replace 
Abstract: Neural networks have become increasingly popular in controller design due to their versatility and efficiency. However, their integration into feedback systems can pose stability challenges, particularly in the presence of uncertainties. This work addresses the problem of certifying robust stability in neural network control systems with interval matrix uncertainties. Leveraging classical robust stability techniques and the quadratic constraint-based method to characterize the input-output behavior of neural networks, we derive novel robust stability certificates formulated as linear matrix inequalities. To reduce computational complexity, we introduce three relaxed sufficient conditions and establish their equivalence in terms of feasibility. Additionally, we explore their connections to existing robust stability results. The effectiveness of the proposed approach is demonstrated through inverted pendulum and mass-spring-damper examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.15109v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuhao Zhang, Xiangru Xu</dc:creator>
    </item>
    <item>
      <title>Moving higher-order Taylor approximations method for smooth constrained minimization problems</title>
      <link>https://arxiv.org/abs/2402.15022</link>
      <description>arXiv:2402.15022v2 Announce Type: replace 
Abstract: In this paper we develop a higher-order method for solving composite (non)convex minimization problems with smooth (non)convex functional constraints. At each iteration our method approximates the smooth part of the objective function and of the constraints by higher-order Taylor approximations, leading to a moving Taylor approximation method (MTA). We present convergence guarantees for MTA algorithm for both, nonconvex and convex problems. In particular, when the objective and the constraints are nonconvex functions, we prove that the sequence generated by MTA algorithm converges globally to a KKT point. Moreover, we derive convergence rates in the iterates when the problem data satisfy the Kurdyka-Lojasiewicz (KL) property. Further, when the objective function is (uniformly) convex and the constraints are also convex, we provide (linear/superlinear) sublinear convergence rates for our algorithm. Finally, we present an efficient implementation of the proposed algorithm and compare it with existing methods from the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.15022v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yassine Nabou, Ion Necoara</dc:creator>
    </item>
    <item>
      <title>Offline Learning of Decision Functions in Multiplayer Games with Expectation Constraints</title>
      <link>https://arxiv.org/abs/2402.15724</link>
      <description>arXiv:2402.15724v2 Announce Type: replace 
Abstract: We explore a class of stochastic multiplayer games where each player in the game aims to optimize its objective under uncertainty and adheres to some expectation constraints. The study employs an offline learning paradigm, leveraging a pre-existing dataset containing auxiliary features. While prior research in deterministic and stochastic multiplayer games primarily explored vector-valued decisions, this work departs by considering function-valued decisions that incorporate auxiliary features as input. We leverage the law of large deviations and degree theory to establish the almost sure convergence of the offline learning solution to the true solution as the number of data samples increases. Finally, we demonstrate the validity of our method via a multi-account portfolio optimization problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.15724v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuanhanqing Huang, Jianghai Hu</dc:creator>
    </item>
    <item>
      <title>Linear quadratic control of nonlinear systems with Koopman operator learning and the Nystr\"om method</title>
      <link>https://arxiv.org/abs/2403.02811</link>
      <description>arXiv:2403.02811v4 Announce Type: replace 
Abstract: In this paper, we study how the Koopman operator framework can be combined with kernel methods to effectively control nonlinear dynamical systems. While kernel methods have typically large computational requirements, we show how random subspaces (Nystr\"om approximation) can be used to achieve huge computational savings while preserving accuracy. Our main technical contribution is deriving theoretical guarantees on the effect of the Nystr\"om approximation. More precisely, we study the linear quadratic regulator problem, showing that the approximated Riccati operator converges at the rate $m^{-1/2}$, and the regulator objective, for the associated solution of the optimal control problem, converges at the rate $m^{-1}$, where $m$ is the random subspace size. Theoretical findings are complemented by numerical experiments corroborating our results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02811v4</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>stat.ML</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Edoardo Caldarelli, Antoine Chatalic, Adri\`a Colom\'e, Cesare Molinari, Carlos Ocampo-Martinez, Carme Torras, Lorenzo Rosasco</dc:creator>
    </item>
    <item>
      <title>Tight Bounds on Polynomials and Its Application to Dynamic Optimization Problems</title>
      <link>https://arxiv.org/abs/2403.07707</link>
      <description>arXiv:2403.07707v3 Announce Type: replace 
Abstract: This paper presents a pseudo-spectral method for Dynamic Optimization Problems (DOPs) that allows for tight polynomial bounds to be achieved via flexible sub-intervals. The proposed method not only rigorously enforces inequality constraints, but also allows for a lower cost in comparison with non-flexible discretizations. Two examples are provided to demonstrate the feasibility of the proposed method to solve optimal control problems. Solutions to the example problems exhibited up to a tenfold reduction in relative cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07707v3</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eduardo M. G. Vila, Eric C. Kerrigan, Paul Bruce</dc:creator>
    </item>
    <item>
      <title>New second-order optimality conditions for directional optimality of a general set-constrained optimization problem</title>
      <link>https://arxiv.org/abs/2404.17696</link>
      <description>arXiv:2404.17696v2 Announce Type: replace 
Abstract: In this paper we derive new second-order optimality conditions for a very general set-constrained optimization problem where the underlying set may be nononvex. We consider local optimality in specific directions (i.e., optimal in a directional neighborhood) in pursuit of developing these new optimality conditions. First-order necessary conditions for local optimality in given directions are provided by virtue of the corresponding directional normal cones. Utilizing the classical and/or the lower generalized support function, we obtain new second-order necessary and sufficient conditions for local optimality of general nonconvex constrained optimization problem in given directions via both the corresponding asymptotic second-order tangent cone and outer second-order tangent set. Our results do not require convexity and/or nonemptyness of the outer second-order tangent set. This is an important improvement to other results in the literature since the outer second-order tangent set can be nonconvex and empty even when the set is convex.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17696v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wei Ouyang, Jane Ye, Binbin Zhang</dc:creator>
    </item>
    <item>
      <title>Fast Two-Time-Scale Stochastic Gradient Method with Applications in Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2405.09660</link>
      <description>arXiv:2405.09660v3 Announce Type: replace 
Abstract: Two-time-scale optimization is a framework introduced in Zeng et al. (2024) that abstracts a range of policy evaluation and policy optimization problems in reinforcement learning (RL). Akin to bi-level optimization under a particular type of stochastic oracle, the two-time-scale optimization framework has an upper level objective whose gradient evaluation depends on the solution of a lower level problem, which is to find the root of a strongly monotone operator. In this work, we propose a new method for solving two-time-scale optimization that achieves significantly faster convergence than the prior arts. The key idea of our approach is to leverage an averaging step to improve the estimates of the operators in both lower and upper levels before using them to update the decision variables. These additional averaging steps eliminate the direct coupling between the main variables, enabling the accelerated performance of our algorithm. We characterize the finite-time convergence rates of the proposed algorithm under various conditions of the underlying objective function, including strong convexity, Polyak-Lojasiewicz condition, and general non-convexity. These rates significantly improve over the best-known complexity of the standard two-time-scale stochastic approximation algorithm. When applied to RL, we show how the proposed algorithm specializes to novel online sample-based methods that surpass or match the performance of the existing state of the art. Finally, we support our theoretical results with numerical simulations in RL.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.09660v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sihan Zeng, Thinh T. Doan</dc:creator>
    </item>
    <item>
      <title>Lower bounds for the integrality gap of the bi-directed cut formulation of the Steiner Tree Problem</title>
      <link>https://arxiv.org/abs/2405.13773</link>
      <description>arXiv:2405.13773v4 Announce Type: replace 
Abstract: In this work, we study the metric Steiner Tree problem on graphs focusing on computing lower bounds for the integrality gap of the bi-directed cut (BCR) formulation and introducing a novel formulation, the Complete Metric (CM) model, specifically designed to address the weakness of the BCR formulation on metric instances. A key contribution of our work is extending the Gap problem, previously explored in the context of the Traveling Salesman problems, to the metric Steiner Tree problem. To tackle the Gap problem for Steiner Tree instances, we first establish several structural properties of the CM formulation. We then classify the isomorphism classes of the vertices within the CM polytope, revealing a correspondence between the vertices of the BCR and CM polytopes. Computationally, we exploit these structural properties to design two complementary heuristics for finding nontrivial small metric Steiner instances with a large integrality gap. We present several vertices for graphs with a number of nodes &lt;=10, which realize the best-known lower bounds on the integrality gap for the CM and the BCR formulations. We conclude the paper by presenting two new conjectures on the integrality gap of the BCR and CM formulations for small graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.13773v4</guid>
      <category>math.OC</category>
      <category>cs.DM</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ambrogio Maria Bernardelli, Eleonora Vercesi, Stefano Gualandi, Monaldo Mastrolilli, Luca Maria Gambardella</dc:creator>
    </item>
    <item>
      <title>Complexity of Zeroth- and First-order Stochastic Trust-Region Algorithms</title>
      <link>https://arxiv.org/abs/2405.20116</link>
      <description>arXiv:2405.20116v2 Announce Type: replace 
Abstract: Model update (MU) and candidate evaluation (CE) are classical steps incorporated inside many stochastic trust-region (TR) algorithms. The sampling effort exerted within these steps, often decided with the aim of controlling model error, largely determines a stochastic TR algorithm's sample complexity. Given that MU and CE are amenable to variance reduction, we investigate the effect of incorporating common random numbers (CRN) within MU and CE on complexity. Using ASTRO and ASTRO-DF as prototype first-order and zeroth-order families of algorithms, we demonstrate that CRN's effectiveness leads to a range of complexities depending on sample-path regularity and the oracle order. For instance, we find that in first-order oracle settings with smooth sample paths, CRN's effect is pronounced -- ASTRO with CRN achieves $\tilde{O}(\epsilon^{-2})$ a.s. sample complexity compared to $\tilde{O}(\epsilon^{-6})$ a.s. in the generic no-CRN setting. By contrast, CRN's effect is muted when the sample paths are not Lipschitz, with the sample complexity improving from $\tilde{O}(\epsilon^{-6})$ a.s. to $\tilde{O}(\epsilon^{-5})$ and $\tilde{O}(\epsilon^{-4})$ a.s. in the zeroth- and first-order settings, respectively. Since our results imply that improvements in complexity are largely inherited from generic aspects of variance reduction, e.g., finite-differencing for zeroth-order settings and sample-path smoothness for first-order settings within MU, we anticipate similar trends in other contexts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20116v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yunsoo Ha, Sara Shashaani, Raghu Pasupathy</dc:creator>
    </item>
    <item>
      <title>Learning with Linear Function Approximations in Mean-Field Control</title>
      <link>https://arxiv.org/abs/2408.00991</link>
      <description>arXiv:2408.00991v2 Announce Type: replace 
Abstract: The paper focuses on mean-field type multi-agent control problems with finite state and action spaces where the dynamics and cost structures are symmetric and homogeneous, and are affected by the distribution of the agents. A standard solution method for these problems is to consider the infinite population limit as an approximation and use symmetric solutions of the limit problem to achieve near optimality. The control policies, and in particular the dynamics, depend on the population distribution in the finite population setting, or the marginal distribution of the state variable of a representative agent for the infinite population setting. Hence, learning and planning for these control problems generally require estimating the reaction of the system to all possible state distributions of the agents. To overcome this issue, we consider linear function approximation for the control problem and provide coordinated and independent learning methods. We rigorously establish error upper bounds for the performance of learned solutions. The performance gap stems from (i) the mismatch due to estimating the true model with a linear one, and (ii) using the infinite population solution in the finite population problem as an approximate control. The provided upper bounds quantify the impact of these error sources on the overall performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.00991v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Erhan Bayraktar, Ali D. Kara</dc:creator>
    </item>
    <item>
      <title>Continuous Relaxation of Discontinuous Shrinkage Operator: Proximal Inclusion and Conversion</title>
      <link>https://arxiv.org/abs/2409.05316</link>
      <description>arXiv:2409.05316v2 Announce Type: replace 
Abstract: We present a principled way of deriving a continuous relaxation of a given discontinuous shrinkage operator, which is based on a couple of fundamental results. First, the image of a point with respect to the ``set-valued'' proximity operator of a nonconvex function is included by that for its lower semicontinuous (l.s.c.) 1-weakly-convex envelope. Second, the ``set-valued'' proximity operator of a proper l.s.c. 1-weakly-convex function is converted, via double inversion, to a ``single-valued'' proximity operator which is Lipschitz continuous. As a specific example, we derive a continuous relaxation of the discontinuous shrinkage operator associated with the reversely ordered weighted $\ell_1$ (ROWL) penalty. Numerical examples demonstrate potential advantages of the continuous relaxation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.05316v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Masahiro Yukawa</dc:creator>
    </item>
    <item>
      <title>$\mathcal{L}_{1}$ Adaptive Optimizer for Online Time-Varying Convex Optimization</title>
      <link>https://arxiv.org/abs/2409.16583</link>
      <description>arXiv:2409.16583v2 Announce Type: replace 
Abstract: We propose an adaptive method for online time-varying (TV) convex optimization, termed $\mathcal{L}_{1}$ adaptive optimization ($\mathcal{L}_{1}$-AO). TV optimizers utilize a prediction model to exploit the temporal structure of TV problems, which can be inaccurate in the online implementation. Inspired by $\mathcal{L}_{1}$ adaptive control, the proposed method augments an adaptive update law to estimate and compensate for the uncertainty from the prediction inaccuracies. The proposed method provides performance bounds of the error in the optimization variables and cost function, allowing efficient and reliable optimization for TV problems. Numerical simulation results demonstrate the effectiveness of the proposed method for online TV convex optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.16583v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jinrae Kim, Naira Hovakimyan</dc:creator>
    </item>
    <item>
      <title>Nonasymptotic Analysis of Stochastic Gradient Descent with the Richardson-Romberg Extrapolation</title>
      <link>https://arxiv.org/abs/2410.05106</link>
      <description>arXiv:2410.05106v2 Announce Type: replace 
Abstract: We address the problem of solving strongly convex and smooth minimization problems using stochastic gradient descent (SGD) algorithm with a constant step size. Previous works suggested to combine the Polyak-Ruppert averaging procedure with the Richardson-Romberg extrapolation to reduce the asymptotic bias of SGD at the expense of a mild increase of the variance. We significantly extend previous results by providing an expansion of the mean-squared error of the resulting estimator with respect to the number of iterations $n$. We show that the root mean-squared error can be decomposed into the sum of two terms: a leading one of order $\mathcal{O}(n^{-1/2})$ with explicit dependence on a minimax-optimal asymptotic covariance matrix, and a second-order term of order $\mathcal{O}(n^{-3/4})$, where the power $3/4$ is best known. We also extend this result to the higher-order moment bounds. Our analysis relies on the properties of the SGD iterates viewed as a time-homogeneous Markov chain. In particular, we establish that this chain is geometrically ergodic with respect to a suitably defined weighted Wasserstein semimetric.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05106v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marina Sheshukova, Denis Belomestny, Alain Durmus, Eric Moulines, Alexey Naumov, Sergey Samsonov</dc:creator>
    </item>
    <item>
      <title>Advances in Nonmonotone Proximal Gradient Methods merely with Local Lipschitz Assumptions in the Presense of Kurdyka-{\L}ojasiewicz Property: A Study of Average and Max Line Search</title>
      <link>https://arxiv.org/abs/2411.19256</link>
      <description>arXiv:2411.19256v2 Announce Type: replace 
Abstract: The proximal gradient method is a standard approach to solve the composite minimization problems where the objective function is the sum of a continuously differentiable function and a lower semicontinuous, extended-valued function. For both monotone and nonmonotone proximal gradient methods, the convergence theory has traditionally replied heavily on the assumption of global Lipschitz continuity. Recent works have shown that the monotone proximal gradient method, even when the local Lipschitz continuity (rather than global) is assumed, converges to the stationarity globally in the presence of Kurdyka-{\L}ojasiewicz Property. However, how to extend these results from monotone proximal gradient method to nonmonotone proximal gradient method (NPG) remains an open question. In this manuscript, we consider two types of NPG: those combined with average line search and max line search, respectively. By partitioning of indices into two subsets, one of them aims to achieve a decrease in the functional sequence, we establish the global convergence and rate-of-convergence (same as the monotone version) results under the KL property, merely requiring the local Lipschitz assumption, and without an a priori knowledge of the iterative sequence being bounded. When our work is almost done, we noticed that [17] presented the analogous results for the NPG with average line search, whose partitioning of index set is totally different with ours. Drawing upon the findings in this manuscript and [17], we confidently conclude that the convergence theory of NPG is independent on the specific partitioning of the index set.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19256v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaoxi Jia, Kai Wang</dc:creator>
    </item>
    <item>
      <title>On the Surprising Robustness of Sequential Convex Optimization for Contact-Implicit Motion Planning</title>
      <link>https://arxiv.org/abs/2502.01055</link>
      <description>arXiv:2502.01055v2 Announce Type: replace 
Abstract: Contact-implicit motion planning-embedding contact sequencing as implicit complementarity constraints-holds the promise of leveraging continuous optimization to discover new contact patterns online. Nevertheless, the resulting optimization, being an instance of Mathematical Programming with Complementary Constraints, fails the classical constraint qualifications that are crucial for the convergence of popular numerical solvers. We present robust contact-implicit motion planning with sequential convex programming (CRISP), a solver that departs from the usual primal-dual algorithmic framework but instead only focuses on the primal problem. CRISP solves a convex quadratic program with an adaptive trust region radius at each iteration, and its convergence is evaluated by a merit function using weighted penalty. We (i) provide sufficient conditions on CRISP's convergence to first-order stationary points of the merit function; (ii) release a high-performance C++ implementation of CRISP with a generic nonlinear programming interface; and (iii) demonstrate CRISP's surprising robustness in solving contact-implicit planning with naive initialization. In fact, CRISP solves several contact-implicit problems with all-zero initialization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01055v2</guid>
      <category>math.OC</category>
      <category>cs.RO</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yulin Li, Haoyu Han, Shucheng Kang, Jun Ma, Heng Yang</dc:creator>
    </item>
    <item>
      <title>Dynamic reinsurance design with heterogeneous beliefs under the mean-variance framework</title>
      <link>https://arxiv.org/abs/2502.05474</link>
      <description>arXiv:2502.05474v2 Announce Type: replace 
Abstract: This paper investigates the dynamic reinsurance design problem under the mean-variance criterion, incorporating heterogeneous beliefs between the insurer and the reinsurer, and introducing an incentive compatibility constraint to address moral hazard. The insurer's surplus process is modeled using the classical Cram\'er-Lundberg risk model, with the option to invest in a risk-free asset. To solve the extended Hamilton-Jacobi-Bellman (HJB) system, we apply the partitioned domain optimization technique, transforming the infinite-dimensional optimization problem into a finite-dimensional one determined by several key parameters. The resulting optimal reinsurance contracts are more complex than the standard proportional and excess-of-loss contracts commonly studied in the mean-variance literature with homogeneous beliefs. By further assuming specific forms of belief heterogeneity, we derive the parametric solutions and obtain a clear optimal equilibrium solution. Finally, we compare our results with models where the insurer and reinsurer share identical beliefs or where the incentive compatibility constraint is relaxed. Numerical examples are provided to illustrate the impact of belief heterogeneity on optimal reinsurance strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05474v2</guid>
      <category>math.OC</category>
      <category>q-fin.RM</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junyi Guo, Xia Han, Hao Wang</dc:creator>
    </item>
    <item>
      <title>Optimal regulation in a periodic environment: insights from a simple model</title>
      <link>https://arxiv.org/abs/2502.06267</link>
      <description>arXiv:2502.06267v2 Announce Type: replace 
Abstract: We perform a detailed study of a simple mathematical model addressing the problem of optimally regulating a process subject to periodic external forcing, which is interesting both in view of its direct applications and as a prototype for more general problems. In this model one must determine an optimal time-periodic `effort' profile, and the natural setting for the problem is in a space of periodic non-negative measures. We prove that there exists a unique solution for the problem in the space of measures, and then turn to characterizing this solution. Under some regularity conditions on the problem's data, we prove that its solution is an absolutely continuous measure, and provide an explicit formula for the measure's density. On the other hand, when the problem's data is discontinuous, the solution measure can also include atomic components. Complementing our analytical results, we carry out numerical computations to obtain solutions of the problem in various instances, which enable us to examine the interesting ways in which the solution's structure varies as the problem's data is varied.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06267v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nir Gavish, Guy Katriel</dc:creator>
    </item>
    <item>
      <title>Sample Complexity of Linear Quadratic Regulator Without Initial Stability</title>
      <link>https://arxiv.org/abs/2502.14210</link>
      <description>arXiv:2502.14210v2 Announce Type: replace 
Abstract: Inspired by REINFORCE, we introduce a novel receding-horizon algorithm for the Linear Quadratic Regulator (LQR) problem with unknown parameters. Unlike prior methods, our algorithm avoids reliance on two-point gradient estimates while maintaining the same order of sample complexity. Furthermore, it eliminates the restrictive requirement of starting with a stable initial policy, broadening its applicability. Beyond these improvements, we introduce a refined analysis of error propagation through the contraction of the Riemannian distance over the Riccati operator. This refinement leads to a better sample complexity and ensures improved convergence guarantees. Numerical simulations validate the theoretical results, demonstrating the method's practical feasibility and performance in realistic scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.14210v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Amirreza Neshaei Moghaddam, Alex Olshevsky, Bahman Gharesifard</dc:creator>
    </item>
    <item>
      <title>Langevin Multiplicative Weights Update with Applications in Polynomial Portfolio Management</title>
      <link>https://arxiv.org/abs/2502.19210</link>
      <description>arXiv:2502.19210v2 Announce Type: replace 
Abstract: We consider nonconvex optimization problem over simplex, and more generally, a product of simplices. We provide an algorithm, Langevin Multiplicative Weights Update (LMWU) for solving global optimization problems by adding a noise scaling with the non-Euclidean geometry in the simplex. Non-convex optimization has been extensively studied by machine learning community due to its application in various scenarios such as neural network approximation and finding Nash equilibrium. Despite recent progresses on provable guarantee of escaping and avoiding saddle point (convergence to local minima) and global convergence of Langevin gradient based method without constraints, the global optimization with constraints is less studied. We show that LMWU algorithm is provably convergent to interior global minima with a non-asymptotic convergence analysis. We verify the efficiency of the proposed algorithm in real data set from polynomial portfolio management, where optimization of a highly non-linear objective function plays a crucial role.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.19210v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yi Feng, Xiao Wang, Tian Xie</dc:creator>
    </item>
    <item>
      <title>Cost-optimal Management of a Residential Heating System With a Geothermal Energy Storage Under Uncertainty</title>
      <link>https://arxiv.org/abs/2502.19619</link>
      <description>arXiv:2502.19619v2 Announce Type: replace 
Abstract: In this paper, we consider a residential heating system with renewable and non-renewable heat generation and different consumption units and investigate a stochastic optimal control problem for its cost-optimal management. As a special feature, the heating system is equipped with a geothermal storage that enables the intertemporal transfer of thermal energy by storing surplus heat for later use. In addition to the numerous technical challenges, economic issues such as cost-optimal control also play a central role in the design and operation of such systems. The latter leads to challenging mathematical optimization problems, as the response of the storage to charging and discharging decisions depends on the spatial temperature distribution in the storage. We take into account uncertainties regarding randomly fluctuating heat generation from renewable energies and the environmental conditions that determine heat demand and supply. The dynamics of the multidimensional controlled state processes is governed by a partial, a random ordinary and two stochastic differential equations. We first apply a spatial discretization to the partial differential equation and use model reduction techniques to reduce the dimension of the associated system of ordinary differential equations. Finally, a time-discretization leads to a Markov decision process for which we apply a state discretization to determine approximations of the cost-optimal control and the associated value function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.19619v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Paul Honore Takam, Ralf Wunderlich</dc:creator>
    </item>
    <item>
      <title>Knowledge Gradient for Multi-Objective Bayesian Optimization with Decoupled Evaluations</title>
      <link>https://arxiv.org/abs/2302.01310</link>
      <description>arXiv:2302.01310v3 Announce Type: replace-cross 
Abstract: Multi-objective Bayesian optimization aims to find the Pareto front of trade-offs between a set of expensive objectives while collecting as few samples as possible. In some cases, it is possible to evaluate the objectives separately, and a different latency or evaluation cost can be associated with each objective. This decoupling of the objectives presents an opportunity to learn the Pareto front faster by avoiding unnecessary, expensive evaluations. We propose a scalarization based knowledge gradient acquisition function which accounts for the different evaluation costs of the objectives. We prove asymptotic consistency of the estimator of the optimum for an arbitrary, D-dimensional, real compact search space and show empirically that the algorithm performs comparably with the state of the art and significantly outperforms versions which always evaluate both objectives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.01310v3</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/978-981-96-3538-2_9</arxiv:DOI>
      <arxiv:journal_reference>EMO LNCS 15513 (2025) 117-132</arxiv:journal_reference>
      <dc:creator>Jack M. Buckingham, Sebastian Rojas Gonzalez, Juergen Branke</dc:creator>
    </item>
    <item>
      <title>Global $\mathcal{L}^2$ minimization at uniform exponential rate via geometrically adapted gradient descent in Deep Learning</title>
      <link>https://arxiv.org/abs/2311.15487</link>
      <description>arXiv:2311.15487v5 Announce Type: replace-cross 
Abstract: We consider the scenario of supervised learning in Deep Learning (DL) networks, and exploit the arbitrariness of choice in the Riemannian metric relative to which the gradient descent flow can be defined (a general fact of differential geometry). In the standard approach to DL, the gradient flow on the space of parameters (weights and biases) is defined with respect to the Euclidean metric. Here instead, we choose the gradient flow with respect to the Euclidean metric in the output layer of the DL network. This naturally induces two modified versions of the gradient descent flow in the parameter space, one adapted for the overparametrized setting, and the other for the underparametrized setting. In the overparametrized case, we prove that, provided that a rank condition holds, all orbits of the modified gradient descent drive the ${\mathcal L}^2$ cost to its global minimum at a uniform exponential convergence rate; one thereby obtains an a priori stopping time for any prescribed proximity to the global minimum. We point out relations of the latter to sub-Riemannian geometry. Moreover, we generalize the above framework to the situation in which the rank condition does not hold; in particular, we show that local equilibria can only exist if a rank loss occurs, and that generically, they are not isolated points, but elements of a critical submanifold of parameter space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.15487v5</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas Chen</dc:creator>
    </item>
    <item>
      <title>A safe exploration approach to constrained Markov decision processes</title>
      <link>https://arxiv.org/abs/2312.00561</link>
      <description>arXiv:2312.00561v3 Announce Type: replace-cross 
Abstract: We consider discounted infinite-horizon constrained Markov decision processes (CMDPs), where the goal is to find an optimal policy that maximizes the expected cumulative reward while satisfying expected cumulative constraints. Motivated by the application of CMDPs in online learning for safety-critical systems, we focus on developing a model-free and \emph{simulator-free} algorithm that ensures \emph{constraint satisfaction during learning}. To this end, we employ the LB-SGD algorithm proposed in \cite{usmanova2022log}, which utilizes an interior-point approach based on the log-barrier function of the CMDP. Under the commonly assumed conditions of relaxed Fisher non-degeneracy and bounded transfer error in policy parameterization, we establish the theoretical properties of the LB-SGD algorithm. In particular, unlike existing CMDP approaches that ensure policy feasibility only upon convergence, the LB-SGD algorithm guarantees feasibility throughout the learning process and converges to the $\varepsilon$-optimal policy with a sample complexity of $\tilde{\mathcal{O}}(\varepsilon^{-6})$. Compared to the state-of-the-art policy gradient-based algorithm, C-NPG-PDA \cite{bai2022achieving2}, the LB-SGD algorithm requires an additional $\mathcal{O}(\varepsilon^{-2})$ samples to ensure policy feasibility during learning with the same Fisher non-degenerate parameterization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.00561v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tingting Ni, Maryam Kamgarpour</dc:creator>
    </item>
    <item>
      <title>Boosting Jailbreak Attack with Momentum</title>
      <link>https://arxiv.org/abs/2405.01229</link>
      <description>arXiv:2405.01229v2 Announce Type: replace-cross 
Abstract: Large Language Models (LLMs) have achieved remarkable success across diverse tasks, yet they remain vulnerable to adversarial attacks, notably the well-known jailbreak attack. In particular, the Greedy Coordinate Gradient (GCG) attack has demonstrated efficacy in exploiting this vulnerability by optimizing adversarial prompts through a combination of gradient heuristics and greedy search. However, the efficiency of this attack has become a bottleneck in the attacking process. To mitigate this limitation, in this paper we rethink the generation of the adversarial prompts through an optimization lens, aiming to stabilize the optimization process and harness more heuristic insights from previous optimization iterations. Specifically, we propose the \textbf{M}omentum \textbf{A}ccelerated G\textbf{C}G (\textbf{MAC}) attack, which integrates a momentum term into the gradient heuristic to boost and stabilize the random search for tokens in adversarial prompts. Experimental results showcase the notable enhancement achieved by MAC over baselines in terms of attack success rate and optimization efficiency. Moreover, we demonstrate that MAC can still exhibit superior performance for transfer attacks and models under defense mechanisms. Our code is available at https://github.com/weizeming/momentum-attack-llm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.01229v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.CR</category>
      <category>math.OC</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yihao Zhang, Zeming Wei</dc:creator>
    </item>
    <item>
      <title>Local convergence of simultaneous min-max algorithms to differential equilibrium on Riemannian manifold</title>
      <link>https://arxiv.org/abs/2405.13392</link>
      <description>arXiv:2405.13392v3 Announce Type: replace-cross 
Abstract: We study min-max algorithms to solve zero-sum differential games on Riemannian manifold. Based on the notions of differential Stackelberg equilibrium and differential Nash equilibrium on Riemannian manifold, we analyze the local convergence of two representative deterministic simultaneous algorithms $\tau$-GDA and $\tau$-SGA to such equilibria. Sufficient conditions are obtained to establish the linear convergence rate of $\tau$-GDA based on the Ostrowski theorem on manifold and spectral analysis. To avoid strong rotational dynamics in $\tau$-GDA, $\tau$-SGA is extended from the symplectic gradient-adjustment method in Euclidean space. We analyze an asymptotic approximation of $\tau$-SGA when the learning rate ratio $\tau$ is big. In some cases, it can achieve a faster convergence rate to differential Stackelberg equilibrium compared to $\tau$-GDA. We show numerically how the insights obtained from the convergence analysis may improve the training of orthogonal Wasserstein GANs using stochastic $\tau$-GDA and $\tau$-SGA on simple benchmarks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.13392v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sixin Zhang</dc:creator>
    </item>
    <item>
      <title>Does SGD really happen in tiny subspaces?</title>
      <link>https://arxiv.org/abs/2405.16002</link>
      <description>arXiv:2405.16002v2 Announce Type: replace-cross 
Abstract: Understanding the training dynamics of deep neural networks is challenging due to their high-dimensional nature and intricate loss landscapes. Recent studies have revealed that, along the training trajectory, the gradient approximately aligns with a low-rank top eigenspace of the training loss Hessian, referred to as the dominant subspace. Given this alignment, this paper explores whether neural networks can be trained within the dominant subspace, which, if feasible, could lead to more efficient training methods. Our primary observation is that when the SGD update is projected onto the dominant subspace, the training loss does not decrease further. This suggests that the observed alignment between the gradient and the dominant subspace is spurious. Surprisingly, projecting out the dominant subspace proves to be just as effective as the original update, despite removing the majority of the original update component. We observe similar behavior across practical setups, including the large learning rate regime (also known as Edge of Stability), Sharpness-Aware Minimization, momentum, and adaptive optimizers. We discuss the main causes and implications of this spurious alignment, shedding light on the dynamics of neural network training.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16002v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Minhak Song, Kwangjun Ahn, Chulhee Yun</dc:creator>
    </item>
    <item>
      <title>DCILP: A Distributed Approach for Large-Scale Causal Structure Learning</title>
      <link>https://arxiv.org/abs/2406.10481</link>
      <description>arXiv:2406.10481v2 Announce Type: replace-cross 
Abstract: Causal learning tackles the computationally demanding task of estimating causal graphs. This paper introduces a new divide-and-conquer approach for causal graph learning, called DCILP. In the divide phase, the Markov blanket MB($X_i$) of each variable $X_i$ is identified, and causal learning subproblems associated with each MB($X_i$) are independently addressed in parallel. This approach benefits from a more favorable ratio between the number of data samples and the number of variables considered. In counterpart, it can be adversely affected by the presence of hidden confounders, as variables external to MB($X_i$) might influence those within it. The reconciliation of the local causal graphs generated during the divide phase is a challenging combinatorial optimization problem, especially in large-scale applications. The main novelty of DCILP is an original formulation of this reconciliation as an integer linear programming (ILP) problem, which can be delegated and efficiently handled by an ILP solver. Through experiments on medium to large scale graphs, and comparisons with state-of-the-art methods, DCILP demonstrates significant improvements in terms of computational complexity, while preserving the learning accuracy on real-world problem and suffering at most a slight loss of accuracy on synthetic problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.10481v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ME</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuyu Dong, Mich\`ele Sebag, Kento Uemura, Akito Fujii, Shuang Chang, Yusuke Koyanagi, Koji Maruhashi</dc:creator>
    </item>
    <item>
      <title>Delay-Aware Robust Edge Network Hardening Under Decision-Dependent Uncertainty</title>
      <link>https://arxiv.org/abs/2407.06142</link>
      <description>arXiv:2407.06142v2 Announce Type: replace-cross 
Abstract: Edge computing promises to offer low-latency and ubiquitous computation to numerous devices at the network edge. For delay-sensitive applications, link delays can have a direct impact on service quality. These delays can fluctuate drastically over time due to various factors such as network congestion, changing traffic conditions, cyberattacks, component failures, and natural disasters. Thus, it is crucial to efficiently harden the edge network to mitigate link delay variation as well as ensure a stable and improved user experience. To this end, we propose a novel robust model for optimal edge network hardening, considering the link delay uncertainty. Departing from the existing literature that treats uncertainties as exogenous, our model incorporates an endogenous uncertainty set to properly capture the impact of hardening and workload allocation decisions on link delays. However, the endogenous set introduces additional complexity to the problem due to the interdependence between decisions and uncertainties. We present two efficient methods to transform the problem into a solvable form. Extensive numerical results are shown to demonstrate the effectiveness of the proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.06142v2</guid>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiaming Cheng, Duong Thuy Anh Nguyen, Ni Trieu, Duong Tung Nguyen</dc:creator>
    </item>
    <item>
      <title>Optimal retirement in presence of stochastic labor income: a free boundary approach in an incomplete market</title>
      <link>https://arxiv.org/abs/2407.19190</link>
      <description>arXiv:2407.19190v2 Announce Type: replace-cross 
Abstract: In this work, we address the optimal retirement problem in the presence of a stochastic wage, formulated as a free boundary problem. Specifically, we explore an incomplete market setting where the wage cannot be perfectly hedged through investments in the risk-free and risky assets that characterize the financial market.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.19190v2</guid>
      <category>q-fin.MF</category>
      <category>math.OC</category>
      <category>q-fin.PM</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Daniele Marazzina</dc:creator>
    </item>
    <item>
      <title>Decoding Game: On Minimax Optimality of Heuristic Text Generation Strategies</title>
      <link>https://arxiv.org/abs/2410.03968</link>
      <description>arXiv:2410.03968v2 Announce Type: replace-cross 
Abstract: Decoding strategies play a pivotal role in text generation for modern language models, yet a puzzling gap divides theory and practice. Surprisingly, strategies that should intuitively be optimal, such as Maximum a Posteriori (MAP), often perform poorly in practice. Meanwhile, popular heuristic approaches like Top-$k$ and Nucleus sampling, which employ truncation and normalization of the conditional next-token probabilities, have achieved great empirical success but lack theoretical justifications. In this paper, we propose Decoding Game, a comprehensive theoretical framework which reimagines text generation as a two-player zero-sum game between Strategist, who seeks to produce text credible in the true distribution, and Nature, who distorts the true distribution adversarially. After discussing the decomposibility of multi-step generation, we derive the optimal strategy in closed form for one-step Decoding Game. It is shown that the adversarial Nature imposes an implicit regularization on likelihood maximization, and truncation-normalization methods are first-order approximations to the optimal strategy under this regularization. Additionally, by generalizing the objective and parameters of Decoding Game, near-optimal strategies encompass diverse methods such as greedy search, temperature scaling, and hybrids thereof. Numerical experiments are conducted to complement our theoretical analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03968v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sijin Chen, Omar Hagrass, Jason M. Klusowski</dc:creator>
    </item>
    <item>
      <title>LDAdam: Adaptive Optimization from Low-Dimensional Gradient Statistics</title>
      <link>https://arxiv.org/abs/2410.16103</link>
      <description>arXiv:2410.16103v4 Announce Type: replace-cross 
Abstract: We introduce LDAdam, a memory-efficient optimizer for training large models, that performs adaptive optimization steps within lower dimensional subspaces, while consistently exploring the full parameter space during training. This strategy keeps the optimizer's memory footprint to a fraction of the model size. LDAdam relies on a new projection-aware update rule for the optimizer states that allows for transitioning between subspaces, i.e., estimation of the statistics of the projected gradients. To mitigate the errors due to low-rank projection, LDAdam integrates a new generalized error feedback mechanism, which explicitly accounts for both gradient and optimizer state compression. We prove the convergence of LDAdam under standard assumptions, and show that LDAdam allows for accurate and efficient fine-tuning and pre-training of language models. Code is available at https://github.com/IST-DASLab/LDAdam</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.16103v4</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas Robert, Mher Safaryan, Ionut-Vlad Modoranu, Dan Alistarh</dc:creator>
    </item>
    <item>
      <title>Destabilizing a Social Network Model via Intrinsic Feedback Vulnerabilities</title>
      <link>https://arxiv.org/abs/2411.10868</link>
      <description>arXiv:2411.10868v3 Announce Type: replace-cross 
Abstract: Social influence plays a significant role in shaping individual sentiments and actions, particularly in a world of ubiquitous digital interconnection. The rapid development of generative AI has engendered well-founded concerns regarding the potential scalable implementation of radicalization techniques in social media. Motivated by these developments, we present a case study investigating the effects of small but intentional perturbations on a simple social network. We employ Taylor's classic model of social influence and tools from robust control theory (most notably the Dynamical Structure Function (DSF)), to identify perturbations that qualitatively alter the system's behavior while remaining as unobtrusive as possible. We examine two such scenarios: perturbations to an existing link and perturbations that introduce a new link to the network. In each case, we identify destabilizing perturbations of minimal norm and simulate their effects. Remarkably, we find that small but targeted alterations to network structure may lead to the radicalization of all agents, exhibiting the potential for large-scale shifts in collective behavior to be triggered by comparatively minuscule adjustments in social influence. Given that this method of identifying perturbations that are innocuous yet destabilizing applies to any suitable dynamical system, our findings emphasize a need for similar analyses to be carried out on real systems (e.g., real social networks), to identify the places where such dynamics may already exist.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10868v3</guid>
      <category>cs.SI</category>
      <category>math.OC</category>
      <category>physics.soc-ph</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lane H. Rogers, Emma J. Reid, Robert A. Bridges</dc:creator>
    </item>
    <item>
      <title>Computing Capacity-Cost Functions for Continuous Channels in Wasserstein Space</title>
      <link>https://arxiv.org/abs/2501.10670</link>
      <description>arXiv:2501.10670v3 Announce Type: replace-cross 
Abstract: This paper investigates the problem of computing capacity-cost (C-C) functions for continuous channels. Motivated by the Kullback-Leibler divergence (KLD) proximal reformulation of the classical Blahut-Arimoto (BA) algorithm, the Wasserstein distance is introduced to the proximal term for the continuous case, resulting in an iterative algorithm related to the Wasserstein gradient descent. Practical implementation involves moving particles along the negative gradient direction of the objective function's first variation in the Wasserstein space and approximating integrals by the importance sampling (IS) technique. Such formulation is also applied to the rate-distortion (R-D) function for continuous source spaces and thus provides a unified computation framework for both problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10670v3</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xinyang Li, Vlad C. Andrei, Ullrich J. M\"onich, Fan Liu, Holger Boche</dc:creator>
    </item>
  </channel>
</rss>
