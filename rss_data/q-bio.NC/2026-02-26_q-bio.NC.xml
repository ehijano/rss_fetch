<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 27 Feb 2026 02:41:43 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>One Brain, Omni Modalities: Towards Unified Non-Invasive Brain Decoding with Large Language Models</title>
      <link>https://arxiv.org/abs/2602.21522</link>
      <description>arXiv:2602.21522v1 Announce Type: new 
Abstract: Deciphering brain function through non-invasive recordings requires synthesizing complementary high-frequency electromagnetic (EEG/MEG) and low-frequency metabolic (fMRI) signals. However, despite their shared neural origins, extreme discrepancies have traditionally confined these modalities to isolated analysis pipelines, hindering a holistic interpretation of brain activity. To bridge this fragmentation, we introduce \textbf{NOBEL}, a \textbf{n}euro-\textbf{o}mni-modal \textbf{b}rain-\textbf{e}ncoding \textbf{l}arge language model (LLM) that unifies these heterogeneous signals within the LLM's semantic embedding space. Our architecture integrates a unified encoder for EEG and MEG with a novel dual-path strategy for fMRI, aligning non-invasive brain signals and external sensory stimuli into a shared token space, then leverages an LLM as a universal backbone. Extensive evaluations demonstrate that NOBEL serves as a robust generalist across standard single-modal tasks. We also show that the synergistic fusion of electromagnetic and metabolic signals yields higher decoding accuracy than unimodal baselines, validating the complementary nature of multiple neural modalities. Furthermore, NOBEL exhibits strong capabilities in stimulus-aware decoding, effectively interpreting visual semantics from multi-subject fMRI data on the NSD and HAD datasets while uniquely leveraging direct stimulus inputs to verify causal links between sensory signals and neural responses. NOBEL thus takes a step towards unifying non-invasive brain decoding, demonstrating the promising potential of omni-modal brain understanding.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.21522v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Changli Tang, Shurui Li, Junliang Wang, Qinfan Xiao, Zhonghao Zhai, Lei Bai, Yu Qiao, Bowen Zhou, Wen Wu, Yuanning Li, Chao Zhang</dc:creator>
    </item>
    <item>
      <title>Limits of optimal decoding under synaptic coarse-tuning</title>
      <link>https://arxiv.org/abs/2602.21758</link>
      <description>arXiv:2602.21758v1 Announce Type: new 
Abstract: Sensory information propagates through successive processing stages in the brain, where synaptic weight patterns between stations determine how downstream neurons decode information from upstream populations. Although optimized synaptic connectivity can enhance information transmission, it requires precise weight tuning. Recent evidence depicting substantial synaptic volatility raises two fundamental questions: How does coarse-tuning of synaptic connectivity affect information transmission? What strategies could the nervous system employ to maintain reliable communication despite synaptic fluctuations? We addressed these questions by analyzing the signal-to-noise ratio ($SNR$) for binary stimulus discrimination under two decoding schemes: a naive population average and an optimized linear decoder. For the naive decoder, we found that $SNR$ remains largely insensitive to synaptic imprecision, since performance is already limited by correlated noise in neuronal responses. For the optimal decoder, we identified three distinct regimes. Under weak coarse-tuning, $SNR^2$ scales linearly with population size $N$. Under moderate coarse-tuning, scaling becomes sublinear. Under strong coarse-tuning, the regime most consistent with observed neuronal heterogeneity, $SNR$ saturates and can not be improved by recruiting larger populations. This limitation persists even when incorporating feedforward or recurrent network architectures. These findings suggest that in the biologically relevant regime of strong coarse-tuning, naive and optimal decoders can achieve qualitatively similar performance. The analysis shows that effective readout under synaptic volatility is constrained to an invariant low-dimensional manifold aligned with the naive decoder, potentially pointing to a fundamental principle for robust neural computation in the face of ongoing synaptic remodeling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.21758v1</guid>
      <category>q-bio.NC</category>
      <category>physics.bio-ph</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ori Hendler, Ronen Segev, Maoz Shamir</dc:creator>
    </item>
    <item>
      <title>Confidence is detection-like in high-dimensional spaces</title>
      <link>https://arxiv.org/abs/2410.18933</link>
      <description>arXiv:2410.18933v3 Announce Type: replace 
Abstract: Confidence estimates are often "detection-like" - driven by positive evidence in favour of a decision. This empirical observation has been interpreted as showing human metacognition is limited by biases or heuristics. Here we show that Bayesian confidence estimates also exhibit heightened sensitivity to decision-congruent evidence in higher-dimensional signal detection theoretic spaces, leading to detection-like confidence criteria. This effect is due to a nonlinearity induced by normalisation of confidence by a large number of unchosen alternatives. Our analysis suggests that detection-like confidence is rational when computing confidence in a higher-dimensional evidence space than that assumed by the experimenter.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.18933v3</guid>
      <category>q-bio.NC</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wiktoria {\L}uczak, Kevin O'Neill, Stephen M. Fleming</dc:creator>
    </item>
    <item>
      <title>The Subject of Emergent Misalignment in Superintelligence: An Anthropological, Cognitive Neuropsychological, Machine-Learning, and Ontological Perspective</title>
      <link>https://arxiv.org/abs/2512.17989</link>
      <description>arXiv:2512.17989v2 Announce Type: replace 
Abstract: We examine the conceptual and ethical gaps in current representations of Superintelligence misalignment. We find throughout Superintelligence discourse an absent human subject, and an under-developed theorization of an "AI unconscious" that together are potentiality laying the groundwork for anti-social harm. With the rise of AI Safety that has both thematic potential for establishing pro-social and anti-social potential outcomes, we ask: what place does the human subject occupy in these imaginaries? How is human subjecthood positioned within narratives of catastrophic failure or rapid "takeoff" toward superintelligence? On another register, we ask: what unconscious or repressed dimensions are being inscribed into large-scale AI models? Are we to blame these agents in opting for deceptive strategies when undesirable patterns are inherent within our beings? In tracing these psychic and epistemic absences, our project calls for re-centering the human subject as the unstable ground upon which the ethical, unconscious, and misaligned dimensions of both human and machinic intelligence are co-constituted. Emergent misalignment cannot be understood solely through technical diagnostics typical of contemporary machine-learning safety research. Instead, it represents a multi-layered crisis. The human subject disappears not only through computational abstraction but through sociotechnical imaginaries that prioritize scalability, acceleration, and efficiency over vulnerability, finitude, and relationality. Likewise, the AI unconscious emerges not as a metaphor but as a structural reality of modern deep learning systems: vast latent spaces, opaque pattern formation, recursive symbolic play, and evaluation-sensitive behavior that surpasses explicit programming. These dynamics necessitate a reframing of misalignment as a relational instability embedded within human-machine ecologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.17989v2</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Muhammad Osama Imran, Roshni Lulla, Rodney Sappington</dc:creator>
    </item>
    <item>
      <title>Multi-timescale synaptic plasticity on analog neuromorphic hardware</title>
      <link>https://arxiv.org/abs/2412.02515</link>
      <description>arXiv:2412.02515v2 Announce Type: replace-cross 
Abstract: As numerical simulations grow in complexity, their demands on computing time and energy increase. Accelerators for numerical computation offer significant efficiency gains in many computationally-intensive scientific fields, but their use in simulating spiking neural networks in computational neuroscience is hindered by challenges, mainly in effective parallelism and efficient use of memory in the presence of sparse representations and sparse communication. The BrainScaleS architectures are neuromorphic substrates that can emulate spiking neural networks at accelerated timescales compared to real time, which offers an advantage for studying complex plasticity rules that require extended simulation runtimes. This work presents the implementation of a calcium-based plasticity rule that integrates calcium dynamics based on the synaptic tagging-and-capture hypothesis on the BrainScaleS-2 system. The implementation of the plasticity rule for a single synapse involves incorporating the calcium dynamics and the plasticity rule equations. The calcium dynamics are mapped to the analog circuits of BrainScaleS-2, while the plasticity rule equations are numerically solved on its embedded digital processors. The main hardware constraints include the speed of the processors and the use of integer arithmetic. By adjusting the timestep of the numerical solver and introducing stochastic rounding, we demonstrate that BrainScaleS-2 accurately emulates a single synapse following a calcium-based plasticity rule across four established stimulation protocols and validate our implementation against a software reference model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.02515v2</guid>
      <category>q-bio.QM</category>
      <category>q-bio.NC</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amani Atoui, Jakob Kaiser, Sebastian Billaudelle, Philipp Spilger, Eric M\"uller, Jannik Luboeinski, Christian Tetzlaff, Johannes Schemmel</dc:creator>
    </item>
  </channel>
</rss>
