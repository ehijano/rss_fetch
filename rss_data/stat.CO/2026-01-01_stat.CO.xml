<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.CO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.CO</link>
    <description>stat.CO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.CO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 01 Jan 2026 05:01:48 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A persistent-homology-based Bayesian prior to identify Robin coefficient in parabolic problems</title>
      <link>https://arxiv.org/abs/2512.24046</link>
      <description>arXiv:2512.24046v1 Announce Type: new 
Abstract: We adopt a Bayesian inference approach with persistent-homology-based prior to estimate a temporally dependent Robin coefficient arising in the analysis of convective heat transfer. And we also discuss the use of a hierarchical Bayesian method for automatic selection of the regularization parameter. Numerical results demonstrate that the PH prior shows consistent improvement compared to the Gaussian and the total variation prior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.24046v1</guid>
      <category>stat.CO</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaomei Yang, Jiaying Jia</dc:creator>
    </item>
    <item>
      <title>Generalized Poisson Matrix Factorization for Overdispersed Count Data</title>
      <link>https://arxiv.org/abs/2512.24604</link>
      <description>arXiv:2512.24604v1 Announce Type: new 
Abstract: Non-negative matrix factorization (NMF) is widely used as a feature extraction technique for matrices with non-negative entries, such as image data, purchase histories, and other types of count data. In NMF, a non-negative matrix is decomposed into the product of two non-negative matrices, and the approximation accuracy is evaluated by a loss function. If the Kullback-Leibler divergence is chosen as the loss function, the estimation coincides with maximum likelihood under the assumption that the data entries are distributed according to a Poisson distribution. To address overdispersion, negative binomial matrix factorization has recently been proposed as an extension of the Poisson-based model. However, the negative binomial distribution often generates an excessive number of zeros, which limits its expressive capacity. In this study, we propose a non-negative matrix factorization based on the generalized Poisson distribution, which can flexibly accommodate overdispersion, and we introduce a maximum likelihood approach for parameter estimation. This methodology provides a more versatile framework than existing models, thereby extending the applicability of NMF to a broader class of count data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.24604v1</guid>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ryo Ohashi, Hiroyasu Abe, Fumitake Sakaori</dc:creator>
    </item>
    <item>
      <title>TabMixNN: A Unified Deep Learning Framework for Structural Mixed Effects Modeling on Tabular Data</title>
      <link>https://arxiv.org/abs/2512.23787</link>
      <description>arXiv:2512.23787v1 Announce Type: cross 
Abstract: We present TabMixNN, a flexible PyTorch-based deep learning framework that synthesizes classical mixed-effects modeling with modern neural network architectures for tabular data analysis. TabMixNN addresses the growing need for methods that can handle hierarchical data structures while supporting diverse outcome types including regression, classification, and multitask learning. The framework implements a modular three-stage architecture: (1) a mixed-effects encoder with variational random effects and flexible covariance structures, (2) backbone architectures including Generalized Structural Equation Models (GSEM) and spatial-temporal manifold networks, and (3) outcome-specific prediction heads supporting multiple outcome families. Key innovations include an R-style formula interface for accessibility, support for directed acyclic graph (DAG) constraints for causal structure learning, Stochastic Partial Differential Equation (SPDE) kernels for spatial modeling, and comprehensive interpretability tools including SHAP values and variance decomposition. We demonstrate the framework's flexibility through applications to longitudinal data analysis, genomic prediction, and spatial-temporal modeling. TabMixNN provides a unified interface for researchers to leverage deep learning while maintaining the interpretability and theoretical grounding of classical mixed-effects models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.23787v1</guid>
      <category>cs.LG</category>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Deniz Akdemir</dc:creator>
    </item>
    <item>
      <title>Bayesian inference for functional extreme events defined via partially unobserved processes</title>
      <link>https://arxiv.org/abs/2512.24356</link>
      <description>arXiv:2512.24356v1 Announce Type: cross 
Abstract: In order to describe the extremal behaviour of some stochastic process $X$, approaches from univariate extreme value theory are typically generalized to the spatial domain. In particular, generalized peaks-over-threshold approaches allow for the consideration of single extreme events. These can be flexibly defined as exceedances of a risk functional $r$, such as a spatial average, applied to $X$. Inference for the resulting limit process, the so-called $r$-Pareto process, requires the evaluation of $r(X)$ and thus the knowledge of the whole process $X$. In many practical applications, however, observations of $X$ are only available at scattered sites. To overcome this issue, we propose a two-step MCMC-algorithm in a Bayesian framework. In a first step, we sample from $X$ conditionally on the observations in order to evaluate which observations lead to $r$-exceedances. In a second step, we use these exceedances to sample from the posterior distribution of the parameters of the limiting $r$-Pareto process. Alternating these steps results in a full Bayesian model for the extremes of $X$. We show that, under appropriate assumptions, the probability of classifying an observation as $r$-exceedance in the first step converges to the desired probability. Furthermore, given the first step, the distribution of the Markov chain constructed in the second step converges to the posterior distribution of interest. The procedure is compared to the Bayesian version of the standard procedure in a simulation study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.24356v1</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Max Thannheimer, Marco Oesting</dc:creator>
    </item>
    <item>
      <title>Exact finite mixture representations for species sampling processes</title>
      <link>https://arxiv.org/abs/2512.24414</link>
      <description>arXiv:2512.24414v1 Announce Type: cross 
Abstract: Random probability measures, together with their constructions, representations, and associated algorithms, play a central role in modern Bayesian inference. A key class is that of proper species sampling processes, which offer a relatively simple yet versatile framework that extends naturally to non-exchangeable settings. We revisit this class from a computational perspective and show that they admit exact finite mixture representations. In particular, we prove that any proper species sampling process can be written, at the prior level, as a finite mixture with a latent truncation variable and reweighted atoms, while preserving its distributional features exactly. These finite formulations can be used as drop-in replacements in Bayesian mixture models, recasting posterior computation in terms of familiar finite-mixture machinery. This yields straightforward MCMC implementations and tractable expressions, while avoiding ad hoc truncations and model-specific constructions. The resulting representation preserves the full generality of the original infinite-dimensional priors while enabling practical gains in algorithm design and implementation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.24414v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.TH</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rams\'es H. Mena, Christos Merkatas, Theodoros Nicoleris, Carlos E. Rodr\'iguez</dc:creator>
    </item>
    <item>
      <title>Improving the stability of the covariance-controlled adaptive Langevin thermostat for large-scale Bayesian sampling</title>
      <link>https://arxiv.org/abs/2512.24515</link>
      <description>arXiv:2512.24515v1 Announce Type: cross 
Abstract: Stochastic gradient Langevin dynamics and its variants approximate the likelihood of an entire dataset, via random (and typically much smaller) subsets, in the setting of Bayesian sampling. Due to the (often substantial) improvement of the computational efficiency, they have been widely used in large-scale machine learning applications. It has been demonstrated that the so-called covariance-controlled adaptive Langevin (CCAdL) thermostat, which incorporates an additional term involving the covariance matrix of the noisy force, outperforms popular alternative methods. A moving average is used in CCAdL to estimate the covariance matrix of the noisy force, in which case the covariance matrix will converge to a constant matrix in long-time limit. Moreover, it appears in our numerical experiments that the use of a moving average could reduce the stability of the numerical integrators, thereby limiting the largest usable stepsize. In this article, we propose a modified CCAdL (i.e., mCCAdL) thermostat that uses the scaling part of the scaling and squaring method together with a truncated Taylor series approximation to the exponential to numerically approximate the exact solution to the subsystem involving the additional term proposed in CCAdL. We also propose a symmetric splitting method for mCCAdL, instead of an Euler-type discretisation used in the original CCAdL thermostat. We demonstrate in our numerical experiments that the newly proposed mCCAdL thermostat achieves a substantial improvement in the numerical stability over the original CCAdL thermostat, while significantly outperforming popular alternative stochastic gradient methods in terms of the numerical accuracy for large-scale machine learning applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.24515v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiani Wei, Xiaocheng Shang</dc:creator>
    </item>
    <item>
      <title>When Does the Silhouette Score Work? A Comprehensive Study in Network Clustering</title>
      <link>https://arxiv.org/abs/2512.24841</link>
      <description>arXiv:2512.24841v1 Announce Type: cross 
Abstract: Selecting the number of communities is a fundamental challenge in network clustering. The silhouette score offers an intuitive, model-free criterion that balances within-cluster cohesion and between-cluster separation. Albeit its widespread use in clustering analysis, its performance in network-based community detection remains insufficiently characterized. In this study, we comprehensively evaluate the performance of the silhouette score across unweighted, weighted, and fully connected networks, examining how network size, separation strength, and community size imbalance influence its performance. Simulation studies show that the silhouette score accurately identifies the true number of communities when clusters are well separated and balanced, but it tends to underestimate under strong imbalance or weak separation and to overestimate in sparse networks. Extending the evaluation to a real airline reachability network, we demonstrate that the silhouette-based clustering can recover geographically interpretable and market-oriented clusters. These findings provide empirical guidance for applying the silhouette score in network clustering and clarify the conditions under which its use is most reliable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.24841v1</guid>
      <category>cs.SI</category>
      <category>stat.CO</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zongyue Teng, Jun Yan, Dandan Liu, Panpan Zhang</dc:creator>
    </item>
    <item>
      <title>Modeling Spatio-Temporal Transport: From Rigid Advection to Realistic Dynamics</title>
      <link>https://arxiv.org/abs/2303.02756</link>
      <description>arXiv:2303.02756v4 Announce Type: replace 
Abstract: Stochastic models for spatio-temporal transport face a critical trade-off between physical realism and interpretability. The advection model with a single constant velocity is interpretable but physically limited by its perfect correlation over time. This work aims to bridge the gap between this simple framework and its physically realistic extensions. Our guiding principle is to introduce a spatial correlation structure that vanishes over time. To achieve this, we present two distinct approaches. The first constructs complex velocity structures, either through superpositions of advection components or by allowing the velocity to vary locally. The second is a spectral technique that replaces the singular spectrum of rigid advection with a more flexible form, introducing temporal decorrelation controlled by parameters. We accompany these models with efficient simulation algorithms and demonstrate their success in replicating complex dynamics, such as tropical cyclones and the solutions of partial differential equations. Finally, we illustrate the practical utility of the proposed framework by comparing its simulations to real-world precipitation data from Hurricane Florence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.02756v4</guid>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maria Laura Battagliola, Sofia Charlotta Olhede</dc:creator>
    </item>
    <item>
      <title>New affine invariant ensemble samplers and their dimensional scaling</title>
      <link>https://arxiv.org/abs/2505.02987</link>
      <description>arXiv:2505.02987v3 Announce Type: replace 
Abstract: We introduce new affine invariant ensemble Markov chain Monte Carlo (MCMC) samplers that are easy to construct and improve upon existing methods, especially for high-dimensional problems. We first propose a simple derivative-free side move sampler that improves upon popular samplers in the \texttt{emcee} package by generating more effective proposal directions. We then develop a class of derivative-based affine invariant ensemble Hamiltonian Monte Carlo (HMC) samplers based on antisymmetric preconditioning using complementary ensembles, which outperform standard, non-affine-invariant HMC when sampling highly anisotropic distributions. We provide asymptotic scaling analysis for high-dimensional Gaussian targets to further elucidate the properties of these affine invariant ensemble samplers. In particular, with derivative information, the affine invariant ensemble HMC can scale much better with dimension compared to derivative-free ensemble samplers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02987v3</guid>
      <category>stat.CO</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yifan Chen</dc:creator>
    </item>
    <item>
      <title>Maximum Likelihood Estimates of Parameters in Generalized Gamma Distribution with SeLF Algorithm</title>
      <link>https://arxiv.org/abs/2306.16419</link>
      <description>arXiv:2306.16419v2 Announce Type: replace-cross 
Abstract: This undergraduate thesis focuses on calculating maximum likelihood estimates of parameters in the generalized Gamma distribution using the SeLF algorithm. As an extension of the Gamma distribution, the generalized Gamma distribution can better fit real data and has been widely applied. The research begins by exploring the definition of the generalized Gamma distribution and its similarities and differences from the traditional Gamma distribution. Then, the SeLF and US algorithms are discussed in detail. The SeLF algorithm is a new algorithm based on the Minorization-Maximization algorithm, which can obtain the local optimal solution with few iterations, with the advantages of fast computation, high accuracy, and good convergence. The US algorithm is a method for finding the zeros of a function, which stands at a higher level than the SeLF algorithm and can improve the convergence speed and stability. This thesis proposes a method for calculating maximum likelihood estimates of the parameters in the generalized Gamma distribution using the SeLF and US algorithms, and presents the practical implementation of the algorithms, as well as simulations and data analysis to evaluate the performance of the proposed methods. The results demonstrate that the SeLF algorithm can achieve more stable and accurate estimates of the parameters in the generalized Gamma distribution more quickly, compared to traditional Newton's method, which can be useful in various applications. This thesis provides a comprehensive and in-depth exploration of the generalized Gamma distribution and the SeLF algorithm, and proposes a new method for calculating maximum likelihood estimates of parameters, contributing to the development of statistical methods for parameter estimation in complex models. The proposed method in this thesis has important practical significance and application value for solving practical problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.16419v2</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yufei Cai</dc:creator>
    </item>
    <item>
      <title>coverforest: Conformal Predictions with Random Forest in Python</title>
      <link>https://arxiv.org/abs/2501.14570</link>
      <description>arXiv:2501.14570v3 Announce Type: replace-cross 
Abstract: Conformal prediction provides a framework for uncertainty quantification, specifically in the forms of prediction intervals and sets with distribution-free guaranteed coverage. While recent cross-conformal techniques such as CV+ and Jackknife+-after-bootstrap achieve better data efficiency than traditional split conformal methods, they incur substantial computational costs due to required pairwise comparisons between training and test samples' out-of-bag scores. Observing that these methods naturally extend from ensemble models, particularly random forests, we leverage existing optimized random forest implementations to enable efficient cross-conformal predictions.
  We present coverforest, a Python package that implements efficient conformal prediction methods specifically optimized for random forests. coverforest supports both regression and classification tasks through various conformal prediction methods, including split conformal, CV+, Jackknife+-after-bootstrap, and adaptive prediction sets. Our package leverages parallel computing and Cython optimizations to speed up out-of-bag calculations. Our experiments demonstrate that coverforest's predictions achieve the desired level of coverage. In addition, its training and prediction times can be faster than an existing implementation by 2--9 times. The source code for the coverforest is hosted on GitHub at https://github.com/donlap/coverforest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14570v3</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>stat.CO</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.neucom.2025.132362</arxiv:DOI>
      <arxiv:journal_reference>Neurocomputing. 668, (Mar. 2026), 132362</arxiv:journal_reference>
      <dc:creator>Panisara Meehinkong, Donlapark Ponnoprat</dc:creator>
    </item>
  </channel>
</rss>
