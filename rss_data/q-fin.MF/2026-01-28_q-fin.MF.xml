<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-fin.MF updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-fin.MF</link>
    <description>q-fin.MF updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-fin.MF" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 29 Jan 2026 02:44:34 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Prediction Markets as Bayesian Inverse Problems: Uncertainty Quantification, Identifiability, and Information Gain from Price-Volume Histories under Latent Types</title>
      <link>https://arxiv.org/abs/2601.18815</link>
      <description>arXiv:2601.18815v1 Announce Type: new 
Abstract: Prediction markets are often described as mechanisms that ``aggregate information'' into prices, yet the mapping from dispersed private information to observed market histories is typically noisy, endogenous, and shaped by heterogeneous and strategic participation. This paper formulates prediction markets as Bayesian inverse problems in which the unknown event outcome \(Y\in\{0,1\}\) is inferred from an observed history of market-implied probabilities and traded volumes. We introduce a mechanism-agnostic observation model in log-odds space in which price increments conditional on volume arise from a latent mixture of trader types. The resulting likelihood class encompasses informed and uninformed trading, heavy-tailed microstructure noise, and adversarial or manipulative flow, while requiring only price and volume as observables.
  Within this framework we define posterior uncertainty quantification for \(Y\), provide identifiability and well-posedness criteria in terms of Kullback--Leibler separation between outcome-conditional increment laws, and derive posterior concentration statements and finite-sample error bounds under general regularity assumptions. We further study stability of posterior odds to perturbations of the observed price--volume path and define realized and expected information gain via the posterior-vs-prior KL divergence and mutual information. The inverse-problem formulation yields explicit diagnostics for regimes in which market histories are informative and stable versus regimes in which inference is ill-posed due to type-composition confounding or outcome--nuisance symmetries.
  Extensive experiments on synthetic data validate our theoretical predictions regarding posterior concentration rates and identifiability thresholds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.18815v1</guid>
      <category>q-fin.MF</category>
      <category>stat.ML</category>
      <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Juan Pablo Madrigal-Cianci, Camilo Monsalve Maya, Lachlan Breakey</dc:creator>
    </item>
    <item>
      <title>P-Sensitive Functions and Localizations</title>
      <link>https://arxiv.org/abs/2601.19511</link>
      <description>arXiv:2601.19511v1 Announce Type: cross 
Abstract: This paper assumes a robust stochastic model where a set $\mathcal{P}$ of probability measures replaces the single probability measure of dominated models. We introduce and study $\mathcal{P}$-sensitive functions defined on robust function spaces of random variables. We show that $\mathcal{P}$-sensitive functions are precisely those that admit a representation via so-called functional localization. The theory is applied to solving robust optimization problems, to convex risk measures, and to the study of no arbitrage in robust one-period financial models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.19511v1</guid>
      <category>math.PR</category>
      <category>math.FA</category>
      <category>math.OC</category>
      <category>q-fin.MF</category>
      <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Johannes Langner, Gregor Svindland</dc:creator>
    </item>
    <item>
      <title>Chaotic Hedging with Iterated Integrals and Neural Networks</title>
      <link>https://arxiv.org/abs/2209.10166</link>
      <description>arXiv:2209.10166v5 Announce Type: replace 
Abstract: In this paper, we derive an $L^p$-chaos expansion based on iterated Stratonovich integrals with respect to a given exponentially integrable continuous semimartingale. By omitting the orthogonality of the expansion, we show that every $p$-integrable functional, $p \in [1,\infty)$, can be approximated by a finite sum of iterated Stratonovich integrals. Using (possibly random) neural networks as integrands, we therefere obtain universal approximation results for $p$-integrable financial derivatives in the $L^p$-sense. Moreover, we can approximately solve the $L^p$-hedging problem (coinciding for $p = 2$ with the quadratic hedging problem), where the approximating hedging strategy can be computed in closed form within short runtime.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.10166v5</guid>
      <category>q-fin.MF</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <category>q-fin.CP</category>
      <category>stat.ML</category>
      <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ariel Neufeld, Philipp Schmocker</dc:creator>
    </item>
  </channel>
</rss>
