<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.ST updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.ST</link>
    <description>math.ST updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.ST" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 26 Nov 2024 05:32:59 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Heavy-tailed Contamination is Easier than Adversarial Contamination</title>
      <link>https://arxiv.org/abs/2411.15306</link>
      <description>arXiv:2411.15306v1 Announce Type: new 
Abstract: A large body of work in the statistics and computer science communities dating back to Huber (Huber, 1960) has led to statistically and computationally efficient outlier-robust estimators. Two particular outlier models have received significant attention: the adversarial and heavy-tailed models. While the former models outliers as the result of a malicious adversary manipulating the data, the latter relaxes distributional assumptions on the data allowing outliers to naturally occur as part of the data generating process. In the first setting, the goal is to develop estimators robust to the largest fraction of outliers while in the second, one seeks estimators to combat the loss of statistical efficiency, where the dependence on the failure probability is paramount.
  Despite these distinct motivations, the algorithmic approaches to both these settings have converged, prompting questions on the relationship between the models. In this paper, we investigate and provide a principled explanation for this phenomenon. First, we prove that any adversarially robust estimator is also resilient to heavy-tailed outliers for any statistical estimation problem with i.i.d data. As a corollary, optimal adversarially robust estimators for mean estimation, linear regression, and covariance estimation are also optimal heavy-tailed estimators. Conversely, for arguably the simplest high-dimensional estimation task of mean estimation, we construct heavy-tailed estimators whose application to the adversarial setting requires any black-box reduction to remove almost all the outliers in the data. Taken together, our results imply that heavy-tailed estimation is likely easier than adversarially robust estimation opening the door to novel algorithmic approaches for the heavy-tailed setting. Additionally, confidence intervals obtained for adversarially robust estimation also hold with high-probability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15306v1</guid>
      <category>math.ST</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yeshwanth Cherapanamjeri, Daniel Lee</dc:creator>
    </item>
    <item>
      <title>Extremal bounds for Gaussian trace estimation</title>
      <link>https://arxiv.org/abs/2411.15454</link>
      <description>arXiv:2411.15454v1 Announce Type: new 
Abstract: This work derives extremal tail bounds for the Gaussian trace estimator applied to a real symmetric matrix. We define a partial ordering on the eigenvalues, so that when a matrix has greater spectrum under this ordering, its estimator will have worse tail bounds. This is done for two families of matrices: positive semidefinite matrices with bounded effective rank, and indefinite matrices with bounded 2-norm and fixed Frobenius norm. In each case, the tail region is defined rigorously and is constant for a given family.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15454v1</guid>
      <category>math.ST</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eric Hallman</dc:creator>
    </item>
    <item>
      <title>Community detection for binary graphical models in high dimension</title>
      <link>https://arxiv.org/abs/2411.15627</link>
      <description>arXiv:2411.15627v1 Announce Type: new 
Abstract: Let $N$ components be partitioned into two communities, denoted ${\cal P}_+$ and ${\cal P}_-$, possibly of different sizes. Assume that they are connected via a directed and weighted Erd\"os-R\'enyi random graph (DWER) with unknown parameter $ p \in (0, 1).$ The weights assigned to the existing connections are of mean-field type, scaling as $N^{-1}$. At each time unit, we observe the state of each component: either it sends some signal to its successors (in the directed graph) or remain silent otherwise. In this paper, we show that it is possible to find the communities ${\cal P}_+$ and ${\cal P}_-$ based only on the activity of the $N$ components observed over $T$ time units. More specifically, we propose a simple algorithm for which the probability of {\it exact recovery} converges to $1$ as long as $(N/T^{1/2})\log(NT) \to 0$, as $T$ and $N$ diverge. Interestingly, this simple algorithm does not required any prior knowledge on the other model parameters (e.g. the edge probability $p$). The key step in our analysis is to derive an asymptotic approximation of the one unit time-lagged covariance matrix associated to the states of the $N$ components, as $N$ diverges. This asymptotic approximation relies on the study of the behavior of the solutions of a matrix equation of Stein type satisfied by the simultaneous (0-lagged) covariance matrix associated to the states of the components. This study is challenging, specially because the simultaneous covariance matrix is random since it depends on underlying DWER random graph.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15627v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Julien Chevallier, Guilherme Ost</dc:creator>
    </item>
    <item>
      <title>Federated PCA and Estimation for Spiked Covariance Matrices: Optimal Rates and Efficient Algorithm</title>
      <link>https://arxiv.org/abs/2411.15660</link>
      <description>arXiv:2411.15660v1 Announce Type: new 
Abstract: Federated Learning (FL) has gained significant recent attention in machine learning for its enhanced privacy and data security, making it indispensable in fields such as healthcare, finance, and personalized services. This paper investigates federated PCA and estimation for spiked covariance matrices under distributed differential privacy constraints. We establish minimax rates of convergence, with a key finding that the central server's optimal rate is the harmonic mean of the local clients' minimax rates. This guarantees consistent estimation at the central server as long as at least one local client provides consistent results. Notably, consistency is maintained even if some local estimators are inconsistent, provided there are enough clients. These findings highlight the robustness and scalability of FL for reliable statistical inference under privacy constraints. To establish minimax lower bounds, we derive a matrix version of van Trees' inequality, which is of independent interest. Furthermore, we propose an efficient algorithm that preserves differential privacy while achieving near-optimal rates at the central server, up to a logarithmic factor. We address significant technical challenges in analyzing this algorithm, which involves a three-layer spectral decomposition. Numerical performance of the proposed algorithm is investigated using both simulated and real data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15660v1</guid>
      <category>math.ST</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jingyang Li, T. Tony Cai, Dong Xia, Anru R. Zhang</dc:creator>
    </item>
    <item>
      <title>Large dimensional Spearman's rank correlation matrices: The central limit theorem and its applications</title>
      <link>https://arxiv.org/abs/2411.15861</link>
      <description>arXiv:2411.15861v1 Announce Type: new 
Abstract: This paper is concerned with Spearman's correlation matrices under large dimensional regime, in which the data dimension diverges to infinity proportionally with the sample size. We establish the central limit theorem for the linear spectral statistics of Spearman's correlation matrices, which extends the results of [\emph{Ann. Statist.} 43(2015) 2588--2623]. We also study the improved Spearman's correlation matrices [\emph{Ann. Math. Statist} 19(1948) 293--325] which is a standard U-statistic of order 3. As applications, we propose three new test statistics for large dimensional independent test and numerical studies demonstrate the applicability of our proposed methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15861v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hantao Chen, Cheng Wang</dc:creator>
    </item>
    <item>
      <title>Augmented Estimation of Principal Component Subspace in High Dimensions</title>
      <link>https://arxiv.org/abs/2411.15899</link>
      <description>arXiv:2411.15899v1 Announce Type: new 
Abstract: In this paper, we introduce a novel estimator, called the Augmented Principal Component Subspace, for estimating the principal component subspace for high-dimensional low-sample size data with spiked covariance structure. Our approach augments the naive sample principal component subspace by incorporating additional information from predefined reference directions. Augmented principal component subspace asymptotically reduces every principal angle between the estimated and the true subspaces, thereby outperforming the naive estimator regardless of the metric used. The estimator's efficiency is validated both analytically and through numerical studies, demonstrating significant improvements in accuracy when the reference directions contain substantial information about the true principal component subspace. Additionally, we suggest Augmented PCA using this estimator and explore connections between our method and the recently proposed James-Stein estimator for principal component directions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15899v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dongsun Yoon, Sungkyu Jung</dc:creator>
    </item>
    <item>
      <title>Detecting practically significant dependencies in infinite dimensional data via distance correlations</title>
      <link>https://arxiv.org/abs/2411.16177</link>
      <description>arXiv:2411.16177v1 Announce Type: new 
Abstract: In this paper we take a different look on the problem of testing the independence of two infinite dimensional random variables using the distance correlation. Instead of testing if the distance correlation vanishes exactly, we are interested in the null hypothesis that it does not exceed a certain threshold. Our formulation of the testing problem is motivated by the observation that in many cases it is more reasonable to test for a practically significant dependency since it is rare that a null hypothesis of perfect independence is exactly satisfied. This point of view also reflects statistical practice, where one often classifies the strength of the association in categories such as 'small', 'medium' and 'large' and the precise definitions depend on the specific application.
  To address these problems we develop a pivotal test for the hypothesis that the distance correlation $\mathrm{dcor}(X,Y)$ between two random variables $X$ and $Y$ does not exceed a pre-specified threshold $\Delta$, that is $H_0 : \mathrm{dcor}(X,Y) \leq \Delta$ versus $H_1 : \mathrm{dcor}(X,Y) &gt; \Delta$. We also determine a minimum value $\hat \Delta_\alpha$ from the data such that $H_0$ is rejected for all $\Delta \leq \hat \Delta_\alpha$ at controlled type I error $\alpha$. This quantity can be interpreted as a measure of evidence against the hypothesis of independence.
  The new test is applicable to data modeled by a strictly stationary and absolutely regular process with components taking values in separable metric spaces of negative type, which includes Euclidean as well as functional data. Our approach is based on a new functional limit theorem for the sequential distance correlation process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.16177v1</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Holger Dette, Marius Kroll</dc:creator>
    </item>
    <item>
      <title>Influence functions and regularity tangents for efficient active learning</title>
      <link>https://arxiv.org/abs/2411.15292</link>
      <description>arXiv:2411.15292v1 Announce Type: cross 
Abstract: In this paper we describe an efficient method for providing a regression model with a sense of curiosity about its data. In the field of machine learning, our framework for representing curiosity is called Active Learning, which means automatically choosing data points for which to query labels in the semisupervised setting. The methods we propose are based on computing a "regularity tangent" vector that can be calculated (with only a constant slow-down) together with the model's parameter vector during training. We then take the inner product of this tangent vector with the gradient vector of the model's loss at a given data point to obtain a measure of the influence of that point on the complexity of the model. There is only a single regularity tangent vector, of the same dimension as the parameter vector. Thus, in the proposed technique, once training is complete, evaluating our "curiosity" about a potential query data point can be done as quickly as calculating the model's loss gradient at that point. The new vector only doubles the amount of storage required by the model. We show that the quantity computed by our technique is an example of an "influence function", and that it measures the expected squared change in model complexity incurred by up-weighting a given data point. We propose a number of ways for using this quantity to choose new training data for a model in the framework of active learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15292v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Frederik Eaton</dc:creator>
    </item>
    <item>
      <title>Gradient dynamics for low-rank fine-tuning beyond kernels</title>
      <link>https://arxiv.org/abs/2411.15385</link>
      <description>arXiv:2411.15385v1 Announce Type: cross 
Abstract: LoRA has emerged as one of the de facto methods for fine-tuning foundation models with low computational cost and memory footprint. The idea is to only train a low-rank perturbation to the weights of a pre-trained model, given supervised data for a downstream task. Despite its empirical sucess, from a mathematical perspective it remains poorly understood what learning mechanisms ensure that gradient descent converges to useful low-rank perturbations.
  In this work we study low-rank fine-tuning in a student-teacher setting. We are given the weights of a two-layer base model $f$, as well as i.i.d. samples $(x,f^*(x))$ where $x$ is Gaussian and $f^*$ is the teacher model given by perturbing the weights of $f$ by a rank-1 matrix. This generalizes the setting of generalized linear model (GLM) regression where the weights of $f$ are zero.
  When the rank-1 perturbation is comparable in norm to the weight matrix of $f$, the training dynamics are nonlinear. Nevertheless, in this regime we prove under mild assumptions that a student model which is initialized at the base model and trained with online gradient descent will converge to the teacher in $dk^{O(1)}$ iterations, where $k$ is the number of neurons in $f$. Importantly, unlike in the GLM setting, the complexity does not depend on fine-grained properties of the activation's Hermite expansion. We also prove that in our setting, learning the teacher model "from scratch'' can require significantly more iterations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15385v1</guid>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arif Kerem Dayi, Sitan Chen</dc:creator>
    </item>
    <item>
      <title>Canonical Correlation Analysis: review</title>
      <link>https://arxiv.org/abs/2411.15625</link>
      <description>arXiv:2411.15625v1 Announce Type: cross 
Abstract: For over a century canonical correlations, variables, and related concepts have been studied across various fields, with contributions dating back to Jordan [1875] and Hotelling [1936]. This text surveys the evolution of canonical correlation analysis, a fundamental statistical tool, beginning with its foundational theorems and progressing to recent developments and open research problems. Along the way we introduce and review methods, notions, and fundamental concepts from linear algebra, random matrix theory, and high-dimensional statistics, placing particular emphasis on rigorous mathematical treatment.
  The survey is intended for technically proficient graduate students and other researchers with an interest in this area. The content is organized into five chapters, supplemented by six sets of exercises found in Chapter 6. These exercises introduce additional material, reinforce key concepts, and serve to bridge ideas across chapters. We recommend the following sequence: first, solve Problem Set 0, then proceed with Chapter 1, solve Problem Set 1, and so on through the text.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15625v1</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anna Bykhovskaya, Vadim Gorin</dc:creator>
    </item>
    <item>
      <title>Computing marginal eigenvalue distributions for the Gaussian and Laguerre orthogonal ensembles</title>
      <link>https://arxiv.org/abs/2411.15635</link>
      <description>arXiv:2411.15635v1 Announce Type: cross 
Abstract: The Gaussian and Laguerre orthogonal ensembles are fundamental to random matrix theory, and the marginal eigenvalue distributions are basic observable quantities. Notwithstanding a long history, a formulation providing high precision numerical evaluations for $N$ large enough to probe asymptotic regimes, has not been provided. An exception is for the largest eigenvalue, where there is a formalism due to Chiani which uses a combination of the Pfaffian structure underlying the ensembles, and a recursive computation of the matrix elements. We augment this strategy by introducing a generating function for the conditioned gap probabilities. A finite Fourier series approach is then used to extract the sequence of marginal eigenvalue distributions as a linear combination of Pfaffians, with the latter then evaluated using an efficient numerical procedure available in the literature. Applications are given to illustrating various asymptotic formulas, local central limit theorems, and central limit theorems, as well as to probing finite size corrections. Further, our data indicates that the mean values of the marginal distributions interlace with the zeros of the Hermite polynomial (Gaussian ensemble) and a Laguerre polynomial (Laguerre ensemble).</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15635v1</guid>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Peter J. Forrester, Santosh Kumar, Bo-Jian Shen</dc:creator>
    </item>
    <item>
      <title>Implicit High-Order Moment Tensor Estimation and Learning Latent Variable Models</title>
      <link>https://arxiv.org/abs/2411.15669</link>
      <description>arXiv:2411.15669v1 Announce Type: cross 
Abstract: We study the task of learning latent-variable models. An obstacle towards designing efficient algorithms for such models is the necessity of approximating moment tensors of super-constant degree. Motivated by such applications, we develop a general efficient algorithm for implicit moment tensor computation. Our algorithm computes in $\mathrm{poly}(d, k)$ time a succinct approximate description of tensors of the form $M_m=\sum_{i=1}^{k}w_iv_i^{\otimes m}$, for $w_i\in\mathbb{R}_+$--even for $m=\omega(1)$--assuming there exists a polynomial-size arithmetic circuit whose expected output on an appropriate samplable distribution is equal to $M_m$, and whose covariance on this input is bounded. Our framework broadly generalizes the work of~\cite{LL21-opt} which developed an efficient algorithm for the specific moment tensors that arise in clustering mixtures of spherical Gaussians.
  By leveraging our general algorithm, we obtain the first polynomial-time learners for the following models.
  * Mixtures of Linear Regressions. We give a $\mathrm{poly}(d, k, 1/\epsilon)$-time algorithm for this task. The previously best algorithm has super-polynomial complexity in $k$.
  * Learning Mixtures of Spherical Gaussians. We give a $\mathrm{poly}(d, k, 1/\epsilon)$-time density estimation algorithm, under the condition that the means lie in a ball of radius $O(\sqrt{\log k})$. Prior algorithms incur super-polynomial complexity in $k$. We also give a $\mathrm{poly}(d, k, 1/\epsilon)$-time parameter estimation algorithm, under the {\em optimal} mean separation of $\Omega(\log^{1/2}(k/\epsilon))$.
  * PAC Learning Sums of ReLUs. We give a learner with complexity $\mathrm{poly}(d, k) 2^{\mathrm{poly}(1/\epsilon)}$. This is the first algorithm for this task that runs in $\mathrm{poly}(d, k)$ time for subconstant values of $\epsilon = o_{k, d}(1)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15669v1</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ilias Diakonikolas, Daniel M. Kane</dc:creator>
    </item>
    <item>
      <title>Data integration using covariate summaries from external sources</title>
      <link>https://arxiv.org/abs/2411.15691</link>
      <description>arXiv:2411.15691v1 Announce Type: cross 
Abstract: In modern data analysis, information is frequently collected from multiple sources, often leading to challenges such as data heterogeneity and imbalanced sample sizes across datasets. Robust and efficient data integration methods are crucial for improving the generalization and transportability of statistical findings. In this work, we address scenarios where, in addition to having full access to individualized data from a primary source, supplementary covariate information from external sources is also available. While traditional data integration methods typically require individualized covariates from external sources, such requirements can be impractical due to limitations related to accessibility, privacy, storage, and cost. Instead, we propose novel data integration techniques that rely solely on external summary statistics, such as sample means and covariances, to construct robust estimators for the mean outcome under both homogeneous and heterogeneous data settings. Additionally, we extend this framework to causal inference, enabling the estimation of average treatment effects for both generalizability and transportability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15691v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Facheng Yu, Yuqian Zhang</dc:creator>
    </item>
    <item>
      <title>Stable Approximation for Call Function Via Stein's method</title>
      <link>https://arxiv.org/abs/2411.15881</link>
      <description>arXiv:2411.15881v1 Announce Type: cross 
Abstract: Let $S_{n}$ be a sum of independent identically distribution random variables with finite first moment and $h_{M}$ be a call function defined by $g_{M}(x)=\max\{x-M,0\}$ for $x\in\mathbb{R}$, $M&gt;0$. In this paper, we assume the random variables are in the domain $\mathcal{R}_{\alpha}$ of normal attraction of a stable law of exponent $\alpha$, then for $\alpha\in(1,2)$, we use the Stein's method developed in \cite{CNX21} to give uniform and non uniform bounds on $\alpha$-stable approximation for the call function without additional moment assumptions. These results will make the approximation theory of call function applicable to the lower moment conditions, and greatly expand the scope of application of call function in many fields.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15881v1</guid>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Peng Chen, Tianyi Qi, Ting Zhang</dc:creator>
    </item>
    <item>
      <title>Selective Inference for Time-Varying Effect Moderation</title>
      <link>https://arxiv.org/abs/2411.15908</link>
      <description>arXiv:2411.15908v1 Announce Type: cross 
Abstract: Causal effect moderation investigates how the effect of interventions (or treatments) on outcome variables changes based on observed characteristics of individuals, known as potential effect moderators. With advances in data collection, datasets containing many observed features as potential moderators have become increasingly common. High-dimensional analyses often lack interpretability, with important moderators masked by noise, while low-dimensional, marginal analyses yield many false positives due to strong correlations with true moderators. In this paper, we propose a two-step method for selective inference on time-varying causal effect moderation that addresses the limitations of both high-dimensional and marginal analyses. Our method first selects a relatively smaller, more interpretable model to estimate a linear causal effect moderation using a Gaussian randomization approach. We then condition on the selection event to construct a pivot, enabling uniformly asymptotic semi-parametric inference in the selected model. Through simulations and real data analyses, we show that our method consistently achieves valid coverage rates, even when existing conditional methods and common sample splitting techniques fail. Moreover, our method yields shorter, bounded intervals, unlike existing methods that may produce infinitely long intervals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15908v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Soham Bakshi, Walter Dempsey, Snigdha Panigrahi</dc:creator>
    </item>
    <item>
      <title>Understanding Machine Learning Paradigms through the Lens of Statistical Thermodynamics: A tutorial</title>
      <link>https://arxiv.org/abs/2411.15945</link>
      <description>arXiv:2411.15945v1 Announce Type: cross 
Abstract: This tutorial investigates the convergence of statistical mechanics and learning theory, elucidating the potential enhancements in machine learning methodologies through the integration of foundational principles from physics. The tutorial delves into advanced techniques like entropy, free energy, and variational inference which are utilized in machine learning, illustrating their significant contributions to model efficiency and robustness. By bridging these scientific disciplines, we aspire to inspire newer methodologies in researches, demonstrating how an in-depth comprehension of physical systems' behavior can yield more effective and dependable machine learning models, particularly in contexts characterized by uncertainty.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15945v1</guid>
      <category>cs.LG</category>
      <category>cond-mat.mtrl-sci</category>
      <category>math.ST</category>
      <category>physics.chem-ph</category>
      <category>stat.TH</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator> Star (Xinxin),  Liu</dc:creator>
    </item>
    <item>
      <title>On the achievability of efficiency bounds for covariate-adjusted response-adaptive randomization</title>
      <link>https://arxiv.org/abs/2411.16220</link>
      <description>arXiv:2411.16220v1 Announce Type: cross 
Abstract: In the context of precision medicine, covariate-adjusted response-adaptive randomization (CARA) has garnered much attention from both academia and industry due to its benefits in providing ethical and tailored treatment assignments based on patients' profiles while still preserving favorable statistical properties. Recent years have seen substantial progress in understanding the inference for various adaptive experimental designs. In particular, research has focused on two important perspectives: how to obtain robust inference in the presence of model misspecification, and what the smallest variance, i.e., the efficiency bound, an estimator can achieve. Notably, Armstrong (2022) derived the asymptotic efficiency bound for any randomization procedure that assigns treatments depending on covariates and accrued responses, thus including CARA, among others. However, to the best of our knowledge, no existing literature has addressed whether and how the asymptotic efficiency bound can be achieved under CARA. In this paper, by connecting two strands of literature on adaptive randomization, namely robust inference and efficiency bound, we provide a definitive answer to this question for an important practical scenario where only discrete covariates are observed and used to form stratification. We consider a specific type of CARA, i.e., a stratified version of doubly-adaptive biased coin design, and prove that the stratified difference-in-means estimator achieves Armstrong (2022)'s efficiency bound, with possible ethical constraints on treatment assignments. Our work provides new insights and demonstrates the potential for more research regarding the design and analysis of CARA that maximizes efficiency while adhering to ethical considerations. Future studies could explore how to achieve the asymptotic efficiency bound for general CARA with continuous covariates, which remains an open question.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.16220v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jiahui Xin, Wei Ma</dc:creator>
    </item>
    <item>
      <title>Local Learning for Covariate Selection in Nonparametric Causal Effect Estimation with Latent Variables</title>
      <link>https://arxiv.org/abs/2411.16315</link>
      <description>arXiv:2411.16315v1 Announce Type: cross 
Abstract: Estimating causal effects from nonexperimental data is a fundamental problem in many fields of science. A key component of this task is selecting an appropriate set of covariates for confounding adjustment to avoid bias. Most existing methods for covariate selection often assume the absence of latent variables and rely on learning the global network structure among variables. However, identifying the global structure can be unnecessary and inefficient, especially when our primary interest lies in estimating the effect of a treatment variable on an outcome variable. To address this limitation, we propose a novel local learning approach for covariate selection in nonparametric causal effect estimation, which accounts for the presence of latent variables. Our approach leverages testable independence and dependence relationships among observed variables to identify a valid adjustment set for a target causal relationship, ensuring both soundness and completeness under standard assumptions. We validate the effectiveness of our algorithm through extensive experiments on both synthetic and real-world data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.16315v1</guid>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zheng Li, Feng Xie, Yan Zeng, Zhi Geng</dc:creator>
    </item>
    <item>
      <title>Generalized bootstrap in the Bures-Wasserstein space</title>
      <link>https://arxiv.org/abs/2111.12612</link>
      <description>arXiv:2111.12612v2 Announce Type: replace 
Abstract: This study focuses on finite-sample inference on the non-linear Bures-Wasserstein manifold and introduces a generalized bootstrap procedure for estimating Bures-Wasserstein barycenters. We provide non-asymptotic statistical guarantees for the resulting bootstrap confidence sets. The proposed approach incorporates classical resampling methods, including the multiplier bootstrap highlighted as a specific example. Additionally, the paper compares bootstrap-based confidence sets with asymptotic sets obtained in the work arXiv:1901.00226v2, evaluating their statistical performance and computational complexities. The methodology is validated through experiments on synthetic datasets and real-world applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2111.12612v2</guid>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.TH</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexey Kroshnin, Vladimir Spokoiny, Alexandra Suvorikova</dc:creator>
    </item>
    <item>
      <title>Sample Complexity of Probability Divergences under Group Symmetry</title>
      <link>https://arxiv.org/abs/2302.01915</link>
      <description>arXiv:2302.01915v3 Announce Type: replace 
Abstract: We rigorously quantify the improvement in the sample complexity of variational divergence estimations for group-invariant distributions. In the cases of the Wasserstein-1 metric and the Lipschitz-regularized $\alpha$-divergences, the reduction of sample complexity is proportional to the group size if the group is finite. In addition to the published version at ICML 2023, our proof indeed has included the case when the group is infinite such as compact Lie groups, the convergence rate can be further improved and depends on the intrinsic dimension of the fundamental domain characterized by the scaling of its covering number. Our approach is different from that in [Tahmasebi &amp; Jegelka, ICML 2024] and our work also applies to asymmetric divergences, such as the Lipschitz-regularized $\alpha$-divergences. For the maximum mean discrepancy (MMD), the improvement of sample complexity is more nuanced, as it depends on not only the group size but also the choice of kernel. Numerical simulations verify our theories.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.01915v3</guid>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ziyu Chen, Markos A. Katsoulakis, Luc Rey-Bellet, Wei Zhu</dc:creator>
    </item>
    <item>
      <title>Distribution-free tests for lossless feature selection in classification and regression</title>
      <link>https://arxiv.org/abs/2311.05033</link>
      <description>arXiv:2311.05033v2 Announce Type: replace 
Abstract: We study the problem of lossless feature selection for a $d$-dimensional feature vector $X=(X^{(1)},\dots ,X^{(d)})$ and label $Y$ for binary classification as well as nonparametric regression. For an index set $S\subset \{1,\dots ,d\}$, consider the selected $|S|$-dimensional feature subvector $X_S=(X^{(i)}, i\in S)$. If $L^*$ and $L^*(S)$ stand for the minimum risk based on $X$ and $X_S$, respectively, then $X_S$ is called lossless if $L^*=L^*(S)$. For classification, the minimum risk is the Bayes error probability, while in regression, the minimum risk is the residual variance. We introduce nearest-neighbor based test statistics to test the hypothesis that $X_S$ is lossless. This test statistic is an estimate of the excess risk $L^*(S)-L^*$. Surprisingly, estimating this excess risk turns out to be a functional estimation problem that does not suffer from the curse of dimensionality in the sense that the convergence rate does not depend on the dimension $d$. For the threshold $a_n=\log n/\sqrt{n}$, the corresponding tests are proved to be consistent under conditions on the distribution of $(X,Y)$ that are significantly milder than in previous work. Also, our threshold is universal (dimension independent), in contrast to earlier methods where for large $d$ the threshold becomes too large to be useful in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.05033v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>L\'aszl\'o Gy\"orfi, Tam\'as Linder, Harro Walk</dc:creator>
    </item>
    <item>
      <title>Selecting informative conformal prediction sets with false coverage rate control</title>
      <link>https://arxiv.org/abs/2403.12295</link>
      <description>arXiv:2403.12295v3 Announce Type: replace 
Abstract: In supervised learning, including regression and classification, conformal methods provide prediction sets for the outcome/label with finite sample coverage for any machine learning predictor. We consider here the case where such prediction sets come after a selection process. The selection process requires that the selected prediction sets be `informative' in a well defined sense. We consider both the classification and regression settings where the analyst may consider as informative only the sample with prediction sets small enough, excluding null values, or obeying other appropriate `monotone' constraints. We develop a unified framework for building such informative conformal prediction sets while controlling the false coverage rate (FCR) on the selected sample. While conformal prediction sets after selection have been the focus of much recent literature in the field, the new introduced procedures, called InfoSP and InfoSCOP, are to our knowledge the first ones providing FCR control for informative prediction sets. We show the usefulness of our resulting procedures on real and simulated data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12295v3</guid>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ulysse Gazin, Ruth Heller, Ariane Marandon, Etienne Roquain</dc:creator>
    </item>
    <item>
      <title>Estimating odds and log odds with guaranteed accuracy</title>
      <link>https://arxiv.org/abs/2404.17705</link>
      <description>arXiv:2404.17705v3 Announce Type: replace 
Abstract: Two sequential estimators are proposed for the odds p/(1-p) and log odds log(p/(1-p)) respectively, using independent Bernoulli random variables with parameter p as inputs. The estimators are unbiased, and guarantee that the variance of the estimation error divided by the true value of the odds, or the variance of the estimation error of the log odds, are less than a target value for any p in (0,1). The estimators are close to optimal in the sense of Wolfowitz's bound.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17705v3</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luis Mendo</dc:creator>
    </item>
    <item>
      <title>Filtering and Statistical Properties of Unimodal Maps Perturbed by Heteroscedastic Noises</title>
      <link>https://arxiv.org/abs/2411.13939</link>
      <description>arXiv:2411.13939v2 Announce Type: replace 
Abstract: We propose a theory of unimodal maps perturbed by an heteroscedastic Markov chain noise and experiencing another heteroscedastic noise due to uncertain observation. We address and treat the filtering problem showing that by collecting more and more observations, one would predict the same distribution for the state of the underlying Markov chain no matter one's initial guess. Moreover we give other limit theorems, emphasizing in particular concentration inequalities and extreme value and Poisson distributions. Our results apply to a family of maps arising from a model of systemic risk in finance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.13939v2</guid>
      <category>math.ST</category>
      <category>math.DS</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fabrizio Lillo, Stefano Marmi, Matteo Tanzi, Sandro Vaienti</dc:creator>
    </item>
    <item>
      <title>Early stopping and polynomial smoothing in regression with reproducing kernels</title>
      <link>https://arxiv.org/abs/2007.06827</link>
      <description>arXiv:2007.06827v3 Announce Type: replace-cross 
Abstract: In this paper, we study the problem of early stopping for iterative learning algorithms in a reproducing kernel Hilbert space (RKHS) in the nonparametric regression framework. In particular, we work with the gradient descent and (iterative) kernel ridge regression algorithms. We present a data-driven rule to perform early stopping without a validation set that is based on the so-called minimum discrepancy principle. This method enjoys only one assumption on the regression function: it belongs to a reproducing kernel Hilbert space (RKHS). The proposed rule is proved to be minimax-optimal over different types of kernel spaces, including finite-rank and Sobolev smoothness classes. The proof is derived from the fixed-point analysis of the localized Rademacher complexities, which is a standard technique for obtaining optimal rates in the nonparametric regression literature. In addition to that, we present simulation results on artificial datasets that show the comparable performance of the designed rule with respect to other stopping rules such as the one determined by V-fold cross-validation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2007.06827v3</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yaroslav Averyanov, Alain Celisse</dc:creator>
    </item>
    <item>
      <title>Posterior risk of modular and semi-modular Bayesian inference</title>
      <link>https://arxiv.org/abs/2301.10911</link>
      <description>arXiv:2301.10911v3 Announce Type: replace-cross 
Abstract: Modular Bayesian methods perform inference in models that are specified through a collection of coupled sub-models, known as modules. These modules often arise from modelling different data sources or from combining domain knowledge from different disciplines. ``Cutting feedback'' is a Bayesian inference method that ensures misspecification of one module does not affect inferences for parameters in other modules, and produces what is known as the cut posterior. However, choosing between the cut posterior and the standard Bayesian posterior is challenging. When misspecification is not severe, cutting feedback can greatly increase posterior uncertainty without a large reduction of estimation bias, leading to a bias-variance trade-off. This trade-off motivates semi-modular posteriors, which interpolate between standard and cut posteriors based on a tuning parameter. In this work, we provide the first precise formulation of the bias-variance trade-off that is present in cutting feedback, and we propose a new semi-modular posterior that takes advantage of it. Under general regularity conditions, we prove that this semi-modular posterior is more accurate than the cut posterior according to a notion of posterior risk. An important implication of this result is that point inferences made under the cut posterior are inadmissable. The new method is demonstrated in a number of examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.10911v3</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.TH</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David T. Frazier, David J. Nott</dc:creator>
    </item>
    <item>
      <title>Estimating the roughness exponent of stochastic volatility from discrete observations of the integrated variance</title>
      <link>https://arxiv.org/abs/2307.02582</link>
      <description>arXiv:2307.02582v3 Announce Type: replace-cross 
Abstract: We consider the problem of estimating the roughness of the volatility process in a stochastic volatility model that arises as a nonlinear function of fractional Brownian motion with drift. To this end, we introduce a new estimator that measures the so-called roughness exponent of a continuous trajectory, based on discrete observations of its antiderivative. The estimator has a very simple form and can be computed with great efficiency on large data sets. It is not derived from distributional assumptions but from strictly pathwise considerations. We provide conditions on the underlying trajectory under which our estimator converges in a strictly pathwise sense. Then we verify that these conditions are satisfied by almost every sample path of fractional Brownian motion (with drift). As a consequence, we obtain strong consistency theorems in the context of a large class of rough volatility models, such as the rough fractional volatility model and the rough Bergomi model. We also demonstrate that our estimator is robust with respect to proxy errors between the integrated and realized variance, and that it can be applied to estimate the roughness exponent directly from the price trajectory. Numerical simulations show that our estimation procedure performs well after passing to a scale-invariant modification of our estimator.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.02582v3</guid>
      <category>q-fin.ST</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiyue Han, Alexander Schied</dc:creator>
    </item>
    <item>
      <title>Robust Point Matching with Distance Profiles</title>
      <link>https://arxiv.org/abs/2312.12641</link>
      <description>arXiv:2312.12641v3 Announce Type: replace-cross 
Abstract: We show the outlier robustness and noise stability of practical matching procedures based on distance profiles. Although the idea of matching points based on invariants like distance profiles has a long history in the literature, there has been little understanding of the theoretical properties of such procedures, especially in the presence of outliers and noise. We provide a theoretical analysis showing that under certain probabilistic settings, the proposed matching procedure is successful with high probability even in the presence of outliers and noise. We demonstrate the performance of the proposed method using a real data example and provide simulation studies to complement the theoretical findings. Lastly, we extend the concept of distance profiles to the abstract setting and connect the proposed matching procedure to the Gromov-Wasserstein distance and its lower bound, with a new sample complexity result derived based on the properties of distance profiles. As a result, we contribute to the literature by providing theoretical underpinnings of the matching procedures based on invariants like distance profiles, which have been widely used in practice but have rarely been analyzed theoretically.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.12641v3</guid>
      <category>stat.ME</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>YoonHaeng Hur, Yuehaw Khoo</dc:creator>
    </item>
    <item>
      <title>Generalization Error Curves for Analytic Spectral Algorithms under Power-law Decay</title>
      <link>https://arxiv.org/abs/2401.01599</link>
      <description>arXiv:2401.01599v3 Announce Type: replace-cross 
Abstract: The generalization error curve of certain kernel regression method aims at determining the exact order of generalization error with various source condition, noise level and choice of the regularization parameter rather than the minimax rate. In this work, under mild assumptions, we rigorously provide a full characterization of the generalization error curves of the kernel gradient descent method (and a large class of analytic spectral algorithms) in kernel regression. Consequently, we could sharpen the near inconsistency of kernel interpolation and clarify the saturation effects of kernel regression algorithms with higher qualification, etc. Thanks to the neural tangent kernel theory, these results greatly improve our understanding of the generalization behavior of training the wide neural networks. A novel technical contribution, the analytic functional argument, might be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.01599v3</guid>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Yicheng Li, Weiye Gan, Zuoqiang Shi, Qian Lin</dc:creator>
    </item>
    <item>
      <title>AdaTrans: Feature-wise and Sample-wise Adaptive Transfer Learning for High-dimensional Regression</title>
      <link>https://arxiv.org/abs/2403.13565</link>
      <description>arXiv:2403.13565v3 Announce Type: replace-cross 
Abstract: We consider the transfer learning problem in the high dimensional linear regression setting, where the feature dimension is larger than the sample size. To learn transferable information, which may vary across features or the source samples, we propose an adaptive transfer learning method that can detect and aggregate the feature-wise (F-AdaTrans) or sample-wise (S-AdaTrans) transferable structures. We achieve this by employing a fused-penalty, coupled with weights that can adapt according to the transferable structure. To choose the weight, we propose a theoretically informed, data-driven procedure, enabling F-AdaTrans to selectively fuse the transferable signals with the target while filtering out non-transferable signals, and S-AdaTrans to obtain the optimal combination of information transferred from each source sample. We show that, with appropriately chosen weights, F-AdaTrans achieves a convergence rate close to that of an oracle estimator with a known transferable structure, and S-AdaTrans recovers existing near-minimax optimal rates as a special case. The effectiveness of the proposed method is validated using both simulation and real data, demonstrating favorable performance compared to the existing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.13565v3</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zelin He, Ying Sun, Jingyuan Liu, Runze Li</dc:creator>
    </item>
    <item>
      <title>Estimation of Spatiotemporal Poisson Processes with Some Missing Location Data</title>
      <link>https://arxiv.org/abs/2410.11103</link>
      <description>arXiv:2410.11103v3 Announce Type: replace-cross 
Abstract: We consider models for spatiotemporal Poisson processes with some missing location data. We discuss four models that make provision for missing location data, and their estimation. The corresponding code is available on GitHub as an extension of LASPATED at https://github.com/vguigues/LASPATED/Missing_Data. We tested our models using the process of emergency call arrivals to an emergency medical service where the emergency reports often omit the location of the emergency. We show the difference made by using models that make provision for missing location data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11103v3</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.TH</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vincent Guigues, Anton Kleywegt, Victor Hugo Nascimento, Lucas Lucas Rafael de Andrade</dc:creator>
    </item>
  </channel>
</rss>
