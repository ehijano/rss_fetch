<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 17 Jun 2025 02:27:57 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Complexity of normalized stochastic first-order methods with momentum under heavy-tailed noise</title>
      <link>https://arxiv.org/abs/2506.11214</link>
      <description>arXiv:2506.11214v1 Announce Type: new 
Abstract: In this paper, we propose practical normalized stochastic first-order methods with Polyak momentum, multi-extrapolated momentum, and recursive momentum for solving unconstrained optimization problems. These methods employ dynamically updated algorithmic parameters and do not require explicit knowledge of problem-dependent quantities such as the Lipschitz constant or noise bound. We establish first-order oracle complexity results for finding approximate stochastic stationary points under heavy-tailed noise and weakly average smoothness conditions -- both of which are weaker than the commonly used bounded variance and mean-squared smoothness assumptions. Our complexity bounds either improve upon or match the best-known results in the literature. Numerical experiments are presented to demonstrate the practical effectiveness of the proposed methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11214v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.CC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chuan He, Zhaosong Lu, Defeng Sun, Zhanwang Deng</dc:creator>
    </item>
    <item>
      <title>A continuous-time model to interpolate between speed and function value restart in accelerated first order methods</title>
      <link>https://arxiv.org/abs/2506.11267</link>
      <description>arXiv:2506.11267v1 Announce Type: new 
Abstract: We introduce a new restarting scheme for a continuous inertial dynamics with Hessian driven-damping, and establish a linear convergence rate for the function values along the restarted trajectories. The proposed routine is a generalization of existing speed restart schemes, and interpolates between speed and function value restarts, considerably delaying the restarting time, while preserving the function value decrease. Numerical experiments show an improvement in the convergence rates for both continuous-time dynamical systems, and associated first-order algorithms derived via time discretization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11267v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Juan Jos\'e Maul\'en, Huiyuan Guo, Juan Peypouquet</dc:creator>
    </item>
    <item>
      <title>Rate of metastability of an iterative algorithm for quadratic optimization</title>
      <link>https://arxiv.org/abs/2506.11342</link>
      <description>arXiv:2506.11342v1 Announce Type: new 
Abstract: In this paper, relying on methods from proof mining, we provide a quantitative analysis of a theorem due to Xu, stating that an iteration strongly converges to the solution of a well known quadratic optimization problem. Rates of metastability and some rates of asymptotic regularity were obtained. We get quadratic rates of asymptotic regularity for particular sequences.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11342v1</guid>
      <category>math.OC</category>
      <category>math.LO</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Paulo Firmino</dc:creator>
    </item>
    <item>
      <title>$\ell_{1}^{2}-\eta\ell_{2}^{2}$ regularization for sparse recovery</title>
      <link>https://arxiv.org/abs/2506.11372</link>
      <description>arXiv:2506.11372v1 Announce Type: new 
Abstract: This paper presents a regularization technique incorporating a non-convex and non-smooth term, $\ell_{1}^{2}-\eta\ell_{2}^{2}$, with parameters $0&lt;\eta\leq 1$ designed to address ill-posed linear problems that yield sparse solutions. We explore the existence, stability, and convergence of the regularized solution, demonstrating that the $\ell_{1}^{2}-\eta\ell_{2}^{2}$ regularization is well-posed and results in sparse solutions. Under suitable source conditions, we establish a convergence rate of $\mathcal{O}\left(\delta\right)$ in the $\ell_{2}$-norm for both a priori and a posteriori parameter choice rules. Additionally, we propose and analyze a numerical algorithm based on a half-variation iterative strategy combined with the proximal gradient method. We prove convergence despite the regularization term being non-smooth and non-convex. The algorithm features a straightforward structure, facilitating implementation. Furthermore, we propose a projected gradient iterative strategy base on surrogate function approach to achieve faster solving. Experimentally, we demonstrate visible improvements of $\ell_{1}^{2}-\eta\ell_{2}^{2}$ over $\ell_{1}$, $\ell_{1}-\eta\ell_{2}$, and other nonconvex regularizations for compressive sensing and image deblurring problems. All the numerical results show the efficiency of our proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11372v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Long Li, Liang Ding</dc:creator>
    </item>
    <item>
      <title>SVD method for sparse recovery</title>
      <link>https://arxiv.org/abs/2506.11379</link>
      <description>arXiv:2506.11379v1 Announce Type: new 
Abstract: Sparsity regularization has garnered significant interest across multiple disciplines, including statistics, imaging, and signal processing. Standard techniques for addressing sparsity regularization include iterative soft thresholding algorithms and their accelerated variants. However, these algorithms rely on Landweber iteration, which can be computationally intensive. Therefore, there is a pressing need to develop a more efficient algorithm for sparsity regularization. The Singular Value Decomposition (SVD) method serves as a regularization strategy that does not require Landweber iterations; however, it is confined to classical quadratic regularization. This paper introduces two inversion schemes tailored for situations where the operator $K$ is diagonal within a specific orthogonal basis, focusing on $\ell_{p}$ regularization when $p=1$ and $p=1/2$. Furthermore, we demonstrate that for a general linear compact operator $K$, the SVD method serves as an effective regularization strategy. To assess the efficacy of the proposed methodologies, We conduct several numerical experiments to evaluate the proposed method's effectiveness. The results indicate that our algorithms not only operate faster but also achieve a higher success rate than traditional iterative methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11379v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Long Li, Liang Ding</dc:creator>
    </item>
    <item>
      <title>Complexity guarantees for risk-neutral generalized Nash equilibrium problems</title>
      <link>https://arxiv.org/abs/2506.11409</link>
      <description>arXiv:2506.11409v1 Announce Type: new 
Abstract: In this paper, we address \ac{SGNEP} seeking with risk-neutral agents. Our main contribution lies the development of a stochastic variance-reduced gradient (SVRG) technique, modified to contend with general sample spaces, within a stochastic forward-backward-forward splitting scheme for resolving structured monotone inclusion problems. This stochastic scheme is a double-loop method, in which the mini-batch gradient estimator is computed periodically in the outer loop, while only cheap sampling is required in a frequently activated inner loop, thus achieving significant speed-ups when sampling costs cannot be overlooked. The algorithm is fully distributed and it guarantees almost sure convergence under appropriate batch size and strong monotonicity assumptions. Moreover, it exhibits a linear rate with possible biased estimators, which is rather mild and imposed in many simulation-based optimization schemes. Under monotone regimes, the expectation of the gap function of an averaged iterate diminishes at a suitable sublinear rate while the sample-complexity of computing an $\epsilon$-solution is provably $\mathcal{O}(\epsilon^{-3})$. A numerical study on a class of networked Cournot games reflects the performance of our proposed algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11409v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haochen Tao, Andrea Iannelli, Meggie Marschner, Mathias Staudigl, Uday V. Shanbhag, Shisheng Cui</dc:creator>
    </item>
    <item>
      <title>Improved Uncooperative Spacecraft Maneuver Detection with Space-based Optical Observations</title>
      <link>https://arxiv.org/abs/2506.11435</link>
      <description>arXiv:2506.11435v1 Announce Type: new 
Abstract: Building and maintaining a space object catalog is necessary for space situational awareness. To realize this, one great challenge is uncooperative spacecraft maneuver detection because unknown maneuver events can lead to deviated orbital predictions and losses of tracking. Nowadays, more and more spacecraft equip electric propulsion and perform long-duration maneuvers to realize orbital transfer. Previous studies have investigated impulsive maneuver detection with space surveillance data. But, the developed method does not suffice for cases where maneuver durations are long. In this study, an improved uncooperative spacecraft maneuver detection method with space-based optical observations is proposed. Instead of a sudden maneuver event, the maneuver duration is considered. The maneuver starting/ending times are estimated along with the thrust acceleration vector. The angular residuals of nonlinear least square estimates are used to judge whether a maneuver policy could be a potential solution. The global optimum maneuver policy is chosen from multiple local minima according to the minimum-fuel principle. It is demonstrated that the maneuver duration is poorly observable if the thrust is along the orbital normal direction attributed to the nature of orbital dynamics. Real maneuver data of the Senitnel-3A spacecraft and the Senitnel-6A spacecraft is used to test the capability of the developed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11435v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xuejian Mao, Pei Liu, Pei Chen</dc:creator>
    </item>
    <item>
      <title>Linear-quadratic stochastic nonzero-sum differential games between graphon teams</title>
      <link>https://arxiv.org/abs/2506.11468</link>
      <description>arXiv:2506.11468v1 Announce Type: new 
Abstract: We study a class of nonzero-sum stochastic differential games between two teams with agents in each team interacting through graphon aggregates. On the one hand, in each large population group, agents act together to optimize a common social cost function. On the other hand, these two groups compete with each other, forming a Nash game between two graphon teams. We note that the original problem can be equivalently formulated as an infinite-dimensional two-agent Nash game. Applying the dynamic programming approach, we obtain a set of coupled operator-valued Riccati-type equations. By proving the existence of solutions to the equations mentioned above, we obtain a Nash equilibrium for the two teams.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11468v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>De-xuan Xu, Zhun Gou, Nan-jing Huang</dc:creator>
    </item>
    <item>
      <title>A stochastic Galerkin method for optimal Dirichlet boundary control problems with uncertain data</title>
      <link>https://arxiv.org/abs/2506.11479</link>
      <description>arXiv:2506.11479v1 Announce Type: new 
Abstract: The paper deals with a stochastic Galerkin approximation of elliptic Dirichlet boundary control problems with random input data. The expectation of a tracking cost functional with the deterministic constrained control is minimized. Error estimates are derived for the control variable in $L^2(\partial \mathcal D)$-norm and state variable in $L^2(\Omega\times\mathcal D)$-norm. To solve large linear systems, appropriate preconditioners are proposed for both unconstrained and constrained scenarios. To illustrate the validity and efficiency of the proposed approaches, some numerical experiments are performed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11479v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Max Winkler, Hamdullah Y\"ucel</dc:creator>
    </item>
    <item>
      <title>Automatic Generation of Explicit Quadratic Programming Solvers</title>
      <link>https://arxiv.org/abs/2506.11513</link>
      <description>arXiv:2506.11513v1 Announce Type: new 
Abstract: We consider a family of convex quadratic programs in which the coefficients of the linear objective term and the righthand side of the constraints are affine functions of a parameter. It is well known that the solution of such a parametrized quadratic program is a piecewise affine function of the parameter. The number of (polyhedral) regions in the solution map can grow exponentially in problem size, but when the number of regions is moderate, a so-called explicit solver is practical. Such a solver computes the coefficients of the affine functions and the linear inequalities defining the polyhedral regions offline; to solve a problem instance online it simply evaluates this explicit solution map. Potential advantages of an explicit solver over a more general purpose iterative solver can include transparency, interpretability, reliability, and speed. In this paper we describe how code generation can be used to automatically generate an explicit solver from a high level description of a parametrized quadratic program. Our method has been implemented in the open-source software CVXPYgen, which is part of CVXPY, a domain specific language for general convex optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11513v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maximilian Schaller, Daniel Arnstr\"om, Alberto Bemporad, Stephen Boyd</dc:creator>
    </item>
    <item>
      <title>An infinite horizon sufficient stochastic maximum principle for regime switching diffusions and applications</title>
      <link>https://arxiv.org/abs/2506.11523</link>
      <description>arXiv:2506.11523v1 Announce Type: new 
Abstract: This paper is concerned with a discounted stochastic optimal control problem for regime switching diffusion in an infinite horizon. First, as a preliminary with particular interests in its own right, the global well-posedness of infinite horizon forward and backward stochastic differential equations with Markov chains and the asymptotic property of their solutions when time goes to infinity are obtained. Then, a sufficient stochastic maximum principle for optimal controls is established via a dual method under certain convexity condition of the Hamiltonian. As an application of our maximum principle, a linear quadratic production planning problem is solved with an explicit feedback optimal production rate. The existence and uniqueness of a non-negative solution to the associated algebraic Riccati equation are proved. Numerical experiments are reported to illustrate the theoretical results, especially, the monotonicity of the value function on various model parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11523v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kai Ding, Xun Li, Siyu Lv, Xin Zhang</dc:creator>
    </item>
    <item>
      <title>SuperADMM: Solving Quadratic Programs Faster with Dynamic Weighting ADMM</title>
      <link>https://arxiv.org/abs/2506.11608</link>
      <description>arXiv:2506.11608v1 Announce Type: new 
Abstract: In this paper we develop an accelerated Alternating Direction Method of Multipliers (ADMM) algorithm for solving quadratic programs called superADMM. Unlike standard ADMM QP solvers, superADMM uses a novel dynamic weighting method that penalizes each constraint individually and performs weight updates at every ADMM iteration. We provide a numerical stability analysis, methods for parameter selection and infeasibility detection. The algorithm is implemented in c with efficient linear algebra packages to provide a short execution time and allows calling superADMM from popular languages such as MATLAB and Python. A comparison of superADMM with state-of-the-art ADMM solvers and widely used commercial solvers showcases the efficiency and accuracy of the developed solver.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11608v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>P. C. N. Verheijen, D. Goswami, M. Lazar</dc:creator>
    </item>
    <item>
      <title>High Probability Convergence of Distributed Clipped Stochastic Gradient Descent with Heavy-tailed Noise</title>
      <link>https://arxiv.org/abs/2506.11647</link>
      <description>arXiv:2506.11647v1 Announce Type: new 
Abstract: In this paper, the problem of distributed optimization is studied via a network of agents. Each agent only has access to a noisy gradient of its own objective function, and can communicate with its neighbors via a network. To handle this problem, a distributed clipped stochastic gradient descent algorithm is proposed, and the high probability convergence of the algorithm is studied. Existing works on distributed algorithms involving stochastic gradients only consider the light-tailed noises. Different from them, we study the case with heavy-tailed settings. Under mild assumptions on the graph connectivity, we prove that the algorithm converges in high probability under a certain clipping operator. Finally, a simulation is provided to demonstrate the effectiveness of our theoretical results</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11647v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuchen Yang, Kaihong Lu, Long Wang</dc:creator>
    </item>
    <item>
      <title>Heavy-ball dynamics with Hessian-driven damping for non-convex optimization under the {\L}ojasiewicz condition</title>
      <link>https://arxiv.org/abs/2506.11705</link>
      <description>arXiv:2506.11705v1 Announce Type: new 
Abstract: In this paper, we examine the convergence properties of heavy-ball dynamics with Hessian-driven damping in smooth non-convex optimization problems satisfying a {\L}ojasiewicz condition. In this general setting, we provide a series of tight, worst-case optimal convergence rate guarantees as a function of the dynamics' friction coefficients and the {\L}ojasiewicz exponent of the problem's objective function. Importantly, the linear rates that we obtain improve on previous available rates and they suggest a different tuning of the dynamics' damping terms, even in the strongly convex regime. We complement our analysis with a range of stability estimates in the presence of perturbation errors and inexact gradient input, as well as an avoidance result showing that the dynamics under study avoid strict saddle points from almost every initial condition,</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11705v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vassilis Apidopoulos, Vasiliki Mavrogeorgou, Theodoros G. Tsironis</dc:creator>
    </item>
    <item>
      <title>Quantum Learning and Estimation for Distribution Networks and Energy Communities Coordination</title>
      <link>https://arxiv.org/abs/2506.11730</link>
      <description>arXiv:2506.11730v1 Announce Type: new 
Abstract: Price signals from distribution networks (DNs) guide energy communities (ECs) to adjust energy usage, enabling effective coordination for reliable power system operation. However, this coordination faces significant challenges due to the limited availability of information (i.e., only the aggregated energy usage of ECs is available to DNs), and the high computational burden of accounting for uncertainties and the associated risks through numerous scenarios. To address these challenges, we propose a quantum learning and estimation approach to enhance coordination between DNs and ECs. Specifically, leveraging advanced quantum properties such as quantum superposition and entanglement, we develop a hybrid quantum temporal convolutional network-long short-term memory (Q-TCN-LSTM) model to establish an end-to-end mapping between ECs' responses and the price incentives from DNs. Moreover, we develop a quantum estimation method based on quantum amplitude estimation (QAE) and two phase-rotation circuits to significantly accelerate the optimization process under numerous uncertainty scenarios. Numerical experiments demonstrate that, compared to classical neural networks, the proposed Q-TCN-LSTM model improves the mapping accuracy by 69.2% while reducing the model size by 99.75% and the computation time by 93.9%. Compared to classical Monte Carlo simulation, QAE achieves comparable accuracy with a dramatic reduction in computational time (up to 99.99%) and requires significantly fewer computational resources.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11730v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yingrui Zhuang, Lin Cheng, Yuji Cao, Tongxin Li, Ning Qi, Yan Xu, Yue Chen</dc:creator>
    </item>
    <item>
      <title>State constrained stochastic optimal control of a PV system with battery storage via Fokker-Planck and Hamilton-Jacobi-Bellman equations</title>
      <link>https://arxiv.org/abs/2506.11765</link>
      <description>arXiv:2506.11765v1 Announce Type: new 
Abstract: With the growing global emphasis on sustainability and the implementation of contemporary environmental policies, the penetration of renewable energy sources has significantly increased --primarily due to their inexhaustible nature. In this context, integrating photovoltaic (PV) modules with energy storage systems offers a means to mitigate the inherent variability of solar energy. This paper proposes an optimal methodology for power management and market bidding strategies tailored to PV power producers. To achieve this, the PV system, electricity price dynamics, and battery storage behavior are modeled using a system of stochastic differential equations (SDEs), resulting in a stochastic optimal control problem with state constraints. The corresponding optimality conditions are derived from the Hamilton-Jacobi-Bellman (HJB) and Fokker-Planck (FP) equations. Additionally, a simplified formulation of the control problem is introduced, which substantially reduces computational complexity by decreasing the dimension of the problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11765v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alfredo Berm\'udez, Iago Pad\'in</dc:creator>
    </item>
    <item>
      <title>Near optimal controls for partially observed stochastic linear quadratic problems</title>
      <link>https://arxiv.org/abs/2506.11778</link>
      <description>arXiv:2506.11778v1 Announce Type: new 
Abstract: In this article, we consider a stochastic linear quadratic control problem with partial observation. A near optimal control in the weak formulation is characterized. The main features of this paper are the presence of the control in the diffusion term of the state equation, the circular dependence between the control process and the filtration generated by the observation, and the observation process contains an unbounded drift term. We address these difficulties by first restricting the control to a smaller domain, which enables us to apply the Girsanov theorem using a conditional argument and thereby break the circular dependence. Subsequently, we study the restricted problem using a non-standard variation method. The desired near optimal control is then obtained by taking the limit of an approximating sequence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11778v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jingrui Sun, Jiaqiang Wen, Jie Xiong, Wen Xu</dc:creator>
    </item>
    <item>
      <title>Lyapunov analysis for FISTA under strong convexity</title>
      <link>https://arxiv.org/abs/2506.11785</link>
      <description>arXiv:2506.11785v1 Announce Type: new 
Abstract: In this paper, we conduct a theoretical and numerical study of the Fast Iterative Shrinkage-Thresholding Algorithm (FISTA) under strong convexity assumptions. We propose an autonomous Lyapunov function that reflects the strong convexity of the objective function, whether it arises from the smooth or non-smooth component. This Lyapunov function decreases monotonically at a linear rate along the iterations of the algorithm for a fixed inertial parameter. Our analysis demonstrates that the best theoretical convergence guarantees for FISTA in this context are obtained when the full strong convexity is treated as if it belongs to the smooth part of the objective. Within this framework, we compare the performance of forward-backward splitting (FBS) and several FISTA variants, and find that this strategy leads FISTA to outperform all other configurations, including FBS. Moreover, we identify parameter regimes in which FBS yields better performance than FISTA when the strong convexity of the non-smooth part is not leveraged appropriately.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11785v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luis M. Brice\~no-Arias</dc:creator>
    </item>
    <item>
      <title>Convergence of Momentum-Based Optimization Algorithms with Time-Varying Parameters</title>
      <link>https://arxiv.org/abs/2506.11904</link>
      <description>arXiv:2506.11904v1 Announce Type: new 
Abstract: In this paper, we present a unified algorithm for stochastic optimization that makes use of a "momentum" term; in other words, the stochastic gradient depends not only on the current true gradient of the objective function, but also on the true gradient at the previous iteration. Our formulation includes the Stochastic Heavy Ball (SHB) and the Stochastic Nesterov Accelerated Gradient (SNAG) algorithms as special cases. In addition, in our formulation, the momentum term is allowed to vary as a function of time (i.e., the iteration counter). The assumptions on the stochastic gradient are the most general in the literature, in that it can be biased, and have a conditional variance that grows in an unbounded fashion as a function of time. This last feature is crucial in order to make the theory applicable to "zero-order" methods, where the gradient is estimated using just two function evaluations.
  We present a set of sufficient conditions for the convergence of the unified algorithm. These conditions are natural generalizations of the familiar Robbins-Monro and Kiefer-Wolfowitz-Blum conditions for standard stochastic gradient descent. We also analyze another method from the literature for the SHB algorithm with a time-varying momentum parameter, and show that it is impracticable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11904v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mathukumalli Vidyasagar</dc:creator>
    </item>
    <item>
      <title>A DC-Reformulation for Gradient-$L^0$-Constrained Problems in Function Spaces</title>
      <link>https://arxiv.org/abs/2506.11917</link>
      <description>arXiv:2506.11917v1 Announce Type: new 
Abstract: Cardinality constraints in optimization are commonly of $L^0$-type, and they lead to sparsely supported optimizers. An efficient way of dealing with these constraints algorithmically, when the objective functional is convex, is reformulating the constraint using the difference of suitable $L^1$- and largest-$K$-norms and subsequently solving a sequence of penalized subproblems in the difference-of-convex (DC) class. We extend this DC-reformulation approach to problems with $L^0$-type cardinality constraints on the support of the gradients, \ie, problems where sparsity of the gradient and thus piecewise constant functions are the target.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11917v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Bastian Dittrich, Evelyn Herberg, Roland Herzog, Georg M\"uller</dc:creator>
    </item>
    <item>
      <title>Worst-Case Complexity of High-Order Algorithms for Pareto-Front Reconstruction</title>
      <link>https://arxiv.org/abs/2506.11929</link>
      <description>arXiv:2506.11929v1 Announce Type: new 
Abstract: In this paper, we are concerned with a worst-case complexity analysis of a-posteriori algorithms for unconstrained multiobjective optimization. Specifically, we propose an algorithmic framework that generates sets of points by means of $p$th-order models regularized with a power $p+1$ of the norm of the step. Through a tailored search procedure, several trial points are generated at each iteration and they can be added to the current set if a decrease is obtained for at least one objective function. Building upon this idea, we devise two algorithmic versions: at every iteration, the first tries to update all points in the current set, while the second tries to update only one point. Under Lipschitz continuity of the derivatives of the objective functions, we derive worst-case complexity bounds for both versions. For the first one, we show that at most $\mathcal O(\epsilon^{m(p+1)/p})$ iterations are needed to generate a set where all points are $\epsilon$-approximate Pareto-stationary, with $m$ being the number of objective functions, requiring at most $\mathcal O(|X(\epsilon)|\epsilon^{m(p+1)/p})$ function evaluations, where $X(\epsilon)$ is the largest set of points computed by the algorithm. Additionally, at most $\mathcal O(\epsilon^{(p+1)/p})$ iterations are needed to generate at least one $\epsilon$-approximate Pareto-stationary point, requiring at most $\mathcal O(|X(\epsilon)|\epsilon^{(p+1)/p})$ function evaluations. For the second version, we get $\mathcal O(\epsilon^{m(p+1)/p})$ worst-case complexity bounds on the number of iterations and function evaluations for generating at least one $\epsilon$-approximate Pareto-stationary point. Our results align with those for single objective optimization and generalize those obtained for methods that produce a single Pareto-stationary point.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11929v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrea Cristofari, Marianna De Santis, Stefano Lucidi, Giampaolo Liuzzi</dc:creator>
    </item>
    <item>
      <title>Nash equilibria in semidefinite games and Lemke-Howson paths</title>
      <link>https://arxiv.org/abs/2506.11940</link>
      <description>arXiv:2506.11940v1 Announce Type: new 
Abstract: We consider an algorithmic framework for two-player non-zero-sum semidefinite games, where each player's strategy is a positive semidefinite matrix with trace one. We formulate the computation of Nash equilibria in such games as semidefinite complementarity problems and develop symbolic-numeric techniques to trace generalized Lemke-Howson paths. These paths generalize the piecewise affine-linear trajectories of the classical Lemke-Howson algorithm for bimatrix games, replacing them with nonlinear curve branches governed by eigenvalue complementarity conditions.
  A key feature of our framework is the introduction of event points, which correspond to curve singularities. We analyze the local behavior near these points using Puiseux series expansions. We prove the smoothness of the curve branches under suitable non-degeneracy conditions and establish connections between our approach and both the classical combinatorial and homotopy-theoretic interpretations of the Lemke-Howson algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11940v1</guid>
      <category>math.OC</category>
      <category>cs.GT</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Constantin Ickstadt, Thorsten Theobald, Elias Tsigaridas, Antonios Varvitsiotis</dc:creator>
    </item>
    <item>
      <title>Full Convergence of Regularized Methods for Unconstrained Optimization</title>
      <link>https://arxiv.org/abs/2506.11971</link>
      <description>arXiv:2506.11971v1 Announce Type: new 
Abstract: Typically, the sequence of points generated by an optimization algorithm may have multiple limit points. Under convexity assumptions, however, (sub)gradient methods are known to generate a convergent sequence of points. In this paper, we extend the latter property to a broader class of algorithms. Specifically, we study unconstrained optimization methods that use local quadratic models regularized by a power $r \ge 3$ of the norm of the step. In particular, we focus on the case where only the objective function and its gradient are evaluated. Our analysis shows that, by a careful choice of the regularized model at every iteration, the whole sequence of points generated by this class of algorithms converges if the objective function is pseudoconvex. The result is achieved by employing appropriate matrices to ensure that the sequence of points is variable metric quasi-Fej\'er monotone.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11971v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrea Cristofari</dc:creator>
    </item>
    <item>
      <title>Dictionary Learning Based Regularization in Quantitative MRI: A Nested Alternating Optimization Framework</title>
      <link>https://arxiv.org/abs/2506.11977</link>
      <description>arXiv:2506.11977v1 Announce Type: new 
Abstract: In this article, we propose a novel regularization method for a class of nonlinear inverse problems that is inspired by an application in quantitative magnetic resonance imaging (qMRI). The latter is a special instance of a general dynamical image reconstruction technique, wherein a radio-frequency pulse sequence gives rise to a time-discrete physics-based mathematical model which acts as a side constraint in our inverse problem. To enhance reconstruction quality, we employ dictionary learning as a data-adaptive regularizer, capturing complex tissue structures beyond handcrafted priors. For computing a solution of the resulting non-convex and non-smooth optimization problem, we alternate between updating the physical parameters of interest via a Levenberg-Marquardt approach and performing several iterations of a dictionary learning algorithm. This process falls under the category of nested alternating optimization schemes. We develop a general overall algorithmic framework whose convergence theory is not directly available in the literature. Global sub-linear and local strong linear convergence in infinite dimensions under certain regularity conditions for the sub-differentials are investigated based on the Kurdyka-Lojasiewicz inequality. Eventually, numerical experiments demonstrate the practical potential and unresolved challenges of the method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11977v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Guozhi Dong, Michael Hinterm\"uller, Clemens Sirotenko</dc:creator>
    </item>
    <item>
      <title>Decentralized Uplink Adaptive Compression for Cell-Free MIMO with Limited Fronthaul</title>
      <link>https://arxiv.org/abs/2506.11284</link>
      <description>arXiv:2506.11284v1 Announce Type: cross 
Abstract: We study the problem of uplink compression for cell-free multi-input multi-output networks with limited fronthaul capacity. In compress-forward mode, remote radio heads (RRHs) compress the received signal and forward it to a central unit for joint processing. While previous work has focused on a transform-based approach, which optimizes the transform matrix that reduces signals of high dimension to a static pre-determined lower dimension, we propose a rate-based approach that simultaneously finds both dimension and compression adaptively. Our approach accommodates for changes to network traffic and fronthaul limits. Using mutual information as the objective, we obtain the theoretical network capacity for adaptive compression and decouple the expression to enable decentralization. Furthermore, using channel statistics and user traffic density, we show different approaches to compute an efficient representation of side information that summarizes global channel state information and is shared with RRHs to assist compression. While keeping the information exchange overhead low, our decentralized implementation of adaptive compression shows competitive overall network performance compared to a centralized approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11284v1</guid>
      <category>cs.IT</category>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>eess.SY</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zehua Li, Jingjie Wei, Raviraj Adve</dc:creator>
    </item>
    <item>
      <title>The Sample Complexity of Parameter-Free Stochastic Convex Optimization</title>
      <link>https://arxiv.org/abs/2506.11336</link>
      <description>arXiv:2506.11336v1 Announce Type: cross 
Abstract: We study the sample complexity of stochastic convex optimization when problem parameters, e.g., the distance to optimality, are unknown. We pursue two strategies. First, we develop a reliable model selection method that avoids overfitting the validation set. This method allows us to generically tune the learning rate of stochastic optimization methods to match the optimal known-parameter sample complexity up to $\log\log$ factors. Second, we develop a regularization-based method that is specialized to the case that only the distance to optimality is unknown. This method provides perfect adaptability to unknown distance to optimality, demonstrating a separation between the sample and computational complexity of parameter-free stochastic convex optimization. Combining these two methods allows us to simultaneously adapt to multiple problem structures.
  Experiments performing few-shot learning on CIFAR-10 by fine-tuning CLIP models and prompt engineering Gemini to count shapes indicate that our reliable model selection method can help mitigate overfitting to small validation sets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11336v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jared Lawrence, Ari Kalinsky, Hannah Bradfield, Yair Carmon, Oliver Hinder</dc:creator>
    </item>
    <item>
      <title>On existence of a variational regularization parameter under Morozov's discrepancy principle</title>
      <link>https://arxiv.org/abs/2506.11397</link>
      <description>arXiv:2506.11397v1 Announce Type: cross 
Abstract: Morozov's discrepancy principle is commonly adopted in Tikhonov regularization for choosing the regularization parameter. Nevertheless, for a general non-linear inverse problem, the discrepancy $\|F(x_{\alpha}^{\delta})-y^{\delta}\|_Y$ does not depend continuously on $\alpha$ and it is questionable whether there exists a regularization parameter $\alpha$ such that $\tau_1\delta\leq \|F(x_{\alpha}^{\delta})-y^{\delta}\|_Y\leq \tau_2 \delta$ $(1\le \tau_1&lt;\tau_2)$. In this paper, we prove the existence of $\alpha$ under Morozov's discrepancy principle if $\tau_2\ge (3+2\gamma)\tau_1$, where $\gamma&gt;0$ is a parameter in a tangential cone condition for the nonlinear operator $F$. Furthermore, we present results on the convergence of the regularized solutions under Morozov's discrepancy principle. Numerical results are reported on the efficiency of the proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11397v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Liang Ding, Long Li, Weimin Han, Wei Wang</dc:creator>
    </item>
    <item>
      <title>Vectorized Sparse Second-Order Forward Automatic Differentiation for Optimal Control Direct Methods</title>
      <link>https://arxiv.org/abs/2506.11537</link>
      <description>arXiv:2506.11537v1 Announce Type: cross 
Abstract: Direct collocation methods are widely used numerical techniques for solving optimal control problems. The discretization of continuous-time optimal control problems transforms them into large-scale nonlinear programming problems, which require efficient computation of first- and second-order derivatives. To achieve computational efficiency, these derivatives must be computed in sparse and vectorized form, exploiting the problem's inherent sparsity structure. This paper presents a vectorized sparse second-order forward automatic differentiation framework designed for direct collocation methods in optimal control. The method exploits the problem's sparse structure to efficiently compute derivatives across multiple mesh points. By incorporating both scalar and vector nodes within the expression graph, the approach enables effective parallelization and optimized memory access patterns while maintaining flexibility for complex problems. The methodology is demonstrated through application to a prototype optimal control problem. A complete implementation for multi-phase optimal control problems is available as an open-source package, supporting both theoretical research and practical applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11537v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yilin Zou, Fanghua Jiang</dc:creator>
    </item>
    <item>
      <title>Data-driven approaches to inverse problems</title>
      <link>https://arxiv.org/abs/2506.11732</link>
      <description>arXiv:2506.11732v1 Announce Type: cross 
Abstract: Inverse problems are concerned with the reconstruction of unknown physical quantities using indirect measurements and are fundamental across diverse fields such as medical imaging, remote sensing, and material sciences. These problems serve as critical tools for visualizing internal structures beyond what is visible to the naked eye, enabling quantification, diagnosis, prediction, and discovery. However, most inverse problems are ill-posed, necessitating robust mathematical treatment to yield meaningful solutions. While classical approaches provide mathematically rigorous and computationally stable solutions, they are constrained by the ability to accurately model solution properties and implement them efficiently.
  A more recent paradigm considers deriving solutions to inverse problems in a data-driven manner. Instead of relying on classical mathematical modeling, this approach utilizes highly over-parameterized models, typically deep neural networks, which are adapted to specific inverse problems using carefully selected training data. Current approaches that follow this new paradigm distinguish themselves through solution accuracy paired with computational efficiency that was previously inconceivable.
  These notes offer an introduction to this data-driven paradigm for inverse problems. The first part of these notes will provide an introduction to inverse problems, discuss classical solution strategies, and present some applications. The second part will delve into modern data-driven approaches, with a particular focus on adversarial regularization and provably convergent linear plug-and-play denoisers. Throughout the presentation of these methodologies, their theoretical properties will be discussed, and numerical examples will be provided. The lecture series will conclude with a discussion of open problems and future perspectives in the field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11732v1</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Carola-Bibiane Sch\"onlieb, Zakhar Shumaylov</dc:creator>
    </item>
    <item>
      <title>Random Batch Methods for Discretized PDEs on Graphs</title>
      <link>https://arxiv.org/abs/2506.11809</link>
      <description>arXiv:2506.11809v1 Announce Type: cross 
Abstract: Gas transport and other complex real-world challenges often require solving and controlling partial differential equations (PDEs) defined on graph structures, which typically demand substantial memory and computational resources. The Random Batch Method (RBM) offers significant relief from these demands by enabling the simulation of large-scale systems with reduced computational cost.
  In this paper, we analyze the application of RBM for solving PDEs on one-dimensional graphs, specifically concentrating on the heat equation. Our approach involves a two-step process: initially discretizing the PDE to transform it into a finite-dimensional problem, followed by the application of the RBM. We refer to this integrated approach as discretize+RBM. We establish the convergence of this method in expectation, under the appropriate selection and simultaneous reduction of the switching parameter in RBM and the discretization parameters. Moreover, we extend these findings to include the optimal control of the heat equation on graphs, enhancing the practical utility of our methodology. The efficacy and computational efficiency of our proposed solution are corroborated through numerical experiments that not only demonstrate convergence but also show significant reductions in computational costs.
  Our algorithm can be viewed as a randomized variant of domain decomposition, specifically adapted for PDEs defined on graph structures. It is sufficiently versatile to be applied to a wide range of linear PDEs -- not just the heat equation -- while maintaining comparable analytical guarantees and convergence properties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11809v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mart\'in Hern\'andez, Enrique Zuazua</dc:creator>
    </item>
    <item>
      <title>A "trembling hand perfect" equilibrium for a certain class of mean field games</title>
      <link>https://arxiv.org/abs/2506.11868</link>
      <description>arXiv:2506.11868v1 Announce Type: cross 
Abstract: We study a particular class of mean field games whose solutions can be formally connected to a scalar transport equation on the Wasserstein space of measures. For this class, we construct some interesting explicit examples of non-uniqueness of Nash equilibria. We then address the selection problem of finding rational criteria by which to choose one equilibrium over others. We show that when the theory of entropy solutions is used, we can obtain explicit error estimates for the ``vanishing noise limit,'' where the error is measured in a certain norm that measures the distance between two functions over the set of empirical measures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11868v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>P. Jameson Graber</dc:creator>
    </item>
    <item>
      <title>On the Relation Between LP Sharpness and Limiting Error Ratio and Complexity Implications for Restarted PDHG</title>
      <link>https://arxiv.org/abs/2312.13773</link>
      <description>arXiv:2312.13773v3 Announce Type: replace 
Abstract: There has been a recent surge in development of first-order methods (FOMs) for solving huge-scale linear programming (LP) problems. The attractiveness of FOMs for LP stems in part from the fact that they avoid costly matrix factorization computation. However, the efficiency of FOMs is significantly influenced - both in theory and in practice - by certain instance-specific LP condition measures. Xiong and Freund recently showed that the performance of the restarted primal-dual hybrid gradient method (PDHG) is predominantly determined by two specific condition measures: LP sharpness and Limiting Error Ratio. In this paper we examine the relationship between these two measures, particularly in the case when the optimal solution is unique (which is generic - at least in theory), and we present an upper bound on the Limiting Error Ratio involving the reciprocal of the LP sharpness. This shows that in LP instances where there is a dual nondegenerate optimal solution, the computational complexity of restarted PDHG can be characterized solely in terms of LP sharpness and the distance to optimal solutions, and simplifies the theoretical complexity upper bound of restarted PDHG for these instances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.13773v3</guid>
      <category>math.OC</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zikai Xiong, Robert M. Freund</dc:creator>
    </item>
    <item>
      <title>Computational Guarantees for Restarted PDHG for LP based on "Limiting Error Ratios" and LP Sharpness</title>
      <link>https://arxiv.org/abs/2312.14774</link>
      <description>arXiv:2312.14774v4 Announce Type: replace 
Abstract: In recent years, there has been growing interest in solving linear optimization problems - or more simply "LP" - using first-order methods in order to avoid the costly matrix factorizations of traditional methods for huge-scale LP instances. The restarted primal-dual hybrid gradient method (PDHG) - together with some heuristic techniques - has emerged as a powerful tool for solving huge-scale LPs. However, the theoretical understanding of the restarted PDHG and the validation of various heuristic implementation techniques are still very limited. Existing complexity analyses have relied on the Hoffman constant of the LP KKT system, which is known to be overly conservative, difficult to compute, and fails to offer insight into instance-specific characteristics of the LP problems. These limitations have limited the capability to discern which characteristics of LP instances lead to easy versus difficult instances. With the goal of overcoming these limitations, we introduce and develop two purely geometry-based condition measures for LP instances: "limiting error ratio" and LP sharpness. We provide new computational guarantees for the restarted PDHG based on these two condition measures. For limiting error ratio, we provide a computable upper bound and show its relationship with the data instance's proximity to infeasibility under perturbation. For LP sharpness, we prove its equivalence to the stability of the LP optimal solution set under perturbation of the objective function. Our computational guarantees are validated by constructed instances. Conversely, our computational guarantees validate the practical efficacy of certain heuristic techniques (row preconditioners and step-size tuning) that improve computational performance. Finally, we present computational experiments on LP relaxations from the MIPLIB dataset that demonstrate the promise of various implementation strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.14774v4</guid>
      <category>math.OC</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zikai Xiong, Robert Michael Freund</dc:creator>
    </item>
    <item>
      <title>Parameter estimation in ODEs: assessing the potential of local and global solvers</title>
      <link>https://arxiv.org/abs/2405.01989</link>
      <description>arXiv:2405.01989v2 Announce Type: replace 
Abstract: We consider the problem of parameter estimation in dynamic systems described by ordinary differential equations. A review of the existing literature emphasizes the need for deterministic global optimization methods due to the nonconvex nature of these problems. Recent works have focused on expanding the capabilities of specialized deterministic global optimization algorithms to handle more complex problems. Despite advancements, current deterministic methods are limited to problems with a maximum of around five state and five decision variables, prompting ongoing efforts to enhance their applicability to practical problems. Our study seeks to assess the effectiveness of state-of-the-art general-purpose global and local solvers in handling realistic-sized problems efficiently, and evaluating their capabilities to cope with the nonconvex nature of the underlying estimation problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.01989v2</guid>
      <category>math.OC</category>
      <category>q-bio.QM</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s11081-025-09978-9</arxiv:DOI>
      <arxiv:journal_reference>Optimization and Engineering (2025)</arxiv:journal_reference>
      <dc:creator>M. Fern\'andez de Dios, \'Angel M. Gonz\'alez-Rueda, Julio R. Banga, Julio Gonz\'alez-D\'iaz, David R. Penas</dc:creator>
    </item>
    <item>
      <title>A new approach to principal-agent problems with volatility control</title>
      <link>https://arxiv.org/abs/2407.09471</link>
      <description>arXiv:2407.09471v2 Announce Type: replace 
Abstract: The recent work by Cvitani\'c, Possama\"i, and Touzi (2018) [9] presents a general approach for continuous-time principal-agent problems, through dynamic programming and second-order backward stochastic differential equations (BSDEs). In this paper, we provide an alternative formulation of the principal-agent problem, which can be solved simply by relying on the theory of BSDEs. This reformulation is strongly inspired by an important remark in [9], namely that if the principal observes the output process in continuous-time, she can compute its quadratic variation pathwise. While in [9], this information is used in the contract, our reformulation consists in assuming that the principal could directly control this process, in a `first-best' fashion. The resolution approach for this alternative problem actually follows the line of the so-called `Sannikov's trick' in the literature on continuous-time principal-agent problems, as originally introduced by Sannikov (2008) [28]. We then show that the solution to this `first-best' formulation is identical to the solution of the original problem. More precisely, using the contract form introduced in [9] as `penalisation contracts', we highlight that this `first-best' scenario can be achieved even if the principal cannot directly control the quadratic variation. Nevertheless, we do not have to rely on the theory of 2BSDEs to prove that such contracts are optimal, as their optimality is ensured by showing that the `first-best' scenario is achieved. We believe that this more straightforward approach to solve continuous-time principal-agent problems with volatility control will facilitate the dissemination of these problems across many fields, and its extension to even more intricate problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09471v2</guid>
      <category>math.OC</category>
      <category>econ.GN</category>
      <category>math.PR</category>
      <category>q-fin.EC</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alessandro Chiusolo, Emma Hubert</dc:creator>
    </item>
    <item>
      <title>Learning Firmly Nonexpansive Operators</title>
      <link>https://arxiv.org/abs/2407.14156</link>
      <description>arXiv:2407.14156v2 Announce Type: replace 
Abstract: This paper proposes a data-driven approach for constructing firmly nonexpansive operators. We demonstrate its applicability in Plug-and-Play (PnP) methods, where classical algorithms such as Forward-Backward splitting, Chambolle-Pock primal-dual iteration, Douglas-Rachford iteration or alternating directions method of multipliers (ADMM), are modified by replacing one proximal map by a learned firmly nonexpansive operator. We provide sound mathematical background to the problem of learning such an operator via expected and empirical risk minimization. We prove that, as the number of training points increases, the empirical risk minimization problem converges (in the sense of Gamma-convergence) to the expected risk minimization problem. Further, we derive a solution strategy that ensures firmly nonexpansive and piecewise affine operators within the convex envelope of the training set. We show that this operator converges to the best empirical solution as the number of points in the envelope increases in an appropriate way. Finally, the experimental section details practical implementations of the method and presents an application in image denoising, where we consider a novel, interpretable PnP Chambolle-Pock primal-dual iteration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.14156v2</guid>
      <category>math.OC</category>
      <category>math.FA</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kristian Bredies, Jonathan Chirinos-Rodriguez, Emanuele Naldi</dc:creator>
    </item>
    <item>
      <title>MindFlayer SGD: Efficient Parallel SGD in the Presence of Heterogeneous and Random Worker Compute Times</title>
      <link>https://arxiv.org/abs/2410.04285</link>
      <description>arXiv:2410.04285v2 Announce Type: replace 
Abstract: We investigate the problem of minimizing the expectation of smooth nonconvex functions in a distributed setting with multiple parallel workers that are able to compute stochastic gradients. A significant challenge in this context is the presence of arbitrarily heterogeneous and stochastic compute times among workers, which can severely degrade the performance of existing parallel stochastic gradient descent (SGD) methods. While some parallel SGD algorithms achieve optimal performance under deterministic but heterogeneous delays, their effectiveness diminishes when compute times are random - a scenario not explicitly addressed in their design. To bridge this gap, we introduce MindFlayer SGD, a novel parallel SGD method specifically designed to handle stochastic and heterogeneous compute times. Through theoretical analysis and empirical evaluation, we demonstrate that MindFlayer SGD consistently outperforms existing baselines, particularly in environments with heavy-tailed noise. Our results highlight its robustness and scalability, making it a compelling choice for large-scale distributed learning tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04285v2</guid>
      <category>math.OC</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Artavazd Maranjyan, Omar Shaikh Omar, Peter Richt\'arik</dc:creator>
    </item>
    <item>
      <title>Double Traversals in Optimal Picker Routes for Warehouses with Multiple Blocks</title>
      <link>https://arxiv.org/abs/2501.14123</link>
      <description>arXiv:2501.14123v2 Announce Type: replace 
Abstract: Order picking is a process that involves collecting items from their respective locations within a warehouse. There exist dynamic programming algorithms for finding the minimal picker route by considering only a limited number of options for possible travel within a subaisle. Although one such action, traversing an aisle twice, has been shown to never be required for a rectangular warehouse with two cross-aisles, this is not the case when there are more than two cross-aisles. In this work, we demonstrate that double traversals within a subaisle are not required to connect cross-aisle travel regardless of the number of cross-aisles. This result simplifies the structure of feasible tours, enabling more efficient algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14123v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>George Dunn, Hadi Charkhgard, Ali Eshragh, Elizabeth Stojanovski</dc:creator>
    </item>
    <item>
      <title>Near-Optimal Sample Complexity for MDPs via Anchoring</title>
      <link>https://arxiv.org/abs/2502.04477</link>
      <description>arXiv:2502.04477v2 Announce Type: replace 
Abstract: We study a new model-free algorithm to compute $\varepsilon$-optimal policies for average reward Markov decision processes, in the weakly communicating case. Given a generative model, our procedure combines a recursive sampling technique with Halpern's anchored iteration, and computes an $\varepsilon$-optimal policy with sample and time complexity $\widetilde{O}(|\mathcal{S}||\mathcal{A}|\|h^*\|_{\text{sp}}^{2}/\varepsilon^{2})$ both in high probability and in expectation. To our knowledge, this is the best complexity among model-free algorithms, matching the known lower bound up to a factor $\|h^*\|_{\text{sp}}$. Although the complexity bound involves the span seminorm $\|h^*\|_{\text{sp}}$ of the unknown bias vector, the algorithm requires no prior knowledge and implements a stopping rule which guarantees with probability 1 that the procedure terminates in finite time. We also analyze how these techniques can be adapted for discounted MDPs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04477v2</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>International Conference on Machine Learning 2025</arxiv:journal_reference>
      <dc:creator>Jongmin Lee, Mario Bravo, Roberto Cominetti</dc:creator>
    </item>
    <item>
      <title>On Solving Minimization and Min-Max Problems by First-Order Methods with Relative Error in Gradients</title>
      <link>https://arxiv.org/abs/2503.06628</link>
      <description>arXiv:2503.06628v2 Announce Type: replace 
Abstract: First-order methods for minimization and saddle point (min-max) problems are one of the cornerstones of modern ML. The majority of works obtain favorable complexity guarantees of such methods, assuming that exact gradient information is available. At the same time, even the use of floating-point representation of real numbers already leads to relative error in all the computations. Relative errors also arise in such applications as bilevel optimization, inverse problems, derivative-free optimization, and inexact proximal methods. This paper answers several theoretical open questions on first-order optimization methods under relative errors in the first-order oracle. We propose an explicit single-loop accelerated gradient method that preserves optimal linear convergence rate under maximal possible relative error in the gradient, and explore the tradeoff between the relative error and deterioration in the linear convergence rate. We further explore similar questions for saddle point problems and nonlinear equations, showing, for the first time in the literature, that a variant of gradient descent-ascent and the extragradient method are robust to such errors and providing estimates for the maximum level of noise that does not break linear convergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.06628v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Artem Vasin, Valery Krivchenko, Dmitry Kovalev, Fedyor Stonyakin, Nazarii Tupitsa, Pavel Dvurechensky, Mohammad Alkousa, Nikita Kornilov, Alexander Gasnikov</dc:creator>
    </item>
    <item>
      <title>Interior Point Differential Dynamic Programming, Redux</title>
      <link>https://arxiv.org/abs/2504.08278</link>
      <description>arXiv:2504.08278v3 Announce Type: replace 
Abstract: We present IPDDP2, a structure-exploiting algorithm for solving discrete-time, finite-horizon optimal control problems (OCPs) with nonlinear constraints. Inequality constraints are handled using a primal-dual interior point formulation and step acceptance for equality constraints follows a line-search filter approach. The iterates of the algorithm are derived under the Differential Dynamic Programming (DDP) framework. A proof of local quadratic convergence of the IPDDP2 iterates is provided. Our numerical experiments evaluate IPDDP2 on over 500 OCPs derived from five different classes of robotic motion planning problems, three of which are contact-implicit trajectory optimisation problems. IPDDP2 demonstrates improvements in robustness against existing constrained DDP algorithms for contact-implicit planning, while being significantly faster than general-purpose solver IPOPT. We provide a full implementation of IPDDP2 in the Julia programming language.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.08278v3</guid>
      <category>math.OC</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Ming Xu, Stephen Gould, Iman Shames</dc:creator>
    </item>
    <item>
      <title>Policy Gradient Adaptive Control for the LQR: Indirect and Direct Approaches</title>
      <link>https://arxiv.org/abs/2505.03706</link>
      <description>arXiv:2505.03706v2 Announce Type: replace 
Abstract: Motivated by recent advances of reinforcement learning and direct data-driven control, we propose policy gradient adaptive control (PGAC) for the linear quadratic regulator (LQR), which uses online closed-loop data to improve the control policy while maintaining stability. Our method adaptively updates the policy in feedback by descending the gradient of the LQR cost and is categorized as indirect, when gradients are computed via an estimated model, versus direct, when gradients are derived from data using sample covariance parameterization. Beyond the vanilla gradient, we also showcase the merits of the natural gradient and Gauss-Newton methods for the policy update. Notably, natural gradient descent bridges the indirect and direct PGAC, and the Gauss-Newton method of the indirect PGAC leads to an adaptive version of the celebrated Hewer's algorithm. To account for the uncertainty from noise, we propose a regularization method for both indirect and direct PGAC. For all the considered PGAC approaches, we show closed-loop stability and convergence of the policy to the optimal LQR gain. Simulations validate our theoretical findings and demonstrate the robustness and computational efficiency of PGAC.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03706v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Feiran Zhao, Alessandro Chiuso, Florian D\"orfler</dc:creator>
    </item>
    <item>
      <title>Revisiting Stochastic Approximation and Stochastic Gradient Descent</title>
      <link>https://arxiv.org/abs/2505.11343</link>
      <description>arXiv:2505.11343v2 Announce Type: replace 
Abstract: In this paper, we introduce a new approach to proving the convergence of the Stochastic Approximation (SA) and the Stochastic Gradient Descent (SGD) algorithms. The new approach is based on a concept called GSLLN (Generalized Strong Law of Large Numbers), which extends the traditional SLLN. Using this concept, we provide sufficient conditions for convergence, which effectively decouple the properties of the function whose zero we are trying to find, from the properties of the measurement errors (noise sequence). The new approach provides an alternative to the two widely used approaches, namely the ODE approach and the martingale approach, and also permits a wider class of noise signals than either of the two known approaches. In particular, the ``noise'' or measurement error \textit{need not} have a finite second moment, and under suitable conditions, not even a finite mean. By adapting this method of proof, we also derive sufficient conditions for the convergence of zero-order SGD, wherein the stochastic gradient is computed using $2d$ function evaluations, but no gradient computations. The sufficient conditions derived here are the weakest to date, thus leading to a considerable expansion of the applicability of SA and SGD theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.11343v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rajeeva Laxman Karandikar, Bhamidi Visweswara Rao, Mathukumalli Vidyasagar</dc:creator>
    </item>
    <item>
      <title>Dual Hierarchical Least-Squares Programming with Equality Constraints</title>
      <link>https://arxiv.org/abs/2505.21071</link>
      <description>arXiv:2505.21071v2 Announce Type: replace 
Abstract: Hierarchical least-squares programming (HLSP) is an important tool in optimization as it enables the stacking of any number of priority levels in order to reflect complex constraint relationships, for example in physical systems like robots. Existing solvers typically address the primal formulation of HLSP's, which is computationally efficient due to sequential treatment of the priority levels. This way, already identified active constraints can be eliminated after each priority level, leading to smaller problems as the solver progresses through the hierarchy. However, this sequential progression makes the solvers discontinuous and therefore not differentiable. This prevents the incorporation of HLSP's as neural network neurons, or solving HLSP's in a distributed fashion. In this work, an efficient solver based on the dual formulation of HLSP's with equality constraints (D-HLSP-E) is developed. D-HLSP-E is a convex and differentiable quadratically constrained least-squares program (QCLSP), which is solved by an Alternating Direction Method of Multipliers (ADMM). By introducing appropriate operator splitting, primal-dual variables, which link each priority level with all their respective higher priority levels, can be eliminated from the main computation step of computing a matrix factorization. The proposed solver D-HADM is about one magnitude faster than a comparable D-HLSP-E solver based on the interior-point method (D-HIPM), where the primal-dual variables enter the computational complexity in a cubic fashion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21071v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kai Pfeiffer</dc:creator>
    </item>
    <item>
      <title>Kurdyka-\L ojasiewicz exponent via square transformation</title>
      <link>https://arxiv.org/abs/2506.10110</link>
      <description>arXiv:2506.10110v2 Announce Type: replace 
Abstract: We consider one of the most common reparameterization techniques, the square transformation. Assuming the original objective function is the sum of a smooth function and a polyhedral function, we study the variational properties of the objective function after reparameterization. In particular, we first study the minimal norm of the subdifferential of the reparameterized objective function. Second, we compute the second subderivative of the reparameterized objective function on a linear subspace, which allows for fully characterizing the subclass of stationary points of the reparameterized objective function that correspond to stationary points of the original objective function. Finally, utilizing the representation of the minimal norm of the subdifferential, we show that the Kurdyka-\L ojasiewicz (KL) exponent of the reparameterized function can be deduced from that of the original function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10110v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenqing Ouyang</dc:creator>
    </item>
    <item>
      <title>Bregman proximal gradient method for linear optimization under entropic constraints</title>
      <link>https://arxiv.org/abs/2506.10849</link>
      <description>arXiv:2506.10849v2 Announce Type: replace 
Abstract: In this paper, we present an efficient algorithm for solving a linear optimization problem with entropic constraints -- a class of problems that arises in game theory and information theory. Our analysis distinguishes between the cases of active and inactive constraints, addressing each using a Bregman proximal gradient method with entropic Legendre functions, for which we establish an ergodic convergence rate of $O(1/n)$ in objective values. For a specific cost structure, our framework provides a theoretical justification for the well-known Blahut-Arimoto algorithm. In the active constraint setting, we include a bisection procedure to approximate the strictly positive Lagrange multiplier. The efficiency of the proposed method is illustrated through comparisons with standard optimization solvers on a representative example from game theory, including extensions to higher-dimensional settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10849v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luis M. Brice\~no-Arias, Ma\"el Le Treust</dc:creator>
    </item>
    <item>
      <title>Critical Influence of Overparameterization on Sharpness-aware Minimization</title>
      <link>https://arxiv.org/abs/2311.17539</link>
      <description>arXiv:2311.17539v5 Announce Type: replace-cross 
Abstract: Sharpness-Aware Minimization (SAM) has attracted considerable attention for its effectiveness in improving generalization in deep neural network training by explicitly minimizing sharpness in the loss landscape. Its success, however, relies on the assumption that there exists sufficient variability of flatness in the solution space-a condition commonly facilitated by overparameterization. Yet, the interaction between SAM and overparameterization has not been thoroughly investigated, leaving a gap in understanding precisely how overparameterization affects SAM. Thus, in this work, we analyze SAM under varying degrees of overparameterization, presenting both empirical and theoretical findings that reveal its critical influence on SAM's effectiveness. First, we conduct extensive numerical experiments across diverse domains, demonstrating that SAM consistently benefits from overparameterization. Next, we attribute this phenomenon to the interplay between the enlarged solution space and increased implicit bias resulting from overparameterization. Furthermore, we show that this effect is particularly pronounced in practical settings involving label noise and sparsity, and yet, sufficient regularization is necessary. Last but not least, we provide other theoretical insights into how overparameterization helps SAM achieve minima with more uniform Hessian moments compared to SGD, and much faster convergence at a linear rate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.17539v5</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sungbin Shin, Dongyeop Lee, Maksym Andriushchenko, Namhoon Lee</dc:creator>
    </item>
    <item>
      <title>The Sharpness Disparity Principle in Transformers for Accelerating Language Model Pre-Training</title>
      <link>https://arxiv.org/abs/2502.19002</link>
      <description>arXiv:2502.19002v2 Announce Type: replace-cross 
Abstract: Transformers consist of diverse building blocks, such as embedding layers, normalization layers, self-attention mechanisms, and point-wise feedforward networks. Thus, understanding the differences and interactions among these blocks is important. In this paper, we uncover a clear Sharpness Disparity across these blocks, which emerges early in training and intriguingly persists throughout the training process. Motivated by this finding, we propose Blockwise Learning Rate (LR), a strategy that tailors the LR to each block's sharpness, accelerating large language model (LLM) pre-training. By integrating Blockwise LR into AdamW, we consistently achieve lower terminal loss and nearly $2\times$ speedup compared to vanilla AdamW. We demonstrate this acceleration across GPT-2 and LLaMA, with model sizes ranging from 0.12B to 2B and datasets of OpenWebText, MiniPile, and C4. Finally, we incorporate Blockwise LR into Adam-mini (Zhang et al., 2024), a recently proposed memory-efficient variant of Adam, achieving a combined $2\times$ speedup and $2\times$ memory saving. These results underscore the potential of exploiting the sharpness disparity to improve LLM training.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.19002v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jinbo Wang, Mingze Wang, Zhanpeng Zhou, Junchi Yan, Weinan E, Lei Wu</dc:creator>
    </item>
    <item>
      <title>Policy Optimization and Multi-agent Reinforcement Learning for Mean-variance Team Stochastic Games</title>
      <link>https://arxiv.org/abs/2503.22779</link>
      <description>arXiv:2503.22779v2 Announce Type: replace-cross 
Abstract: We study a long-run mean-variance team stochastic game (MV-TSG), where each agent shares a common mean-variance objective for the system and takes actions independently to maximize it. MV-TSG has two main challenges. First, the variance metric is neither additive nor Markovian in a dynamic setting. Second, simultaneous policy updates of all agents lead to a non-stationary environment for each individual agent. Both challenges make dynamic programming inapplicable. In this paper, we study MV-TSGs from the perspective of sensitivity-based optimization. The performance difference and performance derivative formulas for joint policies are derived, which provide optimization information for MV-TSGs. We prove the existence of a deterministic Nash policy for this problem. Subsequently, we propose a Mean-Variance Multi-Agent Policy Iteration (MV-MAPI) algorithm with a sequential update scheme, where individual agent policies are updated one by one in a given order. We prove that the MV-MAPI algorithm converges to a first-order stationary point of the objective function. By analyzing the local geometry of stationary points, we derive specific conditions for stationary points to be (local) Nash equilibria, and further, strict local optima. To solve large-scale MV-TSGs in scenarios with unknown environmental parameters, we extend the idea of trust region methods to MV-MAPI and develop a multi-agent reinforcement learning algorithm named Mean-Variance Multi-Agent Trust Region Policy Optimization (MV-MATRPO). We derive a performance lower bound for each update of joint policies. Finally, numerical experiments on energy management in multiple microgrid systems are conducted.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.22779v2</guid>
      <category>cs.MA</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Junkai Hu, Li Xia</dc:creator>
    </item>
    <item>
      <title>Expressivity of Quadratic Neural ODEs</title>
      <link>https://arxiv.org/abs/2504.09385</link>
      <description>arXiv:2504.09385v2 Announce Type: replace-cross 
Abstract: This work focuses on deriving quantitative approximation error bounds for neural ordinary differential equations having at most quadratic nonlinearities in the dynamics. The simple dynamics of this model form demonstrates how expressivity can be derived primarily from iteratively composing many basic elementary operations, versus from the complexity of those elementary operations themselves. Like the analog differential analyzer and universal polynomial DAEs, the expressivity is derived instead primarily from the "depth" of the model. These results contribute to our understanding of what depth specifically imparts to the capabilities of deep learning architectures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.09385v2</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Joshua Hanson, Maxim Raginsky</dc:creator>
    </item>
  </channel>
</rss>
