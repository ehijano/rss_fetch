<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.CO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.CO</link>
    <description>stat.CO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.CO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 05 Mar 2025 03:02:40 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Wild posteriors in the wild</title>
      <link>https://arxiv.org/abs/2503.00239</link>
      <description>arXiv:2503.00239v1 Announce Type: new 
Abstract: Bayesian posterior approximation has become more accessible to practitioners than ever, thanks to modern black-box software. While these tools provide highly accurate approximations with minimal user effort, certain posterior geometries remain notoriously difficult for standard methods. As a result, research into alternative approximation techniques continues to flourish. In many papers, authors validate their new approaches by testing them on posterior shapes deemed challenging or "wild." However, these shapes are not always directly linked to real-world applications where they naturally occur. In this note, we present examples of practical applications that give rise to some commonly used benchmark posterior shapes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00239v1</guid>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yunyi Shen, Tamara Broderick</dc:creator>
    </item>
    <item>
      <title>Efficient Long-Term Structural Reliability Estimation with Non-Gaussian Stochastic Models: A Design of Experiments Approach</title>
      <link>https://arxiv.org/abs/2503.01566</link>
      <description>arXiv:2503.01566v1 Announce Type: new 
Abstract: Extreme response assessment is important in the design and operation of engineering structures, and is a crucial part of structural risk and reliability analyses. Structures should be designed in a way that enables them to withstand the environmental loads they are expected to experience over their lifetime, without designs being unnecessarily conservative and costly. An accurate risk estimate is essential but difficult to obtain because the long-term behaviour of a structure is typically too complex to calculate analytically or with brute force Monte Carlo simulation. Therefore, approximation methods are required to estimate the extreme response using only a limited number of short-term conditional response calculations. Combining surrogate models with Design of Experiments is an approximation approach that has gained popularity due to its ability to account for both long-term environment variability and short-term response variability. In this paper, we propose a method for estimating the extreme response of black-box, stochastic models with heteroscedastic non-Gaussian noise. We present a mathematically founded extreme response estimation process that enables Design of Experiment approaches that are prohibitively expensive with surrogate Monte Carlo. The theory leads us to speculate this method can robustly produce more confident extreme response estimates, and is suitable for a variety of domains. While this needs to be further validated empirically, the method offers a promising tool for reducing the uncertainty decision-makers face, allowing them to make better informed choices and create more optimal structures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01566v1</guid>
      <category>stat.CO</category>
      <category>stat.AP</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sebastian Winter, Christian Agrell, Juan Camilo Guevara G\'omez, Erik Vanem</dc:creator>
    </item>
    <item>
      <title>Metropolis Adjusted Microcanonical Hamiltonian Monte Carlo</title>
      <link>https://arxiv.org/abs/2503.01707</link>
      <description>arXiv:2503.01707v1 Announce Type: new 
Abstract: For unbiased sampling of distributions with a differentiable density, Hamiltonian Monte Carlo (HMC) and in particular the No-U-Turn Sampler (NUTS) are widely used, especially in the context of Bayesian inference. We propose an alternative sampler to NUTS, the Metropolis-Adjusted Microcanonical sampler (MAMS). The success of MAMS relies on two key innovations. The first is the use of microcanonical dynamics. This has been used in previous Bayesian sampling and molecular dynamics applications without Metropolis adjustment, leading to an asymptotically biased algorithm. Building on this work, we show how to calculate the Metropolis-Hastings ratio and prove that extensions with Langevin noise proposed in the context of HMC straightforwardly transfer to this dynamics. The second is a tuning scheme for step size and trajectory length. We demonstrate that MAMS outperforms NUTS on a variety of benchmark problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01707v1</guid>
      <category>stat.CO</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jakob Robnik, Reuben Cohn-Gordon, Uro\v{s} Seljak</dc:creator>
    </item>
    <item>
      <title>Failure of Optimal Design Theory? A Case Study in Toxicology Using Sequential Robust Optimal Design Framework</title>
      <link>https://arxiv.org/abs/2503.00002</link>
      <description>arXiv:2503.00002v1 Announce Type: cross 
Abstract: This paper presents a quasi-sequential optimal design framework for toxicology experiments, specifically applied to sea urchin embryos. The authors propose a novel approach combining robust optimal design with adaptive, stage-based testing to improve efficiency in toxicological studies, particularly where traditional uniform designs fall short. The methodology uses statistical models to refine dose levels across experimental phases, aiming for increased precision while reducing costs and complexity. Key components include selecting an initial design, iterative dose optimization based on preliminary results, and assessing various model fits to ensure robust, data-driven adjustments. Through case studies, we demonstrate improved statistical efficiency and adaptability in toxicology, with potential applications in other experimental domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00002v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Elvis Han Cui, Michael Collins, Jessica Munson, Weng Kee Wong</dc:creator>
    </item>
    <item>
      <title>A Framework to Analyze Multiscale Sampling MCMC Methods</title>
      <link>https://arxiv.org/abs/2503.00251</link>
      <description>arXiv:2503.00251v1 Announce Type: cross 
Abstract: We consider the theoretical analysis of Multiscale Sampling Methods, which are a new class of gradient-free Markov chain Monte Carlo (MCMC) methods for high dimensional inverse differential equation problems. A detailed presentation of those methods is given, including a review of each MCMC technique that they employ. Then, we propose a two-part framework to study and compare those methods. The first part identifies the new corresponding state space for the chain of random fields, and the second assesses convergence conditions on the instrumental and target distributions. Three Multiscale Sampling Methods are then analyzed using this new framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00251v1</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Lucas Seiffert, Felipe Pereira</dc:creator>
    </item>
    <item>
      <title>Bayesian Inference for Non-Synchronously Observed Diffusions</title>
      <link>https://arxiv.org/abs/2503.00465</link>
      <description>arXiv:2503.00465v1 Announce Type: cross 
Abstract: We consider the problem of Bayesian inference for bi-variate data observed in time but with observation times which occur non-synchronously. In particular, this occurs in a wide variety of applications in finance, such as high-frequency trading or crude oil futures trading. We adopt a diffusion model for the data and formulate a Bayesian model with priors on unknown parameters along with a latent representation for the the so-called missing data. We then consider computational methodology to fit the model using Markov chain Monte Carlo (MCMC). We have to resort to time-discretization methods as the complete data likelihood is intractable and this can cause considerable issues for MCMC when the data are observed in low frequencies. In a high frequency observation frequencies we present a simple particle MCMC method based on an Euler--Maruyama time discretization, which can be enhanced using multilevel Monte Carlo (MLMC). In the low frequency observation regime we introduce a novel bridging representation of the posterior in continuous time to deal with the issues of MCMC in this case. This representation is discretized and fitted using MCMC and MLMC. We apply our methodology to real and simulated data to establish the efficacy of our methodology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00465v1</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ajay Jasra, Kengo Kamatani, Amin Wu</dc:creator>
    </item>
    <item>
      <title>Geometric Ergodicity of a Gibbs Algorithm for a Normal Model With a Horseshoe Prior</title>
      <link>https://arxiv.org/abs/2503.00538</link>
      <description>arXiv:2503.00538v1 Announce Type: cross 
Abstract: In this paper, we consider a two-stage Gibbs sampler for a normal linear regression model with a horseshoe prior. Under some assumptions, we show that it produces a geometrically ergodic Markov chain. In particular, we prove geometric ergodicity under some three-parameter beta global prior which does not have a finite $(p / 5)$-th negative moment, where $p$ is the number of regression coefficients. This is in contrast to the case of a known general result which is applicable if the global parameter has a finite approximately $(p / 2)$-th negative moment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00538v1</guid>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.TH</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yasuyuki Hamura</dc:creator>
    </item>
    <item>
      <title>Evaluation of adaptive sampling methods in scenario generation for virtual safety impact assessment of pre-crash safety systems</title>
      <link>https://arxiv.org/abs/2503.00815</link>
      <description>arXiv:2503.00815v1 Announce Type: cross 
Abstract: Virtual safety assessment plays a vital role in evaluating the safety impact of pre-crash safety systems such as advanced driver assistance systems (ADAS) and automated driving systems (ADS). However, as the number of parameters in simulation-based scenario generation increases, the number of crash scenarios to simulate grows exponentially, making complete enumeration computationally infeasible. Efficient sampling methods, such as importance sampling and active sampling, have been proposed to address this challenge. However, a comprehensive evaluation of how domain knowledge, stratification, and batch sampling affect their efficiency remains limited.
  This study evaluates the performance of importance sampling and active sampling in scenario generation, incorporating two domain-knowledge-driven features: adaptive sample space reduction (ASSR) and stratification. Additionally, we assess the effects of a third feature, batch sampling, on computational efficiency in terms of both CPU and wall-clock time. Based on our findings, we provide practical recommendations for applying ASSR, stratification, and batch sampling to optimize sampling performance.
  Our results demonstrate that ASSR substantially improves sampling efficiency for both importance sampling and active sampling. When integrated into active sampling, ASSR reduces the root mean squared estimation error (RMSE) of the estimates by up to 90\%. Stratification further improves sampling performance for both methods, regardless of ASSR implementation. When ASSR and/or stratification are applied, importance sampling performs on par with active sampling, whereas when neither feature is used, active sampling is more efficient. Larger batch sizes reduce wall-clock time but increase the number of simulations required to achieve the same estimation accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00815v1</guid>
      <category>stat.AP</category>
      <category>cs.LG</category>
      <category>stat.CO</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Xiaomi Yang, Henrik Imberg, Carol Flannagan, Jonas B\"argman</dc:creator>
    </item>
    <item>
      <title>Temporal Correlations and Inelastic Dynamics in a Vibrated Binary Granular Mixture</title>
      <link>https://arxiv.org/abs/2503.01414</link>
      <description>arXiv:2503.01414v1 Announce Type: cross 
Abstract: We investigate the dynamics of binary mixtures of inelastic particles through event-driven molecular dynamics simulations, focusing on velocity autocorrelation functions (VACFs). The study examines two distinct particle types under varying inelasticity conditions, systematically analyzing coefficients of restitution (CoR) ranging from 0.80 to 0.95. Like-particle interactions (AA and BB) maintain equal CoR values, while unlike-particle interactions (AB) are assigned the average CoR. The simulation framework incorporates a vibrating base system to maintain energy input and system stability. Our analysis reveals significant differences in VACF decay rates between Type 1 and Type 2 particles, demonstrating non-equipartition of energy within the binary mixture. The degree of this disparity is strongly influenced by the coefficient of restitution, with lower CoR values leading to more pronounced differences between particle types. These findings provide insights into the complex dynamics of granular gases and the role of inelasticity in energy distribution within binary mixtures. Our study contributes to the understanding of non-equilibrium statistical mechanics in granular systems and has potential implications for industrial processes involving particulate materials, such as fluidized beds and pneumatic conveying systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01414v1</guid>
      <category>cond-mat.soft</category>
      <category>stat.CO</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rameez Farooq Shah, Syed Rashid Ahmad, Shikha Kumari</dc:creator>
    </item>
    <item>
      <title>Recommendations for visual predictive checks in Bayesian workflow</title>
      <link>https://arxiv.org/abs/2503.01509</link>
      <description>arXiv:2503.01509v1 Announce Type: cross 
Abstract: A key step in the Bayesian workflow for model building is the graphical assessment of model predictions, whether these are drawn from the prior or posterior predictive distribution. The goal of these assessments is to identify whether the model is a reasonable (and ideally accurate) representation of the domain knowledge and/or observed data. There are many commonly used visual predictive checks which can be misleading if their implicit assumptions do not match the reality. Thus, there is a need for more guidance for selecting, interpreting, and diagnosing appropriate visualizations. As a visual predictive check itself can be viewed as a model fit to data, assessing when this model fails to represent the data is important for drawing well-informed conclusions.
  We present recommendations and diagnostic tools to mitigate ad-hoc decision-making in visual predictive checks. These contributions aim to improve the robustness and interpretability of Bayesian model criticism practices. We offer recommendations for appropriate visual predictive checks for observations that are: continuous, discrete, or a mixture of the two. We also discuss diagnostics to aid in the selection of visual methods. Specifically, in the detection of an incorrect assumption of continuously-distributed data: identifying when data is likely to be discrete or contain discrete components, detecting and estimating possible bounds in data, and a diagnostic of the goodness-of-fit to data for density plots made through kernel density estimates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01509v1</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Teemu S\"ailynoja, Andrew R. Johnson, Osvaldo A. Martin, Aki Vehtari</dc:creator>
    </item>
    <item>
      <title>Bayesian Inference for Spatial-temporal Non-Gaussian Data Using Predictive Stacking</title>
      <link>https://arxiv.org/abs/2406.04655</link>
      <description>arXiv:2406.04655v2 Announce Type: replace-cross 
Abstract: Analysing non-Gaussian spatial-temporal data typically requires introducing spatial dependence in generalised linear models through the link function of an exponential family distribution. However, unlike in Gaussian likelihoods, inference is considerably encumbered by the inability to analytically integrate out the random effects and reduce the dimension of the parameter space. Iterative estimation algorithms struggle to converge due to the presence of weakly identified parameters. We devise an approach that obviates these issues by exploiting generalised conjugate multivariate distribution theory for exponential families, which enables exact sampling from analytically available posterior distributions conditional upon some fixed process parameters. More specifically, we expand upon the Diaconis-Ylvisaker family of conjugate priors to achieve analytically tractable posterior inference for spatially-temporally varying regression models conditional on some kernel parameters. Subsequently, we assimilate inference from these individual posterior distributions over a range of values of these parameters using Bayesian predictive stacking. We evaluate inferential performance on simulated data, compare with fully Bayesian inference using Markov chain Monte Carlo and apply our proposed method to analyse spatially-temporally referenced avian count data from the North American Breeding Bird Survey database.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04655v2</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Soumyakanti Pan, Lu Zhang, Jonathan R. Bradley, Sudipto Banerjee</dc:creator>
    </item>
    <item>
      <title>An Adaptive Importance Sampling for Locally Stable Point Processes</title>
      <link>https://arxiv.org/abs/2408.07372</link>
      <description>arXiv:2408.07372v2 Announce Type: replace-cross 
Abstract: The problem of finding the expected value of a statistic of a locally stable point process in a bounded region is addressed. We propose an adaptive importance sampling for solving the problem. In our proposal, we restrict the importance point process to the family of homogeneous Poisson point processes, which enables us to generate quickly independent samples of the importance point process. The optimal intensity of the importance point process is found by applying the cross-entropy minimization method. In the proposed scheme, the expected value of the function and the optimal intensity are iteratively estimated in an adaptive manner. We show that the proposed estimator converges to the target value almost surely, and prove the asymptotic normality of it. We explain how to apply the proposed scheme to the estimation of the intensity of a stationary pairwise interaction point process. The performance of the proposed scheme is compared numerically with the Markov chain Monte Carlo simulation and the perfect sampling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.07372v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>stat.CO</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1007/s00180-025-01609-2</arxiv:DOI>
      <dc:creator>Hee-Geon Kang, Sunggon Kim</dc:creator>
    </item>
    <item>
      <title>Air-HOLP: Adaptive Regularized Feature Screening for High Dimensional Correlated Data</title>
      <link>https://arxiv.org/abs/2408.13000</link>
      <description>arXiv:2408.13000v2 Announce Type: replace-cross 
Abstract: Handling high-dimensional datasets presents substantial computational challenges, particularly when the number of features far exceeds the number of observations and when features are highly correlated. A modern approach to mitigate these issues is feature screening. In this work, the High-dimensional Ordinary Least-squares Projection (HOLP) feature screening method is advanced by employing adaptive ridge regularization. The impact of the ridge tuning parameter on the Ridge-HOLP method is examined and Adaptive iterative ridge-HOLP (Air-HOLP) is proposed, a data-adaptive advance to Ridge-HOLP where the ridge-regularization tuning parameter is selected iteratively and optimally for better feature screening performance. The proposed method addresses the challenges of tuning parameter selection in high dimensions by offering a computationally efficient and stable alternative to traditional methods like bootstrapping and cross-validation. Air-HOLP is evaluated using simulated data and a prostate cancer genetic dataset. The empirical results demonstrate that Air-HOLP has improved performance over a large range of simulation settings. We provide R codes implementing the Air-HOLP feature screening method and integrating it into existing feature screening methods that utilize the HOLP formula.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.13000v2</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ibrahim Joudah, Samuel Muller, Houying Zhu</dc:creator>
    </item>
  </channel>
</rss>
