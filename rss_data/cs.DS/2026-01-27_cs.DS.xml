<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 27 Jan 2026 05:00:21 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Parallel Algorithm For Finding The Minimum s/t Cut in a Structured 3-Dimensional Proper Order Graph</title>
      <link>https://arxiv.org/abs/2601.17026</link>
      <description>arXiv:2601.17026v1 Announce Type: new 
Abstract: We present a parallel algorithm for computing the minimum s-t cut in structured 3-dimensional proper order graphs arising from image segmentation problems. Proper order graphs are multi-column structures where vertices are arranged in parallel columns, with each vertex connected to consecutive vertices in adjacent columns. This graph structure naturally arises in surface extraction problems for geological horizon segmentation in seismic imaging volumes. We develop two parallel approaches: a hierarchical merging variant of the Boykov-Kolmogorov algorithm, and a novel parallel push-relabel algorithm with level synchronized global relabeling. Our primary contribution is the push-relabel variant, which partitions the graph into segments along columns with processor affinity, eliminating the need for a global shared queue. We introduce level synchronized global relabeling that enables concurrent label updates while maintaining correctness through barriers at each frontier level.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.17026v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shridharan Chandramouli</dc:creator>
    </item>
    <item>
      <title>Minimizing Completion Times of Stochastic Jobs on Parallel Machines is Hard</title>
      <link>https://arxiv.org/abs/2601.17425</link>
      <description>arXiv:2601.17425v1 Announce Type: new 
Abstract: This paper considers the scheduling of stochastic jobs on parallel identical machines to minimize the expected total weighted completion time. While this is a classical problem with a significant body of research on approximation algorithms over the past two decades, constant-factor performance guarantees are currently known only under very restrictive assumptions on the input distributions, even when all job weights are identical. This algorithmic difficulty is striking given the lack of corresponding complexity results: to date, it is conceivable that the problem could be solved optimally in polynomial time.
  We address this gap with hardness results that demonstrate the problem's inherent intractability. For the special case of discrete two-point processing time distributions and unit weights, we prove that deciding whether there exists a scheduling policy with expected cost at most a given threshold is #P-hard. Furthermore, we show that evaluating the expected objective value of the standard (W)SEPT greedy policy is itself #P-hard. These represent the first hardness results for scheduling independent stochastic jobs and min-sum objective that do not merely rely on the intractability of the underlying deterministic counterparts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.17425v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>math.OC</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Benjamin Moseley, Kirk Pruhs, Marc Uetz, Rudy Zhou</dc:creator>
    </item>
    <item>
      <title>Split Algorithm in Linear Time for the Vehicle Routing Problem with Simultaneous Pickup and Delivery and Time Windows</title>
      <link>https://arxiv.org/abs/2601.17572</link>
      <description>arXiv:2601.17572v1 Announce Type: new 
Abstract: For many kinds of vehicle routing problems (VRPs), a popular heuristic approach involves constructing a Traveling Salesman Problem (TSP) solution, referred to as a long tour, then partitioning segments of the solution into routes for different vehicles with respect to problem constraints. Previously, a Split algorithm with a worst-case runtime of $\Theta(n)$ was proposed for the capacitated VRP (CVRP) that finds the most cost-efficient partition of customers, given a long tour. This was an improvement over the previously fastest-known Split algorithm with a worst-case runtime of $\Theta(n^2)$ that was based on Bellman's shortest path algorithm. While this linear Split has been an integral part of modern state-of-the-art CVRP approaches, little progress has been made in extending this algorithm to handle additional VRP variants, limiting the general applicability of the algorithm. In this work, we propose an extension of the linear Split that handles two cardinal VRP variants simultaneously: (i) simultaneous pickups and deliveries (VRPSPD) and (ii) time windows (VRPTW). The resulting $\Theta(n)$ algorithm is guaranteed to be optimal, assuming travel times between nodes satisfy the triangle inequality. Additionally, we extend the linear Split to handle a capacity penalty for the VRPSPD. For the VRPTW, we extend the linear Split to handle the CVRP capacity penalty in conjunction with the popular time warp penalty function. Computational experiments are performed to empirically validate the speed gains of these linear Splits against their $\Theta$($n^2$) counterparts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.17572v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ethan Gibbons, Mario Ventresca, Beatrice M. Ombuki-Berman</dc:creator>
    </item>
    <item>
      <title>Sampling Sphere Packings with Continuum Glauber Dynamics</title>
      <link>https://arxiv.org/abs/2601.18748</link>
      <description>arXiv:2601.18748v1 Announce Type: new 
Abstract: We establish a spectral gap for Continuum Glauber dynamics on the hard sphere model assuming strong spatial mixing, thereby extending the range of parameters in which Continuum Glauber is provably rapidly mixing. To do this, we introduce continuous extensions of spectral independence and negative fields localization. Our techniques apply to general Gibbs point processes with finite-range repulsive pair potentials. As a corollary, we improve the threshold up to which packings of a fixed number of spheres can be sampled from a bounded domain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.18748v1</guid>
      <category>cs.DS</category>
      <category>math.PR</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aiya Kuchukova, Santosh Vempala, Daniel J. Zhang</dc:creator>
    </item>
    <item>
      <title>Robust Learning of a Group DRO Neuron</title>
      <link>https://arxiv.org/abs/2601.18115</link>
      <description>arXiv:2601.18115v1 Announce Type: cross 
Abstract: We study the problem of learning a single neuron under standard squared loss in the presence of arbitrary label noise and group-level distributional shifts, for a broad family of covariate distributions. Our goal is to identify a ''best-fit'' neuron parameterized by $\mathbf{w}_*$ that performs well under the most challenging reweighting of the groups. Specifically, we address a Group Distributionally Robust Optimization problem: given sample access to $K$ distinct distributions $\mathcal p_{[1]},\dots,\mathcal p_{[K]}$, we seek to approximate $\mathbf{w}_*$ that minimizes the worst-case objective over convex combinations of group distributions $\boldsymbol{\lambda} \in \Delta_K$, where the objective is $\sum_{i \in [K]}\lambda_{[i]}\,\mathbb E_{(\mathbf x,y)\sim\mathcal p_{[i]}}(\sigma(\mathbf w\cdot\mathbf x)-y)^2 - \nu d_f(\boldsymbol\lambda,\frac{1}{K}\mathbf1)$ and $d_f$ is an $f$-divergence that imposes (optional) penalty on deviations from uniform group weights, scaled by a parameter $\nu \geq 0$. We develop a computationally efficient primal-dual algorithm that outputs a vector $\widehat{\mathbf w}$ that is constant-factor competitive with $\mathbf{w}_*$ under the worst-case group weighting. Our analytical framework directly confronts the inherent nonconvexity of the loss function, providing robust learning guarantees in the face of arbitrary label corruptions and group-specific distributional shifts. The implementation of the dual extrapolation update motivated by our algorithmic framework shows promise on LLM pre-training benchmarks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.18115v1</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Guyang Cao, Shuyao Li, Sushrut Karmalkar, Jelena Diakonikolas</dc:creator>
    </item>
    <item>
      <title>Stable Matching with Deviators and Conformists</title>
      <link>https://arxiv.org/abs/2601.18573</link>
      <description>arXiv:2601.18573v1 Announce Type: cross 
Abstract: In the fundamental Stable Marriage and Stable Roommates problems, there are inherent trade-offs between the size and stability of solutions. While in the former problem, a stable matching always exists and can be found efficiently using the celebrated Gale-Shapley algorithm, the existence of a stable matching is not guaranteed in the latter problem, but can be determined efficiently using Irving's algorithm. However, the computation of matchings that minimise the instability, either due to the presence of additional constraints on the size of the matching or due to restrictive preference cycles, gives rise to a collection of infamously intractable almost-stable matching problems. In practice, however, not every agent is able or likely to initiate deviations caused by blocking pairs. Suppose we knew, for example, due to a set of requirements or estimates based on historical data, which agents are likely to initiate deviations - the deviators - and which are likely to comply with whatever matching they are presented with - the conformists. Can we decide efficiently whether a matching exists in which no deviator is blocking, i.e., in which no deviator has an incentive to initiate a deviation? Furthermore, can we find matchings in which only a few deviators are blocking? We characterise the computational complexity of this question in bipartite and non-bipartite preference settings. Surprisingly, these problems prove computationally intractable in strong ways: for example, unlike in the classical setting, where every agent is considered a deviator, in this extension, we prove that it is NP-complete to decide whether a matching exists where no deviator is blocking. On the positive side, we identify polynomial-time and fixed-parameter tractable cases, providing novel algorithmics for multi-agent systems where stability cannot be fully guaranteed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.18573v1</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Frederik Glitzner, David Manlove</dc:creator>
    </item>
    <item>
      <title>A Tight Lower Bound for Comparison-Based Quantile Summaries</title>
      <link>https://arxiv.org/abs/1905.03838</link>
      <description>arXiv:1905.03838v3 Announce Type: replace 
Abstract: Quantiles, such as the median or percentiles, provide concise and useful information about the distribution of a collection of items, drawn from a totally ordered universe. We study data structures, called quantile summaries, which keep track of all quantiles, up to an error of at most $\varepsilon$. That is, an $\varepsilon$-approximate quantile summary first processes a stream of items and then, given any quantile query $0\le \phi\le 1$, returns an item from the stream, which is a $\phi'$-quantile for some $\phi' = \phi \pm \varepsilon$. We focus on comparison-based quantile summaries that can only compare two items and are otherwise completely oblivious of the universe.
  The best such deterministic quantile summary to date, due to Greenwald and Khanna (SIGMOD '01), stores at most $O(\frac{1}{\varepsilon}\cdot \log \varepsilon N)$ items, where $N$ is the number of items in the stream. We prove that this space bound is optimal by showing a matching lower bound. Our result thus rules out the possibility of constructing a deterministic comparison-based quantile summary in space $f(\varepsilon)\cdot o(\log N)$, for any function $f$ that does not depend on $N$. As a corollary, we improve the lower bound for biased quantiles, which provide a stronger, relative-error guarantee of $(1\pm \varepsilon)\cdot \phi$, and for other related computational tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:1905.03838v3</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3375395.3387650</arxiv:DOI>
      <arxiv:journal_reference>PODS 2020, p. 81-93, ACM, 2020</arxiv:journal_reference>
      <dc:creator>Graham Cormode, Pavel Vesel\'y</dc:creator>
    </item>
    <item>
      <title>Contraction Clustering (RASTER): A Very Fast Big Data Algorithm for Sequential and Parallel Density-Based Clustering in Linear Time, Constant Memory, and a Single Pass</title>
      <link>https://arxiv.org/abs/1907.03620</link>
      <description>arXiv:1907.03620v3 Announce Type: replace 
Abstract: Clustering is an essential data mining tool for analyzing and grouping similar objects. In big data applications, however, many clustering algorithms are infeasible due to their high memory requirements and/or unfavorable runtime complexity. In contrast, Contraction Clustering (RASTER) is a single-pass algorithm for identifying density-based clusters with linear time complexity. Due to its favorable runtime and the fact that its memory requirements are constant, this algorithm is highly suitable for big data applications where the amount of data to be processed is huge. It consists of two steps: (1) a contraction step which projects objects onto tiles and (2) an agglomeration step which groups tiles into clusters. This algorithm is extremely fast in both sequential and parallel execution. Our quantitative evaluation shows that a sequential implementation of RASTER performs significantly better than various standard clustering algorithms. Furthermore, the parallel speedup is significant: on a contemporary workstation, an implementation in Rust processes a batch of 500 million points with 1 million clusters in less than 50 seconds on one core. With 8 cores, the algorithm is about four times faster.</description>
      <guid isPermaLink="false">oai:arXiv.org:1907.03620v3</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gregor Ulm, Simon Smith, Adrian Nilsson, Emil Gustavsson, Mats Jirstrand</dc:creator>
    </item>
    <item>
      <title>Seat Arrangement Problems under B-utility and W-utility</title>
      <link>https://arxiv.org/abs/2406.09965</link>
      <description>arXiv:2406.09965v2 Announce Type: replace 
Abstract: In the Seat Arrangement problem the goal is to allocate agents to vertices in a graph such that the resulting arrangement is optimal or fair in some way. Examples include an arrangement that maximises utility or one where no agent envies another. We introduce two new ways of calculating the utility that each agent derives from a given arrangement, one in which agents care only about their most preferred neighbour under a given arrangement, and another in which they only care about their least preferred neighbour. We also present a new restriction on agent's preferences, namely 1-dimensional preferences. We give algorithms, hardness results, and impossibility results for these new types of utilities and agents' preferences. Additionally, we refine previous complexity results, by showing that they hold in more restricted settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.09965v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jos\'e Rodr\'iguez</dc:creator>
    </item>
    <item>
      <title>Parameterized Spanning Tree Congestion</title>
      <link>https://arxiv.org/abs/2410.08314</link>
      <description>arXiv:2410.08314v4 Announce Type: replace 
Abstract: In this paper we study the Spanning Tree Congestion problem, where we are given a graph $G=(V,E)$ and are asked to find a spanning tree $T$ of minimum maximum congestion. Here, the congestion of an edge $e\in T$ is the number of edges $uv\in E$ such that the (unique) path from $u$ to $v$ in $T$ traverses $e$. We consider this well-studied NP-hard problem from the point of view of (structural) parameterized complexity and obtain the following results.
  We resolve a natural open problem by showing that Spanning Tree Congestion is not FPT parameterized by treewidth (under standard assumptions). More strongly, we present a generic reduction which applies to (almost) any parameter of the form ``vertex-deletion distance to class $\mathcal{C}$'', thus obtaining W[1]-hardness for parameters more restricted than treewidth, including tree-depth plus feedback vertex set, or incomparable to treewidth, such as twin cover. Via a slight tweak of the same reduction we also show that the problem is NP-complete on graphs of modular-width $4$.
  Even though it is known that Spanning Tree Congestion remains NP-hard on instances with only one vertex of unbounded degree, it is currently open whether the problem remains hard on bounded-degree graphs. We resolve this question by showing NP-hardness on graphs of maximum degree 8.
  Complementing the problem's W[1]-hardness for treewidth...</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08314v4</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael Lampis, Valia Mitsou, Edouard Nemery, Yota Otachi, Manolis Vasilakis, Daniel Vaz</dc:creator>
    </item>
    <item>
      <title>Improved parallel derandomization via finite automata with applications</title>
      <link>https://arxiv.org/abs/2411.18028</link>
      <description>arXiv:2411.18028v3 Announce Type: replace 
Abstract: A central approach to algorithmic derandomization is to construct probability distributions with small support that "fool" randomized algorithms, often enabling efficient parallel (NC) implementations. An abstraction of this idea is fooling polynomial-space statistical tests computed via finite automata (Sivakumar 2002); this encompasses a wide range of properties including $k$-wise independence and sums of random variables.
  We present new parallel algorithms to fool automata, with significantly reduced processor complexity. Briefly, our approach is to iteratively sparsify distributions via work-efficient lattice discrepancy rounding, while tracking an aggregate weighted error that is determined by the Lipschitz value of the statistical tests.
  We illustrate with applications to the Gale-Berlekamp Switching Game and approximate MAX-CUT via SDP rounding. These involve several optimizations, including truncating the state space of the automata and using FFT-based convolutions to compute transition probabilities efficiently.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.18028v3</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jeff Giliberti, David G. Harris</dc:creator>
    </item>
    <item>
      <title>Course Allocation with Credits via Stable Matching</title>
      <link>https://arxiv.org/abs/2505.21229</link>
      <description>arXiv:2505.21229v2 Announce Type: replace 
Abstract: In the {\sc Course Allocation} problem, there are a set of students and a set of courses at a given university. University courses may have different numbers of credits, typically related to different numbers of learning hours, and there may be other constraints such as courses running concurrently. Our goal is to allocate the students to the courses such that the resulting matching is stable, which means that no student and course(s) have an incentive to break away from the matching and become assigned to one another. We study several definitions of stability and for each we give a mixture of polynomial-time algorithms and hardness results for problems involving verifying the stability of a matching, finding a stable matching or determining that none exists, and finding a maximum size stable matching. We also study variants of the problem with master lists of students, and lower quotas on the number of students allocated to a course, establishing additional complexity results in these settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21229v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jos\'e Rodr\'iguez, David Manlove</dc:creator>
    </item>
    <item>
      <title>DTC: Real-Time and Accurate Distributed Triangle Counting in Fully Dynamic Graph Streams</title>
      <link>https://arxiv.org/abs/2508.19057</link>
      <description>arXiv:2508.19057v2 Announce Type: replace 
Abstract: Triangle counting is a fundamental problem in graph mining, essential for analyzing graph streams with arbitrary edge orders. However, exact counting becomes impractical due to the massive size of real-world graph streams. To address this, approximate algorithms have been developed, but existing distributed streaming algorithms lack adaptability and struggle with edge deletions. In this article, we propose DTC, a novel family of single-pass distributed streaming algorithms for global and local triangle counting in fully dynamic graph streams. Our DTC-AR algorithm accurately estimates triangle counts without prior knowledge of graph size, leveraging multi-machine resources. Additionally, we introduce DTC-FD, an algorithm tailored for fully dynamic graph streams, incorporating edge insertions and deletions. Using Random Pairing and future edge insertion compensation, DTC-FD achieves unbiased and accurate approximations across multiple machines. Experimental results demonstrate significant improvements over baselines. DTC-AR achieves up to $2029.4\times$ and $27.1\times$ more accuracy, while maintaining the best trade-off between accuracy and storage space. DTC-FD reduces estimation errors by up to $32.5\times$ and $19.3\times$, scaling linearly with graph stream size. These findings highlight the effectiveness of our proposed algorithms in tackling triangle counting in real-world scenarios. The source code and datasets are released and available at \href{https://github.com/wayne4s/srds-dtc.git}{https://github.com/wayne4s/srds-dtc.git}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.19057v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wei Xuan, Yan Liang, Huawei Cao, Ning Lin, Xiaochun Ye, Dongrui Fan</dc:creator>
    </item>
    <item>
      <title>On the Smallest Size of Internal Collage Systems</title>
      <link>https://arxiv.org/abs/2509.11602</link>
      <description>arXiv:2509.11602v2 Announce Type: replace 
Abstract: A Straight-Line Program (SLP) for a string $T$ is a context-free grammar in Chomsky normal form that derives $T$ only, which can be seen as a compressed form of $T$. Kida et al.\ introduced collage systems [Theor. Comput. Sci., 2003] to generalize SLPs by adding repetition rules and truncation rules. The smallest size $c(T)$ of collage systems for $T$ has gained attention to see how these generalized rules improve the compression ability of SLPs. Navarro et al. [IEEE Trans. Inf. Theory, 2021] showed that $c(T) \in O(z(T))$ and there is a string family with $c(T) \in \Omega(b(T) \log |T|)$, where $z(T)$ is the number of phrases in the Lempel-Ziv parsing of $T$ and $b(T)$ is the smallest size of bidirectional schemes for $T$. They also introduced a subclass of collage systems, called internal collage systems, and proved that its smallest size $\hat{c}(T)$ for $T$ is at least $b(T)$. While $c(T) \le \hat{c}(T)$ is obvious, it is unknown how large $\hat{c}(T)$ is compared to $c(T)$. In this paper, we prove that $\hat{c}(T) = \Theta(c(T))$ by showing that any collage system of size $m$ can be transformed into an internal collage system of size $O(m)$ in $O(m^2)$ time. Thanks to this result, we can focus on internal collage systems to study the asymptotic behavior of $c(T)$, which helps to suppress excess use of truncation rules. As a direct application, we get $b(T) = O(c(T))$, which answers an open question posed in [Navarro et al., IEEE Trans. Inf. Theory, 2021]. We also give a MAX-SAT formulation to compute $\hat{c}(T)$ for a given $T$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11602v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Soichiro Migita, Kyotaro Uehata, Tomohiro I</dc:creator>
    </item>
    <item>
      <title>On Solving Asymmetric Diagonally Dominant Linear Systems in Sublinear Time</title>
      <link>https://arxiv.org/abs/2509.13891</link>
      <description>arXiv:2509.13891v2 Announce Type: replace 
Abstract: We initiate a study of solving a row/column diagonally dominant (RDD/CDD) linear system $Mx=b$ in sublinear time, with the goal of estimating $t^{\top}x^*$ for a given vector $t\in R^n$ and a specific solution $x^*$. This setting naturally generalizes the study of sublinear-time solvers for symmetric diagonally dominant (SDD) systems [AKP19] to the asymmetric case.
  Our first contributions are characterizations of the problem's mathematical structure. We express a solution $x^*$ via a Neumann series, prove its convergence, and upper bound the truncation error on this series through a novel quantity of $M$, termed the maximum $p$-norm gap. This quantity generalizes the spectral gap of symmetric matrices and captures how the structure of $M$ governs the problem's computational difficulty.
  For systems with bounded maximum $p$-norm gap, we develop a collection of algorithmic results for locally approximating $t^{\top}x^*$ under various scenarios and error measures. We derive these results by adapting the techniques of random-walk sampling, local push, and their bidirectional combination, which have proved powerful for special cases of solving RDD/CDD systems, particularly estimating PageRank and effective resistance on graphs. Our general framework yields deeper insights, extended results, and improved complexity bounds for these problems. Notably, our perspective provides a unified understanding of Forward Push and Backward Push, two fundamental approaches for estimating random-walk probabilities on graphs.
  Our framework also inherits the hardness results for sublinear-time SDD solvers and local PageRank computation, establishing lower bounds on the maximum $p$-norm gap or the accuracy parameter. We hope that our work opens the door for further study into sublinear solvers, local graph algorithms, and directed spectral graph theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.13891v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.4230/LIPIcs.ITCS.2026.89</arxiv:DOI>
      <dc:creator>Tsz Chiu Kwok, Zhewei Wei, Mingji Yang</dc:creator>
    </item>
    <item>
      <title>R-enum Revisited: Speedup and Extension for Context-Sensitive Repeats and Net Frequencies</title>
      <link>https://arxiv.org/abs/2511.11057</link>
      <description>arXiv:2511.11057v2 Announce Type: replace 
Abstract: Nishimoto and Tabei [CPM, 2021] proposed r-enum, an algorithm to enumerate various characteristic substrings, including maximal repeats, in a string $T$ of length $n$ in $O(r)$ words of compressed working space, where $r \le n$ is the number of runs in the Burrows-Wheeler transform (BWT) of $T$. Given the run-length encoded BWT (RLBWT) of $T$, r-enum runs in $O(n \log \log_{w} (n/r))$ time in addition to the time linear to the number of output strings, where $w = \Theta(\log n)$ is the word size. In this paper, we first improve the $O(n \log \log_{w} (n/r))$ term to $O(n)$. We next extend r-enum to compute other context-sensitive repeats such as near-supermaximal repeats (NSMRs) and supermaximal repeats, as well as the context diversity for every maximal repeat in the same complexities. Furthermore, we study net occurrences: An occurrence of a repeat is called a net occurrence if it is not covered by another repeat, and the net frequency of a repeat is the number of its net occurrences. With this terminology, an NSMR is a repeat with a positive net frequency. Given the RLBWT of $T$, we show how to compute the set $S^{nsmr}$ of all NSMRs in $T$ together with their net frequency/occurrences in $O(n)$ time and $O(r)$ space. We also show that an $O(r)$-space data structure can be built from the RLBWT to compute the net frequency/occurrences of any pattern in optimal time. The data structure is built in $O(r)$ space and in $O(n)$ time with high probability or deterministic $O(n + |S^{nsmr}| \log \log \min(\sigma, |S^{nsmr}|))$ time, where $\sigma \le r$ is the alphabet size of $T$. To achieve this, we prove that the total number of net occurrences is less than $2r$. With the duality between net occurrences and \emph{minimal unique substrings (MUSs)}, we get a new upper bound $2r$ of the number of MUSs in $T$, which may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.11057v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kotaro Kimura, Tomohiro I</dc:creator>
    </item>
    <item>
      <title>Concurrent Balanced Augmented Trees</title>
      <link>https://arxiv.org/abs/2601.05225</link>
      <description>arXiv:2601.05225v2 Announce Type: replace 
Abstract: Augmentation makes search trees tremendously more versatile, allowing them to support efficient aggregation queries, order-statistic queries, and range queries in addition to insertion, deletion, and lookup. In this paper, we present the first lock-free augmented balanced search tree supporting generic augmentation functions. Our algorithmic ideas build upon a recent augmented unbalanced search tree presented by Fatourou and Ruppert [DISC, 2024]. We implement both data structures, solving some memory reclamation challenges in the process, and provide an experimental performance analysis of them. We also present optimized versions of our balanced tree that use delegation to achieve better scalability and performance (by more than 2x in most workloads). Our experiments show that our augmented balanced tree completes updates 2.2 to 30 times faster than the unbalanced augmented tree, and outperforms unaugmented trees by up to several orders of magnitude on 120 threads.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.05225v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Evan Wrench, Ajay Singh, Younghun Roh, Panagiota Fatourou, Siddhartha Jayanti, Eric Ruppert, Yuanhao Wei</dc:creator>
    </item>
    <item>
      <title>NPA Hierarchy for Quantum Isomorphism and Homomorphism Indistinguishability</title>
      <link>https://arxiv.org/abs/2407.10635</link>
      <description>arXiv:2407.10635v3 Announce Type: replace-cross 
Abstract: Man\v{c}inska and Roberson [FOCS'20] showed that two graphs are quantum isomorphic if and only if they admit the same number of homomorphisms from any planar graph. Atserias et al. [JCTB'19] proved that quantum isomorphism is undecidable in general, which motivates the study of its relaxations. In the classical setting, Roberson and Seppelt [ICALP'23] characterized the feasibility of each level of the Lasserre hierarchy of semidefinite programming relaxations of graph isomorphism in terms of equality of homomorphism counts from an appropriate graph class. The NPA hierarchy, a noncommutative generalization of the Lasserre hierarchy, provides a sequence of semidefinite programming relaxations for quantum isomorphism. In the quantum setting, we show that the feasibility of each level of the NPA hierarchy for quantum isomorphism is equivalent to equality of homomorphism counts from an appropriate class of planar graphs. Combining this characterization with the convergence of the NPA hierarchy, and noting that the union of these classes is the set of all planar graphs, we obtain a new proof of the result of Man\v{c}inska and Roberson [FOCS'20] that avoids the use of quantum groups. Moreover, this homomorphism indistinguishability characterization also yields a randomized polynomial-time algorithm deciding exact feasibility of each fixed level of the NPA hierarchy of SDP relaxations for quantum isomorphism.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10635v3</guid>
      <category>quant-ph</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <category>math.OC</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Prem Nigam Kar, David E. Roberson, Tim Seppelt, Peter Zeman</dc:creator>
    </item>
    <item>
      <title>Detecting null patterns in tensor data</title>
      <link>https://arxiv.org/abs/2408.17425</link>
      <description>arXiv:2408.17425v3 Announce Type: replace-cross 
Abstract: This article introduces a class of efficiently computable null patterns for tensor data. The class includes familiar patterns such as block-diagonal decompositions explored in statistics and signal processing, low-rank tensor decompositions, and Tucker decompositions. It also includes a new family of null patterns -- not known to be detectable by current methods -- that can be thought of as continuous decompositions approximating curves and surfaces. We present a general algorithm to detect null patterns in each class using a parameter we call a \textit{chisel} that tunes the search to patterns of a prescribed shape. We also show that the patterns output by the algorithm are essentially unique.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.17425v3</guid>
      <category>math.NA</category>
      <category>cs.DS</category>
      <category>cs.NA</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Peter A. Brooksbank, Martin D. Kassabov, James B. Wilson</dc:creator>
    </item>
    <item>
      <title>Boltzmann Sampling for Powersets without an Oracle</title>
      <link>https://arxiv.org/abs/2601.09508</link>
      <description>arXiv:2601.09508v2 Announce Type: replace-cross 
Abstract: We show that powersets over structures with a bounded counting sequence can be sampled efficiently without evaluating the generating function. An algorithm is provided, implemented, and tested. Runtimes are comparable to existing Boltzmann samplers reported in the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.09508v2</guid>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <category>math.PR</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jean Peyen</dc:creator>
    </item>
    <item>
      <title>A uniformity principle for spatial matching</title>
      <link>https://arxiv.org/abs/2601.13426</link>
      <description>arXiv:2601.13426v2 Announce Type: replace-cross 
Abstract: Platforms matching spatially distributed supply to demand face a fundamental design choice: given a fixed total budget of service range, how should it be allocated across supply nodes ex ante, i.e. before supply and demand locations are realized, to maximize fulfilled demand? We model this problem using bipartite random geometric graphs where $n$ supply and $m$ demand nodes are uniformly distributed on $[0,1]^k$ ($k \ge 1$), and edges form when demand falls within a supply node's service region, the volume of which is determined by its service range. Since each supply node serves at most one demand, platform performance is determined by the expected size of a maximum matching. We establish a uniformity principle: whenever one service range allocation is more uniform than the other, the more uniform allocation yields a larger expected matching. This principle emerges from diminishing marginal returns to range expanding service range, and limited interference between supply nodes due to bounded ranges naturally fragmenting the graph. For $k=1$, we further characterize the expected matching size through a Markov chain embedding and derive closed-form expressions for special cases. Our results provide theoretical guidance for optimizing service range allocation and designing incentive structures in ride-hailing, on-demand labor markets, and drone delivery networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.13426v2</guid>
      <category>math.PR</category>
      <category>cs.DS</category>
      <category>econ.GN</category>
      <category>math.OC</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Taha Ameen, Flore Sentenac, Sophie H. Yu</dc:creator>
    </item>
  </channel>
</rss>
