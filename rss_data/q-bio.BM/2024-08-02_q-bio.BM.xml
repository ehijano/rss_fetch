<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.BM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.BM</link>
    <description>q-bio.BM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.BM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 02 Aug 2024 04:02:00 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 02 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Barlow Twins Deep Neural Network for Advanced 1D Drug-Target Interaction Prediction</title>
      <link>https://arxiv.org/abs/2408.00040</link>
      <description>arXiv:2408.00040v1 Announce Type: new 
Abstract: Accurate prediction of drug-target interactions is critical for advancing drug discovery. By reducing time and cost, machine learning and deep learning can accelerate this discovery process. Our approach utilises the powerful Barlow Twins architecture for feature-extraction while considering the structure of the target protein, achieving state-of-the-art predictive performance against multiple established benchmarks. The use of gradient boosting machine as the underlying predictor ensures fast and efficient predictions without the need for large computational resources. In addition, we further benchmarked new baselines against existing methods. Together, these innovations improve the efficiency and effectiveness of drug-target interaction predictions, providing robust tools for accelerating drug development and deepening the understanding of molecular interactions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.00040v1</guid>
      <category>q-bio.BM</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maximilian G. Schuh, Davide Boldini, Stephan A. Sieber</dc:creator>
    </item>
    <item>
      <title>GOProteinGNN: Leveraging Protein Knowledge Graphs for Protein Representation Learning</title>
      <link>https://arxiv.org/abs/2408.00057</link>
      <description>arXiv:2408.00057v1 Announce Type: new 
Abstract: Proteins play a vital role in biological processes and are indispensable for living organisms. Accurate representation of proteins is crucial, especially in drug development. Recently, there has been a notable increase in interest in utilizing machine learning and deep learning techniques for unsupervised learning of protein representations. However, these approaches often focus solely on the amino acid sequence of proteins and lack factual knowledge about proteins and their interactions, thus limiting their performance. In this study, we present GOProteinGNN, a novel architecture that enhances protein language models by integrating protein knowledge graph information during the creation of amino acid level representations. Our approach allows for the integration of information at both the individual amino acid level and the entire protein level, enabling a comprehensive and effective learning process through graph-based learning. By doing so, we can capture complex relationships and dependencies between proteins and their functional annotations, resulting in more robust and contextually enriched protein representations. Unlike previous fusion methods, GOProteinGNN uniquely learns the entire protein knowledge graph during training, which allows it to capture broader relational nuances and dependencies beyond mere triplets as done in previous work. We perform a comprehensive evaluation on several downstream tasks demonstrating that GOProteinGNN consistently outperforms previous methods, showcasing its effectiveness and establishing it as a state-of-the-art solution for protein representation learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.00057v1</guid>
      <category>q-bio.BM</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Dan Kalifa, Uriel Singer, Kira Radinsky</dc:creator>
    </item>
    <item>
      <title>Force and kinetics of fast and slow muscle myosin determined with a synthetic sarcomere-like nanomachine</title>
      <link>https://arxiv.org/abs/2408.00373</link>
      <description>arXiv:2408.00373v1 Announce Type: cross 
Abstract: Myosin II is the muscle molecular motor that works in two bipolar arrays in each thick filament of the striated (skeletal and cardiac) muscle, converting the chemical energy into steady force and shortening by cyclic ATP--driven interactions with the nearby actin filaments. Different isoforms of the myosin motor in the skeletal muscles account for the different functional requirements of the slow muscles (primarily responsible for the posture) and fast muscles (responsible for voluntary movements). To clarify the molecular basis of the differences, here the isoform--dependent mechanokinetic parameters underpinning the force of slow and fast muscles are defined with a unidimensional synthetic nanomachine powered by pure myosin isoforms from either slow or fast rabbit skeletal muscle. Data fitting with a stochastic model provides a self--consistent estimate of all the mechanokinetic properties of the motor ensemble including the motor force, the fraction of actin--attached motors and the rate of transition through the attachment--detachment cycle. The achievements in this paper set the stage for any future study on the emergent mechanokinetic properties of an ensemble of myosin molecules either engineered or purified from mutant animal models or human biopsies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.00373v1</guid>
      <category>cond-mat.stat-mech</category>
      <category>q-bio.BM</category>
      <category>q-bio.PE</category>
      <category>q-bio.TO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Valentina Buonfiglio, Irene Pertici, Matteo Marcello, Ilaria Morotti, Marco Caremani, Massimo Reconditi, Marco Linari, Duccio Fanelli, Vincenzo Lombardi, Pasquale Bianco</dc:creator>
    </item>
  </channel>
</rss>
