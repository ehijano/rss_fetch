<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 24 May 2024 04:01:12 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 24 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Convergence of the Deep Galerkin Method for Mean Field Control Problems</title>
      <link>https://arxiv.org/abs/2405.13346</link>
      <description>arXiv:2405.13346v1 Announce Type: new 
Abstract: We establish the convergence of the deep Galerkin method (DGM), a deep learning-based scheme for solving high-dimensional nonlinear PDEs, for Hamilton-Jacobi-Bellman (HJB) equations that arise from the study of mean field control problems (MFCPs). Based on a recent characterization of the value function of the MFCP as the unique viscosity solution of an HJB equation on the simplex, we establish both an existence and convergence result for the DGM. First, we show that the loss functional of the DGM can be made arbitrarily small given that the value function of the MFCP possesses sufficient regularity. Then, we show that if the loss functional of the DGM converges to zero, the corresponding neural network approximators must converge uniformly to the true value function on the simplex. We also provide numerical experiments demonstrating the DGM's ability to generalize to high-dimensional HJB equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.13346v1</guid>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>William Hofgard, Jingruo Sun, Asaf Cohen</dc:creator>
    </item>
    <item>
      <title>A general solution to the simultaneous stabilization problem by analytic interpolation</title>
      <link>https://arxiv.org/abs/2405.13440</link>
      <description>arXiv:2405.13440v1 Announce Type: new 
Abstract: In this paper, we tackle the significant challenge of simultaneous stabilization in control systems engineering, where the aim is to employ a single controller to ensure stability across multiple systems. We delve into both scalar and multivariable scenarios. For the scalar case, we present the necessary and sufficient conditions for a single controller to stabilize multiple plants and reformulate these conditions to interpolation constraints, which expand Ghosh's results by allowing derivative constraints. Furthermore, we implement a methodology based on a Riccati-type matrix equation, called the Covariance Extension Equation. This approach enables us to parameterize all potential solutions using a monic Schur polynomial. Consequently, we extend our result to the multivariable scenario and derive the necessary and sufficient conditions for a group of $m\times m$ plants to be simultaneously stabilizable, which can also be solved by our analytic interpolation method. Finally, we construct four numerical examples, showcasing the application of our method across various scenarios encountered in control systems engineering and highlighting its ability to stabilize diverse systems efficiently and reliably.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.13440v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yufang Cui, Anders Lindquist</dc:creator>
    </item>
    <item>
      <title>Relaxations for binary polynomial optimization via signed certificates</title>
      <link>https://arxiv.org/abs/2405.13447</link>
      <description>arXiv:2405.13447v1 Announce Type: new 
Abstract: We consider the problem of minimizing a polynomial $f$ over the binary hypercube. We show that, for a specific set of polynomials, their binary non-negativity can be checked in a polynomial time via minimum cut algorithms, and we construct a linear programming representation for this set through the min-cut-max-flow duality. We categorize binary polynomials based on their signed support patterns and develop parameterized linear programming representations of binary non-negative polynomials. This allows for constructing binary non-negative signed certificates with adjustable signed support patterns and representation complexities, and we propose a method for minimizing $f$ by decomposing it into signed certificates. This method yields new hierarchies of linear programming relaxations for binary polynomial optimization. Moreover, since our decomposition only depends on the support of $f$, the new hierarchies are sparsity-preserving.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.13447v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Liding Xu, Leo Liberti</dc:creator>
    </item>
    <item>
      <title>Large Deviations in Safety-Critical Hamiltonian Systems with Probabilistic Initial Conditions</title>
      <link>https://arxiv.org/abs/2405.13506</link>
      <description>arXiv:2405.13506v1 Announce Type: new 
Abstract: We address the problem of determining the least improbable deviations leading to an unsafe rare event in a weakly perturbed mechanical system with probabilistic initial conditions. These deviations are obtained as the solution to a variational problem formulated using rigorous approximation techniques grounded in the principles of large deviations theory. These types of results have been extended to accommodate stochastic uncertainty in the initial states, which is a common assumption in mechanical systems. Furthermore, we demonstrate the applicability of the method by solving the problem for a rare collision event between two space objects, i.e. a high-dimensional and non-linear problem, resulting in the most likely sample paths leading to the realization of the unsafe rare event. The solution is validated against the necessary conditions for optimality derived from the maximum principle. Access to these unsafe sample paths offers relevant information regarding the dangerous configurations of rare events and can be used to design control strategies to reduce the probability of realization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.13506v1</guid>
      <category>math.OC</category>
      <category>cond-mat.stat-mech</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Aitor R. Gomez, Manuela L. Bujorianu, Rafal Wisniewski</dc:creator>
    </item>
    <item>
      <title>Learn to formulate: A surrogate model framework for generalized assignment problem with routing constraints</title>
      <link>https://arxiv.org/abs/2405.13509</link>
      <description>arXiv:2405.13509v1 Announce Type: new 
Abstract: The generalized assignment problem with routing constraints, e.g. the vehicle routing problem, has essential practical relevance. This paper focuses on addressing the complexities of the problem by learning a surrogate model with reduced variables and reconstructed constraints. A surrogate model framework is presented with a class of surrogate models and a learning method to acquire parameters. The paper further provides theoretical results regarding the representational power and statistical properties to explore the effectiveness of this framework. Numerical experiments based on two practical problem classes demonstrate the accuracy and efficiency of the framework. The resulting surrogate models perform comparably to or surpass the state-of-the-art heuristics on average. Our findings provide empirical evidence for the effectiveness of utilizing size-reduced and reconstructed surrogate models in producing high-quality solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.13509v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sen Xue, Chuanhou Gao</dc:creator>
    </item>
    <item>
      <title>Verifying feasibility of degenerate semidefinite programs</title>
      <link>https://arxiv.org/abs/2405.13625</link>
      <description>arXiv:2405.13625v1 Announce Type: new 
Abstract: This paper deals with the algorithmic aspects of solving feasibility problems of semidefinite programming (SDP), aka linear matrix inequalities (LMI). Since in some SDP instances all feasible solutions have irrational entries, numerical solvers that work with rational numbers can only find an approximate solution. We study the following question: is it possible to certify feasibility of a given SDP using an approximate solution that is sufficiently close to some exact solution? Existing approaches make the assumption that there exist rational feasible solutions (and use techniques such as rounding and lattice reduction algorithms).
  We propose an alternative approach that does not need this assumption. More specifically, we show how to construct a system of polynomial equations whose set of real solutions is guaranteed to have an isolated correct solution (assuming that the target exact solution is maximum-rank). This allows, in particular, to use algorithms from real algebraic geometry for solving systems of polynomial equations, yielding a hybrid (or symbolic-numerical) method for SDPs. We experimentally compare it with a pure symbolic method in [Henrion, Naldi, Safey El Din; SIAM J. Optim., 2016]; the hybrid method was able to certify feasibility of many SDP instances on which [Henrion, Naldi, Safey El Din; SIAM J. Optim., 2016] failed. We argue that our approach may have other uses, such as refining an approximate solution using methods of numerical algebraic geometry for systems of polynomial equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.13625v1</guid>
      <category>math.OC</category>
      <category>cs.SC</category>
      <category>math.AG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vladimir Kolmogorov, Simone Naldi, Jeferson Zapata</dc:creator>
    </item>
    <item>
      <title>Achieving consensus in networks of increasingly stubborn voters</title>
      <link>https://arxiv.org/abs/2405.13703</link>
      <description>arXiv:2405.13703v1 Announce Type: new 
Abstract: We study opinion evolution in networks of stubborn agents discussing a sequence of issues, modeled through the so called concatenated Friedkin-Johnsen (FJ) model. It is concatenated in the sense that agents' opinions evolve for each issue, and the final opinion is then taken as a starting point for the next issue. We consider the scenario where agents {also take a vote at the end of each issue} and propose a feedback mechanism from the result (based on the median voter) to the agents' stubbornness. Specifically, agents become increasingly stubborn during issue $s+1$ the more they disagree with the vote at the end of issue $s$. We analyze {this model} for a number of special cases and provide sufficient conditions for convergence to consensus stated in terms of permissible initial opinion and stubbornness. In the opposite scenario, where agents become less stubborn when disagreeing with the vote result, we prove that consensus is achieved{, and we demonstrate the faster convergence of opinions compared to constant stubbornness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.13703v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1109/CDC51059.2022.9992899</arxiv:DOI>
      <arxiv:journal_reference>2022 IEEE 61st Conference on Decision and Control (CDC), Cancun, Mexico, 2022, pp. 3531-3537</arxiv:journal_reference>
      <dc:creator>David Ohlin, Fethi Bencherki, Emma Tegling</dc:creator>
    </item>
    <item>
      <title>The Power of Extrapolation in Federated Learning</title>
      <link>https://arxiv.org/abs/2405.13766</link>
      <description>arXiv:2405.13766v1 Announce Type: new 
Abstract: We propose and study several server-extrapolation strategies for enhancing the theoretical and empirical convergence properties of the popular federated learning optimizer FedProx [Li et al., 2020]. While it has long been known that some form of extrapolation can help in the practice of FL, only a handful of works provide any theoretical guarantees. The phenomenon seems elusive, and our current theoretical understanding remains severely incomplete. In our work, we focus on smooth convex or strongly convex problems in the interpolation regime. In particular, we propose Extrapolated FedProx (FedExProx), and study three extrapolation strategies: a constant strategy (depending on various smoothness parameters and the number of participating devices), and two smoothness-adaptive strategies; one based on the notion of gradient diversity (FedExProx-GraDS), and the other one based on the stochastic Polyak stepsize (FedExProx-StoPS). Our theory is corroborated with carefully constructed numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.13766v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hanmin Li, Kirill Acharya, Peter Richt\'arik</dc:creator>
    </item>
    <item>
      <title>On the integrality gap of the Complete Metric Steiner Tree Problem via a novel formulation</title>
      <link>https://arxiv.org/abs/2405.13773</link>
      <description>arXiv:2405.13773v1 Announce Type: new 
Abstract: In this work, we compute the lower bound of the integrality gap of the Metric Steiner Tree Problem (MSTP) on a graph for some small values of number of nodes and terminals. After debating about some limitations of the most used formulation for the Steiner Tree Problem, namely the Bidirected Cut Formulation, we introduce a novel formulation, that we named Complete Metric formulation, tailored for the metric case. We prove some interesting properties of this formulation and characterize some types of vertices. Finally, we define a linear program (LP) by adapting a method already used in the context of the Travelling Salesman Problem. This LP takes as input a vertex of the polytope of the CM relaxation and provides an MSTP instance such that (a) the optimal solution is precisely that vertex and (b) among all of the instances having that vertex as its optimal solution, the selected instance is the one having the highest integrality gap. We propose two heuristics for generating vertices to provide inputs for our procedure. In conclusion, we raise several conjectures and open questions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.13773v1</guid>
      <category>math.OC</category>
      <category>cs.DM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ambrogio Maria Bernardelli, Eleonora Vercesi, Stefano Gualandi, Monaldo Mastrolilli, Luca Maria Gambardella</dc:creator>
    </item>
    <item>
      <title>A Survey on Design-space Dimensionality Reduction Methods for Shape Optimization</title>
      <link>https://arxiv.org/abs/2405.13944</link>
      <description>arXiv:2405.13944v1 Announce Type: new 
Abstract: The rapidly evolving field of engineering design of functional surfaces necessitates sophisticated tools to manage the inherent complexity of high-dimensional design spaces. This review delves into the field of design-space dimensionality reduction techniques tailored for shape optimization, bridging traditional methods and cutting-edge technologies. Dissecting the spectrum of these techniques, from classical linear approaches like principal component analysis to more nuanced nonlinear methods such as autoencoders, the discussion extends to innovative physics-informed methods that integrate physical data into the dimensionality reduction process, enhancing the predictive accuracy and relevance of reduced models. By integrating these methods into optimization frameworks, it is shown how they significantly mitigate the curse of dimensionality, streamline computational processes, and refine the exploration and optimization of complex functional surfaces. The survey provides a classification of method and highlights the transformative impact of these techniques in simplifying design challenges, thereby fostering more efficient and effective engineering solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.13944v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrea Serani, Matteo Diez</dc:creator>
    </item>
    <item>
      <title>Learning Cut Generating Functions for Integer Programming</title>
      <link>https://arxiv.org/abs/2405.13992</link>
      <description>arXiv:2405.13992v1 Announce Type: new 
Abstract: The branch-and-cut algorithm is the method of choice to solve large scale integer programming problems in practice. A key ingredient of branch-and-cut is the use of cutting planes which are derived constraints that reduce the search space for an optimal solution. Selecting effective cutting planes to produce small branch-and-cut trees is a critical challenge in the branch-and-cut algorithm. Recent advances have employed a data-driven approach to select optimal cutting planes from a parameterized family, aimed at reducing the branch-and-bound tree size (in expectation) for a given distribution of integer programming instances. We extend this idea to the selection of the best cut generating function (CGF), which is a tool in the integer programming literature for generating a wide variety of cutting planes that generalize the well-known Gomory Mixed-Integer (GMI) cutting planes. We provide rigorous sample complexity bounds for the selection of an effective CGF from certain parameterized families that provably performs well for any specified distribution on the problem instances. Our empirical results show that the selected CGF can outperform the GMI cuts for certain distributions. Additionally, we explore the sample complexity of using neural networks for instance-dependent CGF selection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.13992v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongyu Cheng, Amitabh Basu</dc:creator>
    </item>
    <item>
      <title>Scalable Multi-Period AC Optimal Power Flow Utilizing GPUs with High Memory Capacities</title>
      <link>https://arxiv.org/abs/2405.14032</link>
      <description>arXiv:2405.14032v1 Announce Type: new 
Abstract: This paper demonstrates the scalability of open-source GPU-accelerated nonlinear programming (NLP) frameworks -- ExaModels.jl and MadNLP.jl -- for solving multi-period alternating current (AC) optimal power flow (OPF) problems on GPUs with high memory capacities (e.g., NVIDIA GH200 with 480 GB of unified memory). There has been a growing interest in solving multi-period AC OPF problems, as the increasingly fluctuating electricity market requires operation planning over multiple periods. These problems, formerly deemed intractable, are now becoming technologically feasible to solve thanks to the advent of high-memory GPU hardware and accelerated NLP tools. This study evaluates the capability of these tools to tackle previously unsolvable multi-period AC OPF instances. Our numerical experiments, run on an NVIDIA GH200, demonstrate that we can solve a multi-period OPF instance with more than 10 million variables up to $10^{-4}$ precision in less than 10 minutes. These results demonstrate the efficacy of the GPU-accelerated NLP frameworks for the solution of extreme-scale multi-period OPF. We provide ExaModelsPower.jl, an open-source modeling tool for multi-period AC OPF models for GPUs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14032v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sungho Shin, Vishwas Rao, Michel Schanen, D. Adrian Maldonado, Mihai Anitescu</dc:creator>
    </item>
    <item>
      <title>A continuous perspective on the inertial corrected primal-dual proximal splitting</title>
      <link>https://arxiv.org/abs/2405.14098</link>
      <description>arXiv:2405.14098v1 Announce Type: new 
Abstract: We give a continuous perspective on the Inertial Corrected Primal-Dual Proximal Splitting (IC-PDPS) proposed by Valkonen ({\it SIAM J. Optim.}, 30(2): 1391--1420, 2020) for solving saddle-point problems. The algorithm possesses nonergodic convergence rate and admits a tight preconditioned proximal point formulation which involves both inertia and additional correction. Based on new understandings on the relation between the discrete step size and rescaling effect, we rebuild IC-PDPS as a semi-implicit Euler scheme with respect to its iterative sequences and integrated parameters. This leads to two novel second-order ordinary differential equation (ODE) models that are equivalent under proper time transformation, and also provides an alternative interpretation from the continuous point of view. Besides, we present the convergence analysis of the Lagrangian gap along the continuous trajectory by using proper Lyapunov functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14098v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hao Luo</dc:creator>
    </item>
    <item>
      <title>High-probability complexity guarantees for nonconvex minimax problems</title>
      <link>https://arxiv.org/abs/2405.14130</link>
      <description>arXiv:2405.14130v1 Announce Type: new 
Abstract: Stochastic smooth nonconvex minimax problems are prevalent in machine learning, e.g., GAN training, fair classification, and distributionally robust learning. Stochastic gradient descent ascent (GDA)-type methods are popular in practice due to their simplicity and single-loop nature. However, there is a significant gap between the theory and practice regarding high-probability complexity guarantees for these methods on stochastic nonconvex minimax problems. Existing high-probability bounds for GDA-type single-loop methods only apply to convex/concave minimax problems and to particular non-monotone variational inequality problems under some restrictive assumptions. In this work, we address this gap by providing the first high-probability complexity guarantees for nonconvex/PL minimax problems corresponding to a smooth function that satisfies the PL-condition in the dual variable. Specifically, we show that when the stochastic gradients are light-tailed, the smoothed alternating GDA method can compute an $\varepsilon$-stationary point within $\mathcal{O}(\frac{\ell \kappa^2 \delta^2}{\varepsilon^4} + \frac{\kappa}{\varepsilon^2}(\ell+\delta^2\log({1}/{\bar{q}})))$ stochastic gradient calls with probability at least $1-\bar{q}$ for any $\bar{q}\in(0,1)$, where $\mu$ is the PL constant, $\ell$ is the Lipschitz constant of the gradient, $\kappa=\ell/\mu$ is the condition number, and $\delta^2$ denotes a bound on the variance of stochastic gradients. We also present numerical results on a nonconvex/PL problem with synthetic data and on distributionally robust optimization problems with real data, illustrating our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14130v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yassine Laguel, Yasa Syed, Necdet Serhat Aybat, Mert G\"urb\"uzbalaban</dc:creator>
    </item>
    <item>
      <title>A Geometric Perspective on the Closed Convex Hull of Some Spectral Sets</title>
      <link>https://arxiv.org/abs/2405.14143</link>
      <description>arXiv:2405.14143v1 Announce Type: new 
Abstract: We propose a geometric approach to characterize the closed convex hull of a spectral set $\mathcal{S}$ under certain structural assumptions, where $\mathcal{S}$ which is defined as the pre-image of a set $\mathcal{C}\subseteq\mathbb{R}^n$ under the ``spectral map'' that includes the eigenvalue and singular-value maps as special cases. Our approach is conceptually and technically simple, and yields geometric characterizations of the closed convex hull of $\mathcal{S}$ in a unified manner that works for all the spectral maps. From our results, we can easily recover the results in Kim et al. (2022) when the spectral map is the eigenvalue or singular-value map, and $\mathcal{C}$ is permutation- and/or sign-invariant. Lastly, we discuss the polynomial computability of the membership and separation oracles associated with the (lifted) closed convex hull of $\mathcal{S}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14143v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Renbo Zhao</dc:creator>
    </item>
    <item>
      <title>The Boolean polynomial polytope with multiple choice constraints</title>
      <link>https://arxiv.org/abs/2405.14207</link>
      <description>arXiv:2405.14207v1 Announce Type: new 
Abstract: We propose a polytope to study multiple choice polynomial programming (MCPP). It is the convex hull of $0$-$1$ vectors satisfying multiple choice constraints and production constraints both of which are associated with a hypergraph. With the help of the decomposability property, we obtain an explicit half-space representation of the MCPP polytope when the underlying hypergraph is $\alpha$-acyclic by induction on the number of hyperedges. We also present a necessary and sufficient condition for the inequalities lifted from the facet-inducing ones for the multilinear polytope to be still facet-inducing for the MCPP polytope.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14207v1</guid>
      <category>math.OC</category>
      <category>math.CO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sihong Shao, Yishan Wu</dc:creator>
    </item>
    <item>
      <title>Condensed-space methods for nonlinear programming on GPUs</title>
      <link>https://arxiv.org/abs/2405.14236</link>
      <description>arXiv:2405.14236v1 Announce Type: new 
Abstract: This paper explores two condensed-space interior-point methods to efficiently solve large-scale nonlinear programs on graphics processing units (GPUs). The interior-point method solves a sequence of symmetric indefinite linear systems, or Karush-Kuhn-Tucker (KKT) systems, which become increasingly ill-conditioned as we approach the solution. Solving a KKT system with traditional sparse factorization methods involve numerical pivoting, making parallelization difficult. A solution is to condense the KKT system into a symmetric positive-definite matrix and solve it with a Cholesky factorization, stable without pivoting. Although condensed KKT systems are more prone to ill-conditioning than the original ones, they exhibit structured ill-conditioning that mitigates the loss of accuracy. This paper compares the benefits of two recent condensed-space interior-point methods, HyKKT and LiftedKKT. We implement the two methods on GPUs using MadNLP.jl, an optimization solver interfaced with the NVIDIA sparse linear solver cuDSS and with the GPU-accelerated modeler ExaModels.jl. Our experiments on the PGLIB and the COPS benchmarks reveal that GPUs can attain up to a tenfold speed increase compared to CPUs when solving large-scale instances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14236v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fran\c{c}ois Pacaud, Sungho Shin, Alexis Montoison, Michel Schanen, Mihai Anitescu</dc:creator>
    </item>
    <item>
      <title>Stochastic Proximal Point Methods for Monotone Inclusions under Expected Similarity</title>
      <link>https://arxiv.org/abs/2405.14255</link>
      <description>arXiv:2405.14255v1 Announce Type: new 
Abstract: Monotone inclusions have a wide range of applications, including minimization, saddle-point, and equilibria problems. We introduce new stochastic algorithms, with or without variance reduction, to estimate a root of the expectation of possibly set-valued monotone operators, using at every iteration one call to the resolvent of a randomly sampled operator. We also introduce a notion of similarity between the operators, which holds even for discontinuous operators. We leverage it to derive linear convergence results in the strongly monotone setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14255v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Abdurakhmon Sadiev, Laurent Condat, Peter Richt\'arik</dc:creator>
    </item>
    <item>
      <title>On discount functions for economic model predictive control without terminal conditions</title>
      <link>https://arxiv.org/abs/2405.14361</link>
      <description>arXiv:2405.14361v1 Announce Type: new 
Abstract: In this paper, we investigate discounted economic model predictive control (E-MPC) schemes without terminal conditions in scenarios where the optimal operating behavior is a periodic orbit. For such a setting, it is known that a linearly discounted stage cost guarantees asymptotic stability of any arbitrarily small neighborhood of the optimal orbit if the prediction horizon is sufficiently long. However, in some examples very long prediction horizons are needed to achieve the desired performance. In this work, we extend these results by providing the same qualitative stability guarantees for a large class of discount functions. Numerical examples illustrate the influence of the discount function and show that with suitable discounting we can achieve significantly better performance than the linearly discounted E-MPC, even for short prediction horizons.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14361v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lukas Schwenkel, Daniel Briem, Matthias A. M\"uller, Frank Allg\"ower</dc:creator>
    </item>
    <item>
      <title>A rolling horizon heuristic approach for a multi-stage stochastic waste collection problem</title>
      <link>https://arxiv.org/abs/2405.14499</link>
      <description>arXiv:2405.14499v1 Announce Type: new 
Abstract: In this paper we present a multi-stage stochastic optimization model to solve an inventory routing problem for recyclable waste collection. The objective is the maximization of the total expected profit of the waste collection company. The decisions are related to the selection of the bins to be visited and the corresponding routing plan in a predefined time horizon. Stochasticity in waste accumulation is modeled through scenario trees generated via conditional density estimation and dynamic stochastic approximation techniques. The proposed formulation is solved through a rolling horizon approach, providing a worst-case analysis on its performance. Extensive computational experiments are carried out on small- and large-sized instances based on real data provided by a large Portuguese waste collection company. The impact of stochasticity on waste generation is examined through stochastic measures, and the performance of the rolling horizon approach is evaluated. Some managerial insights on different configurations of the instances are finally discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14499v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrea Spinelli, Francesca Maggioni, T\^ania Rodrigues Pereira Ramos, Ana Paula Barbosa-P\'ovoa, Daniele Vigo</dc:creator>
    </item>
    <item>
      <title>Last-iterate convergence of modified predictive method via high-resolution differential equation on bilinear game</title>
      <link>https://arxiv.org/abs/2405.14613</link>
      <description>arXiv:2405.14613v1 Announce Type: new 
Abstract: This paper discusses the convergence of the modified predictive method (MPM) proposed by Liang and stokes corresponding to high-resolution differential equations (HRDE) in bilinear games. First, we present the high-resolution differential equations (MPM-HRDE) corresponding to the MPM. Then, we discuss the uniqueness of the solution for MPM-HRDE in bilinear games. Finally, we provide the convergence results of MPM-HRDE in bilinear games. The results obtained in this paper address the gap in the existing literature and extend the conclusions of related works.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14613v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Keke Li, Xinmin Yang</dc:creator>
    </item>
    <item>
      <title>On the role of semismoothness in nonsmooth numerical analysis: Theory</title>
      <link>https://arxiv.org/abs/2405.14637</link>
      <description>arXiv:2405.14637v1 Announce Type: new 
Abstract: For the numerical solution of nonsmooth problems, sometimes it is not necessary that an exact subgradient/generalized Jacobian is at our disposal, but that a certain semismoothness property is fulfilled. In this paper we consider not only semismoothness of nonsmooth real- and vector-valued mappings, but also its interplay with the semismoothness$^*$ property for multifunctions. In particular, we are interested in the semismoothness of solution maps to parametric semismooth$^*$ inclusions. Our results are expressed in terms of suitable generalized derivatives of the set-valued part, i.e., by limiting coderivatives or by SC (subspace containing) derivatives. As a byproduct we identify a class of multifunctions having the remarkable property that they are strictly proto-differentiable almost everywhere (with respect to some Hausdorff measure) on their graph.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14637v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>H. Gfrerer, J. V. Outrata</dc:creator>
    </item>
    <item>
      <title>Decision-Focused Forecasting: Decision Losses for Multistage Optimisation</title>
      <link>https://arxiv.org/abs/2405.14719</link>
      <description>arXiv:2405.14719v1 Announce Type: new 
Abstract: Decision-focused learning has emerged as a promising approach for decision making under uncertainty by training the upstream predictive aspect of the pipeline with respect to the quality of the downstream decisions. Most existing work has focused on single stage problems. Many real-world decision problems are more appropriately modelled using multistage optimisation as contextual information such as prices or demand is revealed over time and decisions now have a bearing on future decisions. We propose decision-focused forecasting, a multiple-implicitlayer model which in its training accounts for the intertemporal decision effects of forecasts using differentiable optimisation. The recursive model reflects a fully differentiable multistage optimisation approach. We present an analysis of the gradients produced by this model showing the adjustments made to account for the state-path caused by forecasting. We demonstrate an application of the model to an energy storage arbitrage task and report that our model outperforms existing approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14719v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Egon Per\v{s}ak, Miguel F. Anjos</dc:creator>
    </item>
    <item>
      <title>Bagging Improves Generalization Exponentially</title>
      <link>https://arxiv.org/abs/2405.14741</link>
      <description>arXiv:2405.14741v1 Announce Type: new 
Abstract: Bagging is a popular ensemble technique to improve the accuracy of machine learning models. It hinges on the well-established rationale that, by repeatedly retraining on resampled data, the aggregated model exhibits lower variance and hence higher stability, especially for discontinuous base learners. In this paper, we provide a new perspective on bagging: By suitably aggregating the base learners at the parametrization instead of the output level, bagging improves generalization performances exponentially, a strength that is significantly more powerful than variance reduction. More precisely, we show that for general stochastic optimization problems that suffer from slowly (i.e., polynomially) decaying generalization errors, bagging can effectively reduce these errors to an exponential decay. Moreover, this power of bagging is agnostic to the solution schemes, including common empirical risk minimization, distributionally robust optimization, and various regularizations. We demonstrate how bagging can substantially improve generalization performances in a range of examples involving heavy-tailed data that suffer from intrinsically slow rates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14741v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Huaqian Jie, Donghao Ying, Henry Lam, Wotao Yin</dc:creator>
    </item>
    <item>
      <title>Second order analysis for the optimal selection of time delays</title>
      <link>https://arxiv.org/abs/2405.14775</link>
      <description>arXiv:2405.14775v1 Announce Type: new 
Abstract: For a nonlinear ordinary differential equation with time delay, the differentiation of the solution with respect to the delay is investigated. Special emphasis is laid on the second-order derivative. The results are applied to an associated optimization problem for the time delay. A first- and second-order sensitivity analysis is performed including an adjoint calculus that avoids the second derivative of the state with respect to the delay.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14775v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Karl Kunisch, Fredi Troeltzsch</dc:creator>
    </item>
    <item>
      <title>An augmented Lagrangian trust-region method with inexact gradient evaluations to accelerate constrained optimization problems using model hyperreduction</title>
      <link>https://arxiv.org/abs/2405.14827</link>
      <description>arXiv:2405.14827v1 Announce Type: new 
Abstract: We present an augmented Lagrangian trust-region method to efficiently solve constrained optimization problems governed by large-scale nonlinear systems with application to partial differential equation-constrained optimization. At each major augmented Lagrangian iteration, the expensive optimization subproblem involving the full nonlinear system is replaced by an empirical quadrature-based hyperreduced model constructed on-the-fly. To ensure convergence of these inexact augmented Lagrangian subproblems, we develop a bound-constrained trust-region method that allows for inexact gradient evaluations, and specialize it to our specific setting that leverages hyperreduced models. This approach circumvents a traditional training phase because the models are built on-the-fly in accordance with the requirements of the trust-region convergence theory. Two numerical experiments (constrained aerodynamic shape design) demonstrate the convergence and efficiency of the proposed work. A speedup of 12.7x (for all computational costs, even costs traditionally considered "offline" such as snapshot collection and data compression) relative to a standard optimization approach that does not leverage model reduction is shown.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14827v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tianshu Wen, Matthew J. Zahr</dc:creator>
    </item>
    <item>
      <title>Accelerated Evaluation of Ollivier-Ricci Curvature Lower Bounds: Bridging Theory and Computation</title>
      <link>https://arxiv.org/abs/2405.13302</link>
      <description>arXiv:2405.13302v1 Announce Type: cross 
Abstract: Curvature serves as a potent and descriptive invariant, with its efficacy validated both theoretically and practically within graph theory. We employ a definition of generalized Ricci curvature proposed by Ollivier, which Lin and Yau later adapted to graph theory, known as Ollivier-Ricci curvature (ORC). ORC measures curvature using the Wasserstein distance, thereby integrating geometric concepts with probability theory and optimal transport. Jost and Liu previously discussed the lower bound of ORC by showing the upper bound of the Wasserstein distance. We extend the applicability of these bounds to discrete spaces with metrics on integers, specifically hypergraphs. Compared to prior work on ORC in hypergraphs by Coupette, Dalleiger, and Rieck, which faced computational challenges, our method introduces a simplified approach with linear computational complexity, making it particularly suitable for analyzing large-scale networks. Through extensive simulations and application to synthetic and real-world datasets, we demonstrate the significant improvements our method offers in evaluating ORC.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.13302v1</guid>
      <category>stat.ML</category>
      <category>cs.DM</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wonwoo Kang, Heehyun Park</dc:creator>
    </item>
    <item>
      <title>Randomized block coordinate descent method for linear ill-posed problems</title>
      <link>https://arxiv.org/abs/2405.13340</link>
      <description>arXiv:2405.13340v1 Announce Type: cross 
Abstract: Consider the linear ill-posed problems of the form $\sum_{i=1}^{b} A_i x_i =y$, where, for each $i$, $A_i$ is a bounded linear operator between two Hilbert spaces $X_i$ and ${\mathcal Y}$. When $b$ is huge, solving the problem by an iterative method using the full gradient at each iteration step is both time-consuming and memory insufficient. Although randomized block coordinate decent (RBCD) method has been shown to be an efficient method for well-posed large-scale optimization problems with a small amount of memory, there still lacks a convergence analysis on the RBCD method for solving ill-posed problems. In this paper, we investigate the convergence property of the RBCD method with noisy data under either {\it a priori} or {\it a posteriori} stopping rules. We prove that the RBCD method combined with an {\it a priori} stopping rule yields a sequence that converges weakly to a solution of the problem almost surely. We also consider the early stopping of the RBCD method and demonstrate that the discrepancy principle can terminate the iteration after finite many steps almost surely. For a class of ill-posed problems with special tensor product form, we obtain strong convergence results on the RBCD method. Furthermore, we consider incorporating the convex regularization terms into the RBCD method to enhance the detection of solution features. To illustrate the theory and the performance of the method, numerical simulations from the imaging modalities in computed tomography and compressive temporal imaging are reported.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.13340v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qinian Jin, Duo Liu</dc:creator>
    </item>
    <item>
      <title>Quantization dimensions of negative order</title>
      <link>https://arxiv.org/abs/2405.13387</link>
      <description>arXiv:2405.13387v1 Announce Type: cross 
Abstract: In this note, we investigate the possibility of defining meaningful upper and lower quantization dimensions for a compactly supported Borel probability measure of order $r$, also for negative values of $r$. To this end, we utilize the concept of partition functions, which generalizes the idea of the $L^{q}$-spectrum and, in this way, naturally extends the work in [M. Kesseb\"ohmer, A. Niemann, and S. Zhu. Quantization dimensions of probability measures via R\'enyi dimensions. $\textit{Trans. Amer. Math. Soc.}$ 376.7 (2023), 4661$\unicode{x2013}$4678]. In particular, we provide natural fractal geometric bounds as well as easily verifiable necessary conditions for the existence of the quantization dimensions. Exact asymptotics for the absolutely continuous case are also given.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.13387v1</guid>
      <category>math.PR</category>
      <category>math.FA</category>
      <category>math.MG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marc Kesseb\"ohmer, Aljoscha Niemann</dc:creator>
    </item>
    <item>
      <title>Local convergence of min-max algorithms to differentiable equilibrium on Riemannian manifold</title>
      <link>https://arxiv.org/abs/2405.13392</link>
      <description>arXiv:2405.13392v1 Announce Type: cross 
Abstract: We study min-max algorithms to solve zero-sum differentiable games on Riemannian manifold. The notions of differentiable Stackelberg equilibrium and differentiable Nash equilibrium in Euclidean space are generalized to Riemannian manifold, through an intrinsic definition which does not depend on the choice of local coordinate chart of manifold. We then provide sufficient conditions for the local convergence of the deterministic simultaneous algorithms $\tau$-GDA and $\tau$-SGA near such equilibrium, using a general methodology based on spectral analysis. These algorithms are extended with stochastic gradients and applied to the training of Wasserstein GAN. The discriminator of GAN is constructed from Lipschitz-continuous functions based on Stiefel manifold. We show numerically how the insights obtained from the local convergence analysis may lead to an improvement of GAN models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.13392v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sixin Zhang</dc:creator>
    </item>
    <item>
      <title>Unimodular polytopes and a new Heller-type bound on totally unimodular matrices via Seymour's decomposition theorem</title>
      <link>https://arxiv.org/abs/2405.13431</link>
      <description>arXiv:2405.13431v1 Announce Type: cross 
Abstract: We prove a sharp upper bound on the number of columns of a totally unimodular matrix with column sums $1$ which improves upon Heller's bound by a factor of $2$. The proof uses Seymour's decomposition theorem. Unimodular polytopes are lattice polytopes such that the vertices of every full-dimensional subsimplex form an affine lattice basis. This is a subclass of 0/1-polytopes and contains for instance edge polytopes of bipartite graphs. Our main result implies a sharp upper bound on the number of vertices of unimodular polytopes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.13431v1</guid>
      <category>math.CO</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Benjamin Nill</dc:creator>
    </item>
    <item>
      <title>Cascading-Tree Algorithm for the 0-1 Knapsack Problem (In Memory of Heiner M{\"u}ller-Merbach, a Former President of IFORS)</title>
      <link>https://arxiv.org/abs/2405.13450</link>
      <description>arXiv:2405.13450v1 Announce Type: cross 
Abstract: In operations research, the Knapsack Problem (KP) is one of the classical optimization problems that has been widely studied. The KP has several variants and, in this paper, we address the binary KP, where for a given knapsack (with limited capacity) as well as a number of items, each of them has its own weight (volume or cost) and value, the objective consists in finding a selection of items such that the total value of the selected items is maximized and the capacity limit of the knapsack is respected. In this paper, in memorial of Prof. Dr. Heiner M{\"u}ller-Merbach, a former president of IFORS, we address the binary KP and revisit a classical algorithm, named cascading-tree branch-and-bound algorithm, that was originally introduced by him in 1978. However, the algorithm is surprisingly absent from the scientific literature because the paper was published in a German journal. We carried out computational experiments in order to compare the algorithm versus some classic methods. The numerical results show the effectiveness of the interesting idea used in the cascading-tree algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.13450v1</guid>
      <category>cs.DS</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mahdi Moeini (ENSIIE), Daniel Schermer (TU Kaiserslautern), Oliver Wendt (TU Kaiserslautern)</dc:creator>
    </item>
    <item>
      <title>Network Inpainting via Optimal Transport</title>
      <link>https://arxiv.org/abs/2405.13520</link>
      <description>arXiv:2405.13520v1 Announce Type: cross 
Abstract: In this work, we present a novel tool for reconstructing networks from corrupted images. The reconstructed network is the result of a minimization problem that has a misfit term with respect to the observed data, and a physics-based regularizing term coming from the theory of optimal transport. Through a range of numerical tests, we demonstrate that our suggested approach can effectively rebuild the primary features of damaged networks, even when artifacts are present.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.13520v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Enrico Facca, Jan Martin Nordbotten, Erik Andreas Hanson</dc:creator>
    </item>
    <item>
      <title>Almost sure convergence rates of stochastic gradient methods under gradient domination</title>
      <link>https://arxiv.org/abs/2405.13592</link>
      <description>arXiv:2405.13592v1 Announce Type: cross 
Abstract: Stochastic gradient methods are among the most important algorithms in training machine learning problems. While classical assumptions such as strong convexity allow a simple analysis they are rarely satisfied in applications. In recent years, global and local gradient domination properties have shown to be a more realistic replacement of strong convexity. They were proved to hold in diverse settings such as (simple) policy gradient methods in reinforcement learning and training of deep neural networks with analytic activation functions. We prove almost sure convergence rates $f(X_n)-f^*\in o\big( n^{-\frac{1}{4\beta-1}+\epsilon}\big)$ of the last iterate for stochastic gradient descent (with and without momentum) under global and local $\beta$-gradient domination assumptions. The almost sure rates get arbitrarily close to recent rates in expectation. Finally, we demonstrate how to apply our results to the training task in both supervised and reinforcement learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.13592v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Simon Weissmann, Sara Klein, Wa\"iss Azizian, Leif D\"oring</dc:creator>
    </item>
    <item>
      <title>Upper and lower memory capacity bounds of transformers for next-token prediction</title>
      <link>https://arxiv.org/abs/2405.13718</link>
      <description>arXiv:2405.13718v1 Announce Type: cross 
Abstract: Given a sequence of tokens, such as words, the task of next-token prediction is to predict the next-token conditional probability distribution. Decoder-only transformers have become effective models for this task, but their properties are still not fully understood. In particular, the largest number of distinct context sequences that a decoder-only transformer can interpolate next-token distributions for has not been established. To fill this gap, we prove upper and lower bounds on this number, which are equal up to a multiplicative constant. We prove these bounds in the general setting where next-token distributions can be arbitrary as well as the empirical setting where they are calculated from a finite number of document sequences. Our lower bounds are for one-layer transformers and our proofs highlight an important injectivity property satisfied by self-attention. Furthermore, we provide numerical evidence that the minimal number of parameters for memorization is sufficient for being able to train the model to the entropy lower bound.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.13718v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liam Madden, Curtis Fox, Christos Thrampoulidis</dc:creator>
    </item>
    <item>
      <title>Memory capacity of three-layer neural networks with non-polynomial activations</title>
      <link>https://arxiv.org/abs/2405.13738</link>
      <description>arXiv:2405.13738v1 Announce Type: cross 
Abstract: The minimal number of neurons required for a feedforward neural network to interpolate $n$ generic input-output pairs from $\mathbb{R}^d\times \mathbb{R}$ is $\Theta(\sqrt{n})$. While previous results have shown that $\Theta(\sqrt{n})$ neurons are sufficient, they have been limited to logistic, Heaviside, and rectified linear unit (ReLU) as the activation function. Using a different approach, we prove that $\Theta(\sqrt{n})$ neurons are sufficient as long as the activation function is real analytic at a point and not a polynomial there. Thus, the only practical activation functions that our result does not apply to are piecewise polynomials. Importantly, this means that activation functions can be freely chosen in a problem-dependent manner without loss of interpolation power.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.13738v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liam Madden</dc:creator>
    </item>
    <item>
      <title>On the stability of second order gradient descent for time varying convex functions</title>
      <link>https://arxiv.org/abs/2405.13765</link>
      <description>arXiv:2405.13765v1 Announce Type: cross 
Abstract: Gradient based optimization algorithms deployed in Machine Learning (ML) applications are often analyzed and compared by their convergence rates or regret bounds. While these rates and bounds convey valuable information they don't always directly translate to stability guarantees. Stability and similar concepts, like robustness, will become ever more important as we move towards deploying models in real-time and safety critical systems. In this work we build upon the results in Gaudio et al. 2021 and Moreu and Annaswamy 2022 for second order gradient descent when applied to explicitly time varying cost functions and provide more general stability guarantees. These more general results can aid in the design and certification of these optimization schemes so as to help ensure safe and reliable deployment for real-time learning applications. We also hope that the techniques provided here will stimulate and cross-fertilize the analysis that occurs on the same algorithms from the online learning and stochastic optimization communities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.13765v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Travis E. Gibson, Sawal Acharya, Anjali Parashar, Joseph E. Gaudio, Anurdha M. Annaswamy</dc:creator>
    </item>
    <item>
      <title>Identifiability of Differential-Algebraic Systems</title>
      <link>https://arxiv.org/abs/2405.13818</link>
      <description>arXiv:2405.13818v1 Announce Type: cross 
Abstract: Data-driven modeling of dynamical systems often faces numerous data-related challenges. A fundamental requirement is the existence of a unique set of parameters for a chosen model structure, an issue commonly referred to as identifiability. Although this problem is well studied for ordinary differential equations (ODEs), few studies have focused on the more general class of systems described by differential-algebraic equations (DAEs). Examples of DAEs include dynamical systems with algebraic equations representing conservation laws or approximating fast dynamics. This work introduces a novel identifiability test for models characterized by nonlinear DAEs. Unlike previous approaches, our test only requires prior knowledge of the system equations and does not need nonlinear transformation, index reduction, or numerical integration of the DAEs. We employed our identifiability analysis across a diverse range of DAE models, illustrating how system identifiability depends on the choices of sensors, experimental conditions, and model structures. Given the added challenges involved in identifying DAEs when compared to ODEs, we anticipate that our findings will have broad applicability and contribute significantly to the development and validation of data-driven methods for DAEs and other structure-preserving models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.13818v1</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arthur N. Montanari, Fran\c{c}ois Lamoline, Robert Bereza, Jorge Gon\c{c}alves</dc:creator>
    </item>
    <item>
      <title>Algebraic Conditions for Stability in Runge-Kutta Methods and Their Certification via Semidefinite Programming</title>
      <link>https://arxiv.org/abs/2405.13921</link>
      <description>arXiv:2405.13921v1 Announce Type: cross 
Abstract: In this work, we present approaches to rigorously certify $A$- and $A(\alpha)$-stability in Runge-Kutta methods through the solution of convex feasibility problems defined by linear matrix inequalities. We adopt two approaches. The first is based on sum-of-squares programming applied to the Runge-Kutta $E$-polynomial and is applicable to both $A$- and $A(\alpha)$-stability. In the second, we sharpen the algebraic conditions for $A$-stability of Cooper, Scherer, T{\"u}rke, and Wendler to incorporate the Runge-Kutta order conditions. We demonstrate how the theoretical improvement enables the practical use of these conditions for certification of $A$-stability within a computational framework. We then use both approaches to obtain rigorous certificates of stability for several diagonally implicit schemes devised in the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.13921v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Austin Juhl, David Shirokoff</dc:creator>
    </item>
    <item>
      <title>Adversarial Training of Two-Layer Polynomial and ReLU Activation Networks via Convex Optimization</title>
      <link>https://arxiv.org/abs/2405.14033</link>
      <description>arXiv:2405.14033v1 Announce Type: cross 
Abstract: Training neural networks which are robust to adversarial attacks remains an important problem in deep learning, especially as heavily overparameterized models are adopted in safety-critical settings. Drawing from recent work which reformulates the training problems for two-layer ReLU and polynomial activation networks as convex programs, we devise a convex semidefinite program (SDP) for adversarial training of polynomial activation networks via the S-procedure. We also derive a convex SDP to compute the minimum distance from a correctly classified example to the decision boundary of a polynomial activation network. Adversarial training for two-layer ReLU activation networks has been explored in the literature, but, in contrast to prior work, we present a scalable approach which is compatible with standard machine libraries and GPU acceleration. The adversarial training SDP for polynomial activation networks leads to large increases in robust test accuracy against $\ell^\infty$ attacks on the Breast Cancer Wisconsin dataset from the UCI Machine Learning Repository. For two-layer ReLU networks, we leverage our scalable implementation to retrain the final two fully connected layers of a Pre-Activation ResNet-18 model on the CIFAR-10 dataset. Our 'robustified' model achieves higher clean and robust test accuracies than the same architecture trained with sharpness-aware minimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14033v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniel Kuelbs, Sanjay Lall, Mert Pilanci</dc:creator>
    </item>
    <item>
      <title>Actively Learning Combinatorial Optimization Using a Membership Oracle</title>
      <link>https://arxiv.org/abs/2405.14090</link>
      <description>arXiv:2405.14090v1 Announce Type: cross 
Abstract: We consider solving a combinatorial optimization problem with an unknown linear constraint using a membership oracle that, given a solution, determines whether it is feasible or infeasible with absolute certainty. The goal of the decision maker is to find the best possible solution subject to a budget on the number of oracle calls. Inspired by active learning based on Support Vector Machines (SVMs), we adapt a classical framework in order to solve the problem by learning and exploiting a surrogate linear constraint. The resulting new framework includes training a linear separator on the labeled points and selecting new points to be labeled, which is achieved by applying a sampling strategy and solving a 0-1 integer linear program. Following the active learning literature, one can consider using SVM as a linear classifier and the information-based sampling strategy known as Simple margin. We improve on both sides: we propose an alternative sampling strategy based on mixed-integer quadratic programming and a linear separation method inspired by an algorithm for convex optimization in the oracle model. We conduct experiments on the pure knapsack problem and on a college study plan problem from the literature to show how different linear separation methods and sampling strategies influence the quality of the results in terms of objective value.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14090v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rosario Messana, Rui Chen, Andrea Lodi</dc:creator>
    </item>
    <item>
      <title>A fast algorithm to minimize prediction loss of the optimal solution in inverse optimization problem of MILP</title>
      <link>https://arxiv.org/abs/2405.14273</link>
      <description>arXiv:2405.14273v1 Announce Type: cross 
Abstract: This paper tackles the problem of minimizing the prediction loss of the optimal solution (PLS) of the MILP with given data, which is one of the inverse optimization problems. While existing methods can approximately solve this problem, their implementation in the high-dimensional case to minimize the PLS is computationally expensive because they are inefficient in reducing the prediction loss of weights (PLW). We propose a fast algorithm for minimizing the PLS of MILP. To demonstrate this property, we attribute the problem of minimizing the PLS to that of minimizing the suboptimality loss (SL), which is convex. If the PLS does not vanish, we can adapt the SL to have the estimated loss (SPO loss) with a positive lower bound, which enables us to evaluate the PLW. Consequently, we prove that the proposed algorithm can effectively reduce the PLW and achieve the minimum value of PLS. Our numerical experiments demonstrated that our algorithm successfully achieved the minimum PLS. Compared to existing methods, our algorithm exhibited a smaller dimensionality effect and minimized the PLS in less than 1/7 the number of iterations. Especially in high dimensions, our algorithm significantly improved the PLS by more than two orders of magnitude compared to existing algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14273v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Akira Kitaoka</dc:creator>
    </item>
    <item>
      <title>Computing the Bias of Constant-step Stochastic Approximation with Markovian Noise</title>
      <link>https://arxiv.org/abs/2405.14285</link>
      <description>arXiv:2405.14285v1 Announce Type: cross 
Abstract: We study stochastic approximation algorithms with Markovian noise and constant step-size $\alpha$. We develop a method based on infinitesimal generator comparisons to study the bias of the algorithm, which is the expected difference between $\theta_n$ -- the value at iteration $n$ -- and $\theta^*$ -- the unique equilibrium of the corresponding ODE. We show that, under some smoothness conditions, this bias is of order $O(\alpha)$. Furthermore, we show that the time-averaged bias is equal to $\alpha V + O(\alpha^2)$, where $V$ is a constant characterized by a Lyapunov equation, showing that $\esp{\bar{\theta}_n} \approx \theta^*+V\alpha + O(\alpha^2)$, where $\bar{\theta}_n=(1/n)\sum_{k=1}^n\theta_k$ is the Polyak-Ruppert average. We also show that $\bar{\theta}_n$ converges with high probability around $\theta^*+\alpha V$. We illustrate how to combine this with Richardson-Romberg extrapolation to derive an iterative scheme with a bias of order $O(\alpha^2)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14285v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Sebastian Allmeier, Nicolas Gast</dc:creator>
    </item>
    <item>
      <title>An 808 Line Phasor-Based Ddehomogenisation Matlab Code For Multi-Scale Topology Optimisation</title>
      <link>https://arxiv.org/abs/2405.14321</link>
      <description>arXiv:2405.14321v1 Announce Type: cross 
Abstract: This work presents an 808-line Matlab educational code for combined multi-scale topology optimisation and phasor-based dehomogenisation titled deHomTop808. The multi-scale formulation utilises homogenisation of optimal microstructures to facilitate efficient coarse-scale optimisation. Dehomogenisation allows for a high-resolution single-scale reconstruction of the optimised multi-scale structure, achieving minor losses in structural performance, at a fraction of the computational cost, compared to its large-scale topology optimisation counterpart. The presented code utilises stiffness optimal Rank-2 microstructures to minimise the compliance of a single-load case problem, subject to a volume fraction constraint. By exploiting the inherent efficiency benefits of the phasor-based dehomogenisation procedure, on-the-fly dehomogenisation to a single-scale structure is obtained. The presented code includes procedures for structural verification of the final dehomogenised structure by comparison to the multi-scale solution. The code is introduced in terms of the underlying theory and its major components, including examples and potential extensions, and can be downloaded from https://github.com/peterdorffler/deHomTop808.git.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14321v1</guid>
      <category>cs.MS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rebekka Varum Woldseth, Ole Sigmund, Peter D{\o}rffler Ladegaard Jensen</dc:creator>
    </item>
    <item>
      <title>Neural Collapse versus Low-rank Bias: Is Deep Neural Collapse Really Optimal?</title>
      <link>https://arxiv.org/abs/2405.14468</link>
      <description>arXiv:2405.14468v1 Announce Type: cross 
Abstract: Deep neural networks (DNNs) exhibit a surprising structure in their final layer known as neural collapse (NC), and a growing body of works has currently investigated the propagation of neural collapse to earlier layers of DNNs -- a phenomenon called deep neural collapse (DNC). However, existing theoretical results are restricted to special cases: linear models, only two layers or binary classification. In contrast, we focus on non-linear models of arbitrary depth in multi-class classification and reveal a surprising qualitative shift. As soon as we go beyond two layers or two classes, DNC stops being optimal for the deep unconstrained features model (DUFM) -- the standard theoretical framework for the analysis of collapse. The main culprit is a low-rank bias of multi-layer regularization schemes: this bias leads to optimal solutions of even lower rank than the neural collapse. We support our theoretical findings with experiments on both DUFM and real data, which show the emergence of the low-rank structure in the solution found by gradient descent.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14468v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Peter S\'uken\'ik, Marco Mondelli, Christoph Lampert</dc:creator>
    </item>
    <item>
      <title>Global Behavior of Learning Dynamics in Zero-Sum Games with Memory Asymmetry</title>
      <link>https://arxiv.org/abs/2405.14546</link>
      <description>arXiv:2405.14546v1 Announce Type: cross 
Abstract: This study examines the global behavior of dynamics in learning in games between two players, X and Y. We consider the simplest situation for memory asymmetry between two players: X memorizes the other Y's previous action and uses reactive strategies, while Y has no memory. Although this memory complicates the learning dynamics, we discover two novel quantities that characterize the global behavior of such complex dynamics. One is an extended Kullback-Leibler divergence from the Nash equilibrium, a well-known conserved quantity from previous studies. The other is a family of Lyapunov functions of X's reactive strategy. These two quantities capture the global behavior in which X's strategy becomes more exploitative, and the exploited Y's strategy converges to the Nash equilibrium. Indeed, we theoretically prove that Y's strategy globally converges to the Nash equilibrium in the simplest game equipped with an equilibrium in the interior of strategy spaces. Furthermore, our experiments also suggest that this global convergence is universal for more advanced zero-sum games than the simplest game. This study provides a novel characterization of the global behavior of learning in games through a couple of indicators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14546v1</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <category>math.OC</category>
      <category>nlin.CD</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuma Fujimoto, Kaito Ariu, Kenshi Abe</dc:creator>
    </item>
    <item>
      <title>Policy Gradient Methods for Risk-Sensitive Distributional Reinforcement Learning with Provable Convergence</title>
      <link>https://arxiv.org/abs/2405.14749</link>
      <description>arXiv:2405.14749v1 Announce Type: cross 
Abstract: Risk-sensitive reinforcement learning (RL) is crucial for maintaining reliable performance in many high-stakes applications. While most RL methods aim to learn a point estimate of the random cumulative cost, distributional RL (DRL) seeks to estimate the entire distribution of it. The distribution provides all necessary information about the cost and leads to a unified framework for handling various risk measures in a risk-sensitive setting. However, developing policy gradient methods for risk-sensitive DRL is inherently more complex as it pertains to finding the gradient of a probability measure. This paper introduces a policy gradient method for risk-sensitive DRL with general coherent risk measures, where we provide an analytical form of the probability measure's gradient. We further prove the local convergence of the proposed algorithm under mild smoothness assumptions. For practical use, we also design a categorical distributional policy gradient algorithm (CDPG) based on categorical distributional policy evaluation and trajectory-based gradient estimation. Through experiments on a stochastic cliff-walking environment, we illustrate the benefits of considering a risk-sensitive setting in DRL.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14749v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Minheng Xiao, Xian Yu, Lei Ying</dc:creator>
    </item>
    <item>
      <title>Exploiting the polyhedral geometry of stochastic linear bilevel programming</title>
      <link>https://arxiv.org/abs/2211.02268</link>
      <description>arXiv:2211.02268v3 Announce Type: replace 
Abstract: We study linear bilevel programming problems whose lower-level objective is given by a random cost vector with known distribution. We consider the case where this distribution is nonatomic, allowing to reformulate the problem of the leader using the Bayesian approach in the sense of Salas and Svensson (2023), with a decision-dependent distribution that concentrates on the vertices of the feasible set of the follower's problem. We call this a vertex-supported belief. We prove that this formulation is piecewise affine over the so-called chamber complex of the feasible set of the high-point relaxation. We propose two algorithmic approaches to solve general problems enjoying this last property. The first one is based on enumerating the vertices of the chamber complex. This approach is not scalable, but we present it as a computational baseline and for its theoretical interest. The second one is a Monte-Carlo approximation scheme based on the fact that randomly drawn points of the domain lie, with probability 1, in the interior of full-dimensional chambers, where the problem (restricted to this chamber) can be reduced to a linear program. Finally, we evaluate these methods through computational experiments showing both approaches' advantages and challenges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.02268v3</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gonzalo Mu\~noz, David Salas, Anton Svensson</dc:creator>
    </item>
    <item>
      <title>Efficient Separation of RLT Cuts for Implicit and Explicit Bilinear Terms</title>
      <link>https://arxiv.org/abs/2211.13545</link>
      <description>arXiv:2211.13545v2 Announce Type: replace 
Abstract: The reformulation-linearization technique (RLT) is a prominent approach to constructing tight linear relaxations of non-convex continuous and mixed-integer optimization problems. The goal of this paper is to extend the applicability and improve the performance of RLT for bilinear product relations. First, a method for detecting bilinear product relations implicitly contained in mixed-integer linear programs is developed based on analyzing linear constraints with binary variables, thus enabling the application of bilinear RLT to a new class of problems. Our second contribution addresses the high computational cost of RLT cut separation, which presents one of the major difficulties in applying RLT efficiently in practice. We propose a new RLT cutting plane separation algorithm which identifies combinations of linear constraints and bound factors that are expected to yield an inequality that is violated by the current relaxation solution. This algorithm is applicable to RLT cuts generated for all types of bilinear terms, including but not limited to the detected implicit products. A detailed computational study based on implementations in two solvers evaluates the performance impact of the proposed methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.13545v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ksenia Bestuzheva, Ambros Gleixner, Tobias Achterberg</dc:creator>
    </item>
    <item>
      <title>Sketch-and-Project Meets Newton Method: Global $\mathcal O(k^{-2})$ Convergence with Low-Rank Updates</title>
      <link>https://arxiv.org/abs/2305.13082</link>
      <description>arXiv:2305.13082v3 Announce Type: replace 
Abstract: In this paper, we propose the first sketch-and-project Newton method with fast $\mathcal O(k^{-2})$ global convergence rate for self-concordant functions. Our method, SGN, can be viewed in three ways: i) as a sketch-and-project algorithm projecting updates of Newton method, ii) as a cubically regularized Newton ethod in sketched subspaces, and iii) as a damped Newton method in sketched subspaces. SGN inherits best of all three worlds: cheap iteration costs of sketch-and-project methods, state-of-the-art $\mathcal O(k^{-2})$ global convergence rate of full-rank Newton-like methods and the algorithm simplicity of damped Newton methods. Finally, we demonstrate its comparable empirical performance to baseline algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.13082v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Slavom\'ir Hanzely</dc:creator>
    </item>
    <item>
      <title>Learning Decision-Focused Uncertainty Sets in Robust Optimization</title>
      <link>https://arxiv.org/abs/2305.19225</link>
      <description>arXiv:2305.19225v3 Announce Type: replace 
Abstract: We propose a data-driven technique to automatically learn the uncertainty sets in robust optimization. Our method reshapes the uncertainty sets by minimizing the expected performance across a family of problems subject to guaranteeing constraint satisfaction. Our approach is very flexible and can learn a wide variety of uncertainty sets while preserving tractability. We solve the constrained learning problem using a stochastic augmented Lagrangian method that relies on differentiating the solutions of the robust optimization problems with respect to the parameters of the uncertainty set. Due to the nonsmooth and nonconvex nature of the augmented Lagrangian function, we apply the nonsmooth conservative implicit function theorem to establish convergence to a critical point, which is a feasible solution of the constrained problem under mild assumptions. Using empirical process theory, we show finite-sample probabilistic guarantees of constraint satisfaction for the resulting solutions. Numerical experiments show that our method outperforms traditional approaches in robust and distributionally robust optimization in terms of out-of-sample performance and constraint satisfaction guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.19225v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Irina Wang, Cole Becker, Bart Van Parys, Bartolomeo Stellato</dc:creator>
    </item>
    <item>
      <title>Entropic mean-field min-max problems via Best Response flow</title>
      <link>https://arxiv.org/abs/2306.03033</link>
      <description>arXiv:2306.03033v2 Announce Type: replace 
Abstract: We investigate the convergence properties of a continuous-time optimization method, the \textit{Mean-Field Best Response} flow, for solving convex-concave min-max games with entropy regularization. We introduce suitable Lyapunov functions to establish exponential convergence to the unique mixed Nash equilibrium. Additionally, we demonstrate the convergence of the fictitious play flow as a by-product of our analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.03033v2</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Razvan-Andrei Lascu, Mateusz B. Majka, {\L}ukasz Szpruch</dc:creator>
    </item>
    <item>
      <title>A Robust Optimization Model for Nonlinear Support Vector Machine</title>
      <link>https://arxiv.org/abs/2306.06223</link>
      <description>arXiv:2306.06223v2 Announce Type: replace 
Abstract: In this paper, we present new optimization models for Support Vector Machine (SVM), with the aim of separating data points in two or more classes. The classification task is performed by means of nonlinear classifiers induced by kernel functions. Along with a deterministic formulation in which data are assumed to be perfectly known, we propose a robust extension with bounded-by-norm uncertainty sets. Robust optimization techniques allow to protect the models against uncertainties arising during the collection of real-world observations. Closed-form expressions for the bounds of the uncertainty sets in the feature space for typically used kernel functions have been derived. Extensive numerical results on real-world datasets show the benefits of the proposed classifiers in comparison with various alternatives in the SVM literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.06223v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Francesca Maggioni, Andrea Spinelli</dc:creator>
    </item>
    <item>
      <title>CMA Light: a novel Minibatch Algorithm for large-scale non convex finite sum optimization</title>
      <link>https://arxiv.org/abs/2307.15775</link>
      <description>arXiv:2307.15775v2 Announce Type: replace 
Abstract: The supervised training of a deep neural network on a given dataset consists in the unconstrained minimization of the finite sum of continuously differentiable functions, commonly referred to as loss with respect to the samples. These functions depend on the network parameters and most of the times are non-convex. We develop CMA Light, a globally convergent mini-batch gradient method to tackle this problem. We consider the recently introduced Controlled Minibatch Algorithm (CMA) framework and we overcome its main bottleneck, removing the need for at least one evaluation of the whole objective function per iteration. We prove globally convergence of CMA Light under mild assumptions and we discuss extensive computational results on the same experimental test-bed used for CMA, showing that CMA Light requires less computational effort than most of the state-of-the-art optimizers. Eventually, we present early results on a large-scale Image Classification task.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.15775v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Corrado Coppola, Giampaolo Liuzzi, Laura Palagi</dc:creator>
    </item>
    <item>
      <title>Platform Design in Curated Dating Markets</title>
      <link>https://arxiv.org/abs/2308.02584</link>
      <description>arXiv:2308.02584v3 Announce Type: replace 
Abstract: Motivated by online dating apps, we study how to select subset of profiles to show to each user in each period in a two-sided matching platform. Users on each side observe the profiles set by the platform and decide which of them to like. A match occurs if and only if two users mutually like each other, potentially in different periods. The goal of the platform is to maximize the total expected number of matches. We study different platform designs, varying (i) how users interact with each other, i.e., whether one or both sides of the market can initiate an interaction, and (ii) the timing of matches, i.e., whether the platform allows non-sequential matches in addition to sequential ones. We focus on the case with two periods and study the performance of different approaches. First, we show that algorithms that exploit the submodularity of the problem and properties of its feasible region can achieve constant factor approximation guarantees that depend on the platform design, ranging from $1-1/e$ to $1/3$. Finally, we show that the Dating Heuristic (DH) (Rios et al., 2023), which is commonly used and achieves good performance in practice, provides an approximation guarantee of $1-1/e$ for all platform designs. We show theoretically and empirically that the performance of the DH is robust to the platform design. Our simulation results -- using real data from our industry partner -- also show that platforms using a one-directional design should initiate interactions with the side that leads to the smallest expected backlog per profile displayed, balancing size and selectivity. Moreover, we find that a one-directional design can lead to at least half of the matches obtained with a two-directional design. Finally, our results show that avoiding non-sequential matches has no sizable effect, regardless of the platform design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.02584v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ignacio Rios, Alfredo Torrico</dc:creator>
    </item>
    <item>
      <title>Two-timescale Derivative Free Optimization for Performative Prediction with Markovian Data</title>
      <link>https://arxiv.org/abs/2310.05792</link>
      <description>arXiv:2310.05792v4 Announce Type: replace 
Abstract: This paper studies the performative prediction problem where a learner aims to minimize the expected loss with a decision-dependent data distribution. Such setting is motivated when outcomes can be affected by the prediction model, e.g., in strategic classification. We consider a state-dependent setting where the data distribution evolves according to an underlying controlled Markov chain. We focus on stochastic derivative free optimization (DFO) where the learner is given access to a loss function evaluation oracle with the above Markovian data. We propose a two-timescale DFO($\lambda$) algorithm that features (i) a sample accumulation mechanism that utilizes every observed sample to estimate the overall gradient of performative risk, and (ii) a two-timescale diminishing step size that balances the rates of DFO updates and bias reduction. Under a general non-convex optimization setting, we show that DFO($\lambda$) requires ${\cal O}( 1 /\epsilon^3)$ samples (up to a log factor) to attain a near-stationary solution with expected squared gradient norm less than $\epsilon &gt; 0$. Numerical experiments verify our analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.05792v4</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haitong Liu, Qiang Li, Hoi-To Wai</dc:creator>
    </item>
    <item>
      <title>A Practical and Optimal First-Order Method for Large-Scale Convex Quadratic Programming</title>
      <link>https://arxiv.org/abs/2311.07710</link>
      <description>arXiv:2311.07710v3 Announce Type: replace 
Abstract: Convex quadratic programming (QP) is an important class of optimization problem with wide applications in practice. The classic QP solvers are based on either simplex or barrier method, both of which suffer from the scalability issue because their computational bottleneck is solving linear equations. In this paper, we design and analyze a first-order method for QP, called restarted accelerated primal-dual hybrid gradient (rAPDHG), whose computational bottleneck is matrix-vector multiplication. We show that rAPDHG has a linear convergence rate to an optimal solution when solving QP, and the obtained linear rate is optimal among a wide class of primal-dual methods. Furthermore, we connect the linear rate with a sharpness constant of the KKT system of QP, which is a standard quantity to measure the hardness of a continuous optimization problem. Numerical experiments demonstrate that both restarts and acceleration can significantly improve the performance of the algorithm. Lastly, we present PDQP.jl, an open-source solver based on rAPDHG that can be run on both GPU and CPU. With a numerical comparison with SCS and OSQP on standard QP benchmark sets and large-scale synthetic QP instances, we demonstrate the effectiveness of rAPDHG for solving QP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.07710v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haihao Lu, Jinwen Yang</dc:creator>
    </item>
    <item>
      <title>Exploring the sensing power of mixed vehicle fleets</title>
      <link>https://arxiv.org/abs/2311.15237</link>
      <description>arXiv:2311.15237v4 Announce Type: replace 
Abstract: Vehicle-based mobile sensing, also known as drive-by sensing, efficiently surveys urban environments at low costs by leveraging the mobility of urban vehicles. While recent studies have focused on drive-by sensing for fleets of a single type, our work explores the sensing power and cost-effectiveness of a mixed fleet that consists of vehicles with distinct and complementary mobility patterns. We formulate the drive-by sensing coverage (DSC) problem, proposing a method to quantify sensing utility and an optimization procedure that determines fleet composition, sensor allocation, and vehicle routing for a given budget. Our air quality sensing case study in Longquanyi District (Chengdu, China) demonstrates that using a mixed fleet enhances sensing utilities and achieves close approximations to the target sensing distribution at a lower cost. Generalizing these insights to two additional real-world networks, our regression analysis uncovers key factors influencing the sensing power of mixed fleets. This research provides quantitative and managerial insights into drive-by sensing, showcasing a positive externality of urban transport activities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.15237v4</guid>
      <category>math.OC</category>
      <category>cs.NI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ke Han (Marco), Wen Ji (Marco),  Yu (Marco),  Nie, Zhexian Li, Shenglin Liu</dc:creator>
    </item>
    <item>
      <title>PySCIPOpt-ML: Embedding Trained Machine Learning Models into Mixed-Integer Programs</title>
      <link>https://arxiv.org/abs/2312.08074</link>
      <description>arXiv:2312.08074v2 Announce Type: replace 
Abstract: A standard tool for modelling real-world optimisation problems is mixed-integer programming (MIP). However, for many of these problems, information about the relationships between variables is either incomplete or highly complex, making it difficult or even impossible to model the problem directly. To overcome these hurdles, machine learning (ML) predictors are often used to represent these relationships and are then embedded in the MIP as surrogate models. Due to the large amount of available ML frameworks and the complexity of many ML predictors, formulating such predictors into MIPs is a highly non-trivial task. In this paper, we introduce PySCIPOpt-ML, an open-source tool for the automatic formulation and embedding of trained ML predictors into MIPs. By directly interfacing with a broad range of commonly used ML frameworks and an open-source MIP solver, PySCIPOpt-ML provides a way to easily integrate ML constraints into optimisation problems. Alongside PySCIPOpt-ML, we introduce, SurrogateLIB, a library of MIP instances with embedded ML constraints, and present computational results over SurrogateLIB, providing intuition on the scale of ML predictors that can be practically embedded. The project is available at https://github.com/Opt-Mucca/PySCIPOpt-ML.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.08074v2</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mark Turner, Antonia Chmiela, Thorsten Koch, Michael Winkler</dc:creator>
    </item>
    <item>
      <title>Optimal Convergence Rate for Mirror Descent Methods with special Time-Varying Step Sizes Rules</title>
      <link>https://arxiv.org/abs/2401.04754</link>
      <description>arXiv:2401.04754v5 Announce Type: replace 
Abstract: In this paper, the optimal convergence rate $O\left(N^{-1/2}\right)$ (where $N$ is the total number of iterations performed by the algorithm), without the presence of a logarithmic factor, is proved for mirror descent algorithms with special time-varying step sizes, for solving classical constrained non-smooth problems, problems with the composite model and problems with non-smooth functional (inequality types) constraints. The proven result is an improvement on the well-known rate $O\left(\log (N) N^{-1/2}\right)$ for the mirror descent algorithms with the time-varying step sizes under consideration. It was studied a new weighting scheme assigns smaller weights to the initial points and larger weights to the most recent points. This scheme improves the convergence rate of the considered mirror descent methods, which in the conducted numerical experiments outperform the other methods providing a better solution in all the considered test problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.04754v5</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohammad Alkousa, Fedor Stonyakin, Asmaa Abdo, Mohammad Alcheikh</dc:creator>
    </item>
    <item>
      <title>Convergence of the deep BSDE method for stochastic control problems formulated through the stochastic maximum principle</title>
      <link>https://arxiv.org/abs/2401.17472</link>
      <description>arXiv:2401.17472v2 Announce Type: replace 
Abstract: It is well-known that decision-making problems from stochastic control can be formulated by means of a forward-backward stochastic differential equation (FBSDE). Recently, the authors of Ji et al. 2022 proposed an efficient deep learning algorithm based on the stochastic maximum principle (SMP). In this paper, we provide a convergence result for this deep SMP-BSDE algorithm and compare its performance with other existing methods. In particular, by adopting a strategy as in Han and Long 2020, we derive a-posteriori estimate, and show that the total approximation error can be bounded by the value of the loss functional and the discretization error. We present numerical examples for high-dimensional stochastic control problems, both in case of drift- and diffusion control, which showcase superior performance compared to existing algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.17472v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>q-fin.CP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhipeng Huang, Balint Negyesi, Cornelis W. Oosterlee</dc:creator>
    </item>
    <item>
      <title>Data-Driven Performance Guarantees for Classical and Learned Optimizers</title>
      <link>https://arxiv.org/abs/2404.13831</link>
      <description>arXiv:2404.13831v2 Announce Type: replace 
Abstract: We introduce a data-driven approach to analyze the performance of continuous optimization algorithms using generalization guarantees from statistical learning theory. We study classical and learned optimizers to solve families of parametric optimization problems. We build generalization guarantees for classical optimizers, using a sample convergence bound, and for learned optimizers, using the Probably Approximately Correct (PAC)-Bayes framework. To train learned optimizers, we use a gradient-based algorithm to directly minimize the PAC-Bayes upper bound. Numerical experiments in signal processing, control, and meta-learning showcase the ability of our framework to provide strong generalization guarantees for both classical and learned optimizers given a fixed budget of iterations. For classical optimizers, our bounds are much tighter than those that worst-case guarantees provide. For learned optimizers, our bounds outperform the empirical outcomes observed in their non-learned counterparts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13831v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Rajiv Sambharya, Bartolomeo Stellato</dc:creator>
    </item>
    <item>
      <title>Real Stability and Log Concavity are coNP-Hard</title>
      <link>https://arxiv.org/abs/2405.00162</link>
      <description>arXiv:2405.00162v2 Announce Type: replace 
Abstract: Real-stable, Lorentzian, and log-concave polynomials are well-studied classes of polynomials, and have been powerful tools in resolving several conjectures. We show that the problems of deciding whether a polynomial of fixed degree is real stable or log concave are coNP-hard. On the other hand, while all homogeneous real-stable polynomials are Lorentzian and all Lorentzian polynomials are log concave on the positive orthant, the problem of deciding whether a polynomial of fixed degree is Lorentzian can be solved in polynomial time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00162v2</guid>
      <category>math.OC</category>
      <category>cs.CC</category>
      <category>math.CO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tracy Chin</dc:creator>
    </item>
    <item>
      <title>Subgradient Convergence Implies Subdifferential Convergence on Weakly Convex Functions: With Uniform Rates Guarantees</title>
      <link>https://arxiv.org/abs/2405.10289</link>
      <description>arXiv:2405.10289v2 Announce Type: replace 
Abstract: In nonsmooth, nonconvex stochastic optimization, understanding the uniform convergence of subdifferential mappings is crucial for analyzing stationary points of sample average approximations of risk as they approach the population risk. Yet, characterizing this convergence remains a fundamental challenge.
  This work introduces a novel perspective by connecting the uniform convergence of subdifferential mappings to that of subgradient mappings as empirical risk converges to the population risk. We prove that, for stochastic weakly-convex objectives, and within any open set, a uniform bound on the convergence of subgradients -- chosen arbitrarily from the corresponding subdifferential sets -- translates to a uniform bound on the convergence of the subdifferential sets itself, measured by the Hausdorff metric.
  Using this technique, we derive uniform convergence rates for subdifferential sets of stochastic convex-composite objectives. Our results do not rely on key distributional assumptions in the literature, which require the population and finite sample subdifferentials to be continuous in the Hausdorff metric, yet still provide tight convergence rates. These guarantees lead to new insights into the nonsmooth landscapes of such objectives within finite samples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10289v2</guid>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Feng Ruan</dc:creator>
    </item>
    <item>
      <title>Chordal-NMF with Riemannian Multiplicative Update</title>
      <link>https://arxiv.org/abs/2405.12823</link>
      <description>arXiv:2405.12823v2 Announce Type: replace 
Abstract: Nonnegative Matrix Factorization (NMF) is the problem of approximating a given nonnegative matrix M through the conic combination of two nonnegative low-rank matrices W and H. Traditionally NMF is tackled by optimizing a specific objective function evaluating the quality of the approximation. This assessment is often done based on the Frobenius norm. In this study, we argue that the Frobenius norm as the "point-to-point" distance may not always be appropriate. Due to the nonnegative combination resulting in a polyhedral cone, this conic perspective of NMF may not naturally align with conventional point-to-point distance measures. Hence, a ray-to-ray chordal distance is proposed as an alternative way of measuring the discrepancy between M and WH. This measure is related to the Euclidean distance on the unit sphere, motivating us to employ nonsmooth manifold optimization approaches.
  We apply Riemannian optimization technique to solve chordal-NMF by casting it on a manifold. Unlike existing works on Riemannian optimization that require the manifold to be smooth, the nonnegativity in chordal-NMF is a non-differentiable manifold. We propose a Riemannian Multiplicative Update (RMU) that preserves the convergence properties of Riemannian gradient descent without breaking the smoothness condition on the manifold.
  We showcase the effectiveness of the Chordal-NMF on synthetic datasets as well as real-world multispectral images.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12823v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Flavia Esposito, Andersen Ang</dc:creator>
    </item>
    <item>
      <title>Modeling and performance evaluation of computer systems security operation</title>
      <link>https://arxiv.org/abs/1212.5289</link>
      <description>arXiv:1212.5289v2 Announce Type: replace-cross 
Abstract: A model of computer system security operation is developed based on the fork-join queueing network formalism. We introduce a security operation performance measure, and show how it may be used to performance evaluation of actual systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:1212.5289v2</guid>
      <category>cs.CR</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>Proc. 4th St. Petersburg Workshop on Simulation, 2001, pp. 233-238</arxiv:journal_reference>
      <dc:creator>D. Guster, N. K. Krivulin</dc:creator>
    </item>
    <item>
      <title>LMI Properties and Applications in Systems, Stability, and Control Theory</title>
      <link>https://arxiv.org/abs/1903.08599</link>
      <description>arXiv:1903.08599v4 Announce Type: replace-cross 
Abstract: Linear matrix inequalities (LMIs) commonly appear in systems, stability, and control applications. Many analysis and synthesis problems in these areas can be solved as feasibility or optimization problems subject to LMI constraints. Although most well-known LMI properties and manipulation tricks, such as the Schur complement and the congruence transformation, can be found in standard references, many useful LMI properties are scattered throughout the literature. The purpose of this document is to collect and organize properties, tricks, and applications related to LMIs from a number of references together in a single document. In this sense, the document can be thought of as an "LMI encyclopedia" or "LMI cookbook." Proofs of the properties presented in this document are not included when they can be found in the cited references in the interest of brevity. Illustrative examples are included whenever necessary to fully explain a certain property. Multiple equivalent forms of LMIs are often presented to give the reader a choice of which form may be best suited for a particular problem at hand. The equivalency of some of the LMIs in this document may be straightforward to more experienced readers, but the authors believe that some readers may benefit from the presentation of multiple equivalent LMIs.</description>
      <guid isPermaLink="false">oai:arXiv.org:1903.08599v4</guid>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ryan James Caverly, James Richard Forbes</dc:creator>
    </item>
    <item>
      <title>Metrizing Fairness</title>
      <link>https://arxiv.org/abs/2205.15049</link>
      <description>arXiv:2205.15049v4 Announce Type: replace-cross 
Abstract: We study supervised learning problems for predicting properties of individuals who belong to one of two demographic groups, and we seek predictors that are fair according to statistical parity. This means that the distributions of the predictions within the two groups should be close with respect to the Kolmogorov distance, and fairness is achieved by penalizing the dissimilarity of these two distributions in the objective function of the learning problem. In this paper, we showcase conceptual and computational benefits of measuring unfairness with integral probability metrics (IPMs) other than the Kolmogorov distance. Conceptually, we show that the generator of any IPM can be interpreted as a family of utility functions and that unfairness with respect to this IPM arises if individuals in the two demographic groups have diverging expected utilities. We also prove that the unfairness-regularized prediction loss admits unbiased gradient estimators if unfairness is measured by the squared $\mathcal L^2$-distance or by a squared maximum mean discrepancy. In this case, the fair learning problem is susceptible to efficient stochastic gradient descent (SGD) algorithms. Numerical experiments on real data show that these SGD algorithms outperform state-of-the-art methods for fair learning in that they achieve superior accuracy-unfairness trade-offs -- sometimes orders of magnitude faster. Finally, we identify conditions under which statistical parity can improve prediction accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2205.15049v4</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yves Rychener, Bahar Taskesen, Daniel Kuhn</dc:creator>
    </item>
    <item>
      <title>Differential Privacy via Distributionally Robust Optimization</title>
      <link>https://arxiv.org/abs/2304.12681</link>
      <description>arXiv:2304.12681v2 Announce Type: replace-cross 
Abstract: In recent years, differential privacy has emerged as the de facto standard for sharing statistics of datasets while limiting the disclosure of private information about the involved individuals. This is achieved by randomly perturbing the statistics to be published, which in turn leads to a privacy-accuracy trade-off: larger perturbations provide stronger privacy guarantees, but they result in less accurate statistics that offer lower utility to the recipients. Of particular interest are therefore optimal mechanisms that provide the highest accuracy for a pre-selected level of privacy. To date, work in this area has focused on specifying families of perturbations a priori and subsequently proving their asymptotic and/or best-in-class optimality. In this paper, we develop a class of mechanisms that enjoy non-asymptotic and unconditional optimality guarantees. To this end, we formulate the mechanism design problem as an infinite-dimensional distributionally robust optimization problem. We show that the problem affords a strong dual, and we exploit this duality to develop converging hierarchies of finite-dimensional upper and lower bounding problems. Our upper (primal) bounds correspond to implementable perturbations whose suboptimality can be bounded by our lower (dual) bounds. Both bounding problems can be solved within seconds via cutting plane techniques that exploit the inherent problem structure. Our numerical experiments demonstrate that our perturbations can outperform the previously best results from the literature on artificial as well as standard benchmark problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.12681v2</guid>
      <category>cs.CR</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aras Selvi, Huikang Liu, Wolfram Wiesemann</dc:creator>
    </item>
    <item>
      <title>Robust Twin Parametric Margin Support Vector Machine for Multiclass Classification</title>
      <link>https://arxiv.org/abs/2306.06213</link>
      <description>arXiv:2306.06213v2 Announce Type: replace-cross 
Abstract: In this paper, we present novel Twin Parametric Margin Support Vector Machine (TPMSVM) models to tackle the problem of multiclass classification. We explore the cases of linear and nonlinear classifiers and propose two possible alternatives for the final decision function. Since real-world observations are plagued by measurement errors and noise, data uncertainties need to be considered in the optimization models. For this reason, we construct bounded-by-norm uncertainty sets around each sample and derive the robust counterpart of deterministic models by means of robust optimization techniques. Finally, we test the proposed TPMSVM methodology on real-world datasets, showing the good performance of the approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.06213v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Renato De Leone, Francesca Maggioni, Andrea Spinelli</dc:creator>
    </item>
    <item>
      <title>Improved sampling via learned diffusions</title>
      <link>https://arxiv.org/abs/2307.01198</link>
      <description>arXiv:2307.01198v2 Announce Type: replace-cross 
Abstract: Recently, a series of papers proposed deep learning-based approaches to sample from target distributions using controlled diffusion processes, being trained only on the unnormalized target densities without access to samples. Building on previous work, we identify these approaches as special cases of a generalized Schr\"odinger bridge problem, seeking a stochastic evolution between a given prior distribution and the specified target. We further generalize this framework by introducing a variational formulation based on divergences between path space measures of time-reversed diffusion processes. This abstract perspective leads to practical losses that can be optimized by gradient-based algorithms and includes previous objectives as special cases. At the same time, it allows us to consider divergences other than the reverse Kullback-Leibler divergence that is known to suffer from mode collapse. In particular, we propose the so-called log-variance loss, which exhibits favorable numerical properties and leads to significantly improved performance across all considered approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.01198v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>International Conference on Learning Representations, 2024</arxiv:journal_reference>
      <dc:creator>Lorenz Richter, Julius Berner</dc:creator>
    </item>
    <item>
      <title>Decision-Focused Learning: Foundations, State of the Art, Benchmark and Future Opportunities</title>
      <link>https://arxiv.org/abs/2307.13565</link>
      <description>arXiv:2307.13565v3 Announce Type: replace-cross 
Abstract: Decision-focused learning (DFL) is an emerging paradigm that integrates machine learning (ML) and constrained optimization to enhance decision quality by training ML models in an end-to-end system. This approach shows significant potential to revolutionize combinatorial decision-making in real-world applications that operate under uncertainty, where estimating unknown parameters within decision models is a major challenge. This paper presents a comprehensive review of DFL, providing an in-depth analysis of both gradient-based and gradient-free techniques used to combine ML and constrained optimization. It evaluates the strengths and limitations of these techniques and includes an extensive empirical evaluation of eleven methods across seven problems. The survey also offers insights into recent advancements and future research directions in DFL.
  Code and benchmark: https://github.com/PredOpt/predopt-benchmarks</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.13565v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jayanta Mandi, James Kotary, Senne Berden, Maxime Mulamba, Victor Bucarey, Tias Guns, Ferdinando Fioretto</dc:creator>
    </item>
    <item>
      <title>Training robust and generalizable quantum models</title>
      <link>https://arxiv.org/abs/2311.11871</link>
      <description>arXiv:2311.11871v3 Announce Type: replace-cross 
Abstract: Adversarial robustness and generalization are both crucial properties of reliable machine learning models. In this paper, we study these properties in the context of quantum machine learning based on Lipschitz bounds. We derive parameter-dependent Lipschitz bounds for quantum models with trainable encoding, showing that the norm of the data encoding has a crucial impact on the robustness against data perturbations. Further, we derive a bound on the generalization error which explicitly involves the parameters of the data encoding. Our theoretical findings give rise to a practical strategy for training robust and generalizable quantum models by regularizing the Lipschitz bound in the cost. Further, we show that, for fixed and non-trainable encodings, as those frequently employed in quantum machine learning, the Lipschitz bound cannot be influenced by tuning the parameters. Thus, trainable encodings are crucial for systematically adapting robustness and generalization during training. The practical implications of our theoretical findings are illustrated with numerical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.11871v3</guid>
      <category>quant-ph</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Julian Berberich, Daniel Fink, Daniel Pranji\'c, Christian Tutschku, Christian Holm</dc:creator>
    </item>
    <item>
      <title>A safe exploration approach to constrained Markov decision processes</title>
      <link>https://arxiv.org/abs/2312.00561</link>
      <description>arXiv:2312.00561v2 Announce Type: replace-cross 
Abstract: We consider discounted infinite horizon constrained Markov decision processes (CMDPs) where the goal is to find an optimal policy that maximizes the expected cumulative reward subject to expected cumulative constraints. Motivated by the application of CMDPs in online learning of safety-critical systems, we focus on developing a model-free and simulator-free algorithm that ensures constraint satisfaction during learning. To this end, we develop an interior point approach based on the log barrier function of the CMDP. Under the commonly assumed conditions of Fisher non-degeneracy and bounded transfer error of the policy parameterization, we establish the theoretical properties of the algorithm. In particular, in contrast to existing CMDP approaches that ensure policy feasibility only upon convergence, our algorithm guarantees the feasibility of the policies during the learning process and converges to the $\varepsilon$-optimal policy with a sample complexity of $\tilde{\mathcal{O}}(\varepsilon^{-6})$. In comparison to the state-of-the-art policy gradient-based algorithm, C-NPG-PDA, our algorithm requires an additional $\mathcal{O}(\varepsilon^{-2})$ samples to ensure policy feasibility during learning with the same Fisher non-degenerate parameterization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.00561v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tingting Ni, Maryam Kamgarpour</dc:creator>
    </item>
    <item>
      <title>Energy-efficient Decentralized Learning via Graph Sparsification</title>
      <link>https://arxiv.org/abs/2401.03083</link>
      <description>arXiv:2401.03083v2 Announce Type: replace-cross 
Abstract: This work aims at improving the energy efficiency of decentralized learning by optimizing the mixing matrix, which controls the communication demands during the learning process. Through rigorous analysis based on a state-of-the-art decentralized learning algorithm, the problem is formulated as a bi-level optimization, with the lower level solved by graph sparsification. A solution with guaranteed performance is proposed for the special case of fully-connected base topology and a greedy heuristic is proposed for the general case. Simulations based on real topology and dataset show that the proposed solution can lower the energy consumption at the busiest node by 54%-76% while maintaining the quality of the trained model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.03083v2</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xusheng Zhang, Cho-Chun Chiu, Ting He</dc:creator>
    </item>
    <item>
      <title>Parallelly Sliced Optimal Transport on Spheres and on the Rotation Group</title>
      <link>https://arxiv.org/abs/2401.16896</link>
      <description>arXiv:2401.16896v2 Announce Type: replace-cross 
Abstract: Sliced optimal transport, which is basically a Radon transform followed by one-dimensional optimal transport, became popular in various applications due to its efficient computation. In this paper, we deal with sliced optimal transport on the sphere $\mathbb{S}^{d-1}$ and on the rotation group SO(3). We propose a parallel slicing procedure of the sphere which requires again only optimal transforms on the line. We analyze the properties of the corresponding parallelly sliced optimal transport, which provides in particular a rotationally invariant metric on the spherical probability measures. For SO(3), we introduce a new two-dimensional Radon transform and develop its singular value decomposition. Based on this, we propose a sliced optimal transport on SO(3).
  As Wasserstein distances were extensively used in barycenter computations, we derive algorithms to compute the barycenters with respect to our new sliced Wasserstein distances and provide synthetic numerical examples on the 2-sphere that demonstrate their behavior for both the free and fixed support setting of discrete spherical measures. In terms of computational speed, they outperform the existing methods for semicircular slicing as well as the regularized Wasserstein barycenters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.16896v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael Quellmalz, L\'eo Buecher, Gabriele Steidl</dc:creator>
    </item>
    <item>
      <title>Analyzing Neural Network-Based Generative Diffusion Models through Convex Optimization</title>
      <link>https://arxiv.org/abs/2402.01965</link>
      <description>arXiv:2402.01965v3 Announce Type: replace-cross 
Abstract: Diffusion models are gaining widespread use in cutting-edge image, video, and audio generation. Score-based diffusion models stand out among these methods, necessitating the estimation of score function of the input data distribution. In this study, we present a theoretical framework to analyze two-layer neural network-based diffusion models by reframing score matching and denoising score matching as convex optimization. We prove that training shallow neural networks for score prediction can be done by solving a single convex program. Although most analyses of diffusion models operate in the asymptotic setting or rely on approximations, we characterize the exact predicted score function and establish convergence results for neural network-based diffusion models with finite data. Our results provide a precise characterization of what neural network-based diffusion models learn in non-asymptotic settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.01965v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fangzhao Zhang, Mert Pilanci</dc:creator>
    </item>
    <item>
      <title>Online Uniform Allocation:Randomized Learning-Augmented Approximation Algorithms with Application to Digital Health</title>
      <link>https://arxiv.org/abs/2402.01995</link>
      <description>arXiv:2402.01995v4 Announce Type: replace-cross 
Abstract: Motivated by applications in digital health, this work studies the novel problem of online uniform allocation (OUA), where the goal is to distribute a budget uniformly across unknown decision times. In the OUA problem, the algorithm is given a budget $b$ and a time horizon $T$, and an adversary then chooses a value $\tau^* \in [b,T]$, which is revealed to the algorithm online. At each decision time $i \in [\tau^*]$, the algorithm must determine a probability that maximizes the budget spent throughout the horizon, respecting budget constraint $b$, while achieving as uniform a distribution as possible over $\tau^*$. We present the first randomized algorithm designed for this problem and subsequently extend it to incorporate learning augmentation. We provide worst-case approximation guarantees for both algorithms, and illustrate the utility of the algorithms through both synthetic experiments and a real-world case study involving the HeartSteps mobile application. Our numerical results show strong empirical average performance of our proposed randomized algorithms against previously proposed heuristic solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.01995v4</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xueqing Liu, Kyra Gan, Esmaeil Keyvanshokooh, Susan Murphy</dc:creator>
    </item>
    <item>
      <title>Sample Complexity of Algorithm Selection Using Neural Networks and Its Applications to Branch-and-Cut</title>
      <link>https://arxiv.org/abs/2402.02328</link>
      <description>arXiv:2402.02328v2 Announce Type: replace-cross 
Abstract: Data-driven algorithm design is a paradigm that uses statistical and machine learning techniques to select from a class of algorithms for a computational problem an algorithm that has the best expected performance with respect to some (unknown) distribution on the instances of the problem. We build upon recent work in this line of research by considering the setup where, instead of selecting a single algorithm that has the best performance, we allow the possibility of selecting an algorithm based on the instance to be solved, using neural networks. In particular, given a representative sample of instances, we learn a neural network that maps an instance of the problem to the most appropriate algorithm for that instance. We formalize this idea and derive rigorous sample complexity bounds for this learning problem, in the spirit of recent work in data-driven algorithm design. We then apply this approach to the problem of making good decisions in the branch-and-cut framework for mixed-integer optimization (e.g., which cut to add?). In other words, the neural network will take as input a mixed-integer optimization instance and output a decision that will result in a small branch-and-cut tree for that instance. Our computational results provide evidence that our particular way of using neural networks for cut selection can make a significant impact in reducing branch-and-cut tree sizes, compared to previous data-driven approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.02328v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongyu Cheng, Sammy Khalife, Barbara Fiedorowicz, Amitabh Basu</dc:creator>
    </item>
    <item>
      <title>Toward TransfORmers: Revolutionizing the Solution of Mixed Integer Programs with Transformers</title>
      <link>https://arxiv.org/abs/2402.13380</link>
      <description>arXiv:2402.13380v2 Announce Type: replace-cross 
Abstract: In this study, we introduce an innovative deep learning framework that employs a transformer model to address the challenges of mixed-integer programs, specifically focusing on the Capacitated Lot Sizing Problem (CLSP). Our approach, to our knowledge, is the first to utilize transformers to predict the binary variables of a mixed-integer programming (MIP) problem. Specifically, our approach harnesses the encoder decoder transformer's ability to process sequential data, making it well-suited for predicting binary variables indicating production setup decisions in each period of the CLSP. This problem is inherently dynamic, and we need to handle sequential decision making under constraints. We present an efficient algorithm in which CLSP solutions are learned through a transformer neural network. The proposed post-processed transformer algorithm surpasses the state-of-the-art solver, CPLEX and Long Short-Term Memory (LSTM) in solution time, optimal gap, and percent infeasibility over 240K benchmark CLSP instances tested. After the ML model is trained, conducting inference on the model, reduces the MIP into a linear program (LP). This transforms the ML-based algorithm, combined with an LP solver, into a polynomial-time approximation algorithm to solve a well-known NP-Hard problem, with almost perfect solution quality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.13380v2</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.CO</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Joshua F. Cooper, Seung Jin Choi, I. Esra Buyuktahtakin</dc:creator>
    </item>
    <item>
      <title>am-AMM: An Auction-Managed Automated Market Maker</title>
      <link>https://arxiv.org/abs/2403.03367</link>
      <description>arXiv:2403.03367v3 Announce Type: replace-cross 
Abstract: Automated market makers (AMMs) have emerged as the dominant market mechanism for trading on decentralized exchanges implemented on blockchains. This paper presents a single mechanism that targets two important unsolved problems for AMMs: reducing losses to informed orderflow, and maximizing revenue from uninformed orderflow. The ``auction-managed AMM'' works by running a censorship-resistant onchain auction for the right to temporarily act as ``pool manager'' for a constant-product AMM. The pool manager sets the swap fee rate on the pool, and also receives the accrued fees from swaps. The pool manager can exclusively capture some arbitrage by trading against the pool in response to small price movements, and also can set swap fees incorporating price sensitivity of retail orderflow and adapting to changing market conditions, with the benefits from both ultimately accruing to liquidity providers. Liquidity providers can enter and exit the pool freely in response to changing rent, though they must pay a small fee on withdrawal. We prove that under certain assumptions, this AMM should have higher liquidity in equilibrium than any standard, fixed-fee AMM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.03367v3</guid>
      <category>q-fin.TR</category>
      <category>cs.GT</category>
      <category>math.OC</category>
      <category>q-fin.MF</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Austin Adams, Ciamac C. Moallemi, Sara Reynolds, Dan Robinson</dc:creator>
    </item>
    <item>
      <title>Towards Stable Machine Learning Model Retraining via Slowly Varying Sequences</title>
      <link>https://arxiv.org/abs/2403.19871</link>
      <description>arXiv:2403.19871v4 Announce Type: replace-cross 
Abstract: We consider the task of retraining machine learning (ML) models when new batches of data become available. Existing methods focus largely on greedy approaches to find the best-performing model for each batch, without considering the stability of the model's structure across retraining iterations. In this study, we propose a methodology for finding sequences of ML models that are stable across retraining iterations. We develop a mixed-integer optimization formulation that is guaranteed to recover Pareto optimal models (in terms of the predictive power-stability trade-off) and an efficient polynomial-time algorithm that performs well in practice. We focus on retaining consistent analytical insights - which is important to model interpretability, ease of implementation, and fostering trust with users - by using custom-defined distance metrics that can be directly incorporated into the optimization problem. Our method shows stronger stability than greedily trained models with a small, controllable sacrifice in predictive power, as evidenced through a real-world case study in a major hospital system in Connecticut.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.19871v4</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Dimitris Bertsimas, Vassilis Digalakis Jr, Yu Ma, Phevos Paschalidis</dc:creator>
    </item>
    <item>
      <title>Designing robust trajectories by lobe dynamics in low-dimensional Hamiltonian systems</title>
      <link>https://arxiv.org/abs/2404.00721</link>
      <description>arXiv:2404.00721v2 Announce Type: replace-cross 
Abstract: Modern space missions with uncrewed spacecraft require robust trajectory design to connect multiple chaotic orbits by small controls. To address this issue, we propose a control scheme to design robust trajectories by leveraging a geometrical structure in chaotic zones, known as a {\it lobe}. Our scheme shows that appropriately selected lobes reveal possible paths to traverse chaotic zones in a short time. The effectiveness of our method is demonstrated through trajectory design in both the standard map and Hill's equation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00721v2</guid>
      <category>nlin.CD</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <category>physics.class-ph</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Naoki Hiraiwa, Mai Bando, Isaia Nisoli, Yuzuru Sato</dc:creator>
    </item>
    <item>
      <title>Towards General Conceptual Model Editing via Adversarial Representation Engineering</title>
      <link>https://arxiv.org/abs/2404.13752</link>
      <description>arXiv:2404.13752v2 Announce Type: replace-cross 
Abstract: Since the development of Large Language Models (LLMs) has achieved remarkable success, understanding and controlling their internal complex mechanisms has become an urgent problem. Recent research has attempted to interpret their behaviors through the lens of inner representation. However, developing practical and efficient methods for applying these representations for general and flexible model editing remains challenging. In this work, we explore how to use representation engineering methods to guide the editing of LLMs by deploying a representation sensor as an oracle. We first identify the importance of a robust and reliable sensor during editing, then propose an Adversarial Representation Engineering (ARE) framework to provide a unified and interpretable approach for conceptual model editing without compromising baseline performance. Experiments on multiple model editing paradigms demonstrate the effectiveness of ARE in various settings. Code and data are available at https://github.com/Zhang-Yihao/Adversarial-Representation-Engineering.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13752v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.CR</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yihao Zhang, Zeming Wei, Jun Sun, Meng Sun</dc:creator>
    </item>
    <item>
      <title>PlanNetX: Learning an Efficient Neural Network Planner from MPC for Longitudinal Control</title>
      <link>https://arxiv.org/abs/2404.18863</link>
      <description>arXiv:2404.18863v2 Announce Type: replace-cross 
Abstract: Model predictive control (MPC) is a powerful, optimization-based approach for controlling dynamical systems. However, the computational complexity of online optimization can be problematic on embedded devices. Especially, when we need to guarantee fixed control frequencies. Thus, previous work proposed to reduce the computational burden using imitation learning (IL) approximating the MPC policy by a neural network. In this work, we instead learn the whole planned trajectory of the MPC. We introduce a combination of a novel neural network architecture PlanNetX and a simple loss function based on the state trajectory that leverages the parameterized optimal control structure of the MPC. We validate our approach in the context of autonomous driving by learning a longitudinal planner and benchmarking it extensively in the CommonRoad simulator using synthetic scenarios and scenarios derived from real data. Our experimental results show that we can learn the open-loop MPC trajectory with high accuracy while improving the closed-loop performance of the learned control policy over other baselines like behavior cloning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18863v2</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jasper Hoffmann, Diego Fernandez, Julien Brosseit, Julian Bernhard, Klemens Esterle, Moritz Werling, Michael Karg, Joschka Boedecker</dc:creator>
    </item>
    <item>
      <title>Early years of Biased Random-Key Genetic Algorithms: A systematic review</title>
      <link>https://arxiv.org/abs/2405.01765</link>
      <description>arXiv:2405.01765v3 Announce Type: replace-cross 
Abstract: This paper presents a systematic literature review and bibliometric analysis focusing on Biased Random-Key Genetic Algorithms (BRKGA). BRKGA is a metaheuristic framework that uses random-key-based chromosomes with biased, uniform, and elitist mating strategies alongside a genetic algorithm. This review encompasses around~250 papers, covering a diverse array of applications ranging from classical combinatorial optimization problems to real-world industrial scenarios, and even non-traditional applications like hyperparameter tuning in machine learning and scenario generation for two-stage problems. In summary, this study offers a comprehensive examination of the BRKGA metaheuristic and its various applications, shedding light on key areas for future research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.01765v3</guid>
      <category>cs.NE</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mariana A. Londe, Luciana S. Pessoa, Cartlos E. Andrade, Mauricio G. C. Resende</dc:creator>
    </item>
    <item>
      <title>Fair Mixed Effects Support Vector Machine</title>
      <link>https://arxiv.org/abs/2405.06433</link>
      <description>arXiv:2405.06433v2 Announce Type: replace-cross 
Abstract: To ensure unbiased and ethical automated predictions, fairness must be a core principle in machine learning applications. Fairness in machine learning aims to mitigate biases present in the training data and model imperfections that could lead to discriminatory outcomes. This is achieved by preventing the model from making decisions based on sensitive characteristics like ethnicity or sexual orientation. A fundamental assumption in machine learning is the independence of observations. However, this assumption often does not hold true for data describing social phenomena, where data points are often clustered based. Hence, if the machine learning models do not account for the cluster correlations, the results may be biased. Especially high is the bias in cases where the cluster assignment is correlated to the variable of interest. We present a fair mixed effects support vector machine algorithm that can handle both problems simultaneously. With a reproducible simulation study we demonstrate the impact of clustered data on the quality of fair machine learning predictions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.06433v2</guid>
      <category>cs.LG</category>
      <category>cs.CY</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jo\~ao Vitor Pamplona, Jan Pablo Burgard</dc:creator>
    </item>
    <item>
      <title>Fair Generalized Linear Mixed Models</title>
      <link>https://arxiv.org/abs/2405.09273</link>
      <description>arXiv:2405.09273v2 Announce Type: replace-cross 
Abstract: When using machine learning for automated prediction, it is important to account for fairness in the prediction. Fairness in machine learning aims to ensure that biases in the data and model inaccuracies do not lead to discriminatory decisions. E.g., predictions from fair machine learning models should not discriminate against sensitive variables such as sexual orientation and ethnicity. The training data often in obtained from social surveys. In social surveys, oftentimes the data collection process is a strata sampling, e.g. due to cost restrictions. In strata samples, the assumption of independence between the observation is not fulfilled. Hence, if the machine learning models do not account for the strata correlations, the results may be biased. Especially high is the bias in cases where the strata assignment is correlated to the variable of interest. We present in this paper an algorithm that can handle both problems simultaneously, and we demonstrate the impact of stratified sampling on the quality of fair machine learning predictions in a reproducible simulation study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.09273v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jan Pablo Burgard, Jo\~ao Vitor Pamplona</dc:creator>
    </item>
    <item>
      <title>Quantum optimal control robust to $1/f^\alpha$ noises using fractional calculus: voltage-controlled exchange in semiconductor spin qubits</title>
      <link>https://arxiv.org/abs/2405.12922</link>
      <description>arXiv:2405.12922v2 Announce Type: replace-cross 
Abstract: Low-frequency $1/f^\alpha$ charge noise significantly hinders the performance of voltage-controlled spin qubits in quantum dots. Here, we utilize fractional calculus to design voltage control pulses yielding the highest average fidelities for noisy quantum gate operations. We focus specifically on the exponential voltage control of the exchange interaction generating two-spin $\mathrm{SWAP}^k$ gates. When stationary charge noise is the dominant source of gate infidelity, we derive that the optimal exchange pulse is long and weak, with the broad shape of the symmetric beta distribution function with parameter $1-\alpha/2$. The common practice of making exchange pulses fast and high-amplitude still remains beneficial in the case of strongly nonstationary noise dynamics, modeled as fractional Brownian motion. The proposed methods are applicable to the characterization and optimization of quantum gate operations in various voltage-controlled qubit architectures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12922v2</guid>
      <category>quant-ph</category>
      <category>cond-mat.mes-hall</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bohdan Khromets, Jonathan Baugh</dc:creator>
    </item>
  </channel>
</rss>
