<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 13 Aug 2024 04:00:00 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 13 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Two-Edge Connectivity via Pac-Man Gluing</title>
      <link>https://arxiv.org/abs/2408.05282</link>
      <description>arXiv:2408.05282v1 Announce Type: new 
Abstract: We study the 2-edge-connected spanning subgraph (2-ECSS) problem: Given a graph $G$, compute a connected subgraph $H$ of $G$ with the minimum number of edges such that $H$ is spanning, i.e., $V(H) = V(G)$, and $H$ is 2-edge-connected, i.e., $H$ remains connected upon the deletion of any single edge, if such an $H$ exists. The $2$-ECSS problem is known to be NP-hard. In this work, we provide a polynomial-time $(\frac 5 4 + \varepsilon)$-approximation for the problem for an arbitrarily small $\varepsilon&gt;0$, improving the previous best approximation ratio of $\frac{13}{10}+\varepsilon$.
  Our improvement is based on two main innovations: First, we reduce solving the problem on general graphs to solving it on structured graphs with high vertex connectivity. This high vertex connectivity ensures the existence of a 4-matching across any bipartition of the vertex set with at least 10 vertices in each part. Second, we exploit this property in a later gluing step, where isolated 2-edge-connected components need to be merged without adding too many edges. Using the 4-matching property, we can repeatedly glue a huge component (containing at least 10 vertices) to other components. This step is reminiscent of the Pac-Man game, where a Pac-Man (a huge component) consumes all the dots (other components) as it moves through a maze. These two innovations lead to a significantly simpler algorithm and analysis for the gluing step compared to the previous best approximation algorithm, which required a long and tedious case analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05282v1</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohit Garg, Felix Hommelsheim, Alexander Lindermayr</dc:creator>
    </item>
    <item>
      <title>Competitive Capacitated Online Recoloring</title>
      <link>https://arxiv.org/abs/2408.05370</link>
      <description>arXiv:2408.05370v1 Announce Type: new 
Abstract: In this paper, we revisit the online recoloring problem introduced recently by Azar et al. In online recoloring, there is a fixed set $V$ of $n$ vertices and an initial coloring $c_0: V\rightarrow [k]$ for some $k\in \mathbb{Z}^{&gt;0}$. Under an online sequence $\sigma$ of requests where each request is an edge $(u_t,v_t)$, a proper vertex coloring $c$ of the graph $G_t$ induced by requests until time $t$ needs to be maintained for all $t$; i.e., for any $(u,v)\in G_t$, $c(u)\neq c(v)$. The objective is to minimize the total weight of vertices recolored for the sequence $\sigma$.
  We obtain the first competitive algorithms for capacitated online recoloring and fully dynamic recoloring. Our first set of results is for $2$-recoloring using algorithms that are $(1+\varepsilon)$-resource augmented where $\varepsilon\in (0,1)$ is an arbitrarily small constant. Our main result is an $O(\log n)$-competitive deterministic algorithm for weighted bipartite graphs, which is asymptotically optimal in light of an $\Omega(\log n)$ lower bound that holds for an unbounded amount of augmentation. We also present an $O(n\log n)$-competitive deterministic algorithm for fully dynamic recoloring, which is optimal within an $O(\log n)$ factor in light of a $\Omega(n)$ lower bound that holds for an unbounded amount of augmentation.
  Our second set of results is for $\Delta$-recoloring in an $(1+\varepsilon)$-overprovisioned setting where the maximum degree of $G_t$ is bounded by $(1-\varepsilon)\Delta$ for all $t$, and each color assigned to at most $(1+\varepsilon)\frac{n}{\Delta}$ vertices, for an arbitrary $\varepsilon &gt; 0$. Our main result is an $O(1)$-competitive randomized algorithm for $\Delta = O(\sqrt{n/\log n})$. We also present an $O(\Delta)$-competitive deterministic algorithm for $\Delta \le \varepsilon n/2$. Both results are asymptotically optimal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05370v1</guid>
      <category>cs.DS</category>
      <category>cs.DC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rajmohan Rajaraman, Omer Wasim</dc:creator>
    </item>
    <item>
      <title>Simple and Nearly-Optimal Sampling for Rank-1 Tensor Completion via Gauss-Jordan</title>
      <link>https://arxiv.org/abs/2408.05431</link>
      <description>arXiv:2408.05431v1 Announce Type: new 
Abstract: We revisit the sample and computational complexity of completing a rank-1 tensor in $\otimes_{i=1}^{N} \mathbb{R}^{d}$, given a uniformly sampled subset of its entries. We present a characterization of the problem (i.e. nonzero entries) which admits an algorithm amounting to Gauss-Jordan on a pair of random linear systems. For example, when $N = \Theta(1)$, we prove it uses no more than $m = O(d^2 \log d)$ samples and runs in $O(md^2)$ time. Moreover, we show any algorithm requires $\Omega(d\log d)$ samples.
  By contrast, existing upper bounds on the sample complexity are at least as large as $d^{1.5} \mu^{\Omega(1)} \log^{\Omega(1)} d$, where $\mu$ can be $\Theta(d)$ in the worst case. Prior work obtained these looser guarantees in higher rank versions of our problem, and tend to involve more complicated algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05431v1</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alejandro Gomez-Leos, Oscar L\'opez</dc:creator>
    </item>
    <item>
      <title>Improved Approximation Guarantees for Joint Replenishment in Continuous Time</title>
      <link>https://arxiv.org/abs/2408.05443</link>
      <description>arXiv:2408.05443v1 Announce Type: new 
Abstract: The primary objective of this work is to revisit and revitalize one of the most fundamental models in deterministic inventory management, the continuous-time joint replenishment problem. Our main contribution consists of resolving several long-standing open questions in this context. For most of these questions, we obtain the first quantitative improvement over power-of-$2$ policies and their nearby derivatives, which have been state-of-the-art in terms of provable performance guarantees since the mid-80's.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05443v1</guid>
      <category>cs.DS</category>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Danny Segev</dc:creator>
    </item>
    <item>
      <title>Memento Filter: A Fast, Dynamic, and Robust Range Filter</title>
      <link>https://arxiv.org/abs/2408.05625</link>
      <description>arXiv:2408.05625v1 Announce Type: new 
Abstract: Range filters are probabilistic data structures that answer approximate range emptiness queries. They aid in avoiding processing empty range queries and have use cases in many application domains such as key-value stores and social web analytics. However, current range filter designs do not support dynamically changing and growing datasets. Moreover, several of these designs also exhibit impractically high false positive rates under correlated workloads, which are common in practice. These impediments restrict the applicability of range filters across a wide range of use cases.
  We introduce Memento filter, the first range filter to offer dynamicity, fast operations, and a robust false positive rate guarantee for any workload. Memento filter partitions the key universe and clusters its keys according to this partitioning. For each cluster, it stores a fingerprint and a list of key suffixes contiguously. The encoding of these lists makes them amenable to existing dynamic filter structures. Due to the well-defined one-to-one mapping from keys to suffixes, Memento filter supports inserts and deletes and can even expand to accommodate a growing dataset.
  We implement Memento filter on top of a Rank-and-Select Quotient filter and InfiniFilter and demonstrate that it achieves competitive false positive rates and performance with the state-of-the-art while also providing dynamicity. Due to its dynamicity, Memento filter is the first range filter applicable to B-Trees. We showcase this by integrating Memento filter into WiredTiger, a B-Tree-based key-value store. Memento filter doubles WiredTiger's range query throughput when 50\% of the queries are empty while keeping all other cost metrics unharmed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05625v1</guid>
      <category>cs.DS</category>
      <category>cs.DB</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Navid Eslami, Niv Dayan</dc:creator>
    </item>
    <item>
      <title>High Probability Low Latency Sequential Change Detection over an Unknown Finite Horizon</title>
      <link>https://arxiv.org/abs/2408.05817</link>
      <description>arXiv:2408.05817v1 Announce Type: new 
Abstract: A finite horizon variant of the quickest change detection problem is studied, in which the goal is to minimize a delay threshold (latency), under constraints on the probability of false alarm and the probability that the latency is exceeded. In addition, the horizon is not known to the change detector. A variant of the cumulative sum (CuSum) test with a threshold that increasing logarithmically with time is proposed as a candidate solution to the problem. An information-theoretic lower bound on the minimum value of the latency under the constraints is then developed. This lower bound is used to establish certain asymptotic optimality properties of the proposed test in terms of the horizon and the false alarm probability. Some experimental results are given to illustrate the performance of the test.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05817v1</guid>
      <category>cs.DS</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yu-Han Huang, Venugopal V. Veeravalli</dc:creator>
    </item>
    <item>
      <title>Spectral Sparsification by Deterministic Discrepancy Walk</title>
      <link>https://arxiv.org/abs/2408.06146</link>
      <description>arXiv:2408.06146v1 Announce Type: new 
Abstract: Spectral sparsification and discrepancy minimization are two well-studied areas that are closely related. Building on recent connections between these two areas, we generalize the "deterministic discrepancy walk" framework by Pesenti and Vladu [SODA~23] for vector discrepancy to matrix discrepancy, and use it to give a simpler proof of the matrix partial coloring theorem of Reis and Rothvoss [SODA~20]. Moreover, we show that this matrix discrepancy framework provides a unified approach for various spectral sparsification problems, from stronger notions including unit-circle approximation and singular-value approximation to weaker notions including graphical spectral sketching and effective resistance sparsification. In all of these applications, our framework produces improved results with a simpler and deterministic analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06146v1</guid>
      <category>cs.DS</category>
      <category>math.CO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lap Chi Lau, Robert Wang, Hong Zhou</dc:creator>
    </item>
    <item>
      <title>Batched Ranged Random Integer Generation</title>
      <link>https://arxiv.org/abs/2408.06213</link>
      <description>arXiv:2408.06213v1 Announce Type: new 
Abstract: Pseudorandom values are often generated as 64-bit binary words. These random words need to be converted into ranged values without statistical bias. We present an efficient algorithm to generate multiple independent uniformly-random bounded integers from a single uniformly-random binary word, without any bias. In the common case, our method uses one multiplication and no division operations per value produced. In practice, our algorithm can more than double the speed of unbiased random shuffling for small to moderately large arrays.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06213v1</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nevin Brackett-Rozinsky, Daniel Lemire</dc:creator>
    </item>
    <item>
      <title>Sequential non-determinism in tile self-assembly: a general framework and an application to efficient temperature-1 self-assembly of squares</title>
      <link>https://arxiv.org/abs/2408.06241</link>
      <description>arXiv:2408.06241v1 Announce Type: new 
Abstract: In this paper, we work in a 2D version of the probabilistic variant of Winfree's abstract Tile Assembly Model defined by Chandran, Gopalkrishnan and Reif (SICOMP 2012) in which attaching tiles are sampled uniformly with replacement. First, we develop a framework called ``sequential non-determinism'' for analyzing the probabilistic correctness of a non-deterministic, temperature-1 tile assembly system (TAS) in which most (but not all) tile attachments are deterministic and the non-deterministic attachments always occur in a specific order. Our main sequential non-determinism result equates the probabilistic correctness of such a TAS to a finite product of probabilities, each of which 1) corresponds to the probability of the correct type of tile attaching at a point where it is possible for two different types to attach, and 2) ignores all other tile attachments that do not affect the non-deterministic attachment. We then show that sequential non-determinism allows for efficient and geometrically expressive self-assembly. To that end, we constructively prove that for any positive integer $N$ and any real $\delta \in (0,1)$, there exists a TAS that self-assembles into an $N \times N$ square with probability at least $1 - \delta$ using only $O\left( \log N + \log \frac{1}{\delta} \right)$ types of tiles. Our bound improves upon the previous state-of-the-art bound for this problem by Cook, Fu and Schweller (SODA 2011).</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06241v1</guid>
      <category>cs.DS</category>
      <category>cs.CG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David Furcy, Scott M. Summers</dc:creator>
    </item>
    <item>
      <title>Dynamic Traffic Assignment for Public Transport with Vehicle Capacities</title>
      <link>https://arxiv.org/abs/2408.06308</link>
      <description>arXiv:2408.06308v1 Announce Type: new 
Abstract: Traffic assignment is a core component of many urban transport planning tools. It is used to determine how traffic is distributed over a transportation network. We study the task of computing traffic assignments for public transport: Given a public transit network, a timetable, vehicle capacities and a demand (i.e. a list of passengers, each with an associated origin, destination, and departure time), the goal is to predict the resulting passenger flow and the corresponding load of each vehicle. Microscopic stochastic simulation of individual passengers is a standard, but computationally expensive approach. Briem et al. (2017) have shown that a clever adaptation of the Connection Scan Algorithm (CSA) can lead to highly efficient traffic assignment algorithms, but ignores vehicle capacities, resulting in overcrowded vehicles. Taking their work as a starting point, we here propose a new and extended model that guarantees capacity-feasible assignments and incorporates dynamic network congestion effects such as crowded vehicles, denied boarding, and dwell time delays. Moreover, we also incorporate learning and adaptation of individual passengers based on their experience with the network. Applications include studying the evolution of perceived travel times as a result of adaptation, the impact of an increase in capacity, or network effects due to changes in the timetable such as the addition or the removal of a service or a whole line. The proposed framework has been experimentally evaluated with public transport networks of G\"ottingen and Stuttgart (Germany). The simulation proves to be highly efficient. On a standard PC the computation of a traffic assignment takes just a few seconds per simulation day.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06308v1</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Julian Patzner, Matthias M\"uller-Hannemann</dc:creator>
    </item>
    <item>
      <title>Convergence Analysis for Deep Sparse Coding via Convolutional Neural Networks</title>
      <link>https://arxiv.org/abs/2408.05540</link>
      <description>arXiv:2408.05540v1 Announce Type: cross 
Abstract: In this work, we explore the intersection of sparse coding theory and deep learning to enhance our understanding of feature extraction capabilities in advanced neural network architectures. We begin by introducing a novel class of Deep Sparse Coding (DSC) models and establish a thorough theoretical analysis of their uniqueness and stability properties. By applying iterative algorithms to these DSC models, we derive convergence rates for convolutional neural networks (CNNs) in their ability to extract sparse features. This provides a strong theoretical foundation for the use of CNNs in sparse feature learning tasks. We additionally extend this convergence analysis to more general neural network architectures, including those with diverse activation functions, as well as self-attention and transformer-based models. This broadens the applicability of our findings to a wide range of deep learning methods for deep sparse feature extraction. Inspired by the strong connection between sparse coding and CNNs, we also explore training strategies to encourage neural networks to learn more sparse features. Through numerical experiments, we demonstrate the effectiveness of these approaches, providing valuable insights for the design of efficient and interpretable deep learning models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05540v1</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>cs.IT</category>
      <category>cs.NE</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jianfei Li, Han Feng, Ding-Xuan Zhou</dc:creator>
    </item>
    <item>
      <title>Mixing on Generalized Associahedra</title>
      <link>https://arxiv.org/abs/2408.05611</link>
      <description>arXiv:2408.05611v1 Announce Type: cross 
Abstract: Eppstein and Frishberg recently proved that the mixing time for the simple random walk on the $1$-skeleton of the associahedron is $O(n^3\log^3 n)$. We obtain similar rapid mixing results for the simple random walks on the $1$-skeleta of the type-$B$ and type-$D$ associahedra. We adapt Eppstein and Frishberg's technique to obtain the same bound of $O(n^3\log^3 n)$ in type $B$ and a bound of $O(n^{13} \log^2 n)$ in type $D$; in the process, we establish an expansion bound that is tight up to logarithmic factors in type $B$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05611v1</guid>
      <category>math.CO</category>
      <category>cs.DS</category>
      <category>math.PR</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>William Chang, Colin Defant, Daniel Frishberg</dc:creator>
    </item>
    <item>
      <title>Separate Generation and Evaluation for Parallel Greedy Best-First Search</title>
      <link>https://arxiv.org/abs/2408.05682</link>
      <description>arXiv:2408.05682v1 Announce Type: cross 
Abstract: Parallelization of Greedy Best First Search (GBFS) has been difficult because straightforward parallelization can result in search behavior which differs significantly from sequential GBFS, exploring states which would not be explored by sequential GBFS with any tie-breaking strategy. Recent work has proposed a class of parallel GBFS algorithms which constrains search to exploration of the Bench Transition System (BTS), which is the set of states that can be expanded by GBFS under some tie-breaking policy. However, enforcing this constraint is costly, as such BTS-constrained algorithms are forced to spend much of the time waiting so that only states which are guaranteed to be in the BTS are expanded. We propose an improvement to parallel search which decouples state generation and state evaluation and significantly improves state evaluation rate, resulting in better search performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05682v1</guid>
      <category>cs.AI</category>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Takumi Shimoda, Alex Fukunaga</dc:creator>
    </item>
    <item>
      <title>The complexity of strong conflict-free vertex-connection $k$-colorability</title>
      <link>https://arxiv.org/abs/2408.05865</link>
      <description>arXiv:2408.05865v1 Announce Type: cross 
Abstract: We study a new variant of graph coloring by adding a connectivity constraint. A path in a vertex-colored graph is called conflict-free if there is a color that appears exactly once on its vertices. A connected graph $G$ is said to be strongly conflict-free vertex-connection $k$-colorable if $G$ admits a vertex $k$-coloring such that any two distinct vertices of $G$ are connected by a conflict-free $shortest$ path.
  Among others, we show that deciding whether a given graph is strongly conflict-free vertex-connection $3$-colorable is NP-complete even when restricted to $3$-colorable graphs with diameter $3$, radius $2$ and domination number $3$, and, assuming the Exponential Time Hypothesis (ETH), cannot be solved in $2^{o(n)}$ time on such restricted input graphs with $n$ vertices. This hardness result is quite strong when compared to the ordinary $3$-COLORING problem: it is known that $3$-COLORING is solvable in polynomial time in graphs with bounded domination number, and assuming ETH, cannot be solved in $2^{o(\sqrt{n})}$ time in $n$-vertex graphs with diameter $3$ and radius $2$. On the positive side, we point out that a strong conflict-free vertex-connection coloring with minimum color number of a given split graph or a co-bipartite graph can be computed in polynomial time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05865v1</guid>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sun-Yuan Hsieh, Hoang-Oanh Le, Van Bang Le, Sheng-Lung Peng</dc:creator>
    </item>
    <item>
      <title>Tolerant testing stabilizer states</title>
      <link>https://arxiv.org/abs/2408.06289</link>
      <description>arXiv:2408.06289v1 Announce Type: cross 
Abstract: We consider the following task: suppose an algorithm is given copies of an unknown $n$-qubit quantum state $|\psi\rangle$ promised $(i)$ $|\psi\rangle$ is $\varepsilon_1$-close to a stabilizer state in fidelity or $(ii)$ $|\psi\rangle$ is $\varepsilon_2$-far from all stabilizer states, decide which is the case. We give a $\textsf{poly}(1/\varepsilon_1)$-sample and $n\cdot \textsf{poly}(1/\varepsilon_1)$-time algorithm for this task for every $\varepsilon_1&gt;0$ and $\varepsilon_2\leq 2^{-\textsf{poly}(1/\varepsilon_1)}$. Our proof includes a new definition of Gowers norm for quantum states, an inverse theorem for the Gowers-$3$ norm of states and new bounds on stabilizer covering for structured subsets of Paulis using results in additive combinatorics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06289v1</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Srinivasan Arunachalam, Arkopal Dutt</dc:creator>
    </item>
    <item>
      <title>Online Vehicle Routing with Pickups and Deliveries under Time-Dependent Travel-Time Constraints</title>
      <link>https://arxiv.org/abs/2408.06324</link>
      <description>arXiv:2408.06324v1 Announce Type: cross 
Abstract: The Vehicle Routing Problem with pickups, deliveries and spatiotemporal service constraints ($VRPPDSTC$) is a quite challenging algorithmic problem that can be dealt with in either an offline or an online fashion. In this work, we focus on a generalization, called $VRPPDSTCtd$, in which the travel-time metric is \emph{time-dependent}: the traversal-time per road segment (represented as a directed arc) is determined by some function of the departure-time from its tail towards its head. Time-dependence makes things much more complicated, even for the simpler problem of computing earliest-arrival-time paths which is a crucial subroutine to be solved (numerous times) by $VRPPDSTCtd$ schedulers.
  We propose two \emph{online} schedulers of requests to workers, one which is a time-dependent variant of the classical Plain-Insertion heuristic, and an extension of it trying to digest some sort of forecasts for future demands for service. We enrich these two online schedulers with two additional heuristics, one targeting for distance-balanced assignments of work loads to the workers and another that makes local-search-improvements to the produced solutions.
  We conduct a careful experimental evaluation of the proposed algorithms on a real-world instance, with or without these heuristics, and compare their quality with human-curated assignments provided by professional experts (human operators at actual pickup-and-delivery control centers), and also with feasible solutions constructed from a relaxed MILP formulation of $VRPPDSTCtd$, which is also introduced in this paper.
  Our findings are quite encouraging, demonstrating that the proposed algorithms produce solutions which (i) are significant improvements over the human-curated assignments, and (ii) have overall quality pretty close to that of the (extremely time-consuming) solutions provided by an exact solver for the MILP formulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06324v1</guid>
      <category>cs.CE</category>
      <category>cs.DS</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Spyros Kontogiannis, Andreas Paraskevopoulos, Christos Zaroliagis</dc:creator>
    </item>
    <item>
      <title>Labeling Methods for Partially Ordered Paths</title>
      <link>https://arxiv.org/abs/2307.10332</link>
      <description>arXiv:2307.10332v3 Announce Type: replace 
Abstract: The landscape of applications and subroutines relying on shortest path computations continues to grow steadily. This growth is driven by the undeniable success of shortest path algorithms in theory and practice. It also introduces new challenges as the models and assessing the optimality of paths become more complicated. Hence, multiple recent publications in the field adapt existing labeling methods in an ad hoc fashion to their specific problem variant without considering the underlying general structure: they always deal with multi-criteria scenarios, and those criteria define different partial orders on the paths. In this paper, we introduce the partial order shortest path problem (POSP), a generalization of the multi-objective shortest path problem (MOSP) and in turn also of the classical shortest path problem. POSP captures the particular structure of many shortest path applications as special cases. In this generality, we study optimality conditions or the lack of them, depending on the objective functions' properties. Our final contribution is a big lookup table summarizing our findings and providing the reader with an easy way to choose among the most recent multi-criteria shortest path algorithms depending on their problems' weight structure. Examples range from time-dependent shortest path and bottleneck path problems to the electric vehicle shortest path problem with recharging and complex financial weight functions studied in the public transportation community. Our results hold for general digraphs and, therefore, surpass previous generalizations that were limited to acyclic graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.10332v3</guid>
      <category>cs.DS</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.ejor.2024.05.002</arxiv:DOI>
      <arxiv:journal_reference>European Journal of Operational Research, Volume 318, Issue 1, 1 October 2024, Pages 19-30</arxiv:journal_reference>
      <dc:creator>Ricardo Euler, Pedro Maristany de las Casas</dc:creator>
    </item>
    <item>
      <title>Movelet Trees</title>
      <link>https://arxiv.org/abs/2408.04537</link>
      <description>arXiv:2408.04537v2 Announce Type: replace 
Abstract: We combine Nishimoto and Tabei's move structure with a wavelet tree to show how, if $T [1..n]$ is over a constant-sized alphabet and its Burrows-Wheeler Transform (BWT) consists of $r$ runs, then we can store $T$ in $O \left( r \log \frac{n}{r} \right)$ bits such that when given a pattern $P [1..m]$, we can find the BWT interval for $P$ in $O (m)$ time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04537v2</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Travis Gagie, Giovanni Manzini, Gonzalo Navarro, Marinella Sciortino</dc:creator>
    </item>
    <item>
      <title>Computing Balanced Solutions for Large International Kidney Exchange Schemes When Cycle Length Is Unbounded</title>
      <link>https://arxiv.org/abs/2312.16653</link>
      <description>arXiv:2312.16653v2 Announce Type: replace-cross 
Abstract: In kidney exchange programmes (KEP) patients may swap their incompatible donors leading to cycles of kidney transplants. Nowadays, countries try to merge their national patient-donor pools leading to international KEPs (IKEPs). As shown in the literature, long-term stability of an IKEP can be achieved through a credit-based system. In each round, every country is prescribed a "fair" initial allocation of kidney transplants. The initial allocation, which we obtain by using solution concepts from cooperative game theory, is adjusted by incorporating credits from the previous round, yielding the target allocation. The goal is to find, in each round, an optimal solution that closely approximates this target allocation. There is a known polynomial-time algorithm for finding an optimal solution that lexicographically minimizes the country deviations from the target allocation if only $2$-cycles (matchings) are permitted. In practice, kidney swaps along longer cycles may be performed. However, the problem of computing optimal solutions for maximum cycle length $\ell$ is NP-hard for every $\ell\geq 3$. This situation changes back to polynomial time once we allow unbounded cycle length. However, in contrast to the case where $\ell=2$, we show that for $\ell=\infty$, lexicographical minimization is only polynomial-time solvable under additional conditions (assuming P $\neq$ NP). Nevertheless, the fact that the optimal solutions themselves can be computed in polynomial time if $\ell=\infty$ still enables us to perform a large scale experimental study for showing how stability and total social welfare are affected when we set $\ell=\infty$ instead of $\ell=2$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.16653v2</guid>
      <category>cs.GT</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>M\'arton Benedek, P\'eter Bir\'o, Gergely Cs\'aji, Matthew Johnson, Dani\"el Paulusma, Xin Ye</dc:creator>
    </item>
    <item>
      <title>Aleph Filter: To Infinity in Constant Time</title>
      <link>https://arxiv.org/abs/2404.04703</link>
      <description>arXiv:2404.04703v3 Announce Type: replace-cross 
Abstract: Filter data structures are widely used in various areas of computer science to answer approximate set-membership queries. In many applications, the data grows dynamically, requiring their filters to expand along with the data. However, existing methods for expanding filters cannot maintain stable performance, memory footprint, and false positive rate (FPR) simultaneously. We address this problem with Aleph Filter, which makes the following contributions. (1) It supports all operations (insertions, queries, deletes, etc.) in constant time, no matter how much the data grows. (2) Given an estimate of how much the data will ultimately grow, Aleph Filter provides a memory vs. FPR trade-offs on par with static filters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.04703v3</guid>
      <category>cs.DB</category>
      <category>cs.DS</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Niv Dayan, Ioana Bercea, Rasmus Pagh</dc:creator>
    </item>
  </channel>
</rss>
