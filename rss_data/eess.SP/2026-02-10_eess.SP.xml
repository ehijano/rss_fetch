<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>eess.SP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/eess.SP</link>
    <description>eess.SP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/eess.SP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 11 Feb 2026 02:54:43 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Deep Reinforcement Learning for Interference Suppression in RIS-Aided Space-Air-Ground Integrated Networks</title>
      <link>https://arxiv.org/abs/2602.06982</link>
      <description>arXiv:2602.06982v1 Announce Type: new 
Abstract: Future 6G networks envision ubiquitous connectivity through space-air-ground integrated networks (SAGINs), where high-altitude platform stations (HAPSs) and satellites complement terrestrial systems to provide wide-area, low-latency coverage. However, the rapid growth of terrestrial devices intensifies spectrum sharing between terrestrial and non-terrestrial segments, resulting in severe cross-tier interference. In particular, frequency sharing between the HAPS satellite uplink and HAPS ground downlink improves spectrum efficiency but suffers from interference caused by the HAPS antenna back-lobe. Existing approaches relying on zero-forcing (ZF) codebooks have limited performance under highly dynamic channel conditions. To overcome this limitation, we employ a reconfigurable intelligent surface (RIS)-aided HAPS-based SAGIN framework with a deep deterministic policy gradient (DDPG) algorithm. The proposed DDPG framework optimizes the HAPS beamforming weights to form spatial nulls toward interference sources while maintaining robust links to the desired signals. Simulation results demonstrate that the DDPG framework consistently outperforms conventional ZF beamforming among different RIS configurations, achieving up to \(11.3\%\) throughput improvement for a \(4\times4\) RIS configuration, validating its adaptive capability to enhance spectral efficiency in dynamic HAPS-based SAGINs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.06982v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pujitha Mamillapalli, Shikhar Verma, Tiago Koketsu Rodrigues, Abhinav Kumar</dc:creator>
    </item>
    <item>
      <title>Hybrid Deep Learning Framework for CSI-Based Activity Recognition in Bandwidth-Constrained Wi-Fi Sensing</title>
      <link>https://arxiv.org/abs/2602.06983</link>
      <description>arXiv:2602.06983v1 Announce Type: new 
Abstract: This paper presents a novel hybrid deep learning framework designed to enhance the robustness of CSI-based Human Activity Recognition (HAR) within bandwidth-constrained Wi-Fi sensing environments. The core of our proposed methodology is a preliminary Doppler trace extraction stage, implemented to amplify salient motion-related signal features before classification. Subsequently, these enhanced inputs are processed by a hybrid neural architecture, which integrates Inception networks responsible for hierarchical spatial feature extraction and Bidirectional Long Short-Term Memory (BiLSTM) networks that capture temporal dependencies. A Support Vector Machine (SVM) is then utilized as the final classification layer to optimize decision boundaries. The framework's efficacy was systematically validated using a public dataset across 20, 40, and 80 MHz bandwidth configurations. The model yielded accuracies of 89.27% (20 MHz), 94.13% (40 MHz), and 95.30% (80 MHz), respectively. These results confirm a marked superiority over standalone deep learning baselines, especially in the most constrained low-bandwidth scenarios. This study underscores the utility of combining Doppler-based feature engineering with a hybrid learning architecture for reliable HAR in bandwidth-limited wireless sensing applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.06983v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Alison M. Fernandes, Hermes I. Del Monego, Bruno S. Chang, Anelise Munaretto, H\'elder M. Fontes, Rui Campos</dc:creator>
    </item>
    <item>
      <title>A Pre-trained EEG-to-MEG Generative Framework for Enhancing BCI Decoding</title>
      <link>https://arxiv.org/abs/2602.06990</link>
      <description>arXiv:2602.06990v1 Announce Type: new 
Abstract: Electroencephalography (EEG) and magnetoencephalography (MEG) play important and complementary roles in non-invasive brain-computer interface (BCI) decoding. However, compared to the low cost and portability of EEG, MEG is more expensive and less portable, which severely limits the practical application of MEG in BCI systems. To overcome this limitation, this study proposes the first cross-modal generation framework based on EEG-MEG spatiotemporal coupled representations to synthesize MEG signals cost-effectively. The framework first extracts general neural activity representations through a pre-trained EEG model. Building upon these representations, the framework effectively learns the lower spatial dispersion and higher high-frequency sensitivity of MEG via the spatial focus mapping module and the broadband spectral calibration module. Experimental results demonstrate that the synthesized MEG signals show high consistency with the real MEG in both time-frequency characteristics and source space activation patterns. More importantly, downstream BCI decoding experiments demonstrate that using synthesized MEG leads to performance enhancements not only on paired EEG-MEG datasets but also on independent EEG-only datasets. Overall, this framework opens a new avenue for overcoming data bottlenecks in BCI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.06990v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhuo Li, Shuqiang Wang</dc:creator>
    </item>
    <item>
      <title>Adaptive Temporal Dynamics for Personalized Emotion Recognition: A Liquid Neural Network Approach</title>
      <link>https://arxiv.org/abs/2602.06997</link>
      <description>arXiv:2602.06997v1 Announce Type: new 
Abstract: Emotion recognition from physiological signals remains challenging due to their non-stationary, noisy, and subject-dependent characteristics. This work presents, to the best of our knowledge, the first comprehensive application of liquid neural networks for EEG-based emotion recognition. The proposed multimodal framework combines convolutional feature extraction, liquid neural networks with learnable time constants, and attention-guided fusion to model temporal EEG dynamics with complementary peripheral physiological and personality features. Dedicated subnetworks are used to process EEG features and auxiliary modalities, and a shared autoencoder-based fusion module is used to learn discriminative latent representations before classification. Subject-dependent experiments conducted on the PhyMER dataset across seven emotional classes achieve an accuracy of 95.45%, surpassing previously reported results. Furthermore, temporal attention analysis provides interpretable insights into emotion-specific temporal relevance, and t-SNE visualizations demonstrate enhanced class separability, highlighting the effectiveness of the proposed approach. Finally, statistical analysis of temporal dynamics confirms that the network self-organizes into distinct functional groups with specialized fast and slow neurons, proving it independently tunes learnable time constants and memory dominance to effectively capture complex emotion artifacts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.06997v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anindya Bhattacharjee, Nittya Ananda Biswas, K. A. Shahriar, Adib Rahman</dc:creator>
    </item>
    <item>
      <title>OTFS-based Integrated Positioning and Communication Systems with Low-Resolution ADCs</title>
      <link>https://arxiv.org/abs/2602.07001</link>
      <description>arXiv:2602.07001v1 Announce Type: new 
Abstract: This paper proposes a two-phase orthogonal time frequency space (OTFS)-based integrated positioning and communication (IPAC) framework under realistic low-resolution analog-to-digital converters (ADCs). In the uplink phase, the positioning signal is used to estimate channel parameters, which are subsequently used to determine the user's position. The spatial smoothing-multiple signal classification algorithm is introduced to estimate the angle-of-arrival, whereas an iterative interference cancellation scheme is conceived for the remaining parameters' estimation. The corresponding Cramer-Rao lower bounds of channel parameters and user position are also derived. During the downlink communication phase, the estimated parameters are exploited to improve beamforming at the base station. Simulation results evaluate the impact of ADC quantizer resolutions. Specifically, it is shown that enhanced downlink bit error rate performance can be achieved with improved uplink positioning, while the use of low-resolution ADCs induces noticeable performance degradation in the OTFS-IPAC system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07001v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yueyi Yang, Zeping Sui, Zilong Liu, Leila Musavian</dc:creator>
    </item>
    <item>
      <title>Behavior Score Prediction in Resting-State Functional MRI by Deep State Space Modeling</title>
      <link>https://arxiv.org/abs/2602.07131</link>
      <description>arXiv:2602.07131v1 Announce Type: new 
Abstract: Early clinical assessment of Alzheimer's disease relies on behavior scores that measure a subject's language, memory, and cognitive skills. On the medical imaging side, functional magnetic resonance imaging has provided invaluable insights into the neural pathways underlying Alzheimer's disease. While prior studies have used resting-state functional MRI by extracting functional connectivity matrices, these approaches neglect the temporal dynamics inherent in functional data. In this work, we present a deep state space modeling framework that directly leverages the blood-oxygenation-level-dependent time series to learn a sparse collection of brain regions to predict behavior scores. Our model extracts temporal features that encapsulate nuanced patterns of intrinsic brain activity, thereby enhancing predictive performance compared to traditional connectivity methods. We identify specific brain regions that are most predictive of cognitive impairment through experiments on data provided by the Michigan Alzheimer's Disease Research Center, providing new insights into the neural substrates of early Alzheimer's pathology. These findings have important implications for the possible development of risk monitoring and intervention strategies in Alzheimer's disease.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07131v1</guid>
      <category>eess.SP</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Javier Salazar Cavazos, Maximillian Egan, Krisanne Litinas, Benjamin Hampstead, Scott Peltier</dc:creator>
    </item>
    <item>
      <title>ML-Enabled Deformable Matched Filters for Bandlimitation Compensation in Free-Space Optics</title>
      <link>https://arxiv.org/abs/2602.07169</link>
      <description>arXiv:2602.07169v1 Announce Type: new 
Abstract: This paper proposes a neural-network-assisted deformable matched filtering framework for carrier-less amplitude and phase (CAP) modulation operating under bandwidth-limited channel conditions. Instead of replacing the analytically derived CAP matched filter, the proposed receiver learns a residual deformation of the nominal matched filter based on a compact set of physically motivated signal features extracted from the received waveform. A total of 16 time-domain, frequency-domain, and memory-related features are used to provide a low-dimensional representation of bandwidth-induced pulse distortion. These features are mapped by a fully connected neural network to complex-valued matched filter coefficients, enabling adaptive pulse-shape compensation prior to symbol-rate sampling. The network is trained end-to-end using a differentiable loss function based on error vector magnitude (EVM). Experimental results obtained using a hardware-in-the-loop CAP transmission system demonstrate that the proposed deformable matched filter significantly outperforms conventional fixed matched filtering under severe bandwidth constraints, without requiring decision feedback or increasing receiver latency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07169v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Paul Anthony Haigh</dc:creator>
    </item>
    <item>
      <title>Spectrum Coexistence, Network Dimensioning, and Cell-Free Architectures in 5G and 5G-Advanced Wireless Networks</title>
      <link>https://arxiv.org/abs/2602.07270</link>
      <description>arXiv:2602.07270v1 Announce Type: new 
Abstract: Fifth-generation (5G) wireless networks introduce new architectural paradigms, spectrum usage models, and optimization challenges to support enhanced mobile broadband, massive machine-type communications, and ultra-reliable low-latency communications. This survey provides a comprehensive overview of key technologies and design challenges in 5G systems, with a focus on spectrum coexistence and interference management, network dimensioning and planning, cell-free massive MIMO architectures, fronthaul-aware user management, and power allocation strategies. Representative analytical, simulation-based, and optimization-driven approaches are reviewed, fundamental trade-offs are highlighted, and open research challenges relevant to 5G-Advanced and beyond are identified.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07270v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Siminfar Samakoush Galougah</dc:creator>
    </item>
    <item>
      <title>Wireless Context Engineering for Efficient Mobile Agentic AI and Edge General Intelligence</title>
      <link>https://arxiv.org/abs/2602.07321</link>
      <description>arXiv:2602.07321v1 Announce Type: new 
Abstract: Future wireless networks demand increasingly powerful intelligence to support sensing, communication, and autonomous decision-making. While scaling laws suggest improving performance by enlarging model capacity, practical edge deployments are fundamentally constrained by latency, energy, and memory, making unlimited model scaling infeasible. This creates a critical need to maximize the utility of limited inference-time inputs by filtering redundant observations and focusing on high-impact data. In large language models and generative artificial intelligence (AI), context engineering has emerged as a key paradigm to guide inference by selectively structuring and injecting task-relevant information. Inspired by this success, we extend context engineering to wireless systems, providing a systematic way to enhance edge AI performance without increasing model complexity. In dynamic environments, for example, beam prediction can benefit from augmenting instantaneous channel measurements with contextual cues such as user mobility trends or environment-aware propagation priors. We formally introduce wireless context engineering and propose a Wireless Context Communication Framework (WCCF) to adaptively orchestrate wireless context under inference-time constraints. This work provides researchers with a foundational perspective and practical design dimensions to manage the wireless context of wireless edge intelligence. An ISAC-enabled beam prediction case study illustrates the effectiveness of the proposed paradigm under constrained sensing budgets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07321v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Changyuan Zhao, Jiacheng Wang, Yunting Xu, Geng Sun, Dusit Niyato, Zan Li, Abbas Jamalipour, Dong In Kim</dc:creator>
    </item>
    <item>
      <title>Pulse Shaping Filter Design for Zak-OTFS</title>
      <link>https://arxiv.org/abs/2602.07350</link>
      <description>arXiv:2602.07350v1 Announce Type: new 
Abstract: The Zak-transform-based Orthogonal Time Frequency Space (Zak-OTFS), offers a robust framework for high-mobility communications by simplifying the input-output (I/O) relation to a twisted convolution. While this structure theoretically enables accurate channel estimation by sampling the response from one pilot symbol, practical implementation is constrained by the spreading of effective channel response induced by pulse shaping filters. To address this, we first derive the I/O relationship for discrete-time oversampled Zak-OTFS, which closely approximates the continuous-time system and facilitates analysis and numerical simulation. We show that every delay-Doppler domain symbol undergoes the same effective channel response under the discrete oversampled Zak-OTFS. We then analyze the impact of window ambiguity functions, and reveal that high sidelobes lead to wide channel spreading and degrade estimation accuracy. Building on this insight, we propose a novel pulse shaping filter design that synthesizes Prolate Spheroidal Wave Functions (PSWFs) within the Isotropic Orthogonal Transform Algorithm (IOTA) framework. Numerical simulations confirm that the proposed design achieves superior channel estimation accuracy and bit error rate (BER) performance compared to conventional root-raised-cosine and rectangular windowing schemes in the high-SNR regime.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07350v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Kecheng Zhang, Weijie Yuan, Yonghui Li</dc:creator>
    </item>
    <item>
      <title>Message Passing based Parameter Estimation in Cooperative MIMO-OFDM ISAC Systems</title>
      <link>https://arxiv.org/abs/2602.07365</link>
      <description>arXiv:2602.07365v1 Announce Type: new 
Abstract: In integrated sensing and communication (ISAC) networks, multiple base stations (BSs) collaboratively sense a common target, leveraging diversity from multiple observation perspectives and joint signal processing to enhance sensing performance. This paper introduces a novel message-passing (MP)-based parameter estimation framework for collaborative MIMO-OFDM ISAC systems, which jointly estimates the target's position and velocity. First, a signal propagation model is established based on geometric relationships, and a factor graph is constructed to represent the unknown parameters. The sum-product algorithm (SPA) is then applied to this factor graph to jointly estimate the multi-dimensional parameter vector. To reduce communication overhead and computational complexity, we employ a hierarchical message-passing scheme with Gaussian approximation. By adopting parameterized message distributions and layered processing, the proposed method significantly reduces both computational complexity and inter-BS communication overhead. Simulation results demonstrate the effectiveness of the proposed MP-based parameter estimation algorithm and highlight the benefits of multi-perspective observations and joint signal processing for cooperative sensing in MIMO-OFDM ISAC systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07365v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaohan Lv, Rang Liu, Yi Chen, Qian Liu, Ming Li</dc:creator>
    </item>
    <item>
      <title>Optimal Low-Dimensional Structures of ISAC Beamforming: Theory and Efficient Algorithms</title>
      <link>https://arxiv.org/abs/2602.07502</link>
      <description>arXiv:2602.07502v1 Announce Type: new 
Abstract: Transmit beamforming design is a fundamental problem in integrated sensing and communication (ISAC) systems. Numerous methods have been proposed to jointly optimize key performance metrics such as the signal-to-interference-plus-noise ratio and Cram\'er-Rao bound. However, the computational complexity of these methods often grows rapidly with the number of transmit antennas at the base station (BS). To tackle this challenge, we prove a fundamental structural property of the ISAC beamforming problem, i.e., there exists an optimal solution exhibiting a low-dimensional structure. This leads to an equivalent reformulation of the problem with dimension related to the number of users rather than the number of BS antennas, thereby enabling the development of low-complexity algorithms. When applying the interior-point method to the reformulated problem, we achieve up to six orders of magnitude in complexity reduction when the number of antennas exceeds the number of users by an order of magnitude. To further reduce the complexity, we develop a balanced augmented Lagrangian method to solve the reformulated problem. The proposed algorithm maintains optimality while achieving a computational complexity that scales quartically with the number of users. Our simulation results demonstrate that the proposed R-BAL method can achieve a speedup of more than 10000$\times$ over the conventional IPM in massive MIMO scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07502v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaotong Zhao, Mian Li, Ya-Feng Liu, Qingjiang Shi, Anthony Man-Cho So</dc:creator>
    </item>
    <item>
      <title>Beyond $\lambda/2$: Can Arbitrary EMVS Arrays Achieve Unambiguous NLOS Localization?</title>
      <link>https://arxiv.org/abs/2602.07515</link>
      <description>arXiv:2602.07515v1 Announce Type: new 
Abstract: Conventional radar array design mandates interelement spacing not exceeding half a wavelength ($\lambda/2$) to avoid spatial ambiguity, fundamentally limiting array aperture and angular resolution. This paper addresses the fundamental question: Can arbitrary electromagnetic vector sensor (EMVS) arrays achieve unambiguous reconfigurable intelligent surface (RIS)-aided localization when element spacing exceeds $\lambda/2$? We provide an affirmative answer by exploiting the multi-component structure of EMVS measurements and developing a synergistic estimation and optimization framework for non-line-of-sight (NLOS) bistatic multiple input multiple output (MIMO) radar. A third-order parallel factor (PARAFAC) model is constructed from EMVS observations, enabling natural separation of spatial, polarimetric, and propagation effects via the trilinear alternating least squares (TALS) algorithm. A novel phase-disambiguation procedure leverages rotational invariance across the six electromagnetic components of EMVSs to resolve $2\pi$ phase wrapping in arbitrary array geometries, allowing unambiguous joint estimation of two-dimensional (2-D) direction of departure (DOD), two-dimensional direction of arrival (DOA), and polarization parameters with automatic pairing. To support localization in NLOS environments and enhance estimation robustness, a reconfigurable intelligent surface (RIS) is incorporated and its phase shifts are optimized via semidefinite programming (SDP) relaxation to maximize received signal power, improving signal-to-noise ratio (SNR) and further suppressing spatial ambiguities through iterative refinement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07515v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hua Chen, Zhenhao Yu, Tuo Wu, Wei Liu, Maged Elkashlan, Hyundong Shin, Matthew C. Valenti, Robert Schober</dc:creator>
    </item>
    <item>
      <title>Fractional Filtering and Anomaly-Guided Diagnostics: The Local Damage Mode Extractor (LDME) for Early Gear Fault Detection</title>
      <link>https://arxiv.org/abs/2602.07527</link>
      <description>arXiv:2602.07527v1 Announce Type: new 
Abstract: Early and reliable detection of gear faults in complex drivetrain systems is critical for aviation safety and operational availability. We present the Local Damage Mode Extractor (LDME), a structured, physics-informed signal processing framework that combines dual-path denoising, multiscale decomposition, fractional-domain enhancement, and statistically principled anomaly scoring to produce interpretable condition indicators without supervision. LDME is organized in three layers: (i) dual-path denoising (DWT with adaptive Savitzky-Golay smoothing) to suppress broadband noise while preserving transient fault structure; (ii) multi-scale damage enhancement using a Teager-Kaiser pre-amplifier followed by a Hadamard-Caputo fractional operator that accentuates non-sinusoidal, low-frequency fault signatures; and (iii) decision fusion, where harmonics-aware Fourier indicators are combined and scored by an unsupervised anomaly detector. Evaluation using the Case Western Reserve University (CWRU) bearing dataset, the HUMS 2023 planetary gearbox benchmark, and a controlled simulated dataset shows that LDME consistently distinguishes nominal, early-crack, and propagated-crack stages under various operating conditions. LDME identifies the primary detection event earlier (198 cycles) than HT-TSA (284 cycles) and advances maintenance recommendation time from 383 to 365 cycles. We discuss its relation to prior art, limitations, and future theoretical directions. All code and experimental configurations are documented for reproducibility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07527v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yaakoub Berrouche</dc:creator>
    </item>
    <item>
      <title>A Scalable Cloud-Edge Collaborative CKM Construction Framework Enabled by a Foundation Prior Model</title>
      <link>https://arxiv.org/abs/2602.07586</link>
      <description>arXiv:2602.07586v1 Announce Type: new 
Abstract: Channel knowledge maps (CKMs) provide a site-specific, location-indexed knowledge base that supports environment-aware communications and sensing in 6G networks. In practical deployments, CKM observations are often noisy and irregular due to coverage-induced sparsity and hardware-induced linear/nonlinear degradations. Conventional end-to-end algorithms couple CKM prior information with task- and device-specific observations, and require labeled data and separate training for each construction configuration, which is expensive and therefore incompatible with scalable edge deployments. Motivated by the trends toward cloud-edge collaboration and the Artificial Intelligence - Radio Access Network (AI-RAN) paradigm, we develop a cloud-edge collaborative framework for scalable CKM construction, which enables knowledge sharing across tasks, devices, and regions by explicitly decoupling a generalizable CKM prior from the information provided by local observations. A foundation model is trained once in the cloud using unlabeled data to learn a generalizable CKM prior. During inference, edge nodes combine the shared prior with local observations. Experiments on the CKMImageNet dataset show that the proposed method achieves competitive construction accuracy while substantially reducing training cost and data requirements, mitigating negative transfer, and offering clear advantages in generalization and deployment scalability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07586v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sixu Xiao, Yong Zeng, Haotian Rong, Yanqun Tang</dc:creator>
    </item>
    <item>
      <title>A Tutorial on 3GPP Rel-19 Channel Modeling for 6G FR3 (7-24 GHz): From Standard Specification to Simulation Implementation</title>
      <link>https://arxiv.org/abs/2602.07623</link>
      <description>arXiv:2602.07623v1 Announce Type: new 
Abstract: The upper-mid band (7-24 GHz), designated as Frequency Range 3 (FR3), has emerged as a definitive ``golden band" for 6G networks, strategically balancing the wide coverage of sub-6 GHz with the high capacity of mmWave. To compensate for the severe path loss inherent to this band, the deployment of Extremely Large Aperture Arrays (ELAA) is indispensable. However, the legacy 3GPP TR 38.901 channel model faces critical validity challenges when applied to 6G FR3, stemming from both the distinct propagation characteristics of this frequency band and the fundamental physical paradigm shift induced by ELAA. In response, 3GPP Release 19 (Rel-19) has validated the model through extensive new measurements and introduced significant enhancements. This tutorial provides a comprehensive guide to the Rel-19 channel model for 6G FR3, bridging the gap between standardization specifications and practical simulation implementation. First, we provide a high-level overview of the fundamental principles of the 3GPP channel modeling framework. Second, we detail the specific enhancements and modifications introduced in Rel-19, including the rationale behind the new Suburban Macro (SMa) scenario, the mathematical modeling of ELAA-driven features such as near-field and spatial non-stationarity, and the recalibration of large-scale parameters. Overall, this tutorial serves as an essential guide for researchers and engineers to master the latest 3GPP channel modeling methodology, laying a solid foundation for the accurate design and performance evaluation of future 6G FR3 networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07623v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Pan Tang, Huixin Xu, Jianhua Zhang, Ximan Liu, Enrui Liu, Haiyang Miao, Xiaodong Sun, Wei Jiang, Guangyi Liu</dc:creator>
    </item>
    <item>
      <title>MI-ISAC: Magneto-Inductive Integrated Sensing and Communication in the Reactive Near-Field for RF-Denied Environments</title>
      <link>https://arxiv.org/abs/2602.07714</link>
      <description>arXiv:2602.07714v1 Announce Type: new 
Abstract: Radio-frequency integrated sensing and communication (RF-ISAC) is ineffective inunderground, underwater, and in-body environments where conductive media attenuate electromagnetic waves by tens of dB per meter. This article presents magneto-inductive ISAC (MI-ISAC), a paradigm that exploits the reactive near-field quasi-static coupling inherent to MI links, enabling a fundamentally different approach to ISAC in these RF-denied environments. Five foundational results are established: (i)~tri-axial coils are necessary and sufficient for identifiable joint range-and-angle estimation; (ii)~coupling strength changes sharply with range, enabling theoretical sub-millimeter accuracy at typical MI distances despite kHz-level bandwidth; (iii)~time-of-flight is ineffective under such narrow bandwidth, but the coupling gradient provides approximately six orders of magnitude finer resolution; (iv)~MI-ISAC can provide 4--10+\,dB sensing gain over time-division baselines; and (v)~the MI-MIMO channel is geometry-invariant and well-conditioned across all orientations. Applications and a research roadmap are discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07714v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haofan Dong, Ozgur B. Akan</dc:creator>
    </item>
    <item>
      <title>Joint Simplicial Complex Learning via Binary Linear Programming</title>
      <link>https://arxiv.org/abs/2602.07896</link>
      <description>arXiv:2602.07896v1 Announce Type: new 
Abstract: Learning the topology of higher-order networks from data is a fundamental challenge in many signal processing and machine learning applications. Simplicial complexes provide a principled framework for modeling multi-way interactions, yet learning their structure is challenging due to the strong coupling across different simplicial levels imposed by the inclusion property. In this work, we propose a joint framework for simplicial complex learning that enforces the inclusion property through a linear constraint, enabling the formulation of the problem as a binary linear program. The objective function consists of a combination of smoothness measures across all considered simplicial levels, allowing for the incorporation of arbitrary smoothness criteria. This formulation enables the simultaneous estimation of edges and higher-order simplices within a single optimization problem. Experiments on simulated and real-world data demonstrate that the proposed joint approach outperforms hierarchical and greedy baselines, while more faithfully enforcing higher-order structural priors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07896v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Varun Sarathchandran, Geert Leus</dc:creator>
    </item>
    <item>
      <title>End-to-End Secure Connection Probability in MultiLayer Networks with Heterogeneous Rician Fading</title>
      <link>https://arxiv.org/abs/2602.07959</link>
      <description>arXiv:2602.07959v1 Announce Type: new 
Abstract: Ensuring physical-layer security in non-terrestrial networks (NTNs) is challenging due to their global coverage and multi-hop relaying across heterogeneous network layers, where the locations and channels of potential eavesdroppers are typically unknown. In this work, we derive a tractable closedform expression of the end-to-end secure connection probability (SCP) of multi-hop relay routes under heterogeneous Rician fading. The resulting formula shares the same functional form as prior Rayleigh-based approximations but for the coefficients, thereby providing analytical support for the effectiveness of heuristic posterior coefficient calibration adopted in prior work. Numerical experiments under various conditions show that the proposed scheme estimates the SCP with an 1%p error in most cases; and doubles the accuracy compared with the conventional scheme even in the worst case. As a case study, we apply the proposed framework to real-world space-air-groundsea integrated network dataset, showing that the derived SCP accurately captures observed security trends in practical settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07959v1</guid>
      <category>eess.SP</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hyeonsu Lyu, Yumin Kim, Hyun Jong Yang</dc:creator>
    </item>
    <item>
      <title>Adjustment of Cluster-Then-Predict Framework for Multiport Scatterer Load Prediction</title>
      <link>https://arxiv.org/abs/2602.08129</link>
      <description>arXiv:2602.08129v1 Announce Type: new 
Abstract: Predicting interdependent load values in multiport scatterers is challenging due to high dimensionality and complex dependence between impedance and scattering ability, yet this prediction remains crucial for the design of communication and measurement systems. In this paper, we propose a two-stage cluster-then-predict framework for multiple load values prediction task in multiport scatterers. The proposed cluster-then-predict approach effectively captures the underlying functional relation between S-parameters and corresponding load impedances, achieving up to a 46% reduction in Root Mean Square Error (RMSE) compared to the baseline when applied to gradient boosting (GB). This improvement is consistent across various clustering and regression methods. Furthermore, we introduce the Real-world Unified Index (RUI), a metric for quantitative analysis of trade-offs among multiple metrics with conflicting objectives and different scales, suitable for performance assessment in realistic scenarios. Based on RUI, the combination of K-means clustering and k-nearest neighbors (KNN) is identified as the optimal setup for the analyzed multiport scatterer.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08129v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hanjun Park, Aleksandr D. Kuznetsov, Ville Viikari</dc:creator>
    </item>
    <item>
      <title>AFDM: Evolving OFDM Towards 6G+</title>
      <link>https://arxiv.org/abs/2602.08163</link>
      <description>arXiv:2602.08163v2 Announce Type: new 
Abstract: As the standardization of sixth generation (6G) wireless systems accelerates, there is a growing consensus in favor of evolutionary waveforms that offer new features while maximizing compatibility with orthogonal frequency division multiplexing (OFDM), which underpins the 4G and 5G systems. This article presents affine frequency division multiplexing (AFDM) as a premier candidate for 6G, offering intrinsic robustness for both high-mobility communications and integrated sensing and communication (ISAC) in doubly dispersive channels, while maintaining a high degree of synergy with the legacy OFDM. To this end, we provide a comprehensive analysis of AFDM, starting with a generalized fractional-delay-fractional-Doppler (FDFD) channel model that accounts for practical pulse shaping filters and inter-sample coupling. We then detail the AFDM transceiver architecture, demonstrating that it reuses nearly the entire OFDM pipeline and requires only lightweight digital pre- and post-processing. We also analyze the impact of hardware impairments, such as phase noise and carrier frequency offset, and explore advanced functionalities enabled by the chirp-parameter domain, including index modulation and physical-layer security. By evaluating the reusability across the radio-frequency, physical, and higher layers, the article demonstrates that AFDM provides a low-risk, feature-rich, and efficient path toward achieving high-fidelity communications in the later versions of 6G and beyond (6G+).</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08163v2</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hyeon Seok Rou, Vincent Savaux, Zeping Sui, Giuseppe Thadeu Freitas de Abreu, Zilong Liu</dc:creator>
    </item>
    <item>
      <title>An Experimental Study on Fine-Grained Bistatic Sensing of UAV Trajectory via Cellular Downlink Signals</title>
      <link>https://arxiv.org/abs/2602.08203</link>
      <description>arXiv:2602.08203v1 Announce Type: new 
Abstract: In this letter, a dual-bistatic unmanned aerial vehicles (UAVs) tracking system utilizing downlink Long-Term Evolution (LTE) signals is proposed and demonstrated. Particularly, two LTE base stations (BSs) are exploited as illumination sources. Two passive sensing receivers are deployed at different locations to detect the bistatic Doppler frequencies of the target UAV at different directions according to downlink signals transmitted from their corresponding BSs, such that the velocities of the UAV versus time can be estimated. Hence, the trajectories of the target UAV can be reconstructed. Although both the target UAV and the sensing receivers are around 200 meters away from the illuminating BSs, it is demonstrated by experiments that the tracking errors are below 50 centimeters for 90% of the complicated trajectories, when the distances between the UAV and sensing receivers are less than 30 meters. Note this accuracy is significantly better than the ranging resolution of LTE signals, high-accuracy trajectory tracking for UAV might be feasible via multi-angle bistatic Doppler measurements if the receivers are deployed with a sufficient density.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08203v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chenqing Ji, Jiahong Liu, Qionghui Liu, Yifei Sun, Chao Yu, Rui Wang</dc:creator>
    </item>
    <item>
      <title>LocDreamer: World Model-Based Learning for Joint Indoor Tracking and Anchor Scheduling</title>
      <link>https://arxiv.org/abs/2602.08204</link>
      <description>arXiv:2602.08204v1 Announce Type: new 
Abstract: Accurate, resource-efficient localization and tracking enables numerous location-aware services in next-generation wireless networks. However, existing machine learning-based methods often require large labeled datasets while overlooking spectrum and energy efficiencies. To fill this gap, we propose LocDreamer, a world model (WM)-based framework for joint target tracking and scheduling of localization anchors. LocDreamer learns a WM that captures the latent representation of the target motion and localization environment, thereby generating synthetic measurements to imagine arbitrary anchor deployments. These measurements enable imagination-driven training of both the tracking model and the reinforcement learning (RL)-based anchor scheduler that activates only the most informative anchors, which significantly reduce energy and signaling costs while preserving high tracking accuracy. Experiments on a real-world indoor dataset demonstrate that LocDreamer substantially improves data efficiency and generalization, outperforming conventional Bayesian filter with random scheduling by 37% in tracking accuracy, and achieving 86% of the accuracy of same model trained directly on real data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08204v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>AAAI-26 Workshop Machine Learning for Wireless Communication and Networks (ML4Wireless), 2026</arxiv:journal_reference>
      <dc:creator>Geng Wang, Zhouyou Gu, Shenghong Li, Peng Cheng, Jihong Park, Branka Vucetic, Yonghui Li</dc:creator>
    </item>
    <item>
      <title>Riemannian Manifold Optimization for Advanced Wireless Communications: Fundamentals and Applications</title>
      <link>https://arxiv.org/abs/2602.08225</link>
      <description>arXiv:2602.08225v1 Announce Type: new 
Abstract: Next-generation wireless communications promise transformative technologies such as massive multiple-input multiple-output (MIMO), reconfigurable intelligent surfaces (RIS), integrated sensing and communication (ISAC), and fluid antenna systems (FAS). However, deploying these technologies is hindered by large-scale optimization problems with nonconvex constraints. Conventional Euclidean-space methods rely on approximations or relaxations, which degrade performance and incur substantial computational costs. Riemannian manifold optimization (RMO) offers a powerful alternative that directly operates on the manifold defined by the geometric constraints. This approach inherently satisfies the constraints at every optimization step, thereby avoiding the performance degradation and substantial computational costs. In this paper, we first elaborate on the principles of RMO, including the fundamental concepts, tools, and methods, emphasizing its effectiveness for nonconvex problems. We then introduce its applications in advanced wireless communications, showing how constrained problems are reformulated on their natural manifolds and solved using tailored RMO algorithms. Furthermore, we present a case study on secure beamforming in an FAS-assisted non-orthogonal multiple access (NOMA) system, demonstrating RMO's superiority over conventional methods in terms of both performance and computational efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08225v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Siwen Li, Jiacheng Chen, Yunting Xu, Shaofeng Li, Le Yao, Jieling Wang, Dusit Niyato</dc:creator>
    </item>
    <item>
      <title>Towards Optimal Semantic Communications: Reconsidering the Role of Semantic Feature Channels</title>
      <link>https://arxiv.org/abs/2602.08260</link>
      <description>arXiv:2602.08260v1 Announce Type: new 
Abstract: This paper investigates the optimization of transmitting the encoder outputs, termed semantic features (SFs), in semantic communication (SC). We begin by modeling the entire communication process from the encoder output to the decoder input, encompassing the physical channel and all transceiver operations, as the SF channel, thereby establishing an encoder-SF channel-decoder pipeline. In contrast to prior studies that assume a fixed SF channel, we note that the SF channel is configurable, as its characteristics are shaped by various transmission and reception strategies, such as power allocation. Based on this observation, we formulate the SF channel optimization problem under a mutual information constraint between the SFs and their reconstructions, and analytically derive the optimal SF channel under a linear encoder-decoder structure and Gaussian source assumption. Building upon this theoretical foundation, we propose a joint optimization framework for the encoder-decoder and SF channel, applicable to both analog and digital SCs. To realize the optimized SF channel, we also propose a physical-layer calibration strategy that enables real-time power control and adaptation to varying channel conditions. Simulation results demonstrate that the proposed SF channel optimization achieves superior task performance under various communication environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08260v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yongjeong Oh, Jihong Park, Jinho Choi, Yo-Seb Jeon</dc:creator>
    </item>
    <item>
      <title>Beam Alignment in Multipath Environments for Integrated Sensing and Communication using Bandit Learning</title>
      <link>https://arxiv.org/abs/2602.08380</link>
      <description>arXiv:2602.08380v1 Announce Type: new 
Abstract: Prior works have explored multi-armed bandit (MAB) algorithms for the selection of optimal beams for millimeter-wave (mmW) communications between base station and mobile users. However, when the number of beams is large, the existing MAB algorithms are characterized by long exploration times, resulting in poor overall communication throughput. In this work, we propose augmenting the upper confidence bound (UCB) based MAB with integrated sensing and communication (ISAC) to address this limitation. The premise of the work is that the radar and communication functionalities share the same field-of-view and that communication mobile users are detected by the radar as mobile targets. The radar information is used for significantly reducing the number of candidate beams for the UCB, resulting in an overall reduction in the exploration time. Further, the radar information is used to estimate the realignment time in quasi-stationary scenarios. We have realized the MAB and radar signal processing algorithms on the system on chip (SoC) via hardware-software co-design (HSCD) and fixed-point analysis. We demonstrate the significant gain in execution time using accelerators. The simulations consider complex propagation channels involving direct and multipath, with simple and extended radar targets in the presence of significant static clutter. The resulting experiments show that the proposed ISAC-based MAB achieves a 35% reduction in the overall exploration time and 1.4 factor higher throughput as compared to the conventional MAB that is based only on communications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08380v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <arxiv:journal_reference>IEEE Journal of Selected Topics in Signal Processing 18.5 (2024): pp-871-885</arxiv:journal_reference>
      <dc:creator>Akanksha Sneh, Shobha Sundar Ram, Sumit J Darak, Aakanksha Tewari</dc:creator>
    </item>
    <item>
      <title>IEEE 802.11ad-Aided 5-D Sensing with a UAV Swarm in Urban Environment</title>
      <link>https://arxiv.org/abs/2602.08396</link>
      <description>arXiv:2602.08396v1 Announce Type: new 
Abstract: Aerial base stations mounted on unmanned aerial vehicles (UAVs) support next-generation wireless networks in challenging environments such as urban areas, disaster zones, and remote locations. Further, UAV swarms overcome the challenges of limited battery life and other operational constraints of a single UAV. However, tracking mobile users on the ground by each UAV and the corresponding synchronization between the UAVs is a significant issue that must be addressed before this framework can be deployed in reality. Incorporating additional sensing capabilities to facilitate this additional requirement would introduce significant overhead in terms of hardware, cost, and power to each UAV. Instead, we propose an integrated sensing and communications-enabled swarm UAV system, based on the millimeter-wave IEEE 802.11ad protocol. Further, we show that our proposed system is capable of five-dimensional (5-D) ground target sensing (range, Doppler velocity, azimuth, elevation, and polarization) in an urban environment. Numerical experiments using realistic models demonstrate and validate the performance of 5-D sensing using our proposed 802-11ad-aided UAV system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08396v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <arxiv:journal_reference>ICASSP 2025-2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2025</arxiv:journal_reference>
      <dc:creator>Akanksha Sneh, Shobha Sundar Ram, Kumar Vijay Mishra</dc:creator>
    </item>
    <item>
      <title>Movable Antenna Enabled Reconfigurable Array Topologies for Structured Beam Communications</title>
      <link>https://arxiv.org/abs/2602.08409</link>
      <description>arXiv:2602.08409v1 Announce Type: new 
Abstract: Spatially structured beams have emerged as a promising technology for enhancing spectrum efficiency (SE) in sixth-generation (6G) networks. However, structured beam schemes based on fixed-position antennas (FPAs) fail to fully exploit the array aperture, thereby limiting their topological reconfigurability and adaptability to diverse communication scenarios. To overcome these limitations, this paper proposes a novel structured beam communication framework exploiting movable antennas (MAs) to achieve reconfigurable array topologies. Specifically, we develop an MA-based geometric modeling framework to construct a variety of practical array topologies, thereby enabling the realization of diverse array configurations utilizing a unified hardware platform. Furthermore, we investigate the joint design of the array topology and the structured beamforming vector to efficiently exploit the array aperture and facilitate the multiplexing of orthogonal spatial modes. Accordingly, we formulate the corresponding beam generation and demodulation schemes and derive the channel gains under varying array topologies. We also propose an alternating optimization algorithm to jointly optimize the array topology configuration, the antenna element positions, and the structured beamforming vector, with the aim of maximizing the system SE. Numerical results demonstrate that the proposed joint design significantly enhances the SE compared to conventional FPA schemes. By synergizing the spatial multiplexing degrees of freedom (DoFs) of structured beams with the mobility DoFs of MAs within 2D planar regions, this work establishes a reconfigurable and practical framework for structured beam-based wireless communications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08409v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongyun Jin, Wenchi Cheng, Jingqing Wang</dc:creator>
    </item>
    <item>
      <title>Reconfigurable Low-Complexity Architecture for High Resolution Doppler Velocity Estimation in Integrated Sensing and Communication System</title>
      <link>https://arxiv.org/abs/2602.08415</link>
      <description>arXiv:2602.08415v1 Announce Type: new 
Abstract: In millimeter wave integrated sensing and communication (ISAC) systems for intelligent transportation, radar and communication share spectrum and hardware in a time division manner. Radar rapidly detects and localizes mobile users (MUs), after which communication proceeds through narrow beams identified by radar. Achieving fine Doppler resolution for MU clutter discrimination requires long coherent processing intervals, reducing communication time and throughput. To address this, we propose a reconfigurable architecture for Doppler estimation realized on a system on chip using hardware software codesign. The architecture supports algorithm level reconfiguration, dynamically switching between low-complexity, high-speed FFT-based coarse estimation and high complexity ESPRIT based fine estimation. We introduce modifications to ESPRIT that achieve 6.7 times faster execution while reducing memory and multiplier usage by 79% and 63%, respectively, compared to state of the art approaches, without compromising accuracy. Additionally, the reconfigurable architecture can switch to lower slow time packets under high SNR conditions, improving latency further by 2 times with no loss in performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08415v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aakanksha Tewari, Samarth Sharma Bhardwaj, Sumit J Darak, Shobha Sundar Ram</dc:creator>
    </item>
    <item>
      <title>Symbol Rate Maximization in Rolling-Shutter OCC: Design and Implementation Considerations</title>
      <link>https://arxiv.org/abs/2602.08474</link>
      <description>arXiv:2602.08474v1 Announce Type: new 
Abstract: Optical Camera Communication (OCC) systems can take advantage of the row-by-row scanning process of rolling-shutter cameras to capture the fast variations of light intensity coming from Visible Light Communication (VLC) LED-based transmitters. In order to study the maximum data rate that is feasible in such kind of OCC systems, this paper presents its equivalent digital communication system model in which the rolling-shutter camera is modeled as a rectangular matched-filter whose time width is equal to the exposure time of the camera, followed by a sampling process at the pixel row sweep rate of the camera. Based on the proposed rolling-shutter camera model, the maximum symbol rate that such OCC systems can support is experimentally demonstrated, and the impact of imperfect time synchronization between the VLC transmitter and the rolling-shutter OCC receiver is characterized in the form of Inter-Symbol Interference (ISI). The equivalent three-tap channel model that results from this process is experimentally validated and the generated ISI is compensated with the use of linear equalization in reception. Simulation and experimental results show a strong correlation between them, demonstrating that the proposed approach can be used to make the OCC system work at the Nyquist sampling rate, which is equivalent to the pixel row sweep rate of the rolling-shutter camera used in reception.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08474v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xinyu Zhang, Alexis A. Dowhuszko, Miguel R\^ego, Pedro Fonseca, Lu\'is Nero Alves, Jyri H\"am\"al\"ainen, Risto Wichman</dc:creator>
    </item>
    <item>
      <title>Radar Operating Metrics and Network Throughput for Integrated Sensing and Communications in Millimeter-wave Urban Environments</title>
      <link>https://arxiv.org/abs/2602.08495</link>
      <description>arXiv:2602.08495v1 Announce Type: new 
Abstract: Millimeter wave integrated sensing and communication (ISAC) systems are being researched for next-generation intelligent transportation systems. Here, radar and communication functionalities share a common spectrum and hardware resources in a time-multiplexed manner. The objective of the radar is to first scan the angular search space and detect and localize mobile users/targets in the presence of discrete clutter scatterers. Subsequently, this information is used to direct highly directional beams toward these mobile users for communication service. The choice of radar parameters such as the radar duty cycle and the corresponding beamwidth are critical for realizing high communication throughput. In this work, we use the stochastic geometry-based mathematical framework to analyze the radar operating metrics as a function of diverse radar, target, and clutter parameters and subsequently use these results to study the network throughput of the ISAC system. The results are validated through Monte Carlo simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08495v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <arxiv:journal_reference>2024 IEEE Radar Conference (RadarConf24) (pp. 1-6)</arxiv:journal_reference>
      <dc:creator>Akanksha Sneh, Shobha Sundar Ram</dc:creator>
    </item>
    <item>
      <title>DNS: Data-driven Nonlinear Smoother for Complex Model-free Process</title>
      <link>https://arxiv.org/abs/2602.08560</link>
      <description>arXiv:2602.08560v1 Announce Type: new 
Abstract: We propose data-driven nonlinear smoother (DNS) to estimate a hidden state sequence of a complex dynamical process from a noisy, linear measurement sequence. The dynamical process is model-free, that is, we do not have any knowledge of the nonlinear dynamics of the complex process. There is no state-transition model (STM) of the process available. The proposed DNS uses a recurrent architecture that helps to provide a closed-form posterior of the hidden state sequence given the measurement sequence. DNS learns in an unsupervised manner, meaning the training dataset consists of only measurement data and no state data. We demonstrate DNS using simulations for smoothing of several stochastic dynamical processes, including a benchmark Lorenz system. Experimental results show that the DNS is significantly better than a deep Kalman smoother (DKS) and an iterative data-driven nonlinear state estimation (iDANSE) smoother.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08560v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fredrik Cumlin, Anubhab Ghosh, Saikat Chatterjee</dc:creator>
    </item>
    <item>
      <title>RFSoC-Based Integrated Navigation and Sensing Using NavIC</title>
      <link>https://arxiv.org/abs/2602.08596</link>
      <description>arXiv:2602.08596v1 Announce Type: new 
Abstract: Prior art has proposed a secondary application for Global Navigation Satellite System (GNSS) infrastructure for remote sensing of ground-based and maritime targets. Here, a passive radar receiver is deployed to detect uncooperative targets on Earth's surface by capturing ground-reflected satellite signals. This work demonstrates a hardware prototype of an L-band Navigation with Indian Constellation (NavIC) satellite-based remote sensing receiver system mounted on an AMD Zynq radio frequency system-on-chip (RFSoC) platform. Two synchronized receiver channels are introduced for capturing the direct signal (DS) from the satellite and ground-reflected signal (GRS) returns from targets. These signals are processed on the ARM processor and field programmable gate array (FPGA) of the RFSoC to generate delay-Doppler maps of the ground-based targets. The performance is first validated in a loop-back configuration of the RFSoC. Next, the DS and GRS signals are emulated by the output from two ports of the Keysight Arbitrary Waveform Generator (AWG) and interfaced with the RFSoC where the signals are subsequently processed to obtain the delay-Doppler maps. The performance is validated for different signal-to-noise ratios (SNR).</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08596v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Riya Sachdeva, Aakanksha Tewari, Sumit J. Darak, Shobha Sundar Ram, Sanat K. Biswas</dc:creator>
    </item>
    <item>
      <title>Ziv-Zakai Bound for Near-Field Localization and Sensing</title>
      <link>https://arxiv.org/abs/2602.08609</link>
      <description>arXiv:2602.08609v1 Announce Type: new 
Abstract: The increasing carrier frequencies and growing physical dimensions of antenna arrays in modern wireless systems are driving renewed interest in localization and sensing under near-field conditions. In this paper, we analyze the Ziv-Zakai Bound (ZZB) for near-field localization and sensing operated with large antenna arrays, which offers a tighter characterization of estimation accuracy compared to traditional bounds such as the Cram\'er-Rao Bound (CRB), especially in low signal-to-noise ratio or threshold regions. Leveraging spherical wavefront and array geometry in the signal model, we evaluate the ZZB for distance and angle estimation, investigating the dependence of the accuracy on key signal and system parameters such as array geometry, wavelength, and target position. Our analysis highlights the transition behavior of the ZZB and underscores the fundamental limitations and opportunities for accurate near-field sensing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08609v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicol\`o Decarli, Davide Dardari</dc:creator>
    </item>
    <item>
      <title>Improving Reliability of Hybrid Bit-Semantic Communications for Cellular Networks</title>
      <link>https://arxiv.org/abs/2602.08697</link>
      <description>arXiv:2602.08697v1 Announce Type: new 
Abstract: Semantic communications (SemComs) have been considered as a promising solution to reduce the amount of transmitted information, thus paving the way for more energy-and spectrum-efficient wireless networks. Nevertheless, SemComs rely heavily on the utilization of deep neural networks (DNNs) at the transceivers, which limit the accuracy between the original and reconstructed data and are challenging to implement in practice due to increased architecture complexity. Thus, hybrid cellular networks that utilize both conventional bit communications (BitComs) and SemComs have been introduced to bridge the gap between required and existing infrastructure. To facilitate such networks, in this work, we investigate reliability by deriving closed-form expressions for the outage probability of the network. Additionally, we propose a generalized outage probability through which the cell radius that achieves a desired outage threshold for a specific range of users is calculated in closed form. Additionally, to consider the practical limitations caused by the specialized dedicated hardware and the increased memory and computational resources that are required to support SemCom, a semantic utilization metric is proposed. Based on this metric, we express the probability that a specific number of users select SemCom transmission and calculate the optimal cell radius for that number in closed form. Simulation results validate the derived analytical expressions and the characterized design properties of the cell radius found through the proposed metrics, providing useful insights.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08697v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nikos G. Evgenidis, Sotiris A. Tegos, Panagiotis D. Diamantoulakis, Ioannis Krikidis, George K. Karagiannidis</dc:creator>
    </item>
    <item>
      <title>Joint Channel Sounding and Source-Channel Coding for MIMO-OFDM Systems: Deep Unified Encoding and Parallel Flow-Matching Decoding</title>
      <link>https://arxiv.org/abs/2602.08795</link>
      <description>arXiv:2602.08795v1 Announce Type: new 
Abstract: In this work, we propose a deep unified (DU) encoder that embeds source information in a codeword that contains sufficient redundancy to handle both channel and source uncertainties, without enforcing an explicit pilot-data separation. At the receiver, we design a parallel flow-matching (PFM) decoder that leverages flow-based generative priors to jointly estimate the channel and the source, yielding much more efficient inference than the existing diffusion-based approaches. To benchmark performance limits, we derive the Bayesian Cram\'er-Rao bound (BCRB) for the joint channel and source estimation problem. Extensive simulations over block-fading MIMO-OFDM channels demonstrate that the proposed DU-PFM approach drastically outperforms the state-of-the-art methods in both channel estimation accuracy and source reconstruction quality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08795v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hao Jiang, Xiaojun Yuan, Qinghua Guo</dc:creator>
    </item>
    <item>
      <title>Denoise Stepwise Signals by Diffusion Model Based Approach</title>
      <link>https://arxiv.org/abs/2602.08904</link>
      <description>arXiv:2602.08904v1 Announce Type: new 
Abstract: Stepwise signals are ubiquitous in single-molecule detections, where abrupt changes in signal levels typically correspond to molecular conformational changes or state transitions. However, these features are inevitably obscured by noise, leading to uncertainty in estimating both signal levels and transition points. Traditional frequency-domain filtering is ineffective for denoising stepwise signals, as edge-related high-frequency components strongly overlap with noise. Although Hidden Markov Model-based approaches are widely used, they rely on stationarity assumptions and are not specifically designed for signal denoising. Here, we propose a diffusion model-based algorithm for stepwise signal denoising, named the Stepwise Signal Diffusion Model (SSDM). During training, SSDM learns the statistical structure of stepwise signals via a forward diffusion process that progressively adds noise. In the following reverse process, the model reconstructs clean signals from noisy observations, integrating a multi-scale convolutional network with an attention mechanism. Training data are generated by simulating stepwise signals through a Markov process with additive Gaussian noise. Across a broad range of signal-to-noise ratios, SSDM consistently outperforms traditional methods in both signal level reconstruction and transition point detection. Its effectiveness is further demonstrated on experimental data from single-molecule Forster Resonance Energy Transfer and nanopore DNA translocation measurements. Overall, SSDM provides a general and robust framework for recovering stepwise signals in various single-molecule detections and other physical systems exhibiting discrete state transitions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08904v1</guid>
      <category>eess.SP</category>
      <category>physics.app-ph</category>
      <category>physics.bio-ph</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Xingdi Tong, Chenyu Wen</dc:creator>
    </item>
    <item>
      <title>Perspective-aware fusion of incomplete depth maps and surface normals for accurate 3D reconstruction</title>
      <link>https://arxiv.org/abs/2602.07444</link>
      <description>arXiv:2602.07444v1 Announce Type: cross 
Abstract: We address the problem of reconstructing 3D surfaces from depth and surface normal maps acquired by a sensor system based on a single perspective camera. Depth and normal maps can be obtained through techniques such as structured-light scanning and photometric stereo, respectively. We propose a perspective-aware log-depth fusion approach that extends existing orthographic gradient-based depth-normals fusion methods by explicitly accounting for perspective projection, leading to metrically accurate 3D reconstructions. Additionally, the method handles missing depth measurements by leveraging available surface normal information to inpaint gaps. Experiments on the DiLiGenT-MV data set demonstrate the effectiveness of our approach and highlight the importance of perspective-aware depth-normals fusion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07444v1</guid>
      <category>cs.CV</category>
      <category>eess.SP</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ondrej Hlinka, Georg Kaniak, Christian Kapeller</dc:creator>
    </item>
    <item>
      <title>Information Theoretic Modeling of Interspecies Molecular Communication</title>
      <link>https://arxiv.org/abs/2602.07474</link>
      <description>arXiv:2602.07474v1 Announce Type: cross 
Abstract: Plants and insects communicate using chemical signals like volatile organic compounds (VOCs). A plant encodes information using different blends of VOCs, which propagate through the air to represent different symbolic information. This communication occurs in a noisy environment, characterized by wind, distance, and complex biological reactions. At the receiver, cross-reactive olfactory receptors produce stochastic binding events whose discretized durations form the receiver observation. In this paper, an information-theoretic framework is developed to model interspecies molecular communication (MC), where receptor responses are modeled probabilistically using a multinomial distribution. Numerical results show that the communication depends on environmental parameters such as wind speed, distance, and the number of released molecules. The proposed framework provides fundamental insights into the VOC-based interspecies communication under realistic biological and environmental conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07474v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bitop Maitra, Murat Kuscu, Ozgur B. Akan</dc:creator>
    </item>
    <item>
      <title>ODELoRA: Training Low-Rank Adaptation by Solving Ordinary Differential Equations</title>
      <link>https://arxiv.org/abs/2602.07479</link>
      <description>arXiv:2602.07479v1 Announce Type: cross 
Abstract: Low-rank adaptation (LoRA) has emerged as a widely adopted parameter-efficient fine-tuning method in deep transfer learning, due to its reduced number of trainable parameters and lower memory requirements enabled by Burer-Monteiro factorization on adaptation matrices. However, classical LoRA training methods treat the low-rank factor matrices individually and optimize them using standard gradient-based algorithms. Such decoupled optimization schemes are theoretically and empirically suboptimal, as they fail to fully exploit the intrinsic structure of the LoRA parameterization. In this work, we propose a novel continuous-time optimization dynamic for LoRA factor matrices in the form of an ordinary differential equation (ODE) that emulates the gradient flow of full fine-tuning on the balanced manifold. We term this approach ODELoRA. To faithfully track the trajectories of ODELoRA, we adopt well-established and theoretically grounded time-discretization schemes, including Euler and Runge--Kutta methods. Our framework provides a unified ODE-based perspective for understanding and designing LoRA training algorithms. We establish linear convergence of the proposed method under strongly convex objectives for certain discretization schemes under mild conditions, and further extend our analysis to the matrix sensing setting. Moreover, we show that ODELoRA achieves stable feature learning, a property that is crucial for training deep neural networks at different scales of problem dimensionality. Empirical results on matrix sensing tasks confirm the derived linear convergence behavior, and experiments on training physics-informed neural networks further demonstrate the superiority of ODELoRA over existing baselines, especially in the training stability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07479v1</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yihang Gao, Vincent Y. F. Tan</dc:creator>
    </item>
    <item>
      <title>Transformer-based Hybrid Beamforming with Dynamic Subarray for Near-Space Airship-Borne Communications</title>
      <link>https://arxiv.org/abs/2602.07509</link>
      <description>arXiv:2602.07509v1 Announce Type: cross 
Abstract: This paper proposes a hybrid beamforming framework for massive multiple-input multiple-output (MIMO) in near-space airship-borne communications. To achieve high energy efficiency (EE) in energy-constraint airships, a dynamic subarray structure is introduced, where each radio frequency chain (RFC) is connected to a disjoint subset of the antennas according to channel state information (CSI). The proposed joint dynamic hybrid beamforming network (DyHBFNet) comprises three key components: 1) An analog beamforming network (ABFNet) that optimizes the analog beamforming matrices and provides auxiliary information for the antenna selection network (ASNet) design, 2) an ASNet that dynamically optimizes the connections between antennas and RFCs, and 3) a digital beamforming network (DBFNet) that optimizes digital beamforming matrices by employing a model-driven weighted minimum mean square error algorithm for improving beamforming performance and convergence speed. The proposed ABFNet, ASNet, and DBFNet are all designed based on advanced Transformer encoders. Simulation results demonstrate that the proposed framework significantly enhances spectral efficiency and EE compared to baseline schemes. Additionally, its robust performance under imperfect CSI makes it a scalable solution for practical implementations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07509v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ruiqi Wang, Zhen Gao, Keke Ying, Ziwei Wan, Symeon Chatzinotas, Mohamed-Slim Alouini</dc:creator>
    </item>
    <item>
      <title>Spectral Guardrails for Agents in the Wild: Detecting Tool Use Hallucinations via Attention Topology</title>
      <link>https://arxiv.org/abs/2602.08082</link>
      <description>arXiv:2602.08082v1 Announce Type: cross 
Abstract: Deploying autonomous agents in the wild requires reliable safeguards against tool use failures. We propose a training free guardrail based on spectral analysis of attention topology that complements supervised approaches. On Llama 3.1 8B, our method achieves 97.7\% recall with multi-feature detection and 86.1\% recall with 81.0\% precision for balanced deployment, without requiring any labeled training data. Most remarkably, we discover that single layer spectral features act as near-perfect hallucination detectors: Llama L26 Smoothness achieves 98.2\% recall (213/217 hallucinations caught) with a single threshold, and Mistral L3 Entropy achieves 94.7\% recall. This suggests hallucination is not merely a wrong token but a thermodynamic state change: the model's attention becomes noise when it errs. Through controlled cross-model evaluation on matched domains ($N=1000$, $T=0.3$, same General domain, hallucination rates 20--22\%), we reveal the ``Loud Liar'' phenomenon: Llama 3.1 8B's failures are spectrally catastrophic and dramatically easier to detect, while Mistral 7B achieves the best discrimination (AUC 0.900). These findings establish spectral analysis as a principled, efficient framework for agent safety.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08082v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>eess.SP</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Valentin No\"el</dc:creator>
    </item>
    <item>
      <title>Optimal Transmit Beamforming for MIMO ISAC with Unknown Target and User Locations</title>
      <link>https://arxiv.org/abs/2602.08255</link>
      <description>arXiv:2602.08255v1 Announce Type: cross 
Abstract: This paper studies a challenging scenario in a multiple-input multiple-output (MIMO) integrated sensing and communication (ISAC) system where the locations of the sensing target and the communication user are both unknown and random, while only their probability distribution information is known. In this case, how to fully utilize the spatial resources by designing the transmit beamforming such that both sensing and communication can achieve satisfactory performance statistically is a difficult problem, which motivates the study in this paper. Moreover, we aim to reveal if it is desirable to have similar probability distributions for the target and user locations in terms of the ISAC performance. Firstly, based on only probability distribution information, we establish communication and sensing performance metrics via deriving the expected rate or posterior Cram\'{e}r-Rao bound (PCRB). Then, we formulate the transmit beamforming optimization problem to minimize the PCRB subject to the expected rate constraint, for which the optimal solution is derived. It is unveiled that the rank of the optimal transmit covariance matrix is upper bounded by the summation of MIMO communication channel matrices for all possible user locations. Furthermore, due to the need to cater to multiple target/user locations, we investigate whether dynamically employing different beamforming designs over different time slots improves the performance. It is proven that using a static beamforming strategy is sufficient for achieving the optimal performance. Numerical results validate our analysis, show that ISAC performance improves as the target/user location distributions become similar, and provide useful insights on the BS-user/-target association strategy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08255v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yizhuo Wang, Shuowen Zhang</dc:creator>
    </item>
    <item>
      <title>Hierarchical Subcode Ensemble Decoding of Polar Codes</title>
      <link>https://arxiv.org/abs/2602.08391</link>
      <description>arXiv:2602.08391v1 Announce Type: cross 
Abstract: Subcode-ensemble decoders improve iterative decoding by running multiple decoders in parallel over carefully chosen subcodes, increasing the likelihood that at least one decoder avoids the dominant trapping structures. Achieving strong diversity gains, however, requires constructing many subcodes that satisfy a linear covering property-yet existing approaches lack a systematic way to scale the ensemble size while preserving this property. This paper introduces hierarchical subcode ensemble decoding (HSCED), a new ensemble decoding framework that expands the number of constituent decoders while still guaranteeing linear covering. The key idea is to recursively generate subcode parity constraints in a hierarchical structure so that coverage is maintained at every level, enabling large ensembles with controlled complexity. To demonstrate its effectiveness, we apply HSCED to belief propagation (BP) decoding of polar codes, where dense parity-check matrices induce severe stopping-set effects that limit conventional BP. Simulations confirm that HSCED delivers significant block-error-rate improvements over standard BP and conventional subcode-ensemble decoding under the same decoding-latency constraint.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08391v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yubeen Jo, Geon Choi, Chanho Park, Namyoon Lee</dc:creator>
    </item>
    <item>
      <title>Optimizing Spectral Prediction in MXene-Based Metasurfaces Through Multi-Channel Spectral Refinement and Savitzky-Golay Smoothing</title>
      <link>https://arxiv.org/abs/2602.08406</link>
      <description>arXiv:2602.08406v1 Announce Type: cross 
Abstract: The prediction of electromagnetic spectra for MXene-based solar absorbers is a computationally intensive task, traditionally addressed using full-wave solvers. This study introduces an efficient deep learning framework incorporating transfer learning, multi-channel spectral refinement (MCSR), and Savitzky-Golay smoothing to accelerate and enhance spectral prediction accuracy. The proposed architecture leverages a pretrained MobileNetV2 model, fine-tuned to predict 102-point absorption spectra from $64\times64$ metasurface designs. Additionally, the MCSR module processes the feature map through multi-channel convolutions, enhancing feature extraction, while Savitzky-Golay smoothing mitigates high-frequency noise. Experimental evaluations demonstrate that the proposed model significantly outperforms baseline Convolutional Neural Network (CNN) and deformable CNN models, achieving an average root mean squared error (RMSE) of 0.0245, coefficient of determination \( R^2 \) of 0.9578, and peak signal-to-noise ratio (PSNR) of 32.98 dB. The proposed framework presents a scalable and computationally efficient alternative to conventional solvers, positioning it as a viable candidate for rapid spectral prediction in nanophotonic design workflows.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08406v1</guid>
      <category>physics.optics</category>
      <category>cs.AI</category>
      <category>eess.SP</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shujaat Khan, Waleed Iqbal Waseer</dc:creator>
    </item>
    <item>
      <title>Multipoint Code-Weight Sphere Decoding: Parallel Near-ML Decoding for Short-Blocklength Codes</title>
      <link>https://arxiv.org/abs/2602.08501</link>
      <description>arXiv:2602.08501v1 Announce Type: cross 
Abstract: Ultra-reliable low-latency communications (URLLC) operate with short packets, where finite-blocklength effects make near-maximum-likelihood (near-ML) decoding desirable but often too costly. This paper proposes a two-stage near-ML decoding framework that applies to any linear block code. In the first stage, we run a low-complexity decoder to produce a candidate codeword and a cyclic redundancy check. When this stage succeeds, we terminate immediately. When it fails, we invoke a second-stage decoder, termed multipoint code-weight sphere decoding (MP-WSD). The central idea behind {MP-WSD} is to concentrate the ML search where it matters. We pre-compute a set of low-weight codewords and use them to generate structured local perturbations of the current estimate. Starting from the first-stage output, MP-WSD iteratively explores a small Euclidean sphere of candidate codewords formed by adding selected low-weight codewords, tightening the search region as better candidates are found. This design keeps the average complexity low: at high signal-to-noise ratio, the first stage succeeds with high probability and the second stage is rarely activated; when it is activated, the search remains localized. Simulation results show that the proposed decoder attains near-ML performance for short-blocklength, low-rate codes while maintaining low decoding latency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08501v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yubeen Jo, Geon Choi, Yongjune Kim, Namyoon Lee</dc:creator>
    </item>
    <item>
      <title>FreqLens: Interpretable Frequency Attribution for Time Series Forecasting</title>
      <link>https://arxiv.org/abs/2602.08768</link>
      <description>arXiv:2602.08768v1 Announce Type: cross 
Abstract: Time series forecasting models often lack interpretability, limiting their adoption in domains requiring explainable predictions. We propose \textsc{FreqLens}, an interpretable forecasting framework that discovers and attributes predictions to learnable frequency components. \textsc{FreqLens} introduces two key innovations: (1) \emph{learnable frequency discovery} -- frequency bases are parameterized via sigmoid mapping and learned from data with diversity regularization, enabling automatic discovery of dominant periodic patterns without domain knowledge; and (2) \emph{axiomatic frequency attribution} -- a theoretically grounded framework that provably satisfies Completeness, Faithfulness, Null-Frequency, and Symmetry axioms, with per-frequency attributions equivalent to Shapley values. On Traffic and Weather datasets, \textsc{FreqLens} achieves competitive or superior performance while discovering physically meaningful frequencies: all 5 independent runs discover the 24-hour daily cycle ($24.6 \pm 0.1$h, 2.5\% error) and 12-hour half-daily cycle ($11.8 \pm 0.1$h, 1.6\% error) on Traffic, and weekly cycles ($10\times$ longer than the input window) on Weather. These results demonstrate genuine frequency-level knowledge discovery with formal theoretical guarantees on attribution quality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08768v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>eess.SP</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chi-Sheng Chen, Xinyu Zhang, En-Jui Kuo, Guan-Ying Chen, Qiuzhe Xie, Fan Zhang</dc:creator>
    </item>
    <item>
      <title>CFARNet: Learning-Based High-Resolution Multi-Target Detection for Rainbow Beam Radar</title>
      <link>https://arxiv.org/abs/2505.10150</link>
      <description>arXiv:2505.10150v3 Announce Type: replace 
Abstract: Millimeter-wave (mmWave) OFDM radar equipped with rainbow beamforming, enabled by phase-time arrays (PTAs), provides wide-angle coverage and is well-suited for fast real-time target detection and tracking. However, accurate detection of multiple closely spaced targets remains a key challenge for conventional signal processing pipelines, particularly those relying on constant false alarm rate (CFAR) detectors. This paper presents CFARNet, a learning-based processing framework that replaces CFAR with a convolutional neural network (CNN) for peak detection in the angle-Doppler domain. The network predicts target subcarrier indices, which guide angle estimation via a known frequency-angle mapping and enable high-resolution range and velocity estimation using the MUSIC algorithm. Extensive simulations demonstrate that CFARNet significantly outperforms a baseline combining CFAR and MUSIC, especially under low transmit power and dense multi-target conditions. The proposed method offers superior angular resolution, enhanced robustness in low-SNR scenarios, and improved computational efficiency, highlighting the potential of data-driven approaches for high-resolution mmWave radar sensing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.10150v3</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qiushi Liang, Yeyue Cai, Jianhua Mo, Meixia Tao</dc:creator>
    </item>
    <item>
      <title>Joint Activity Detection and Channel Estimation for Massive Connectivity: Where Message Passing Meets Score-Based Generative Priors</title>
      <link>https://arxiv.org/abs/2506.00581</link>
      <description>arXiv:2506.00581v2 Announce Type: replace 
Abstract: Massive connectivity supports the sporadic access of a vast number of devices without requiring prior permission from the base station (BS). In such scenarios, the BS must perform joint activity detection and channel estimation (JADCE) prior to data reception. Message-passing algorithms have emerged as a prominent solution for JADCE under a Bayesian inference framework. The existing message-passing algorithms, however, typically rely on some hand-crafted and overly simplistic priors of the wireless channel, leading to significant channel estimation errors and reduced activity detection accuracy. In this paper, we focus on the problem of JADCE in a multiple-input multiple-output orthogonal frequency division multiplexing (MIMO-OFDM) grant-free random access network. We propose to incorporate a more accurate channel prior learned by score-based generative models into message passing, so as to push towards the performance limit of JADCE. Specifically, we develop a novel turbo message passing (TMP) framework that models the entire channel matrix as a super node, rather than factorizing it element-wise. This design enables the seamless integration of score-based generative models as a minimum mean-squared error (MMSE) denoiser. The variance of the denoiser, which is essential in message passing, can also be learned through score-based generative models. Our approach, termed score-based TMP for JADCE (STMP-JADCE), takes full advantages of the powerful generative prior and, meanwhile, benefits from the fast convergence speed of message passing. Numerical simulations show that STMP-JADCE drastically enhances the activity detection and channel estimation performance compared to the state-of-the-art baseline algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00581v2</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chang Cai, Wenjun Jiang, Xiaojun Yuan, Ying-Jun Angela Zhang</dc:creator>
    </item>
    <item>
      <title>Inference-Driven Uplink for 6G: Architecture, Principles, and Challenges</title>
      <link>https://arxiv.org/abs/2508.09348</link>
      <description>arXiv:2508.09348v2 Announce Type: replace 
Abstract: Next-generation wireless networks (6G) face a critical uplink challenge arising from stringent device-side resource constraints and the growing demand for intelligence services. This article introduces InferCom, an inference-driven communication architecture designed to enable robust 6G uplink transmission under low signal-to-noise (SNR) conditions. InferCom adopts a compute-asymmetric architecture, featuring a lightweight transmitter and an inference-capable receiver empowered by generative artificial intelligence (GenAI) models, together with a quality-of-experience (QoE)-aware retransmission mechanism. Grounded in the information bottleneck (IB) theory, InferCom redefines uplink communications through task-agnostic compression, inference-driven reconstruction, error-distribution channel coding, and QoE-aware feedback. The case study demonstrates that InferCom outperforms conventional 5G NR and Deep- JSCC in terms of transmitter-side computational complexity, required SNRs and retransmission efficiency. Finally, we outline key challenges and research directions toward making InferCom a practical enabler of human-centric, intelligent and sustainable wireless networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.09348v2</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chunmei Xu, Zhi Ding, Yi Ma, Rahim Tafazolli, Peiying Zhu</dc:creator>
    </item>
    <item>
      <title>Neural Gaussian Radio Fields for Channel Estimation</title>
      <link>https://arxiv.org/abs/2508.11668</link>
      <description>arXiv:2508.11668v3 Announce Type: replace 
Abstract: Accurate channel state information (CSI) is a critical bottleneck in modern wireless networks, with pilot overhead consuming 11\% to 21\% of transmission bandwidth and feedback delays causing severe throughput degradation under mobility. Addressing this requires rethinking how neural fields represent coherent wave phenomena. This work introduces \textit{neural Gaussian radio fields (\textcolor{stanfordred}{nGRF})}, a physics-informed framework that fundamentally reframes neural field design by replacing view-dependent rasterization with direct complex-valued aggregation in 3D space. This approach natively models wave superposition rather than visual occlusion. The architectural shift transforms the learning objective from function-fitting to source-recovery, a well-posed inverse problem grounded in electromagnetic theory. While demonstrated for wireless channel estimation, the core principle of explicit primitive-based fields with physics-constrained aggregation extends naturally to any coherent wave-based domain, including acoustic propagation, seismic imaging, and ultrasound reconstruction. Evaluations show that the inductive bias of \textcolor{stanfordred}{nGRF} achieves 10.9 dB higher prediction SNR than state-of-the-art methods with 220$\times$ faster inference (1.1 ms vs. 242 ms), 18$\times$ lower measurement density, and 180$\times$ faster training. For large-scale outdoor environments where implicit methods fail, \textcolor{stanfordred}{nGRF} achieves 28.32 dB SNR, demonstrating that structured representations supplemented by domain physics can fundamentally outperform generic deep learning architectures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.11668v3</guid>
      <category>eess.SP</category>
      <category>cs.NI</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Muhammad Umer, Muhammad Ahmed Mohsin, Ahsan Bilal, John M. Cioffi</dc:creator>
    </item>
    <item>
      <title>Memory-Augmented Generative AI for Real-time Wireless Prediction in Dynamic Industrial Environments</title>
      <link>https://arxiv.org/abs/2510.06884</link>
      <description>arXiv:2510.06884v3 Announce Type: replace 
Abstract: Accurate and real-time prediction of wireless channel conditions, particularly the Signal-to-Interference-plus-Noise Ratio (SINR), is a foundational requirement for enabling Ultra-Reliable Low-Latency Communication (URLLC) in highly dynamic Industry 4.0 environments. Traditional physics-based or statistical models fail to cope with the spatio-temporal complexities introduced by mobile obstacles and transient interference inherent to smart warehouses. To address this, we introduce Evo-WISVA (Evolutionary Wireless Infrastructure for Smart Warehouse using VAE), a novel synergistic deep learning architecture that functions as a lightweight 2D predictive digital twin of the radio environment. Evo-WISVA integrates a memory-augmented Variational Autoencoder (VAE) featuring an Attention-driven Latent Memory Module (LMM) for robust, context-aware spatial feature extraction, with a Convolutional Long Short-Term Memory (ConvLSTM) network for precise temporal forecasting and sequential refinement. The entire pipeline is optimized end-to-end via a joint loss function, ensuring optimal feature alignment between the generative and predictive components. Rigorous experimental evaluation conducted on a high-fidelity ns-3-generated industrial warehouse dataset demonstrates that Evo-WISVA significantly surpasses state-of-the-art baselines, achieving up to a 47.6\% reduction in average reconstruction error. Crucially, the model exhibits exceptional generalization capacity to unseen environments with vastly increased dynamic complexity (up to ten simultaneously moving obstacles) while maintaining amortized computational efficiency essential for real-time deployment. Evo-WISVA establishes a foundational technology for proactive wireless resource management, enabling autonomous optimization and advancing the realization of predictive digital twins in industrial communication networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.06884v3</guid>
      <category>eess.SP</category>
      <category>cs.NI</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rahul Gulia, Amlan Ganguly, Michael E. Kuhl, Ehsan Rashedi, Clark Hochgraf</dc:creator>
    </item>
    <item>
      <title>MARBLE-Net: Learning to Localize in Multipath Environment with Adaptive Rainbow Beams</title>
      <link>https://arxiv.org/abs/2511.06971</link>
      <description>arXiv:2511.06971v3 Announce Type: replace 
Abstract: Integrated sensing and communication (ISAC) systems demand precise and efficient target localization, a task challenged by rich multipath propagation in complex wireless environments. This paper introduces MARBLE-Net (Multipath-Aware Rainbow Beam Learning Network), a deep learning framework that jointly optimizes the analog beamforming parameters of a frequency-dependent rainbow beam and a neural localization network for high-accuracy position estimation. By treating the phase-shifter (PS) and true-time-delay (TTD) parameters as learnable weights, the system adaptively refines its sensing beam to exploit environment-specific multipath characteristics. A structured multi-stage training strategy is proposed to ensure stable convergence and effective end-to-end optimization. Simulation results show that MARBLE-Net outperforms both a fixed-beam deep learning baseline (RaiNet) and a traditional k-nearest neighbors (k-NN) method, reducing localization error by more than 50\% in a multipath-rich scene. Moreover, the results reveal a nuanced interaction with multipath propagation: while confined uni-directional multipath degrades accuracy, structured and directional multipath can be effectively exploited to achieve performance surpassing even line-of-sight (LoS) conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06971v3</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qiushi Liang, Yeyue Cai, Jianhua Mo, Meixia Tao</dc:creator>
    </item>
    <item>
      <title>A Design Framework that Unifies 6G Modulation Schemes for Double Selectivity</title>
      <link>https://arxiv.org/abs/2511.09418</link>
      <description>arXiv:2511.09418v2 Announce Type: replace 
Abstract: There is significant recent interest in designing new modulation schemes for doubly-selective channels with large delay and Doppler spreads, where legacy modulation schemes based on time-frequency signal representations underperform. Multiple modulation schemes, e.g., in the delay-Doppler, chirp, time-sequency, and other domains, have been proposed in the literature for this purpose, with varying implementation details. In this letter, we establish that all previously proposed modulation schemes for doubly-selective signaling are instances of a single family of complex Hadamard-modulated pulse trains. When the delay and Doppler spread of the doubly-selective channel is limited to a certain support, all modulation schemes in this waveform family offer equivalent, full diversity achieving performance with no symbol fading and low channel estimation overhead. The existence of this waveform family also enables flexible, multi-waveform co-existence -- allowing a common transceiver architecture to generate multiple waveforms in the family, that may each be flexibly allocated to different users and services.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.09418v2</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nishant Mehrotra, Sandesh Rao Mattu, Robert Calderbank</dc:creator>
    </item>
    <item>
      <title>Division-based Receiver-agnostic RFF Identification in WiFi Systems</title>
      <link>https://arxiv.org/abs/2511.15458</link>
      <description>arXiv:2511.15458v3 Announce Type: replace 
Abstract: In physical-layer security schemes, radio frequency fingerprint (RFF) identification of WiFi devices is susceptible to receiver differences, which can significantly degrade classification performance when a model is trained on one receiver but tested on another. In this paper, we propose a division-based receiver-agnostic RFF extraction method for WiFi systems, which removes the receivers' effects by dividing different preambles in the frequency domain. The proposed method requires only a single receiver for training and does not rely on additional calibration or stacking processes. First, for flat fading channel scenarios, the legacy short training field (L-STF) and legacy long training field (L-LTF) of the unknown device are divided by those of the reference device in the frequency domain. The receiver-dependent effects can be eliminated with the requirement of only a single receiver for training, and the higher-dimensional RFF features can be extracted. Second, for frequency-selective fading channel scenarios, the high-throughput long training field (HT-LTF) is divided by the L-LTF in the frequency domain. Only a single receiver is required for training and the higher-dimensional RFF features that are both channel-invariant and receiver-agnostic are extracted. Finally, simulation and experimental results demonstrate that the proposed method effectively mitigate the impacts of channel variations and receiver differences. The classification results show that, even when training on a single receiver and testing on a different one, the proposed method achieves classification accuracy improvements of 15.5% and 28.45% over the state-of-the-art approach in flat fading and frequency-selective fading channel scenarios, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15458v3</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xuan Yang, Dongming Li, Dong Wei, Meng Zhang</dc:creator>
    </item>
    <item>
      <title>Rapid and Accurate Changepoint Detection of Power System Forced Oscillations</title>
      <link>https://arxiv.org/abs/2511.15812</link>
      <description>arXiv:2511.15812v2 Announce Type: replace 
Abstract: This paper describes a new approach for using changepoint detection (CPD) to estimate the starting and stopping times of a forced oscillation (FO) in measured power system data. As with a previous application of CPD to this problem, the pruned exact linear time (PELT) algorithm is used. However, instead of allowing PELT to automatically tune its penalty parameter, a method of manually providing it is presented that dramatically reduces computation time without sacrificing accuracy. Additionally, the new algorithm requires fewer input parameters and provides a formal, data-driven approach to setting the minimum FO segment length to consider as troublesome for an electromechanical mode meter. A low-order ARMAX representation of the minniWECC model is used to test the approach, where a 98\% reduction in computation time is enjoyed with high estimation accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15812v2</guid>
      <category>eess.SP</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luke Dosiek, Akaash Karn, Frank Liu</dc:creator>
    </item>
    <item>
      <title>Graph Signal Denoising Using Regularization by Denoising and Its Parameter Estimation</title>
      <link>https://arxiv.org/abs/2512.14213</link>
      <description>arXiv:2512.14213v2 Announce Type: replace 
Abstract: In this paper, we propose an interpretable denoising method for graph signals using regularization by denoising (RED). RED is a technique developed for image restoration that uses an efficient (and sometimes black-box) denoiser in the regularization term of the optimization problem. By using RED, optimization problems can be designed with the explicit use of the denoiser, and the gradient of the regularization term can be easily computed under mild conditions. We adapt RED for denoising of graph signals beyond image processing. We show that many graph signal denoisers, including graph neural networks, theoretically or practically satisfy the conditions for RED. We also study the effectiveness of RED from a graph filter perspective. Furthermore, we propose supervised and unsupervised parameter estimation methods based on deep algorithm unrolling. These methods aim to enhance the algorithm applicability, particularly in the unsupervised setting. Denoising experiments for synthetic and real-world datasets show that our proposed method improves signal denoising accuracy in mean squared error compared to existing graph signal denoising methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.14213v2</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hayate Kojima, Hiroshi Higashi, Yuichi Tanaka</dc:creator>
    </item>
    <item>
      <title>Cell-Free Massive MIMO with Hardware-Impaired Wireless Fronthaul</title>
      <link>https://arxiv.org/abs/2601.06486</link>
      <description>arXiv:2601.06486v2 Announce Type: replace 
Abstract: Cell-free massive MIMO (multiple-input multiple-output) enhances spectral and energy efficiency compared to conventional cellular networks by enabling joint transmission and reception across a large number of distributed access points (APs). Since these APs are envisioned to be low-cost and densely deployed, hardware impairments, stemming from non-ideal radio-frequency (RF) chains, are unavoidable. While existing studies primarily address hardware impairments on the access side, the impact of hardware impairments on the wireless fronthaul link has remained largely unexplored. In this work, we fill this important gap by introducing a novel amplify-and-forward (AF) based wireless fronthauling scheme tailored for cell-free massive MIMO. Focusing on the uplink, we develop an analytical framework that jointly models the hardware impairments at both the APs and the fronthaul transceivers, derives the resulting end-to-end distorted signal expression, and quantifies the individual contribution of each impairment to the spectral efficiency. Furthermore, we design distortion-aware linear combiners that optimally mitigate these effects. Numerical results demonstrate significant performance gains from distortion-aware processing and illustrate the potential of the proposed AF fronthauling scheme as a cost-effective enabler for future cell-free architectures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06486v2</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>\"Ozlem Tu\u{g}fe Demir, Emil Bj\"ornson</dc:creator>
    </item>
    <item>
      <title>Silhouette Score Efficient Radio Frequency Fingerprint Feature Extraction</title>
      <link>https://arxiv.org/abs/2602.02065</link>
      <description>arXiv:2602.02065v2 Announce Type: replace 
Abstract: Radio frequency fingerprint (RFF) identification technology, which exploits relatively stable hardware imperfections, is highly susceptible to constantly changing channel effects. Although various channel-robust RFF feature extraction methods have been proposed, they predominantly rely on experimental comparisons rather than theoretical analyses. This limitation hinders the progress of channel-robust RFF feature extraction and impedes the establishment of theoretical guidance for its design. In this paper, we establish a unified theoretical performance analysis framework for different RFF feature extraction methods using the silhouette score as an evaluation metric, and propose a precoding-based channel-robust RFF feature extraction method that enhances the silhouette score without requiring channel estimation. First, we employ the silhouette score as an evaluation metric and obtain the theoretical performance of various RFF feature extraction methods using the Taylor series expansion. Next, we mitigate channel effects by computing the reciprocal of the received signal in the frequency domain at the device under authentication. We then compare these methods across three different scenarios: the deterministic channel scenario, the independent and identically distributed (i.i.d.) stochastic channel scenario, and the non-i.i.d. stochastic channel scenario. Finally, simulation and experimental results demonstrate that the silhouette score is an efficient metric to evaluate classification accuracy. Furthermore, the results indicate that the proposed precoding-based channel-robust RFF feature extraction method achieves the highest silhouette score and classification accuracy under channel variations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.02065v2</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xuan Yang, Dongming Li, Yi Lou, Xianglin Fan</dc:creator>
    </item>
    <item>
      <title>Spatial Angular Pseudo-Derivative Searching: A Single Snapshot Super-resolution Sparse DOA Scheme with Potential for Practical Application</title>
      <link>https://arxiv.org/abs/2602.04169</link>
      <description>arXiv:2602.04169v2 Announce Type: replace 
Abstract: Accurate, high-resolution, and real-time DOA estimation is a cornerstone of environmental perception in automotive radar systems. While sparse signal recovery techniques offer super-resolution and high-precision estimation, their prohibitive computational complexity remains a primary bottleneck for practical deployment. This paper proposes a sparse DOA estimation scheme specifically tailored for the stringent requirements of automotive radar such as limited computational resources, restricted array apertures, and a single snapshot. By introducing the concept of the spatial angular pseudo-derivative and incorporating this property as a constraint into a standard L0-norm minimization problem, we formulate an objective function that more faithfully characterizes the physical properties of the DOA problem. The associated solver, designated as the SAPD search algorithm, naturally transforms the high-dimensional optimization task into an efficient grid-search scheme. The SAPD algorithm circumvents high-order matrix inversions and computationally intensive iterations. We provide an analysis of the computational complexity and convergence properties of the proposed algorithm. Extensive numerical simulations demonstrate that the SAPD method achieves a superior balance of real-time efficiency, high precision, and super-resolution, making it highly suitable for next-generation automotive radar applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.04169v2</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Longxin Bai, Jingchao Zhang, Liyan Qiao</dc:creator>
    </item>
    <item>
      <title>Infinity Search: Approximate Vector Search with Projections on q-Metric Spaces</title>
      <link>https://arxiv.org/abs/2506.06557</link>
      <description>arXiv:2506.06557v2 Announce Type: replace-cross 
Abstract: An ultrametric space or infinity-metric space is defined by a dissimilarity function that satisfies a strong triangle inequality in which every side of a triangle is not larger than the larger of the other two. We show that search in ultrametric spaces with a vantage point tree has worst-case complexity equal to the depth of the tree. Since datasets of interest are not ultrametric in general, we employ a projection operator that transforms an arbitrary dissimilarity function into an ultrametric space while preserving nearest neighbors. We further learn an approximation of this projection operator to efficiently compute ultrametric distances between query points and points in the dataset. We proceed to solve a more general problem in which we consider projections in $q$-metric spaces -- in which triangle sides raised to the power of $q$ are smaller than the sum of the $q$-powers of the other two. Notice that the use of learned approximations of projected $q$-metric distances renders the search pipeline approximate. We show in experiments that increasing values of $q$ result in faster search but lower recall. Overall, search in q-metric and infinity metric spaces is competitive with existing search methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.06557v2</guid>
      <category>cs.IR</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.MG</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Antonio Pariente, Ignacio Hounie, Santiago Segarra, Alejandro Ribeiro</dc:creator>
    </item>
    <item>
      <title>Transformer-based Learning-to-Optimize Approach for Scalable and Generalizable Beamforming</title>
      <link>https://arxiv.org/abs/2510.13077</link>
      <description>arXiv:2510.13077v2 Announce Type: replace-cross 
Abstract: We develop an unsupervised deep learning framework for downlink beamforming in large-scale MU-MISO channels. The model is trained offline, allowing real-time inference through lightweight feedforward computations in dynamic communication environments. Following the learning-to-optimize (L2O) paradigm, a multi-layer Transformer iteratively refines both channel and beamformer features via residual connections. To enhance training, three strategies are introduced: (i) curriculum learning (CL) to improve early-stage convergence and avoid local optima, (ii) semi-amortized learning to refine each Transformer block with a few gradient ascent steps, and (iii) sliding-window training to stabilize optimization by training only a subset of Transformer blocks at a time. Extensive simulations show that the proposed scheme outperforms existing baselines at low-to-medium SNRs and closely approaches WMMSE performance at high SNRs, while achieving substantially faster inference than iterative and online learning approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.13077v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>eess.SP</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yubo Zhang, Xiao-Yang Liu, Xiaodong Wang</dc:creator>
    </item>
  </channel>
</rss>
