<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.NA</link>
    <description>math.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 31 Jul 2024 04:00:21 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 31 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Homomorphic data compression for real time photon correlation analysis</title>
      <link>https://arxiv.org/abs/2407.20356</link>
      <description>arXiv:2407.20356v1 Announce Type: new 
Abstract: The construction of highly coherent x-ray sources has enabled new research opportunities across the scientific landscape. The maximum raw data rate per beamline now exceeds 40 GB/s, posing unprecedented challenges for the online processing and offline storage of the big data. Such challenge is particularly prominent for x-ray photon correlation spectroscopy (XPCS), where real time analyses require simultaneous calculation on all the previously acquired data in the time series. We present a homomorphic compression scheme to effectively reduce the computational time and memory space required for XPCS analysis. Leveraging similarities in the mathematical expression between a matrix-based compression algorithm and the correlation calculation, our approach allows direct operation on the compressed data without their decompression. The lossy compression reduces the computational time by a factor of 10,000, enabling real time calculation of the correlation functions at kHz framerate. Our demonstration of a homomorphic compression of scientific data provides an effective solution to the big data challenge at coherent light sources. Beyond the example shown in this work, the framework can be extended to facilitate real-time operations directly on a compressed data stream for other techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.20356v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.data-an</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sebastian Strempfer, Zichao Wendy Di, Kazutomo Yoshii, Yue Cao, Qingteng Zhang, Eric M. Dufresne, Mathew Cherukara, Suresh Narayanan, Martin V. Holt, Antonino Miceli, Tao Zhou</dc:creator>
    </item>
    <item>
      <title>Optimizing Variational Physics-Informed Neural Networks Using Least Squares</title>
      <link>https://arxiv.org/abs/2407.20417</link>
      <description>arXiv:2407.20417v1 Announce Type: new 
Abstract: Variational Physics-Informed Neural Networks often suffer from poor convergence when using stochastic gradient-descent-based optimizers. By introducing a Least Squares solver for the weights of the last layer of the neural network, we improve the convergence of the loss during training in most practical scenarios. This work analyzes the computational cost of the resulting hybrid Least-Squares/Gradient-Descent optimizer and explains how to implement it efficiently. In particular, we show that a traditional implementation based on backward-mode automatic differentiation leads to a prohibitively expensive algorithm. To remedy this, we propose using either forward-mode automatic differentiation or an ultraweak-type scheme that avoids the differentiation of trial functions in the discrete weak formulation. The proposed alternatives are up to 100 times faster than the traditional one, recovering a computational cost-per-iteration similar to that of a conventional gradient-descent-based optimizer alone. To support our analysis, we derive computational estimates and conduct numerical experiments in one- and two-dimensional problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.20417v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Carlos Uriarte, Manuela Bastidas, David Pardo, Jamie M. Taylor, Sergio Rojas</dc:creator>
    </item>
    <item>
      <title>A convergent augmented SAV scheme for stochastic Cahn--Hilliard equations with dynamic boundary conditions describing contact line tension</title>
      <link>https://arxiv.org/abs/2407.20424</link>
      <description>arXiv:2407.20424v1 Announce Type: new 
Abstract: We augment a thermodynamically consistent diffuse interface model for the description of line tension phenomena by multiplicative stochastic noise to capture the effects of thermal fluctuations and establish the existence of pathwise unique (stochastically) strong solutions. By starting from a fully discrete linear finite element scheme, we do not only prove the well-posedness of the model, but also provide a practicable and convergent scheme for its numerical treatment. Conceptually, our discrete scheme relies on a recently developed augmentation of the scalar auxiliary variable approach, which reduces the requirements on the time regularity of the solution. By showing that fully discrete solutions to this scheme satisfy an energy estimate, we obtain first uniform regularity results. Establishing Nikolskii estimates with respect to time, we are able to show convergence towards pathwise unique martingale solutions by applying Jakubowski's generalization of Skorokhod's theorem. Finally, a generalization of the Gy\"ongy--Krylov characterization of convergence in probability provides convergence towards strong solutions and thereby completes the proof.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.20424v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stefan Metzger</dc:creator>
    </item>
    <item>
      <title>Adaptive planning for risk-aware predictive digital twins</title>
      <link>https://arxiv.org/abs/2407.20490</link>
      <description>arXiv:2407.20490v1 Announce Type: new 
Abstract: This work proposes a mathematical framework to increase the robustness to rare events of digital twins modelled with graphical models. We incorporate probabilistic model-checking and linear programming into a dynamic Bayesian network to enable the construction of risk-averse digital twins. By modeling with a random variable the probability of the asset to transition from one state to another, we define a parametric Markov decision process. By solving this Markov decision process, we compute a policy that defines state-dependent optimal actions to take. To account for rare events connected to failures we leverage risk measures associated with the distribution of the random variables describing the transition probabilities. We refine the optimal policy at every time step resulting in a better trade off between operational costs and performances. We showcase the capabilities of the proposed framework with a structural digital twin of an unmanned aerial vehicle and its adaptive mission replanning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.20490v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Marco Tezzele, Steven Carr, Ufuk Topcu, Karen E. Willcox</dc:creator>
    </item>
    <item>
      <title>Patterns in soil organic carbon dynamics: integrating microbial activity, chemotaxis and data-driven approaches</title>
      <link>https://arxiv.org/abs/2407.20625</link>
      <description>arXiv:2407.20625v1 Announce Type: new 
Abstract: Models of soil organic carbon (SOC) frequently overlook the effects of spatial dimensions and microbiological activities. In this paper, we focus on two reaction-diffusion chemotaxis models for SOC dynamics, both supporting chemotaxis-driven instability and exhibiting a variety of spatial patterns as stripes, spots and hexagons when the microbial chemotactic sensitivity is above a critical threshold. We use symplectic techniques to numerically approximate chemotaxis-driven spatial patterns and explore the effectiveness of the piecewice dynamic mode decomposition (pDMD) to reconstruct them. Our findings show that pDMD is effective at precisely recreating chemotaxis-driven spatial patterns, therefore broadening the range of application of the method to classes of solutions different than Turing patterns. By validating its efficacy across a wider range of models, this research lays the groundwork for applying pDMD to experimental spatiotemporal data, advancing predictions crucial for soil microbial ecology and agricultural sustainability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.20625v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>q-bio.QM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Angela Monti, Fasma Diele, Deborah Lacitignola, Carmela Marangi</dc:creator>
    </item>
    <item>
      <title>Robust Augmented Mixed Finite Element Methods for Stoke Interface Problems with Discontinuous Viscosity in Multiple Subdomains</title>
      <link>https://arxiv.org/abs/2407.20655</link>
      <description>arXiv:2407.20655v1 Announce Type: new 
Abstract: A stationary Stokes problem with a piecewise constant viscosity coefficient in multiple subdomains is considered in the paper. For standard finite element pairs, a robust inf-sup condition is required to show the robustness of the discretization error with respect to the discontinuous viscosity, which has only been proven for the two-subdomain case in the paper [Numer. Math. (2006) 103: 129--149]. To avoid the robust inf-sup condition of a discrete finite element pair for multiple subdomains, we propose an ultra-weak augmented mixed finite element formulation. By adopting a Galerkin-least-squares method, the augmented mixed formulation can achieve stability without relying on the inf-sup condition in both continuous and discrete settings. The key step to having a robust priori error estimate is to use two norms, one energy norm and one full norm, in robust continuity. The robust coercivity is proved for the energy norm. A robust a priori error estimate in the energy norm is then derived with the best approximation property in the full norm for the case of multiple subdomains. Additionally, the paper introduces a singular Kellogg-type example with exact solutions for the first time. Extensive numerical tests are conducted to validate the robust error estimate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.20655v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuxiang Liang, Shun Zhang</dc:creator>
    </item>
    <item>
      <title>Error estimates for full discretization of Cahn--Hilliard equation with dynamic boundary conditions</title>
      <link>https://arxiv.org/abs/2407.20698</link>
      <description>arXiv:2407.20698v1 Announce Type: new 
Abstract: A proof of optimal-order error estimates is given for the full discretization of the Cahn--Hilliard equation with Cahn--Hilliard-type dynamic boundary conditions in a smooth domain. The numerical method combines a linear bulk--surface finite element discretization in space and linearly implicit backward difference formulae of order 1 to 5 in time. Optimal-order error estimates are proven. The error estimates are based on a consistency and stability analysis in an abstract framework, based on energy estimates exploiting the anti-symmetric structure of the second-order system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.20698v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Nils Bullerjahn, Bal\'azs Kov\'acs</dc:creator>
    </item>
    <item>
      <title>A priori error estimates for optimal control problems governed by the transient Stokes equations and subject to state constraints pointwise in time</title>
      <link>https://arxiv.org/abs/2407.20702</link>
      <description>arXiv:2407.20702v1 Announce Type: new 
Abstract: In this paper, we consider a state constrained optimal control problem governed by the transient Stokes equations. The state constraint is given by an L2 functional in space, which is required to fulfill a pointwise bound in time. The discretization scheme for the Stokes equations consists of inf-sup stable finite elements in space and a discontinuous Galerkin method in time, for which we have recently established best approximation type error estimates. Using these error estimates, for the discrete control problem we establish error estimates and as a by-product we show an improved regularity for the optimal control. We complement our theoretical analysis with numerical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.20702v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dmitriy Leykekhman, Boris Vexler, Jakob Wagner</dc:creator>
    </item>
    <item>
      <title>High-order limiting methods using maximum principle bounds derived from the Boltzmann equation I: Euler equations</title>
      <link>https://arxiv.org/abs/2407.20966</link>
      <description>arXiv:2407.20966v1 Announce Type: new 
Abstract: The use of limiting methods for high-order numerical approximations of hyperbolic conservation laws generally requires defining an admissible region/bounds for the solution. In this work, we present a novel approach for computing solution bounds and limiting for the Euler equations through the kinetic representation provided by the Boltzmann equation, which allows for extending limiters designed for linear advection directly to the Euler equations. Given an arbitrary set of solution values to compute bounds over (e.g., numerical stencil) and a desired linear advection limiter, the proposed approach yields an analytic expression for the admissible region of particle distribution function values, which may be numerically integrated to yield a set of bounds for the density, momentum, and total energy. These solution bounds are shown to preserve positivity of density/pressure/internal energy and, when paired with a limiting technique, can robustly resolve strong discontinuities while recovering high-order accuracy in smooth regions without any ad hoc corrections (e.g., relaxing the bounds). This approach is demonstrated in the context of an explicit unstructured high-order discontinuous Galerkin/flux reconstruction scheme for a variety of difficult problems in gas dynamics, including cases with extreme shocks and shock-vortex interactions. Furthermore, this work presents a foundation for limiting techniques for more complex macroscopic governing equations that can be derived from an underlying kinetic representation for which admissible solution bounds are not well-understood.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.20966v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Tarik Dzanic, Luigi Martinelli</dc:creator>
    </item>
    <item>
      <title>Optimal Algorithms for Quantifying Spectral Size with Applications to Quasicrystals</title>
      <link>https://arxiv.org/abs/2407.20353</link>
      <description>arXiv:2407.20353v1 Announce Type: cross 
Abstract: We introduce computational strategies for measuring the ``size'' of the spectrum of bounded self-adjoint operators using various metrics such as the Lebesgue measure, fractal dimensions, the number of connected components (or gaps), and other spectral characteristics. Our motivation comes from the study of almost-periodic operators, particularly those that arise as models of quasicrystals. Such operators are known for intricate hierarchical patterns and often display delicate spectral properties, such as Cantor spectra, which are significant in studying quantum mechanical systems and materials science. We propose a series of algorithms that compute these properties under different assumptions and explore their theoretical implications through the Solvability Complexity Index (SCI) hierarchy. This approach provides a rigorous framework for understanding the computational feasibility of these problems, proving algorithmic optimality, and enhancing the precision of spectral analysis in practical settings. For example, we show that our methods are optimal by proving certain lower bounds (impossibility results) for the class of limit-periodic Schr\"odinger operators. We demonstrate our methods through state-of-the-art computations for aperiodic systems in one and two dimensions, effectively capturing these complex spectral characteristics. The results contribute significantly to connecting theoretical and computational aspects of spectral theory, offering insights that bridge the gap between abstract mathematical concepts and their practical applications in physical sciences and engineering. Based on our work, we conclude with conjectures and open problems regarding the spectral properties of specific models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.20353v1</guid>
      <category>math.SP</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matthew J. Colbrook, Mark Embree, Jake Fillman</dc:creator>
    </item>
    <item>
      <title>Generalized Ellipsoids</title>
      <link>https://arxiv.org/abs/2407.20362</link>
      <description>arXiv:2407.20362v1 Announce Type: cross 
Abstract: We introduce a family of symmetric convex bodies called generalized ellipsoids of degree $d$ (GE-$d$s), with ellipsoids corresponding to the case of $d=0$. Generalized ellipsoids (GEs) retain many geometric, algebraic, and algorithmic properties of ellipsoids. We show that the conditions that the parameters of a GE must satisfy can be checked in strongly polynomial time, and that one can search for GEs of a given degree by solving a semidefinite program whose size grows only linearly with dimension. We give an example of a GE which does not have a second-order cone representation, but show that every GE has a semidefinite representation whose size depends linearly on both its dimension and degree. In terms of expressiveness, we prove that for any integer $m\geq 2$, every symmetric full-dimensional polytope with $2m$ facets and every intersection of $m$ co-centered ellipsoids can be represented exactly as a GE-$d$ with $d \leq 2m-3$. Using this result, we show that every symmetric convex body can be approximated arbitrarily well by a GE-$d$ and we quantify the quality of the approximation as a function of the degree $d$. Finally, we present applications of GEs to several areas, such as time-varying portfolio optimization, stability analysis of switched linear systems, robust-to-dynamics optimization, and robust polynomial regression.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.20362v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.AG</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amir Ali Ahmadi, Abraar Chaudhry, Cemil Dibek</dc:creator>
    </item>
    <item>
      <title>Uncertainty Quantification under Noisy Constraints, with Applications to Raking</title>
      <link>https://arxiv.org/abs/2407.20520</link>
      <description>arXiv:2407.20520v1 Announce Type: cross 
Abstract: We consider statistical inference problems under uncertain equality constraints, and provide asymptotically valid uncertainty estimates for inferred parameters. The proposed approach leverages the implicit function theorem and primal-dual optimality conditions for a particular problem class. The motivating application is multi-dimensional raking, where observations are adjusted to match marginals; for example, adjusting estimated deaths across race, county, and cause in order to match state all-race all-cause totals. We review raking from a convex optimization perspective, providing explicit primal-dual formulations, algorithms, and optimality conditions for a wide array of raking applications, which are then leveraged to obtain the uncertainty estimates. Empirical results show that the approach obtains, at the cost of a single solve, nearly the same uncertainty estimates as computationally intensive Monte Carlo techniques that pass thousands of observed and of marginal draws through the entire raking process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.20520v1</guid>
      <category>stat.ME</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ariane Ducellier (Institute for Health Metrics and Evaluation, Seattle, WA), Alexander Hsu (Institute for Health Metrics and Evaluation, Seattle, WA, Department of Applied Mathematics, University of Washington, Seattle, WA), Parkes Kendrick (Institute for Health Metrics and Evaluation, Seattle, WA), Bill Gustafson (Institute for Health Metrics and Evaluation, Seattle, WA), Laura Dwyer-Lindgren (Institute for Health Metrics and Evaluation, Seattle, WA), Christopher Murray (Institute for Health Metrics and Evaluation, Seattle, WA), Peng Zheng (Institute for Health Metrics and Evaluation, Seattle, WA), Aleksandr Aravkin (Institute for Health Metrics and Evaluation, Seattle, WA, Department of Applied Mathematics, University of Washington, Seattle, WA)</dc:creator>
    </item>
    <item>
      <title>Improving PINNs By Algebraic Inclusion of Boundary and Initial Conditions</title>
      <link>https://arxiv.org/abs/2407.20741</link>
      <description>arXiv:2407.20741v1 Announce Type: cross 
Abstract: "AI for Science" aims to solve fundamental scientific problems using AI techniques. As most physical phenomena can be described as Partial Differential Equations (PDEs) , approximating their solutions using neural networks has evolved as a central component of scientific-ML. Physics-Informed Neural Networks (PINNs) is the general method that has evolved for this task but its training is well-known to be very unstable. In this work we explore the possibility of changing the model being trained from being just a neural network to being a non-linear transformation of it - one that algebraically includes the boundary/initial conditions. This reduces the number of terms in the loss function than the standard PINN losses. We demonstrate that our modification leads to significant performance gains across a range of benchmark tasks, in various dimensions and without having to tweak the training algorithm. Our conclusions are based on conducting hundreds of experiments, in the fully unsupervised setting, over multiple linear and non-linear PDEs set to exactly solvable scenarios, which lends to a concrete measurement of our performance gains in terms of order(s) of magnitude lower fractional errors being achieved, than by standard PINNs. The code accompanying this manuscript is publicly available at, https://github.com/MorganREN/Improving-PINNs-By-Algebraic-Inclusion-of-Boundary-and-Initial-Conditions</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.20741v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.DS</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohan Ren, Zhihao Fang, Keren Li, Anirbit Mukherjee</dc:creator>
    </item>
    <item>
      <title>A Stochastic Precipitating Quasi-Geostrophic Model</title>
      <link>https://arxiv.org/abs/2407.20886</link>
      <description>arXiv:2407.20886v1 Announce Type: cross 
Abstract: Efficient and effective modeling of complex systems, incorporating cloud physics and precipitation, is essential for accurate climate modeling and forecasting. However, simulating these systems is computationally demanding since microphysics has crucial contributions to the dynamics of moisture and precipitation. In this paper, appropriate stochastic models are developed for the phase-transition dynamics of water, focusing on the precipitating quasi-geostrophic (PQG) model as a prototype. By treating the moisture, phase transitions, and latent heat release as integral components of the system, the PQG model constitutes a set of partial differential equations (PDEs) that involve Heaviside nonlinearities due to phase changes of water. Despite systematically characterizing the precipitation physics, expensive iterative algorithms are needed to find a PDE inversion at each numerical integration time step. As a crucial step toward building an effective stochastic model, a computationally efficient Markov jump process is designed to randomly simulate transitions between saturated and unsaturated states that avoids using the expensive iterative solver. The transition rates, which are deterministic, are derived from the physical fields, guaranteeing physical and statistical consistency with nature. Furthermore, to maintain the consistent spatial pattern of precipitation, the stochastic model incorporates an adaptive parameterization that automatically adjusts the transitions based on spatial information. Numerical tests show the stochastic model retains critical properties of the original PQG system while significantly reducing computational demands. It accurately captures observed precipitation patterns, including the spatial distribution and temporal variability of rainfall, alongside reproducing essential dynamic features such as potential vorticity fields and zonal mean flows.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.20886v1</guid>
      <category>physics.flu-dyn</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.geo-ph</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nan Chen, Changhong Mou, Leslie M. Smith, Yeyu Zhang</dc:creator>
    </item>
    <item>
      <title>A stochastic perturbation approach to nonlinear bifurcating problems</title>
      <link>https://arxiv.org/abs/2402.16803</link>
      <description>arXiv:2402.16803v2 Announce Type: replace 
Abstract: Incorporating probabilistic terms in mathematical models is crucial for capturing and quantifying uncertainties of real-world systems. However, stochastic models typically require large computational resources to produce meaningful statistics. For such reason, the development of reduction techniques becomes essential for enabling efficient and scalable simulations of complex scenarios while quantifying the underlying uncertainties. In this work, we study the accuracy of Polynomial Chaos (PC) surrogate expansion of the probability space on a bifurcating phenomena in fluid dynamics, namely the Coand\u{a} effect. In particular, we propose a novel non-deterministic approach to generic bifurcation problems, where the stochastic setting gives a different perspective on the non-uniqueness of the solution, also avoiding expensive simulations for many instances of the parameter. Thus, starting from the formulation of the Spectral Stochastic Finite Element Method (SSFEM), we extend the methodology to deal with solutions of a bifurcating problem, by working with a perturbed version of the deterministic model. We discuss the link between the deterministic and the stochastic bifurcation diagram, highlighting the surprising capability of PC polynomials coefficients of giving insights on the deterministic solution manifold.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.16803v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.PR</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Isabella Carla Gonnella, Moaad Khamlich, Federico Pichi, Gianluigi Rozza</dc:creator>
    </item>
    <item>
      <title>Learning reduced-order Quadratic-Linear models in Process Engineering using Operator Inference</title>
      <link>https://arxiv.org/abs/2402.17698</link>
      <description>arXiv:2402.17698v2 Announce Type: replace 
Abstract: In this work, we address the challenge of efficiently modeling dynamical systems in process engineering. We use reduced-order model learning, specifically operator inference. This is a non-intrusive, data-driven method for learning dynamical systems from time-domain data. The application in our study is carbon dioxide methanation, an important reaction within the Power-to-X framework, to demonstrate its potential. The numerical results show the ability of the reduced-order models constructed with operator inference to provide a reduced yet accurate surrogate solution. This represents an important milestone towards the implementation of fast and reliable digital twin architectures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.17698v2</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ion Victor Gosea, Luisa Peterson, Pawan Goyal, Jens Bremer, Kai Sundmacher, Peter Benner</dc:creator>
    </item>
    <item>
      <title>Physics-informed Discretization-independent Deep Compositional Operator Network</title>
      <link>https://arxiv.org/abs/2404.13646</link>
      <description>arXiv:2404.13646v2 Announce Type: replace 
Abstract: Solving parametric Partial Differential Equations (PDEs) for a broad range of parameters is a critical challenge in scientific computing. To this end, neural operators, which \textcolor{black}{predicts the PDE solution with variable PDE parameter inputs}, have been successfully used. However, the training of neural operators typically demands large training datasets, the acquisition of which can be prohibitively expensive. To address this challenge, physics-informed training can offer a cost-effective strategy. However, current physics-informed neural operators face limitations, either in handling irregular domain shapes or in in generalizing to various discrete representations of PDE parameters. In this research, we introduce a novel physics-informed model architecture which can generalize to various discrete representations of PDE parameters and irregular domain shapes. Particularly, inspired by deep operator neural networks, our model involves a discretization-independent learning of parameter embedding repeatedly, and this parameter embedding is integrated with the response embeddings through multiple compositional layers, for more expressivity. Numerical results demonstrate the accuracy and efficiency of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13646v2</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Weiheng Zhong, Hadi Meidani</dc:creator>
    </item>
    <item>
      <title>Adaptive Parameter Selection in Nudging Based Data Assimilation</title>
      <link>https://arxiv.org/abs/2407.18886</link>
      <description>arXiv:2407.18886v2 Announce Type: replace 
Abstract: Data assimilation combines (imperfect) knowledge of a flow's physical laws with (noisy, time-lagged, and otherwise imperfect) observations to produce a more accurate prediction of flow statistics. Assimilation by nudging (from 1964), while non-optimal, is easy to implement and its analysis is clear and well-established. Nudging's uniform in time accuracy has even been established under conditions on the nudging parameter $\chi$ and the density of observational locations, $H$, Larios, Rebholz, and Zerfas [1]. One remaining issue is that nudging requires the user to select a key parameter. The conditions required for this parameter, derived through \'a priori (worst case) analysis are severe (Section 2.1 herein) and far beyond those found to be effective in computational experience. One resolution, developed herein, is self-adaptive parameter selection. This report develops, analyzes, tests, and compares two methods of self-adaptation of nudging parameters. One combines analysis and response to local flow behavior. The other is based only on response to flow behavior. The comparison finds both are easily implemented and yield effective values of the nudging parameter much smaller than those of \'a priori analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18886v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.flu-dyn</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Aytekin \c{C}{\i}b{\i}k, Rui Fang, William Layton, Farjana Siddiqua</dc:creator>
    </item>
    <item>
      <title>Permuted preconditioning for extended saddle point problem arising from Neumann boundary control</title>
      <link>https://arxiv.org/abs/2407.19217</link>
      <description>arXiv:2407.19217v2 Announce Type: replace 
Abstract: In this paper, a new block preconditioner is proposed for the saddle point problem arising from the Neumann boundary control problem. In order to deal with the singularity of the stiffness matrix, the saddle point problem is first extended to a new one by a regularization of the pure Neumann problem. Then after row permutations of the extended saddle point problem, a new block triangular preconditioner is constructed based on an approximation of the Schur complement. We analyze the eigenvalue properties of the preconditioned matrix and provide eigenvalue bounds. Numerical results illustrate the efficiency of the proposed preconditioning method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.19217v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chaojie Wang, Xuan Zhang, Xingding Chen</dc:creator>
    </item>
    <item>
      <title>Neural networks for bifurcation and linear stability analysis of steady states in partial differential equations</title>
      <link>https://arxiv.org/abs/2407.19707</link>
      <description>arXiv:2407.19707v2 Announce Type: replace 
Abstract: This research introduces an extended application of neural networks for solving nonlinear partial differential equations (PDEs). A neural network, combined with a pseudo-arclength continuation, is proposed to construct bifurcation diagrams from parameterized nonlinear PDEs. Additionally, a neural network approach is also presented for solving eigenvalue problems to analyze solution linear stability, focusing on identifying the largest eigenvalue. The effectiveness of the proposed neural network is examined through experiments on the Bratu equation and the Burgers equation. Results from a finite difference method are also presented as comparison. Varying numbers of grid points are employed in each case to assess the behavior and accuracy of both the neural network and the finite difference method. The experimental results demonstrate that the proposed neural network produces better solutions, generates more accurate bifurcation diagrams, has reasonable computational times, and proves effective for linear stability analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.19707v2</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Muhammad Luthfi Shahab, Hadi Susanto</dc:creator>
    </item>
    <item>
      <title>Spectral bounds for certain special type of rational matrices</title>
      <link>https://arxiv.org/abs/2302.02894</link>
      <description>arXiv:2302.02894v5 Announce Type: replace-cross 
Abstract: We derive bounds on the moduli of eigenvalues of certain special type of rational matrices, using the following techniques/methods: (1) an upper bound is obtained using the Bauer-Fike theorem on an associated block matrix of the given rational matrix, (2) a lower bound is obtained by associating a real rational function, along with Rouch$\text{\'e}$'s theorem for the rational matrix and (3) an upper bound is also obtained using a numerical radius inequality for a block matrix for the rational matrix. These bounds are compared when the coefficients are unitary matrices. Numerical examples are given to illustrate the results obtained.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.02894v5</guid>
      <category>math.SP</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pallavi Basavaraju, Shrinath Hadimani, Sachindranath Jayaraman</dc:creator>
    </item>
  </channel>
</rss>
