<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.IT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.IT</link>
    <description>cs.IT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.IT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 13 Feb 2026 05:00:20 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Generative AI-Driven Phase Control for RIS-Aided Cell-Free Massive MIMO Systems</title>
      <link>https://arxiv.org/abs/2602.11226</link>
      <description>arXiv:2602.11226v1 Announce Type: new 
Abstract: This work investigates a generative artificial intelligence (GenAI) model to optimize the reconfigurable intelligent surface (RIS) phase shifts in RIS-aided cell-free massive multiple-input multiple-output (mMIMO) systems under practical constraints, including imperfect channel state information (CSI) and spatial correlation. We propose two GenAI based approaches, generative conditional diffusion model (GCDM) and generative conditional diffusion implicit model (GCDIM), leveraging the diffusion model conditioned on dynamic CSI to maximize the sum spectral efficiency (SE) of the system. To benchmark performance, we compare the proposed GenAI based approaches against an expert algorithm, traditionally known for achieving near-optimal solutions at the cost of computational efficiency. The simulation results demonstrate that GCDM matches the sum SE achieved by the expert algorithm while significantly reducing the computational overhead. Furthermore, GCDIM achieves a comparable sum SE with an additional $98\%$ reduction in computation time, underscoring its potential for efficient phase optimization in RIS-aided cell-free mMIMO systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11226v1</guid>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kalpesh K. Patel, Malay Chakraborty, Ekant Sharma, Sandeep Kumar Singh</dc:creator>
    </item>
    <item>
      <title>Coupler Position Optimization and Channel Estimation for Flexible Coupler Aided Multiuser Communication</title>
      <link>https://arxiv.org/abs/2602.11319</link>
      <description>arXiv:2602.11319v1 Announce Type: new 
Abstract: In this paper, we propose a distributed flexible coupler (FC) array to enhance communication performance with low hardware cost. At each FC antenna, there is one fixed-position active antenna and multiple passive couplers that can move within a designated region around the active antenna. Moreover, each FC antenna is equipped with a local processing unit (LPU). All LPUs exchange signals with a central processing unit (CPU) for joint signal processing. We study an FC-aided multiuser multiple-input multiple-output (MIMO) system, where an FC array base station (BS) is deployed to enhance the downlink communication between the BS and multiple single-antenna users. We formulate optimization problems to maximize the achievable sum rate of users by jointly optimizing the coupler positions and digital beamforming, subject to movement constraints on the coupler positions and the transmit power constraint. To address the resulting nonconvex optimization problem, the digital beamforming is expressed as a function of the FC position vectors, which are then optimized using the proposed distributed coupler position optimization algorithm. Considering a structured time domain pattern of pilots and coupler positions, pilot-assisted centralized and distributed channel estimation algorithms are designed under the FC array architecture. Simulation results demonstrate that the distributed FC array achieves substantial rate gains over conventional benchmarks in multiuser systems without moving active antennas, and approaches the performance of fully active arrays while significantly reducing hardware cost and power consumption. Moreover, the proposed channel estimation algorithms outperform the benchmark schemes in terms of both pilot overhead and channel reconstruction accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11319v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaodan Shao, Chuangye Shan, Weihua Zhuang, Xuemin Shen</dc:creator>
    </item>
    <item>
      <title>Non-signaling Assisted Capacity of a Classical Channel with Causal CSIT</title>
      <link>https://arxiv.org/abs/2602.11568</link>
      <description>arXiv:2602.11568v1 Announce Type: new 
Abstract: The non-signaling (NS) assisted capacity of a classical channel with causal channel state information at the transmitter (CSIT) is shown to be $C^{NS,ca}=\max_{P_{X|S}}I(X;Y\mid S)$, where $X, Y, S$ correspond to the input, output and state of the channel. Remarkably, this is the same as the capacity of the channel in the NS-assisted non-causal CSIT setting, $C^{NS,nc}=\max_{P_{X|S}}I(X;Y\mid S)$, which was previously established, and also matches the (either classical or with NS assistance) capacity of the channel where the state is available not only (either causally or non-causally) to the transmitter but also to the receiver. While the capacity remains unchanged, the optimal probability of error for fixed message size and blocklength, in the NS-assisted causal CSIT setting can be further improved if channel state is made available to the receiver. This is in contrast to corresponding NS-assisted non-causal CSIT setting where it was previously noted that the optimal probability of error cannot be further improved by providing the state to the receiver.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11568v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuhang Yao, Syed A. Jafar</dc:creator>
    </item>
    <item>
      <title>The Arithmetic Singleton Bound on the Hamming Distances of Simple-rooted Constacyclic Codes over Finite Fields</title>
      <link>https://arxiv.org/abs/2602.11788</link>
      <description>arXiv:2602.11788v1 Announce Type: new 
Abstract: This paper establishes a novel upper bound-termed the arithmetic Singleton bound-on the Hamming distance of any simple-root constacyclic code over a finite field. The key technical ingredient is the notion of multiple equal-difference (MED) representations of the defining set of a simple-root polynomial, which generalizes the MED representation of a cyclotomic coset. We prove that every MED representation induces an upper bound on the minimum distance; the classical Singleton bound corresponds to the coarsest representation, while the strongest among these bounds is defined as the arithmetic Singleton bound. It is shown that the arithmetic Singleton bound is always at least as tight as the Singleton bound, and a precise criterion for it to be strictly tighter is obtained. For irreducible constacyclic codes, the bound is given explicitly by $\omega+1$, where $\omega$ is a constant closely related to the order of $q$ modulo the radical of the polynomial order. This work provides the first systematic translation of arithmetic structure-via MED representations-into restrictive constraints on the minimum distance, revealing that the Singleton bound may be unattainable not because of linear limitations, but due to underlying algebraic obstructions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11788v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Li Zhu, Hongfeng Wu</dc:creator>
    </item>
    <item>
      <title>A Comparative Study of MAP and LMMSE Estimators for Blind Inverse Problems</title>
      <link>https://arxiv.org/abs/2602.11814</link>
      <description>arXiv:2602.11814v1 Announce Type: new 
Abstract: Maximum-a-posteriori (MAP) approaches are an effective framework for inverse problems with known forward operators, particularly when combined with expressive priors and careful parameter selection. In blind settings, however, their use becomes significantly less stable due to the inherent non-convexity of the problem and the potential non-identifiability of the solutions. (Linear) minimum mean square error (MMSE) estimators provide a compelling alternative that can circumvent these limitations. In this work, we study synthetic two-dimensional blind deconvolution problems under fully controlled conditions, with complete prior knowledge of both the signal and kernel distributions. We compare tailored MAP algorithms with simple LMMSE estimators whose functional form is closely related to that of an optimal Tikhonov estimator. Our results show that, even in these highly controlled settings, MAP methods remain unstable and require extensive parameter tuning, whereas the LMMSE estimator yields a robust and reliable baseline. Moreover, we demonstrate empirically that the LMMSE solution can serve as an effective initialization for MAP approaches, improving their performance and reducing sensitivity to regularization parameters, thereby opening the door to future theoretical and practical developments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11814v1</guid>
      <category>cs.IT</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nathan Buskulic, Luca Calatroni</dc:creator>
    </item>
    <item>
      <title>On Fundamental Limits of Transmission Activity Detection in Fluid Antenna Systems</title>
      <link>https://arxiv.org/abs/2602.11901</link>
      <description>arXiv:2602.11901v1 Announce Type: new 
Abstract: In this letter, we develop a unified Cram\'{e}r-Rao bound (CRB) framework to characterize the fundamental performance limits of transmission activity detection in fluid antenna systems (FASs) and conventional multiple fixed-position antenna (FPA) systems. To facilitate CRB analysis applicable to activity indicators, we relax the binary activity states to continuous parameters, thereby aligning the bound-based evaluation with practical threshold-based detection decisions. Closed-form CRB expressions are derived for two representative detection formulations, namely covariance-oriented and coherent models. Moreover, for single-antenna FASs, we obtain a closed-form coherent CRB by leveraging random matrix theory. The results demonstrate that CRB-based analysis provides a tractable and informative benchmark for evaluating activity detection across architectures and detection schemes, and further reveal that FASs can deliver strong spatial-diversity gains with significantly reduced complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11901v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhentian Zhang, Kai-Kit Wong, Hao Jiang, Christos Masouros, Chan-Byoung Chae</dc:creator>
    </item>
    <item>
      <title>Towards a Sustainable Age of Information Metric: Carbon Footprint of Real-Time Status Updates</title>
      <link>https://arxiv.org/abs/2602.11946</link>
      <description>arXiv:2602.11946v1 Announce Type: new 
Abstract: The timeliness of collected information is essential for monitoring and control in data-driven intelligent infrastructures. It is typically quantified using the Age of Information (AoI) metric, which has been widely adopted to capture the freshness of information received in the form of status updates. While AoI-based metrics quantify how timely the collected information is, they largely overlook the environmental impact associated with frequent transmissions, specifically, the resulting Carbon Footprint (CF). To address this gap, we introduce a carbon-aware AoI framework. We first derive closed-form expressions for the average AoI under constrained CF budgets for the baseline $M/M/1$ and $M/M/1^*$ queuing models, assuming fixed Carbon Intensity (CI). We then extend the analysis by treating CI as a dynamic, time-varying parameter and solve the AoI minimization problem. Our results show that minimizing AoI does not inherently minimize CF, highlighting a clear trade-off between information freshness and environmental impact. CI variability further affects achievable AoI, indicating that sustainable operation requires joint optimization of CF budgets, Signal-to-noise Ratio (SNR), and transmission scheduling. This work lays the foundation for carbon-aware information freshness optimization in next-generation networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11946v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shih-Kai Chou, Maice Costa, Mihael Mohor\v{c}i\v{c}, Jernej Hribar</dc:creator>
    </item>
    <item>
      <title>Robust Composite DNA Storage under Sampling Randomness, Substitution, and Insertion-Deletion Errors</title>
      <link>https://arxiv.org/abs/2602.11951</link>
      <description>arXiv:2602.11951v1 Announce Type: new 
Abstract: DNA data storage offers a high-density, long-term alternative to traditional storage systems, addressing the exponential growth of digital data. Composite DNA extends this paradigm by leveraging mixtures of nucleotides to increase storage capacity beyond the four standard bases. In this work, we model composite DNA storage as a multinomial channel and draw an analogy to digital modulation by representing composite letters on the three-dimensional probability simplex. To mitigate errors caused by sampling randomness, we derive transition probabilities and log-likelihood ratios (LLRs) for each constellation point and employ practical channel codes for error correction. We then extend this framework to substitution and insertion-deletion (ID) channels, proposing constellation update rules that account for these additional impairments. Numerical results demonstrate that our approach achieves reliable performance with existing LDPC codes, compared to the prior schemes designed for limited-magnitude probability errors, whose performance degrades significantly under sampling randomness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11951v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Busra Tegin, Tolga M Duman</dc:creator>
    </item>
    <item>
      <title>Achievability Bounds of Coding with Finite Blocklength for Gaussian Broadcast Channels</title>
      <link>https://arxiv.org/abs/2602.11986</link>
      <description>arXiv:2602.11986v1 Announce Type: new 
Abstract: In this paper, we study the achievable performance of dirty paper coding for the Gaussian broadcast channel (BC) with finite blocklength and we propose two different achievability bounds for this problem. We present the broadcast adaptation of dependence testing bound of Polyanskiy et al. 2010, which is an upper bound on the average error probability that depends on the channel dispersion terms of each error event for fixed input. Additionally, we introduce the $\kappa \beta$ lower bounds on the maximal code sizes of each user using dirty paper coding.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11986v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ay\c{s}e \"Unsal, Jean-Marie Gorce</dc:creator>
    </item>
    <item>
      <title>Rate-Reliability Tradeoff for Deterministic Identification over Gaussian Channels</title>
      <link>https://arxiv.org/abs/2602.12182</link>
      <description>arXiv:2602.12182v1 Announce Type: new 
Abstract: We extend the recent analysis of the rate-reliability tradeoff in deterministic identification (DI) to general linear Gaussian channels, marking the first such analysis for channels with continuous output. Because DI provides a framework that can substantially enhance communication efficiency, and since the linear Gaussian model underlies a broad range of physical communication systems, our results offer both theoretical insights and practical relevance for the performance evaluation of DI in future networks. Moreover, the structural parallels observed between the Gaussian and discrete-output cases suggest that similar rate-reliability behaviour may extend to wider classes of continuous channels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.12182v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pau Colomer, Christian Deppe, Holger Boche, Andreas Winter</dc:creator>
    </item>
    <item>
      <title>Taming Subpacketization without Sacrificing Communication: A Packet Type-based Framework for D2D Coded Caching</title>
      <link>https://arxiv.org/abs/2602.12220</link>
      <description>arXiv:2602.12220v1 Announce Type: new 
Abstract: Finite-length analysis is critical for bringing coded caching closer to practical deployment. In this work, we study the design of communication rate-optimal device-to-device (D2D) coded caching schemes with minimal subpacketization levels, a key bottleneck in finite-length settings. We present a novel \tit{packet type-based} (PT) design framework that (i) strategically introduces \tit{asymmetry} into file splitting through user grouping, and (ii) systematically exploits such asymmetry in both cache placement and multicast delivery to create subpacketization reduction opportunities. In particular, the induced asymmetry gives rise to two fundamental forms of subpacketization reduction gains: the \emph{subfile saving gain}, achieved by eliminating certain types of subfiles through careful user grouping and transmitter selection, and the \emph{further splitting saving gain}, attained by reducing the splitting granularity for the remaining subfiles. The combined effect of these two reduction gains yields an overall subpacketization improvement over the original Ji-Caire-Molisch (JCM) caching scheme~\cite{ji2016fundamental}, as well as various state-of-the-art schemes, while preserving optimal communication rates.
  Under the PT framework, we formulate the caching scheme design as an integer linear program (ILP), where each feasible solution corresponds to a valid rate-optimal D2D coded caching scheme with potentially reduced subpacketization relative to the JCM baseline.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.12220v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiang Zhang, Giuseppe Caire, Mingyue Ji</dc:creator>
    </item>
    <item>
      <title>Transmit or Idle: Efficient AoI Optimal Transmission Policy for Gossiping Receivers</title>
      <link>https://arxiv.org/abs/2602.12264</link>
      <description>arXiv:2602.12264v1 Announce Type: new 
Abstract: We study the optimal transmission and scheduling policy for a transmitter (source) communicating with two gossiping receivers aiming at tracking the source's status over time using the age of information (AoI) metric. Gossiping enables local information exchange in a decentralized manner without relying solely on the transmitter's direct communication, which we assume incurs a transmission cost. On the other hand, gossiping may be communicating stale information, necessitating the transmitter's intervention. With communication links having specific success probabilities, we formulate an average-cost Markov Decision Process (MDP) to jointly minimize the sum AoI and transmission cost for such a system in a time-slotted setting. We employ the Relative Value Iteration (RVI) algorithm to evaluate the optimal policy for the transmitter and then prove several structural properties showing that it has an age-difference threshold structure with minimum age activation in the case where gossiping is relatively more reliable. Specifically, direct transmission is optimal only if the minimum AoI of the receivers is large enough and their age difference is below a certain threshold. Otherwise, the transmitter idles to effectively take advantage of gossiping and reduce direct transmission costs. Numerical evaluations demonstrate the significance of our optimal policy compared to multiple baselines. Our result is a first step towards characterizing optimal freshness and transmission cost trade-offs in gossiping networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.12264v1</guid>
      <category>cs.IT</category>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Irtiza Hasan, Ahmed Arafa</dc:creator>
    </item>
    <item>
      <title>ChaosBench-Logic: A Benchmark for Logical and Symbolic Reasoning on Chaotic Dynamical Systems</title>
      <link>https://arxiv.org/abs/2601.01982</link>
      <description>arXiv:2601.01982v1 Announce Type: cross 
Abstract: Large language models (LLMs) excel at natural language tasks but remain brittle in domains requiring precise logical and symbolic reasoning. Chaotic dynamical systems provide an especially demanding test because chaos is deterministic yet often misinterpreted as randomness or complexity. We introduce ChaosBench-Logic, a benchmark that evaluates LLM reasoning across 30 diverse dynamical systems using a unified first-order logic (FOL) ontology. Each system is annotated with truth assignments for 11 semantic predicates, and 621 questions are generated across seven reasoning categories, including multi-hop implications, cross-system analogies, counterfactual reasoning, bias probes, and multi-turn dialogues. We define metrics for logical accuracy, implication consistency, dialogue coherence, and contradiction, and we release an open-source evaluation pipeline. Initial experiments show that frontier LLMs such as GPT-4, Claude 3.5 Sonnet, Gemini 2.5 Flash, and the open-source LLaMA-3 70B achieve 91-94% per-item accuracy, yet still score 0% on compositional items and exhibit fragile global coherence. Dialogue-level accuracy ranges from 53.1% (GPT-4 CoT) to 75.5% (LLaMA-3 zero-shot). ChaosBench-Logic provides a rigorous testbed for diagnosing such failures and a foundation for developing neuro-symbolic approaches that improve scientific reasoning in LLMs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.01982v1</guid>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>AAAI 2026 Bridge Program on Logical and Symbolic Reasoning in Language Models, Singapore, Jan 2026</arxiv:journal_reference>
      <dc:creator>Noel Thomas</dc:creator>
    </item>
    <item>
      <title>How Many Features Can a Language Model Store Under the Linear Representation Hypothesis?</title>
      <link>https://arxiv.org/abs/2602.11246</link>
      <description>arXiv:2602.11246v1 Announce Type: cross 
Abstract: We introduce a mathematical framework for the linear representation hypothesis (LRH), which asserts that intermediate layers of language models store features linearly. We separate the hypothesis into two claims: linear representation (features are linearly embedded in neuron activations) and linear accessibility (features can be linearly decoded). We then ask: How many neurons $d$ suffice to both linearly represent and linearly access $m$ features? Classical results in compressed sensing imply that for $k$-sparse inputs, $d = O(k\log (m/k))$ suffices if we allow non-linear decoding algorithms (Candes and Tao, 2006; Candes et al., 2006; Donoho, 2006). However, the additional requirement of linear decoding takes the problem out of the classical compressed sensing, into linear compressed sensing.
  Our main theoretical result establishes nearly-matching upper and lower bounds for linear compressed sensing. We prove that $d = \Omega_\epsilon(\frac{k^2}{\log k}\log (m/k))$ is required while $d = O_\epsilon(k^2\log m)$ suffices. The lower bound establishes a quantitative gap between classical and linear compressed setting, illustrating how linear accessibility is a meaningfully stronger hypothesis than linear representation alone. The upper bound confirms that neurons can store an exponential number of features under the LRH, giving theoretical evidence for the "superposition hypothesis" (Elhage et al., 2022).
  The upper bound proof uses standard random constructions of matrices with approximately orthogonal columns. The lower bound proof uses rank bounds for near-identity matrices (Alon, 2003) together with Tur\'an's theorem (bounding the number of edges in clique-free graphs). We also show how our results do and do not constrain the geometry of feature representations and extend our results to allow decoders with an activation function and bias.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11246v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.IT</category>
      <category>math.CO</category>
      <category>math.IT</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nikhil Garg, Jon Kleinberg, Kenny Peng</dc:creator>
    </item>
    <item>
      <title>Universal Sequential Changepoint Detection of Quantum Observables via Classical Shadows</title>
      <link>https://arxiv.org/abs/2602.11846</link>
      <description>arXiv:2602.11846v1 Announce Type: cross 
Abstract: We study sequential quantum changepoint detection in settings where the pre- and post-change regimes are specified through constraints on the expectation values of a finite set of observables. We consider an architecture with separate measurement and detection modules, and assume that the observables relevant to the detector are unknown to the measurement device. For this scenario, we introduce shadow-based sequential changepoint e-detection (eSCD), a novel protocol that combines a universal measurement strategy based on classical shadows with a nonparametric sequential test built on e-detectors. Classical shadows provide universality with respect to the detector's choice of observables, while the e-detector framework enables explicit control of the average run length (ARL) to false alarm. Under an ARL constraint, we establish finite-sample guarantees on the worst-case expected detection delay of eSCD. Numerical experiments validate the theory and demonstrate that eSCD achieves performance competitive with observable-specific measurement strategies, while retaining full measurement universality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11846v1</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Matteo Zecchin, Osvaldo Simeone, Aaditya Ramdas</dc:creator>
    </item>
    <item>
      <title>Seq2Seq2Seq: Lossless Data Compression via Discrete Latent Transformers and Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2602.12146</link>
      <description>arXiv:2602.12146v1 Announce Type: cross 
Abstract: Efficient lossless compression is essential for minimizing storage costs and transmission overhead while preserving data integrity. Traditional compression techniques, such as dictionary-based and statistical methods, often struggle to optimally exploit the structure and redundancy in complex data formats. Recent advancements in deep learning have opened new avenues for compression; however, many existing approaches depend on dense vector representations that obscure the underlying token structure. To address these limitations, we propose a novel lossless compression method that leverages Reinforcement Learning applied to a T5 language model architecture. This approach enables the compression of data into sequences of tokens rather than traditional vector representations. Unlike auto-encoders, which typically encode information into continuous latent spaces, our method preserves the token-based structure, aligning more closely with the original data format. This preservation allows for higher compression ratios while maintaining semantic integrity. By training the model using an off-policy Reinforcement Learning algorithm, we optimize sequence length to minimize redundancy and enhance compression efficiency. Our method introduces an efficient and adaptive data compression system built upon advanced Reinforcement Learning techniques, functioning independently of external grammatical or world knowledge. This approach shows significant improvements in compression ratios compared to conventional methods. By leveraging the latent information within language models, our system effectively compresses data without requiring explicit content understanding, paving the way for more robust and practical compression solutions across various applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.12146v1</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mahdi Khodabandeh, Ghazal Shabani, Arash Yousefi Jordehi, Seyed Abolghasem Mirroshandel</dc:creator>
    </item>
    <item>
      <title>Effective Wordle Heuristics</title>
      <link>https://arxiv.org/abs/2408.11730</link>
      <description>arXiv:2408.11730v2 Announce Type: replace 
Abstract: While previous researchers have performed an exhaustive search to determine an optimal Wordle strategy, that computation is very time consuming and produced a strategy using words that are unfamiliar to most people. With Wordle solutions being gradually eliminated (with a new puzzle each day and no reuse), an improved strategy could be generated each day, but the computation time makes a daily exhaustive search impractical. This paper shows that simple heuristics allow for fast generation of effective strategies and that little is lost by guessing only words that are possible solution words rather than more obscure words.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.11730v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ronald I. Greenberg</dc:creator>
    </item>
    <item>
      <title>A Tutorial on AI-Empowered Integrated A Tutorial on AI-Empowered Integrated Sensing and Communications</title>
      <link>https://arxiv.org/abs/2504.13363</link>
      <description>arXiv:2504.13363v2 Announce Type: replace 
Abstract: Integrating sensing and communication (ISAC) can help overcome the challenges of limited spectrum and expensive hardware, leading to improved energy and cost efficiency. While full cooperation between sensing and communication can result in significant performance gains, achieving optimal performance requires efficient designs of unified waveforms and beamformers for joint sensing and communication. Sophisticated statistical signal processing and multi-objective optimization techniques are necessary to balance the competing design requirements of joint sensing and communication tasks. As model-based approaches can be suboptimal or too complex, deep learning offers a powerful data-driven alternative, especially when optimal algorithms are unknown or impractical for real-time use. Unified waveform and beamformer design problems for ISAC fall into this category, where fundamental design trade-offs exist between sensing and communication performance metrics, and the underlying models may be inadequate or incomplete. This tutorial paper explores the application of artificial intelligence (AI) to enhance efficiency or reduce complexity in ISAC designs. We emphasize the integration benefits through AI-driven ISAC designs, prioritizing the development of unified waveforms, constellations, and beamforming strategies for both sensing and communication. To illustrate the practical potential of AI-driven ISAC, we present three case studies on waveform, beamforming, and constellation design, demonstrating how unsupervised learning and neural network-based optimization can effectively balance performance, complexity, and implementation constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.13363v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mojtaba Vaezi, Gayan Aruma Baduge, Esa Ollila, Sergiy A. Vorobyov</dc:creator>
    </item>
    <item>
      <title>Constant Modulus Waveforms for IoT-Centric Integrated Sensing and Communications</title>
      <link>https://arxiv.org/abs/2506.21078</link>
      <description>arXiv:2506.21078v2 Announce Type: replace 
Abstract: Integrated sensing and communications (ISAC) is considered a key enabler to support application scenarios such as the Internet-of-Things (IoT) in which both communications and sensing play significant roles. Multi-carrier waveforms, such as orthogonal frequency division multiplexing (OFDM), have been considered as good candidates for ISAC due to their high communications data rate and good time bandwidth property for sensing. Nevertheless, their high peak-to-average-power-ratio (PAPR) values lead to either performance degradation or an increase in system complexity. This can make OFDM unsuitable for IoT applications with insufficient resources in terms of power, system complexity, hardware size or cost. This article provides IoT-centric constant modulus waveform designs that leverage the advantage of unit PAPR and thus are more suitable in resource-limited scenarios. More specifically, several single-carrier frequency and/or phase-modulated waveforms are considered. A comprehensive discussion on their radar sensing and communications performance is conducted based on performance metrics, including the radar ambiguity function, the bandwidth property, the data rate, and the communications receiver complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.21078v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tian Han, Shalanika Dayarathna, Rajitha Senanayake, Peter Smith, Aryan Kaushik, Alain Mourad, Richard A. Stirling-Gallacher, Jamie Evans</dc:creator>
    </item>
    <item>
      <title>Multivariate Partial Information Decomposition: Constructions, Inconsistencies, and Alternative Measures</title>
      <link>https://arxiv.org/abs/2508.05530</link>
      <description>arXiv:2508.05530v2 Announce Type: replace 
Abstract: While mutual information effectively quantifies dependence between two variables, it does not by itself reveal the complex, fine-grained interactions among variables, i.e., how multiple sources contribute redundantly, uniquely, or synergistically to a target in multivariate settings. The Partial Information Decomposition (PID) framework was introduced to address this by decomposing the mutual information between a set of source variables and a target variable into fine-grained information atoms such as redundant, unique, and synergistic components. In this work, we review the axiomatic system and desired properties of the PID framework and make three main contributions. First, we resolve the two-source PID case by providing explicit closed-form formulas for all information atoms that satisfy the full set of axioms and desirable properties. Second, we prove that for three or more sources, PID suffers from fundamental inconsistencies: we review the known three-variable counterexample where the sum of atoms exceeds the total information, and extend it to a comprehensive impossibility theorem showing that no lattice-based decomposition can be consistent for all subsets when the number of sources exceeds three. Finally, we deviate from the PID lattice approach to avoid its inconsistencies, and present explicit measures of multivariate unique and synergistic information. Our proposed measures, which rely on new systems of random variables that eliminate higher-order dependencies, satisfy key axioms such as additivity and continuity, provide a robust theoretical explanation of high-order relations, and show strong numerical performance in comprehensive experiments on the Ising model. Our findings highlight the need for a new framework for studying multivariate information decomposition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.05530v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aobo Lyu, Andrew Clark, Netanel Raviv</dc:creator>
    </item>
    <item>
      <title>Implementation of Oblivious Transfer over Binary-Input AWGN Channels by Polar Codes</title>
      <link>https://arxiv.org/abs/2601.10682</link>
      <description>arXiv:2601.10682v2 Announce Type: replace 
Abstract: We develop a one-out-of-two oblivious transfer protocol over the binary-input additive white Gaussian noise (BI-AWGN) channel using polar codes. The scheme uses two decoder views linked by automorphisms of the polar transform and publicly draws the encoder at random from the corresponding automorphism group. This yields perfect secrecy for Bob at any blocklength. Secrecy for Alice is obtained asymptotically via channel polarization combined with privacy amplification. Because the construction deliberately injects randomness into selected bad bit-channels, we derive a relaxed reliability criterion, which is empirically certified via Monte-Carlo simulations. We also evaluate finite-blocklength performance. Finally, we characterize the polar-transform automorphisms as bit-level permutations of bit-channel indices, and exploit this structure to derive and optimize an achievable finite-blocklength rate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10682v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pin-Hsun Lin, Hadi Aghaee, Christian Deppe, Eduard A. Jorswieck, Holger Boche</dc:creator>
    </item>
    <item>
      <title>Physics-Informed Implicit Neural Representation for Wireless Imaging in RIS-Aided ISAC System</title>
      <link>https://arxiv.org/abs/2601.15113</link>
      <description>arXiv:2601.15113v2 Announce Type: replace 
Abstract: Wireless imaging has become a vital function in future integrated sensing and communication (ISAC) systems. However, traditional model-based and data-driven deep learning imaging methods face challenges related to multipath extraction, dataset acquisition, and multi-scenario adaptation. To overcome these limitations, this study innovatively combines implicit neural representation (INR) with explicit physical models to realize wireless imaging in reconfigurable intelligent surface (RIS)-aided ISAC systems. INR employs neural networks (NNs) to project physical locations to voxel values, which is indirectly supervised by measurements of channel state information with physics-informed loss functions. The continuous shape and scattering characteristics of targets are embedded into NN parameters through training, enabling arbitrary image resolutions and off-grid voxel value prediction. Additionally, three issues related to INR-based imager are further addressed. First, INR is generalized to enable efficient imaging under multipath interference by jointly learning image and multipath information. Second, the imaging speed and accuracy for dynamic targets are enhanced by embedding prior image information. Third, imaging results are employed to assist in RIS phase design for improved communication performance. Extensive simulations demonstrate that the proposed INR-based imager significantly outperforms traditional model-based methods with super-resolution abilities, and the focal length characteristics of the imaging system is revealed. Moreover, communication performance can benefit from the imaging results. Part of the source code for this paper can be accessed at https://github.com/kiwi1944/INRImager</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.15113v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yixuan Huang, Jie Yang, Chao-Kai Wen, Shi Jin</dc:creator>
    </item>
    <item>
      <title>Can Complexity and Uncomputability Explain Intelligence? SuperARC: A Test for Artificial Super Intelligence Based on Recursive Compression</title>
      <link>https://arxiv.org/abs/2503.16743</link>
      <description>arXiv:2503.16743v5 Announce Type: replace-cross 
Abstract: We introduce an increasing-complexity, open-ended, and human-agnostic metric to evaluate foundational and frontier AI models in the context of Artificial General Intelligence (AGI) and Artificial Super Intelligence (ASI) claims. Unlike other tests that rely on human-centric questions and expected answers, or on pattern-matching methods, the test here introduced is grounded on fundamental mathematical areas of randomness and optimal inference. We argue that human-agnostic metrics based on the universal principles established by Algorithmic Information Theory (AIT) formally framing the concepts of model abstraction and prediction offer a powerful metrological framework. When applied to frontiers models, the leading LLMs outperform most others in multiple tasks, but they do not always do so with their latest model versions, which often regress and appear far from any global maximum or target estimated using the principles of AIT defining a Universal Intelligence (UAI) point and trend in the benchmarking. Conversely, a hybrid neuro-symbolic approach to UAI based on the same principles is shown to outperform frontier specialised prediction models in a simplified but relevant example related to compression-based model abstraction and sequence prediction. Finally, we prove and conclude that predictive power through arbitrary formal theories is directly proportional to compression over the algorithmic space, not the statistical space, and so further AI models' progress can only be achieved in combination with symbolic approaches that LLMs developers are adopting often without acknowledgement or realisation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16743v5</guid>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alberto Hern\'andez-Espinosa, Luan Ozelim, Felipe S. Abrah\~ao, Hector Zenil</dc:creator>
    </item>
    <item>
      <title>On the optimization dynamics of RLVR: Gradient gap and step size thresholds</title>
      <link>https://arxiv.org/abs/2510.08539</link>
      <description>arXiv:2510.08539v3 Announce Type: replace-cross 
Abstract: Reinforcement Learning with Verifiable Rewards (RLVR), which uses simple binary feedback to post-train large language models, has found significant empirical success. However, a principled understanding of why it works is lacking. This paper builds a theoretical foundation for RLVR by analyzing its training process at both the full-response (trajectory) and token levels. Central to our analysis is a new quantity called the Gradient Gap, which formalizes the direction of improvement from low-reward to high-reward regions of the response space. We prove that convergence critically depends on aligning the update direction with this Gradient Gap. Moreover, we derive a sharp step-size threshold based on the magnitude of the Gradient Gap: below it, learning converges, whereas above it, performance collapses. Our theory further predicts how the critical step size must scale with response length and the success rate, thereby explaining why practical heuristics such as length normalization improve stability and showing that, with a fixed learning rate, the success rate can stagnate strictly below $100\%$. Importantly, our theory holds flexibly for any policy-gradient algorithm and so characterizes the dynamics of popular approaches such as REINFORCE and GRPO. We validate these predictions through controlled bandit simulations and language model experiments on post-training Qwen2.5-Math-7B with GRPO.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.08539v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joe Suk, Yaqi Duan</dc:creator>
    </item>
    <item>
      <title>Deterministic Sort-Free Candidate Pruning for Scalable MIMO Box Decoding</title>
      <link>https://arxiv.org/abs/2512.00653</link>
      <description>arXiv:2512.00653v2 Announce Type: replace-cross 
Abstract: Box Decoding is a sort-free tree-search MIMO detector whose complexity is independent of the QAM order, achieved by searching a fixed candidate box around a zero-forcing (ZF) estimate. However, without pruning, the number of visited nodes grows exponentially with the MIMO dimension, limiting scalability. This work proposes two deterministic, low-complexity, sort-free pruning strategies to control node growth. By exploiting the geometric symmetry of the QAM grid and the relative displacement between the ZF estimate and nearby constellation points, the proposed methods eliminate unnecessary metric evaluations while preserving QAM-order independence. The resulting detector achieves substantial complexity reduction with negligible error-rate degradation and enables fully parallel, hardware-efficient implementations for large-scale MIMO and higher-order QAM systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.00653v2</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shengchun Yang, Amit Sravan Bora, Emil Matus, Gerhard Fettweis</dc:creator>
    </item>
    <item>
      <title>Asymmetry in Spectral Graph Theory: Harmonic Analysis on Directed Networks via Biorthogonal Bases (Adjacency-Operator Formulation)</title>
      <link>https://arxiv.org/abs/2512.12226</link>
      <description>arXiv:2512.12226v2 Announce Type: replace-cross 
Abstract: Classical spectral graph theory and graph signal processing rely on a symmetry principle: undirected graphs induce symmetric (self-adjoint) adjacency/Laplacian operators, yielding orthogonal eigenbases and energy-preserving Fourier expansions. Real-world networks are typically directed and hence asymmetric, producing non-self-adjoint and frequently non-normal operators for which orthogonality fails and spectral coordinates can be ill-conditioned. In this paper we develop an original harmonic-analysis framework for directed networks centered on the \emph{adjacency} operator. We propose a \emph{Biorthogonal Graph Fourier Transform} (BGFT) built from left/right eigenvectors, formulate directed ``frequency'' and filtering in the non-Hermitian setting, and quantify how asymmetry and non-normality affect stability via condition numbers and a departure-from-normality functional. We prove exact synthesis/analysis identities under diagonalizability, establish sampling-and-reconstruction guarantees for BGFT-bandlimited signals, and derive perturbation/stability bounds that explain why naive orthogonal-GFT assumptions break down on non-normal directed graphs. A simulation protocol compares undirected versus directed cycles (asymmetry without non-normality) and a perturbed directed cycle (genuine non-normality), demonstrating that BGFT yields coherent reconstruction and filtering across asymmetric regimes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.12226v2</guid>
      <category>math.RA</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.56581/IJLRET.12.01.21-33</arxiv:DOI>
      <dc:creator>Chandrasekhar Gokavarapu (Department of Mathematics, Government College)</dc:creator>
    </item>
    <item>
      <title>Beyond the Loss Curve: Scaling Laws, Active Learning, and the Limits of Learning from Exact Posteriors</title>
      <link>https://arxiv.org/abs/2602.00315</link>
      <description>arXiv:2602.00315v2 Announce Type: replace-cross 
Abstract: How close are neural networks to the best they could possibly do? Standard benchmarks cannot answer this because they lack access to the true posterior p(y|x). We use class-conditional normalizing flows as oracles that make exact posteriors tractable on realistic images (AFHQ, ImageNet). This enables five lines of investigation. Scaling laws: Prediction error decomposes into irreducible aleatoric uncertainty and reducible epistemic error; the epistemic component follows a power law in dataset size, continuing to shrink even when total loss plateaus. Limits of learning: The aleatoric floor is exactly measurable, and architectures differ markedly in how they approach it: ResNets exhibit clean power-law scaling while Vision Transformers stall in low-data regimes. Soft labels: Oracle posteriors contain learnable structure beyond class labels: training with exact posteriors outperforms hard labels and yields near-perfect calibration. Distribution shift: The oracle computes exact KL divergence of controlled perturbations, revealing that shift type matters more than shift magnitude: class imbalance barely affects accuracy at divergence values where input noise causes catastrophic degradation. Active learning: Exact epistemic uncertainty distinguishes genuinely informative samples from inherently ambiguous ones, improving sample efficiency. Our framework reveals that standard metrics hide ongoing learning, mask architectural differences, and cannot diagnose the nature of distribution shift.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.00315v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arian Khorasani, Nathaniel Chen, Yug D Oswal, Akshat Santhana Gopalan, Egemen Kolemen, Ravid Shwartz-Ziv</dc:creator>
    </item>
    <item>
      <title>Information-Theoretic Thresholds for Bipartite Latent-Space Graphs under Noisy Observations</title>
      <link>https://arxiv.org/abs/2602.11129</link>
      <description>arXiv:2602.11129v2 Announce Type: replace-cross 
Abstract: We study information-theoretic phase transitions for the detectability of latent geometry in bipartite random geometric graphs RGGs with Gaussian d-dimensional latent vectors while only a subset of edges carries latent information determined by a random mask with i.i.d. Bern(q) entries. For any fixed edge density p in (0,1) we determine essentially tight thresholds for this problem as a function of d and q. Our results show that the detection problem is substantially easier if the mask is known upfront compared to the case where the mask is hidden.
  Our analysis is built upon a novel Fourier-analytic framework for bounding signed subgraph counts in Gaussian random geometric graphs that exploits cancellations which arise after approximating characteristic functions by an appropriate power series. The resulting bounds are applicable to much larger subgraphs than considered in previous work which enables tight information-theoretic bounds, while the bounds considered in previous works only lead to lower bounds from the lens of low-degree polynomials. As a consequence we identify the optimal information-theoretic thresholds and rule out computational-statistical gaps. Our bounds further improve upon the bounds on Fourier coefficients of random geometric graphs recently given by Bangachev and Bresler [STOC'24] in the dense, bipartite case. The techniques also extend to sparser and non-bipartite settings, at least if the considered subgraphs are sufficiently small. We furhter believe that they might help resolve open questions for related detection problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11129v2</guid>
      <category>math.PR</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Andreas G\"obel, Marcus Pappik, Leon Schiller</dc:creator>
    </item>
  </channel>
</rss>
