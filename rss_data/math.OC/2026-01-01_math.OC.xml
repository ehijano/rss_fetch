<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 01 Jan 2026 05:00:12 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Stochastic Galerkin Method and Hierarchical Preconditioning for PDE-constrained Optimization</title>
      <link>https://arxiv.org/abs/2512.23804</link>
      <description>arXiv:2512.23804v1 Announce Type: new 
Abstract: We develop efficient hierarchical preconditioners for optimal control problems governed by partial differential equations with uncertain coefficients. Adopting a discretize-then-optimize framework that integrates finite element discretization, stochastic Galerkin approximation, and advanced time-discretization schemes, the approach addresses the challenge of large-scale, ill-conditioned linear systems arising in uncertainty quantification. By exploiting the sparsity inherent in generalized polynomial chaos expansions, we derive hierarchical preconditioners based on truncated stochastic expansion that strike an effective balance between computational cost and preconditioning quality. Numerical experiments demonstrate that the proposed preconditioners significantly accelerate the convergence of iterative solvers compared to existing methods, providing robust and efficient solvers for both steady-state and time-dependent optimal control applications under uncertainty.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.23804v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.NA</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhendong Li, Akwum Onwunta, Bed\v{r}ich Soused\'ik</dc:creator>
    </item>
    <item>
      <title>The Flow-Limit of Reflect-Reflect-Relax: Existence, Stability, and Discrete-Time Behavior</title>
      <link>https://arxiv.org/abs/2512.23843</link>
      <description>arXiv:2512.23843v1 Announce Type: new 
Abstract: We study the Reflect-Reflect-Relax (RRR) algorithm in its small-step (flow-limit) regime. In the smooth transversal setting, we show that the transverse dynamics form a hyperbolic sink, yielding exponential decay of a natural gap measure. Under uniform geometric assumptions, we construct a tubular neighborhood of the feasible manifold on which the squared gap defines a strict Lyapunov function, excluding recurrent dynamics and chaotic behavior within this basin.
  In the discrete setting, the induced flow is piecewise constant on W-domains and supports Filippov sliding along convergent boundaries, leading to finite-time capture into a solution domain. We prove that small-step RRR is a forward-Euler discretization of this flow, so that solution times measured in rescaled units converge to a finite limit while iteration counts diverge, explaining the emergence of iteration-optimal relaxation parameters. Finally, we introduce a heuristic mesoscopic framework based on percolation and renormalization group to organize performance deterioration near the Douglas-Rachford limit.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.23843v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.DS</category>
      <category>math.NA</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Manish Krishan Lal</dc:creator>
    </item>
    <item>
      <title>Policy Mirror Descent with Temporal Difference Learning: Sample Complexity under Online Markov Data</title>
      <link>https://arxiv.org/abs/2512.24056</link>
      <description>arXiv:2512.24056v1 Announce Type: new 
Abstract: This paper studies the policy mirror descent (PMD) method, which is a general policy optimization framework in reinforcement learning and can cover a wide range of policy gradient methods by specifying difference mirror maps. Existing sample complexity analysis for policy mirror descent either focuses on the generative sampling model, or the Markovian sampling model but with the action values being explicitly approximated to certain pre-specified accuracy. In contrast, we consider the sample complexity of policy mirror descent with temporal difference (TD) learning under the Markovian sampling model. Two algorithms called Expected TD-PMD and Approximate TD-PMD have been presented, which are off-policy and mixed policy algorithms respectively. Under a small enough constant policy update step size, the $\tilde{O}(\varepsilon^{-2})$ (a logarithm factor about $\varepsilon$ is hidden in $\tilde{O}(\cdot)$) sample complexity can be established for them to achieve average-time $\varepsilon$-optimality. The sample complexity is further improved to $O(\varepsilon^{-2})$ (without the hidden logarithm factor) to achieve the last-iterate $\varepsilon$-optimality based on adaptive policy update step sizes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.24056v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wenye Li, Hongxu Chen, Jiacai Liu, Ke Wei</dc:creator>
    </item>
    <item>
      <title>Complexity and convergence analysis of a single-loop SDCAM for Lipschitz composite optimization and beyond</title>
      <link>https://arxiv.org/abs/2512.24059</link>
      <description>arXiv:2512.24059v1 Announce Type: new 
Abstract: We develop and analyze a single-loop algorithm for minimizing the sum of a Lipschitz differentiable function $f$, a prox-friendly proper closed function $g$ (with a closed domain on which $g$ is continuous) and the composition of another prox-friendly proper closed function $h$ (whose domain is closed on which $h$ is continuous) with a continuously differentiable mapping $c$ (that is Lipschitz continuous and Lipschitz differentiable on the convex closure of the domain of $g$). Such models arise naturally in many contemporary applications, where $f$ is the loss function for data misfit, and $g$ and $h$ are nonsmooth functions for inducing desirable structures in $x$ and $c(x)$. Existing single-loop algorithms mainly focus either on the case where $h$ is Lipschitz continuous or the case where $h$ is an indicator function of a closed convex set. In this paper, we develop a single-loop algorithm for more general possibly non-Lipschitz $h$. Our algorithm is a single-loop variant of the successive difference-of-convex approximation method (SDCAM) proposed in [22]. We show that when $h$ is Lipschitz, our algorithm exhibits an iteration complexity that matches the best known complexity result for obtaining an $(\epsilon_1,\epsilon_2,0)$-stationary point. Moreover, we show that, by assuming additionally that dom $g$ is compact, our algorithm exhibits an iteration complexity of $\tilde{O}(\epsilon^{-4})$ for obtaining an $(\epsilon,\epsilon,\epsilon)$-stationary point when $h$ is merely continuous and real-valued. Furthermore, we consider a scenario where $h$ does not have full domain and establish vanishing bounds on successive changes of iterates. Finally, in all three cases mentioned above, we show that one can construct a subsequence such that any accumulation point $x^*$ satisfies $c(x^*)\in$ dom $h$, and if a standard constraint qualification holds at $x^*$, then $x^*$ is a stationary point.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.24059v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hao Zhang, Naoki Marumo, Ting Kei Pong, Akiko Takeda</dc:creator>
    </item>
    <item>
      <title>Complete lift of control system</title>
      <link>https://arxiv.org/abs/2512.24262</link>
      <description>arXiv:2512.24262v1 Announce Type: new 
Abstract: We study affine control systems on smooth manifolds and their complete lifts to the tangent bundle, providing an explicit geometric description of the solutions of the lifted system. We show that, although controllability of the complete lift implies controllability of the original system, the lifted system is never controllable due to intrinsic geometric constraints. By introducing chain controllability, we prove that controllability of the original system guarantees chain controllability of its complete lift.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.24262v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sim\~ao N. Stelmastchuk</dc:creator>
    </item>
    <item>
      <title>Adaptive Algorithms for Nonconvex Bilevel Optimization under P{\L} Conditions</title>
      <link>https://arxiv.org/abs/2512.24291</link>
      <description>arXiv:2512.24291v1 Announce Type: new 
Abstract: Existing methods for nonconvex bilevel optimization (NBO) require prior knowledge of first- and second-order problem-specific parameters (e.g., Lipschitz constants and the Polyak-{\L}ojasiewicz (P{\L}) parameters) to set step sizes, a requirement that poses practical limitations when such parameters are unknown or computationally expensive. We introduce the Adaptive Fully First-order Bilevel Approximation (AF${}^2$BA) algorithm and its accelerated variant, A${}^2$F${}^2$BA, for solving NBO problems under the P{\L} conditions. To our knowledge, these are the first methods to employ fully adaptive step size strategies, eliminating the need for any problem-specific parameters in NBO. We prove that both algorithms achieve $\mathcal{O}(1/\epsilon^2)$ iteration complexity for finding an $\epsilon$-stationary point, matching the iteration complexity of existing well-tuned methods. Furthermore, we show that A${}^2$F${}^2$BA enjoys a near-optimal first-order oracle complexity of $\tilde{\mathcal{O}}(1/\epsilon^2)$, matching the oracle complexity of existing well-tuned methods, and aligning with the complexity of gradient descent for smooth nonconvex single-level optimization when ignoring the logarithmic factors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.24291v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xu Shi, Yinglin Du, Rufeng Xiao, Rujun Jiang</dc:creator>
    </item>
    <item>
      <title>Optimization over Trained Neural Networks: Going Large with Gradient-Based Algorithms</title>
      <link>https://arxiv.org/abs/2512.24295</link>
      <description>arXiv:2512.24295v1 Announce Type: new 
Abstract: When optimizing a nonlinear objective, one can employ a neural network as a surrogate for the nonlinear function. However, the resulting optimization model can be time-consuming to solve globally with exact methods. As a result, local search that exploits the neural-network structure has been employed to find good solutions within a reasonable time limit. For such methods, a lower per-iteration cost is advantageous when solving larger models. The contribution of this paper is two-fold. First, we propose a gradient-based algorithm with lower per-iteration cost than existing methods. Second, we further adapt this algorithm to exploit the piecewise-linear structure of neural networks that use Rectified Linear Units (ReLUs). In line with prior research, our methods become competitive with -- and then dominant over -- other local search methods as the optimization models become larger.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.24295v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiatai Tong, Yilin Zhu, Thiago Serra, Samuel Burer</dc:creator>
    </item>
    <item>
      <title>Approximation algorithms for integer programming with resource augmentation</title>
      <link>https://arxiv.org/abs/2512.24302</link>
      <description>arXiv:2512.24302v1 Announce Type: new 
Abstract: The classic algorithm [Papadimitriou, J.ACM '81] for IPs has a running time $n^{O(m)}(m\cdot\max\{\Delta,\|\textbf{b}\|_{\infty}\})^{O(m^2)}$, where $m$ is the number of constraints, $n$ is the number of variables, and $\Delta$ and $\|\textbf{b}\|_{\infty}$ are, respectively, the largest absolute values among the entries in the constraint matrix and the right-hand side vector of the constraint. The running time is exponential in $m$, and becomes pseudo-polynomial if $m$ is a constant. In recent years, there has been extensive research on FPT (fixed parameter tractable) algorithms for the so-called $n$-fold IPs, which may possess a large number of constraints, but the constraint matrix satisfies a specific block structure. It is remarkable that these FPT algorithms take as parameters $\Delta$ and the number of rows and columns of some small submatrices. If $\Delta$ is not treated as a parameter, then the running time becomes pseudo-polynomial even if all the other parameters are taken as constants.
  This paper explores the trade-off between time and accuracy in solving an IP. We show that, for arbitrary small $\varepsilon&gt;0$, there exists an algorithm for IPs with $m$ constraints that runs in ${f(m,\varepsilon)}\cdot\textnormal{poly}(|I|)$ time, and returns a near-feasible solution that violates the constraints by at most $\varepsilon\Delta$. Furthermore, for $n$-fold IPs, we establish a similar result -- our algorithm runs in time that depends on the number of rows and columns of small submatrices together with $1/\varepsilon$, and returns a solution that slightly violates the constraints. Meanwhile, both solutions guarantee that their objective values are no worse than the corresponding optimal objective values satisfying the constraints. As applications, our results can be used to obtain additive approximation schemes for multidimensional knapsack as well as scheduling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.24302v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hauke Brinkop, Hua Chen, Lin Chen, Klaus Jansen, Guochuan Zhang</dc:creator>
    </item>
    <item>
      <title>Discrete-Time Mean Field Type Games: Probabilistic Setup</title>
      <link>https://arxiv.org/abs/2512.24313</link>
      <description>arXiv:2512.24313v1 Announce Type: new 
Abstract: We introduce a general probabilistic framework for discrete-time, infinite-horizon discounted Mean Field Type Games (MFTGs) with both global common noise and team-specific common noises. In our model, agents are allowed to use randomized actions, both at the individual level and at the team level. We formalize the concept of Mean Field Markov Games (MFMGs) and establish a connection between closed-loop policies in MFTGs and Markov policies in MFMGs through different layers of randomization. By leveraging recent results on infinite-horizon discounted games with infinite compact state-action spaces, we prove the existence of an optimal closed-loop policy for the original MFTG when the state spaces are at most countable and the action spaces are general Polish spaces. We also present an example satisfying our assumptions, called Mean Field Drift of Intentions, where the dynamics are strongly randomized, and we establish the existence of a Nash equilibrium using our theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.24313v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gr\'egoire Lambrecht, Mathieu Lauri\`ere</dc:creator>
    </item>
    <item>
      <title>Backpropagation from KL Projections: Differential and Exact I-Projection Correspondences</title>
      <link>https://arxiv.org/abs/2512.24335</link>
      <description>arXiv:2512.24335v1 Announce Type: new 
Abstract: We establish two exact correspondences between reverse-mode automatic differentiation (backpropagation evaluated at a fixed forward pass) and compositions of projection maps in Kullback--Leibler (KL) geometry. In both settings, message passing defined by alternating KL projections enforces agreement and factorization constraints. In the first setting, backpropagation arises as the differential of a KL projection map on a delta-lifted factorization. In the second setting, on complete and decomposable sum--product networks, backpropagation coincides with exact probabilistic inference, and the backward values admit an interpretation as Lagrange multipliers of a KL I-projection problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.24335v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Manish Krishan Lal</dc:creator>
    </item>
    <item>
      <title>Decentralized Optimization over Time-Varying Row-Stochastic Digraphs</title>
      <link>https://arxiv.org/abs/2512.24483</link>
      <description>arXiv:2512.24483v1 Announce Type: new 
Abstract: Decentralized optimization over directed graphs is essential for applications such as robotic swarms, sensor networks, and distributed learning. In many practical scenarios, the underlying network is a Time-Varying Broadcast Network (TVBN), where only row-stochastic mixing matrices can be constructed due to inaccessible out-degree information. Achieving exact convergence over TVBNs has remained a long-standing open question, as the limiting distribution of time-varying row-stochastic mixing matrices depends on unpredictable future graph realizations, rendering standard bias-correction techniques infeasible.
  This paper resolves this open question by developing the first algorithm that achieves exact convergence using only time-varying row-stochastic matrices. We propose PULM (Pull-with-Memory), a gossip protocol that attains average consensus with exponential convergence by alternating between row-stochastic mixing and local adjustment. Building on PULM, we develop PULM-DGD, which converges to a stationary solution at $\mathcal{O}(\ln(T)/T)$ for smooth nonconvex objectives. Our results significantly extend decentralized optimization to highly dynamic communication environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.24483v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Liyuan Liang, Yilong Song, Kun Yuan</dc:creator>
    </item>
    <item>
      <title>A Study on the Algorithm and Implementation of SDPT3</title>
      <link>https://arxiv.org/abs/2512.24623</link>
      <description>arXiv:2512.24623v1 Announce Type: new 
Abstract: This technical report presents a comprehensive study of SDPT3, a widely used open-source MATLAB solver for semidefinite-quadratic-linear programming, which is based on the interior-point method. It includes a self-contained and consistent description of the algorithm, with mathematical notation carefully aligned with the implementation. The aim is to offer a clear and structured reference for researchers and developers seeking to understand or build upon the implementation of SDPT3.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.24623v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Naoki Ito</dc:creator>
    </item>
    <item>
      <title>A Differential Game with Symmetric Incomplete Information on Probabilistic Initial Condition and with Signal Revelation</title>
      <link>https://arxiv.org/abs/2512.24640</link>
      <description>arXiv:2512.24640v1 Announce Type: new 
Abstract: In this paper, we investigate the existence and characterization of the value for a two-player zero-sum differential game with symmetric incomplete information on a continuum of initial positions and with signal revelation. Before the game starts, the initial position is chosen randomly according to a probability measure with compact support, and neither player is informed of the chosen initial position. However, they observe a public signal revealing the current state as soon as the trajectory of the dynamics hits a target set. We prove that, under a suitable notion of signal-dependent strategies, the value of the game exists, and the extended value function of the game is the unique viscosity solution of an associated Hamilton-Jacobi-Isaacs equation that satisfies a boundary condition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.24640v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaochi Wu</dc:creator>
    </item>
    <item>
      <title>A New Decomposition Paradigm for Graph-structured Nonlinear Programs via Message Passing</title>
      <link>https://arxiv.org/abs/2512.24676</link>
      <description>arXiv:2512.24676v1 Announce Type: new 
Abstract: We study finite-sum nonlinear programs whose decision variables interact locally according to a graph or hypergraph. We propose MP-Jacobi (Message Passing-Jacobi), a graph-compliant decentralized framework that couples min-sum message passing with Jacobi block updates. The (hyper)graph is partitioned into tree clusters. At each iteration, agents update in parallel by solving a cluster subproblem whose objective decomposes into (i) an intra-cluster term evaluated by a single min-sum sweep on the cluster tree (cost-to-go messages) and (ii) inter-cluster couplings handled via a Jacobi correction using neighbors' latest iterates. This design uses only single-hop communication and yields a convergent message-passing method on loopy graphs.
  For strongly convex objectives we establish global linear convergence and explicit rates that quantify how curvature, coupling strength, and the chosen partition affect scalability and provide guidance for clustering. To mitigate the computation and communication cost of exact message updates, we develop graph-compliant surrogates that preserve convergence while reducing per-iteration complexity. We further extend MP-Jacobi to hypergraphs; in heavily overlapping regimes, a surrogate-based hyperedge-splitting scheme restores finite-time intra-cluster message updates and maintains convergence. Experiments validate the theory and show consistent improvements over decentralized gradient baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.24676v1</guid>
      <category>math.OC</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kuangyu Ding, Marie Maros, Gesualdo Scutari</dc:creator>
    </item>
    <item>
      <title>A proximal subgradient algorithm for constrained multiobjective DC-type optimization</title>
      <link>https://arxiv.org/abs/2512.24717</link>
      <description>arXiv:2512.24717v1 Announce Type: new 
Abstract: In this paper, we consider a class of constrained multiobjective optimization problems, where each objective function can be expressed by adding a possibly nonsmooth nonconvex function and a differentiable function with Lipschitz continuous gradient, then subtracting a weakly convex function. This encompasses multiobjective optimization problems involving difference-of-convex (DC) functions, which are prevalent in various applications due to their ability to model nonconvex problems. We first establish necessary and sufficient optimality conditions for these problems, providing a theoretical foundation for algorithm development. Building on these conditions, we propose a proximal subgradient algorithm tailored to the structure of the objectives. Under mild assumptions, the sequence generated by the proposed algorithm is bounded and each of its cluster points is a stationary solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.24717v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nguyen Van Tuyen, Minh N. Dao, Tran Van Nghi</dc:creator>
    </item>
    <item>
      <title>Some Studies on Stochastic Optimization based Quantitative Risk Management</title>
      <link>https://arxiv.org/abs/2512.24736</link>
      <description>arXiv:2512.24736v1 Announce Type: new 
Abstract: Risk management often plays an important role in decision making under uncertainty. In quantitative risk management, assessing and optimizing risk metrics requires efficient computing techniques and reliable theoretical guarantees. In this paper, we introduce several topics on quantitative risk management and review some of the recent studies and advancements on the topics. We consider several risk metrics and study decision models that involve the metrics, with a main focus on the related computing techniques and theoretical properties. We show that stochastic optimization, as a powerful tool, can be leveraged to effectively address these problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.24736v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>Operations Research Transactions, 29(3) 135-159 (2025)</arxiv:journal_reference>
      <dc:creator>Zhaolin Hu</dc:creator>
    </item>
    <item>
      <title>A first approximation algorithm for the Bin Packing Problem with Setups</title>
      <link>https://arxiv.org/abs/2512.24785</link>
      <description>arXiv:2512.24785v1 Announce Type: new 
Abstract: We study constant-factor approximation algorithms for the Bin Packing Problem with Setups (BPPS). First, we show that adaptations of classical BPP heuristics can have arbitrarily poor worst-case performance on BPPS instances. Then, we propose a two-phase heuristic for the BPPS that applies an {\alpha}-approximation algorithm for the BPP to the items of each class and then performs a merging phase on the open bins. We prove that this heuristic is a 2 {\alpha}-approximation algorithm for the BPPS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.24785v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Roberto Baldacci, Fabio Ciccarelli, Stefano Coniglio, Valerio Dose, Fabio Furini</dc:creator>
    </item>
    <item>
      <title>Tensor Based Proximal Alternating Minimization Method for A Kind of Inhomogeneous Quartic Optimization Problem</title>
      <link>https://arxiv.org/abs/2512.24872</link>
      <description>arXiv:2512.24872v1 Announce Type: new 
Abstract: In this paper, we propose an efficient numerical approach for solving a specific type of quartic inhomogeneous polynomial optimization problem inspired by practical applications. The primary contribution of this work lies in establishing an inherent equivalence between the quartic inhomogeneous polynomial optimization problem and a multilinear optimization problem (MOP). This result extends the equivalence between fourth-order homogeneous polynomial optimization and multilinear optimization in the existing literature to the equivalence between fourth-order inhomogeneous polynomial optimization and multilinear optimization. By leveraging the multi-block structure embedded within the MOP, a tensor-based proximal alternating minimization algorithm is proposed to approximate the optimal value of the quartic problem. Under mild assumptions, the convergence of the algorithm is rigorously proven. Finally, the effectiveness of the proposed algorithm is demonstrated through preliminary computational results obtained using synthetic datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.24872v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haibin Chen, Yixuan Chen, Chunyan Wang, Qi Fan</dc:creator>
    </item>
    <item>
      <title>Adaptive Clutter Suppression via Convex Optimization</title>
      <link>https://arxiv.org/abs/2512.24889</link>
      <description>arXiv:2512.24889v1 Announce Type: new 
Abstract: Passive and bistatic radar systems are often limited by strong clutter and direct-path interference that mask weak moving targets. Conventional cancellation methods such as the extensive cancellation algorithm require careful tuning and can distort the delay-Doppler response. This paper introduces a convex optimization framework that adaptively synthesizes per-cell delay-Doppler filters to suppress clutter while preserving the canonical cross-ambiguity function (CAF). The approach formulates a quadratic program that minimizes distortion of the CAF surface subject to linear clutter-suppression constraints, eliminating the need for a separate cancellation stage. Monte Carlo simulations using common communication waveforms demonstrate strong clutter suppression, accurate CFAR calibration, and major detection-rate gains over the classical CAF. The results highlight a scalable, CAF-faithful method for adaptive clutter mitigation in passive radar.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.24889v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yifan He, Griffin Kearney, Makan Fardad</dc:creator>
    </item>
    <item>
      <title>Self-Supervised Amortized Neural Operators for Optimal Control: Scaling Laws and Applications</title>
      <link>https://arxiv.org/abs/2512.24897</link>
      <description>arXiv:2512.24897v1 Announce Type: new 
Abstract: Optimal control provides a principled framework for transforming dynamical system models into intelligent decision-making, yet classical computational approaches are often too expensive for real-time deployment in dynamic or uncertain environments. In this work, we propose a method based on self-supervised neural operators for open-loop optimal control problems. It offers a new paradigm by directly approximating the mapping from system conditions to optimal control strategies, enabling instantaneous inference across diverse scenarios once trained. We further extend this framework to more complex settings, including dynamic or partially observed environments, by integrating the learned solution operator with Model Predictive Control (MPC). This yields a solution-operator learning method for closed-loop control, in which the learned operator supplies rapid predictions that replace the potentially time-consuming optimization step in conventional MPC. This acceleration comes with a quantifiable price to pay. Theoretically, we derive scaling laws that relate generalization error and sample/model complexity to the intrinsic dimension of the problem and the regularity of the optimal control function. Numerically, case studies show efficient, accurate real-time performance in low-intrinsic-dimension regimes, while accuracy degrades as problem complexity increases. Together, these results provide a balanced perspective: neural operators are a powerful novel tool for high-performance control when hidden low-dimensional structure can be exploited, yet they remain fundamentally constrained by the intrinsic dimensional complexity in more challenging settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.24897v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wuzhe Xu, Jiequn Han, Rongjie Lai</dc:creator>
    </item>
    <item>
      <title>A Pontryagin Maximum Principle on the Belief Space for Continuous-Time Optimal Control with Discrete Observations</title>
      <link>https://arxiv.org/abs/2512.24916</link>
      <description>arXiv:2512.24916v1 Announce Type: new 
Abstract: We study a continuous time stochastic optimal control problem under partial observations that are available only at discrete time instants. This hybrid setting, with continuous dynamics and intermittent noisy measurements, arises in applications ranging from robotic exploration and target tracking to epidemic control. We formulate the problem on the space of beliefs (information states), treating the controller's posterior distribution of the state as the state variable for decision making. On this belief space we derive a Pontryagin maximum principle that provides necessary conditions for optimality. The analysis carefully tracks both the continuous evolution of the state between observation times and the Bayesian jump updates of the belief at observation instants.
  A key insight is a relationship between the adjoint process in our maximum principle and the gradient of the value functional on the belief space, which links the optimality conditions to the dynamic programming approach on the space of probability measures. The resulting optimality system has a prediction and update structure that is closely related to the unnormalised Zakai equation and the normalised Kushner-Stratonovich equation in nonlinear filtering.
  Building on this analysis, we design a particle based numerical scheme to approximate the coupled forward (filter) and backward (adjoint) system. The scheme uses particle filtering to represent the evolving belief and regression techniques to approximate the adjoint, which yields a practical algorithm for computing near optimal controls under partial information. The effectiveness of the approach is illustrated on both linear and nonlinear examples and highlights in particular the benefits of actively controlling the observation process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.24916v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christian Bayer, Saifeddine Ben naamia, Erik von Schwerin, Raul Tempone</dc:creator>
    </item>
    <item>
      <title>Strengthening Dual Bounds for Multicommodity Capacitated Network Design with Unsplittable Flow Constraints</title>
      <link>https://arxiv.org/abs/2512.25018</link>
      <description>arXiv:2512.25018v1 Announce Type: new 
Abstract: Multicommodity capacitated network design (MCND) models can be used to optimize the consolidation of shipments within e-commerce fulfillment networks. In practice, fulfillment networks require that shipments with the same origin and destination follow the same transfer path. This unsplittable flow requirement complicates the MCND problem, requiring integer programming (IP) formulations in which binary variables replace continuous flow variables. To enhance the solvability of this variant of the MCND problem for large-scale logistics networks, this work focuses on strengthening dual bounds. We investigate the polyhedra of arc-set relaxations, and we introduce two new classes of valid inequalities that can be implemented within solution approaches. We develop one approach that dynamically adds valid inequalities to the root node of a reformulation of the MCND IP with additional valid metric inequalities. We show the effectiveness of our ideas with a comprehensive computational study using path-based fulfillment instances, constructed from data provided by a large U.S.-based e-commerce company, and the well-known arc-based Canad instances. Experiments show that our best solution approach for a practical path-based model reduces the IP gap by an average of 26.5% and 22.5% for the two largest instance groups, compared to solving the reformulation alone, demonstrating its effectiveness in improving the dual bound. In addition, experiments using only the arc-based relaxation highlight the strength of our new valid inequalities relative to the linear programming relaxation (LPR), yielding an IP-gap reduction of more than 85%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.25018v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lacy M. Greening, Santanu S. Dey, Alan L. Erera</dc:creator>
    </item>
    <item>
      <title>Assured Autonomy: How Operations Research Powers and Orchestrates Generative AI Systems</title>
      <link>https://arxiv.org/abs/2512.23978</link>
      <description>arXiv:2512.23978v1 Announce Type: cross 
Abstract: Generative artificial intelligence (GenAI) is shifting from conversational assistants toward agentic systems -- autonomous decision-making systems that sense, decide, and act within operational workflows. This shift creates an autonomy paradox: as GenAI systems are granted greater operational autonomy, they should, by design, embody more formal structure, more explicit constraints, and stronger tail-risk discipline. We argue stochastic generative models can be fragile in operational domains unless paired with mechanisms that provide verifiable feasibility, robustness to distribution shift, and stress testing under high-consequence scenarios. To address this challenge, we develop a conceptual framework for assured autonomy grounded in operations research (OR), built on two complementary approaches. First, flow-based generative models frame generation as deterministic transport characterized by an ordinary differential equation, enabling auditability, constraint-aware generation, and connections to optimal transport, robust optimization, and sequential decision control. Second, operational safety is formulated through an adversarial robustness lens: decision rules are evaluated against worst-case perturbations within uncertainty or ambiguity sets, making unmodeled risks part of the design. This framework clarifies how increasing autonomy shifts OR's role from solver to guardrail to system architect, with responsibility for control logic, incentive protocols, monitoring regimes, and safety boundaries. These elements define a research agenda for assured autonomy in safety-critical, reliability-sensitive operational domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.23978v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tinglong Dai, David Simchi-Levi, Michelle Xiao Wu, Yao Xie</dc:creator>
    </item>
    <item>
      <title>Time-varying Mixing Matrix Design for Energy-efficient Decentralized Federated Learning</title>
      <link>https://arxiv.org/abs/2512.24069</link>
      <description>arXiv:2512.24069v1 Announce Type: cross 
Abstract: We consider the design of mixing matrices to minimize the operation cost for decentralized federated learning (DFL) in wireless networks, with focus on minimizing the maximum per-node energy consumption. As a critical hyperparameter for DFL, the mixing matrix controls both the convergence rate and the needs of agent-to-agent communications, and has thus been studied extensively. However, existing designs mostly focused on minimizing the communication time, leaving open the minimization of per-node energy consumption that is critical for energy-constrained devices. This work addresses this gap through a theoretically-justified solution for mixing matrix design that aims at minimizing the maximum per-node energy consumption until convergence, while taking into account the broadcast nature of wireless communications. Based on a novel convergence theorem that allows arbitrarily time-varying mixing matrices, we propose a multi-phase design framework that activates time-varying communication topologies under optimized budgets to trade off the per-iteration energy consumption and the convergence rate while balancing the energy consumption across nodes. Our evaluations based on real data have validated the efficacy of the proposed solution in combining the low energy consumption of sparse mixing matrices and the fast convergence of dense mixing matrices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.24069v1</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>math.OC</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xusheng Zhang, Tuan Nguyen, Ting He</dc:creator>
    </item>
    <item>
      <title>Variational Quantum Brushes</title>
      <link>https://arxiv.org/abs/2512.24173</link>
      <description>arXiv:2512.24173v1 Announce Type: cross 
Abstract: Quantum brushes are computational arts software introduced by Ferreira et al (2025) that leverage quantum behavior to generate novel artistic effects. In this outreach paper, we introduce the mathematical framework and describe the implementation of two quantum brushes based on variational quantum algorithms, Steerable and Chemical. While Steerable uses quantum geometric control theory to merge two works of art, Chemical mimics variational eigensolvers for estimating molecular ground energies to evolve colors on an underlying canvas. The implementation of both brushes is available open-source at https://github.com/moth-quantum/QuantumBrush and is fully compatible with the original quantum brushes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.24173v1</guid>
      <category>quant-ph</category>
      <category>cs.GR</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jui-Ting Lu, Henrique Ennes, Chih-Kang Huang, Ali Abbassi</dc:creator>
    </item>
    <item>
      <title>An Equivalence Result on the Order of Differentiability in Frobenius' Theorem</title>
      <link>https://arxiv.org/abs/2512.24218</link>
      <description>arXiv:2512.24218v1 Announce Type: cross 
Abstract: This paper examines the simplest case of total differential equations that appears in the theory of foliation structures, without imposing the smoothness assumptions. This leads to a peculiar asymmetry in the differentiability of solutions. To resolve this asymmetry, this paper focuses on the differentiability of the integral manifold. When the system is locally Lipschitz, a solution is ensured to be only locally Lipschitz, but the integral manifolds must be $C^1$. When the system is $C^k$, we can only ensure the existence of a $C^k$ solution, but the integral manifolds must be $C^{k+1}$. In addition, we see a counterexample in which the system is $C^1$, but there is no $C^2$ solution. Moreover, we characterize a minimizer of an optimization problem whose objective function is a quasi-convex solution to a total differential equation. In this connection, we examine two necessary and sufficient conditions for the system in which any solution is quasi-convex.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.24218v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuhki Hosoya</dc:creator>
    </item>
    <item>
      <title>Deep Reinforcement Learning for Solving the Fleet Size and Mix Vehicle Routing Problem</title>
      <link>https://arxiv.org/abs/2512.24251</link>
      <description>arXiv:2512.24251v1 Announce Type: cross 
Abstract: The Fleet Size and Mix Vehicle Routing Problem (FSMVRP) is a prominent variant of the Vehicle Routing Problem (VRP), extensively studied in operations research and computational science. FSMVRP requires simultaneous decisions on fleet composition and routing, making it highly applicable to real-world scenarios such as short-term vehicle rental and on-demand logistics. However, these requirements also increase the complexity of FSMVRP, posing significant challenges, particularly in large-scale and time-constrained environments. In this paper, we propose a deep reinforcement learning (DRL)-based approach for solving FSMVRP, capable of generating near-optimal solutions within a few seconds. Specifically, we formulate the problem as a Markov Decision Process (MDP) and develop a novel policy network, termed FRIPN, that seamlessly integrates fleet composition and routing decisions. Our method incorporates specialized input embeddings designed for distinctdecision objectives, including a remaining graph embedding to facilitate effective vehicle employment decisions. Comprehensive experiments are conducted on both randomly generated instances and benchmark datasets. The experimental results demonstrate that our method exhibits notable advantages in terms of computational efficiency and scalability, particularly in large-scale and time-constrained scenarios. These strengths highlight the potential of our approach for practical applications and provide valuable inspiration for extending DRL-based techniques to other variants of VRP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.24251v1</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pengfu Wan, Jiawei Chen, Gangyan Xu</dc:creator>
    </item>
    <item>
      <title>Achieving high-performance polarization-independent nonreciprocal thermal radiation with pattern-free heterostructures</title>
      <link>https://arxiv.org/abs/2512.24398</link>
      <description>arXiv:2512.24398v1 Announce Type: cross 
Abstract: Many advanced energy harvesting technologies rely on advanced control of thermal emission. Recently, it has been shown that the emissivity and absorptivity of thermal emitters can be controlled independently in nonreciprocal emitters. While significant progress has been made in engineering these nonreciprocal thermal emitters, realizing a highly efficient, pattern-free emitter capable of supporting dual-polarization nonreciprocal emission remains a challenging task. Existing solutions are largely based on metamaterials and exhibit polarization-dependent behavior. This work proposes pattern-free multilayer heterostructures combining magneto-optical and magnetic Weyl semimetal materials and systematically evaluates their nonreciprocal emission performance for p- and s-polarized waves. The findings show that omnidirectional polarization-independent nonreciprocity can be achieved utilizing multilayer structures with different magnetization directions that do not follow simple vector summation. To further enhance the performance, Pareto optimization is employed to tune the key design parameters, enabling the maximization of nonreciprocal thermal emission in a given wavelength range. This approach offers a versatile strategy for designing high-performance thermal emitters tailored for multi-objective optical functionalities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.24398v1</guid>
      <category>physics.optics</category>
      <category>cond-mat.mtrl-sci</category>
      <category>math.OC</category>
      <category>physics.app-ph</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bach Do, Bardia Nabavi, Sina Jafari Ghalekohneh, Taiwo Adebiyi, Bo Zhao, Ruda Zhang</dc:creator>
    </item>
    <item>
      <title>Dimension-free estimators of gradients of functions with(out) non-independent variables</title>
      <link>https://arxiv.org/abs/2512.24527</link>
      <description>arXiv:2512.24527v1 Announce Type: cross 
Abstract: This study proposes a unified stochastic framework for approximating and computing the gradient of every smooth function evaluated at non-independent variables, using $\ell_p$-spherical distributions on $\R^d$ with $d, p\geq 1$. The upper-bounds of the bias of the gradient surrogates do not suffer from the curse of dimensionality for any $p\geq 1$. Also, the mean squared errors (MSEs) of the gradient estimators are bounded by $K_0 N^{-1} d$ for any $p \in [1, 2]$, and by $K_1 N^{-1} d^{2/p}$ when $2 \leq p \ll d$ with $N$ the sample size and $K_0, K_1$ some constants. Taking $\max\left\{2, \log(d) \right\} &lt; p \ll d$ allows for achieving dimension-free upper-bounds of MSEs. In the case where $d\ll p&lt; +\infty$, the upper-bound $K_2 N^{-1} d^{2-2/p}/ (d+2)^2$ is reached with $K_2$ a constant. Such results lead to dimension-free MSEs of the proposed estimators, which boil down to estimators of the traditional gradient when the variables are independent. Numerical comparisons show the efficiency of the proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.24527v1</guid>
      <category>math.ST</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Matieyendou Lamboni</dc:creator>
    </item>
    <item>
      <title>OCP-LS: An Efficient Algorithm for Visual Localization</title>
      <link>https://arxiv.org/abs/2512.24552</link>
      <description>arXiv:2512.24552v1 Announce Type: cross 
Abstract: This paper proposes a novel second-order optimization algorithm. It aims to address large-scale optimization problems in deep learning because it incorporates the OCP method and appropriately approximating the diagonal elements of the Hessian matrix. Extensive experiments on multiple standard visual localization benchmarks demonstrate the significant superiority of the proposed method. Compared with conventional optimiza tion algorithms, our framework achieves competitive localization accuracy while exhibiting faster convergence, enhanced training stability, and improved robustness to noise interference.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.24552v1</guid>
      <category>cs.CV</category>
      <category>math.OC</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jindi Zhong, Hongxia Wang, Huanshui Zhang</dc:creator>
    </item>
    <item>
      <title>Dynamic response phenotypes and model discrimination in systems and synthetic biology</title>
      <link>https://arxiv.org/abs/2512.24945</link>
      <description>arXiv:2512.24945v1 Announce Type: cross 
Abstract: Biological systems encode function not primarily in steady states, but in the structure of transient responses elicited by time-varying stimuli. Overshoots, biphasic dynamics, adaptation kinetics, fold-change detection, entrainment, and cumulative exposure effects often determine phenotypic outcomes, yet are poorly captured by classical steady-state or dose-response analyses. This paper develops an input-output perspective on such "dynamic phenotypes," emphasizing how qualitative features of transient behavior constrain underlying network architectures independently of detailed parameter values. A central theme is the role of sign structure and interconnection logic, particularly the contrast between monotone systems and architectures containing antagonistic pathways. We show how incoherent feedforward (IFF) motifs provide a simple and recurrent mechanism for generating non-monotonic and adaptive responses across multiple levels of biological organization, from molecular signaling to immune regulation and population dynamics. Conversely, monotonicity imposes sharp impossibility results that can be used to falsify entire classes of models from transient data alone. Beyond step inputs, we highlight how periodic forcing, ramps, and integral-type readouts such as cumulative dose responses offer powerful experimental probes that reveal otherwise hidden structure, separate competing motifs, and expose invariances such as fold-change detection. Throughout, we illustrate how control-theoretic concepts, including monotonicity, equivariance, and input-output analysis, can be used not as engineering metaphors, but as precise mathematical tools for biological model discrimination. Thus we argue for a shift in emphasis from asymptotic behavior to transient and input-driven dynamics as a primary lens for understanding, testing, and reverse-engineering biological networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.24945v1</guid>
      <category>q-bio.QM</category>
      <category>math.OC</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eduardo D. Sontag</dc:creator>
    </item>
    <item>
      <title>Basic Inequalities for First-Order Optimization with Applications to Statistical Risk Analysis</title>
      <link>https://arxiv.org/abs/2512.24999</link>
      <description>arXiv:2512.24999v1 Announce Type: cross 
Abstract: We introduce \textit{basic inequalities} for first-order iterative optimization algorithms, forming a simple and versatile framework that connects implicit and explicit regularization. While related inequalities appear in the literature, we isolate and highlight a specific form and develop it as a well-rounded tool for statistical analysis. Let $f$ denote the objective function to be optimized. Given a first-order iterative algorithm initialized at $\theta_0$ with current iterate $\theta_T$, the basic inequality upper bounds $f(\theta_T)-f(z)$ for any reference point $z$ in terms of the accumulated step sizes and the distances between $\theta_0$, $\theta_T$, and $z$. The bound translates the number of iterations into an effective regularization coefficient in the loss function. We demonstrate this framework through analyses of training dynamics and prediction risk bounds. In addition to revisiting and refining known results on gradient descent, we provide new results for mirror descent with Bregman divergence projection, for generalized linear models trained by gradient descent and exponentiated gradient descent, and for randomized predictors. We illustrate and supplement these theoretical findings with experiments on generalized linear models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.24999v1</guid>
      <category>math.ST</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Seunghoon Paik, Kangjie Zhou, Matus Telgarsky, Ryan J. Tibshirani</dc:creator>
    </item>
    <item>
      <title>Progressive Optimal Path Sampling for Closed-Loop Optimal Control Design with Deep Neural Networks</title>
      <link>https://arxiv.org/abs/2209.04078</link>
      <description>arXiv:2209.04078v3 Announce Type: replace 
Abstract: Closed-loop optimal control design for high-dimensional nonlinear systems has been a long-standing challenge. Traditional methods, such as solving the associated Hamilton-Jacobi-Bellman equation, suffer from the curse of dimensionality. Recent literature proposed a new promising approach based on supervised learning, by leveraging powerful open-loop optimal control solvers to generate training data and neural networks as efficient high-dimensional function approximators to fit the closed-loop optimal control. This approach successfully handles certain high-dimensional optimal control problems but still performs poorly on more challenging problems. One of the crucial reasons for the failure is the so-called distribution mismatch phenomenon brought by the controlled dynamics. In this paper, we investigate this phenomenon and propose the Progressive Optimal Path Sampling (POPS) method to mitigate this problem. We theoretically prove that this enhanced sampling strategy outperforms both the vanilla approach and the widely used Dataset Aggregation (DAgger) method on the classical linear-quadratic regulator by a factor proportional to the total time duration. We further numerically demonstrate that the proposed sampling strategy significantly improves the performance on tested control problems, including the optimal landing problem of a quadrotor and the optimal reaching problem of a 7 DoF manipulator.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.04078v3</guid>
      <category>math.OC</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.4208/jml.250213</arxiv:DOI>
      <arxiv:journal_reference>Journal of Machine Learning, 4(4), 223-263 (2025)</arxiv:journal_reference>
      <dc:creator>Xuanxi Zhang, Jihao Long, Wei Hu, Weinan E, Jiequn Han</dc:creator>
    </item>
    <item>
      <title>Time-Domain Moment Matching for Second-Order Systems</title>
      <link>https://arxiv.org/abs/2305.01254</link>
      <description>arXiv:2305.01254v2 Announce Type: replace 
Abstract: The paper develops a second-order time-domain moment matching framework for the structure-preserving model reduction of second-order dynamical systems of high dimension, avoiding the first-order double-sized equivalent system. The moments of a second-order system are defined based on the solutions of second-order Sylvester equations, leading to families of parameterized second-order reduced models that match the moments of an original second-order system at selected interpolation points. Furthermore, a two-sided moment matching problem is addressed, providing a unique second-order reduced system that matches two distinct sets of interpolation points. We also construct the reduced second-order systems that match the moments of both the zero and first-order derivatives of the transfer function of the original second-order system. Finally, the Loewner framework is extended to second-order systems, where two parameterized families of models are presented that retain the second-order structure and interpolate sets of tangential data. The theory of the second-order time-domain moment matching is illustrated on vibrating systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.01254v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaodong Cheng, Tudor C. Ionescu</dc:creator>
    </item>
    <item>
      <title>GeNIOS: an (almost) second-order operator-splitting solver for large-scale convex optimization</title>
      <link>https://arxiv.org/abs/2310.08333</link>
      <description>arXiv:2310.08333v2 Announce Type: replace 
Abstract: We introduce the GEneralized Newton Inexact Operator Splitting solver (GeNIOS) for large-scale convex optimization. GeNIOS speeds up ADMM by approximately solving approximate subproblems: it uses a second-order approximation to the most challenging ADMM subproblem and solves it inexactly with a fast randomized solver. Despite these approximations, GeNIOS retains the convergence rate of classic ADMM and can detect primal and dual infeasibility from the algorithm iterates. At each iteration, the algorithm solves a positive-definite linear system that arises from a second-order approximation of the first subproblem and computes an approximate proximal operator. GeNIOS solves the linear system using an indirect solver with a randomized preconditioner, making it particularly useful for large-scale problems with dense data. Our high-performance open-source implementation in Julia allows users to specify convex optimization problems directly (with or without conic reformulation) and allows extensive customization. We illustrate GeNIOS's performance on a variety of problem types. Notably, GeNIOS is up to ten times faster than existing solvers on large-scale, dense problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.08333v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Theo Diamandis, Zachary Frangella, Shipu Zhao, Bartolomeo Stellato, Madeleine Udell</dc:creator>
    </item>
    <item>
      <title>A Rank-Dependent Theory for Decision under Risk and Ambiguity</title>
      <link>https://arxiv.org/abs/2312.05977</link>
      <description>arXiv:2312.05977v3 Announce Type: replace 
Abstract: This paper axiomatizes, in a two-stage setup, a new theory for decision under risk and ambiguity. The axiomatized preference relation $\succeq$ on the space $\tilde{V}$ of random variables induces an ambiguity index $c$ on the space $\Delta$ of probabilities, a probability weighting function $\psi$, generating the measure $\nu_{\psi}$ by transforming an objective probability measure, and a utility function $\phi$, such that, for all $\tilde{v},\tilde{u}\in\tilde{V}$, \begin{align*} \tilde{v}\succeq\tilde{u} \Leftrightarrow \min_{Q \in \Delta} \left\{\mathbb{E}_Q\left[\int\phi\left(\tilde{v}^{\centerdot}\right)\,\mathrm{d}\nu_{\psi}\right]+c(Q)\right\} \geq \min_{Q \in \Delta} \left\{\mathbb{E}_Q\left[\int\phi\left(\tilde{u}^{\centerdot}\right)\,\mathrm{d}\nu_{\psi}\right]+c(Q)\right\}. \end{align*} Our theory extends the rank-dependent utility model of Quiggin (1982) for decision under risk to risk and ambiguity, reduces to the variational preferences model when $\psi$ is the identity, and is dual to variational preferences when $\phi$ is affine in the same way as the theory of Yaari (1987) is dual to expected utility. As a special case, we obtain a preference axiomatization of a decision theory that is a rank-dependent generalization of the popular maxmin expected utility theory. We characterize ambiguity aversion in our theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.05977v3</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>q-fin.RM</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Roger J. A. Laeven, Mitja Stadje</dc:creator>
    </item>
    <item>
      <title>Approximate Controllability of Linear Fractional Impulsive Evolution Equations in Hilbert Spaces</title>
      <link>https://arxiv.org/abs/2406.15114</link>
      <description>arXiv:2406.15114v3 Announce Type: replace 
Abstract: This paper investigates the approximate controllability of linear fractional impulsive evolution equations in Hilbert spaces. The system under consideration involves the Caputo fractional derivative of order $0&lt;\alpha\leq 1$, a closed linear operator generating a strongly continuous semigroup, and instantaneous state jumps governed by bounded linear impulse operators. We first derive an explicit representation of the mild solution by combining fractional solution operators with impulsive operators. Using this representation, we characterize the approximate controllability of the system through a necessary and sufficient condition expressed in terms of the convergence of an associated family of impulsive resolvent operators. This resolvent condition extends the classical criterion for approximate controllability to the fractional impulsive setting. To illustrate the applicability of our theoretical results, a concrete example is provided. The analysis presented here bridges the gap between the well-established theory for integer-order impulsive systems and the more complex fractional case, highlighting the distinct challenges and solutions arising from the interplay of fractional dynamics and impulsive effects.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15114v3</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Javad A. Asadzade, Nazim I. Mahmudov</dc:creator>
    </item>
    <item>
      <title>Fej\'er* monotonicity in optimization algorithms</title>
      <link>https://arxiv.org/abs/2410.08331</link>
      <description>arXiv:2410.08331v2 Announce Type: replace 
Abstract: Fej\'er monotonicity is a well-established property often observed in sequences generated by optimization algorithms. In this paper, we study an extension of this property, called Fej\'er* monotonicity, which was initially proposed in [SIAM J. Optim., 34(3), 2535-2556 (2024)]. We discuss and explore its behavior within Hilbert spaces as a tool for optimization algorithms. Additionally, we investigate weak and strong convergence properties of this novel concept. Through illustrative examples and insightful results, we contrast Fej\'er* with weaker notions of quasi-Fej\'er-type monotonicity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08331v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Roger Behling, Yunier Bello-Cruz, Alfredo Noel Iusem, Ademir Alves Ribeiro, Luiz-Rafael Santos</dc:creator>
    </item>
    <item>
      <title>A Gauge Set Framework for Flexible Robustness Design</title>
      <link>https://arxiv.org/abs/2501.14989</link>
      <description>arXiv:2501.14989v3 Announce Type: replace 
Abstract: This paper proposes a unified framework for designing robustness in optimization under uncertainty using gauge sets, convex sets that generalize distance and capture how distributions may deviate from a nominal reference. Representing robustness through a gauge set reweighting formulation brings many classical robustness paradigms under a single convex-analytic perspective. The corresponding dual problem, the upper approximator regularization model, reveals a direct connection between distributional perturbations and objective regularization via polar gauge sets. This framework decouples the design of the nominal distribution, distance metric, and reformulation method, components often entangled in classical approaches, thus enabling modular and composable robustness modeling. We further provide a gauge set algebra toolkit that supports intersection, summation, convex combination, and composition, enabling complex ambiguity structures to be assembled from simpler components. For computational tractability under continuously supported uncertainty, we introduce two general finite-dimensional reformulation methods. The functional parameterization approach guarantees any prescribed gauge-based robustness through flexible selection of function bases, while the envelope representation approach yields exact reformulations under empirical nominal distributions and is asymptotically exact for arbitrary nominal choices. A detailed case study demonstrates how the framework accommodates diverse robustness requirements while admitting multiple tractable reformulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14989v3</guid>
      <category>math.OC</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ningji Wei, Xian Yu, Peter Zhang</dc:creator>
    </item>
    <item>
      <title>Constrained Reinforcement Learning for the Dynamic Inventory Routing Problem under Stochastic Supply and Demand</title>
      <link>https://arxiv.org/abs/2503.05276</link>
      <description>arXiv:2503.05276v2 Announce Type: replace 
Abstract: Green hydrogen has multiple use cases and is produced from renewable energy, such as solar or wind energy. It can be stored in large quantities, decoupling renewable energy generation from its use, and is therefore considered essential for achieving a climate-neutral economy. The intermittency of renewable energy generation and the stochastic nature of demand are, however, challenging factors for the dynamic planning of hydrogen storage and transportation. This holds particularly in the early-adoption phase when hydrogen distribution occurs through vehicle-based networks. We therefore address the Dynamic Inventory Routing Problem (DIRP) under stochastic supply and demand with direct deliveries for the vehicle-based distribution of hydrogen. To solve this problem, we propose a Constrained Reinforcement Learning (CRL) framework that integrates constraints into the learning process and incorporates parameterized post-decision state value predictions. Additionally, we introduce Lookahead-based CRL (LCRL), which improves decision-making over a multi-period horizon to enhance short-term planning while maintaining the value predictions. Our computational experiments demonstrate the efficacy of CRL and LCRL across diverse instances. Our learning methods provide near-optimal solutions on small scale instances that are solved via value iteration. Furthermore, both methods outperform typical deep learning approaches such as Proximal Policy Optimization, as well as classical inventory heuristics, such as (s,S)-policy-based and Power-of-Two-based heuristics. Furthermore, LCRL achieves a 10% improvement over CRL on average, albeit with higher computational requirements. Analyses of optimal replenishment policies reveal that accounting for stochastic supply and demand influences these policies, showing the importance of our addition to the DIRP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.05276v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Umur Hasturk, Albert H. Schrotenboer, Kees Jan Roodbergen, Evrim Ursavas</dc:creator>
    </item>
    <item>
      <title>Reachability for multiagent control systems via Lyapunov functions</title>
      <link>https://arxiv.org/abs/2503.09179</link>
      <description>arXiv:2503.09179v2 Announce Type: replace 
Abstract: This paper concerns the problem of reachability of a given state for a multiagent control system in $\mathbb{R}^d$. In such a system, at every time each agent can choose his/her velocity which depends both on his/her position and on the position of the whole crowd of agents (modeled by a probability measure on $ \mathbb{R}^d$). The main contribution of the paper is to study the above reachability problem with a given rate of attainability through a Lyapunov method adapted to the Wasserstein space of probability measures. As a byproduct we obtain a new comparison result for viscosity solutions of Hamilton Jacobi equations in the Wasserstein space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09179v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.3934/cpaa.2025100</arxiv:DOI>
      <arxiv:journal_reference>Communications on Pure and Applied Analysis, vol. 26 (2026)</arxiv:journal_reference>
      <dc:creator>Giulia Cavagnari, Marc Quincampoix</dc:creator>
    </item>
    <item>
      <title>Representation Theorems for Convex Expectations and Semigroups on Path Space</title>
      <link>https://arxiv.org/abs/2503.10572</link>
      <description>arXiv:2503.10572v2 Announce Type: replace 
Abstract: The objective of this paper is to investigate the connection between penalty functions from stochastic optimal control, convex semigroups from analysis and convex expectations from probability theory. Our main result provides a one-to-one relation between these objects. As an application, we use the representation via penality functions and duality arguments to show that convex expectations are determined by their finite dimensional distributions. To illustrate this structural result, we show that Hu and Peng's axiomatic description of $G$-L\'evy processes in terms of finite dimensional distributions extends uniquely to the control approach introduced by Neufeld and Nutz. Finally, we show that convex expectations with a Markovian structure are fully determined by their one-dimensional distributions, which give rise to a classical semigroup on the state space. As an application of this result, we establish a Laplace principle for entropic risk measures associated to controlled diffusions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.10572v2</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David Criens, Michael Kupper</dc:creator>
    </item>
    <item>
      <title>Optimization over Trained (and Sparse) Neural Networks: A Surrogate within a Surrogate</title>
      <link>https://arxiv.org/abs/2505.01985</link>
      <description>arXiv:2505.01985v2 Announce Type: replace 
Abstract: In constraint learning, we use a neural network as a surrogate for part of the constraints or of the objective function of an optimization model. However, the tractability of the resulting model is heavily influenced by the size of the neural network used as a surrogate. One way to obtain a more tractable surrogate is by pruning the neural network first. In this work, we consider how to approach the setting in which the neural network is actually a given: how can we solve an optimization model embedding a large and predetermined neural network? We propose surrogating the neural network itself by pruning it, which leads to a sparse and more tractable optimization model, for which we hope to still obtain good solutions with respect to the original neural network. For network verification and function maximization models, that indeed leads to better solutions within a time limit, especially -- and surprisingly -- if we skip the standard retraining step known as finetuning. Hence, a pruned network with worse inference for lack of finetuning can be a better surrogate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01985v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hung Pham, Aiden Ren, Ibrahim Tahir, Jiatai Tong, Thiago Serra</dc:creator>
    </item>
    <item>
      <title>Generic Frameworks for Distributed Functional Optimization and Learning over Time-Varying Networks</title>
      <link>https://arxiv.org/abs/2509.17554</link>
      <description>arXiv:2509.17554v2 Announce Type: replace 
Abstract: In this paper, we establish a distributed functional optimization (DFO) theory over time-varying networks. The vast majority of existing distributed optimization theories are developed based on Euclidean decision variables. However, for many scenarios in machine learning and statistical learning, such as reproducing kernel spaces or probability measure spaces that use functions or probability measures as fundamental variables, the development of existing distributed optimization theories exhibit obvious theoretical and technical deficiencies. This paper addresses these issues by developing a novel general DFO theory on Banach spaces, allowing functional learning problems in the aforementioned scenarios to be incorporated into our framework for resolution. We study both convex and nonconvex DFO problems and rigorously establish a comprehensive convergence theory of distributed functional mirror descent and distributed functional gradient descent algorithm to solve them. Satisfactory convergence rates are fully derived. The work has provided generic analyzing frameworks for DFO. The established theory is shown to have crucial application value in the kernel-based distributed learning theory over networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.17554v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhan Yu, Zhongjie Shi, Deming Yuan, Daniel W. C. Ho</dc:creator>
    </item>
    <item>
      <title>Non-Attainment of Minima in Non-Polyhedral Conic Optimization: A Robust SOCP Example</title>
      <link>https://arxiv.org/abs/2510.00318</link>
      <description>arXiv:2510.00318v2 Announce Type: replace 
Abstract: A fundamental theorem of linear programming states that a feasible linear program is solvable if and only if its objective function is copositive with respect to the recession cone of its feasible set. This paper demonstrates that this crucial guarantee does not extend to Second-Order Cone Programs (SOCPs), a workhorse model in robust and convex optimization. We construct and analyze a rigorous counterexample derived from a robust linear optimization problem with ellipsoidal uncertainty. The resulting SOCP possesses a non-empty feasible set, a bounded objective, and an objective function that is copositive on its recession cone. Despite satisfying these classical conditions for solvability, the problem admits no optimal solution; its infimum is finite but unattainable. We trace this pathology directly to the non-polyhedral geometry of the second-order cone, which causes the image of the feasible set under the linear objective to be non-closed. We interpret the example explicitly within the context of robust optimization, discuss its significant practical implications for modeling and computation, and propose effective mitigation strategies via polyhedral approximation or regularization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.00318v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Vinh Nguyen</dc:creator>
    </item>
    <item>
      <title>Value of Multi-pursuer Single-evader Pursuit-evasion Game with Terminal Cost of Evader's Position: Relaxation of Convexity Condition</title>
      <link>https://arxiv.org/abs/2510.27271</link>
      <description>arXiv:2510.27271v2 Announce Type: replace 
Abstract: In this study, we consider a multi-pursuer single-evader quantitative pursuit-evasion game with payoff function that includes only the terminal cost. The terminal cost is a function related only to the terminal position of the evader. This problem has been extensively studied in target defense games. Here, we prove that a candidate for the value function generated by geometric method is the viscosity solution of the corresponding Hamilton-Jacobi-Isaacs partial differential equation (HJI PDE) Dirichlet problem. Therefore, the value function of the game at each point can be computed by a mathematical program. In our work, the convexity of the terminal cost or the target is not required. The terminal cost only needs to be locally Lipschitz continuous. The cases in which the terminal costs or the targets are not convex are covered. Therefore, our result is more universal than those of previous studies, and the complexity of the proof is improved. We also discuss the optimal strategies in this game and present an intuitive explanation of this value function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.27271v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weiwen Huang, Li Liang, Ningsheng Xu, Fang Deng</dc:creator>
    </item>
    <item>
      <title>Improving Directions in Mixed Integer Bilevel Linear Optimization</title>
      <link>https://arxiv.org/abs/2511.03566</link>
      <description>arXiv:2511.03566v3 Announce Type: replace 
Abstract: We consider the central role of improving directions in solution methods for mixed integer bilevel linear optimization problems (MIBLPs). Current state-of-the-art methods for solving MIBLPs employ the branch-and-cut framework originally developed for solving mixed integer linear optimization problems. This approach relies on oracles for two kinds of subproblems: those for checking whether a candidate pair of leader's and follower's decisions is bilevel feasible, and those required for generating valid inequalities. Typically, these two types of oracles are managed separately, but in this work, we explore their close connection and propose a solution framework based on solving a single type of subproblem: determining whether there exists a so-called improving feasible direction for the follower's problem. Solution of this subproblem yields information that can be used both to check feasibility and to generate strong valid inequalities. Building on prior works, we expose the foundational role of improving directions in enforcing the follower's optimality condition and extend a previously known hierarchy of optimality-based relaxations to the mixed-integer setting, showing that the associated relaxed feasible regions coincide exactly with the closure associated with intersection cuts derived from improving directions. Numerical results with an implementation using a modified version of the open source solver MibS show that this approach can yield practical improvements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.03566v3</guid>
      <category>math.OC</category>
      <category>cs.MS</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Federico Battista, Ted K. Ralphs</dc:creator>
    </item>
    <item>
      <title>Avoidance of non-strict saddle points by blow-up</title>
      <link>https://arxiv.org/abs/2511.23268</link>
      <description>arXiv:2511.23268v2 Announce Type: replace 
Abstract: It is an old idea to use gradient flows or time-discretized variants thereof as methods for solving minimization problems. In some applications, for example in machine learning contexts, it is important to know that for generic initial data, gradient flow trajectories do not get stuck at saddle points. There are classical results concerned with the non-degenerate situation. But if the Hessian of the objective function has a non-trivial kernel at the critical point, then these results are inconclusive in general. In this paper, we show how relevant information can be extracted by ``blowing up'' the objective function around the non-strict saddle point, i.e., by a suitable non-linear rescaling that makes the higher order geometry visible.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.23268v2</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>El Mehdi Achour, Umberto L. Hryniewicz, Michael Westdickenberg</dc:creator>
    </item>
    <item>
      <title>Towards Real Time Control of Water Engineering with Nonlinear Hyperbolic Partial Differential Equations</title>
      <link>https://arxiv.org/abs/2512.14387</link>
      <description>arXiv:2512.14387v3 Announce Type: replace 
Abstract: This paper examines aspirational requirements for software addressing mixed-integer optimization problems constrained by the nonlinear Shallow Water partial differential equations (PDEs), motivated by applications such as river-flow management in hydropower cascades. Realistic deployment of such software would require the simultaneous treatment of nonlinear and potentially non-smooth PDE dynamics, limited theoretical guarantees on the existence and regularity of control-to-state mappings under varying boundary conditions, and computational performance compatible with operational decision-making. In addition, practical settings motivate consideration of uncertainty arising from forecasts of demand, inflows, and environmental conditions. At present, the theoretical foundations, numerical optimization methods, and large-scale scientific computing tools required to address these challenges in a unified and tractable manner remain the subject of ongoing research across the associated research communities. Rather than proposing a complete solution, this work uses the problem as a case study to identify and organize the mathematical, algorithmic, and computational components that would be necessary for its realization. The resulting framework highlights open challenges and intermediate research directions, and may inform both more circumscribed related problems and the design of future large-scale collaborative efforts aimed at addressing such objectives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.14387v3</guid>
      <category>math.OC</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fabio DiFonzo, Michael Holst, Morteza Kimiaei, Vyacheslav Kungurtsev, Songqiang Qiu</dc:creator>
    </item>
    <item>
      <title>Deep Reinforcement Learning Optimization for Uncertain Nonlinear Systems via Event-Triggered Robust Adaptive Dynamic Programming</title>
      <link>https://arxiv.org/abs/2512.15735</link>
      <description>arXiv:2512.15735v4 Announce Type: replace 
Abstract: This work proposes a unified control architecture that couples a Reinforcement Learning (RL)-driven controller with a disturbance-rejection Extended State Observer (ESO), complemented by an Event-Triggered Mechanism (ETM) to limit unnecessary computations. The ESO is utilized to estimate the system states and the lumped disturbance in real time, forming the foundation for effective disturbance compensation. To obtain near-optimal behavior without an accurate system description, a value-iteration-based Adaptive Dynamic Programming (ADP) method is adopted for policy approximation. The inclusion of the ETM ensures that parameter updates of the learning module are executed only when the state deviation surpasses a predefined bound, thereby preventing excessive learning activity and substantially reducing computational load. A Lyapunov-oriented analysis is used to characterize the stability properties of the resulting closed-loop system. Numerical experiments further confirm that the developed approach maintains strong control performance and disturbance tolerance, while achieving a significant reduction in sampling and processing effort compared with standard time-triggered ADP schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.15735v4</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ningwei Bai, Chi Pui Chan, Qichen Yin, Tengyang Gong, Yunda Yan, Zezhi Tang</dc:creator>
    </item>
    <item>
      <title>Contingency Model-based Control (CMC) for Communicationless Cooperative Collision Avoidance in Robot Swarms</title>
      <link>https://arxiv.org/abs/2512.20391</link>
      <description>arXiv:2512.20391v3 Announce Type: replace 
Abstract: Cooperative collision avoidance between robots, or `agents,' in swarm operations remains an open challenge. Assuming a decentralized architecture, each agent is responsible for making its own decisions and choosing its control actions. Most existing approaches rely on a (wireless) communication network between (some of) the agents. In reality, however, communication is brittle. It may be affected by latency, further delays and packet losses, and transmission faults. Moreover, it is subject to adversarial attacks, such as jamming or spoofing. This paper proposes Contingency Model-based Control (CMC), a decentralized cooperative approach that does not rely on communication. Instead, the control algorithm is based on consensual rules that are designed for all agents offline, similar to traffic rules. For CMC, this includes the definition of a contingency trajectory for each robot, and perpendicular bisecting planes as collision avoidance constraints. The setup permits a full guarantee of recursive feasibility and collision avoidance between all swarm members in closed-loop operation. CMC naturally satisfies the plug &amp; play paradigm, i.e., new robots may enter the swarm dynamically. The effectiveness of the CMC regime is demonstrated in two numerical examples, showing that the collision avoidance guarantee is intact and the robot swarm operates smoothly in a constrained environment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.20391v3</guid>
      <category>math.OC</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Georg Schildbach</dc:creator>
    </item>
    <item>
      <title>The Power of Preconditioning in Overparameterized Low-Rank Matrix Sensing</title>
      <link>https://arxiv.org/abs/2302.01186</link>
      <description>arXiv:2302.01186v4 Announce Type: replace-cross 
Abstract: We propose $\textsf{ScaledGD($\lambda$)}$, a preconditioned gradient descent method to tackle the low-rank matrix sensing problem when the true rank is unknown, and when the matrix is possibly ill-conditioned. Using overparametrized factor representations, $\textsf{ScaledGD($\lambda$)}$ starts from a small random initialization, and proceeds by gradient descent with a specific form of damped preconditioning to combat bad curvatures induced by overparameterization and ill-conditioning. At the expense of light computational overhead incurred by preconditioners, $\textsf{ScaledGD($\lambda$)}$ is remarkably robust to ill-conditioning compared to vanilla gradient descent ($\textsf{GD}$) even with overprameterization. Specifically, we show that, under the Gaussian design, $\textsf{ScaledGD($\lambda$)}$ converges to the true low-rank matrix at a constant linear rate after a small number of iterations that scales only logarithmically with respect to the condition number and the problem dimension. This significantly improves over the convergence rate of vanilla $\textsf{GD}$ which suffers from a polynomial dependency on the condition number. Our work provides evidence on the power of preconditioning in accelerating the convergence without hurting generalization in overparameterized learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.01186v4</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xingyu Xu, Yandi Shen, Yuejie Chi, Cong Ma</dc:creator>
    </item>
    <item>
      <title>Multi-fidelity Bayesian Optimization: A Review</title>
      <link>https://arxiv.org/abs/2311.13050</link>
      <description>arXiv:2311.13050v3 Announce Type: replace-cross 
Abstract: Resided at the intersection of multi-fidelity optimization (MFO) and Bayesian optimization (BO), MF BO has found a niche in solving expensive engineering design optimization problems, thanks to its advantages in incorporating physical and mathematical understandings of the problems, saving resources, addressing exploitation-exploration trade-off, considering uncertainty, and processing parallel computing. The increasing number of works dedicated to MF BO suggests the need for a comprehensive review of this advanced optimization technique. In this paper, we survey recent developments of two essential ingredients of MF BO: Gaussian process (GP) based MF surrogates and acquisition functions. We first categorize the existing MF modeling methods and MFO strategies to locate MF BO in a large family of surrogate-based optimization and MFO algorithms. We then exploit the common properties shared between the methods from each ingredient of MF BO to describe important GP-based MF surrogate models and review various acquisition functions. By doing so, we expect to provide a structured understanding of MF BO. Finally, we attempt to reveal important aspects that require further research for applications of MF BO in solving intricate yet important design optimization problems, including constrained optimization, high-dimensional optimization, optimization under uncertainty, and multi-objective optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.13050v3</guid>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.2514/1.J063812</arxiv:DOI>
      <arxiv:journal_reference>AIAA Journal 63:6 (2025) 2286-2322</arxiv:journal_reference>
      <dc:creator>Bach Do, Ruda Zhang</dc:creator>
    </item>
    <item>
      <title>The Oracle Complexity of Simplex-based Matrix Games: Linear Separability and Nash Equilibria</title>
      <link>https://arxiv.org/abs/2412.06990</link>
      <description>arXiv:2412.06990v3 Announce Type: replace-cross 
Abstract: We study the problem of solving matrix games of the form $\max_{\mathbf{w}\in\mathcal{W}}\min_{\mathbf{p}\in\Delta}\mathbf{p}^{\top}A\mathbf{w}$, where $A$ is some matrix and $\Delta$ is the probability simplex. This problem encapsulates canonical tasks such as finding a linear separator and computing Nash equilibria in zero-sum games. However, perhaps surprisingly, its inherent complexity (as formalized in the standard framework of oracle complexity [Nemirovski and Yudin, 1983]) is not well-understood. In this work, we first identify different oracle models which are implicitly used by prior algorithms, amounting to multiplying the matrix $A$ by a vector from either one or both sides. We then prove complexity lower bounds for algorithms under both access models, which in particular imply a separation between them. Specifically, we start by showing that algorithms for linear separability based on one-sided multiplications must require $\Omega(\gamma_A^{-2})$ iterations, where $\gamma_A$ is the margin, as matched by the Perceptron algorithm. We then prove that accelerated algorithms for this task, which utilize multiplications from both sides, must require $\tilde{\Omega}(\gamma_{A}^{-2/3})$ iterations, establishing the first oracle complexity barrier for such algorithms. Finally, by adapting our lower bound to $\ell_1$ geometry, we prove that computing an $\epsilon$-approximate Nash equilibrium requires $\tilde{\Omega}(\epsilon^{-2/3})$ iterations, which is an exponential improvement over the previously best-known lower bound due to Hadiji et al. [2024].</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06990v3</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guy Kornowski, Ohad Shamir</dc:creator>
    </item>
    <item>
      <title>Lagrangian Index Policy for Restless Bandits with Average Reward</title>
      <link>https://arxiv.org/abs/2412.12641</link>
      <description>arXiv:2412.12641v3 Announce Type: replace-cross 
Abstract: We study the Lagrangian Index Policy (LIP) for restless multi-armed bandits with long-run average reward. In particular, we compare the performance of LIP with the performance of the Whittle Index Policy (WIP), both heuristic policies known to be asymptotically optimal under certain natural conditions. Even though in most cases their performances are very similar, in the cases when WIP shows bad performance, LIP continues to perform very well. We then propose reinforcement learning algorithms, both tabular and NN-based, to obtain online learning schemes for LIP in the model-free setting. The proposed reinforcement learning schemes for LIP require significantly less memory than the analogous schemes for WIP. We calculate analytically the Lagrangian index for the restart model, which applies to the optimal web crawling and the minimization of the weighted age of information. We also give a new proof of asymptotic optimality in case of homogeneous arms as the number of arms goes to infinity, based on exchangeability and de Finetti's theorem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.12641v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Konstantin Avrachenkov, Vivek S. Borkar, Pratik Shah</dc:creator>
    </item>
    <item>
      <title>A Particle Algorithm for Mean-Field Variational Inference</title>
      <link>https://arxiv.org/abs/2412.20385</link>
      <description>arXiv:2412.20385v4 Announce Type: replace-cross 
Abstract: Variational inference is a fast and scalable alternative to Markov chain Monte Carlo and has been widely applied to posterior inference tasks in statistics and machine learning. A traditional approach for implementing mean-field variational inference (MFVI) is coordinate ascent variational inference (CAVI), which relies crucially on parametric assumptions on complete conditionals. We introduce a novel particle-based algorithm for MFVI, named PArticle VI (PAVI), for nonparametric mean-field approximation. We obtain non-asymptotic error bounds for our algorithm. To our knowledge, this is the first end-to-end guarantee for particle-based MFVI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.20385v4</guid>
      <category>math.ST</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qiang Du, Kaizheng Wang, Edith Zhang, Chenyang Zhong</dc:creator>
    </item>
    <item>
      <title>Algorithms for Nonlinear Mixed-Integer Location Estimation</title>
      <link>https://arxiv.org/abs/2505.12980</link>
      <description>arXiv:2505.12980v2 Announce Type: replace-cross 
Abstract: For three decades, carrier-phase observations have been used to obtain the most accurate location estimates using global navigation satellite systems (GNSS). These estimates are computed by minimizing a nonlinear mixed-integer least-squares problem. Existing algorithms linearize the problem, orthogonally project it to eliminate real variables, and then solve the integer least-square problem. There is now considerable interest in developing similar localization techniques for terrestrial and indoor settings. We show that algorithms that linearize first fail in these settings and we propose several algorithms for computing the estimates. Some of our algorithms are elimination algorithms that start by eliminating the non-linear terms in the constraints; others construct a geometric arrangement that allows us to efficiently enumerate integer solutions (in polynomial time). We focus on simplified localization problems in which the measurements are range (distance) measurements and carrier phase range measurements, with no nuisance parameters. The simplified problem allows us to focus on the core question of untangling the nonlinearity and the integer nature of some parameters. We show using simulations that the new algorithms are effective at close ranges at which the linearize-first approach fails.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12980v2</guid>
      <category>eess.SP</category>
      <category>cs.MS</category>
      <category>math.OC</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ophir Uziel, Efi Fogel, Dan Halperin, Sivan Toledo</dc:creator>
    </item>
    <item>
      <title>Some remarks on stochastic converse Lyapunov theorems</title>
      <link>https://arxiv.org/abs/2506.06053</link>
      <description>arXiv:2506.06053v2 Announce Type: replace-cross 
Abstract: In this brief note, we investigate some constructions of Lyapunov functions for stochastic discrete-time stabilizable dynamical systems, in other words, controlled Markov chains. The main question here is whether a Lyapunov function in some statistical sense exists if the respective controlled Markov chain admits a stabilizing policy. We demonstrate some constructions extending on the classical results for deterministic systems. Some limitations of the constructed Lyapunov functions for stabilization are discussed, particularly for stabilization in mean. Although results for deterministic systems are well known, the stochastic case was addressed in less detail, which the current paper remarks on. A distinguishable feature of this work is the study of stabilizers that possess computationally tractable convergence certificates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.06053v2</guid>
      <category>math.DS</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pavel Osinenko, Grigory Yaremenko</dc:creator>
    </item>
    <item>
      <title>Sampling from Gaussian Processes: A Tutorial and Applications in Global Sensitivity Analysis and Optimization</title>
      <link>https://arxiv.org/abs/2507.14746</link>
      <description>arXiv:2507.14746v2 Announce Type: replace-cross 
Abstract: High-fidelity simulations and physical experiments are essential for engineering analysis and design, yet their high cost often makes two critical tasks--global sensitivity analysis (GSA) and optimization--prohibitively expensive. This limitation motivates the common use of Gaussian processes (GPs) as proxy regression models that provide uncertainty-aware predictions from a limited number of high-quality observations. GPs naturally enable efficient sampling strategies that support informed decision-making under uncertainty by extracting information from a subset of possible functions for the model of interest. However, direct sampling from GPs is inefficient due to their infinite-dimensional nature and the high cost associated with large covariance matrix operations. Despite their popularity in machine learning and statistics communities, sampling from GPs has received little attention in the community of engineering optimization. In this paper, we present the formulation and detailed implementation of two notable sampling methods--random Fourier features and pathwise conditioning--for generating posterior samples from GPs at reduced computational cost. Alternative approaches are briefly described. Importantly, we detail how the generated samples can be applied in GSA, single-objective optimization, and multi-objective optimization. We show successful applications of these sampling methods through a series of numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.14746v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.AP</category>
      <category>stat.ML</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bach Do, Nafeezat A. Ajenifuja, Taiwo A. Adebiyi, Ruda Zhang</dc:creator>
    </item>
    <item>
      <title>Online Convex Optimization with Heavy Tails: Old Algorithms, New Regrets, and Applications</title>
      <link>https://arxiv.org/abs/2508.07473</link>
      <description>arXiv:2508.07473v2 Announce Type: replace-cross 
Abstract: In Online Convex Optimization (OCO), when the stochastic gradient has a finite variance, many algorithms provably work and guarantee a sublinear regret. However, limited results are known if the gradient estimate has a heavy tail, i.e., the stochastic gradient only admits a finite $\mathsf{p}$-th central moment for some $\mathsf{p}\in\left(1,2\right]$. Motivated by it, this work examines different old algorithms for OCO (e.g., Online Gradient Descent) in the more challenging heavy-tailed setting. Under the standard bounded domain assumption, we establish new regrets for these classical methods without any algorithmic modification. Remarkably, these regret bounds are fully optimal in all parameters (can be achieved even without knowing $\mathsf{p}$), suggesting that OCO with heavy tails can be solved effectively without any extra operation (e.g., gradient clipping). Our new results have several applications. A particularly interesting one is the first provable and optimal convergence result for nonsmooth nonconvex optimization under heavy-tailed noise without gradient clipping. Furthermore, we explore broader settings (e.g., smooth OCO) and extend our ideas to optimistic algorithms to handle different cases simultaneously.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.07473v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zijian Liu</dc:creator>
    </item>
    <item>
      <title>Leveraging High-Fidelity Digital Models and Reinforcement Learning for Mission Engineering: A Case Study of Aerial Firefighting Under Perfect Information</title>
      <link>https://arxiv.org/abs/2512.20589</link>
      <description>arXiv:2512.20589v2 Announce Type: replace-cross 
Abstract: As systems engineering (SE) objectives evolve from design and operation of monolithic systems to complex System of Systems (SoS), the discipline of Mission Engineering (ME) has emerged which is increasingly being accepted as a new line of thinking for the SE community. Moreover, mission environments are uncertain, dynamic, and mission outcomes are a direct function of how the mission assets will interact with this environment. This proves static architectures brittle and calls for analytically rigorous approaches for ME. To that end, this paper proposes an intelligent mission coordination methodology that integrates digital mission models with Reinforcement Learning (RL), that specifically addresses the need for adaptive task allocation and reconfiguration. More specifically, we are leveraging a Digital Engineering (DE) based infrastructure that is composed of a high-fidelity digital mission model and agent-based simulation; and then we formulate the mission tactics management problem as a Markov Decision Process (MDP), and employ an RL agent trained via Proximal Policy Optimization. By leveraging the simulation as a sandbox, we map the system states to actions, refining the policy based on realized mission outcomes. The utility of the RL-based intelligent mission coordinator is demonstrated through an aerial firefighting case study. Our findings indicate that the RL-based intelligent mission coordinator not only surpasses baseline performance but also significantly reduces the variability in mission performance. Thus, this study serves as a proof of concept demonstrating that DE-enabled mission simulations combined with advanced analytical tools offer a mission-agnostic framework for improving ME practice; which can be extended to more complicated fleet design and selection problems in the future from a mission-first perspective.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.20589v2</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>\.Ibrahim O\u{g}uz \c{C}etinkaya, Sajad Khodadadian, Taylan G. Topcu</dc:creator>
    </item>
  </channel>
</rss>
