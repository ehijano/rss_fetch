<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 04 Sep 2025 01:29:30 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>VOTA: Parallelizing 6G-RAN Experimentation with Virtualized Over-The-Air Workloads</title>
      <link>https://arxiv.org/abs/2509.00130</link>
      <description>arXiv:2509.00130v1 Announce Type: new 
Abstract: Testbed sharing, a practice in which different researchers concurrently develop independent use cases on top of the same testbed, is ubiquitous in wireless experimental research. Its key drawback is experimental inconvenience: one must delay experiments or tolerate compute and RF interference that harms experimental fidelity. In this paper, we propose \textbf{VOTA}, an open-source, software-only testbed scaling method that leverages real-time virtualization and frequency tuning to maximize parallel experiments while controlling interference. In a demonstration of two interference-sensitive 6G use cases -- \textit{MIMO iDFT/DFT Offloading} and \textit{O-RAN DoS Attack} -- running side-by-side on a 32-core host, we showcase VOTA capabilities: \textbf{dedicated-like} results while allowing \textbf{2.67$\times$} more sharing opportunities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.00130v1</guid>
      <category>cs.NI</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chang Liu, T. D. Khoa Le, Rahul Saini, Kishor C. Joshi, George Exarchakos</dc:creator>
    </item>
    <item>
      <title>Intelligent Spectrum Management in Satellite Communications</title>
      <link>https://arxiv.org/abs/2509.00286</link>
      <description>arXiv:2509.00286v1 Announce Type: new 
Abstract: Satellite Communication (SatCom) networks represent a fundamental pillar in modern global connectivity, facilitating reliable service and extensive coverage across a plethora of applications. The expanding demand for high-bandwidth services and the proliferation of mega satellite constellations highlight the limitations of traditional exclusive satellite spectrum allocation approaches. Cognitive Radio (CR) leading to Cognitive Satellite (CogSat) networks through Dynamic Spectrum Management (DSM), which enables the dynamic adaptability of radio equipment to environmental conditions for optimal performance, presents a promising solution for the emerging spectrum scarcity. In this survey, we explore the adaptation of intelligent DSM methodologies to SatCom, leveraging satellite network integrations. We discuss contributions and hurdles in regulations and standardizations in realizing intelligent DSM in SatCom, and deep dive into DSM techniques, which enable CogSat networks. Furthermore, we extensively evaluate and categorize state-of-the-art Artificial Intelligence (AI)/Machine Learning (ML) methods leveraged for DSM while exploring operational resilience and robustness of such integrations. In addition, performance evaluation metrics critical for adaptive resource management and system optimization in CogSat networks are thoroughly investigated. This survey also identifies open challenges and outlines future research directions in regulatory frameworks, network architectures, and intelligent spectrum management, paving the way for sustainable and scalable SatCom networks for enhanced global connectivity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.00286v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rakshitha De Silva, Shiva Raj Pokhrel, Jonathan Kua, Sithamparanathan Kandeepan</dc:creator>
    </item>
    <item>
      <title>SpliDT: Partitioned Decision Trees for Scalable Stateful Inference at Line Rate</title>
      <link>https://arxiv.org/abs/2509.00397</link>
      <description>arXiv:2509.00397v1 Announce Type: new 
Abstract: Machine learning (ML) is increasingly being deployed in programmable data planes (switches and SmartNICs) to enable real-time traffic analysis, security monitoring, and in-network decision-making. Decision trees (DTs) are particularly well-suited for these tasks due to their interpretability and compatibility with data-plane architectures, i.e., match-action tables (MATs). However, existing in-network DT implementations are constrained by the need to compute all input features upfront, forcing models to rely on a small, fixed set of features per flow. This significantly limits model accuracy and scalability under stringent hardware resource constraints.
  We present SPLIDT, a system that rethinks DT deployment in the data plane by enabling partitioned inference over sliding windows of packets. SPLIDT introduces two key innovations: (1) it assigns distinct, variable feature sets to individual sub-trees of a DT, grouped into partitions, and (2) it leverages an in-band control channel (via recirculation) to reuse data-plane resources (both stateful registers and match keys) across partitions at line rate. These insights allow SPLIDT to scale the number of stateful features a model can use without exceeding hardware limits. To support this architecture, SPLIDT incorporates a custom training and design-space exploration (DSE) framework that jointly optimizes feature allocation, tree partitioning, and DT model depth. Evaluation across multiple real-world datasets shows that SPLIDT achieves higher accuracy while supporting up to 5x more stateful features than prior approaches (e.g., NetBeacon and Leo). It maintains the same low time-to-detection (TTD) as these systems, while scaling to millions of flows with minimal recirculation overhead (&lt;0.05%).</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.00397v1</guid>
      <category>cs.NI</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Murayyiam Parvez, Annus Zulfiqar, Roman Beltiukov, Shir Landau Feibish, Walter Willinger, Arpit Gupta, Muhammad Shahbaz</dc:creator>
    </item>
    <item>
      <title>Interference Between FM Cell Sites and CDMA Cell Sites</title>
      <link>https://arxiv.org/abs/2509.00567</link>
      <description>arXiv:2509.00567v1 Announce Type: new 
Abstract: Interference is the major problem now days in telecommunication sector. One type of interference which is very common now days is FM Cell sites interference between CDMA Cell sites. Which are the types of interference and various observations during this interference is discussed below in this paper.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.00567v1</guid>
      <category>cs.NI</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1049/ic:20070718</arxiv:DOI>
      <arxiv:journal_reference>Information and Communication Technology in Electrical Sciences (ICTES 2007)</arxiv:journal_reference>
      <dc:creator>P. Kumar</dc:creator>
    </item>
    <item>
      <title>SmartFLow: A Communication-Efficient SDN Framework for Cross-Silo Federated Learning</title>
      <link>https://arxiv.org/abs/2509.00603</link>
      <description>arXiv:2509.00603v1 Announce Type: new 
Abstract: Cross-silo Federated Learning (FL) enables multiple institutions to collaboratively train machine learning models while preserving data privacy. In such settings, clients repeatedly exchange model weights with a central server, making the overall training time highly sensitive to network performance. However, conventional routing methods often fail to prevent congestion, leading to increased communication latency and prolonged training. Software-Defined Networking (SDN), which provides centralized and programmable control over network resources, offers a promising way to address this limitation. To this end, we propose SmartFLow, an SDN-based framework designed to enhance communication efficiency in cross-silo FL. SmartFLow dynamically adjusts routing paths in response to changing network conditions, thereby reducing congestion and improving synchronization efficiency. Experimental results show that SmartFLow decreases parameter synchronization time by up to 47% compared to shortest-path routing and 41% compared to capacity-aware routing. Furthermore, it achieves these gains with minimal computational overhead and scales effectively to networks of up to 50 clients, demonstrating its practicality for real-world FL deployments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.00603v1</guid>
      <category>cs.NI</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Osama Abu Hamdan, Hao Che, Engin Arslan, Md Arifuzzaman</dc:creator>
    </item>
    <item>
      <title>FLEET: A Federated Learning Emulation and Evaluation Testbed for Holistic Research</title>
      <link>https://arxiv.org/abs/2509.00621</link>
      <description>arXiv:2509.00621v1 Announce Type: new 
Abstract: Federated Learning (FL) presents a robust paradigm for privacy-preserving, decentralized machine learning. However, a significant gap persists between the theoretical design of FL algorithms and their practical performance, largely because existing evaluation tools often fail to model realistic operational conditions. Many testbeds oversimplify the critical dynamics among algorithmic efficiency, client-level heterogeneity, and continuously evolving network infrastructure. To address this challenge, we introduce the Federated Learning Emulation and Evaluation Testbed (FLEET). This comprehensive platform provides a scalable and configurable environment by integrating a versatile, framework-agnostic learning component with a high-fidelity network emulator. FLEET supports diverse machine learning frameworks, customizable real-world network topologies, and dynamic background traffic generation. The testbed collects holistic metrics that correlate algorithmic outcomes with detailed network statistics. By unifying the entire experiment configuration, FLEET enables researchers to systematically investigate how network constraints, such as limited bandwidth, high latency, and packet loss, affect the convergence and efficiency of FL algorithms. This work provides the research community with a robust tool to bridge the gap between algorithmic theory and real-world network conditions, promoting the holistic and reproducible evaluation of federated learning systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.00621v1</guid>
      <category>cs.NI</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Osama Abu Hamdan, Hao Che, Engin Arslan, Md Arifuzzaman</dc:creator>
    </item>
    <item>
      <title>Unsupervised Dataset Cleaning Framework for Encrypted Traffic Classification</title>
      <link>https://arxiv.org/abs/2509.00701</link>
      <description>arXiv:2509.00701v1 Announce Type: new 
Abstract: Traffic classification, a technique for assigning network flows to predefined categories, has been widely deployed in enterprise and carrier networks. With the massive adoption of mobile devices, encryption is increasingly used in mobile applications to address privacy concerns. Consequently, traditional methods such as Deep Packet Inspection (DPI) fail to distinguish encrypted traffic. To tackle this challenge, Artificial Intelligence (AI), in particular Machine Learning (ML), has emerged as a promising solution for encrypted traffic classification. A crucial prerequisite for any ML-based approach is traffic data cleaning, which removes flows that are not useful for training (e.g., irrelevant protocols, background activity, control-plane messages, and long-lived sessions). Existing cleaning solutions depend on manual inspection of every captured packet, making the process both costly and time-consuming. In this poster, we present an unsupervised framework that automatically cleans encrypted mobile traffic. Evaluation on real-world datasets shows that our framework incurs only a 2%~2.5% reduction in classification accuracy compared with manual cleaning. These results demonstrate that our method offers an efficient and effective preprocessing step for ML-based encrypted traffic classification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.00701v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kun Qiu, Ying Wang, Baoqian Li, Wenjun Zhu</dc:creator>
    </item>
    <item>
      <title>ReWeave: Traffic Engineering with Robust Path Weaving for Localized Link Failure Recover</title>
      <link>https://arxiv.org/abs/2509.00708</link>
      <description>arXiv:2509.00708v1 Announce Type: new 
Abstract: Link failures occur frequently in Internet Service Provider (ISP) networks and pose significant challenges for Traffic Engineering (TE). Existing TE schemes either reroute traffic over vulnerable static paths, leading to performance degradation, or precompute backup routes for a broad range of failure scenarios, which introduces high overhead and limits scalability. Hence, an effective failure recovery mechanism is required to offer sufficient path diversity under constrained overhead, thereby ensuring robust and performant network operation. This paper presents ReWeave, a scalable and efficient link-level TE scheme that enables localized rerouting by equipping each link with a compact set of adjacent-only backup paths. Upon detecting a failure, only the routers at both ends of the failed link reroute traffic dynamically using SRv6-based detours, without controller intervention or full-path recomputation. Evaluation results on large-scale backbone networks demonstrate that ReWeave outperforms existing TE schemes in link failure scenarios. Compared to HARP, the state-of-the-art failure recovery scheme based on centralized control and dynamic traffic reallocation, our approach reduces the average maximum link utilization by 10.5%~20.1%, and lowers the worst-case utilization by 29.5%~40.9%. When compared with Flexile, a protection-based scheme that precomputes routes for multi-failure scenarios, ReWeave achieves a similarly low packet loss rate in 90% of failure cases, while maintaining a response speed comparable to the fastest router-based local rerouting schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.00708v1</guid>
      <category>cs.NI</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jingyi Guan, Kun Qiu, Jin Zhao</dc:creator>
    </item>
    <item>
      <title>A Modular and Scalable Simulator for Connected-UAVs Communication in 5G Networks</title>
      <link>https://arxiv.org/abs/2509.00868</link>
      <description>arXiv:2509.00868v2 Announce Type: new 
Abstract: Cellular-connected UAV systems have enabled a wide range of low-altitude aerial services. However, these systems still face many challenges, such as frequent handovers and the inefficiency of traditional transport protocols. To better study these issues, we develop a modular and scalable simulation platform specifically designed for UAVs communication leveraging the research ecology in wireless communication of MATLAB. The platform supports flexible 5G NR node deployment, customizable UAVs mobility models, and multi-network-interface extensions. It also supports multiple transport protocols including TCP, UDP, QUIC, etc., allowing to investigate how different transport protocols affect UAVs communication performance. In addition, the platform includes a handover management module, enabling the evaluation of both traditional and learning-based handover strategies. Our platform can serve as a testbed for the development and evaluation of advanced transmission strategies in cellular-connected UAV systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.00868v2</guid>
      <category>cs.NI</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yong Su, Yiyi Chen, Shenghong Yi, Hui Feng, Yuedong Xu, Wang Xiang, Bo Hu</dc:creator>
    </item>
    <item>
      <title>Efficient Multichannel Rendezvous Algorithms without Global Channel Enumeration</title>
      <link>https://arxiv.org/abs/2509.00885</link>
      <description>arXiv:2509.00885v1 Announce Type: new 
Abstract: The multichannel rendezvous problem (MRP) is a critical challenge for neighbor discovery in IoT applications, requiring two users to find each other by hopping among available channels over time. This paper addresses the MRP in scenarios where a global channel enumeration system is unavailable. To tackle this challenge, we propose a suite of low-complexity multichannel rendezvous algorithms based on locality-sensitive hashing (LSH), tailored for environments where channel labels are unique L-bit identifiers rather than globally coordinated indices. Inspired by consistent hashing techniques in distributed systems, we develop the LC-LSH and LC-LSH4 algorithms for synchronous and asynchronous settings, respectively. These algorithms significantly reduce implementation complexity while maintaining expected time-to-rendezvous (ETTR) performance comparable to state-of-the-art methods that require global channel enumeration. To ensure bounded maximum time-to-rendezvous (MTTR) in the asynchronous setting, we further introduce the ASYM-LC-LSH4 and QR-LC-LSH4 algorithms by embedding multiset-enhanced modular clock and quasi-random techniques into our framework. Extensive simulations demonstrate that the proposed algorithms achieve performance comparable to state-of-the-art LSH algorithms in both synchronous and asynchronous settings, even without a global channel enumeration system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.00885v1</guid>
      <category>cs.NI</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yi-Chia Cheng, Cheng-Shang Chang</dc:creator>
    </item>
    <item>
      <title>BUBBLE-BLUE a multihop private network based on Bluetooth</title>
      <link>https://arxiv.org/abs/2509.00967</link>
      <description>arXiv:2509.00967v1 Announce Type: new 
Abstract: The BUBBLE-BLUE (BB) project aims to create private Bluetooth bubbles on top of smartphones and to create a kind of terrestrial STARLINK network based on users smartphones.. In each private bubble, participants will be able to communicate autonomously, without recourse to private operator networks, neither data nor cellular, relying solely on the Bluetooth technology of smartphones. The routing strategy is based on dynamic Connected Dominant Sets (CDS). We present the specific features of a BB network as well as some simulation results on their routing performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.00967v1</guid>
      <category>cs.NI</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nadjib Achir, Philippe Jacquet</dc:creator>
    </item>
    <item>
      <title>Quantum-based QoE Optimization in Advanced Cellular Networks: Integration and Cloud Gaming Use Case</title>
      <link>https://arxiv.org/abs/2509.01008</link>
      <description>arXiv:2509.01008v1 Announce Type: new 
Abstract: This work explores the integration of Quantum Machine Learning (QML) and Quantum-Inspired (QI) techniques for optimizing end-to-end (E2E) network services in telecommunication systems, particularly focusing on 5G networks and beyond. The application of QML and QI algorithms is investigated, comparing their performance with classical Machine Learning (ML) approaches. The present study employs a hybrid framework combining quantum and classical computing leveraging the strengths of QML and QI, without the penalty of quantum hardware availability. This is particularized for the optimization of the Quality of Experience (QoE) over cellular networks. The framework comprises an estimator for obtaining the expected QoE based on user metrics, service settings, and cell configuration, and an optimizer that uses the estimation to choose the best cell and service configuration. Although the approach is applicable to any QoE-based network management, its implementation is particularized for the optimization of network configurations for Cloud Gaming services. Then, it is evaluated via performance metrics such as accuracy and model loading and inference times for the estimator, and time to solution and solution score for the optimizer. The results indicate that QML models achieve similar or superior accuracy to classical ML models for estimation, while decreasing inference and loading times. Furthermore, potential for better performance is observed for higher-dimensional data, highlighting promising results for higher complexity problems. Thus, the results demonstrate the promising potential of QML in advancing network optimization, although challenges related to data availability and integration complexities between quantum and classical ML are identified as future research lines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.01008v1</guid>
      <category>cs.NI</category>
      <category>cs.LG</category>
      <category>quant-ph</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fatma Chaouech, Javier Villegas, Ant\'onio Pereira, Carlos Baena, Sergio Fortes, Raquel Barco, Dominic Gribben, Mohammad Dib, Alba Villarino, Aser Cortines, Rom\'an Or\'us</dc:creator>
    </item>
    <item>
      <title>Modeling and Analysis of Coexistence Between MLO NSTR-based Wi-Fi 7 and Legacy Wi-Fi</title>
      <link>https://arxiv.org/abs/2509.01201</link>
      <description>arXiv:2509.01201v1 Announce Type: new 
Abstract: Wi-Fi 7 introduces Multi-link operation (MLO) to enhance throughput and latency performance compared to legacy Wi-Fi standards. MLO enables simultaneous transmission and reception through multiple links, departing from conventional single-link operations (SLO). To fully exploit MLO's potential, it is essential to investigate Wi-Fi 7's coexistence performance with legacy Wi-Fi devices. Existing approaches, however, have overlooked some crucial aspects of MLO, necessitating the development of a standards-compliant analytical framework to model the actual channel access mechanism of MLO. Therefore, this paper tries to fill the gap by proposing a set of novel Markov chains (MC) to accurately model the MLO operation aligned with multi-link backoff behaviors specified by the standard. Specifically, we design two separate MCs for AP and non-AP multi-link devices (MLD) respectively, based on which transmit and collision probabilities are derived under the saturated traffic condition. Then, we also derive closed-form expressions for the throughput of various device types in the coexistence scenario between Wi-Fi 7 and legacy Wi-Fi, including AP MLD, non- AP MLD, and legacy devices. To validate the accuracy of our proposed models, we developed an ns-3 based simulator by implementing both STR(simultaneous transmission and reception) and NSTR(non-STR) based MLO operations. Our ns-3 based extensive simulations have demonstrated that the proposed analytic model provides accurate estimates on the per device throughput performance, while also revealing the dynamics of inter-WLAN coexistence scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.01201v1</guid>
      <category>cs.NI</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Suhwan Jung, Seokwoo Choi, Youngkeun Yoon, Ho-kyung Son, Hyoil Kim</dc:creator>
    </item>
    <item>
      <title>A Real-time Data Collection Approach for 6G AI-native Networks</title>
      <link>https://arxiv.org/abs/2509.01276</link>
      <description>arXiv:2509.01276v1 Announce Type: new 
Abstract: During the development of the Sixth Generation (6G) networks, the integration of Artificial Intelligence (AI) into network systems has become a focal point, leading to the concept of AI-native networks. High quality data is essential for developing such networks. Although some studies have explored data collection and analysis in 6G networks, significant challenges remain, particularly in real-time data acquisition and processing. This paper proposes a comprehensive data collection method that operates in parallel with bitstream processing for wireless communication networks. By deploying data probes, the system captures real-time network and system status data in software-defined wireless communication networks. Furthermore, a data support system is implemented to integrate heterogeneous data and provide automatic support for AI model training and decision making. Finally, a 6G communication testbed using OpenAirInterface5G and Open5GS is built on Kubernetes, as well as the system's functionality is demonstrated via a network traffic prediction case study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.01276v1</guid>
      <category>cs.NI</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>He Shiwen, Dong Haolei, Wang Liangpeng, An Zhenyu</dc:creator>
    </item>
    <item>
      <title>Multi-AAV-enabled Distributed Beamforming in Low-Altitude Wireless Networking for AoI-Sensitive IoT Data Forwarding</title>
      <link>https://arxiv.org/abs/2509.01427</link>
      <description>arXiv:2509.01427v1 Announce Type: new 
Abstract: With the rapid development of low-altitude wireless networking, autonomous aerial vehicles (AAVs) have emerged as critical enablers for timely and reliable data delivery, particularly in remote or underserved areas. In this context, the age of information (AoI) has emerged as a critical performance metric for evaluating the freshness and timeliness of transmitted information in Internet of things (IoT) networks. However, conventional AAV-assisted data transmission is fundamentally limited by finite communication coverage ranges, which requires periodic return flights for data relay operations. This propulsion-repositioning cycle inevitably introduces latency spikes that raise the AoI while degrading service reliability. To address these challenges, this paper proposes a AAV-assisted forwarding system based on distributed beamforming to enhance the AoI in IoT. Specifically, AAVs collaborate via distributed beamforming to collect and relay data between the sensor nodes and remote base station. Then, we formulate an optimization problem to minimize the AoI and AAV energy consumption, by jointly optimizing the AAV trajectories and communication schedules. Due to the non-convex nature of the problem and its pronounced temporal variability, we introduce a deep reinforcement learning solution that incorporates temporal sequence input, layer normalization gated recurrent unit, and a squeeze-and-excitation block to capture long-term dependencies, thereby improving decision-making stability and accuracy, and reducing computational complexity. Simulation results demonstrate that the proposed SAC-TLS algorithm outperforms baseline algorithms in terms of convergence, time average AoI, and energy consumption of AAVs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.01427v1</guid>
      <category>cs.NI</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zifan Lang, Guixia Liu, Jiahui Li, Geng Sun, Zemin Sun, Jiacheng Wang, Dusit Niyato, Victor C. M. Leung</dc:creator>
    </item>
    <item>
      <title>A QoS Framework for Service Provision in Multi-Infrastructure-Sharing Networks</title>
      <link>https://arxiv.org/abs/2509.01694</link>
      <description>arXiv:2509.01694v1 Announce Type: new 
Abstract: We propose a framework for resource provisioning with QoS guarantees in shared infrastructure networks. Our novel framework provides tunable probabilistic service guarantees for throughput and delay. Key to our approach is a Modified Dirft-plus-Penalty (MDP) policy that ensures long-term stability while capturing short-term probabilistic service guarantees using linearized upper-confidence bounds. We characterize the feasible region of service guarantees and show that our MDP procedure achieves mean rate stability and an optimality gap that vanishes with the frame size over which service guarantees are provided. Finally, empirical simulations validate our theory and demonstrate the favorable performance of our algorithm in handling QoS in multi-infrastructure networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.01694v1</guid>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3704413.3764414</arxiv:DOI>
      <dc:creator>Quang Minh Nguyen, Eytan Modiano</dc:creator>
    </item>
    <item>
      <title>FCT O-RAN: Design and Deployment of a Multi-Vendor End-to-End Private 5G Testbed</title>
      <link>https://arxiv.org/abs/2509.01891</link>
      <description>arXiv:2509.01891v1 Announce Type: new 
Abstract: The transformation of 5G networks into software-defined, agile, intelligent and programmable architectures necessitates a paradigm shift in deployment strategies. To deliver superior performance and surpass traditional systems, public and private 5G networks must adopt software-centric cloud native frameworks that enable flexibility through tailored configurations and optimized deployment approaches. In Singapore, the Infocomm Media Development Authority (IMDA) and the National Research Foundation Singapore (NRF) launched the Future Communications Research and Development Programme (FCP) to advance the nation's communications and connectivity landscape. At the core of this initiative is the Future Communications Translation Lab (FCT) at the Singapore Institute of Technology (SIT), which focuses on advancing 5G technologies to higher readiness levels, facilitating their adoption across various industries. A key component is the deployment of FCT O-RAN, a state-of-the-art multi-vendor private 5G platform. The setup includes a 5G core network powered by Microsoft Affirmed and ENEA, O-RAN Centralized and Distributed Units from Radisys. Indoor Remote Units are deployed with Foxconn, while outdoor RUs are deployed with Benetel. To optimize the deployment of remote units, a digital twin was created using Wireless InSite, and performance evaluations were conducted for both the digital twin and the private 5G deployment. Smartphones equipped with QualiPoc were used to measure network performance. The testbed demonstrated effective performance with optimized bandwidth allocations for both indoor and outdoor environments. In the indoor setup, utilizing 50 MHz of bandwidth, a downlink throughput of 713 Mbps and an uplink throughput of 66 Mbps were achieved. Meanwhile, the outdoor setup, utilizing 40 MHz of bandwidth, achieved a downlink throughput of 371 Mbps and an uplink throughput of 55 Mbps.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.01891v1</guid>
      <category>cs.NI</category>
      <category>cs.ET</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amogh PC, Nagamuthu Vignesh, Pei Yiyang, Neelakantam Venkatarayalu, Pedro Henrique Amorim Rezende, Shyam Babu Mahato, Sumei Sun</dc:creator>
    </item>
    <item>
      <title>Adaptive AI Model Partitioning over 5G Networks</title>
      <link>https://arxiv.org/abs/2509.01906</link>
      <description>arXiv:2509.01906v1 Announce Type: new 
Abstract: Mobile devices increasingly rely on deep neural networks (DNNs) for complex inference tasks, but running entire models locally drains the device battery quickly. Offloading computation entirely to cloud or edge servers reduces processing load at devices but poses privacy risks and can incur high network bandwidth consumption and long delays. Split computing (SC) mitigates these challenges by partitioning DNNs between user equipment (UE) and edge servers. However, 5G wireless channels are time-varying and a fixed splitting scheme can lead to sub-optimal solutions. This paper addresses the limitations of fixed model partitioning in privacy-focused image processing and explores trade-offs in key performance metrics, including end-to-end (E2E) latency, energy consumption, and privacy, by developing an adaptive ML partitioning scheme based on real-time AI-powered throughput estimation. Evaluation in multiple scenarios demonstrates significant performance gains of our scheme.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.01906v1</guid>
      <category>cs.NI</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Tam Thanh Nguyen, Tuan Van Ngo, Long Thanh Le, Yong Hao Pua, Mao Van Ngo, Binbin Chen, Tony Q. S. Quek</dc:creator>
    </item>
    <item>
      <title>AoI-based Scheduling of Correlated Sources for Timely Inference</title>
      <link>https://arxiv.org/abs/2509.01926</link>
      <description>arXiv:2509.01926v1 Announce Type: new 
Abstract: We investigate a real-time remote inference system where multiple correlated sources transmit observations over a communication channel to a receiver. The receiver utilizes these observations to infer multiple time-varying targets. Due to limited communication resources, the delivered observations may not be fresh. To quantify data freshness, we employ the Age of Information (AoI) metric. To minimize the inference error, we aim to design a signal-agnostic scheduling policy that leverages AoI without requiring knowledge of the actual target values or the source observations. This scheduling problem is a restless multi-armed bandit (RMAB) problem with a non-separable penalty function. Unlike traditional RMABs, the correlation among sources introduces a unique challenge: the penalty function of each source depends on the AoI of other correlated sources, preventing decomposition of the problem into multiple independent Markov Decision Processes (MDPs), a key step in applying traditional RMAB solutions. To address this, we propose a novel approach by approximating the penalty function of each source and establish an analytical bound on the approximation error. We then develop scheduling policies for two scenarios: (i) full knowledge of the penalty functions and (ii) no knowledge of the penalty functions. For the case of known penalty functions, we present an upper bound on the optimality gap of our policy in the asymptotic regime. For the case of unknown penalty functions and signal distributions, we develop an online learning approach that utilizes bandit feedback to learn an online Maximum Gain First (MGF) policy. Simulation results demonstrate the effectiveness of our proposed policies in minimizing inference error and achieving scalability in the number of sources.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.01926v1</guid>
      <category>cs.NI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Md Kamran Chowdhury Shisher, Vishrant Tripathi, Mung Chiang, Christopher G. Brinton</dc:creator>
    </item>
    <item>
      <title>Federated Foundation Models in Harsh Wireless Environments: Prospects, Challenges, and Future Directions</title>
      <link>https://arxiv.org/abs/2509.01957</link>
      <description>arXiv:2509.01957v1 Announce Type: new 
Abstract: Foundation models (FMs) have shown remarkable capabilities in generalized intelligence, multimodal understanding, and adaptive learning across a wide range of domains. However, their deployment in harsh or austere environments -- characterized by intermittent connectivity, limited computation, noisy data, and dynamically changing network topologies -- remains an open challenge. Existing distributed learning methods such as federated learning (FL) struggle to adapt in such settings due to their reliance on stable infrastructure, synchronized updates, and resource-intensive training. In this work, we explore the potential of Federated Foundation Models (FFMs) as a promising paradigm to address these limitations. By integrating the scalability and generalization power of FMs with novel decentralized, communication-aware FL frameworks, we aim to enable robust, energy-efficient, and adaptive intelligence in extreme and adversarial conditions. We present a detailed breakdown of system-level constraints in harsh environments, and discuss the open research challenges in communication design, model robustness, and energy-efficient personalization for these unique settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.01957v1</guid>
      <category>cs.NI</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Evan Chen, Seyyedali Hosseinalipour, Christopher G. Brinton, David J. Love</dc:creator>
    </item>
    <item>
      <title>FlexNGIA 2.0: Redesigning the Internet with Agentic AI - Protocols, Services, and Traffic Engineering Designed, Deployed, and Managed by AI</title>
      <link>https://arxiv.org/abs/2509.02124</link>
      <description>arXiv:2509.02124v1 Announce Type: new 
Abstract: The escalating demands of immersive communications, alongside advances in network softwarization and AI-driven cognition and generative reasoning, create a pivotal opportunity to rethink and reshape the future Internet. In this context, we introduce in this paper, FlexNGIA 2.0, an Agentic AI-driven Internet architecture that leverages LLM-based AI agents to autonomously orchestrate, configure, and evolve the network. These agents can, at runtime, perceive, reason, coordinate among themselves to dynamically design, implement, deploy, and adapt communication protocols, Service Function Chains (SFCs), network functions, resource allocation strategies, congestion control, and traffic engineering schemes, thereby ensuring optimal performance, reliability, and efficiency under evolving conditions.
  The paper first outlines the overall architecture of FlexNGIA 2.0 and its constituent LLM-Based AI agents. For each agent, we detail its design, implementation, inputs and outputs, prompt structures, interactions with tools and other agents, followed by preliminary proof-of-concept experiments demonstrating its operation and potential. The results clearly highlight the ability of these LLM-based AI agents to automate the design, the implementation, the deployment, and the performance evaluation of transport protocols, service function chains, network functions, congestion control schemes, and resource allocation strategies.
  FlexNGIA 2.0 paves the way for a new class of Agentic AI-Driven networks, where fully cognitive, self-evolving AI agents can autonomously design, implement, adapt and optimize the network's protocols, algorithms, and behaviors to efficiently operate across complex, dynamic, and heterogeneous environments. To bring this vision to reality, we also identify key research challenges toward achieving fully autonomous, adaptive, and agentic AI-driven networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.02124v1</guid>
      <category>cs.NI</category>
      <category>cs.ET</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Mohamed Faten Zhani, Younes Korbi, Yamen Mkadem</dc:creator>
    </item>
    <item>
      <title>Green Traffic Engineering for Satellite Networks Using Segment Routing Flexible Algorithm</title>
      <link>https://arxiv.org/abs/2509.02149</link>
      <description>arXiv:2509.02149v1 Announce Type: new 
Abstract: Large-scale low-Earth-orbit (LEO) constellations demand routing that simultaneously minimizes energy, guarantees delivery under congestion, and meets latency requirements for time-critical flows. We present a segment routing over IPv6 (SRv6) flexible algorithm (Flex-Algo) framework that consists of three logical slices: an energy-efficient slice (Algo 130), a high-reliability slice (Algo 129), and a latency-sensitive slice (Algo 128). The framework provides a unified mixed-integer linear program (MILP) that combines satellite CPU power, packet delivery rate (PDR), and end-to-end latency into a single objective, allowing a lightweight software-defined network (SDN) controller to steer traffic from the source node. Emulation of Telesat's Lightspeed constellation shows that, compared with different routing schemes, the proposed design reduces the average CPU usage by 73%, maintains a PDR above 91% during traffic bursts, and decreases urgent flow delay by 18 ms between Ottawa and Vancouver. The results confirm Flex-Algo's value as a slice-based traffic engineering (TE) tool for resource-constrained satellite networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.02149v1</guid>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>eess.SY</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jintao Liang, Pablo G. Madoery, Chung-Horng Lung, Halim Yanikomeroglu, Gunes Karabulut Kurt</dc:creator>
    </item>
    <item>
      <title>AI Agent Communication from Internet Architecture Perspective: Challenges and Opportunities</title>
      <link>https://arxiv.org/abs/2509.02317</link>
      <description>arXiv:2509.02317v1 Announce Type: new 
Abstract: The rapid development of AI agents leads to a surge in communication demands. Alongside this rise, a variety of frameworks and protocols emerge. While these efforts demonstrate the vitality of the field, they also highlight increasing fragmentation, with redundant innovation and siloed designs hindering cross-domain interoperability. These challenges underscore the need for a systematic perspective to guide the development of scalable, secure, and sustainable AI agent ecosystems. To address this need, this paper provides the first systematic analysis of AI agent communication from the standpoint of Internet architecture-the most successful global-scale distributed system in history. Specifically, we distill decades of Internet evolution into five key elements that are directly relevant to agent communication: scalability, security, real-time performance, high performance, and manageability. We then use these elements to examine both the opportunities and the bottlenecks in developing robust multi-agent ecosystems. Overall, this paper bridges Internet architecture and AI agent communication for the first time, providing a new lens for guiding the sustainable growth of AI agent communication ecosystems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.02317v1</guid>
      <category>cs.NI</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chenguang Du, Chuyi Wang, Yihan Chao, Xiaohui Xie, Yong Cui</dc:creator>
    </item>
    <item>
      <title>Towards Intelligent Battery Management via A Five-Tier Digital Twin Framework</title>
      <link>https://arxiv.org/abs/2509.02366</link>
      <description>arXiv:2509.02366v1 Announce Type: new 
Abstract: Battery management systems (BMSs) are critical to ensuring safety, efficiency, and longevity across electronics, transportation, and energy storage. However, with the rapid growth of lithium-ion batteries, conventional reactive BMS approaches face limitations in health prediction and advanced maintenance management, resulting in increased safety risks and economic costs. To address these challenges, we propose a five-tier digital twin framework for intelligent battery management. The framework spans geometric visualization, predictive modeling, prescriptive optimization, and autonomous operation, enabling full lifecycle optimization. In validation, an electrochemical model calibrated via Bayesian optimization achieved strong alignment with measured voltage and temperature, with Mean Absolute Percentage Errors (MAPE) below 1.57\% and 0.39\%. A Physics-Informed Neural Network (PINN) then combined data and simulations to predict State of Health (SOH), attaining MAPE under 3\% with quantified uncertainty. This framework elevates BMSs into intelligent systems capable of proactive management and autonomous optimization, advancing safety and reliability in critical applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.02366v1</guid>
      <category>cs.NI</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tianwen Zhu, Hao Wang, Zhiwei Cao, Jiarong Xi, Yonggang Wen</dc:creator>
    </item>
    <item>
      <title>Tree algorithms for set reconciliation</title>
      <link>https://arxiv.org/abs/2509.02373</link>
      <description>arXiv:2509.02373v1 Announce Type: new 
Abstract: In this work, a set reconciliation setting is considered in which two parties have similar sets that they would like to reconcile. In particular, we focus on a divide-and-conquer strategy known as partitioned set reconciliation (PSR), in which the sets to be reconciled are successively partitioned until they contain a number of differences below some predetermined value. Borrowing techniques from tree-algorithms for random-access protocols, we present and analyze a novel set reconciliation scheme that we term enhanced partitioned set reconciliation (EPSR). This approach improves the efficiency in terms of overhead, i.e., it yields a lower communication cost, while keeping the same time and communication round complexity as PSR. Additionally, we simulate the performance of the proposed algorithm in an event-driven simulator. Our findings indicate that this novel protocol nearly halves the communication cost of PSR while maintaining the same time complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.02373v1</guid>
      <category>cs.NI</category>
      <category>cs.DS</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Francisco L\'azaro, \v{C}edomir Stefanovi\'c</dc:creator>
    </item>
    <item>
      <title>Inter-DU Load Balancing in an Experimental Over-the-Air 5G Open Radio Access Network</title>
      <link>https://arxiv.org/abs/2509.02420</link>
      <description>arXiv:2509.02420v1 Announce Type: new 
Abstract: This paper presents the first ever fully open-source implementation of Load Balancing (LB) in an experimental Fifth Generation (5G) New Radio (NR) Standalone (SA) network using Open Radio Access Network (O-RAN) architecture. The deployment leverages the O-RAN Software Community (SC) Near Real-Time RAN Intelligent Controller (Near-RT RIC), srsRAN stack, Open5GS core, and Software-Defined Radios (SDRs), with Commercial Off-The-Shelf (COTS) User Equipments (UEs). The implementation extends the srsRAN stack to support E2 Service Model for RAN Control (E2SM-RC) Style 3 Action 1 to facilitate Handovers (HOs) and adds Medium Access Control (MAC) downlink (DL) buffer volume reporting to srsRAN's E2 Service Model for Key Performance Measurement (E2SM-KPM). The deployment demonstrates Near-RT RIC closed-loop control where our Mobility Load Balancing (MLB) xApp makes HO decisions based on network load metrics for LB between two Open Distributed Units (O-DUs) operating at different frequencies in the same band.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.02420v1</guid>
      <category>cs.NI</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fahim Bashar, Asheesh Tripathi, Mayukh Roy Chowdhury, Aloizio Da Silva, Alexandre Huff</dc:creator>
    </item>
    <item>
      <title>On Transferring, Merging, and Splitting Task-Oriented Network Digital Twins</title>
      <link>https://arxiv.org/abs/2509.02551</link>
      <description>arXiv:2509.02551v1 Announce Type: new 
Abstract: The integration of digital twinning technologies is driving next-generation networks toward new capabilities, allowing operators to thoroughly understand network conditions, efficiently analyze valuable radio data, and innovate applications through user-friendly, immersive interfaces. Building on this foundation, network digital twins (NDTs) accurately depict the operational processes and attributes of network infrastructures, facilitating predictive management through real-time analysis and measurement. However, constructing precise NDTs poses challenges, such as integrating diverse data sources, mapping necessary attributes from physical networks, and maintaining scalability for various downstream tasks. Unlike previous works that focused on the creation and mapping of NDTs from scratch, we explore intra- and inter-operations among NDTs within a Unified Twin Transformation (UTT) framework, which uncovers a new computing paradigm for efficient transfer, merging, and splitting of NDTs to create task-oriented twins. By leveraging joint multi-modal and distributed mapping mechanisms, UTT optimizes resource utilization and reduces the cost of creating NDTs, while ensuring twin model consistency. A theoretical analysis of the distributed mapping problem is conducted to establish convergence bounds for this multi-modal gated aggregation process. Evaluations on real-world twin-assisted applications, such as trajectory reconstruction, human localization, and sensory data generation, demonstrate the feasibility and effectiveness of interoperability among NDTs for corresponding task development.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.02551v1</guid>
      <category>cs.NI</category>
      <category>cs.LG</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zifan Zhang, Minghong Fang, Mingzhe Chen, Yuchen Liu</dc:creator>
    </item>
    <item>
      <title>Multi-Agent Reinforcement Learning for Task Offloading in Wireless Edge Networks</title>
      <link>https://arxiv.org/abs/2509.01257</link>
      <description>arXiv:2509.01257v1 Announce Type: cross 
Abstract: In edge computing systems, autonomous agents must make fast local decisions while competing for shared resources. Existing MARL methods often resume to centralized critics or frequent communication, which fail under limited observability and communication constraints. We propose a decentralized framework in which each agent solves a constrained Markov decision process (CMDP), coordinating implicitly through a shared constraint vector. For the specific case of offloading, e.g., constraints prevent overloading shared server resources. Coordination constraints are updated infrequently and act as a lightweight coordination mechanism. They enable agents to align with global resource usage objectives but require little direct communication. Using safe reinforcement learning, agents learn policies that meet both local and global goals. We establish theoretical guarantees under mild assumptions and validate our approach experimentally, showing improved performance over centralized and independent baselines, especially in large-scale settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.01257v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NI</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrea Fox, Francesco De Pellegrini, Eitan Altman</dc:creator>
    </item>
    <item>
      <title>Online Identification of IT Systems through Active Causal Learning</title>
      <link>https://arxiv.org/abs/2509.02130</link>
      <description>arXiv:2509.02130v1 Announce Type: cross 
Abstract: Identifying a causal model of an IT system is fundamental to many branches of systems engineering and operation. Such a model can be used to predict the effects of control actions, optimize operations, diagnose failures, detect intrusions, etc., which is central to achieving the longstanding goal of automating network and system management tasks. Traditionally, causal models have been designed and maintained by domain experts. This, however, proves increasingly challenging with the growing complexity and dynamism of modern IT systems. In this paper, we present the first principled method for online, data-driven identification of an IT system in the form of a causal model. The method, which we call active causal learning, estimates causal functions that capture the dependencies among system variables in an iterative fashion using Gaussian process regression based on system measurements, which are collected through a rollout-based intervention policy. We prove that this method is optimal in the Bayesian sense and that it produces effective interventions. Experimental validation on a testbed shows that our method enables accurate identification of a causal system model while inducing low interference with system operations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.02130v1</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Kim Hammar, Rolf Stadler</dc:creator>
    </item>
    <item>
      <title>Next-Generation Sustainable Wireless Systems: Energy Efficiency Meets Environmental Impact</title>
      <link>https://arxiv.org/abs/2509.02395</link>
      <description>arXiv:2509.02395v1 Announce Type: cross 
Abstract: Aligning with the global mandates pushing towards advanced technologies with reduced resource consumption and environmental impacts, the sustainability of wireless networks becomes a significant concern in 6G systems. To address this concern, a native integration of sustainability into the operations of next-generation networks through novel designs and metrics is necessary. Nevertheless, existing wireless sustainability efforts remain limited to energy-efficient network designs which fail to capture the environmental impact of such systems. In this paper, a novel sustainability metric is proposed that captures emissions per bit, providing a rigorous measure of the environmental foot- print associated with energy consumption in 6G networks. This metric also captures how energy, computing, and communication resource parameters influence the reduction of emissions per bit. Then, the problem of allocating the energy, computing and communication resources is posed as a multi-objective (MO) optimization problem. To solve the resulting non-convex problem, our framework leverages MO reinforcement learning (MORL) to maximize the novel sustainability metric alongside minimizing energy consumption and average delays in successfully delivering the data, all while adhering to constraints on energy resource capacity. The proposed MORL methodology computes a global policy that achieves a Pareto-optimal tradeoff among multiple objectives, thereby balancing environmental sustainability with network performance. Simulation results show that the proposed approach reduces the average emissions per bit by around 26% compared to state-of-the-art methods that do not explicitly integrate carbon emissions into their control objectives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.02395v1</guid>
      <category>cs.IT</category>
      <category>cs.NI</category>
      <category>math.IT</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christo Kurisummoottil Thomas, Omar Hashash, Kimia Ehsani, Walid Saad</dc:creator>
    </item>
    <item>
      <title>REPS: Recycled Entropy Packet Spraying for Adaptive Load Balancing and Failure Mitigation</title>
      <link>https://arxiv.org/abs/2407.21625</link>
      <description>arXiv:2407.21625v5 Announce Type: replace 
Abstract: Next-generation datacenters require highly efficient network load balancing to manage the growing scale of artificial intelligence (AI) training and general datacenter traffic. However, existing Ethernet-based solutions, such as Equal Cost Multi-Path (ECMP) and oblivious packet spraying (OPS), struggle to maintain high network utilization due to both increasing traffic demands and the expanding scale of datacenter topologies, which also exacerbate network failures. To address these limitations, we propose REPS, a lightweight decentralized per-packet adaptive load balancing algorithm designed to optimize network utilization while ensuring rapid recovery from link failures. REPS adapts to network conditions by caching good-performing paths. In case of a network failure, REPS re-routes traffic away from it in less than 100 microseconds. REPS is designed to be deployed with next-generation out-of-order transports, such as Ultra Ethernet, and uses less than 25 bytes of per-connection state regardless of the topology size. We extensively evaluate REPS in large-scale simulations and FPGA-based NICs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.21625v5</guid>
      <category>cs.NI</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tommaso Bonato, Abdul Kabbani, Ahmad Ghalayini, Michael Papamichael, Mohammad Dohadwala, Lukas Gianinazzi, Mikhail Khalilov, Elias Achermann, Daniele De Sensi, Torsten Hoefler</dc:creator>
    </item>
    <item>
      <title>A Hierarchical Gradient Tracking Algorithm for Mitigating Subnet-Drift in Fog Learning Networks</title>
      <link>https://arxiv.org/abs/2409.17430</link>
      <description>arXiv:2409.17430v2 Announce Type: replace 
Abstract: Federated learning (FL) encounters scalability challenges when implemented over fog networks that do not follow FL's conventional star topology architecture. Semi-decentralized FL (SD-FL) has proposed a solution for device-to-device (D2D) enabled networks that divides model cooperation into two stages: at the lower stage, D2D communications is employed for local model aggregations within subnetworks (subnets), while the upper stage handles device-server (DS) communications for global model aggregations. However, existing SD-FL schemes are based on gradient diversity assumptions that become performance bottlenecks as data distributions become more heterogeneous. In this work, we develop semi-decentralized gradient tracking (SD-GT), the first SD-FL methodology that removes the need for such assumptions by incorporating tracking terms into device updates for each communication layer. Our analytical characterization of SD-GT reveals upper bounds on convergence for non-convex, convex, and strongly-convex problems. We show how the bounds enable the development of an optimization algorithm that navigates the performance-efficiency trade-off by tuning subnet sampling rate and D2D rounds for each global training interval. Our subsequent numerical evaluations demonstrate that SD-GT obtains substantial improvements in trained model quality and communication cost relative to baselines in SD-FL and gradient tracking on several datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.17430v2</guid>
      <category>cs.NI</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Evan Chen, Shiqiang Wang, Christopher G. Brinton</dc:creator>
    </item>
    <item>
      <title>Cruise Control: Dynamic Model Selection for ML-Based Network Traffic Analysis</title>
      <link>https://arxiv.org/abs/2412.15146</link>
      <description>arXiv:2412.15146v2 Announce Type: replace 
Abstract: Modern networks increasingly rely on machine learning models for real-time insights, including traffic classification, application quality of experience inference, and intrusion detection. However, existing approaches prioritize prediction accuracy without considering deployment constraints or the dynamism of network traffic, leading to potentially suboptimal performance. Because of this, deploying ML models in real-world networks with tight performance constraints remains an open challenge. In contrast with existing work that aims to select an optimal candidate model for each task based on offline information, we propose an online, system-driven approach to dynamically select the best ML model for network traffic analysis. To this end, we present Cruise Control, a system that pre-trains several models for a given task with different accuracy-cost tradeoffs and selects the most appropriate model based on lightweight signals representing the system's current traffic processing ability. Experimental results using two real-world traffic analysis tasks demonstrate Cruise Control's effectiveness in adapting to changing network conditions. Our evaluation shows that Cruise Control improves median accuracy by 2.78% while reducing packet loss by a factor of four compared to offline-selected models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.15146v2</guid>
      <category>cs.NI</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Johann Hugon, Paul Schmitt, Anthony Busson, Francesco Bronzino</dc:creator>
    </item>
    <item>
      <title>Distilling Large Language Models for Network Active Queue Management</title>
      <link>https://arxiv.org/abs/2501.16734</link>
      <description>arXiv:2501.16734v3 Announce Type: replace 
Abstract: The growing complexity of network traffic and demand for ultra-low latency communication require smarter packet traffic management. Existing Deep Learning-based queuing approaches struggle with dynamic network scenarios and demand high engineering effort. We propose AQM-LLM, distilling Large Language Models (LLMs) with few-shot learning, contextual understanding, and pattern recognition to improve Active Queue Management (AQM) [RFC 9330] with minimal manual effort. We consider a specific case where AQM is Low Latency, Low Loss, and Scalable Throughput (L4S) and our design of AQM-LLM builds on speculative decoding and reinforcement-based distilling of LLM by tackling congestion prevention in the L4S architecture using Explicit Congestion Notification (ECN) [RFC 9331] and periodic packet dropping. We develop a new open-source experimental platform by executing L4S-AQM on FreeBSD-14, providing interoperable modules to support LLM integration and facilitate IETF recognition through wider testing. Our extensive evaluations show L4S-LLM enhances queue management, prevents congestion, reduces latency, and boosts network performance, showcasing LLMs' adaptability and efficiency in uplifting AQM systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.16734v3</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:journal_reference>IEEE Trans on Networking, 2025</arxiv:journal_reference>
      <dc:creator>Shiva Raj Pokhrel, Deol Satish, Jonathan Kua, Anwar Walid</dc:creator>
    </item>
    <item>
      <title>StarCast: A Secure and Spectrum-Efficient Group Communication Scheme for LEO Satellite Networks</title>
      <link>https://arxiv.org/abs/2502.07901</link>
      <description>arXiv:2502.07901v2 Announce Type: replace 
Abstract: Low Earth Orbit (LEO) satellite networks serve as a cornerstone infrastructure for providing ubiquitous connectivity in areas where terrestrial infrastructure is unavailable. With the emergence of Direct-to-Cell (DTC) satellites, these networks can provide direct access to mobile phones and IoT devices without relying on terrestrial base stations, leading to a surge in massive connectivity demands for the serving satellite. To address this issue, group communication is an effective paradigm that enables simultaneous content delivery to multiple users and thus optimizes bandwidth reuse. Although extensive research has been conducted to improve group communication performance, securing this communication without compromising its inherent spectrum efficiency remains a critical challenge. To address this, we introduce StarCast, a secure group encryption scheme for LEO satellite networks. Our solution leverages ciphertext-policy attribute-based encryption (CP-ABE) to implement fine-grained access control by embedding access policies directly within the ciphertext. Unlike standard secure communication approaches that require dedicated per-user channels and significantly deplete limited satellite spectrum resources, StarCast maintains efficient spectrum reuse within user groups while ensuring that only authorized users can access transmitted data. Additionally, it significantly reduces the costly key management overhead associated with conventional encryption schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.07901v2</guid>
      <category>cs.NI</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chaoyu Zhang, Hexuan Yu, Shanghao Shi, Shaoyu Li, Yi Shi, Eric Burger, Y. Thomas Hou, Wenjing Lou</dc:creator>
    </item>
    <item>
      <title>Compact routing schemes in undirected and directed graphs</title>
      <link>https://arxiv.org/abs/2503.13753</link>
      <description>arXiv:2503.13753v3 Announce Type: replace 
Abstract: In this paper, we study the problem of compact routing schemes in weighted undirected and directed graphs.
  \textit{For weighted undirected graphs}, more than a decade ago, Chechik [PODC'13] presented a $\approx3.68k$-stretch compact routing scheme that uses $\tilde{O}(n^{1/k}\log{D})$ local storage, where $D$ is the normalized diameter, for every $k&gt;1$. We present a $\approx 2.64k$-stretch compact routing scheme that uses $\tilde{O}(n^{1/k})$ local storage \textit{on average} in each vertex. This is the first compact routing scheme that uses total local storage of $\tilde{O}(n^{1+1/k})$ while achieving a $c \cdot k$ stretch, for a constant $c &lt; 3$.
  In real-world network protocols, messages are usually transformed as part of a communication session between two parties. Therefore, more than two decades ago, Thorup and Zwick [SPAA'01] considered compact routing schemes that establish a communication session using a handshake. In their handshake-based compact routing scheme, the handshake is routed along a $(4k-5)$-stretch path, and the rest of the communication session is routed along an optimal $(2k-1)$-stretch path. It is straightforward to improve the $(4k-5)$-stretch of the handshake to $\approx3.68k$-stretch using the compact routing scheme of Chechik [PODC'13]. We improve the handshake stretch to the optimal $(2k-1)$, by borrowing the concept of roundtrip routing from directed graphs to \textit{undirected} graphs.
  \textit{For weighted directed graphs}, more than two decades ago, Roditty, Thorup, and Zwick [SODA'02 and TALG'08] presented a $(4k+\eps)$-stretch compact roundtrip routing scheme that uses $\tilde{O}(n^{1/k})$ local storage for every $k\ge 3$. For $k=3$, this gives a $(12+\eps)$-roundtrip stretch using $\tilde{O}(n^{1/3})$ local storage. We improve the stretch by developing a $7$-roundtrip stretch routing scheme with $\tilde{O}(n^{1/3})$ local storage.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13753v3</guid>
      <category>cs.NI</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Avi Kadria, Liam Roditty</dc:creator>
    </item>
    <item>
      <title>LACeS: an Open, Fast, Responsible and Efficient Longitudinal Anycast Census System</title>
      <link>https://arxiv.org/abs/2503.20554</link>
      <description>arXiv:2503.20554v2 Announce Type: replace 
Abstract: IP anycast is a widely adopted technique in which an address is replicated at multiple locations, to, e.g., reduce latency and enhance resilience. Due to anycast's crucial role on the modern Internet, earlier research introduced tools to perform anycast censuses. The first, iGreedy, uses latency measurements from geographically dispersed locations to map anycast deployments. The second, MAnycast2, uses anycast to perform a census of other anycast networks. MAnycast2's advantage is speed, performing an Internet-wide census in 3 hours, but it suffers from problems with accuracy and precision. Inversely, iGreedy is highly accurate but much slower. On top of that, iGreedy has a much higher probing cost.
  In this paper we address the shortcomings of both systems and present LACeS (Longitudinal Anycast Census System). Taking MAnycast2 as a basis, we completely redesign its measurement pipeline, and add support for distributed probing, additional protocols (UDP, TCP and IPv6) and latency measurements similar to iGreedy. We validate LACeS on an anycast testbed with 32 globally distributed nodes, compare against an external anycast production deployment and extensive latency measurements with RIPE Atlas, and cross-check over 60% of detected anycast prefixes against operator ground truth. This shows that MAnycastR achieves high accuracy and precision. We make continual daily MAnycastR censuses available to the community and release the source code of the tool under a permissive open source license.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.20554v2</guid>
      <category>cs.NI</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Remi Hendriks, Matthew Luckie, Mattijs Jonker, Raffaele Sommese, Roland van Rijswijk-Deij</dc:creator>
    </item>
    <item>
      <title>A Comparative Analyses Of Network Formation In Low-power Lossy Networks: ContikiMAC vs Orchestra-enabled TSCH</title>
      <link>https://arxiv.org/abs/2506.06688</link>
      <description>arXiv:2506.06688v2 Announce Type: replace 
Abstract: Medium Access Control (MAC) layer protocols are the underlying paradigms which dictate the transmission &amp; reception of data in any network. Particularly for Low-powered Lossy Networks (LLNs), the design and selection of appropiate MAC-layer protocols is crucial inorder to satisfy several networking objectives such as joining time, network lifetime, energy consumption, end-to-end-delay, etc. In this report, we have presented a comparative analysis between Contiki-MAC and Orchestra-enabled TSCH protocol which provides insights towards the network joining &amp; convergence time as well as an estimate of the energy consumption required of build such LLNs. Our results indicates that Contiki-MAC outperforms Orchestra-enabled TSCH by a factor of 13 times in network formation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.06688v2</guid>
      <category>cs.NI</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Heerok Banerjee</dc:creator>
    </item>
    <item>
      <title>ML-MaxProp: Bridging Machine Learning and Delay-Tolerant Routing for Resilient Post-Disaster Communication</title>
      <link>https://arxiv.org/abs/2508.20077</link>
      <description>arXiv:2508.20077v2 Announce Type: replace 
Abstract: In disaster-stricken and large-scale urban emergency scenarios, ensuring reliable communication remains a formidable challenge, as collapsed infrastructure, unpredictable mobility, and severely constrained resources disrupt conventional networks. Delay-Tolerant Networks (DTNs), though resilient through their store-carry-forward paradigm, reveal the fundamental weaknesses of classical protocols - Epidemic, Spray-and-Wait, and MaxProp - when confronted with sparse encounters, buffer shortages, and volatile connectivity. To address these obstacles, this study proposes ML-MaxProp, a hybrid routing protocol that strengthens MaxProp with supervised machine learning. By leveraging contextual features such as encounter frequency, hop count, buffer occupancy, message age, and time-to-live (TTL), ML-MaxProp predicts relay suitability in real time, transforming rigid heuristics into adaptive intelligence. Extensive simulations in the ONE environment using the Helsinki SPMBM mobility model show that ML-MaxProp consistently surpasses baseline protocols, achieving higher delivery probability, lower latency, and reduced overhead. Statistical validation further shows that these improvements are both significant and robust, even under highly resource-constrained and unstable conditions. Overall, this work shows that ML-MaxProp is not just an incremental refinement but a lightweight, adaptive, and practical solution to one of the hardest challenges in DTNs: sustaining mission-critical communication when infrastructure collapses and every forwarding decision becomes critical.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.20077v2</guid>
      <category>cs.NI</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tao Xiuyuan, Milena Radenkovic</dc:creator>
    </item>
    <item>
      <title>KeySpace: Enhancing Public Key Infrastructure for Interplanetary Networks</title>
      <link>https://arxiv.org/abs/2408.10963</link>
      <description>arXiv:2408.10963v4 Announce Type: replace-cross 
Abstract: As the use of satellites continues to grow, new networking paradigms are emerging to support the scale and long distance communication inherent to these networks. In particular, interplanetary communication relays connect distant network segments together, but result in a sparsely connected network with long-distance links that are frequently interrupted. In this new context, traditional Public Key Infrastructure (PKI) becomes difficult to implement, due to the impossibility of low-latency queries to a central authority. This paper addresses the challenge of implementing PKI in these complex networks, identifying the essential goals and requirements.
  Using these requirements, we develop the KeySpace framework, comprising a set of standardized experiments and metrics for comparing PKI systems across various network topologies, evaluating their performance and security. This enables the testing of different protocols and configurations in a standard, repeatable manner, so that improvements can be more fairly tested and clearly demonstrated. We use KeySpace to test two standard PKI protocols in use in terrestrial networks (OCSP and CRLs), demonstrating for the first time that both can be effectively utilized even in interplanetary networks with high latency and frequent interruptions, provided authority is properly distributed throughout the network. Finally, we propose and evaluate a number of novel techniques extending standard OCSP to improve the overhead of connection establishment, reduce link congestion, and limit the reach of an attacker with a compromised key. Using KeySpace we validate these claims, demonstrating their improved performance over the state of the art.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.10963v4</guid>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joshua Smailes, Filip Futera, Sebastian K\"ohler, Simon Birnbach, Martin Strohmeier, Ivan Martinovic</dc:creator>
    </item>
    <item>
      <title>SAFER-D: A Self-Adaptive Security Framework for Distributed Computing Architectures</title>
      <link>https://arxiv.org/abs/2506.16545</link>
      <description>arXiv:2506.16545v2 Announce Type: replace-cross 
Abstract: The rise of the Internet of Things and Cyber-Physical Systems has introduced new challenges on ensuring secure and robust communication. The growing number of connected devices increases network complexity, leading to higher latency and traffic. Distributed computing architectures (DCAs) have gained prominence to address these issues. This shift has significantly expanded the attack surface, requiring additional security measures to protect all components -- from sensors and actuators to edge nodes and central servers. Recent incidents highlight the difficulty of this task: Cyberattacks, like distributed denial of service attacks, continue to pose severe threats and cause substantial damage. Implementing a holistic defense mechanism remains an open challenge, particularly against attacks that demand both enhanced resilience and rapid response. Addressing this gap requires innovative solutions to enhance the security of DCAs. In this work, we present our holistic self-adaptive security framework which combines different adaptation strategies to create comprehensive and efficient defense mechanisms. We describe how to incorporate the framework into a real-world use case scenario and further evaluate its applicability and efficiency. Our evaluation yields promising results, indicating great potential to further extend the research on our framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.16545v2</guid>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1007/978-3-032-02138-0_13</arxiv:DOI>
      <dc:creator>Marco Stadler, Michael Vierhauser, Michael Riegler, Daniel Waghubinger, Johannes Sametinger</dc:creator>
    </item>
  </channel>
</rss>
