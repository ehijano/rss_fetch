<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>eess.SP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/eess.SP</link>
    <description>eess.SP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/eess.SP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 09 Aug 2024 01:35:32 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 08 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>EEGMobile: Enhancing Speed and Accuracy in EEG-Based Gaze Prediction with Advanced Mobile Architectures</title>
      <link>https://arxiv.org/abs/2408.03449</link>
      <description>arXiv:2408.03449v1 Announce Type: new 
Abstract: Electroencephalography (EEG) analysis is an important domain in the realm of Brain-Computer Interface (BCI) research. To ensure BCI devices are capable of providing practical applications in the real world, brain signal processing techniques must be fast, accurate, and resource-conscious to deliver low-latency neural analytics. This study presents a model that leverages a pre-trained MobileViT alongside Knowledge Distillation (KD) for EEG regression tasks. Our results showcase that this model is capable of performing at a level comparable (only 3% lower) to the previous State-Of-The-Art (SOTA) on the EEGEyeNet Absolute Position Task while being 33% faster and 60% smaller. Our research presents a cost-effective model applicable to resource-constrained devices and contributes to expanding future research on lightweight, mobile-friendly models for EEG regression.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.03449v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Teng Liang, Andrews Damoah</dc:creator>
    </item>
    <item>
      <title>Sub-Resolution mmWave FMCW Radar-based Touch Localization using Deep Learning</title>
      <link>https://arxiv.org/abs/2408.03485</link>
      <description>arXiv:2408.03485v1 Announce Type: new 
Abstract: Touchscreen-based interaction on display devices are ubiquitous nowadays. However, capacitive touch screens, the core technology that enables its widespread use, are prohibitively expensive to be used in large displays because the cost increases proportionally with the screen area. In this paper, we propose a millimeter wave (mmWave) radar-based solution to achieve subresolution error performance using a network of four mmWave radar sensors. Unfortunately, achieving this is non-trivial due to inherent range resolution limitations of mmWave radars, since the target (human hand, finger etc.) is 'distributed' in space. We overcome this using a deep learning-based approach, wherein we train a deep convolutional neural network (CNN) on range-FFT (range vs power profile)-based features against ground truth (GT) positions obtained using a capacitive touch screen. To emulate the clutter characteristics encountered in radar-based positioning of human fingers, we use a metallic finger mounted on a metallic robot arm as the target. Using this setup, we demonstrate subresolution position error performance. Compared to conventional signal processing (CSP)-based approaches, we achieve a 2-3x reduction in positioning error using the CNN. Furthermore, we observe that the inference time performance and CNN model size support real-time integration of our approach on general purpose processor-based computing platforms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.03485v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Raghunandan M. Rao, Amit Kachroo, Koushik A. Manjunatha, Morris Hsu, Rohit Kumar</dc:creator>
    </item>
    <item>
      <title>Deep-learning-based electrode action potential mapping (DEAP Mapping) from annotation-free unipolar electrogram</title>
      <link>https://arxiv.org/abs/2408.03589</link>
      <description>arXiv:2408.03589v1 Announce Type: new 
Abstract: Catheter ablation has limited therapeutic efficacy against non-paroxysmal atrial fibrillation (AF), and electrophysiological studies using mapping catheters have been applied to evaluate the AF substrate. However, many of these approaches rely on detecting excitation timing from electrograms (ECGs), potentially compromising their effectiveness in complex AF scenarios. Herein, we introduce Deep-learning-based Electrode Action Potential Mapping (DEAP Mapping), a deep learning model designed to reconstruct membrane potential images from annotation-free unipolar ECG signals. We conducted ex vivo experiments using porcine hearts (N = 6) to evaluate the accuracy of DEAP Mapping by simultaneously performing fluorescence measurement of membrane potentials and measurements of epicardial unipolar ECGs. Membrane potentials estimated via DEAP Mapping were compared with those measured via optical mapping. We assessed the clinical applicability of DEAP Mapping by comparing the DEAP Mapping's estimations from clinically measured catheter electrode signals with those from established electrode-mapping techniques. DEAP Mapping accurately estimated conduction delays and blocks in ex vivo experiments. Phase variance analysis, an AF substrate evaluation method, revealed that the substrate identified from optical mapping closely resembled that identified from DEAP Mapping estimations (structural similarity index of &gt;0.8). In clinical evaluations, DEAP Mapping estimation observed several conduction delays and blocks that were not observed with existing methods, indicating that DEAP Mapping can estimate excitation patterns with higher spatiotemporal resolution. DEAP Mapping has a potential to derive detailed changes in membrane potential from intra-operative catheter electrode signals, offering enhanced visualisation of the AF substrate from the estimated membrane potentials.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.03589v1</guid>
      <category>eess.SP</category>
      <category>eess.IV</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hiroshi Seno, Toshiya Kojima, Masatoshi Yamazaki, Ichiro Sakuma, Katsuhito Fujiu, Naoki Tomii</dc:creator>
    </item>
    <item>
      <title>HELPS for Emergency Location Service: Hyper-Enhanced Local Positioning System</title>
      <link>https://arxiv.org/abs/2408.03609</link>
      <description>arXiv:2408.03609v1 Announce Type: new 
Abstract: In this study, we propose a novel positioning and searching system for emergency location services, namely the hyper-enhanced local positioning system (HELPS), which is applicable to all mobile phone users, including legacy feature phone users. In the case of an emergency, rescuers are dispatched with portable signal measurement equipment around the estimated location of the emergency caller. Each signal measurement device measures the uplink signal from the mobile phone of the caller. After calculating the rough location of the caller's mobile phone based on these measurements, rescuers can efficiently search for the caller using the received uplink signal strength. Thus, the positioning accuracy in a conventional sense is not a limitation for rescuers in finding the caller. HELPS is not a traditional positioning system but rather a system with humans in the loop designed to reduce search time in emergencies. HELPS can provide emergency location information even in environments where the GPS or Wi-Fi is not functional. Furthermore, for HELPS operation, no hardware changes or software installations are required on the caller's mobile phone.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.03609v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/MWC.011.2300354</arxiv:DOI>
      <dc:creator>Hichan Moon, Hyosoon Park, Jiwon Seo</dc:creator>
    </item>
    <item>
      <title>Signal Attenuation through Foliage Estimator (SAFE)</title>
      <link>https://arxiv.org/abs/2408.03724</link>
      <description>arXiv:2408.03724v1 Announce Type: new 
Abstract: The SAFE tool is an open-source Radio Frequency (RF) propagation model designed for path loss predictions in foliage-dominant environments. It utilizes the ITU-R P.1812-6 model as its backbone, enhances predictions with the physics-based Radiative Energy Transfer (RET) model and makes use of high-resolution terrain and clutter elevation datasets</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.03724v1</guid>
      <category>eess.SP</category>
      <category>physics.comp-ph</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/UEMCON59035.2023.10316052</arxiv:DOI>
      <arxiv:journal_reference>2023 IEEE 14th Annual Ubiquitous Computing, Electronics &amp; Mobile Communication Conference (UEMCON)</arxiv:journal_reference>
      <dc:creator>Mathieu Ch\^ateauvert, Jonathan Ethier, Pierre Bouchard</dc:creator>
    </item>
    <item>
      <title>User-to-User Interference Mitigation in Dynamic TDD MIMO Systems with Multi-Antenna Users</title>
      <link>https://arxiv.org/abs/2408.03740</link>
      <description>arXiv:2408.03740v1 Announce Type: new 
Abstract: We propose a novel method for user-to-user interference (UUI) mitigation in dynamic time-division duplex multiple-input multiple-output communication systems with multi-antenna users. Specifically, we consider the downlink data transmission in the presence of UUI caused by a user that simultaneously transmits in uplink. Our method introduces an overhead for estimation of the user-to-user channels by transmitting pilots from the uplink user to the downlink users. Each downlink user obtains a channel estimate that is used to design a combining matrix for UUI mitigation. We analytically derive an achievable spectral efficiency for the downlink transmission in the presence of UUI with our mitigation technique. Through numerical simulations, we show that our method can significantly improve the spectral efficiency performance in cases of heavy UUI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.03740v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Martin Andersson, Tung T. Vu, P{\aa}l Frenger, Erik G. Larsson</dc:creator>
    </item>
    <item>
      <title>Few-Shot Transfer Learning for Individualized Braking Intent Detection on Neuromorphic Hardware</title>
      <link>https://arxiv.org/abs/2408.03336</link>
      <description>arXiv:2408.03336v1 Announce Type: cross 
Abstract: Objective: This work explores use of a few-shot transfer learning method to train and implement a convolutional spiking neural network (CSNN) on a BrainChip Akida AKD1000 neuromorphic system-on-chip for developing individual-level, instead of traditionally used group-level, models using electroencephalographic data. The efficacy of the method is studied on an advanced driver assist system related task of predicting braking intention. Main Results: Efficacy of the above methodology to develop individual specific braking intention predictive models by rapidly adapting the group-level model in as few as three training epochs while achieving at least 90% accuracy, true positive rate and true negative rate is presented. Further, results show an energy reduction of over 97% with only a 1.3x increase in latency when using the Akida AKD1000 processor for network inference compared to an Intel Xeon CPU. Similar results were obtained in a subsequent ablation study using a subset of five out of 19 channels. Significance: Especially relevant to real-time applications, this work presents an energy-efficient, few-shot transfer learning method that is implemented on a neuromorphic processor capable of training a CSNN as new data becomes available, operating conditions change, or to customize group-level models to yield personalized models unique to each individual.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.03336v1</guid>
      <category>cs.NE</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nathan Lutes, Venkata Sriram Siddhardh Nadendla, K. Krishnamurthy</dc:creator>
    </item>
    <item>
      <title>Optimizing NOMA Transmissions to Advance Federated Learning in Vehicular Networks</title>
      <link>https://arxiv.org/abs/2408.03446</link>
      <description>arXiv:2408.03446v1 Announce Type: cross 
Abstract: Diverse critical data, such as location information and driving patterns, can be collected by IoT devices in vehicular networks to improve driving experiences and road safety. However, drivers are often reluctant to share their data due to privacy concerns. The Federated Vehicular Network (FVN) is a promising technology that tackles these concerns by transmitting model parameters instead of raw data, thereby protecting the privacy of drivers. Nevertheless, the performance of Federated Learning (FL) in a vehicular network depends on the joining ratio, which is restricted by the limited available wireless resources. To address these challenges, this paper proposes to apply Non-Orthogonal Multiple Access (NOMA) to improve the joining ratio in a FVN. Specifically, a vehicle selection and transmission power control algorithm is developed to exploit the power domain differences in the received signal to ensure the maximum number of vehicles capable of joining the FVN. Our simulation results demonstrate that the proposed NOMA-based strategy increases the joining ratio and significantly enhances the performance of the FVN.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.03446v1</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ziru Chen, Zhou Ni, Peiyuan Guan, Lu Wang, Lin X. Cai, Morteza Hashemi, Zongzhi Li</dc:creator>
    </item>
    <item>
      <title>Molecular Absorption-Aware User Assignment, Spectrum, and Power Allocation in Dense THz Networks with Multi-Connectivity</title>
      <link>https://arxiv.org/abs/2408.03451</link>
      <description>arXiv:2408.03451v1 Announce Type: cross 
Abstract: This paper develops a unified framework to maximize the network sum-rate in a multi-user, multi-BS downlink terahertz (THz) network by optimizing user associations, number and bandwidth of sub-bands in a THz transmission window (TW), bandwidth of leading and trailing edge-bands in a TW, sub-band assignment, and power allocations. The proposed framework incorporates multi-connectivity and captures the impact of molecular absorption coefficient variations in a TW, beam-squint, molecular absorption noise, and link blockages. To make the problem tractable, we first propose a convex approximation of the molecular absorption coefficient using curve fitting in a TW, determine the feasible bandwidths of the leading and trailing edge-bands, and then derive closed-form optimal solution for the number of sub-bands considering beam-squint constraints. We then decompose joint user associations, sub-band assignment, and power allocation problem into two sub-problems, i.e., \textbf{(i)} joint user association and sub-band assignment, and \textbf{(ii)} power allocation. To solve the former problem, we analytically prove the unimodularity of the constraint matrix which enables us to relax the integer constraint without loss of optimality. To solve power allocation sub-problem, a fractional programming (FP)-based centralized solution as well as an alternating direction method of multipliers (ADMM)-based light-weight distributed solution is proposed. The overall problem is then solved using alternating optimization until convergence. Complexity analysis of the algorithms and numerical convergence are presented. Numerical findings validate the effectiveness of the proposed algorithms and extract useful insights about the interplay of the density of base stations (BSs), Average order of multi-connectivity (AOM), molecular absorption, {hardware impairment}, {imperfect CSI}, and link blockages.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.03451v1</guid>
      <category>cs.IT</category>
      <category>cs.ET</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohammad Amin Saeidi, Hina Tabassum, Mehrazin Alizadeh</dc:creator>
    </item>
    <item>
      <title>Performance Classification and Remaining Useful Life Prediction of Lithium Batteries Using Machine Learning and Early Cycle Electrochemical Impedance Spectroscopy Measurements</title>
      <link>https://arxiv.org/abs/2408.03469</link>
      <description>arXiv:2408.03469v1 Announce Type: cross 
Abstract: We presents an approach for early cycle classification of lithium-ion batteries into high and low-performing categories, coupled with the prediction of their remaining useful life (RUL) using a linear lasso technique. Traditional methods often rely on extensive cycling and the measurement of a large number of electrochemical impedance spectroscopy (EIS) frequencies to assess battery performance, which can be time and resource consuming. In this study, we propose a methodology that leverages specific EIS frequencies to achieve accurate classification and RUL prediction within the first few cycles of battery operation. Notably, given only the 20 kHz impedance response, our support vector machine (SVM) model classifies batteries with 100\% accuracy. Additionally, our findings reveal that battery performance classification is frequency agnostic within the high frequency ($&lt;20$ kHz) to low-frequency (32 mHz) range. Our model also demonstrates accurate RUL predictions with $R^2&gt;0.96$ based on the out of phase impedance response at a single high (20 kHz) and a single mid-frequency (8.8 Hz), in conjunction with temperature data. This research underscores the significance of the mid-frequency impedance response as merely one among several crucial features in determining battery performance, thereby broadening the understanding of factors influencing battery behavior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.03469v1</guid>
      <category>cond-mat.mtrl-sci</category>
      <category>eess.SP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christian Parsons, Adil Amin, Prasenjit Guptasarma</dc:creator>
    </item>
    <item>
      <title>Focal Depth Estimation: A Calibration-Free, Subject- and Daytime Invariant Approach</title>
      <link>https://arxiv.org/abs/2408.03591</link>
      <description>arXiv:2408.03591v1 Announce Type: cross 
Abstract: In an era where personalized technology is increasingly intertwined with daily life, traditional eye-tracking systems and autofocal glasses face a significant challenge: the need for frequent, user-specific calibration, which impedes their practicality. This study introduces a groundbreaking calibration-free method for estimating focal depth, leveraging machine learning techniques to analyze eye movement features within short sequences. Our approach, distinguished by its innovative use of LSTM networks and domain-specific feature engineering, achieves a mean absolute error (MAE) of less than 10 cm, setting a new focal depth estimation accuracy standard. This advancement promises to enhance the usability of autofocal glasses and pave the way for their seamless integration into extended reality environments, marking a significant leap forward in personalized visual technology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.03591v1</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Benedikt W. Hosp, Bj\"orn Severitt, Rajat Agarwala, Evgenia Rusak, Yannick Sauer, Siegfried Wahl</dc:creator>
    </item>
    <item>
      <title>Time is Not Enough: Time-Frequency based Explanation for Time-Series Black-Box Models</title>
      <link>https://arxiv.org/abs/2408.03636</link>
      <description>arXiv:2408.03636v1 Announce Type: cross 
Abstract: Despite the massive attention given to time-series explanations due to their extensive applications, a notable limitation in existing approaches is their primary reliance on the time-domain. This overlooks the inherent characteristic of time-series data containing both time and frequency features. In this work, we present Spectral eXplanation (SpectralX), an XAI framework that provides time-frequency explanations for time-series black-box classifiers. This easily adaptable framework enables users to "plug-in" various perturbation-based XAI methods for any pre-trained time-series classification models to assess their impact on the explanation quality without having to modify the framework architecture. Additionally, we introduce Feature Importance Approximations (FIA), a new perturbation-based XAI method. These methods consist of feature insertion, deletion, and combination techniques to enhance computational efficiency and class-specific explanations in time-series classification tasks. We conduct extensive experiments in the generated synthetic dataset and various UCR Time-Series datasets to first compare the explanation performance of FIA and other existing perturbation-based XAI methods in both time-domain and time-frequency domain, and then show the superiority of our FIA in the time-frequency domain with the SpectralX framework. Finally, we conduct a user study to confirm the practicality of our FIA in SpectralX framework for class-specific time-frequency based time-series explanations. The source code is available in https://github.com/gustmd0121/Time_is_not_Enough</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.03636v1</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3627673.3679844</arxiv:DOI>
      <dc:creator>Hyunseung Chung, Sumin Jo, Yeonsu Kwon, Edward Choi</dc:creator>
    </item>
    <item>
      <title>Real-time Event Recognition of Long-distance Distributed Vibration Sensing with Knowledge Distillation and Hardware Acceleration</title>
      <link>https://arxiv.org/abs/2408.03647</link>
      <description>arXiv:2408.03647v1 Announce Type: cross 
Abstract: Distributed optical fiber vibration sensing (DVS) technology based on phase-sensitive optical time-domain reflectometry is widely used for safety monitoring and intrusion event surveillance in wide-ranging fields. Existing methods rely on deep learning models for event recognition but struggle with real-time processing of large data volumes in long-distance applications. To address these challenges, we use a four-layer convolutional neural network (CNN). The application of knowledge distillation with ResNet as the teacher model improves the generalization ability of the four-layer CNN, increasing the accuracy from 83.41% to 95.39% on data from untrained environments. The model is implemented on a field programmable gate array (FPGA) using a novel design that replaces multiplication with binary shift operations and quantizes model weights accordingly, allowing for high parallelism and low latency. An inference time of 0.083 ms is achieved for a spatial-temporal sample with a 12.5 m fiber length and 0.256 s time frame. This implies the system can process signals over a fiber length of approximately 38.55 km in real time, which is more than twice the capability of a GPU of Nvidia GTX 4090. The proposed method greatly improves the efficiency of vibration pattern recognition, thus promoting the application of DVS as smart sensing system in various areas. The data and code is available at https://github.com/HUST-IOF/Efficient-DVS</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.03647v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhongyao Luo, Hao Wu, Zhao Ge, Ming Tang</dc:creator>
    </item>
    <item>
      <title>One-Shot Distributed Node-Specific Signal Estimation with Non-Overlapping Latent Subspaces in Acoustic Sensor Networks</title>
      <link>https://arxiv.org/abs/2408.03752</link>
      <description>arXiv:2408.03752v1 Announce Type: cross 
Abstract: A one-shot algorithm called iterationless DANSE (iDANSE) is introduced to perform distributed adaptive node-specific signal estimation (DANSE) in a fully connected wireless acoustic sensor network (WASN) deployed in an environment with non-overlapping latent signal subspaces. The iDANSE algorithm matches the performance of a centralized algorithm in a single processing cycle while devices exchange fused versions of their multichannel local microphone signals. Key advantages of iDANSE over currently available solutions are its iterationless nature, which favors deployment in real-time applications, and the fact that devices can exchange fewer fused signals than the number of latent sources in the environment. The proposed method is validated in numerical simulations including a speech enhancement scenario.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.03752v1</guid>
      <category>eess.AS</category>
      <category>eess.SP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Paul Didier, Pourya Behmandpoor, Toon van Waterschoot, Marc Moonen</dc:creator>
    </item>
    <item>
      <title>A Versatile Pilot Design Scheme for FDD Systems Utilizing Gaussian Mixture Models</title>
      <link>https://arxiv.org/abs/2408.03756</link>
      <description>arXiv:2408.03756v1 Announce Type: cross 
Abstract: In this work, we propose a Gaussian mixture model (GMM)-based pilot design scheme for downlink (DL) channel estimation in single- and multi-user multiple-input multiple-output (MIMO) frequency division duplex (FDD) systems. In an initial offline phase, the GMM captures prior information during training, which is then utilized for pilot design. In the single-user case, the GMM is utilized to construct a codebook of pilot matrices and, once shared with the mobile terminal (MT), can be employed to determine a feedback index at the MT. This index selects a pilot matrix from the constructed codebook, eliminating the need for online pilot optimization. We further establish a sum conditional mutual information (CMI)-based pilot optimization framework for multi-user MIMO (MU-MIMO) systems. Based on the established framework, we utilize the GMM for pilot matrix design in MU-MIMO systems. The analytic representation of the GMM enables the adaptation to any signal-to-noise ratio (SNR) level and pilot configuration without re-training. Additionally, an adaption to any number of MTs is facilitated. Extensive simulations demonstrate the superior performance of the proposed pilot design scheme compared to state-of-the-art approaches. The performance gains can be exploited, e.g., to deploy systems with fewer pilots.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.03756v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nurettin Turan, Benedikt B\"ock, Benedikt Fesl, Michael Joham, Deniz G\"und\"uz, Wolfgang Utschick</dc:creator>
    </item>
    <item>
      <title>Traffic and Obstacle-aware UAV Positioning in Urban Environments Using Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2408.03894</link>
      <description>arXiv:2408.03894v1 Announce Type: cross 
Abstract: Unmanned Aerial Vehicles (UAVs) are suited as cost-effective and adaptable platforms for carrying Wi-Fi Access Points (APs) and cellular Base Stations (BSs). Implementing aerial networks in disaster management scenarios and crowded areas can effectively enhance Quality of Service (QoS). In such environments, maintaining Line-of-Sight (LoS), especially at higher frequencies, is crucial for ensuring reliable communication networks with high capacity, particularly in environments with obstacles. The main contribution of this paper is a traffic- and obstacle-aware UAV positioning algorithm named Reinforcement Learning-based Traffic and Obstacle-aware Positioning Algorithm (RLTOPA), for such environments. RLTOPA determines the optimal position of the UAV by considering the positions of ground users, the coordinates of obstacles, and the traffic demands of users. This positioning aims to maximize QoS in terms of throughput by ensuring optimal LoS between ground users and the UAV. The network performance of the proposed solution, characterized in terms of mean delay and throughput, was evaluated using the ns- 3 simulator. The results show up to 95% improvement in aggregate throughput and 71% in delay without compromising fairness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.03894v1</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kamran Shafafi, Manuel Ricardo, Rui Campos</dc:creator>
    </item>
    <item>
      <title>Lightweight Video Denoising Using a Classic Bayesian Backbone</title>
      <link>https://arxiv.org/abs/2408.03904</link>
      <description>arXiv:2408.03904v1 Announce Type: cross 
Abstract: In recent years, state-of-the-art image and video denoising networks have become increasingly large, requiring millions of trainable parameters to achieve best-in-class performance. Improved denoising quality has come at the cost of denoising speed, where modern transformer networks are far slower to run than smaller denoising networks such as FastDVDnet and classic Bayesian denoisers such as the Wiener filter.
  In this paper, we implement a hybrid Wiener filter which leverages small ancillary networks to increase the original denoiser performance, while retaining fast denoising speeds. These networks are used to refine the Wiener coring estimate, optimise windowing functions and estimate the unknown noise profile. Using these methods, we outperform several popular denoisers and remain within 0.2 dB, on average, of the popular VRT transformer. Our method was found to be over x10 faster than the transformer method, with a far lower parameter cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.03904v1</guid>
      <category>eess.IV</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>eess.SP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cl\'ement Bled, Fran\c{c}ois Piti\'e</dc:creator>
    </item>
    <item>
      <title>Exploiting Semantic Localization in Highly Dynamic Wireless Networks Using Deep Homoscedastic Domain Adaptation</title>
      <link>https://arxiv.org/abs/2310.07792</link>
      <description>arXiv:2310.07792v2 Announce Type: replace 
Abstract: Localization in GPS-denied outdoor locations, such as street canyons in an urban or metropolitan environment, has many applications. Machine Learning (ML) is widely used to tackle this critical problem. One challenge lies in the mixture of line-of-sight (LOS), obstructed LOS (OLOS), and non-LOS (NLOS) conditions. In this paper, we consider a semantic localization that treats these three propagation conditions as the ''semantic objects", and aims to determine them together with the actual localization, and show that this increases accuracy and robustness. Furthermore, the propagation conditions are highly dynamic, since obstruction by cars or trucks can change the channel state information (CSI) at a fixed location over time. We therefore consider the blockage by such dynamic objects as another semantic state. Based on these considerations, we formulate the semantic localization with a joint task (coordinates regression and semantics classification) learning problem. Another problem created by the dynamics is the fact that each location may be characterized by a number of different CSIs. To avoid the need for excessive amount of labeled training data, we propose a multi-task deep domain adaptation (DA) based localization technique, training neural networks with a limited number of labeled samples and numerous unlabeled ones. Besides, we introduce novel scenario adaptive learning strategies to ensure efficient representation learning and successful knowledge transfer. Finally, we use Bayesian theory for uncertainty modeling of the importance weights in each task, reducing the need for time-consuming parameter finetuning; furthermore, with some mild assumptions, we derive the related log-likelihood for the joint task and present the deep homoscedastic DA based localization method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.07792v2</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Lei Chu, Abdullah Alghafis, Andreas F. Molisch</dc:creator>
    </item>
    <item>
      <title>Array Synthesis in Terms of Characteristic Modes and Generalized Scattering Matrices</title>
      <link>https://arxiv.org/abs/2403.02046</link>
      <description>arXiv:2403.02046v3 Announce Type: replace 
Abstract: The synthesis of antenna arrays in presence of mutual coupling using generalized scattering matrices in terms of characteristic modes is proposed. For the synthesis, the array is built of synthetic elements that are described by their modal scattering and radiation behavior. In particular, the question of how to describe the degrees of freedom of such elements is addressed. The eigenvalues of the characteristic modes of the element geometry and the modal radiation behavior of the antenna are thereby selected as degrees of freedom for the model of the synthetic elements. Using this model and a modal coupling matrix, an approach to optimize the modal configuration of the elements within an array is proposed. Finally, a close to reality example shows how the proposed theory can be used to enhance the cross-polarization rejection of a circularly polarized patch antenna array with a fixed beam.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02046v3</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Leonardo M\"orlein, Dirk Manteuffel</dc:creator>
    </item>
    <item>
      <title>Fusing Pretrained ViTs with TCNet for Enhanced EEG Regression</title>
      <link>https://arxiv.org/abs/2404.15311</link>
      <description>arXiv:2404.15311v2 Announce Type: replace 
Abstract: The task of Electroencephalogram (EEG) analysis is paramount to the development of Brain-Computer Interfaces (BCIs). However, to reach the goal of developing robust, useful BCIs depends heavily on the speed and the accuracy at which BCIs can understand neural dynamics. In response to that goal, this paper details the integration of pre-trained Vision Transformers (ViTs) with Temporal Convolutional Networks (TCNet) to enhance the precision of EEG regression. The core of this approach lies in harnessing the sequential data processing strengths of ViTs along with the superior feature extraction capabilities of TCNet, to significantly improve EEG analysis accuracy. In addition, we analyze the importance of how to construct optimal patches for the attention mechanism to analyze, balancing both speed and accuracy tradeoffs. Our results showcase a substantial improvement in regression accuracy, as evidenced by the reduction of Root Mean Square Error (RMSE) from 55.4 to 51.8 on EEGEyeNet's Absolute Position Task, outperforming existing state-of-the-art models. Without sacrificing performance, we increase the speed of this model by an order of magnitude (up to 4.32x faster). This breakthrough not only sets a new benchmark in EEG regression analysis but also opens new avenues for future research in the integration of transformer architectures with specialized feature extraction methods for diverse EEG datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15311v2</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eric Modesitt, Haicheng Yin, Williams Huang Wang, Brian Lu</dc:creator>
    </item>
    <item>
      <title>Mobile Edge Generation-Enabled Digital Twin: Architecture Design and Research Opportunities</title>
      <link>https://arxiv.org/abs/2407.02804</link>
      <description>arXiv:2407.02804v2 Announce Type: replace 
Abstract: A novel paradigm of mobile edge generation (MEG)-enabled digital twin (DT) is proposed, which enables distributed on-device generation at mobile edge networks for real-time DT applications. First, an MEG-DT architecture is put forward to decentralize generative artificial intelligence (GAI) models onto edge servers (ESs) and user equipments (UEs), which has the advantages of low latency, privacy preservation, and individual-level customization. Then, various single-user and multi-user generation mechanisms are conceived for MEG-DT, which strike trade-offs between generation latency, hardware costs, and device coordination. Furthermore, to perform efficient distributed generation, two operating protocols are explored for transmitting interpretable and latent features between ESs and UEs, namely sketch-based generation and seed-based generation, respectively. Based on the proposed protocols, the convergence between MEG and DT are highlighted. Considering the seed-based image generation scenario, numerical case studies are provided to reveal the superiority of MEG-DT over centralized generation. Finally, promising applications and research opportunities are identified.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.02804v2</guid>
      <category>eess.SP</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaoxia Xu, Ruikang Zhong, Xidong Mu, Yuanwei Liu, Kaibin Huang</dc:creator>
    </item>
    <item>
      <title>Spatio-Temporal Adaptive Diffusion Models for EEG Super-Resolution in Epilepsy Diagnosis</title>
      <link>https://arxiv.org/abs/2407.03089</link>
      <description>arXiv:2407.03089v3 Announce Type: replace 
Abstract: Electroencephalogram (EEG) technology, particularly high-density EEG (HD EEG) devices, is widely used in fields such as neuroscience. HD EEG devices improve the spatial resolution of EEG by placing more electrodes on the scalp, meeting the requirements of clinical diagnostic applications such as epilepsy focus localization. However, this technique faces challenges such as high acquisition costs and limited usage scenarios. In this paper, spatio-temporal adaptive diffusion models (STADMs) are proposed to pioneer the use of diffusion models for achieving spatial SR reconstruction from low-resolution (LR, 64 channels or fewer) EEG to high-resolution (HR, 256 channels) EEG. Specifically, a spatio-temporal condition module is designed to extract the spatio-temporal features of LR EEG, which then serve as conditional inputs to guide the reverse denoising process of diffusion models. Additionally, a multi-scale Transformer denoising module is constructed to leverage multi-scale convolution blocks and cross-attention-based diffusion Transformer blocks for conditional guidance to generate subject-adaptive SR EEG. Experimental results demonstrate that the proposed method effectively enhances the spatial resolution of LR EEG and quantitatively outperforms existing methods. Furthermore, STADMs demonstrate their value by applying synthetic SR EEG to classification and source localization tasks of epilepsy patients, indicating their potential to significantly improve the spatial resolution of LR EEG.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03089v3</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tong Zhou, Shuqiang Wang</dc:creator>
    </item>
    <item>
      <title>Deep learning based ECG segmentation for delineation of diverse arrhythmias</title>
      <link>https://arxiv.org/abs/2304.06237</link>
      <description>arXiv:2304.06237v3 Announce Type: replace-cross 
Abstract: Accurate delineation of key waveforms in an ECG is a critical step in extracting relevant features to support the diagnosis and treatment of heart conditions. Although deep learning based methods using segmentation models to locate P, QRS, and T waves have shown promising results, their ability to handle arrhythmias has not been studied in any detail. In this paper we investigate the effect of arrhythmias on delineation quality and develop strategies to improve performance in such cases. We introduce a U-Net-like segmentation model for ECG delineation with a particular focus on diverse arrhythmias. This is followed by a post-processing algorithm which removes noise and automatically determines the boundaries of P, QRS, and T waves. Our model has been trained on a diverse dataset and evaluated against the LUDB and QTDB datasets to show strong performance, with F1-scores exceeding 99% for QRS and T waves, and over 97% for P waves in the LUDB dataset. Furthermore, we assess various models across a wide array of arrhythmias and observe that models with a strong performance on standard benchmarks may still perform poorly on arrhythmias that are underrepresented in these benchmarks, such as tachycardias. We propose solutions to address this discrepancy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.06237v3</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1371/journal.pone.0303178</arxiv:DOI>
      <arxiv:journal_reference>PLoS ONE 19(6): e0303178 (2024)</arxiv:journal_reference>
      <dc:creator>Chankyu Joung, Mijin Kim, Taejin Paik, Seong-Ho Kong, Seung-Young Oh, Won Kyeong Jeon, Jae-hu Jeon, Joong-Sik Hong, Wan-Joong Kim, Woong Kook, Myung-Jin Cha, Otto van Koert</dc:creator>
    </item>
    <item>
      <title>Next-Generation Teleophthalmology: AI-enabled Quality Assessment Aiding Remote Smartphone-based Consultation</title>
      <link>https://arxiv.org/abs/2402.07118</link>
      <description>arXiv:2402.07118v2 Announce Type: replace-cross 
Abstract: Blindness and other eye diseases are a global health concern, particularly in low- and middle-income countries like India. In this regard, during the COVID-19 pandemic, teleophthalmology became a lifeline, and the Grabi attachment for smartphone-based eye imaging gained in use. However, quality of user-captured image often remained inadequate, requiring clinician vetting and delays. In this backdrop, we propose an AI-based quality assessment system with instant feedback mimicking clinicians' judgments and tested on patient-captured images. Dividing the complex problem hierarchically, here we tackle a nontrivial part, and demonstrate a proof of the concept.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.07118v2</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>eess.IV</category>
      <category>eess.SP</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dhruv Srikanth, Jayang Gurung, N Satya Deepika, Vineet Joshi, Lopamudra Giri, Pravin Vaddavalli, Soumya Jana</dc:creator>
    </item>
    <item>
      <title>Telco-RAG: Navigating the Challenges of Retrieval-Augmented Language Models for Telecommunications</title>
      <link>https://arxiv.org/abs/2404.15939</link>
      <description>arXiv:2404.15939v3 Announce Type: replace-cross 
Abstract: The application of Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG) systems in the telecommunication domain presents unique challenges, primarily due to the complex nature of telecom standard documents and the rapid evolution of the field. The paper introduces Telco-RAG, an open-source RAG framework designed to handle the specific needs of telecommunications standards, particularly 3rd Generation Partnership Project (3GPP) documents. Telco-RAG addresses the critical challenges of implementing a RAG pipeline on highly technical content, paving the way for applying LLMs in telecommunications and offering guidelines for RAG implementation in other technical domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15939v3</guid>
      <category>cs.IR</category>
      <category>eess.SP</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrei-Laurentiu Bornea, Fadhel Ayed, Antonio De Domenico, Nicola Piovesan, Ali Maatouk</dc:creator>
    </item>
    <item>
      <title>Accelerating Mobile Edge Generation (MEG) by Constrained Learning</title>
      <link>https://arxiv.org/abs/2407.07245</link>
      <description>arXiv:2407.07245v2 Announce Type: replace-cross 
Abstract: A novel accelerated mobile edge generation (MEG) framework is proposed for generating high-resolution images on mobile devices. Exploiting a large-scale latent diffusion model (LDM) distributed across edge server (ES) and user equipment (UE), cost-efficient artificial intelligence generated content (AIGC) is achieved by transmitting low-dimensional features between ES and UE. To reduce overheads of both distributed computations and transmissions, a dynamic diffusion and feature merging scheme is conceived. By jointly optimizing the denoising steps and feature merging ratio, the image generation quality is maximized subject to latency and energy consumption constraints. To address this problem and tailor LDM sub-models, a low-complexity MEG acceleration protocol is developed. Particularly, a backbone meta-architecture is trained via offline distillation. Then, dynamic diffusion and feature merging are determined in online channel environment, which can be viewed as a constrained Markov Decision Process (MDP). A constrained variational policy optimization (CVPO) based MEG algorithm is further proposed for constraint-guaranteed learning, namely MEG-CVPO. Numerical results verify that: 1) The proposed framework can generate 1024$\times$1024 high-quality images over noisy channels while reducing over $40\%$ latency compared to conventional generation schemes. 2) The developed MEG-CVPO effectively mitigates constraint violations, thus flexibly controlling the trade-off between image distortion and generation costs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.07245v2</guid>
      <category>eess.SY</category>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaoxia Xu, Yuanwei Liu, Xidong Mu, Hong Xing, Arumugam Nallanathan</dc:creator>
    </item>
    <item>
      <title>Unleashing the Power of Data Tsunami: A Comprehensive Survey on Data Assessment and Selection for Instruction Tuning of Language Models</title>
      <link>https://arxiv.org/abs/2408.02085</link>
      <description>arXiv:2408.02085v3 Announce Type: replace-cross 
Abstract: Instruction tuning plays a critical role in aligning large language models (LLMs) with human preference. Despite the vast amount of open instruction datasets, naively training a LLM on all existing instructions may not be optimal and practical. To pinpoint the most beneficial datapoints, data assessment and selection methods have been proposed in the fields of natural language processing (NLP) and deep learning. However, under the context of instruction tuning, there still exists a gap in knowledge on what kind of data evaluation metrics can be employed and how they can be integrated into the selection mechanism. To bridge this gap, we present a comprehensive review on existing literature of data assessment and selection especially for instruction tuning of LLMs. We systematically categorize all applicable methods into quality-based, diversity-based, and importance-based ones where a unified, fine-grained taxonomy is structured. For each category, representative methods are elaborated to describe the landscape of relevant research. In addition, comparison between latest methods is conducted on their officially reported results to provide in-depth discussions on their limitations. Finally, we summarize the open challenges and propose the promosing avenues for future studies. All related contents are available at https://github.com/yuleiqin/fantastic-data-engineering.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02085v3</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>eess.SP</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yulei Qin, Yuncheng Yang, Pengcheng Guo, Gang Li, Hang Shao, Yuchen Shi, Zihan Xu, Yun Gu, Ke Li, Xing Sun</dc:creator>
    </item>
  </channel>
</rss>
