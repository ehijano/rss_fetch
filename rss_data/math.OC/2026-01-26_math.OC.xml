<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 27 Jan 2026 03:39:36 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>A Constructive Cayley Representation of Orthogonal Matrices and Applications to Optimization</title>
      <link>https://arxiv.org/abs/2601.16271</link>
      <description>arXiv:2601.16271v1 Announce Type: new 
Abstract: It is known that every real orthogonal matrix can be brought into the domain of the Cayley transform by multiplication with a suitable diagonal signature matrix. In this paper we provide a constructive and numerically efficient algorithm that, given a real orthogonal matrix $U$, computes a diagonal matrix $D$ with entries in $\{\pm1\}$ such that the Cayley transform of $DU$ is well defined. This yields a representation of $U$ in the form \[ U = D(I-S)(I+S)^{-1}, \] where $S$ is a skew-symmetric matrix. The proposed algorithm requires $O(n^{3})$ arithmetic operations and produces an explicit quantitative bound on the associated skew-symmetric generator. As an application, we show how this construction can be used to control singularities in Cayley-transform-based optimization methods on the orthogonal group.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.16271v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.AG</category>
      <category>math.NA</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Iwo Biborski</dc:creator>
    </item>
    <item>
      <title>Maximizing Reach-Avoid Probabilities for Linear Stochastic Systems via Control Architectures</title>
      <link>https://arxiv.org/abs/2601.16290</link>
      <description>arXiv:2601.16290v1 Announce Type: new 
Abstract: The maximization of reach-avoid probabilities for stochastic systems is a central topic in the control literature. Yet, the available methods are either restricted to low-dimensional systems or suffer from conservative approximations. To address these limitations, we propose control architectures that combine the flexibility of Markov Decision Processes with the scalability of Model Predictive Controllers. The Model Predictive Controller tracks reference signals while remaining agnostic to the stochasticity and reach-avoid objective. Instead, the reach-avoid probability is maximized by optimally updating the controller's reference online. To achieve this, the closed-loop system, consisting of the system and Model Predictive Controller, is abstracted as a Markov Decision Process in which a new reference can be chosen at every time-step. A feedback policy generating optimal references is then computed via Dynamic Programming. If the state space of the system is continuous, the Dynamic Programming algorithm must be executed on a finite system approximation. Modifications to the Model Predictive Controller enable a computationally efficient robustification of the Dynamic Programming algorithm to approximation errors, preserving bounds on the achieved reach-avoid probability. The approach is validated on a perturbed 12D quadcopter model in cluttered reach-avoid environments proving its flexibility and scalability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.16290v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Niklas Schmid, Jaeyoun Choi, Oswin So, Chuchu Fan</dc:creator>
    </item>
    <item>
      <title>Solving Regularized Multifacility Location Problems with Unknown Number of Centers via Difference-of-Convex Optimization</title>
      <link>https://arxiv.org/abs/2601.16576</link>
      <description>arXiv:2601.16576v1 Announce Type: new 
Abstract: In this paper, we develop optimization methods for a new model of multifacility location problems defined by a Minkowski gauge with Laplace-type regularization terms. The model is analyzed from both theoretical and numerical perspectives. In particular, we establish the existence of optimal solutions and study qualitative properties of global minimizers. By combining Nesterov's smoothing technique with recent advances in difference-of-convex optimization, following the pioneering work of P. D. Tao and L. T. H. An and others, we propose efficient numerical algorithms for minimizing the objective function of this model. As an application, our approach provides an effective method for determining the number of centers in gauge-based multifacility location and clustering problems. Our results extend and complement recent developments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.16576v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>W. Geremew, V. S. T. Long, N. M. Nam, A. Solano-Herrera</dc:creator>
    </item>
    <item>
      <title>Necessary Optimality Conditions for Integrated Learning and Optimization Problem in Contextual Optimization</title>
      <link>https://arxiv.org/abs/2601.16581</link>
      <description>arXiv:2601.16581v1 Announce Type: new 
Abstract: Integrated learning and optimization (ILO) is a framework in contextual optimization which aims to train a predictive model for the probability distribution of the underlying problem data uncertainty, with the goal of enhancing the quality of downstream decisions. This framework represents a new class of stochastic bilevel programs, which are extensively utilized in the literature of operations research and management science, yet remain underexplored from the perspective of optimization theory. In this paper, we fill the gap. Specifically, we derive the first-order necessary optimality conditions in terms of Mordukhovich limiting subdifferentials. To this end, we formulate the bilevel program as a two-stage stochastic program with variational inequality constraints when the lower-level decision-making problem is convex, and establish an optimality condition via sensitivity analysis of the second-stage value function. In the case where the lower level optimization problem is nonconvex, we adopt the value function approach in the literature of bilevel programs and derive the first-order necessary conditions under stochastic partial calmness conditions. The derived optimality conditions are applied to several existing ILO problems in the literature. These conditions may be used for the design of gradient-based algorithms for solving ILO problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.16581v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuan Tao, Huifu Xu</dc:creator>
    </item>
    <item>
      <title>Stabilization of a Wave-Heat Cascade System</title>
      <link>https://arxiv.org/abs/2601.16610</link>
      <description>arXiv:2601.16610v1 Announce Type: new 
Abstract: We consider the output-feedback stabilization of a one-dimensional cascade coupling a reaction-diffusion equation and a wave equation through an internal term, with Neumann boundary control acting at the wave endpoint. Two measurements are available: the wave velocity at the controlled boundary and a temperature-type observation of the reaction-diffusion component, either distributed or pointwise. Under explicit, necessary and sufficient conditions on the coupling and observation profiles, we show that the generator of the open-loop system is a Riesz-spectral operator. Exploiting this structure, we design a finite-dimensional dynamic output-feedback law, based on a finite number of parabolic modes, which achieves arbitrary exponential decay in both the natural energy space and a stronger parabolic norm. The construction relies on a spectral reduction and a Lyapunov argument in Riesz bases. We also extend the design to pointwise temperature or heat-flux measurements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.16610v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hugo Lhachemi (L2S), Christophe Prieur (GIPSA-INFINITY), Emmanuel Tr\'elat (LJLL)</dc:creator>
    </item>
    <item>
      <title>Projected Gradient Methods with Momentum</title>
      <link>https://arxiv.org/abs/2601.16683</link>
      <description>arXiv:2601.16683v1 Announce Type: new 
Abstract: We focus on the optimization problem with smooth, possibly nonconvex objectives and a convex constraint set for which the Euclidean projection operation is practically available. Focusing on this setting, we carry out a general convergence and complexity analysis for algorithmic frameworks. Consequently, we discuss theoretically sound strategies to integrate momentum information within classical projected gradient type algorithms. One of these approaches is then developed in detail, up to the definition of a tailored algorithm with both theoretical guarantees and reasonable per-iteration cost. The proposed method is finally shown to outperform the standard (spectral) projected gradient method in two different experimental benchmarks, indicating that the addition of momentum terms is as beneficial in the constrained setting as it is in the unconstrained scenario.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.16683v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matteo Lapucci, Giampaolo Liuzzi, Stefano Lucidi, Marco Sciandrone, Diego Scuppa</dc:creator>
    </item>
    <item>
      <title>Resource Allocation Based on Past Incident Patterns</title>
      <link>https://arxiv.org/abs/2601.16702</link>
      <description>arXiv:2601.16702v1 Announce Type: new 
Abstract: We formulate and solve two resource allocation problems motivated by a preparedness question of emergency response services. First, we consider the assignment of vehicles to stations, and, in a second step, assign crews to vehicles. In both cases, we work in a minimax framework and define the objective function for a spatial catchment area as the total risk in this area per resource unit allocated to it. The solutions are explicit and can be calculated in practice by a greedy algorithm that successively allocates a resource unit to an area having maximal relative risk, with suitable tie breaker rules. The approach is illustrated on a data set of incidents reported to the Twente Fire Brigade.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.16702v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>M. N. M. van Lieshout</dc:creator>
    </item>
    <item>
      <title>Optimal Control of Hydro-Electric Power Plants with Uncontrolled Spillways</title>
      <link>https://arxiv.org/abs/2601.16748</link>
      <description>arXiv:2601.16748v1 Announce Type: new 
Abstract: In this paper, we study an optimal control problem for a cascade of hydroelectric power plants with reversible turbines and uncontrolled spillways. The system dynamics are governed by a linear control model subject to path constraints. The aim is to maximize the power production profit while respecting operational restrictions on reservoir water levels. The challenge is the presence of uncontrollable spillways: their discontinuous nature and the fact that they are activated at the state boundary prevent the application of known necessary conditions of optimality. To overcome this, we derive necessary conditions by approximating the original problem through a sequence of standard optimal control problems using exponential penalty functions. The applicability of resulting conditions are illustrated by an example.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.16748v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Maria do Rosario de Pinho, Maria Margarida A. Ferreira, Georgi Smirnov</dc:creator>
    </item>
    <item>
      <title>Approximate controllability on the group of volume-preserving diffeomorphisms</title>
      <link>https://arxiv.org/abs/2601.16939</link>
      <description>arXiv:2601.16939v1 Announce Type: new 
Abstract: We study controlability issues for the group of volume-preserving diffeomorphisms of the torus $\mathbb T^d$ for system $\dot x=f(x)+u(t)$, where $f$ is a fixed divergence free vector field on $\mathbb T^d$ and $u(t)$ are constant vector fields which generate translations of the torus. Main results concern $d$ equals two or three.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.16939v1</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrei Agrachev, Bettina Kazandjian</dc:creator>
    </item>
    <item>
      <title>BONO-Bench: A Comprehensive Test Suite for Bi-objective Numerical Optimization with Traceable Pareto Sets</title>
      <link>https://arxiv.org/abs/2601.16970</link>
      <description>arXiv:2601.16970v1 Announce Type: new 
Abstract: The evaluation of heuristic optimizers on test problems, better known as \emph{benchmarking}, is a cornerstone of research in multi-objective optimization.
  However, most test problems used in benchmarking numerical multi-objective black-box optimizers come from one of two flawed approaches: On the one hand, problems are constructed manually, which result in problems with well-understood optimal solutions, but unrealistic properties and biases.
  On the other hand, more realistic and complex single-objective problems are composited into multi-objective problems, but with a lack of control and understanding of problem properties.
  This paper proposes an extensive problem generation approach for bi-objective numerical optimization problems consisting of the combination of theoretically well-understood convex-quadratic functions into unimodal and multimodal landscapes with and without global structure.
  It supports configuration of test problem properties, such as the number of decision variables, local optima, Pareto front shape, plateaus in the objective space, or degree of conditioning, while maintaining theoretical tractability: The optimal front can be approximated to an arbitrary degree of precision regarding Pareto-compliant performance indicators such as the hypervolume or the exact R2 indicator.
  To demonstrate the generator's capabilities, a test suite of 20 problem categories, called \emph{BONO-Bench}, is created and subsequently used as a basis of an illustrative benchmark study.
  Finally, the general approach underlying our proposed generator, together with the associated test suite, is publicly released in the Python package \texttt{bonobench} to facilitate reproducible benchmarking.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.16970v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lennart Sch\"apermeier, Pascal Kerschke</dc:creator>
    </item>
    <item>
      <title>A Regularized Actor-Critic Algorithm for Bi-Level Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2601.16399</link>
      <description>arXiv:2601.16399v2 Announce Type: cross 
Abstract: We study a structured bi-level optimization problem where the upper-level objective is a smooth function and the lower-level problem is policy optimization in a Markov decision process (MDP). The upper-level decision variable parameterizes the reward of the lower-level MDP, and the upper-level objective depends on the optimal induced policy. Existing methods for bi-level optimization and RL often require second-order information, impose strong regularization at the lower level, or inefficiently use samples through nested-loop procedures. In this work, we propose a single-loop, first-order actor-critic algorithm that optimizes the bi-level objective via a penalty-based reformulation. We introduce into the lower-level RL objective an attenuating entropy regularization, which enables asymptotically unbiased upper-level hyper-gradient estimation without solving the unregularized RL problem exactly. We establish the finite-time and finite-sample convergence of the proposed algorithm to a stationary point of the original, unregularized bi-level optimization problem through a novel lower-level residual analysis under a special type of Polyak-Lojasiewicz condition. We validate the performance of our method through experiments on a GridWorld goal position problem and on happy tweet generation through reinforcement learning from human feedback (RLHF).</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.16399v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sihan Zeng, Sujay Bhatt, Sumitra Ganesh, Alec Koppel</dc:creator>
    </item>
    <item>
      <title>Learning to Optimize by Differentiable Programming</title>
      <link>https://arxiv.org/abs/2601.16510</link>
      <description>arXiv:2601.16510v1 Announce Type: cross 
Abstract: Solving massive-scale optimization problems requires scalable first-order methods with low per-iteration cost. This tutorial highlights a shift in optimization: using differentiable programming not only to execute algorithms but to learn how to design them. Modern frameworks such as PyTorch, TensorFlow, and JAX enable this paradigm through efficient automatic differentiation. Embedding first-order methods within these systems allows end-to-end training that improves convergence and solution quality. Guided by Fenchel-Rockafellar duality, the tutorial demonstrates how duality-informed iterative schemes such as ADMM and PDHG can be learned and adapted. Case studies across LP, OPF, Laplacian regularization, and neural network verification illustrate these gains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.16510v1</guid>
      <category>cs.MS</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liping Tao, Xindi Tong, Chee Wei Tan</dc:creator>
    </item>
    <item>
      <title>Finite-Time Analysis of Gradient Descent for Shallow Transformers</title>
      <link>https://arxiv.org/abs/2601.16514</link>
      <description>arXiv:2601.16514v1 Announce Type: cross 
Abstract: Understanding why Transformers perform so well remains challenging due to their non-convex optimization landscape. In this work, we analyze a shallow Transformer with $m$ independent heads trained by projected gradient descent in the kernel regime. Our analysis reveals two main findings: (i) the width required for nonasymptotic guarantees scales only logarithmically with the sample size $n$, and (ii) the optimization error is independent of the sequence length $T$. This contrasts sharply with recurrent architectures, where the optimization error can grow exponentially with $T$. The trade-off is memory: to keep the full context, the Transformer's memory requirement grows with the sequence length. We validate our theoretical results numerically in a teacher-student setting and confirm the predicted scaling laws for Transformers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.16514v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Enes Arda, Semih Cayci, Atilla Eryilmaz</dc:creator>
    </item>
    <item>
      <title>Generalized Logarithmic Sobolev Inequality by the JKO Scheme</title>
      <link>https://arxiv.org/abs/2601.16620</link>
      <description>arXiv:2601.16620v1 Announce Type: cross 
Abstract: Using a discrete Bakry-{\'E}mery method based on the JKO scheme, relying on the dissipation of entropy and Fisher information along a discrete flow, we establish new generalized logarithmic Sobolev inequality for log-concave measures of the form $e^{-V} under strict convexity assumptions on $V$ . We then show how this method recovers some well-known inequalities. This approach can be viewed as interpolating between the Bakry-{\'E}mery method and optimal transport techniques based on geodesic convexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.16620v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thibault Caillet (IUT Saint-Denis), Fanch Coudreuse (ICJ, UCBL, MMCS)</dc:creator>
    </item>
    <item>
      <title>Distance to nearest skew-symmetric matrix polynomials of bounded rank</title>
      <link>https://arxiv.org/abs/2601.16676</link>
      <description>arXiv:2601.16676v1 Announce Type: cross 
Abstract: We propose an algorithm that approximates a given matrix polynomial of degree $d$ by another skew-symmetric matrix polynomial of a specified rank and degree at most $d$. The algorithm is built on recent advances in the theory of generic eigenstructures and factorizations for skew-symmetric matrix polynomials of bounded rank and degree. Taking into account that the rank of a skew-symmetric matrix polynomial is even, the algorithm works for any prescribed even rank greater than or equal to $2$ and produces a skew-symmetric matrix polynomial of that exact rank. We also adapt the algorithm for matrix pencils to achieve a better performance. Lastly, we present numerical experiments for testing our algorithms and for comparison to the previously known ones.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.16676v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrii Dmytryshyn, Froil\'an M. Dopico, Rakel Hellberg</dc:creator>
    </item>
    <item>
      <title>Noise Resilience and Robust Convergence Guarantees for the Variational Quantum Eigensolver</title>
      <link>https://arxiv.org/abs/2601.16758</link>
      <description>arXiv:2601.16758v1 Announce Type: cross 
Abstract: Variational Quantum Algorithms (VQAs) are a class of hybrid quantum-classical algorithms that leverage on classical optimization tools to find the optimal parameters for a parameterized quantum circuit. One relevant application of VQAs is the Variational Quantum Eigensolver (VQE), which aims at steering the output of the quantum circuit to the ground state of a certain Hamiltonian. Recent works have provided global convergence guarantees for VQEs under suitable local surjectivity and smoothness hypotheses, but little has been done in characterizing convergence of these algorithms when the underlying quantum circuit is affected by noise. In this work, we characterize the effect of different coherent and incoherent noise processes on the optimal parameters and the optimal cost of the VQE, and we study their influence on the convergence guarantees of the algorithm. Our work provides novel theoretical insight into the behavior of parameterized quantum circuits. Furthermore, we accompany our results with numerical simulations implemented via Pennylane.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.16758v1</guid>
      <category>quant-ph</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mirko Legnini, Julian Berberich</dc:creator>
    </item>
    <item>
      <title>ReLU Networks for Model Predictive Control: Network Complexity and Performance Guarantees</title>
      <link>https://arxiv.org/abs/2601.16764</link>
      <description>arXiv:2601.16764v1 Announce Type: cross 
Abstract: Recent years have witnessed a resurgence in using ReLU neural networks (NNs) to represent model predictive control (MPC) policies. However, determining the required network complexity to ensure closed-loop performance remains a fundamental open problem. This involves a critical precision-complexity trade-off: undersized networks may fail to capture the MPC policy, while oversized ones may outweigh the benefits of ReLU network approximation. In this work, we propose a projection-based method to enforce hard constraints and establish a state-dependent Lipschitz continuity property for the optimal MPC cost function, which enables sharp convergence analysis of the closed-loop system. For the first time, we derive explicit bounds on ReLU network width and depth for approximating MPC policies with guaranteed closed-loop performance. To further reduce network complexity and enhance closed-loop performance, we propose a non-uniform error framework with a state-aware scaling function to adaptively adjust both the input and output of the ReLU network. Our contributions provide a foundational step toward certifiable ReLU NN-based MPC.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.16764v1</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xingchen Li, Keyou You</dc:creator>
    </item>
    <item>
      <title>Sample-wise Constrained Learning via a Sequential Penalty Approach with Applications in Image Processing</title>
      <link>https://arxiv.org/abs/2601.16812</link>
      <description>arXiv:2601.16812v1 Announce Type: cross 
Abstract: In many learning tasks, certain requirements on the processing of individual data samples should arguably be formalized as strict constraints in the underlying optimization problem, rather than by means of arbitrary penalties. We show that, in these scenarios, learning can be carried out exploiting a sequential penalty method that allows to properly deal with constraints. The proposed algorithm is shown to possess convergence guarantees under assumptions that are reasonable in deep learning scenarios. Moreover, the results of experiments on image processing tasks show that the method is indeed viable to be used in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.16812v1</guid>
      <category>cs.LG</category>
      <category>eess.IV</category>
      <category>math.OC</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Francesca Lanzillotta, Chiara Albisani, Davide Pucci, Daniele Baracchi, Alessandro Piva, Matteo Lapucci</dc:creator>
    </item>
    <item>
      <title>FedSGM: A Unified Framework for Constraint Aware, Bidirectionally Compressed, Multi-Step Federated Optimization</title>
      <link>https://arxiv.org/abs/2601.16897</link>
      <description>arXiv:2601.16897v1 Announce Type: cross 
Abstract: We introduce FedSGM, a unified framework for federated constrained optimization that addresses four major challenges in federated learning (FL): functional constraints, communication bottlenecks, local updates, and partial client participation. Building on the switching gradient method, FedSGM provides projection-free, primal-only updates, avoiding expensive dual-variable tuning or inner solvers. To handle communication limits, FedSGM incorporates bi-directional error feedback, correcting the bias introduced by compression while explicitly understanding the interaction between compression noise and multi-step local updates. We derive convergence guarantees showing that the averaged iterate achieves the canonical $\boldsymbol{\mathcal{O}}(1/\sqrt{T})$ rate, with additional high-probability bounds that decouple optimization progress from sampling noise due to partial participation. Additionally, we introduce a soft switching version of FedSGM to stabilize updates near the feasibility boundary. To our knowledge, FedSGM is the first framework to unify functional constraints, compression, multiple local updates, and partial client participation, establishing a theoretically grounded foundation for constrained federated learning. Finally, we validate the theoretical guarantees of FedSGM via experimentation on Neyman-Pearson classification and constrained Markov decision process (CMDP) tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.16897v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Antesh Upadhyay, Sang Bin Moon, Abolfazl Hashemi</dc:creator>
    </item>
    <item>
      <title>A Theory of the NEPv Approach for Optimization On the Stiefel Manifold</title>
      <link>https://arxiv.org/abs/2305.00091</link>
      <description>arXiv:2305.00091v5 Announce Type: replace 
Abstract: The NEPv approach has been increasingly used lately for optimization on the Stiefel manifold arising from machine learning. General speaking, the approach first turns the first order optimality condition, also known as the KKT condition, into a nonlinear eigenvalue problem with eigenvector dependency (NEPv) or a nonlinear polar decomposition with orthogonal factor dependency (NPDo) and then solve the nonlinear problem via some variations of the self-consistent-field (SCF) iteration. The difficulty, however, lies in designing a proper SCF iteration so that a maximizer is found at the end. Currently, each use of the approach is very much individualized, especially in its convergence analysis to show that the approach does work or otherwise. In this paper, a unifying framework is established. The framework is built upon some basic assumptions. If the basic assumptions are satisfied, globally convergence is guaranteed to a stationary point and during the SCF iterative process that leads to the stationary point, the objective function increases monotonically. Also a notion of atomic functions is proposed, which include commonly used matrix traces of linear and quadratic forms as special ones. It is shown that the basic assumptions are satisfied by atomic functions and by convex compositions of atomic functions. Together they provide a large collection of objectives for which the NEPv/NPDo approach is guaranteed to work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.00091v5</guid>
      <category>math.OC</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/s10208-024-09687-2</arxiv:DOI>
      <dc:creator>Ren-Cang Li</dc:creator>
    </item>
    <item>
      <title>Frank-Wolfe algorithm for DC optimization problem</title>
      <link>https://arxiv.org/abs/2308.16444</link>
      <description>arXiv:2308.16444v3 Announce Type: replace 
Abstract: In the present paper, we formulate two versions of Frank--Wolfe algorithm or conditional gradient method to solve the DC optimization problem with an adaptive step size. The DC objective function consists of two components; the first is thought to be differentiable with a continuous Lipschitz gradient, while the second is only thought to be convex. The second version is based on the first and employs finite differences to approximate the gradient of the first component of the objective function. In contrast to past formulations that used the curvature/Lipschitz-type constant of the objective function, the step size computed does not require any constant associated with the components. For the first version, we established that the algorithm is well-defined of the algorithm and that every limit point of the generated sequence is a stationary point of the problem. We also introduce the class of weak-star-convex functions and show that, despite the fact that these functions are non-convex in general, the rate of convergence of the first version of the algorithm to minimize these functions is ${\cal O}(1/k)$. The finite difference used to approximate the gradient in the second version of the Frank-Wolfe algorithm is computed with the step-size adaptively updated using two previous iterations. Unlike previous applications of finite difference in the Frank-Wolfe algorithm, which provided approximate gradients with absolute error, the one used here provides us with a relative error, simplifying the algorithm analysis. In this case, we show that all limit points of the generated sequence for the second version of the Frank-Wolfe algorithm are stationary points for the problem under consideration, and we establish that the rate of convergence for the duality gap is ${\cal O}(1/\sqrt{k})$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.16444v3</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>R. D\'iaz Mill\'an, O. P. Ferreira, J. Ugon</dc:creator>
    </item>
    <item>
      <title>Beyond Nonconvexity: A Universal Trust-Region Method with New Analyses</title>
      <link>https://arxiv.org/abs/2311.11489</link>
      <description>arXiv:2311.11489v4 Announce Type: replace 
Abstract: The trust-region (TR) method is renowned historically for its robustness in nonconvex problems and extraordinary numerical performance, but the study of its performance in convex optimization is somehow limited. This paper complements the existing literature by presenting a universal trust-region method that simultaneously incorporates the quadratic regularization and ball constraint. In particular, we introduce a novel descent property tailored for trust-region-type algorithms, enabling us to unify and streamline the analysis for both convex and nonconvex optimization. Our method exhibits an iteration complexity of $\tilde O(\epsilon^{-3/2})$ to find an $\epsilon$-approximate second-order stationary point for nonconvex optimization. Meanwhile, the analysis reveals that the universal method attains an $O(\epsilon^{-1/2})$ complexity bound for convex optimization. Finally, we develop an adaptive universal method to address practical implementations. The numerical results show the effectiveness of our method in both nonconvex and convex problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.11489v4</guid>
      <category>math.OC</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuntian Jiang, Chang He, Chuwen Zhang, Dongdong Ge, Bo Jiang, Yinyu Ye</dc:creator>
    </item>
    <item>
      <title>Asymptotically Optimal Policies for Weakly Coupled Markov Decision Processes</title>
      <link>https://arxiv.org/abs/2406.04751</link>
      <description>arXiv:2406.04751v3 Announce Type: replace 
Abstract: We consider the problem of maximizing the expected average reward obtained over an infinite time horizon by $n$ weakly coupled Markov decision processes. Our setup is a substantial generalization of the multi-armed restless bandit problem that allows for multiple actions and constraints. We establish a connection with a deterministic and continuous-variable control problem where the objective is to maximize the average reward derived from an occupancy measure that represents the empirical distribution of the processes when $n \to \infty$. We show that a solution of this fluid problem can be used to construct policies for the weakly coupled processes that achieve the maximum expected average reward as $n \to \infty$, and we give sufficient conditions for the existence of solutions. Under certain assumptions on the constraints, we prove that these conditions are automatically satisfied if the unconstrained single-process problem admits a suitable unichain and aperiodic policy. In particular, the assumptions include multi-armed restless bandits and a broad class of problems with multiple actions and inequality constraints. Also, the policies can be constructed in an explicit way in these cases. Our theoretical results are complemented by several concrete examples and numerical experiments, which include multichain setups that are covered by the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04751v3</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Diego Goldsztajn, Konstantin Avrachenkov</dc:creator>
    </item>
    <item>
      <title>Domain decomposition for entropic unbalanced optimal transport</title>
      <link>https://arxiv.org/abs/2410.08859</link>
      <description>arXiv:2410.08859v4 Announce Type: replace 
Abstract: Solving large scale entropic optimal transport problems with the Sinkhorn algorithm remains challenging, and domain decomposition has been shown to be an efficient strategy for problems on large grids. Unbalanced optimal transport is a versatile variant of the balanced transport problem and its entropic regularization can be solved with an adapted Sinkhorn algorithm. However, it is a priori unclear how to apply domain decomposition to unbalanced problems since the independence of the cell problems is lost. In this article we show how this difficulty can be overcome at a theoretical and practical level and demonstrate with experiments that domain decomposition is also viable and efficient on large unbalanced entropic transport problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08859v4</guid>
      <category>math.OC</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ismael Medina, The Sang Nguyen, Bernhard Schmitzer</dc:creator>
    </item>
    <item>
      <title>A Gauge Set Framework for Flexible Robustness Design</title>
      <link>https://arxiv.org/abs/2501.14989</link>
      <description>arXiv:2501.14989v4 Announce Type: replace 
Abstract: This paper proposes a unified framework for designing robustness in optimization under uncertainty using gauge sets, convex sets that generalize distance and capture how distributions may deviate from a nominal reference. Representing robustness through a gauge set reweighting formulation brings many classical robustness paradigms under a single convex-analytic perspective. The corresponding dual problem, the upper approximator regularization model, reveals a direct connection between distributional perturbations and objective regularization via polar gauge sets. This framework decouples the design of the nominal distribution, distance metric, and reformulation method, components often entangled in classical approaches, thus enabling modular and composable robustness modeling. We further provide a gauge set algebra toolkit that supports intersection, summation, convex combination, and composition, enabling complex ambiguity structures to be assembled from simpler components. For computational tractability under continuously supported uncertainty, we introduce two general finite-dimensional reformulation methods. The functional parameterization approach guarantees any prescribed gauge-based robustness through flexible selection of function bases, while the envelope representation approach yields exact reformulations under empirical nominal distributions and is asymptotically exact for arbitrary nominal choices. A detailed case study demonstrates how the framework accommodates diverse robustness requirements while admitting multiple tractable reformulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14989v4</guid>
      <category>math.OC</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ningji Wei, Xian Yu, Peter Zhang</dc:creator>
    </item>
    <item>
      <title>Faster Newton Methods for Convex and Nonconvex Optimization in Gradient Complexity</title>
      <link>https://arxiv.org/abs/2501.17488</link>
      <description>arXiv:2501.17488v2 Announce Type: replace 
Abstract: Second-order optimization methods are computationally expensive for large-scale problems. Recently, Doikov, Chayti, and Jaggi (ICML 2023) proposed the LazyCRN method that reduces computation by studying the gradient complexity of second-order methods. Their method can achieve a gradient complexity of $\mathcal{O}( d + d^{1/2} \epsilon^{-3/2})$ and $\mathcal{O}( d + d^{1/2} \epsilon^{-1/2})$ for nonconvex and convex optimization, respectively, where $d$ is the effective dimension and $\epsilon$ is the target precision. Very recently, Adil, Bullins, Sidford, and Zhang (NeurIPS 2025) improved the gradient complexity to $\mathcal{O}( d + d^{1/3} \epsilon^{-3/2} \ln^{18} \epsilon^{-1})$ for nonconvex optimization. However, the tightness of these methods remains open. In this work, we propose new methods that achieve an improved complexity of $\mathcal{O}( d + d^{1/3} \epsilon^{-3/2})$ and $\mathcal{O}( (d + d^{13/21} \epsilon^{-2/7}) \ln d)$ for nonconvex and convex optimization, respectively, improving best-known results for both setups.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.17488v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lesi Chen, Chengchang Liu, Luo Luo, Jingzhao Zhang</dc:creator>
    </item>
    <item>
      <title>On the relationship between MESP and 0/1 D-Opt and their upper bounds</title>
      <link>https://arxiv.org/abs/2511.04350</link>
      <description>arXiv:2511.04350v2 Announce Type: replace 
Abstract: We establish strong connections between two fundamental nonlinear 0/1 optimization problems coming from the area of experimental design, namely maximum entropy sampling and 0/1 D-Optimality. The connections are based on maps between instances, and we analyze the behavior of these maps. Using these maps, we transport basic upper-bounding methods between these two problems, and we are able to establish new domination results and other inequalities relating various basic upper bounds. Further, we establish results relating how different branch-and-bound schemes based on these maps compare. Additionally, we observe some surprising numerical results, where bounding methods that did not seem promising in their direct application to real-data MESP instances, are now useful for MESP instances that come from 0/1 D-Optimality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.04350v2</guid>
      <category>math.OC</category>
      <category>cs.CE</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gabriel Ponte, Marcia Fampa, Jon Lee</dc:creator>
    </item>
    <item>
      <title>Infinite-Dimensional LQ Mean Field Games with Common Noise: Small and Arbitrary Finite Time Horizons</title>
      <link>https://arxiv.org/abs/2601.13493</link>
      <description>arXiv:2601.13493v2 Announce Type: replace 
Abstract: We extend the results of (Liu and Firoozi, 2025), which develops the theory of linear-quadratic (LQ) mean field games (MFGs) in Hilbert spaces, by incorporating a common noise. This common noise is modeled as an infinite-dimensional Wiener process affecting the dynamics of all agents. In the presence of common noise, the mean-field consistency condition is characterized by a system of coupled forward-backward stochastic evolution equations (FBSEEs) in Hilbert spaces, whereas, in its absence it is represented by coupled forward-backward deterministic evolution equations. We establish the existence and uniqueness of solutions to the coupled linear FBSEEs associated with the LQ MFG framework for small time horizons and prove the $\epsilon$-Nash property of the resulting equilibrium strategy. Furthermore, we establish the well-posedness of these coupled linear FBSEEs for arbitrary finite time horizons. Beyond the specific context of MFGs, our analysis also yields a broader contribution by providing, to the best of our knowledge, the first well-posedness result for a class of infinite-dimensional linear FBSEEs, for which only mild solutions exist, over arbitrary finite time horizons.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.13493v2</guid>
      <category>math.OC</category>
      <category>math.FA</category>
      <category>math.PR</category>
      <category>q-fin.MF</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hanchao Liu, Dena Firoozi</dc:creator>
    </item>
    <item>
      <title>Time-Optimal Switching Surfaces for Triple Integrator under Full Box Constraints</title>
      <link>https://arxiv.org/abs/2601.16003</link>
      <description>arXiv:2601.16003v2 Announce Type: replace 
Abstract: Time-optimal control for triple integrator under full box constraints is a fundamental problem in the field of optimal control, which has been widely applied in the industry. However, scenarios involving asymmetric constraints, non-stationary boundary conditions, and active position constraints pose significant challenges. This paper provides a complete characterization of time-optimal switching surfaces for the problem, leading to novel insights into the geometric structure of the optimal control. The active condition of position constraints is derived, which is absent from the literature. An efficient algorithm is proposed, capable of planning time-optimal trajectories under asymmetric full constraints and arbitrary boundary states, with a 100% success rate. Computational time for each trajectory is within approximately 10$\mu$s, achieving a 5-order-of-magnitude reduction compared to optimization-based baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.16003v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yunan Wang, Chuxiong Hu, Zhao Jin</dc:creator>
    </item>
    <item>
      <title>Dimension Reduction in Martingale Optimal Transport: Geometry and Robust Option Pricing</title>
      <link>https://arxiv.org/abs/2309.04947</link>
      <description>arXiv:2309.04947v3 Announce Type: replace-cross 
Abstract: This paper addresses the problem of robust option pricing within the framework of Vectorial Martingale Optimal Transport (VMOT). We investigate the geometry of VMOT solutions for $N$-period market models and demonstrate that, when the number of underlying assets is $d=2$ and the payoff is sub- or supermodular, the extremal model reduces to a single-factor structure in the first period. This structural result allows for a significant dimension reduction, transforming the problem into a more tractable format. We prove that this reduction is specific to the two-asset case and provide counterexamples showing it generally fails for $d \geq 3$. Finally, we exploit this monotonicity to develop a reduced-dimension Sinkhorn algorithm. Numerical experiments demonstrate that this structure-preserving approach reduces computational time by approximately 99\% compared to standard methods while improving accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.04947v3</guid>
      <category>q-fin.MF</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joshua Zoen-Git Hiew, Tongseok Lim, Brendan Pass, Marcelo Cruz de Souza</dc:creator>
    </item>
    <item>
      <title>Sard properties for polynomial maps in infinite dimension</title>
      <link>https://arxiv.org/abs/2407.02296</link>
      <description>arXiv:2407.02296v3 Announce Type: replace-cross 
Abstract: Sard's theorem asserts that the set of critical values of a smooth map from one Euclidean space to another one has measure zero. A version of this result for infinite-dimensional Banach manifolds was proven by Smale for maps with Fredholm differential. It is well-known, however, that when the domain is infinite dimensional and the range is finite dimensional, the result is not true -- even under the assumption that the map is ``polynomial'' -- and a general theory is still lacking. Addressing this issue, in this paper, we provide sharp quantitative criteria for the validity of Sard's theorem in this setting. Our motivation comes from sub-Riemannian geometry and, as an application of our results, we prove the sub-Riemannian Sard conjecture for the restriction of the Endpoint map of Carnot groups to the set of piece-wise real-analytic controls with large enough radius of convergence, and the strong Sard conjecture for the restriction to the set of piece-wise entire controls.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.02296v3</guid>
      <category>math.DG</category>
      <category>math.FA</category>
      <category>math.MG</category>
      <category>math.OC</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Antonio Lerario, Luca Rizzi, Daniele Tiberio</dc:creator>
    </item>
    <item>
      <title>Critical lengths for the linear Kadomtsev-Petviashvili II equation</title>
      <link>https://arxiv.org/abs/2409.03221</link>
      <description>arXiv:2409.03221v3 Announce Type: replace-cross 
Abstract: The critical length phenomenon of the Korteweg-de Vries equation is well known; however, in higher dimensions, it is unknown. This work explores this property in the context of the Kadomtsev-Petviashvili equation, a two-dimensional generalization of the Korteweg-de Vries equation. Specifically, we demonstrate observability inequalities for this equation, which allow us to deduce the exact boundary controllability and boundary exponential stabilization of the linear system, provided that the spatial domain length avoids certain specific values, a direct consequence of the Paley-Wiener theorem. To the best of our knowledge, our work introduces new results by identifying a set of critical lengths for the two-dimensional Kadomtsev-Petviashvili equation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.03221v3</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Roberto de A. Capistrano-Filho (UFPE), Fernando Gallego (UNAL), Ricardo Mu\~noz (UFPE)</dc:creator>
    </item>
    <item>
      <title>Dynamic Pricing with Adversarially-Censored Demands</title>
      <link>https://arxiv.org/abs/2502.06168</link>
      <description>arXiv:2502.06168v2 Announce Type: replace-cross 
Abstract: We study an online dynamic pricing problem where the potential demand at each time period $t=1,2,\ldots, T$ is stochastic and dependent on the price. However, a perishable inventory is imposed at the beginning of each time $t$, censoring the potential demand if it exceeds the inventory level. To address this problem, we introduce a pricing algorithm based on the optimistic estimates of derivatives. We show that our algorithm achieves $\tilde{O}(\sqrt{T})$ optimal regret even with adversarial inventory series. Our findings advance the state-of-the-art in online decision-making problems with censored feedback, offering a theoretically optimal solution against adversarial observations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06168v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>econ.EM</category>
      <category>math.OC</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jianyu Xu, Yining Wang, Xi Chen, Yu-Xiang Wang</dc:creator>
    </item>
    <item>
      <title>Statistical Analysis of Conditional Group Distributionally Robust Optimization with Cross-Entropy Loss</title>
      <link>https://arxiv.org/abs/2507.09905</link>
      <description>arXiv:2507.09905v3 Announce Type: replace-cross 
Abstract: In multi-source learning with discrete labels, distributional heterogeneity across domains poses a central challenge to developing predictive models that transfer reliably to unseen domains. We study multi-source unsupervised domain adaptation, where labeled data are available from multiple source domains and only unlabeled data are observed from the target domain. To address potential distribution shifts, we propose a novel Conditional Group Distributionally Robust Optimization (CG-DRO) framework that learns a classifier by minimizing the worst-case cross-entropy loss over the convex combinations of the conditional outcome distributions from sources domains. We develop an efficient Mirror Prox algorithm for solving the minimax problem and employ a double machine learning procedure to estimate the risk function, ensuring that errors in nuisance estimation contribute only at higher-order rates. We establish fast statistical convergence rates for the empirical CG-DRO estimator by constructing two surrogate minimax optimization problems that serve as theoretical bridges. A distinguishing challenge for CG-DRO is the emergence of nonstandard asymptotics: the empirical CG-DRO estimator may fail to converge to a standard limiting distribution due to boundary effects and system instability. To address this, we introduce a perturbation-based inference procedure that enables uniformly valid inference, including confidence interval construction and hypothesis testing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.09905v3</guid>
      <category>stat.ME</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zijian Guo, Zhenyu Wang, Yifan Hu, Francis Bach</dc:creator>
    </item>
    <item>
      <title>Resolvent Compositions for Positive Linear Operators</title>
      <link>https://arxiv.org/abs/2509.07251</link>
      <description>arXiv:2509.07251v2 Announce Type: replace-cross 
Abstract: Resolvent compositions were recently introduced as monotonicity-preserving operations that combine a set-valued monotone operator and a bounded linear operator. They generalize in particular the notion of a resolvent average. We analyze the resolvent compositions when the monotone operator is a positive linear operator. We establish several new properties, including L\"owner partial order relations, concavity, and asymptotic behavior. In addition, we show that the resolvent composition operations are nonexpansive with respect to the Thompson metric. We also introduce a new form of geometric interpolation and explore its connections to resolvent compositions. Finally, we study two nonlinear equations based on resolvent compositions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.07251v2</guid>
      <category>math.FA</category>
      <category>math.OC</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Diego J. Cornejo</dc:creator>
    </item>
    <item>
      <title>Joint learning of a network of linear dynamical systems via total variation penalization</title>
      <link>https://arxiv.org/abs/2511.18737</link>
      <description>arXiv:2511.18737v2 Announce Type: replace-cross 
Abstract: We consider the problem of joint estimation of the parameters of $m$ linear dynamical systems, given access to single realizations of their respective trajectories, each of length $T$. The linear systems are assumed to reside on the nodes of an undirected and connected graph $G = ([m], \mathcal{E})$, and the system matrices are assumed to either vary smoothly or exhibit small number of ``jumps'' across the edges. We consider a total variation penalized least-squares estimator and derive non-asymptotic bounds on the mean squared error (MSE) which hold with high probability. In particular, the bounds imply for certain choices of well connected $G$ that the MSE goes to zero as $m$ increases, even when $T$ is constant. The theoretical results are supported by extensive experiments on synthetic and real data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.18737v2</guid>
      <category>math.ST</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Claire Donnat, Olga Klopp, Hemant Tyagi</dc:creator>
    </item>
  </channel>
</rss>
