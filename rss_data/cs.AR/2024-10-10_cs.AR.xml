<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.AR updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.AR</link>
    <description>cs.AR updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.AR" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 10 Oct 2024 04:01:49 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Salient Store: Enabling Smart Storage for Continuous Learning Edge Servers</title>
      <link>https://arxiv.org/abs/2410.05435</link>
      <description>arXiv:2410.05435v1 Announce Type: new 
Abstract: As continuous learning based video analytics continue to evolve, the role of efficient edge servers in efficiently managing vast and dynamic datasets is becoming increasingly crucial. Unlike their compute architecture, storage and archival system for these edge servers has often been under-emphasized. This is unfortunate as they contribute significantly to the data management and data movement, especially in a emerging complute landscape where date storage and data protection has become one of the key concerns. To mitigate this, we propose Salient Store that specifically focuses on the integration of Computational Storage Devices (CSDs) into edge servers to enhance data processing and management, particularly in continuous learning scenarios, prevalent in fields such as autonomous driving and urban mobility. Our research, gos beyond the compute domain, and identifies the gaps in current storage system designs. We proposes a framework that aligns more closely with the growing data demands. We present a detailed analysis of data movement challenges within the archival workflows and demonstrate how the strategic integration of CSDs can significantly optimize data compression, encryption, as well as other data management tasks, to improve overall system performance. By leveraging the parallel processing capabilities of FPGAs and the high internal bandwidth of SSDs, Salient Store reduces the communication latency and data volume by ~6.2x and ~6.1x, respectively. This paper provides a comprehensive overview of the potential of CSDs to revolutionize storage, making them not just data repositories but active participants in the computational process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05435v1</guid>
      <category>cs.AR</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Cyan Subhra Mishra, Deeksha Chaudhary, Jack Sampson, Mahmut Taylan Knademir, Chita Das</dc:creator>
    </item>
    <item>
      <title>OpenEarable ExG: Open-Source Hardware for Ear-Based Biopotential Sensing Applications</title>
      <link>https://arxiv.org/abs/2410.06533</link>
      <description>arXiv:2410.06533v1 Announce Type: new 
Abstract: While traditional earphones primarily offer private audio spaces, so-called "earables" emerged to offer a variety of sensing capabilities. Pioneering platforms like OpenEarable have introduced novel sensing platforms targeted at the ears, incorporating various sensors. The proximity of the ears to the eyes, brain, and facial muscles has also sparked investigation into sensing biopotentials. However, currently there is no platform available that is targeted at the ears to sense biopotentials. To address this gap, we introduce OpenEarable ExG - an open-source hardware platform designed to measure biopotentials in and around the ears. OpenEarable ExG can be freely configured and has up to 7 sensing channels. We initially validate OpenEarable ExG in a study with a left-right in-ear dual-electrode montage setup with 3 participants. Our results demonstrate the successful detection of smooth pursuit eye movements via Electrooculography (EOG), alpha brain activity via Electroencephalography (EEG), and jaw clenching via Electromyography (EMG). OpenEarable ExG is part of the OpenEarable initiative and is fully open-source under MIT license.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06533v1</guid>
      <category>cs.AR</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3675094.3678480</arxiv:DOI>
      <arxiv:journal_reference>UbiComp '24: Companion of the 2024 on ACM International Joint Conference on Pervasive and Ubiquitous Computing, Pages 916 - 92</arxiv:journal_reference>
      <dc:creator>Philipp Lepold, Tobias R\"oddiger, Tobias King, Kai Kunze, Christoph Maurer, Michael Beigl</dc:creator>
    </item>
    <item>
      <title>Evaluation of Run-Time Energy Efficiency using Controlled Approximation in a RISC-V Core</title>
      <link>https://arxiv.org/abs/2410.07027</link>
      <description>arXiv:2410.07027v1 Announce Type: new 
Abstract: The limited energy available in most embedded systems poses a significant challenge in enhancing the performance of embedded processors and microcontrollers. One promising approach to address this challenge is the use of approximate computing, which can be implemented in both hardware and software layers to balance the trade-off between performance and power consumption. In this study, the impact of dynamic hardware approximation methods on the run-time energy efficiency of a RISC-V embedded processor with specialized features for approximate computing is investigated. The results indicate that the platform achieves an average energy efficiency of 13.3 pJ/instruction at a 500MHz clock frequency adhering approximation in 45nm CMOS technology. Compared to accurate circuits and computation, the approximate computing techniques in the processing core resulted in a significant improvement of 9.21% in overall energy efficiency, 60.83% in multiplication instructions, 14.64% in execution stage, and 9.23% in overall power consumption.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07027v1</guid>
      <category>cs.AR</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arvin Delavari, Faraz Ghoreishy, Hadi Shahriar Shahhoseini, Sattar Mirzakuchaki</dc:creator>
    </item>
    <item>
      <title>Deep Learning and Machine Learning with GPGPU and CUDA: Unlocking the Power of Parallel Computing</title>
      <link>https://arxiv.org/abs/2410.05686</link>
      <description>arXiv:2410.05686v1 Announce Type: cross 
Abstract: This book presents a comprehensive exploration of GPGPU (General Purpose Graphics Processing Unit) and its applications in deep learning and machine learning. It focuses on how parallel computing, particularly through the use of CUDA (Compute Unified Device Architecture), can unlock unprecedented computational power for complex tasks. The book provides detailed discussions on CPU and GPU architectures, data flow in deep learning, and advanced GPU features like streams, concurrency, and dynamic parallelism. Furthermore, it delves into practical applications of GPGPU in various domains such as scientific computing, machine learning acceleration, real-time rendering, and cryptocurrency mining. The authors also emphasize the importance of selecting the right parallel architecture (e.g., GPU, FPGA, TPU, ASIC) based on specific tasks, offering insights into optimizing algorithms for these platforms. The book also provides practical examples with popular machine learning frameworks like PyTorch, TensorFlow, and XGBoost, demonstrating how to efficiently leverage GPU resources in both training and inference. This resource is valuable for both beginners and advanced readers who are looking to deepen their understanding of GPU-based parallel computing and its significant role in modern machine learning and AI applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05686v1</guid>
      <category>cs.DC</category>
      <category>cs.AR</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ming Li, Ziqian Bi, Tianyang Wang, Yizhu Wen, Qian Niu, Junyu Liu, Benji Peng, Sen Zhang, Xuanhe Pan, Jiawei Xu, Jinlang Wang, Keyu Chen, Caitlyn Heqi Yin, Pohsun Feng, Ming Liu</dc:creator>
    </item>
    <item>
      <title>LoopTree: Exploring the Fused-layer Dataflow Accelerator Design Space</title>
      <link>https://arxiv.org/abs/2409.13625</link>
      <description>arXiv:2409.13625v3 Announce Type: replace 
Abstract: Latency and energy consumption are key metrics in the performance of deep neural network (DNN) accelerators. A significant factor contributing to latency and energy is data transfers. One method to reduce transfers or data is reusing data when multiple operations use the same data. Fused-layer accelerators reuse data across operations in different layers by retaining intermediate data in on-chip buffers, which has been shown to reduce energy consumption and latency. Moreover, the intermediate data is often tiled (i.e., broken into chunks) to reduce the on-chip buffer capacity required to reuse the data. Because on-chip buffer capacity is frequently more limited than computation units, fused-layer dataflow accelerators may also recompute certain parts of the intermediate data instead of retaining them in a buffer. Achieving efficient trade-offs between on-chip buffer capacity, off-chip transfers, and recomputation requires systematic exploration of the fused-layer dataflow design space. However, prior work only explored a subset of the design space, and more efficient designs are left unexplored.
  In this work, we propose (1) a more extensive design space that has more choices in terms of tiling, data retention, recomputation and, importantly, allows us to explore them in combination, (2) a taxonomy to systematically specify designs, and (3) a model, LoopTree, to evaluate the latency, energy consumption, buffer capacity requirements, and off-chip transfers of designs in this design space. We validate our model against a representative set of prior architectures, achieving a worst-case 4% error. Finally, we present case studies that show how exploring this larger space results in more efficient designs (e.g., up to a 10$\times$ buffer capacity reduction to achieve the same off-chip transfers).</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.13625v3</guid>
      <category>cs.AR</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TCASAI.2024.3461716)</arxiv:DOI>
      <dc:creator>Michael Gilbert, Yannan Nellie Wu, Joel S. Emer, Vivienne Sze</dc:creator>
    </item>
    <item>
      <title>Secure Software/Hardware Hybrid In-Field Testing for System-on-Chip</title>
      <link>https://arxiv.org/abs/2410.05109</link>
      <description>arXiv:2410.05109v2 Announce Type: replace 
Abstract: Modern Systems-on-Chip (SoCs) incorporate built-in self-test (BIST) modules deeply integrated into the device's intellectual property (IP) blocks. Such modules handle hardware faults and defects during device operation. As such, BIST results potentially reveal the internal structure and state of the device under test (DUT) and hence open attack vectors. So-called result compaction can overcome this vulnerability by hiding the BIST chain structure but introduces the issues of aliasing and invalid signatures. Software-BIST provides a flexible solution, that can tackle these issues, but suffers from limited observability and fault coverage. In this paper, we hence introduce a low-overhead software/hardware hybrid approach that overcomes the mentioned limitations. It relies on (a) keyed-hash message authentication code (KMAC) available on the SoC providing device-specific secure and valid signatures with zero aliasing and (b) the SoC processor for test scheduling hence increasing DUT availability. The proposed approach offers both on-chip- and remote-testing capabilities. We showcase a RISC-V-based SoC to demonstrate our approach, discussing system overhead and resulting compaction rates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05109v2</guid>
      <category>cs.AR</category>
      <category>cs.CR</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Saleh Mulhem, Christian Ewert, Andrija Neskovic, Amrit Sharma Poudel, Christoph H\"ubner, Mladen Berekovic, Rainer Buchty</dc:creator>
    </item>
    <item>
      <title>Research Directions for Verifiable Crypto-Physically Secure TEEs</title>
      <link>https://arxiv.org/abs/2410.03183</link>
      <description>arXiv:2410.03183v2 Announce Type: replace-cross 
Abstract: A niche corner of the Web3 world is increasingly making use of hardware-based Trusted Execution Environments (TEEs) to build decentralized infrastructure. One of the motivations to use TEEs is to go beyond the current performance limitations of cryptography-based alternatives such as zero-knowledge proofs (ZKP), fully homomorphic encryption (FHE), and multi-party computation (MPC). Despite their appealing advantages, current TEEs suffer from serious limitations as they are not secure against physical attacks, and their attestation mechanism is rooted in the chip manufacturer's trust. As a result, Web3 applications have to rely on cloud infrastruture to act as trusted guardians of hardware-based TEEs and have to accept to trust chip manufacturers. This work aims at exploring how we could potentially architect and implement chips that would be secure against physical attacks and would not require putting trust in chip manufacturers. One goal of this work is to motivate the Web3 movement to acknowledge and leverage the substantial amount of relevant hardware research that already exists. In brief, a combination of: (1) physical unclonable functions (PUFs) to secure the root-of-trust; (2) masking and redundancy techniques to secure computations; (3) open source hardware and imaging techniques to verify that a chip matches its expected design; can help move towards attesting that a given TEE can be trusted without the need to trust a cloud provider and a chip manufacturer.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03183v2</guid>
      <category>cs.CR</category>
      <category>cs.AR</category>
      <category>cs.ET</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sylvain Bellemare</dc:creator>
    </item>
  </channel>
</rss>
