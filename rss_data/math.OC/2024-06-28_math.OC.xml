<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 28 Jun 2024 04:00:04 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 28 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Markov Decision Process and Approximate Dynamic Programming for a Patient Assignment Scheduling problem</title>
      <link>https://arxiv.org/abs/2406.18618</link>
      <description>arXiv:2406.18618v1 Announce Type: new 
Abstract: We study the Patient Assignment Scheduling (PAS) problem in a random environment that arises in the management of patient flow in the hospital systems, due to the stochastic nature of the arrivals as well as the Length of Stay distribution. We develop a Markov Decision Process (MDP) which aims to assign the newly arrived patients in an optimal way so as to minimise the total expected long-run cost per unit time over an infinite horizon. We assume Poisson arrival rates that depend on patient types, and Length of Stay distributions that depend on whether patients stay in their primary wards or not. Since the instances of realistic size of this problem are not easy to solve, we develop numerical methods based on Approximate Dynamic Programming. We illustrate the theory with numerical examples with parameters obtained by fitting to data from a tertiary referral hospital in Australia, and demonstrate the application potential of our methodology under practical considerations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.18618v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>math.PR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Malgorzata M. O'Reilly, Sebastian Krasnicki, James Montgomery, Mojtaba Heydar, Richard Turner, Pieter Van Dam, Peter Maree</dc:creator>
    </item>
    <item>
      <title>A simple and improved algorithm for noisy, convex, zeroth-order optimisation</title>
      <link>https://arxiv.org/abs/2406.18672</link>
      <description>arXiv:2406.18672v1 Announce Type: new 
Abstract: In this paper, we study the problem of noisy, convex, zeroth order optimisation of a function $f$ over a bounded convex set $\bar{\mathcal X}\subset \mathbb{R}^d$. Given a budget $n$ of noisy queries to the function $f$ that can be allocated sequentially and adaptively, our aim is to construct an algorithm that returns a point $\hat x\in \bar{\mathcal X}$ such that $f(\hat x)$ is as small as possible. We provide a conceptually simple method inspired by the textbook center of gravity method, but adapted to the noisy and zeroth order setting. We prove that this method is such that the $f(\hat x) - \min_{x\in \bar{\mathcal X}} f(x)$ is of smaller order than $d^2/\sqrt{n}$ up to poly-logarithmic terms. We slightly improve upon existing literature, where to the best of our knowledge the best known rate is in [Lattimore, 2024] is of order $d^{2.5}/\sqrt{n}$, albeit for a more challenging problem. Our main contribution is however conceptual, as we believe that our algorithm and its analysis bring novel ideas and are significantly simpler than existing approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.18672v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexandra Carpentier</dc:creator>
    </item>
    <item>
      <title>Learning to Remove Cuts in Integer Linear Programming</title>
      <link>https://arxiv.org/abs/2406.18781</link>
      <description>arXiv:2406.18781v1 Announce Type: new 
Abstract: Cutting plane methods are a fundamental approach for solving integer linear programs (ILPs). In each iteration of such methods, additional linear constraints (cuts) are introduced to the constraint set with the aim of excluding the previous fractional optimal solution while not affecting the optimal integer solution. In this work, we explore a novel approach within cutting plane methods: instead of only adding new cuts, we also consider the removal of previous cuts introduced at any of the preceding iterations of the method under a learnable parametric criteria. We demonstrate that in fundamental combinatorial optimization settings such cut removal policies can lead to significant improvements over both human-based and machine learning-guided cut addition policies even when implemented with simple models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.18781v1</guid>
      <category>math.OC</category>
      <category>cs.DM</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pol Puigdemont, Stratis Skoulakis, Grigorios Chrysos, Volkan Cevher</dc:creator>
    </item>
    <item>
      <title>Fast Convergence of Frank-Wolfe algorithms on polytopes</title>
      <link>https://arxiv.org/abs/2406.18789</link>
      <description>arXiv:2406.18789v1 Announce Type: new 
Abstract: We provide a template to derive convergence rates for the following popular versions of the Frank-Wolfe algorithm on polytopes: vanilla Frank-Wolfe, Frank-Wolfe with away steps, Frank-Wolfe with blended pairwise steps, and Frank-Wolfe with in-face directions. Our template shows how the convergence rates follow from two affine-invariant properties of the problem, namely, error bound and extended curvature. These properties depend solely on the polytope and objective function but not on any affine-dependent object like norms. For each one of the above algorithms, we derive rates of convergence ranging from sublinear to linear depending on the degree of the error bound.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.18789v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Elias Wirth, Javier Pena, Sebastian Pokutta</dc:creator>
    </item>
    <item>
      <title>Schur Stability of Matrix Segment via Bialternate Product</title>
      <link>https://arxiv.org/abs/2406.18973</link>
      <description>arXiv:2406.18973v1 Announce Type: new 
Abstract: In this study, the problem of robust Schur stability of $n\times n$ dimensional matrix segments by using the bialternate product of matrices is considered. It is shown that the problem can be reduced to the existence of negative eigenvalues of two of three specially constructed matrices and the existence of eigenvalues belonging to the interval $[1,\infty)$ of the third matrix. A necessary and sufficient condition is given for the convex combinations of two stable matrices with rank one difference to be robust Schur stable. It is shown that the robust stability of the convex hull of a finite number of matrices whose two-by-two differences are of rank $1$ is equivalent to the robust stability of the segments formed by these matrices. Examples of applying the obtained results are given.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.18973v1</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <category>math.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Serife Yilmaz</dc:creator>
    </item>
    <item>
      <title>Optimal routing and communication strategies for autonomous reconnaissance missions</title>
      <link>https://arxiv.org/abs/2406.19001</link>
      <description>arXiv:2406.19001v1 Announce Type: new 
Abstract: We consider an autonomous reconnaissance mission where a drone has to visit several points of interest and communicate the intel back to the base. At every point of interest, the drone has the option to either send back all available info, or continue to the next point of interest and communicate at a later stage. Both choices have a chance of detection, meaning the mission fails. We wish to maximize the expected amount of information gathered by the mission. This is modeled by a routing problem in a weighted graph. We discuss the ILP formulation of this problem, show it is NP-complete, and use a genetic algorithm to find good solutions for up to ten points of interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19001v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Riley Badenbroek, Relinde Jurrius, Lander Verlinde</dc:creator>
    </item>
    <item>
      <title>A numerical solution approach for non-smooth optimal control problems based on the Pontryagin maximum principle</title>
      <link>https://arxiv.org/abs/2406.19010</link>
      <description>arXiv:2406.19010v1 Announce Type: new 
Abstract: We consider nonsmooth optimal control problems subject to a linear elliptic partial differential equation with homogeneous Dirichlet boundary conditions. It is well-known that local solutions satisfy the celebrated Pontryagin maximum principle. In this note, we will investigate an optimization method that is based on the maximum principle. We prove that the discrepancy in the maximum principle vanishes along the resulting sequence of iterates. Numerical experiments confirm the theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19010v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Daniel Wachsmuth</dc:creator>
    </item>
    <item>
      <title>Task-splitting in home healthcare routing and scheduling</title>
      <link>https://arxiv.org/abs/2406.19288</link>
      <description>arXiv:2406.19288v1 Announce Type: new 
Abstract: This paper introduces the concept of task-splitting into home healthcare (HHC) routing and scheduling. It focuses on the design of routes and timetables for caregivers providing services at patients' homes. Task-splitting is the division of a (lengthy) patient visit into separate visits that can be performed by different caregivers at different times. The resulting split parts may have reduced caregiver qualification requirements, relaxed visiting time windows, or a shorter/longer combined duration. However, additional temporal dependencies can arise between them. To incorporate task-splitting decisions into the planning process, we introduce two different mixed integer linear programming formulations, a Miller-Tucker-Zemlin and a time-indexed variant. These formulations aim to minimize operational costs while simultaneously deciding which visits to split and imposing a potentially wide range of temporal dependencies. We also propose pre-processing routines for the time-indexed formulation and two heuristic procedures. These methods are embedded into the branch-and-bound approach as primal and improvement heuristics. The results of our computational study demonstrate the additional computational difficulty introduced by task-splitting and the associated additional synchronization, and the usefulness of the proposed heuristic procedures. From a planning perspective, our results indicate that introducing task-splitting reduces staff requirements, decreases HHC operational costs, and allows caregivers to spend relatively more time on tasks aligned with their qualifications. Moreover, we observe that the potential of task-splitting is not specific to the chosen planning objective; it can also be beneficial when minimizing travel time instead.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19288v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Loek van Montfort, Wout Dullaert, Markus Leitner</dc:creator>
    </item>
    <item>
      <title>Grassmannian optimization is NP-hard</title>
      <link>https://arxiv.org/abs/2406.19377</link>
      <description>arXiv:2406.19377v1 Announce Type: new 
Abstract: We show that unconstrained quadratic optimization over a Grassmannian $\operatorname{Gr}(k,n)$ is NP-hard. Our results cover all scenarios: (i) when $k$ and $n$ are both allowed to grow; (ii) when $k$ is arbitrary but fixed; (iii) when $k$ is fixed at its lowest possible value $1$. We then deduce the NP-hardness of unconstrained cubic optimization over the Stiefel manifold $\operatorname{V}(k,n)$ and the orthogonal group $\operatorname{O}(n)$. As an addendum we demonstrate the NP-hardness of unconstrained quadratic optimization over the Cartan manifold, i.e., the positive definite cone $\mathbb{S}^n_{\scriptscriptstyle++}$ regarded as a Riemannian manifold, another popular example in manifold optimization. We will also establish the nonexistence of $\mathrm{FPTAS}$ in all cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19377v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zehua Lai, Lek-Heng Lim, Ke Ye</dc:creator>
    </item>
    <item>
      <title>Generalized Cuts and Grothendieck Covers: a Primal-Dual Approximation Framework Extending the Goemans--Williamson Algorithm</title>
      <link>https://arxiv.org/abs/2406.18670</link>
      <description>arXiv:2406.18670v1 Announce Type: cross 
Abstract: We provide a primal-dual framework for randomized approximation algorithms utilizing semidefinite programming (SDP) relaxations. Our framework pairs a continuum of APX-complete problems including MaxCut, Max2Sat, MaxDicut, and more generally, Max-Boolean Constraint Satisfaction and MaxQ (maximization of a positive semidefinite quadratic form over the hypercube) with new APX-complete problems which are stated as convex optimization problems with exponentially many variables. These new dual counterparts, based on what we call Grothendieck covers, range from fractional cut covering problems (for MaxCut) to tensor sign covering problems (for MaxQ). For each of these problem pairs, our framework transforms the randomized approximation algorithms with the best known approximation factors for the primal problems to randomized approximation algorithms for their dual counterparts with reciprocal approximation factors which are tight with respect to the Unique Games Conjecture. For each APX-complete pair, our algorithms solve a single SDP relaxation and generate feasible solutions for both problems which also provide approximate optimality certificates for each other. Our work utilizes techniques from areas of randomized approximation algorithms, convex optimization, spectral sparsification, as well as Chernoff-type concentration results for random matrices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.18670v1</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nathan Benedetto Proen\c{c}a, Marcel K. de Carli Silva, Cristiane M. Sato, Levent Tun\c{c}el</dc:creator>
    </item>
    <item>
      <title>Sharp isoanisotropic estimates for fundamental frequencies of membranes and connections with shapes</title>
      <link>https://arxiv.org/abs/2406.18683</link>
      <description>arXiv:2406.18683v1 Announce Type: cross 
Abstract: The underlying motivation of the present work lies on one of the cornerstone problems in spectral optimization that consists of determining sharp lower and upper uniform estimates for fundamental frequencies of a set of uniformly elliptic operators on a given membrane. Our approach allows to give a complete solution of the problem for the general class of anisotropic operators in divergence form generated by arbitrary norms on R^2, including the computation of optimal constants and the characterization of all anisotropic extremizers. Such achievements demand that isoanisotropic type problems be addressed within the broader environment of nonnegative, convex and 1-homogeneous anisotropies and involve a deep and fine analysis of least energy levels associated to anisotropies with maximum degeneracy. As a central outcome we find out a key close relation between shapes and fundamental frequencies for rather degenerate elliptic operators. Our findings also permit to establish that the supremum of anisotropic fundamental frequencies over all fixed-area membranes is infinite for any nonzero anisotropy. This particularly proves the well-known maximization conjecture for fundamental frequencies of the p-laplacian for any p other than 2. Our new sharp lower estimate is just the planar isoanisotropic counterpart of the Faber-Krahn isoperimetric inequality and for the associated optimal constant we provide optimal geometric controls through isodiametric and isoperimetric shape optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.18683v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Raul Fernandes Horta, Marcos Montenegro</dc:creator>
    </item>
    <item>
      <title>Singular $p$-biharmonic problem with the Hardy potential</title>
      <link>https://arxiv.org/abs/2406.18982</link>
      <description>arXiv:2406.18982v1 Announce Type: cross 
Abstract: The aim of this paper is to study existence results for a singular problem involving the $p$-biharmonic operator and the Hardy potential. More precisely, by combining monotonicity arguments with the variational method, the existence of solutions is established. By using the Nehari manifold method, the multiplicity of solutions is proved. An example is also given, to illustrate the importance of these results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.18982v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.15388/namc.2024.29.35410</arxiv:DOI>
      <arxiv:journal_reference>Nonlinear Anal. Model. Control 29 (2024), 21 pp</arxiv:journal_reference>
      <dc:creator>A. Drissi, A. Ghanmi, D. D. Repov\v{s}</dc:creator>
    </item>
    <item>
      <title>Semi-definite optimization of the measured relative entropies of quantum states and channels</title>
      <link>https://arxiv.org/abs/2406.19060</link>
      <description>arXiv:2406.19060v1 Announce Type: cross 
Abstract: The measured relative entropies of quantum states and channels find operational significance in quantum information theory as achievable error rates in hypothesis testing tasks. They are of interest in the near term, as they correspond to hybrid quantum-classical strategies with technological requirements far less challenging to implement than required by the most general strategies allowed by quantum mechanics. In this paper, we prove that these measured relative entropies can be calculated efficiently by means of semi-definite programming, by making use of variational formulas for the measured relative entropies of states and semi-definite representations of the weighted geometric mean and the operator connection of the logarithm. Not only do the semi-definite programs output the optimal values of the measured relative entropies of states and channels, but they also provide numerical characterizations of optimal strategies for achieving them, which is of significant practical interest for designing hypothesis testing protocols.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19060v1</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math-ph</category>
      <category>math.IT</category>
      <category>math.MP</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zixin Huang, Mark M. Wilde</dc:creator>
    </item>
    <item>
      <title>A Distributed Iterative Tikhonov Method for Networked Monotone Aggregative Hierarchical Stochastic Games</title>
      <link>https://arxiv.org/abs/2304.03651</link>
      <description>arXiv:2304.03651v2 Announce Type: replace 
Abstract: We consider a class of nonsmooth aggregative games over networks in stochastic regimes, where each player is characterized by a composite cost function $f_i+r_i$, $f_i$ is a smooth expectation-valued function dependent on its own strategy and an aggregate function of rival strategies, and $r_i$ is a nonsmooth convex function of its strategy with an efficient prox-evaluation. We design a fully distributed iterative proximal stochastic gradient method overlaid by a Tikhonov regularization, where each player may independently choose its steplengths and regularization parameters while meeting some coordination requirements. Under a monotonicity assumption on the pseudo-gradient mapping, we prove the almost sure convergence to the least-norm Nash equilibrium. In addition, when each $r_i$ is an indicator function of a compact convex set, we establish the convergence rate associated with the expected gap function at the time-averaged sequence. We further establish high probability bounds for the gap function via both Markov's inequality as well as a more refined argument that leverages Azuma's inequality. Furthermore, we consider the extension to the private hierarchical regime where each player is a leader with respect to a collection of private followers competing in a strongly monotone game, parametrized by leader decisions. By leveraging a convolution-smoothing framework, we present amongst the first fully distributed schemes for computing a Nash equilibrium of a game complicated by such a hierarchical structure. Based on this framework, we extend the rate statements to accommodate the computation of a hierarchical stochastic Nash equilibrium by using a Fitzpatrick gap function. Finally, we validate the proposed methods on a networked Nash-Cournot equilibrium problem and a hierarchical generalization, observing that regularization has a beneficial impact on empirical behavior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.03651v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jinlong Lei, Uday V. Shanbhag, Jie Chen</dc:creator>
    </item>
    <item>
      <title>Some Primal-Dual Theory for Subgradient Methods for Strongly Convex Optimization</title>
      <link>https://arxiv.org/abs/2305.17323</link>
      <description>arXiv:2305.17323v4 Announce Type: replace 
Abstract: We consider (stochastic) subgradient methods for strongly convex but potentially nonsmooth non-Lipschitz optimization. We provide new equivalent dual descriptions (in the style of dual averaging) for the classic subgradient method, the proximal subgradient method, and the switching subgradient method. These equivalences enable $O(1/T)$ convergence guarantees in terms of both their classic primal gap and a not previously analyzed dual gap for strongly convex optimization. Consequently, our theory provides these classic methods with simple, optimal stopping criteria and optimality certificates at no added computational cost. Our results apply to a wide range of stepsize selections and of non-Lipschitz ill-conditioned problems where the early iterations of the subgradient method may diverge exponentially quickly (a phenomenon which, to the best of our knowledge, no prior works address). Even in the presence of such undesirable behaviors, our theory still ensures and bounds eventual convergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.17323v4</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Benjamin Grimmer, Danlin Li</dc:creator>
    </item>
    <item>
      <title>A Branch-and-Cut-and-Price Algorithm for Cutting Stock and Related Problems</title>
      <link>https://arxiv.org/abs/2308.03595</link>
      <description>arXiv:2308.03595v2 Announce Type: replace 
Abstract: We present a branch-and-cut-and-price framework to solve Cutting Stock Problems with strong relaxations using Set Covering (Packing) Formulations, which are solved by column generation. The main contributions of this paper include an extended Ryan-Foster scheme, which allows us to use this powerful branching scheme even in non-binary problems by using a conflict propagation lemma; a fast column generation process based on a diversification strategy; custom primal heuristics, enabling us to find optimal solutions for several open instances; and a technique to use a smaller feasibility tolerance in floating-point linear programming solvers, combined with numerically safe methods to produce stronger and safer lower bounds. Additional performance-improving strategies include a technique that controls the height of the branch-and-bound tree; a variable selection algorithm based on branching history; a new set of dual inequalities; insights to obtain a lean model; and the subset-row inequalities. By employing this comprehensive framework, we overcame the current state-of-the-art concerning the following problems: Cutting Stock, Skiving Stock, Ordered Open-End Bin Packing, Class-Constrained Bin Packing, and Identical Parallel Machines Scheduling with Minimum Makespan. Additionally, a new challenging benchmark for Cutting Stock is introduced.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.03595v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Renan F. F. da Silva, Rafael C. S. Schouery</dc:creator>
    </item>
    <item>
      <title>Direct Approach of Linear-Quadratic Stackelberg Mean Field Games of Backward-Forward Stochastic Systems</title>
      <link>https://arxiv.org/abs/2401.15835</link>
      <description>arXiv:2401.15835v3 Announce Type: replace 
Abstract: This paper is concerned with a linear-quadratic (LQ) Stackelberg mean field games of backward-forward stochastic systems, involving a backward leader and a substantial number of forward followers. The leader initiates by providing its strategy, and subsequently, each follower optimizes its individual cost. A direct approach is applied to solve this game. Initially, we address a mean field game problem, determining the optimal response of followers to the leader's strategy. Following the implementation of followers' strategies, the leader faces an optimal control problem driven by high-dimensional forward-backward stochastic differential equations (FBSDEs). Through the decoupling of the high-dimensional Hamiltonian system using mean field approximations, we formulate a set of decentralized strategies for all players, demonstrated to be an $(\epsilon_1, \epsilon_2)$-Stackelberg equilibrium.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.15835v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Wenyu Cong, Jingtao Shi</dc:creator>
    </item>
    <item>
      <title>The Price of Adaptivity in Stochastic Convex Optimization</title>
      <link>https://arxiv.org/abs/2402.10898</link>
      <description>arXiv:2402.10898v3 Announce Type: replace 
Abstract: We prove impossibility results for adaptivity in non-smooth stochastic convex optimization. Given a set of problem parameters we wish to adapt to, we define a "price of adaptivity" (PoA) that, roughly speaking, measures the multiplicative increase in suboptimality due to uncertainty in these parameters. When the initial distance to the optimum is unknown but a gradient norm bound is known, we show that the PoA is at least logarithmic for expected suboptimality, and double-logarithmic for median suboptimality. When there is uncertainty in both distance and gradient norm, we show that the PoA must be polynomial in the level of uncertainty. Our lower bounds nearly match existing upper bounds, and establish that there is no parameter-free lunch.
  En route, we also establish tight upper and lower bounds for (known-parameter) high-probability stochastic convex optimization with heavy-tailed and bounded noise, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.10898v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yair Carmon, Oliver Hinder</dc:creator>
    </item>
    <item>
      <title>Decentralized Stochastic Subgradient Methods for Nonsmooth Nonconvex Optimization</title>
      <link>https://arxiv.org/abs/2403.11565</link>
      <description>arXiv:2403.11565v2 Announce Type: replace 
Abstract: In this paper, we concentrate on decentralized optimization problems with nonconvex and nonsmooth objective functions, especially on the decentralized training of nonsmooth neural networks. We introduce a unified framework to analyze the global convergence of decentralized stochastic subgradient-based methods. We prove the global convergence of our proposed framework under mild conditions, by establishing that the generated sequence asymptotically approximates the trajectories of its associated differential inclusion. Furthermore, we establish that our proposed framework covers a wide range of existing efficient decentralized subgradient-based methods, including decentralized stochastic subgradient descent (DSGD), DSGD with gradient-tracking technique (DSGD-T), and DSGD with momentum (DSGD-M). In addition, we introduce the sign map to regularize the update directions in DSGD-M, and show it is enclosed in our proposed framework. Consequently, our convergence results establish, for the first time, global convergence of these methods when applied to nonsmooth nonconvex objectives. Preliminary numerical experiments demonstrate that our proposed framework yields highly efficient decentralized subgradient-based methods with convergence guarantees in the training of nonsmooth neural networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11565v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Siyuan Zhang, Nachuan Xiao, Xin Liu</dc:creator>
    </item>
    <item>
      <title>Arrow of Time in Estimation and Control: Duality Theory Beyond the Linear Gaussian Model</title>
      <link>https://arxiv.org/abs/2405.07650</link>
      <description>arXiv:2405.07650v2 Announce Type: replace 
Abstract: Duality between estimation and control is a foundational concept in Control Theory. Most students learn about the elementary duality -- between observability and controllability -- in their first graduate course in linear systems theory. Therefore, it comes as a surprise that for a more general class of nonlinear stochastic systems (hidden Markov models or HMMs), duality is incomplete.
  Our objective in writing this article is two-fold: (i) To describe the difficulty in extending duality to HMMs; and (ii) To discuss its recent resolution by the authors. A key message is that the main difficulty in extending duality comes from time reversal in going from estimation to control. The reason for time reversal is explained with the aid of the familiar linear deterministic and linear Gaussian models. The explanation is used to motivate the difference between the linear and the nonlinear models. Once the difference is understood, duality for HMMs is described based on our recent work. The article also includes a comparison and discussion of the different types of duality considered in literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07650v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jin Won Kim, Prashant G. Mehta</dc:creator>
    </item>
    <item>
      <title>End-to-End Optimization of Metasurfaces for Imaging with Compressed Sensing</title>
      <link>https://arxiv.org/abs/2201.12348</link>
      <description>arXiv:2201.12348v4 Announce Type: replace-cross 
Abstract: We present a framework for the end-to-end optimization of metasurface imaging systems that reconstruct targets using compressed sensing, a technique for solving underdetermined imaging problems when the target object exhibits sparsity (i.e. the object can be described by a small number of non-zero values, but the positions of these values are unknown). We nest an iterative, unapproximated compressed sensing reconstruction algorithm into our end-to-end optimization pipeline, resulting in an interpretable, data-efficient method for maximally leveraging metaoptics to exploit object sparsity. We apply our framework to super-resolution imaging and high-resolution depth imaging with a phase-change material. In both situations, our end-to-end framework computationally discovers optimal metasurface structures for compressed sensing recovery, automatically balancing a number of complicated design considerations to select an imaging measurement matrix from a complex, physically constrained manifold with millions ofdimensions. The optimized metasurface imaging systems are robust to noise, significantly improving over random scattering surfaces and approaching the ideal compressed sensing performance of a Gaussian matrix, showing how a physical metasurface system can demonstrably approach the mathematical limits of compressed sensing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2201.12348v4</guid>
      <category>eess.IV</category>
      <category>math.OC</category>
      <category>physics.optics</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1021/acsphotonics.4c00259</arxiv:DOI>
      <arxiv:journal_reference>ACS Photonics 2024, 11, 5, 2077-2087</arxiv:journal_reference>
      <dc:creator>Gaurav Arya, William F. Li, Charles Roques-Carmes, Marin Solja\v{c}i\'c, Steven G. Johnson, Zin Lin</dc:creator>
    </item>
    <item>
      <title>Riemannian Newton methods for energy minimization problems of Kohn-Sham type</title>
      <link>https://arxiv.org/abs/2307.13820</link>
      <description>arXiv:2307.13820v2 Announce Type: replace-cross 
Abstract: This paper is devoted to the numerical solution of constrained energy minimization problems arising in computational physics and chemistry such as the Gross-Pitaevskii and Kohn-Sham models. In particular, we introduce the Riemannian Newton methods on the infinite-dimensional Stiefel and Grassmann manifolds. We study the geometry of these two manifolds, its impact on the Newton algorithms, and present expressions of the Riemannian Hessians in the infinite-dimensional setting, which are suitable for variational spatial discretizations. A series of numerical experiments illustrates the performance of the methods and demonstrates its supremacy compared to other well-established schemes such as the self-consistent field iteration and gradient descent schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.13820v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>R. Altmann, D. Peterseim, T. Stykel</dc:creator>
    </item>
    <item>
      <title>Efficient Interaction-Aware Interval Analysis of Neural Network Feedback Loops</title>
      <link>https://arxiv.org/abs/2307.14938</link>
      <description>arXiv:2307.14938v3 Announce Type: replace-cross 
Abstract: In this paper, we propose a computationally efficient framework for interval reachability of systems with neural network controllers. Our approach leverages inclusion functions for the open-loop system and the neural network controller to embed the closed-loop system into a larger-dimensional embedding system, where a single trajectory over-approximates the original system's behavior under uncertainty. We propose two methods for constructing closed-loop embedding systems, which account for the interactions between the system and the controller in different ways. The interconnection-based approach considers the worst-case evolution of each coordinate separately by substituting the neural network inclusion function into the open-loop inclusion function. The interaction-based approach uses novel Jacobian-based inclusion functions to capture the first-order interactions between the open-loop system and the controller by leveraging state-of-the-art neural network verifiers. Finally, we implement our approach in a Python framework called ReachMM to demonstrate its efficiency and scalability on benchmarks and examples ranging to $200$ state dimensions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.14938v3</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Saber Jafarpour, Akash Harapanahalli, Samuel Coogan</dc:creator>
    </item>
    <item>
      <title>Estimating True Beliefs in Opinion Dynamics with Social Pressure</title>
      <link>https://arxiv.org/abs/2310.17171</link>
      <description>arXiv:2310.17171v2 Announce Type: replace-cross 
Abstract: Social networks often exert social pressure, causing individuals to adapt their expressed opinions to conform to their peers. An agent in such systems can be modeled as having a (true and unchanging) inherent belief while broadcasting a declared opinion at each time step based on her inherent belief and the past declared opinions of her neighbors. An important question in this setting is parameter estimation: how to disentangle the effects of social pressure to estimate inherent beliefs from declared opinions. This is useful for forecasting when agents' declared opinions are influenced by social pressure while real-world behavior only depends on their inherent beliefs. To address this, Jadbabaie et al. formulated the Interacting P\'olya Urn model of opinion dynamics under social pressure and studied it on complete-graph social networks using an aggregate estimator, and found that their estimator converges to the inherent beliefs unless majority pressure pushes the network to consensus.
  In this work, we studythis model on arbitrary networks, providing an estimator which converges to the inherent beliefs even in consensus situations. Finally, we bound the convergence rate of our estimator in both consensus and non-consensus scenarios; to get the bound for consensus scenarios (which converge slower than non-consensus) we additionally found how quickly the system converges to consensus.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.17171v2</guid>
      <category>eess.SY</category>
      <category>cs.SI</category>
      <category>cs.SY</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jennifer Tang, Aviv Adler, Amir Ajorlou, Ali Jadbabaie</dc:creator>
    </item>
    <item>
      <title>Preconditioned iterative solvers for constrained high-order implicit shock tracking methods</title>
      <link>https://arxiv.org/abs/2402.18403</link>
      <description>arXiv:2402.18403v2 Announce Type: replace-cross 
Abstract: High-order implicit shock tracking (fitting) is a class of high-order numerical methods that use numerical optimization to simultaneously compute a high-order approximation to a conservation law solution and align elements of the computational mesh with non-smooth features. This alignment ensures that non-smooth features are perfectly represented by inter-element jumps and high-order basis functions approximate smooth regions of the solution without nonlinear stabilization, which leads to accurate approximations on traditionally coarse meshes. In this work, we devise a family of preconditioners for the saddle point linear system that defines the step toward optimality at each iteration of the optimization solver so Krylov solvers can be effectively used. Our preconditioners integrate standard preconditioners from constrained optimization with popular preconditioners for discontinuous Galerkin discretizations such as block Jacobi, block incomplete LU factorizations with minimum discarded fill reordering, and p-multigrid. Thorough studies are performed using two inviscid compressible flow problems to evaluate the effectivity of each preconditioner in this family and their sensitivity to critical shock tracking parameters such as the mesh and Hessian regularization, linearization state, and resolution of the solution space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.18403v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jakob Vandergrift, Matthew J. Zahr</dc:creator>
    </item>
    <item>
      <title>Reconstruction of the local contractility of the cardiac muscle from deficient apparent kinematics</title>
      <link>https://arxiv.org/abs/2404.11137</link>
      <description>arXiv:2404.11137v2 Announce Type: replace-cross 
Abstract: Active solids are a large class of materials, including both living soft tissues and artificial matter, that share the ability to undergo strain even in absence of external loads. While in engineered materials the actuation is typically designed a priori, in natural materials it is an unknown of the problem. In such a framework, the identification of inactive regions in active materials is of particular interest. An example of paramount relevance is cardiac mechanics and the assessment of regions of the cardiac muscle with impaired contractility. The impossibility to measure the local active forces directly suggests us to develop a novel methodology exploiting kinematic data from clinical images by a variational approach to reconstruct the local contractility of the cardiac muscle. By finding the stationary points of a suitable cost functional we recover the contractility map of the muscle. Numerical experiments, including severe conditions with added noise to model uncertainties, and data knowledge limited to the boundary, demonstrate the effectiveness of our approach. Unlike other methods, we provide a spatially continuous recovery of the contractility map without compromising the computational efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11137v2</guid>
      <category>physics.med-ph</category>
      <category>math.OC</category>
      <category>q-bio.QM</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Giulia Pozzi, Davide Ambrosi, Simone Pezzuto</dc:creator>
    </item>
    <item>
      <title>Submodular Information Selection for Hypothesis Testing with Misclassification Penalties</title>
      <link>https://arxiv.org/abs/2405.10930</link>
      <description>arXiv:2405.10930v2 Announce Type: replace-cross 
Abstract: We consider the problem of selecting an optimal subset of information sources for a hypothesis testing/classification task where the goal is to identify the true state of the world from a finite set of hypotheses, based on finite observation samples from the sources. In order to characterize the learning performance, we propose a misclassification penalty framework, which enables non-uniform treatment of different misclassification errors. In a centralized Bayesian learning setting, we study two variants of the subset selection problem: (i) selecting a minimum cost information set to ensure that the maximum penalty of misclassifying the true hypothesis remains bounded and (ii) selecting an optimal information set under a limited budget to minimize the maximum penalty of misclassifying the true hypothesis. Under certain assumptions, we prove that the objective (or constraints) of these combinatorial optimization problems are weak (or approximate) submodular, and establish high-probability performance guarantees for greedy algorithms. Further, we propose an alternate metric for information set selection which is based on the total penalty of misclassification. We prove that this metric is submodular and establish near-optimal guarantees for the greedy algorithms for both the information set selection problems. Finally, we present numerical simulations to validate our theoretical results over several randomly generated instances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10930v2</guid>
      <category>stat.ML</category>
      <category>cs.CC</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jayanth Bhargav, Mahsa Ghasemi, Shreyas Sundaram</dc:creator>
    </item>
    <item>
      <title>Large Stepsize Gradient Descent for Non-Homogeneous Two-Layer Networks: Margin Improvement and Fast Optimization</title>
      <link>https://arxiv.org/abs/2406.08654</link>
      <description>arXiv:2406.08654v2 Announce Type: replace-cross 
Abstract: The typical training of neural networks using large stepsize gradient descent (GD) under the logistic loss often involves two distinct phases, where the empirical risk oscillates in the first phase but decreases monotonically in the second phase. We investigate this phenomenon in two-layer networks that satisfy a near-homogeneity condition. We show that the second phase begins once the empirical risk falls below a certain threshold, dependent on the stepsize. Additionally, we show that the normalized margin grows nearly monotonically in the second phase, demonstrating an implicit bias of GD in training non-homogeneous predictors. If the dataset is linearly separable and the derivative of the activation function is bounded away from zero, we show that the average empirical risk decreases, implying that the first phase must stop in finite steps. Finally, we demonstrate that by choosing a suitably large stepsize, GD that undergoes this phase transition is more efficient than GD that monotonically decreases the risk. Our analysis applies to networks of any width, beyond the well-known neural tangent kernel and mean-field regimes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.08654v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuhang Cai, Jingfeng Wu, Song Mei, Michael Lindsey, Peter L. Bartlett</dc:creator>
    </item>
    <item>
      <title>Cross-Dimensional Mathematics: A Foundation For STP/STA</title>
      <link>https://arxiv.org/abs/2406.12920</link>
      <description>arXiv:2406.12920v2 Announce Type: replace-cross 
Abstract: A new mathematical structure, called the cross-dimensional mathematics (CDM), is proposed. The CDM considered in this paper consists of three parts: hyper algebra, hyper geometry, and hyper Lie group/Lie algebra. Hyper algebra proposes some new algebraic structures such as hyper group, hyper ring, and hyper module over matrices and vectors with mixed dimensions (MVMDs). They have sets of classical groups, rings, and modules as their components and cross-dimensional connections among their components. Their basic properties are investigated. Hyper geometry starts from mixed dimensional Euclidian space, and hyper vector space. Then the hyper topological vector space, hyper inner product space, and hyper manifold are constructed. They have a joined cross-dimensional geometric structure. Finally, hyper metric space, topological hyper group and hyper Lie algebra are built gradually, and finally, the corresponding hyper Lie group is introduced. All these concepts are built over MVMDs, and to reach our purpose in addition to existing semi-tensor products (STPs) and semi-tensor additions (STAs), a couple of most general STP and STA are introduced. Some existing structures/results about STPs/STAs have also been resumed and integrated into this CDM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12920v2</guid>
      <category>math.RA</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daizhan Cheng</dc:creator>
    </item>
  </channel>
</rss>
