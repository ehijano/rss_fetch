<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-fin.EC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-fin.EC</link>
    <description>q-fin.EC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-fin.EC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 19 Feb 2026 02:36:26 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Agent-based macroeconomics for the UK's Seventh Carbon Budget</title>
      <link>https://arxiv.org/abs/2602.15607</link>
      <description>arXiv:2602.15607v1 Announce Type: new 
Abstract: In June 2026, the UK government will set its carbon budget for the period 2038 to 2042, the seventh such carbon budget (CB7) since the Climate Change Act became law in 2008. For the first time, this carbon budget will be accompanied by a macroeconomic assessment of its impact on growth, employment, inflation and inequality. Researchers from the Institute of New Economic Thinking (INET) Oxford are working in partnership with the Department for Energy Security and Net Zero to deliver this assessment using our data-driven macroeconomic agent-based model (ABM). This extended abstract presents the work in progress towards this pioneering policymaking using our data-driven macroeconomic ABM. We are conducting our work in three work packages. By the time of the workshop, we hope to be able to present preliminary findings from the first two work packages. In WP1, we adapt an existing macro-ABM prototype and build a UK macroeconomic baseline. The main task for this is initialising the model with suitable UK household microdata. We present the options considered and the approach settled upon. In WP2, we conduct preliminary modelling that represents UK decarbonisation as an external shock to financial flows and technical coefficients. In order to present results in time to influence the June 2026 policy decision, this second work package exogenously forces the ABM to follow the CB7 green investment and associated technological change projections provided by the Climate Change Committee. Finally, we will implement more sophisticated social and technological learning packages in WP3, building our own projections of likely decarbonisation pathways that may diverge from UK government plans. For the workshop, we will present the progress of WP1 and WP2.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15607v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tom Youngman, Tim Lennox, M. Lopes Alves, Pirta Palola, Brendon Tankwa, Emma Bailey, Emilien Ravigne, Thijs Ter Horst, Benjamin Wagenvoort, Harry Lightfoot Brown, Jose Moran, Doyne Farmer</dc:creator>
    </item>
    <item>
      <title>Understanding Classical Decomposability of Inequality Measures: A Graphical Analysis</title>
      <link>https://arxiv.org/abs/2602.15699</link>
      <description>arXiv:2602.15699v1 Announce Type: new 
Abstract: This paper's objective is pedagogical and interpretive. Namely, it gives a simple geometric analysis of classical (by which I mean population-share-weighted or income-share-weighted) inequality decomposability in the simplest nontrivial setting of three individuals. Income distributions in this case can be represented as points on the two-dimensional income-share simplex. In this representation, classical decomposability translates into concrete geometric restrictions of within- and between-group components. The geometric framework makes it possible to localize and compare violations of decomposability across inequality measures. The analysis is applied to the Mean Log Deviation, the Gini coefficient, the coefficient of variation, and the Theil index.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15699v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tatiana Komarova</dc:creator>
    </item>
    <item>
      <title>Travel Time Prediction from Sparse Open Data</title>
      <link>https://arxiv.org/abs/2602.15069</link>
      <description>arXiv:2602.15069v1 Announce Type: cross 
Abstract: Travel time prediction is central to transport geography and planning's accessibility analyses, sustainable transportation infrastructure provision, and active transportation interventions. However, calculating accurate travel times, especially for driving, requires either extensive technical capacity and bespoke data, or resources like the Google Maps API that quickly become prohibitively expensive to analyze thousands or millions of trips necessary for metropolitan-scale analyses. Such obstacles particularly challenge less-resourced researchers, practitioners, and community advocates. This article argues that a middle-ground is needed to provide reasonably accurate travel time predictions without extensive data or computing requirements. It introduces a free, open-source minimally-congested driving time prediction model with minimal cost, data, and computational requirements. It trains and tests this model using the Los Angeles, California urban area as a case study by calculating naive travel times from open data then developing a random forest model to predict travel times as a function of those naive times plus open data on turns and traffic controls. Validation shows that this interpretable machine learning method offers a superior middle-ground technique that balances reasonable accuracy with minimal resource requirements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15069v1</guid>
      <category>physics.soc-ph</category>
      <category>cs.CY</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1080/13658816.2026.2628193</arxiv:DOI>
      <arxiv:journal_reference>International Journal of Geographical Information Science, 2026</arxiv:journal_reference>
      <dc:creator>Geoff Boeing, Yuquan Zhou</dc:creator>
    </item>
    <item>
      <title>Pricing Discrete and Nonlinear Markets With Semidefinite Relaxations</title>
      <link>https://arxiv.org/abs/2602.15722</link>
      <description>arXiv:2602.15722v1 Announce Type: cross 
Abstract: Nonconvexities in markets with discrete decisions and nonlinear constraints make efficient pricing challenging, often necessitating subsidies. A prime example is the unit commitment (UC) problem in electricity markets, where costly subsidies are commonly required. We propose a new pricing scheme for nonconvex markets with both discreteness and nonlinearity, by convexifying nonconvex structures through a semidefinite programming (SDP) relaxation and deriving prices from the relaxation's dual variables. When the choice set is bounded, we establish strong duality for the SDP, which allows us to extend the envelope theorem to the value function of the relaxation. This extension yields a marginal price signal for demand, which we use as our pricing mechanism. We demonstrate that under certain conditions-for instance, when the relaxation's right hand sides are linear in demand-the resulting lost opportunity cost is bounded by the relaxation's optimality gap. This result highlights the importance of achieving tight relaxations. The proposed framework applies to nonconvex electricity market problems, including for both direct current and alternating current UC. Our numerical experiments indicate that the SDP relaxations are often tight, reinforcing the effectiveness of the proposed pricing scheme. Across a suite of IEEE benchmark instances, the lost opportunity cost under our pricing scheme is, on average, 46% lower than that of the commonly used fixed-binary pricing scheme.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15722v1</guid>
      <category>math.OC</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cheng Guo, Lauren Henderson, Ryan Cory-Wright, Boshi Yang</dc:creator>
    </item>
    <item>
      <title>Sovereign Hold-Up and Technology Adoption: Evidence from the North Sea</title>
      <link>https://arxiv.org/abs/2205.13186</link>
      <description>arXiv:2205.13186v4 Announce Type: replace 
Abstract: Contractual relationships between the state and private firms involving large irreversible investments are vulnerable to sovereign hold-up risk: anticipating that the state can unilaterally revise terms once capital is sunk, firms may underinvest. Causal evidence on this mechanism is scarce because sovereign commitment is typically bundled with broader institutional quality. We overcome this identification challenge by exploiting a natural experiment in the North Sea oil and gas industry. In 1985, a Norwegian Supreme Court ruling declared retroactive changes to petroleum licenses unconstitutional, while the UK retained the discretion to revise contracts. Using granular data on the universe of fields and firms from 1975 to 1995, we estimate the impact of this strengthening of sovereign commitment on the adoption of Enhanced Oil Recovery (EOR), a major extraction technology requiring large irreversible investments. Firms exposed to the ruling sharply increased EOR adoption and productivity, gaining market share through aggressive portfolio expansion. We find that private firms with preexisting EOR expertise -- rather than state-owned enterprises -- drove this transformation, leveraging this expertise to diversify into riskier geologies and adopt complementary technologies. These findings establish sovereign commitment as a primary determinant of investment and technology adoption. By tying the state's hands, the ruling transformed promises into credible commitments, effectively functioning as an industrial policy that unlocked a trajectory of technological deepening. While such constitutional protections are critical for investment, a global survey of constitutions reveals that only 30.6% of countries prohibit retroactive legislation beyond criminal law.</description>
      <guid isPermaLink="false">oai:arXiv.org:2205.13186v4</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Michele Fioretti, Alessandro Iaria, Aljoscha Janssen, Cl\'ement Mazet-Sonilhac, Robert K. Perrons</dc:creator>
    </item>
    <item>
      <title>Measuring economic outlook in the news</title>
      <link>https://arxiv.org/abs/2511.04299</link>
      <description>arXiv:2511.04299v3 Announce Type: replace 
Abstract: We develop a resource-efficient methodology for measuring economic outlook in news text that combines document embeddings with synthetic training data generated by large language models. Applied to 27 million news articles, the resulting indicator significantly improves GDP growth forecast accuracy and captures sentiment shifts weeks before official releases, proving particularly valuable during crises. The indicator outperforms both survey-based benchmarks and traditional dictionary methods and is interpretable, allowing identification of specific drivers of economic sentiment. Our approach addresses key institutional constraints: it performs sentiment classification locally, enabling analyses of proprietary news content without transmission to external services while requiring minimal computational resources compared to direct large language model classification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.04299v3</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Elliot Beck, Franziska Eckert, Linus K\"uhne, Helge Liebert, Rina Rosenblatt-Wisch</dc:creator>
    </item>
    <item>
      <title>The Directions of Technical Change</title>
      <link>https://arxiv.org/abs/2602.12958</link>
      <description>arXiv:2602.12958v2 Announce Type: replace 
Abstract: Generative AI is directional: it performs well in some task directions and poorly in others. Knowledge work is directional and endogenous as well: workers can satisfy the same job requirements with different mixes of tasks. We develop a high-dimensional model of AI adoption in which a worker uses a tool when it raises their output. Both the worker and the AI tool can perform a variety of tasks, which we model as convex production possibility sets. Because the tool requires supervision from the worker's own time and attention budget, adoption is a team-production decision, similar to hiring a coworker. The key sufficient statistics are the worker's pre-AI shadow prices: these equal the output gain from a small relaxation in each task direction, and they generally differ from the worker's observed activity mix. As AI capability improves, the set of adopted directions expands in a cone centered on these autarky prices. Near the entry threshold, small capability improvements generate large extensive-margin expansions in adoption. The model also delivers a structured intensive margin: between the entry and all-in thresholds, optimal use is partial. We parametrize the model in a simple but flexible way that nests most existing task-based models of technical change.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.12958v2</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Miklos Koren, Zsofia Barany, Ulrich Wohak</dc:creator>
    </item>
  </channel>
</rss>
