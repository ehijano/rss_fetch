<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CC</link>
    <description>cs.CC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 23 Feb 2026 05:00:18 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 23 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Hilbert's Nullstellensatz is in the Counting Hierarchy</title>
      <link>https://arxiv.org/abs/2602.17904</link>
      <description>arXiv:2602.17904v1 Announce Type: new 
Abstract: We show that Hilbert's Nullstellensatz, the problem of deciding if a system of multivariate polynomial equations has a solution in the algebraic closure of the underlying field, lies in the counting hierarchy. More generally, we show that the number of solutions to a system of equations can be computed in polynomial time with oracle access to the counting hierarchy. Our results hold in particular for polynomials with coefficients in either the rational numbers or a finite field. Previously, the best-known bounds on the complexities of these problems were PSPACE and FPSPACE, respectively. Our main technical contribution is the construction of a uniform family of constant-depth arithmetic circuits that compute the multivariate resultant.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.17904v1</guid>
      <category>cs.CC</category>
      <category>cs.SC</category>
      <pubDate>Mon, 23 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Robert Andrews, Abhibhav Garg, \'Eric Schost</dc:creator>
    </item>
    <item>
      <title>Convergent Gate Elimination and Constructive Circuit Lower Bounds</title>
      <link>https://arxiv.org/abs/2602.17942</link>
      <description>arXiv:2602.17942v1 Announce Type: new 
Abstract: Towards better understanding of gate elimination, the only method known that can prove complexity lower bounds for explicit functions against unrestricted Boolean circuits, this work contributes: (1) formalizing circuit simplifications as a convergent term graph rewriting system and (2) giving a simple and constructive proof of a classical lower bound using this system.
  First, we show that circuit simplification is a convergent term graph rewriting system over the DeMorgan and $\{\land, \lor, \oplus\}$ bases. We define local rewriting rules from Boolean identities such that every simplification sequence yields an identical final result (up to circuit isomorphism or bisimulation). Convergence enables rigorous reasoning about structural properties of simplified circuits without dependence on the order of simplification. Then, we show that there is \emph{no similar} convergent formalization of circuit simplification over the $U_2$ and $B_2$ bases.
  Then, we use our simplification system to give a constructive circuit lower bound, generalizing Schnorr's classical result that the XOR function requires $3(n - 1)$ gates to compute in the DeMorgan basis. A constructive lower bound $f \not\in C$ gives an algorithm (called a "refuter") that efficiently finds counter-examples for every $C$-circuit trying to compute the function $f$. Chen, Jin, Santhanam, and Williams showed that constructivity plays a central role in many longstanding open problems about complexity theory (FOCS 2021), so it is natural to ask for constructive circuit lower bounds from gate elimination arguments. This demonstrates how using convergent simplification can lead to shorter and more modular proofs of circuit lower bounds. Furthermore, until this work, no constructive lower bound had been proved via gate elimination.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.17942v1</guid>
      <category>cs.CC</category>
      <pubDate>Mon, 23 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marco Carmosino, Ngu Dang, Tim Jackman</dc:creator>
    </item>
    <item>
      <title>Complexity lower bounds for succinct binary structures of bounded clique-width with restrictions</title>
      <link>https://arxiv.org/abs/2602.18240</link>
      <description>arXiv:2602.18240v1 Announce Type: new 
Abstract: We present a Rice-like complexity lower bound for any MSO-definable problem on binary structures succinctly encoded by circuits. This work extends the framework recently developed as a counterpoint to Courcelle's theorem for graphs encoded by circuits, in two interplaying directions: (1) by allowing multiple binary relations, and (2) by restricting the interpretation of new symbols. Depending on the pair of an MSO problem $\psi$ and an MSO restriction $\chi$, the problem is proven to be NP-hard or coNP-hard or P-hard, as long as $\psi$ is non-trivial on structures satisfying $\chi$ with bounded clique-width. Indeed, there are P-complete problems (for logspace reductions) in our extended context. Finally, we strengthen a previous result on the necessity to parameterize the notion of non-triviality, hence supporting the choice of clique-width.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.18240v1</guid>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>cs.LO</category>
      <pubDate>Mon, 23 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Colin Geniet, Ali\'enor Goubault-Larrecq, K\'evin Perrot</dc:creator>
    </item>
    <item>
      <title>The Complexity of Sparse Win-Lose Bimatrix Games</title>
      <link>https://arxiv.org/abs/2602.18380</link>
      <description>arXiv:2602.18380v1 Announce Type: new 
Abstract: We prove that computing an $\epsilon$-approximate Nash equilibrium of a win-lose bimatrix game with constant sparsity is PPAD-hard for inverse-polynomial $\epsilon$. Our result holds for 3-sparse games, which is tight given that 2-sparse win-lose bimatrix games can be solved in polynomial time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.18380v1</guid>
      <category>cs.CC</category>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <pubDate>Mon, 23 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eleni Batziou, John Fearnley, Abheek Ghosh, Rahul Savani</dc:creator>
    </item>
    <item>
      <title>Policy Gradient Algorithms in Average-Reward Multichain MDPs</title>
      <link>https://arxiv.org/abs/2602.18003</link>
      <description>arXiv:2602.18003v1 Announce Type: cross 
Abstract: While there is an extensive body of research analyzing policy gradient methods for discounted cumulative-reward MDPs, prior work on policy gradient methods for average-reward MDPs has been limited, with most existing results restricted to ergodic or unichain settings. In this work, we first establish a policy gradient theorem for average-reward multichain MDPs based on the invariance of the classification of recurrent and transient states. Building on this foundation, we develop refined analyses and obtain a collection of convergence and sample-complexity results that advance the understanding of this setting. In particular, we show that the proposed $\alpha$-clipped policy mirror ascent algorithm attains an $\epsilon$-optimal policy with respect to positive policies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.18003v1</guid>
      <category>math.OC</category>
      <category>cs.CC</category>
      <pubDate>Mon, 23 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jongmin Lee, Ernest K. Ryu</dc:creator>
    </item>
    <item>
      <title>Unifying Formal Explanations: A Complexity-Theoretic Perspective</title>
      <link>https://arxiv.org/abs/2602.18160</link>
      <description>arXiv:2602.18160v1 Announce Type: cross 
Abstract: Previous work has explored the computational complexity of deriving two fundamental types of explanations for ML model predictions: (1) *sufficient reasons*, which are subsets of input features that, when fixed, determine a prediction, and (2) *contrastive reasons*, which are subsets of input features that, when modified, alter a prediction. Prior studies have examined these explanations in different contexts, such as non-probabilistic versus probabilistic frameworks and local versus global settings. In this study, we introduce a unified framework for analyzing these explanations, demonstrating that they can all be characterized through the minimization of a unified probabilistic value function. We then prove that the complexity of these computations is influenced by three key properties of the value function: (1) *monotonicity*, (2) *submodularity*, and (3) *supermodularity* - which are three fundamental properties in *combinatorial optimization*. Our findings uncover some counterintuitive results regarding the nature of these properties within the explanation settings examined. For instance, although the *local* value functions do not exhibit monotonicity or submodularity/supermodularity whatsoever, we demonstrate that the *global* value functions do possess these properties. This distinction enables us to prove a series of novel polynomial-time results for computing various explanations with provable guarantees in the global explainability setting, across a range of ML models that span the interpretability spectrum, such as neural networks, decision trees, and tree ensembles. In contrast, we show that even highly simplified versions of these explanations become NP-hard to compute in the corresponding local explainability setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.18160v1</guid>
      <category>cs.LG</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Mon, 23 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shahaf Bassan, Xuanxiang Huang, Guy Katz</dc:creator>
    </item>
    <item>
      <title>Ex-post Stability under Two-Sided Matching: Complexity and Characterization</title>
      <link>https://arxiv.org/abs/2411.14821</link>
      <description>arXiv:2411.14821v2 Announce Type: replace-cross 
Abstract: A probabilistic approach to the stable matching problem has been identified as an important research area with several important open problems. When considering random matchings, ex-post stability is a fundamental stability concept. A prominent open problem is characterizing ex-post stability and establishing its computational complexity. We investigate the computational complexity of testing ex-post stability. Our central result is that when either side has ties in the preferences/priorities, testing ex-post stability is NP-complete. The result even holds if both sides have dichotomous preferences. On the positive side, we give an algorithm using an integer programming approach, that can determine a decomposition with a maximum probability of being weakly stable. We also consider stronger versions of ex-post stability (in particular robust ex-post stability and ex-post strong stability) and prove that they can be tested in polynomial time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.14821v2</guid>
      <category>cs.GT</category>
      <category>cs.CC</category>
      <pubDate>Mon, 23 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haris Aziz, Gergely Cs\'aji, P\'eter Bir\'o</dc:creator>
    </item>
    <item>
      <title>Colouring Graphs Without a Subdivided H-Graph: A Full Complexity Classification</title>
      <link>https://arxiv.org/abs/2512.09859</link>
      <description>arXiv:2512.09859v2 Announce Type: replace-cross 
Abstract: We consider Colouring on graphs that are $H$-subgraph-free for some fixed graph $H$, which are graphs that do not contain $H$ as a subgraph. To classify the complexity of Colouring on $H$-subgraph-free graphs for connected $H$, it remains to consider when $H$ is a tree of maximum degree $4$ with exactly one vertex of degree $4$, or a tree of maximum degree $3$ with at least two vertices of degree $3$. We let $H$ be a so-called subdivided ``H''-graph, which is either a subdivided $\mathbb{H}_0$: a tree of maximum degree $4$ that is a star, or a subdivided $\mathbb{H}_1$: a tree of maximum degree $3$ with exactly two vertices of degree $3$. We develop new decomposition theorems resulting in polynomial-time algorithms, and in combination with known results, fully classify all cases $\mathbb{H}_0$ and $\mathbb{H}_1$. To illustrate the wider applicability of our techniques, we also employ them to obtain similar new polynomial-time results for two other classic graph problems: Stable Cut and, in part, Feedback Vertex Set.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.09859v2</guid>
      <category>math.CO</category>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <pubDate>Mon, 23 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tala Eagling-Vose, Jorik Jooken, Felicia Lucke, Barnaby Martin, Dani\"el Paulusma</dc:creator>
    </item>
    <item>
      <title>End Cover for Initial Value Problem: Complete Validated Algorithms with Complexity Analysis</title>
      <link>https://arxiv.org/abs/2602.00162</link>
      <description>arXiv:2602.00162v2 Announce Type: replace-cross 
Abstract: We consider the first-order autonomous ordinary differential equation \[ \mathbf{x}' = \mathbf{f}(\mathbf{x}), \] where $\mathbf{f} : \mathbb{R}^n \to \mathbb{R}^n$ is locally Lipschitz. For a box $B_0 \subseteq \mathbb{R}^n$ and $h &gt; 0$, we denote by $\mathrm{IVP}_{\mathbf{f}}(B_0,h)$ the set of solutions $\mathbf{x} : [0,h] \to \mathbb{R}^n$ satisfying \[ \mathbf{x}'(t) = \mathbf{f}(\mathbf{x}(t)), \qquad \mathbf{x}(0) \in B_0 . \]
  We present a complete validated algorithm for the following \emph{End Cover Problem}: given $(\mathbf{f}, B_0, \varepsilon, h)$, compute a finite set $\mathcal{C}$ of boxes such that \[ \mathrm{End}_{\mathbf{f}}(B_0,h) \;\subseteq\; \bigcup_{B \in \mathcal{C}} B \;\subseteq\; \mathrm{End}_{\mathbf{f}}(B_0,h) \oplus [-\varepsilon,\varepsilon]^n , \] where \[ \mathrm{End}_{\mathbf{f}}(B_0,h) = \left\{ \mathbf{x}(h) : \mathbf{x} \in \mathrm{IVP}_{\mathbf{f}}(B_0,h) \right\}. \]
  Moreover, we provide a complexity analysis of our algorithm and introduce a novel technique for computing the end cover $\mathcal{C}$ based on covering the boundary of $\mathrm{End}_{\mathbf{f}}(B_0,h)$. Finally, we present experimental results demonstrating the practicality of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.00162v2</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Mon, 23 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bingwei Zhang, Chee Yap</dc:creator>
    </item>
    <item>
      <title>Neighborhood-Aware Graph Labeling Problem</title>
      <link>https://arxiv.org/abs/2602.08098</link>
      <description>arXiv:2602.08098v2 Announce Type: replace-cross 
Abstract: Motivated by optimization oracles in bandits with network interference, we study the Neighborhood-Aware Graph Labeling (NAGL) problem. Given a graph $G = (V,E)$, a label set of size $L$, and local reward functions $f_v$ accessed via evaluation oracles, the objective is to assign labels to maximize $\sum_{v \in V} f_v(x_{N[v]})$, where each term depends on the closed neighborhood of $v$. Two vertices co-occur in some neighborhood term exactly when their distance in $G$ is at most $2$, so the dependency graph is the squared graph $G^2$ and $\mathrm{tw}(G^2)$ governs exact algorithms and matching fine-grained lower bounds. Accordingly, we show that this dependence is inherent: NAGL is NP-hard even on star graphs with binary labels and, assuming SETH, admits no $(L-\varepsilon)^{\mathrm{tw}(G^2)}\cdot n^{O(1)}$-time algorithm for any $\varepsilon&gt;0$. We match this with an exact dynamic program on a tree decomposition of $G^2$ running in $O\!\left(n\cdot \mathrm{tw}(G^2)\cdot L^{\mathrm{tw}(G^2)+1}\right)$ time. For approximation, unless $\mathsf{P}=\mathsf{NP}$, for every $\varepsilon&gt;0$ there is no polynomial-time $n^{1-\varepsilon}$-approximation on general graphs even under the promise $\mathrm{OPT}&gt;0$; without the promise $\mathrm{OPT}&gt;0$, no finite multiplicative approximation ratio is possible. In the nonnegative-reward regime, we give polynomial-time approximation algorithms for NAGL in two settings: (i) given a proper $q$-coloring of $G^2$, we obtain a $1/q$-approximation; and (ii) on planar graphs of bounded maximum degree, we develop a Baker-type polynomial-time approximation scheme (PTAS), which becomes an efficient PTAS (EPTAS) when $L$ is constant.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08098v2</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Mon, 23 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammad Shahverdikondori, Sepehr Elahi, Patrick Thiran, Negar Kiyavash</dc:creator>
    </item>
  </channel>
</rss>
