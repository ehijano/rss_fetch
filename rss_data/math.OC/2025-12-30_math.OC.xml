<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 30 Dec 2025 05:00:18 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Reinforcement Learning for Optimal Stopping in POMDPs with Application to Quickest Change Detection</title>
      <link>https://arxiv.org/abs/2512.22347</link>
      <description>arXiv:2512.22347v1 Announce Type: new 
Abstract: The field of quickest change detection (QCD) focuses on the design and analysis of online algorithms that estimate the time at which a significant event occurs. In this paper, design and analysis are cast in a Bayesian framework, where QCD is formulated as an optimal stopping problem with partial observations. An approximately optimal detection algorithm is sought using techniques from reinforcement learning. The contributions of the paper are summarized as follows: (i) A Q-learning algorithm is proposed for the general partially observed optimal stopping problem. It is shown to converge under linear function approximation, given suitable assumptions on the basis functions. An example is provided to demonstrate that these assumptions are necessary to ensure algorithmic stability. (ii) Prior theory motivates a particular choice of features in applying Q-learning to QCD. It is shown that, in several scenarios and under ideal conditions, the resulting class of policies contains one that is approximately optimal. (iii) Numerical experiments show that Q-learning consistently produces policies that perform close to the best achievable within the chosen function class.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.22347v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Austin Cooper, Sean Meyn</dc:creator>
    </item>
    <item>
      <title>A Decomposition Method for Solving Sensitivity-Based Distributed Optimal Power Flow</title>
      <link>https://arxiv.org/abs/2512.22419</link>
      <description>arXiv:2512.22419v1 Announce Type: new 
Abstract: Efficiently solving large-scale optimal power flow (OPF) problems is challenging due to the high dimensionality and interconnectivity of modern power systems. Decomposition methods offer a promising solution via partitioning large problems into smaller subproblems that can be solved in parallel, often with local information. These approaches reduce computational burden and improve flexibility by allowing agents to manage their local models. This article introduces a decomposition method that enables a distributed solution to OPF problems. The proposed method solves OPF problems with a sensitivity-based formulation using the alternating direction method of multipliers (ADMM) algorithm. We also propose a distributed method to compute system-wide sensitivities without sharing local parameters. This approach facilitates scalable optimization while satisfying global constraints and limiting data sharing. We demonstrate the effectiveness of the proposed approach using a large set of test systems and compare its performance against existing decomposition methods. The results show that the proposed method significantly outperforms the typical phase-angle formulation with a 14-times faster computation speed on average.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.22419v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mohannad Alkhraijah, Devon Sigler, Daniel K. Molzahn</dc:creator>
    </item>
    <item>
      <title>Small-time approximate controllability for the nonlinear complex Ginzburg-Landau equation with bilinear control</title>
      <link>https://arxiv.org/abs/2512.22512</link>
      <description>arXiv:2512.22512v1 Announce Type: new 
Abstract: In this paper, we consider the bilinear approximate controllability for the complex Ginzburg-Landau (CGL) equation with a power-type nonlinearity of any integer degree on a torus of arbitrary space dimension. Under a saturation hypothesis on the control operator, we show the small-time global controllability of the CGL equation. The proof is obtained by developing a multiplicative version of a geometric control approach, introduced by Agrachev and Sarychev in \cite{AS05,AS06}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.22512v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xingwu Zeng, Can Zhang</dc:creator>
    </item>
    <item>
      <title>Robust generalized S-Procedure</title>
      <link>https://arxiv.org/abs/2512.22561</link>
      <description>arXiv:2512.22561v1 Announce Type: new 
Abstract: We introduce in this paper the so-called robust generalized S-procedure associated with a given robust optimization problem. We provide a primal characterization for the validity of this procedure as well as a dual characterization under the assumption that the decision space is locally convex. We also analyze an extension of the mentioned robust S-procedure that incorporates a right-hand side function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.22561v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>N. Dinh, M. A. Goberna, D. H. Long, M. Volle</dc:creator>
    </item>
    <item>
      <title>A Survey of Machine-Learning-Based Scheduling: From Solver-Centric to Data-Centric Paradigms</title>
      <link>https://arxiv.org/abs/2512.22642</link>
      <description>arXiv:2512.22642v1 Announce Type: new 
Abstract: Scheduling problems are a fundamental class of combinatorial optimization problems that underpin operational efficiency in manufacturing, logistics, and service systems. While operations research has traditionally developed solver-centric methods emphasizing model structure and optimality, recent advances in machine learning are reshaping scheduling into a data-centric discipline that learns from experience and adapts to dynamic environments. This paper provides a comprehensive and comparative review of this methodological transition. We first revisit classical optimization-based approaches and summarize how ML has been integrated within them to improve computational efficiency. We then review end-to-end learning approaches that generate scheduling solutions directly from data, highlighting how they shift decision-making from explicit optimization to learned inference. Adopting a systematic, method-oriented perspective, we compare these paradigms and their underlying learning algorithms in terms of principles, scalability, interpretability, and generalization. Finally, we discuss key research challenges and outline future directions along three interdependent dimensions, scalability, reliability, and universality, that together define a pathway toward adaptive, intelligent, and trustworthy scheduling systems for data-driven operations management.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.22642v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anbang Liu, Shaochong Lin, Jingchuan Chen, Peng Wu, Zuojun Max Shen</dc:creator>
    </item>
    <item>
      <title>A Single-loop Stochastic Riemannian ADMM for Nonsmooth Optimization</title>
      <link>https://arxiv.org/abs/2512.22750</link>
      <description>arXiv:2512.22750v1 Announce Type: new 
Abstract: We study a class of nonsmooth stochastic optimization problems on Riemannian manifolds. In this work, we propose MARS-ADMM, the first stochastic Riemannian alternating direction method of multipliers with provable near-optimal complexity guarantees. Our algorithm incorporates a momentum-based variance-reduced gradient estimator applied exclusively to the smooth component of the objective, together with carefully designed penalty parameter and dual stepsize updates. Unlike existing approaches that rely on computationally expensive double-loop frameworks, MARS-ADMM operates in a single-loop fashion and requires only a constant number of stochastic gradient evaluations per iteration. Under mild assumptions, we establish that MARS-ADMM achieves an iteration complexity of \(\tilde{\mathcal{O}}(\varepsilon^{-3})\), which improves upon the previously best-known bound of \(\mathcal{O}(\varepsilon^{-3.5})\) for stochastic Riemannian operator-splitting methods. As a result, our analysis closes the theoretical complexity gap between stochastic Riemannian operator-splitting algorithms and stochastic methods for nonsmooth optimization with nonlinear constraints. Notably, the obtained complexity also matches the best-known bounds in deterministic nonsmooth Riemannian optimization, demonstrating that deterministic-level accuracy can be achieved using only constant-size stochastic samples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.22750v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiachen Jin, Kangkang Deng, Hongxia Wang</dc:creator>
    </item>
    <item>
      <title>On Composite Foster Functions for a Class of Singularly Perturbed Stochastic Hybrid Inclusions</title>
      <link>https://arxiv.org/abs/2512.22806</link>
      <description>arXiv:2512.22806v1 Announce Type: new 
Abstract: We study sufficient conditions for stability and recurrence in a class of singularly perturbed stochastic hybrid dynamical systems. The systems considered combine multi-time-scale deterministic continuous-time dynamics, modeled by constrained differential inclusions, with discrete-time dynamics described by constrained difference inclusions subject to random disturbances. Under suitable regularity assumptions on the dynamics and causality of the associated solutions, we develop a family of composite nonsmooth Lagrange-Foster and Lyapunov-Foster functions that certify stability and recurrence properties by leveraging simpler functions related to the slow and fast subsystems. Stability is characterized with respect to compact sets, while recurrence is established for bounded open sets. The proposed framework is illustrated through several examples and applications, including the stability analysis of singularly perturbed switching systems with stochastic spontaneous mode transitions, feedback optimization problems with stochastically switching plants, and momentum-based feedback optimization algorithms with stochastic restarting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.22806v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jorge I. Poveda, Mahmoud Abdelgalil</dc:creator>
    </item>
    <item>
      <title>Baillon-Bruck-Reich revisited: divergent-series parameters and strong convergence in the linear case</title>
      <link>https://arxiv.org/abs/2512.22817</link>
      <description>arXiv:2512.22817v1 Announce Type: new 
Abstract: The Krasnoselskii-Mann iteration is an important algorithm in optimization and variational analysis for finding fixed points of nonexpansive mappings. In the general case, it produces a sequence converging \emph{weakly} to a fixed point provided the parameter sequence satisfies a divergent-series condition.
  In this paper, we show that \emph{strong} convergence holds provided the underlying nonexpansive mapping is \emph{linear}. This improves on a celebrated result by Baillon, Bruck, and Reich from 1978, where the parameter sequence was assumed to be constant as well as on recent work where the parameters were bounded away from $0$ and $1$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.22817v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sedi Bartz, Heinz H. Bauschke, Yuan Gao</dc:creator>
    </item>
    <item>
      <title>A first-order method for nonconvex-strongly-concave constrained minimax optimization</title>
      <link>https://arxiv.org/abs/2512.22909</link>
      <description>arXiv:2512.22909v1 Announce Type: new 
Abstract: In this paper we study a nonconvex-strongly-concave constrained minimax problem. Specifically, we propose a first-order augmented Lagrangian method for solving it, whose subproblems are nonconvex-strongly-concave unconstrained minimax problems and suitably solved by a first-order method developed in this paper that leverages the strong concavity structure. Under suitable assumptions, the proposed method achieves an \emph{operation complexity} of $O(\varepsilon^{-3.5}\log\varepsilon^{-1})$, measured in terms of its fundamental operations, for finding an $\varepsilon$-KKT solution of the constrained minimax problem, which improves the previous best-known operation complexity by a factor of $\varepsilon^{-0.5}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.22909v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhaosong Lu, Sanyou Mei</dc:creator>
    </item>
    <item>
      <title>Deep Learning for the Multiple Optimal Stopping Problem</title>
      <link>https://arxiv.org/abs/2512.22961</link>
      <description>arXiv:2512.22961v1 Announce Type: new 
Abstract: This paper presents a novel deep learning framework for solving multiple optimal stopping problems in high dimensions. While deep learning has recently shown promise for single stopping problems, the multiple exercise case involves complex recursive dependencies that remain challenging. We address this by combining the Dynamic Programming Principle with neural network approximation of the value function. Unlike policy-search methods, our algorithm explicitly learns the value surface. We first consider the discrete-time problem and analyze neural network training error. We then turn to continuous problems and analyze the additional error due to the discretization of the underlying stochastic processes. Numerical experiments on high-dimensional American basket options and nonlinear utility maximization demonstrate that our method provides an efficient and scalable method for the multiple optimal stopping problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.22961v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mathieu Lauri\`ere, Mehdi Talbi</dc:creator>
    </item>
    <item>
      <title>Risk-Averse Learning with Varying Risk Levels</title>
      <link>https://arxiv.org/abs/2512.22986</link>
      <description>arXiv:2512.22986v1 Announce Type: new 
Abstract: In safety-critical decision-making, the environment may evolve over time, and the learner adjusts its risk level accordingly. This work investigates risk-averse online optimization in dynamic environments with varying risk levels, employing Conditional Value-at-Risk (CVaR) as the risk measure. To capture the dynamics of the environment and risk levels, we employ the function variation metric and introduce a novel risk-level variation metric. Two information settings are considered: a first-order scenario, where the learner observes both function values and their gradients; and a zeroth-order scenario, where only function evaluations are available. For both cases, we develop risk-averse learning algorithms with a limited sampling budget and analyze their dynamic regret bounds in terms of function variation, risk-level variation, and the total number of samples. The regret analysis demonstrates the adaptability of the algorithms in non-stationary and risk-sensitive settings. Finally, numerical experiments are presented to demonstrate the efficacy of the methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.22986v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Siyi Wang, Zifan Wang, Karl H. Johansson</dc:creator>
    </item>
    <item>
      <title>The Design of Optimal Dependency and Rewards</title>
      <link>https://arxiv.org/abs/2512.23115</link>
      <description>arXiv:2512.23115v1 Announce Type: new 
Abstract: We analyze a two-period principal-agent model in which the principal faces a budget constraint, and the agent's private costs of performing tasks across the two periods may be correlated. We examine the optimal design of the reward scheme and the cost correlation structure. Our findings reveal that when the budget is low, the optimal reward scheme employs \textit{sufficient performance targeting}, rewarding the agent's first performance. Conversely, when the principal's budget is high, the focus shifts to \textit{sustained performance targeting}, compensating the agent's second performance. Introducing a negative cost correlation proves particularly beneficial in both scenarios: it increases the likelihood of the agent performing at least once under low budgets and balances the agent's total costs to facilitate consistent performance under high budgets. However, the optimal cost correlation structure can be more elaborate, especially for intermediate budget levels. Our results offer valuable insights for real-world applications, such as research funding allocation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.23115v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eilon Solan, Avraham Tabbach, Chang Zhao</dc:creator>
    </item>
    <item>
      <title>Difference-of-Convex Elastic Net for Compressed Sensing</title>
      <link>https://arxiv.org/abs/2512.23134</link>
      <description>arXiv:2512.23134v1 Announce Type: new 
Abstract: This work proposes a novel and unified sparse recovery framework, termed the difference of convex Elastic Net (DCEN). This framework effectively balances strong sparsity promotion with solution stability, and is particularly suitable for high-dimensional variable selection involving highly correlated features. Built upon a difference-of-convex (DC) structure, DCEN employs two continuously tunable parameters to unify classical and state-of-the-art models--including Lasso, Elastic Net, Ridge, and $\ell_1-\alpha\ell_2$--as special cases. Theoretically, sufficient conditions for exact and stable recovery are established under the restricted isometry property (RIP), and a closed-form expression of the DCEN regularization proximal operator is derived. Moreover, two efficient optimization algorithms are developed based on the DC algorithm (DCA) and the alternating direction method of multipliers (ADMM). Within the Kurdyka-Lojasiewicz (KL) framework, the global convergence of DCA and its linear convergence rate are rigorously established. Furthermore, DCEN is extended to image reconstruction by incorporating total variation (TV) regularization, yielding the DCEN-TV model, which is efficiently solved via the Split Bregman method. Numerical experiments demonstrate that DCEN consistently outperforms state-of-the-art methods in sparse signal recovery, high-dimensional variable selection under strong collinearity, and Magnetic Resonance Imaging (MRI) image reconstruction, achieving superior recovery accuracy and robustness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.23134v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lang Yu, Nanjing Huang</dc:creator>
    </item>
    <item>
      <title>Constraint programming model and biased random-key genetic algorithm for the single-machine coupled task scheduling problem with exact delays to minimize the makespan</title>
      <link>https://arxiv.org/abs/2512.23150</link>
      <description>arXiv:2512.23150v1 Announce Type: new 
Abstract: We consider the strongly NP-hard single-machine coupled task scheduling problem with exact delays to minimize the makespan. In this problem, a set of jobs has to be scheduled, each composed of two tasks interspersed by an exact delay. Given that no preemption is allowed, the goal consists of minimizing the completion time of the last scheduled task. We model the problem using constraint programming (CP) and propose a biased random-key genetic algorithm (BRKGA). Our CP model applies well-established global constraints. Our BRKGA combines some successful components in the literature: an initial solution generator, periodical restarts and shakes, and a local search algorithm. Furthermore, the BRKGA's decoder is focused on efficiency rather than optimality, which accelerates the solution space exploration. Computational experiments on a benchmark set containing instances with up to 100 jobs (200 tasks) indicate that the proposed BRKGA can efficiently explore the problem solution space, providing high-quality approximate solutions within low computational times. It can also provide better solutions than the CP model under the same computational settings, i.e., three minutes of time limit and a single thread. The CP model, when offered a longer running time of 3600 seconds and multiple threads, significantly improved the results, reaching the current best-known solution for 90.56% of these instances. Finally, our experiments highlight the importance of the shake and local search components in the BRKGA, whose combination significantly improves the results of a standard BRKGA.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.23150v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>V\'itor A. Barbosa, Rafael A. Melo</dc:creator>
    </item>
    <item>
      <title>A Proximal-Gradient Method for Solving Regularized Optimization Problems with General Constraints</title>
      <link>https://arxiv.org/abs/2512.23166</link>
      <description>arXiv:2512.23166v1 Announce Type: new 
Abstract: We propose, analyze, and test a proximal-gradient method for solving regularized optimization problems with general constraints. The method employs a decomposition strategy to compute trial steps and uses a merit function to determine step acceptance or rejection. Under various assumptions, we establish a worst-case iteration complexity result, prove that limit points are first-order KKT points, and show that manifold identification and active-set identification properties hold. Preliminary numerical experiments on a subset of the CUTEst test problems and sparse canonical correlation analysis problems demonstrate the promising performance of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.23166v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Frank E. Curtis, Xiaoyi Qu, Daniel P. Robinson</dc:creator>
    </item>
    <item>
      <title>Clipped Gradient Methods for Nonsmooth Convex Optimization under Heavy-Tailed Noise: A Refined Analysis</title>
      <link>https://arxiv.org/abs/2512.23178</link>
      <description>arXiv:2512.23178v1 Announce Type: new 
Abstract: Optimization under heavy-tailed noise has become popular recently, since it better fits many modern machine learning tasks, as captured by empirical observations. Concretely, instead of a finite second moment on gradient noise, a bounded ${\frak p}$-th moment where ${\frak p}\in(1,2]$ has been recognized to be more realistic (say being upper bounded by $\sigma_{\frak l}^{\frak p}$ for some $\sigma_{\frak l}\ge0$). A simple yet effective operation, gradient clipping, is known to handle this new challenge successfully. Specifically, Clipped Stochastic Gradient Descent (Clipped SGD) guarantees a high-probability rate ${\cal O}(\sigma_{\frak l}\ln(1/\delta)T^{1/{\frak p}-1})$ (resp. ${\cal O}(\sigma_{\frak l}^2\ln^2(1/\delta)T^{2/{\frak p}-2})$) for nonsmooth convex (resp. strongly convex) problems, where $\delta\in(0,1]$ is the failure probability and $T\in\mathbb{N}$ is the time horizon. In this work, we provide a refined analysis for Clipped SGD and offer two faster rates, ${\cal O}(\sigma_{\frak l}d_{\rm eff}^{-1/2{\frak p}}\ln^{1-1/{\frak p}}(1/\delta)T^{1/{\frak p}-1})$ and ${\cal O}(\sigma_{\frak l}^2d_{\rm eff}^{-1/{\frak p}}\ln^{2-2/{\frak p}}(1/\delta)T^{2/{\frak p}-2})$, than the aforementioned best results, where $d_{\rm eff}\ge1$ is a quantity we call the $\textit{generalized effective dimension}$. Our analysis improves upon the existing approach on two sides: better utilization of Freedman's inequality and finer bounds for clipping error under heavy-tailed noise. In addition, we extend the refined analysis to convergence in expectation and obtain new rates that break the known lower bounds. Lastly, to complement the study, we establish new lower bounds for both high-probability and in-expectation convergence. Notably, the in-expectation lower bounds match our new upper bounds, indicating the optimality of our refined analysis for convergence in expectation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.23178v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zijian Liu</dc:creator>
    </item>
    <item>
      <title>Incorporating Authority Perception, Economic Status, and Behavioral Response in Infectious Disease Control</title>
      <link>https://arxiv.org/abs/2512.23188</link>
      <description>arXiv:2512.23188v1 Announce Type: new 
Abstract: We introduce a multi-population mean field game framework to examine how economic status and authority perception shape vaccination and social distancing decisions under different epidemic control policies. We carried out a survey to inform our model and stratify the population into six groups based on income and perception of authority, capturing behavioral heterogeneity. Individuals adjust their socialization and vaccination levels to optimize objectives such as minimizing treatment costs, complying with social-distancing guidelines if they are authority-followers, or reducing losses from decreased social interactions if they are authority-indifferents, alongside economic costs. Public health authorities influence behavior through social-distancing guidelines and vaccination costs. We characterize the Nash equilibrium via a forward-backward differential equation system, provide its mathematical analysis, and develop a numerical algorithm to solve it. Our findings reveal a trade-off between social-distancing and vaccination decisions. Under stricter guidelines that target both susceptible and infected individuals, followers reduce both socialization and vaccination levels, while indifferents increase socialization due to followers' preventative measures. Adaptive guidelines targeting infected individuals effectively reduce infections and narrow the gap between low- and high-income groups, even when susceptible individuals socialize more and vaccinate less. Lower vaccination costs incentivize vaccination among low-income groups, but their impact on disease spread is smaller than when they are coupled with social-distancing guidelines. Trust-building emerges as a critical factor in epidemic mitigation, underscoring the importance of data-informed, game-theoretical models that aim to understand complex human responses to mitigation policies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.23188v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Huaning Liu, Junke Yang, Soren L. Larsen, Pamela P. Martinez, Gokce Dayanikli</dc:creator>
    </item>
    <item>
      <title>Output feedback stabilization of linear port-Hamiltonian descriptor systems</title>
      <link>https://arxiv.org/abs/2512.23203</link>
      <description>arXiv:2512.23203v1 Announce Type: new 
Abstract: This paper presents a structure-preserving method for the stabilization of linear port-Hamiltonian (pH) descriptor systems via output feedback. The stabilization problem is NP-hard for general descriptor systems. Existing approaches often rely on explicit knowledge of the structure-defining matrix $Q$, which is difficult to determine in practice. When $Q$ is unknown, we derive necessary and sufficient conditions under which proportional output feedback ensures that the closed-loop system is regular, impulse-free, asymptotically stable, and retains the port-Hamiltonian structure. These conditions also allow any positive definite matrix to serve as the feedback matrix. The framework is further extended to proportional and derivative output feedback, enabling the assignment of a desired dynamical order. The proposed method thus generalizes existing stabilization results from the special case $Q = I$ to systems with an unknown $Q$, offering a systematic method to structure-preserving stabilization of pH descriptor systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.23203v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuo Shi, Juan Zhang</dc:creator>
    </item>
    <item>
      <title>Essential Convergence Rates of Continuous-Time Models for Optimization Methods</title>
      <link>https://arxiv.org/abs/2512.23317</link>
      <description>arXiv:2512.23317v1 Announce Type: new 
Abstract: Designing and analyzing optimization methods via continuous-time models expressed as ordinary differential equations (ODEs) is a promising approach for its intuitiveness and simplicity. A key concern, however, is that the convergence rates of such models can be arbitrarily modified by time rescaling, rendering the task of seeking ODEs with ``fast'' convergence meaningless. To eliminate this ambiguity of the rates, we introduce the notion of the essential convergence rate. We justify this notion by proving that, under appropriate assumptions on discretization, no method obtained by discretizing an ODE can achieve a faster rate than its essential convergence rate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.23317v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kansei Ushiyama, Shun Sato, Takayasu Matsuo</dc:creator>
    </item>
    <item>
      <title>Small-time global controllability of a class of bilinear fourth-order parabolic equations</title>
      <link>https://arxiv.org/abs/2512.23339</link>
      <description>arXiv:2512.23339v1 Announce Type: new 
Abstract: In this work, we investigate the small-time global controllability properties of a class of fourth-order nonlinear parabolic equations driven by a bilinear control posed on the one-dimensional torus. The controls depend only on time and act through a prescribed family of spatial profiles. Our first result establishes the small-time global approximate controllability of the system using three scalar controls, between states that share the same sign. This property is obtained by adapting the geometric control approach to the fourth-order setting, using a finite family of frequency-localized controls. We then study the small-time global exact controllability to non-zero constant states for the concerned system. This second result is achieved by analyzing the null controllability of an appropriate linearized fourth-order system and by deducing the controllability of the nonlinear bilinear model through a fixed-point argument together with the small-time global approximate control property.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.23339v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Subrata Majumdar, Debanjit Mondal</dc:creator>
    </item>
    <item>
      <title>Identifying faulty edges in resistive electrical networks</title>
      <link>https://arxiv.org/abs/2512.23527</link>
      <description>arXiv:2512.23527v1 Announce Type: new 
Abstract: Given a resistive electrical network, we would like to determine whether all the resistances (edges) in the network are working, and if not, identify which edge (or edges) are faulty. To make this determination, we are allowed to measure the effective resistance between certain pairs of nodes (which can be done by measuring the amount of current when one unit of voltage difference is applied at the chosen pair of nodes). The goal is to determine which edge, if any, is not working in the network using the smallest number of measurements. We prove rigorous upper and lower bounds on this optimal number of measurements for different classes of graphs. These bounds are tight for several of these classes showing that our measurement strategies are optimal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.23527v1</guid>
      <category>math.OC</category>
      <category>cs.DM</category>
      <category>cs.IT</category>
      <category>math.CO</category>
      <category>math.IT</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Barbara Fiedorowicz, Amitabh Basu</dc:creator>
    </item>
    <item>
      <title>A dimension reduction procedure for the selection of Two-spring lattice-spring topologies with minimal fabrication cost and required weighted force-resistance performance</title>
      <link>https://arxiv.org/abs/2512.23695</link>
      <description>arXiv:2512.23695v1 Announce Type: new 
Abstract: Starting from a problem in elastoplasticity, we consider an optimization problem $C(c_1,c_2)=c_1+c_2\to \min$ under constraints $F_R^k(c_1,c_2)=a\cdot F^k(c_1,c_2)+b\cdot R^k(c_1,c_2)\ge 1$ and $F^k(c_1,c_2)\ge 1$, where both $F^k$ and $R^k$ non-linear, $a,b$ are constants, and $i\in\{1,2\}$ is an index. For each $(a,b)$ we determine which of the two values of $i\in\{1,2\}$ leads to the smaller minimum of the optimization problem. This way we obtain an interesting curve bounding the region where $k=1$ outperforms $k=2$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.23695v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Egor Makarenkov</dc:creator>
    </item>
    <item>
      <title>The Solution of Potential-Driven, Steady-State Nonlinear Network Flow Equations via Graph Partitioning</title>
      <link>https://arxiv.org/abs/2512.22124</link>
      <description>arXiv:2512.22124v1 Announce Type: cross 
Abstract: The solution of potential-driven steady-state flow in large networks is required in various engineering applications, such as transport of natural gas or water through pipeline networks. The resultant system of nonlinear equations depends on the network topology, and its solution grows more challenging as the network size increases. We present an algorithm that utilizes a given partition of a network into tractable sizes to compute a global solution for the full nonlinear system through local solution of smaller subsystems induced by the partitions. When the partitions are induced by interconnects or transfer points corresponding to networks owned by different operators, the method ensures data is shared solely at the interconnects, leaving network operators free to solve the network flow system corresponding to their own domain in any manner of their choosing. The proposed method is shown to be connected to the Schur complement and the method's viability demonstrated on some challenging test cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.22124v1</guid>
      <category>physics.comp-ph</category>
      <category>math.OC</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Shriram Srinivasan, Kaarthik Sundar</dc:creator>
    </item>
    <item>
      <title>Validation methodology on real data of reversible Kalman Filter for state estimation with Manifold</title>
      <link>https://arxiv.org/abs/2512.22126</link>
      <description>arXiv:2512.22126v1 Announce Type: cross 
Abstract: This work extends a previous study that introduced an algorithm for state estimation on manifolds within the framework of the Kalman filter. Its objective is to address the limitations of the earlier approach. The reversible Kalman filter was designed to provide a methodology for evaluating the accuracy of existing Kalman filter variants with arbitrary precision on synthetic data. It has favorable numerical properties on synthetic data, achieving arbitrary precision without relying on the small-velocity assumption and depending only on sensor noise. However, its application to real data encountered difficulties related to measurement noise, which was mitigated using a heuristic. In particular, the heuristic involved an event detection step switching between reversible Kalman filter and classical Kalman variant at chosen moments. In the present work, we propose a study of this detection step and propose a methodology to prove at which moment the reversible Kalman approach improves on classical multiplicative variant. In particular, we propose a metric allowing one to discriminate situations in real-world scenarios where it behaves better than classical approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.22126v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Svyatoslav Covanov, Cedric Pradalier</dc:creator>
    </item>
    <item>
      <title>A review of NMF, PLSA, LBA, EMA, and LCA with a focus on the identifiability issue</title>
      <link>https://arxiv.org/abs/2512.22282</link>
      <description>arXiv:2512.22282v1 Announce Type: cross 
Abstract: Across fields such as machine learning, social science, geography, considerable attention has been given to models that factorize a nonnegative matrix into the product of two or three matrices, subject to nonnegative or row-sum-to-1 constraints. Although these models are to a large extend similar or even equivalent, they are presented under different names, and their similarity is not well known. This paper highlights similarities among five popular models, latent budget analysis (LBA), latent class analysis (LCA), end-member analysis (EMA), probabilistic latent semantic analysis (PLSA), and nonnegative matrix factorization (NMF). We focus on an essential issue-identifiability-of these models and prove that the solution of LBA, EMA, LCA, PLSA is unique if and only if the solution of NMF is unique. We also provide a brief review for algorithms of these models. We illustrate the models with a time budget dataset from social science, and end the paper with a discussion of closely related models such as archetypal analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.22282v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qianqian Qi, Peter G. M. van der Heijden</dc:creator>
    </item>
    <item>
      <title>BLISS: Bandit Layer Importance Sampling Strategy for Efficient Training of Graph Neural Networks</title>
      <link>https://arxiv.org/abs/2512.22388</link>
      <description>arXiv:2512.22388v1 Announce Type: cross 
Abstract: Graph Neural Networks (GNNs) are powerful tools for learning from graph-structured data, but their application to large graphs is hindered by computational costs. The need to process every neighbor for each node creates memory and computational bottlenecks. To address this, we introduce BLISS, a Bandit Layer Importance Sampling Strategy. It uses multi-armed bandits to dynamically select the most informative nodes at each layer, balancing exploration and exploitation to ensure comprehensive graph coverage. Unlike existing static sampling methods, BLISS adapts to evolving node importance, leading to more informed node selection and improved performance. It demonstrates versatility by integrating with both Graph Convolutional Networks (GCNs) and Graph Attention Networks (GATs), adapting its selection policy to their specific aggregation mechanisms. Experiments show that BLISS maintains or exceeds the accuracy of full-batch training.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.22388v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.SI</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Omar Alsaqa, Linh Thi Hoang, Muhammed Fatih Balin</dc:creator>
    </item>
    <item>
      <title>Communication Compression for Distributed Learning with Aggregate and Server-Guided Feedback</title>
      <link>https://arxiv.org/abs/2512.22623</link>
      <description>arXiv:2512.22623v1 Announce Type: cross 
Abstract: Distributed learning, particularly Federated Learning (FL), faces a significant bottleneck in the communication cost, particularly the uplink transmission of client-to-server updates, which is often constrained by asymmetric bandwidth limits at the edge. Biased compression techniques are effective in practice, but require error feedback mechanisms to provide theoretical guarantees and to ensure convergence when compression is aggressive. Standard error feedback, however, relies on client-specific control variates, which violates user privacy and is incompatible with stateless clients common in large-scale FL. This paper proposes two novel frameworks that enable biased compression without client-side state or control variates. The first, Compressed Aggregate Feedback (CAFe), uses the globally aggregated update from the previous round as a shared control variate for all clients. The second, Server-Guided Compressed Aggregate Feedback (CAFe-S), extends this idea to scenarios where the server possesses a small private dataset; it generates a server-guided candidate update to be used as a more accurate predictor. We consider Distributed Gradient Descent (DGD) as a representative algorithm and analytically prove CAFe's superiority to Distributed Compressed Gradient Descent (DCGD) with biased compression in the non-convex regime with bounded gradient dissimilarity. We further prove that CAFe-S converges to a stationary point, with a rate that improves as the server's data become more representative. Experimental results in FL scenarios validate the superiority of our approaches over existing compression schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.22623v1</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.OC</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Tomas Ortega, Chun-Yin Huang, Xiaoxiao Li, Hamid Jafarkhani</dc:creator>
    </item>
    <item>
      <title>Active Constraint Learning in High Dimensions from Demonstrations</title>
      <link>https://arxiv.org/abs/2512.22757</link>
      <description>arXiv:2512.22757v1 Announce Type: cross 
Abstract: We present an iterative active constraint learning (ACL) algorithm, within the learning from demonstrations (LfD) paradigm, which intelligently solicits informative demonstration trajectories for inferring an unknown constraint in the demonstrator's environment. Our approach iteratively trains a Gaussian process (GP) on the available demonstration dataset to represent the unknown constraints, uses the resulting GP posterior to query start/goal states, and generates informative demonstrations which are added to the dataset. Across simulation and hardware experiments using high-dimensional nonlinear dynamics and unknown nonlinear constraints, our method outperforms a baseline, random-sampling based method at accurately performing constraint inference from an iteratively generated set of sparse but informative demonstrations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.22757v1</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zheng Qiu, Chih-Yuan Chiu, Glen Chou</dc:creator>
    </item>
    <item>
      <title>A Counterexample to the Optimality Conjecture in Convex Quantum Channel Optimization</title>
      <link>https://arxiv.org/abs/2512.22863</link>
      <description>arXiv:2512.22863v1 Announce Type: cross 
Abstract: This paper presents a counterexample to the optimality conjecture in convex quantum channel optimization proposed by Coutts et al. The conjecture posits that for nuclear norm minimization problems in quantum channel optimization, the dual certificate of an optimal solution can be uniquely determined via the spectral calculus of the Choi matrix. By constructing a counterexample in 2-dimensional Hilbert spaces, we disprove this conjecture.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.22863v1</guid>
      <category>quant-ph</category>
      <category>math.OC</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jianting Yang</dc:creator>
    </item>
    <item>
      <title>Fast chiral resolution with optimal control</title>
      <link>https://arxiv.org/abs/2512.22998</link>
      <description>arXiv:2512.22998v1 Announce Type: cross 
Abstract: In this work, we formulate the problem of achieving in minimum-time perfect chiral resolution with bounded control fields, as an optimal control problem on two non-interacting spins-$1/2$. We assume the same control bound for the two Raman fields (pump and Stokes) and a different bound for the field connecting directly the two lower-energy states. Using control theory, we show that the optimal fields can only take the boundary values or be zero, the latter corresponding to singular control. Subsequently, using numerical optimal control and intuitive arguments, we identify some three-stage symmetric optimal pulse-sequences, for relatively larger values of the ratio between the two control bounds, and analytically calculate the corresponding pulse timings as functions of this ratio. For smaller values of the bounds ratio, numerical optimal control indicates that the optimal pulse-sequence loses its symmetry and the number of stages increases in general. In all cases, the analytical or numerical optimal protocol achieves a faster perfect chiral resolution than other pulsed protocols, mainly because of the simultaneous action of the control fields. The present work is expected to be useful in the wide spectrum of applications across the natural sciences where enantiomer separation is a crucial task.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.22998v1</guid>
      <category>quant-ph</category>
      <category>math.OC</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1103/fkmb-b4k4</arxiv:DOI>
      <arxiv:journal_reference>Physical Review A 112, 023116 (2025)</arxiv:journal_reference>
      <dc:creator>Dionisis Stefanatos, Ioannis Thanopulos, Emmanuel Paspalakis</dc:creator>
    </item>
    <item>
      <title>A Simple, Optimal and Efficient Algorithm for Online Exp-Concave Optimization</title>
      <link>https://arxiv.org/abs/2512.23190</link>
      <description>arXiv:2512.23190v1 Announce Type: cross 
Abstract: Online eXp-concave Optimization (OXO) is a fundamental problem in online learning. The standard algorithm, Online Newton Step (ONS), balances statistical optimality and computational practicality, guaranteeing an optimal regret of $O(d \log T)$, where $d$ is the dimension and $T$ is the time horizon. ONS faces a computational bottleneck due to the Mahalanobis projections at each round. This step costs $\Omega(d^\omega)$ arithmetic operations for bounded domains, even for the unit ball, where $\omega \in (2,3]$ is the matrix-multiplication exponent. As a result, the total runtime can reach $\tilde{O}(d^\omega T)$, particularly when iterates frequently oscillate near the domain boundary. For Stochastic eXp-concave Optimization (SXO), computational cost is also a challenge. Deploying ONS with online-to-batch conversion for SXO requires $T = \tilde{O}(d/\epsilon)$ rounds to achieve an excess risk of $\epsilon$, and thereby necessitates an $\tilde{O}(d^{\omega+1}/\epsilon)$ runtime. A COLT'13 open problem posed by Koren [2013] asks for an SXO algorithm with runtime less than $\tilde{O}(d^{\omega+1}/\epsilon)$.
  This paper proposes a simple variant of ONS, LightONS, which reduces the total runtime to $O(d^2 T + d^\omega \sqrt{T \log T})$ while preserving the optimal $O(d \log T)$ regret. LightONS implies an SXO method with runtime $\tilde{O}(d^3/\epsilon)$, thereby answering the open problem. Importantly, LightONS preserves the elegant structure of ONS by leveraging domain-conversion techniques from parameter-free online learning to introduce a hysteresis mechanism that delays expensive Mahalanobis projections until necessary. This design enables LightONS to serve as an efficient plug-in replacement of ONS in broader scenarios, even beyond regret minimization, including gradient-norm adaptive regret, parametric stochastic bandits, and memory-efficient online learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.23190v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yi-Han Wang, Peng Zhao, Zhi-Hua Zhou</dc:creator>
    </item>
    <item>
      <title>Revealing design archetypes and flexibility in e-molecule import pathways using Modeling to Generate Alternatives and interpretable machine learning</title>
      <link>https://arxiv.org/abs/2512.23284</link>
      <description>arXiv:2512.23284v1 Announce Type: cross 
Abstract: Given the central role of green e-molecule imports in the European energy transition, many studies optimize import pathways and identify a single cost-optimal solution. However, cost optimality is fragile, as real-world implementation depends on regulatory, spatial, and stakeholder constraints that are difficult to represent in optimization models and can render cost-optimal designs infeasible. To address this limitation, we generate a diverse set of near-cost-optimal alternatives within an acceptable cost margin using Modeling to Generate Alternatives, accounting for unmodeled uncertainties. Interpretable machine learning is then applied to extract insights from the resulting solution space. The approach is applied to hydrogen import pathways considering hydrogen, ammonia, methane, and methanol as carriers. Results reveal a broad near-optimal space with great flexibility: solar, wind, and storage are not strictly required to remain within 10% of the cost optimum. Wind constraints favor solar-storage methanol pathways, while limited storage favors wind-based ammonia or methane pathways.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.23284v1</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mahdi Kchaou, Francesco Contino, Diederik Coppitters</dc:creator>
    </item>
    <item>
      <title>From geometry to dynamics: Learning overdamped Langevin dynamics from sparse observations with geometric constraints</title>
      <link>https://arxiv.org/abs/2512.23566</link>
      <description>arXiv:2512.23566v1 Announce Type: cross 
Abstract: How can we learn the laws underlying the dynamics of stochastic systems when their trajectories are sampled sparsely in time? Existing methods either require temporally resolved high-frequency observations, or rely on geometric arguments that apply only to conservative systems, limiting the range of dynamics they can recover. Here, we present a new framework that reconciles these two perspectives by reformulating inference as a stochastic control problem. Our method uses geometry-driven path augmentation, guided by the geometry in the system's invariant density to reconstruct likely trajectories and infer the underlying dynamics without assuming specific parametric models. Applied to overdamped Langevin systems, our approach accurately recovers stochastic dynamics even from extremely undersampled data, outperforming existing methods in synthetic benchmarks. This work demonstrates the effectiveness of incorporating geometric inductive biases into stochastic system identification methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.23566v1</guid>
      <category>math.DS</category>
      <category>cond-mat.stat-mech</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dimitra Maoutsa</dc:creator>
    </item>
    <item>
      <title>The N-5 Scaling Law: Topological Dimensionality Reduction in the Optimal Design of Fully-actuated Multirotors</title>
      <link>https://arxiv.org/abs/2512.23619</link>
      <description>arXiv:2512.23619v1 Announce Type: cross 
Abstract: The geometric design of fully-actuated and omnidirectional N-rotor aerial vehicles is conventionally formulated as a parametric optimization problem, seeking a single optimal set of N orientations within a fixed architectural family. This work departs from that paradigm to investigate the intrinsic topological structure of the optimization landscape itself. We formulate the design problem on the product manifold of Projective Lines \RP^2^N, fixing the rotor positions to the vertices of polyhedral chassis while varying their lines of action. By minimizing a coordinate-invariant Log-Volume isotropy metric, we reveal that the topology of the global optima is governed strictly by the symmetry of the chassis. For generic (irregular) vertex arrangements, the solutions appear as a discrete set of isolated points. However, as the chassis geometry approaches regularity, the solution space undergoes a critical phase transition, collapsing onto an N-dimensional Torus of the lines tangent at the vertexes to the circumscribing sphere of the chassis, and subsequently reducing to continuous 1-dimensional curves driven by Affine Phase Locking. We synthesize these observations into the N-5 Scaling Law: an empirical relationship holding for all examined regular planar polygons and Platonic solids (N &lt;= 10), where the space of optimal configurations consists of K=N-5 disconnected 1D topological branches. We demonstrate that these locking patterns correspond to a sequence of admissible Star Polygons {N/q}, allowing for the exact prediction of optimal phases for arbitrary N. Crucially, this topology reveals a design redundancy that enables optimality-preserving morphing: the vehicle can continuously reconfigure along these branches while preserving optimal isotropic control authority.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.23619v1</guid>
      <category>cs.RO</category>
      <category>math.GT</category>
      <category>math.OC</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Antonio Franchi</dc:creator>
    </item>
    <item>
      <title>Calibrated Multi-Level Quantile Forecasting</title>
      <link>https://arxiv.org/abs/2512.23671</link>
      <description>arXiv:2512.23671v1 Announce Type: cross 
Abstract: We present an online method for guaranteeing calibration of quantile forecasts at multiple quantile levels simultaneously. A sequence of $\alpha$-level quantile forecasts is calibrated if the forecasts are larger than the target value at an $\alpha$-fraction of time steps. We introduce a lightweight method called Multi-Level Quantile Tracker (MultiQT) that wraps around any existing point or quantile forecaster to produce corrected forecasts guaranteed to achieve calibration, even against adversarial distribution shifts, while ensuring that the forecasts are ordered -- e.g., the 0.5-level quantile forecast is never larger than the 0.6-level forecast. Furthermore, the method comes with a no-regret guarantee that implies it will not worsen the performance of an existing forecaster, asymptotically, with respect to the quantile loss. In experiments, we find that MultiQT significantly improves the calibration of real forecasters in epidemic and energy forecasting problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.23671v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ME</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tiffany Ding, Isaac Gibbs, Ryan J. Tibshirani</dc:creator>
    </item>
    <item>
      <title>Anisotropic Proximal Point Algorithm</title>
      <link>https://arxiv.org/abs/2312.09834</link>
      <description>arXiv:2312.09834v4 Announce Type: replace 
Abstract: In this paper we study a nonlinear dual space preconditioning approach for the relaxed Proximal Point Algorithm (PPA) with application to monotone and relatively cohypomonotone inclusions, called anisotropic PPA. The algorithm is an instance of Luque's nonlinear PPA wherein the nonlinear preconditioner is chosen as the gradient of a Legendre convex function. Since the preconditioned operator is nonmonotone in general, convergence cannot be shown using standard arguments, unless the preconditioner exhibits isotropy (preserves directions) as in existing literature. To address the broader applicability we show convergence along subsequences invoking a Bregman version of Fej\'er-monotonicity in the dual space. Via a nonlinear generalization of Moreau's decomposition for operators, we provide a dual interpretation of the algorithm in terms of a forward iteration applied to a $D$-firmly nonexpansive mapping which involves the Bregman resolvent. For a suitable preconditioner, convergence rates of arbitrary order are derived under a mild H\"older growth condition. Finally, we discuss an anisotropic generalization of the proximal augmented Lagrangian method obtained via the proposed scheme. This aligns with Rockafellar's generalized and sharp Lagrangian functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.09834v4</guid>
      <category>math.OC</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Emanuel Laude, Panagiotis Patrinos</dc:creator>
    </item>
    <item>
      <title>EM++: A parameter learning framework for stochastic switching systems</title>
      <link>https://arxiv.org/abs/2407.16359</link>
      <description>arXiv:2407.16359v2 Announce Type: replace 
Abstract: This paper proposes a general switching dynamical system model, and a custom majorization-minimization-based algorithm EM++ for identifying its parameters. For certain families of distributions, such as Gaussian distributions, this algorithm reduces to the well-known expectation-maximization method. We prove global convergence of the algorithm under suitable assumptions, thus addressing an important open issue in the switching system identification literature. The effectiveness of both the proposed model and algorithm is validated through extensive numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.16359v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Renzi Wang, Alexander Bodard, Mathijs Schuurmans, Panagiotis Patrinos</dc:creator>
    </item>
    <item>
      <title>Parametrized Families of Resolvent Compositions</title>
      <link>https://arxiv.org/abs/2410.01090</link>
      <description>arXiv:2410.01090v3 Announce Type: replace 
Abstract: This paper presents an in-depth analysis of a parametrized version of the resolvent composition, an operation that combines a set-valued operator and a linear operator. We provide new properties and examples, and show that resolvent compositions can be interpreted as parallel compositions of perturbed operators. Additionally, we establish new monotonicity results, even in cases when the initial operator is not monotone. Finally, we derive asymptotic results regarding operator convergence, specifically focusing on graph-convergence and the $\rho$-Hausdorff distance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.01090v3</guid>
      <category>math.OC</category>
      <category>math.FA</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Diego J. Cornejo</dc:creator>
    </item>
    <item>
      <title>A regularized transportation cost stemming from entropic approximation</title>
      <link>https://arxiv.org/abs/2501.03906</link>
      <description>arXiv:2501.03906v2 Announce Type: replace 
Abstract: We study the entropic regularizations of optimal transport problems under suitable summability assumptions on the point-wise transport cost. These summability assumptions already appear in the literature. However, we show that the weakest compactness conditions that can be derived are already enough to obtain the convergence of the regularized functionals. This approach allows us to characterize the variational limit of the regularization even when it does not converge to the original problem. The results apply also to problems with more than two marginals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.03906v2</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <category>math.PR</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Camilla Brizzi, Luigi De Pascale, Anna Kausamo</dc:creator>
    </item>
    <item>
      <title>Linear-quadratic optimal control for non-exchangeable mean-field SDEs and applications to systemic risk</title>
      <link>https://arxiv.org/abs/2503.03318</link>
      <description>arXiv:2503.03318v2 Announce Type: replace 
Abstract: We study the linear-quadratic control problem for a class of non-exchangeable mean-field systems, which model large populations of heterogeneous interacting agents. We explicitly characterize the optimal control in terms of a new infinite-dimensional system of Riccati equations, for which we establish existence and uniqueness. To illustrate our results, we apply this framework to a systemic risk model involving heterogeneous banks, demonstrating the impact of agent heterogeneity on optimal risk mitigation strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.03318v2</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anna de Crescenzo (UPCit\'e, LPSM), Filippo de Feo (X, CMAP), Huy\^en Pham (X, CMAP)</dc:creator>
    </item>
    <item>
      <title>How to optimise tournament draws: The case of the FIFA World Cup</title>
      <link>https://arxiv.org/abs/2505.13106</link>
      <description>arXiv:2505.13106v3 Announce Type: replace 
Abstract: The organisers of major sports competitions use different policies with respect to constraints in the group draw. Our paper aims to rationalise these choices by analysing the trade-off between attractiveness (the number of games played by teams from the same geographic zone) and fairness (the departure of the draw mechanism from a uniform distribution). A parametric optimisation model is formulated and applied to the 2018 and 2022 FIFA World Cup draws. A flaw of the draw procedure is identified: the pre-assignment of the host to a group unnecessarily increases the distortions. All Pareto efficient sets of draw constraints are determined via simulations. The proposed framework can be used to find the optimal draw rules and justify the non-uniformity of the draw procedure for the stakeholders.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13106v3</guid>
      <category>math.OC</category>
      <category>physics.soc-ph</category>
      <category>stat.AP</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>L\'aszl\'o Csat\'o</dc:creator>
    </item>
    <item>
      <title>Model-free source seeking of exponentially convergent unicycle: theoretical and robotic experimental results</title>
      <link>https://arxiv.org/abs/2511.00752</link>
      <description>arXiv:2511.00752v2 Announce Type: replace 
Abstract: This paper introduces a novel model-free, real-time unicycle-based source seeking design. This design autonomously steers the unicycle dynamic system towards the extremum point of an objective function or physical/scalar signal that is unknown expression-wise, but accessible via measurements. A key contribution of this paper is that the introduced design converges exponentially to the extremum point of objective functions (or scalar signals) that behave locally like a higher-degree power function (e.g., fourth-degree polynomial function) as opposed to locally quadratic objective functions, the usual case in literature. We provide theoretical results and design characterization, supported by a variety of simulation results that demonstrate the robustness of the proposed design, including cases with different initial conditions and measurement delays/noise. Also, for the first time in the literature, we provide experimental robotic results that demonstrate the effectiveness of the proposed design and its exponential convergence ability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00752v2</guid>
      <category>math.OC</category>
      <category>cs.RO</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rohan Palanikumar, Ahmed A. Elgohary, Victoria Grushkovskaya, Sameh A. Eisa</dc:creator>
    </item>
    <item>
      <title>An alternative approach to well-posedness of McKean-Vlasov equations arising in Consensus-Based Optimization</title>
      <link>https://arxiv.org/abs/2512.19446</link>
      <description>arXiv:2512.19446v3 Announce Type: replace 
Abstract: In this work we study the mean-field description of Consensus-Based Optimization (CBO), a derivative-free particle optimization method. Such a description is provided by a non-local SDE of McKean-Vlasov type, whose fields lack of global Lipschitz continuity. We propose a novel approach to prove the well-posedness of the mean-field CBO equation based on a truncation argument. The latter is performed through the introduction of a cut-off function, defined on the space of probability measures, acting on the fields. This procedure allows us to study the well-posedness problem in the classical framework of Sznitman. Through this argument, we recover the established result on the existence of strong solutions, and we extend the class of solutions for which pathwise uniqueness holds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.19446v3</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <category>math.PR</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alessandro Baldi</dc:creator>
    </item>
    <item>
      <title>Contingency Model-based Control (CMC) for Communicationless Cooperative Collision Avoidance in Robot Swarms</title>
      <link>https://arxiv.org/abs/2512.20391</link>
      <description>arXiv:2512.20391v2 Announce Type: replace 
Abstract: Cooperative collision avoidance between robots in swarm operations remains an open challenge. Assuming a decentralized architecture, each robot is responsible for making its own control decisions, including motion planning. To this end, most existing approaches mostly rely some form of (wireless) communication between the agents of the swarm. In reality, however, communication is brittle. It may be affected by latency, further delays and packet losses, transmission faults, and is subject to adversarial attacks, such as jamming or spoofing. This paper proposes Contingency Model-based Control (CMC) as a communicationless alternative. It follows the implicit cooperation paradigm, under which the design of the robots is based on consensual (offline) rules, similar to traffic rules. They include the definition of a contingency trajectory for each robot, and a method for construction of mutual collision avoidance constraints. The setup is shown to guarantee the recursive feasibility and collision avoidance between all swarm members in closed-loop operation. Moreover, CMC naturally satisfies the Plug \&amp; Play paradigm, i.e., for new robots entering the swarm. Two numerical examples demonstrate that the collision avoidance guarantee is intact and that the robot swarm operates smoothly under the CMC regime.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.20391v2</guid>
      <category>math.OC</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Georg Schildbach</dc:creator>
    </item>
    <item>
      <title>The Dynamical Anatomy of Anderson Acceleration:From Adaptive Momentum to Variable-Mass ODEs</title>
      <link>https://arxiv.org/abs/2512.21269</link>
      <description>arXiv:2512.21269v2 Announce Type: replace 
Abstract: This paper provides a rigorous derivation and analysis of accelerated optimization algorithms through the lens of High-Resolution Ordinary Differential Equations (ODEs). While classical Nesterov acceleration is well-understood via asymptotic vanishing damping, the dynamics of Anderson Acceleration (AA) remain less transparent. This work makes significant theoretical contributions to AA by bridging discrete acceleration algorithms with continuous dynamical systems, while also providing practical algorithmic innovations. Our work addresses fundamental questions about the physical nature of Anderson Acceleration that have remained unanswered since its introduction in 1965. Firstly, we prove that AA can be exactly rewritten as an adaptive momentum method and, in the high-resolution limit, converges to a second-order ODE with Variable Effective Mass. Through a Lyapunov energy analysis, we reveal the specific instability mechanism of standard AA: unchecked growth in effective mass acts as negative damping, physically injecting energy into the system and violating dissipation constraints. Conversely, high-resolution analysis identifies an implicit Hessian-driven damping term that provides stabilization in stiff regimes. Leveraging these dynamical insights, we then propose Energy-Guarded Anderson Acceleration (EG-AA), an algorithm that acts as an inertial governor to enforce thermodynamic consistency. Morevoer, our convergence analysis, formulated via the Acceleration Gain Factor, proves that EG-AA improves upon gradient descent by maximizing the geometric contraction of the linear subspace projection while actively suppressing nonlinear approximation errors. Theoretical bounds confirm that EG-AA is no worse than standard AA, and numerical experiments demonstrate strictly improved convergence stability and rates in ill-conditioned convex composite problems compared to standard Anderson mixing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.21269v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kewang Chen, Yongqiu Jiang, Kees Vuik</dc:creator>
    </item>
    <item>
      <title>Revisiting the Last-Iterate Convergence of Stochastic Gradient Methods</title>
      <link>https://arxiv.org/abs/2312.08531</link>
      <description>arXiv:2312.08531v3 Announce Type: replace-cross 
Abstract: In the past several years, the last-iterate convergence of the Stochastic Gradient Descent (SGD) algorithm has triggered people's interest due to its good performance in practice but lack of theoretical understanding. For Lipschitz convex functions, different works have established the optimal $O(\log(1/\delta)\log T/\sqrt{T})$ or $O(\sqrt{\log(1/\delta)/T})$ high-probability convergence rates for the final iterate, where T is the time horizon and \delta is the failure probability. However, to prove these bounds, all the existing works are either limited to compact domains or require almost surely bounded noise. It is natural to ask whether the last iterate of SGD can still guarantee the optimal convergence rate but without these two restrictive assumptions. Besides this important question, there are still lots of theoretical problems lacking an answer. For example, compared with the last-iterate convergence of SGD for non-smooth problems, only few results for smooth optimization have yet been developed. Additionally, the existing results are all limited to a non-composite objective and the standard Euclidean norm. It still remains unclear whether the last-iterate convergence can be provably extended to wider composite optimization and non-Euclidean norms. In this work, to address the issues mentioned above, we revisit the last-iterate convergence of stochastic gradient methods and provide the first unified way to prove the convergence rates both in expectation and in high probability to accommodate general domains, composite objectives, non-Euclidean norms, Lipschitz conditions, smoothness, and (strong) convexity simultaneously. Additionally, we extend our analysis to obtain the last-iterate convergence under heavy-tailed noise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.08531v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zijian Liu, Zhengyuan Zhou</dc:creator>
    </item>
    <item>
      <title>On the Convergence Theory of Pipeline Gradient-based Analog In-memory Training</title>
      <link>https://arxiv.org/abs/2410.15155</link>
      <description>arXiv:2410.15155v2 Announce Type: replace-cross 
Abstract: Aiming to accelerate the training of large deep neural networks (DNN) in an energy-efficient way, analog in-memory computing (AIMC) emerges as a solution with immense potential. AIMC accelerator keeps model weights in memory without moving them from memory to processors during training, reducing overhead dramatically. Despite its efficiency, scaling up AIMC systems presents significant challenges. Since weight copying is expensive and inaccurate, data parallelism is less efficient on AIMC accelerators. It necessitates the exploration of pipeline parallelism, particularly asynchronous pipeline parallelism, which utilizes all available accelerators during the training process. This paper examines the convergence theory of stochastic gradient descent on AIMC hardware with an asynchronous pipeline (Analog-SGD-AP). Although there is empirical exploration of AIMC accelerators, the theoretical understanding of how analog hardware imperfections in weight updates affect the training of multi-layer DNN models remains underexplored. Furthermore, the asynchronous pipeline parallelism results in stale weights issues, which render the update signals no longer valid gradients. To close the gap, this paper investigates the convergence properties of Analog-SGD-AP on multi-layer DNN training. We show that the Analog-SGD-AP converges with iteration complexity $O(\varepsilon^{-2}+\varepsilon^{-1})$ despite the aforementioned issues, which matches the complexities of digital SGD and Analog SGD with synchronous pipeline, except the non-dominant term $O(\varepsilon^{-1})$. It implies that AIMC training benefits from asynchronous pipelining almost for free compared with the synchronous pipeline by overlapping computation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15155v2</guid>
      <category>cs.LG</category>
      <category>cs.AR</category>
      <category>math.OC</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhaoxian Wu, Quan Xiao, Tayfun Gokmen, Hsinyu Tsai, Kaoutar El Maghraoui, Tianyi Chen</dc:creator>
    </item>
    <item>
      <title>Edge of Stochastic Stability: Revisiting the Edge of Stability for SGD</title>
      <link>https://arxiv.org/abs/2412.20553</link>
      <description>arXiv:2412.20553v5 Announce Type: replace-cross 
Abstract: Recent findings by Cohen et al., 2021, demonstrate that when training neural networks using full-batch gradient descent with a step size of $\eta$, the largest eigenvalue $\lambda_{\max}$ of the full-batch Hessian consistently stabilizes around $2/\eta$. These results have significant implications for convergence and generalization. This, however, is not the case for mini-batch optimization algorithms, limiting the broader applicabilityof the consequences of these findings. We show mini-batch Stochastic Gradient Descent (SGD) trains in a different regime we term Edge of Stochastic Stability (EoSS). In this regime, what stabilizes at $2/\eta$ is Batch Sharpness: the expected directional curvature of mini-batch Hessians along their corresponding stochastic gradients. As a consequence $\lambda_{\max}$ -- which is generally smaller than Batch Sharpness -- is suppressed, aligning with the long-standing empirical observation that smaller batches and larger step sizes favor flatter minima. We further discuss implications for mathematical modeling of SGD trajectories.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.20553v5</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arseniy Andreyev, Pierfrancesco Beneventano</dc:creator>
    </item>
    <item>
      <title>Sequential Operation of Residential Energy Hubs using Physics-Based Economic Nonlinear MPC</title>
      <link>https://arxiv.org/abs/2507.20621</link>
      <description>arXiv:2507.20621v2 Announce Type: replace-cross 
Abstract: The operation of residential energy hubs with multiple energy carriers (electricity, heat, mobility) poses a significant challenge due to different carrier dynamics, hybrid storage coordination and high-dimensional action-spaces. Energy management systems oversee their operation, deciding the set points of the primary control layer. This paper presents a novel 2-stage economic model predictive controller for electrified buildings including physics-based models of the battery degradation and thermal systems. The hierarchical control operates in the Dutch sequential energy markets. In particular common assumptions regarding intra-day markets (auction and continuous-time) are discussed as well as the coupling of the different storage systems. The best control policy it is best to follow continuous time intra-day in the summer and the intra-day auction in the winter. This sequential operation comes at the expense of increased battery degradation. Lastly, under our controller, the realized short-term flexibility of the thermal energy storage is marginal compared to the flexibility delivered by stationary battery pack and electric vehicles with bidirectional charging.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.20621v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Dar\'io Slaifstein (Delft University of Technology), Gautham Ram Chandra Mouli (Delft University of Technology), Laura Ramirez-Elizondo (Delft University of Technology), Pavol Bauer (Delft University of Technology)</dc:creator>
    </item>
    <item>
      <title>A Theory of Saving under Risk Preference Dynamics</title>
      <link>https://arxiv.org/abs/2511.03142</link>
      <description>arXiv:2511.03142v2 Announce Type: replace-cross 
Abstract: Empirical evidence shows that wealthy households have substantially higher saving rates and markedly lower marginal propensity to consume (MPC) than other groups. Existing theory cannot account for this pattern unless under restrictive assumptions on returns, discounting, and preferences. This paper develops a general theory of optimal savings with preference shocks, allowing risk aversion to vary across states and over time. We show that incorporating such heterogeneity in risk attitudes fundamentally alters the asymptotic dynamics of consumption and saving. In particular, we provide an analytical characterization of the asymptotic MPCs and show that zero asymptotic MPCs, corresponding to a 100% asymptotic saving rate, arise under markedly weaker conditions than in existing theory. Strikingly, such outcomes occur whenever there is a positive probability that agents become less risk averse in the future. As a result, the vanishing MPC emerges as a generic feature rather than a knife-edge result of the optimal savings model, offering a more theoretically robust and empirically consistent account of the saving behavior of wealthy households.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.03142v2</guid>
      <category>econ.TH</category>
      <category>math.OC</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qingyin Ma, Xinxi Song, Alexis Akira Toda</dc:creator>
    </item>
    <item>
      <title>Beyond Single-Device Constraints: A System-Level Theoretical Framework for High-Performance Single-Photon Detection at Room Temperature</title>
      <link>https://arxiv.org/abs/2512.01328</link>
      <description>arXiv:2512.01328v4 Announce Type: replace-cross 
Abstract: Photon detection, a fundamental quantum technology, is traditionally treated as a fixed device-level operation governed by intrinsic properties of single-photon detectors (SPDs). High-performance detection has therefore largely relied on superconducting technologies whose requirement for cryogenic operation imposes substantial infrastructure constraints, limiting scalable deployments. Here, the enhanced single-photon detection (ESPD) framework is presented as a system-level theoretical paradigm that shifts photon detection from device-centric optimization to an integrated quantum-information-processing task, by reformulating it as an iteratively enhanced process integrating state-preparation, controlled operations, projective measurements, and multi-copy analysis. ESPD enables systematic performance enhancement through architectural design rather than material modification, thereby circumventing superconducting components, allowing high-performance detection using exclusively room-temperature hardware. Numerical simulations grounded in physically motivated parameters indicate that the ESPD framework can upgrade a conventional room-temperature SPD to effective DE exceeding 93\% and DCR below $10^{-9}$, which are comparable to state-of-the-art superconducting SPDs and can significantly relax the minimal tolerable channel transmission rate in quantum communications. While physical realization would require further component integration, this work establishes a rigorous theoretical framework for enhancing detection performance through architectural quantum-information principles, providing a general blueprint for transcending device-level constraints and guiding the development of next-generation room-temperature quantum technologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.01328v4</guid>
      <category>quant-ph</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.OC</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hao Shu</dc:creator>
    </item>
    <item>
      <title>Fare Zone Assignment on Trees</title>
      <link>https://arxiv.org/abs/2512.19493</link>
      <description>arXiv:2512.19493v2 Announce Type: replace-cross 
Abstract: Tariff setting in public transportation networks is an important challenge. A popular approach is to partition the network into fare zones ("zoning") and fix journey prices depending on the number of traversed zones ("pricing"). In this paper, we focus on finding revenue-optimal solutions to the zoning problem for a given concave pricing function. We consider tree networks with $n$ vertices, since trees already pose non-trivial algorithmic challenges. Our main results are efficient algorithms that yield a simple $\mathcal{O}(\log n)$-approximation as well as a more involved $\mathcal{O}(\log n/\log \log n)$-approximation. We show how to solve the problem exactly on rooted instances, in which all demand arises at the same source. For paths, we prove strong NP-hardness and outline a PTAS. Moreover, we show that computing an optimal solution is in FPT or XP for several natural problem parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.19493v2</guid>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Martin Hoefer, Lennart Kauther, Philipp Pabst, Britta Peis, Khai Van Tran</dc:creator>
    </item>
  </channel>
</rss>
