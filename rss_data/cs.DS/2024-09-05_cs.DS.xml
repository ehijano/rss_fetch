<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 06 Sep 2024 04:00:04 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 06 Sep 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Note On Deterministic Submodular Maximization With Bounded Curvature</title>
      <link>https://arxiv.org/abs/2409.02943</link>
      <description>arXiv:2409.02943v1 Announce Type: new 
Abstract: We show that the recent breakthrough result of [Buchbinder and Feldman, FOCS'24] could further lead to a deterministic $(1-\kappa_{f}/e-\varepsilon)$-approximate algorithm for maximizing a submodular function with curvature $\kappa_{f}$ under matroid constraint.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02943v1</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Fri, 06 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenxin Li</dc:creator>
    </item>
    <item>
      <title>Online Scheduling via Gradient Descent for Weighted Flow Time Minimization</title>
      <link>https://arxiv.org/abs/2409.03020</link>
      <description>arXiv:2409.03020v1 Announce Type: new 
Abstract: In this paper, we explore how a natural generalization of Shortest Remaining Processing Time (SRPT) can be a powerful \emph{meta-algorithm} for online scheduling. The meta-algorithm processes jobs to maximally reduce the objective of the corresponding offline scheduling problem of the remaining jobs: minimizing the total weighted completion time of them (the residual optimum). We show that it achieves scalability for minimizing total weighted flow time when the residual optimum exhibits \emph{supermodularity}. Scalability here means it is $O(1)$-competitive with an arbitrarily small speed augmentation advantage over the adversary, representing the best possible outcome achievable for various scheduling problems.
  Thanks to this finding, our approach does not require the residual optimum to have a closed mathematical form. Consequently, we can obtain the schedule by solving a linear program, which makes our approach readily applicable to a rich body of applications. Furthermore, by establishing a novel connection to \emph{substitute valuations in Walrasian markets}, we show how to achieve supermodularity, thereby obtaining scalable algorithms for various scheduling problems, such as matroid scheduling, generalized network flow, and generalized arbitrary speed-up curves, etc., and this is the \emph{first} non-trivial or scalable algorithm for many of them.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.03020v1</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 06 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qingyun Chen, Sungjin Im, Aditya Petety</dc:creator>
    </item>
    <item>
      <title>Minimizing Cost Rather Than Maximizing Reward in Restless Multi-Armed Bandits</title>
      <link>https://arxiv.org/abs/2409.03071</link>
      <description>arXiv:2409.03071v1 Announce Type: new 
Abstract: Restless Multi-Armed Bandits (RMABs) offer a powerful framework for solving resource constrained maximization problems. However, the formulation can be inappropriate for settings where the limiting constraint is a reward threshold rather than a budget. We introduce a constrained minimization problem for RMABs that balances the goal of achieving a reward threshold while minimizing total cost. We show that even a bi-criteria approximate version of the problem is PSPACE-hard. Motivated by the hardness result, we define a decoupled problem, indexability and a Whittle index for the minimization problem, mirroring the corresponding concepts for the maximization problem. Further, we show that the Whittle index for the minimization problem can easily be computed from the Whittle index for the maximization problem. Consequently, Whittle index results on RMAB instances for the maximization problem give Whittle index results for the minimization problem. Despite the similarities between the minimization and maximization problems, solving the minimization problem is not as simple as taking direct analogs of the heuristics for the maximization problem. We give an example of an RMAB for which the greedy Whittle index heuristic achieves the optimal solution for the maximization problem, while the analogous heuristic yields the worst possible solution for the minimization problem. In light of this, we present and compare several heuristics for solving the minimization problem on real and synthetic data. Our work suggests the importance of continued investigation into the minimization problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.03071v1</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 06 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>R. Teal Witter, Lisa Hellerstein</dc:creator>
    </item>
    <item>
      <title>Does Subset Sum Admit Short Proofs?</title>
      <link>https://arxiv.org/abs/2409.03526</link>
      <description>arXiv:2409.03526v1 Announce Type: new 
Abstract: We investigate the question whether Subset Sum can be solved by a polynomial-time algorithm with access to a certificate of length poly(k) where k is the maximal number of bits in an input number. In other words, can it be solved using only few nondeterministic bits?
  This question has motivated us to initiate a systematic study of certification complexity of parameterized problems. Apart from Subset Sum, we examine problems related to integer linear programming, scheduling, and group theory. We reveal an equivalence class of problems sharing the same hardness with respect to having a polynomial certificate. These include Subset Sum and Boolean Linear Programming parameterized by the number of constraints. Secondly, we present new techniques for establishing lower bounds in this regime. In particular, we show that Subset Sum in permutation groups is at least as hard for nondeterministic computation as 3Coloring in bounded-pathwidth graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.03526v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Fri, 06 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Micha{\l} W{\l}odarczyk</dc:creator>
    </item>
    <item>
      <title>Constant Approximating Disjoint Paths on Acyclic Digraphs is W[1]-hard</title>
      <link>https://arxiv.org/abs/2409.03596</link>
      <description>arXiv:2409.03596v1 Announce Type: new 
Abstract: In the Disjoint Paths problem, one is given a graph with a set of $k$ vertex pairs $(s_i,t_i)$ and the task is to connect each $s_i$ to $t_i$ with a path, so that the $k$ paths are pairwise disjoint. In the optimization variant, Max Disjoint Paths, the goal is to maximize the number of vertex pairs to be connected. We study this problem on acyclic directed graphs, where Disjoint Paths is known to be W[1]-hard when parameterized by $k$. We show that in this setting Max Disjoint Paths is W[1]-hard to $c$-approximate for any constant $c$. To the best of our knowledge, this is the first non-trivial result regarding the parameterized approximation for Max Disjoint Paths with respect to the natural parameter $k$. Our proof is based on an elementary self-reduction that is guided by a certain combinatorial object constructed by the probabilistic method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.03596v1</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 06 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Micha{\l} W{\l}odarczyk</dc:creator>
    </item>
    <item>
      <title>Fine-Grained Equivalence for Problems Related to Integer Linear Programming</title>
      <link>https://arxiv.org/abs/2409.03675</link>
      <description>arXiv:2409.03675v1 Announce Type: new 
Abstract: Integer Linear Programming with $n$ binary variables and $m$ many $0/1$-constraints can be solved in time $2^{\tilde O(m^2)} \text{poly}(n)$ and it is open whether the dependence on $m$ is optimal. Several seemingly unrelated problems, which include variants of Closest String, Discrepancy Minimization, Set Cover, and Set Packing, can be modelled as Integer Linear Programming with $0/1$ constraints to obtain algorithms with the same running time for a natural parameter $m$ in each of the problems. Our main result establishes through fine-grained reductions that these problems are equivalent, meaning that a $2^{O(m^{2-\varepsilon})} \text{poly}(n)$ algorithm with $\varepsilon &gt; 0$ for one of them implies such an algorithm for all of them.
  In the setting above, one can alternatively obtain an $n^{O(m)}$ time algorithm for Integer Linear Programming using a straightforward dynamic programming approach, which can be more efficient if $n$ is relatively small (e.g., subexponential in $m$). We show that this can be improved to ${n'}^{O(m)} + O(nm)$, where $n'$ is the number of distinct (i.e., non-symmetric) variables. This dominates both of the aforementioned running times.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.03675v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Fri, 06 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Lars Rohwedder, Karol W\k{e}grzycki</dc:creator>
    </item>
    <item>
      <title>Space-Efficient Algorithm for Integer Programming with Few Constraints</title>
      <link>https://arxiv.org/abs/2409.03681</link>
      <description>arXiv:2409.03681v1 Announce Type: new 
Abstract: Integer linear programs $\min\{c^T x : A x = b, x \in \mathbb{Z}^n_{\ge 0}\}$, where $A \in \mathbb{Z}^{m \times n}$, $b \in \mathbb{Z}^m$, and $c \in \mathbb{Z}^n$, can be solved in pseudopolynomial time for any fixed number of constraints $m = O(1)$. More precisely, in time $(m\Delta)^{O(m)} \text{poly}(I)$, where $\Delta$ is the maximum absolute value of an entry in $A$ and $I$ the input size.
  Known algorithms rely heavily on dynamic programming, which leads to a space complexity of similar order of magnitude as the running time. In this paper, we present a polynomial space algorithm that solves integer linear programs in $(m\Delta)^{O(m (\log m + \log\log\Delta))} \text{poly}(I)$ time, that is, in almost the same time as previous dynamic programming algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.03681v1</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 06 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Lars Rohwedder, Karol W\k{e}grzycki</dc:creator>
    </item>
    <item>
      <title>An Efficient Algorithm for Group Testing with Runlength Constraints</title>
      <link>https://arxiv.org/abs/2409.03491</link>
      <description>arXiv:2409.03491v1 Announce Type: cross 
Abstract: In this paper, we provide an efficient algorithm to construct almost optimal $(k,n,d)$-superimposed codes with runlength constraints. A $(k,n,d)$-superimposed code of length $t$ is a $t \times n$ binary matrix such that any two 1's in each column are separated by a run of at least $d$ 0's, and such that for any column $\mathbf{c}$ and any other $k-1$ columns, there exists a row where $\mathbf{c}$ has $1$ and all the remaining $k-1$ columns have $0$. These combinatorial structures were introduced by Agarwal et al. [1], in the context of Non-Adaptive Group Testing algorithms with runlength constraints.
  By using Moser and Tardos' constructive version of the Lov\'asz Local Lemma, we provide an efficient randomized Las Vegas algorithm of complexity $\Theta(t n^2)$ for the construction of $(k,n,d)$-superimposed codes of length $t=O(dk\log n +k^2\log n)$. We also show that the length of our codes is shorter, for $n$ sufficiently large, than that of the codes whose existence was proved in [1].</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.03491v1</guid>
      <category>cs.IT</category>
      <category>cs.DS</category>
      <category>math.IT</category>
      <pubDate>Fri, 06 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marco Dalai, Stefano Della Fiore, Adele A. Rescigno, Ugo Vaccaro</dc:creator>
    </item>
    <item>
      <title>The Power of Second Chance: Personalized Submodular Maximization with Two Candidates</title>
      <link>https://arxiv.org/abs/2409.03545</link>
      <description>arXiv:2409.03545v1 Announce Type: cross 
Abstract: Most of existing studies on submodular maximization focus on selecting a subset of items that maximizes a \emph{single} submodular function. However, in many real-world scenarios, we might have multiple user-specific functions, each of which models the utility of a particular type of user. In these settings, our goal would be to choose a set of items that performs well across all the user-specific functions. One way to tackle this problem is to select a single subset that maximizes the sum of all of the user-specific functions. Although this aggregate approach is efficient in the sense that it avoids computation of sets for individual functions, it really misses the power of personalization - for it does not allow to choose different sets for different functions. In this paper, we introduce the problem of personalized submodular maximization with two candidate solutions. For any two candidate solutions, the utility of each user-specific function is defined as the better of these two candidates. Our objective is, therefore, to select the best set of two candidates that maximize the sum of utilities of all the user-specific functions. We have designed effective algorithms for this problem. We also discuss how our approach generalizes to multiple candidate solutions, increasing flexibility and personalization in our solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.03545v1</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <pubDate>Fri, 06 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jing Yuan, Shaojie Tang</dc:creator>
    </item>
    <item>
      <title>Predicting quantum channels over general product distributions</title>
      <link>https://arxiv.org/abs/2409.03684</link>
      <description>arXiv:2409.03684v1 Announce Type: cross 
Abstract: We investigate the problem of predicting the output behavior of unknown quantum channels. Given query access to an $n$-qubit channel $E$ and an observable $O$, we aim to learn the mapping \begin{equation*}
  \rho \mapsto \mathrm{Tr}(O E[\rho]) \end{equation*} to within a small error for most $\rho$ sampled from a distribution $D$. Previously, Huang, Chen, and Preskill proved a surprising result that even if $E$ is arbitrary, this task can be solved in time roughly $n^{O(\log(1/\epsilon))}$, where $\epsilon$ is the target prediction error. However, their guarantee applied only to input distributions $D$ invariant under all single-qubit Clifford gates, and their algorithm fails for important cases such as general product distributions over product states $\rho$.
  In this work, we propose a new approach that achieves accurate prediction over essentially any product distribution $D$, provided it is not "classical" in which case there is a trivial exponential lower bound. Our method employs a "biased Pauli analysis," analogous to classical biased Fourier analysis. Implementing this approach requires overcoming several challenges unique to the quantum setting, including the lack of a basis with appropriate orthogonality properties. The techniques we develop to address these issues may have broader applications in quantum information.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.03684v1</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Fri, 06 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sitan Chen, Jaume de Dios Pont, Jun-Ting Hsieh, Hsin-Yuan Huang, Jane Lange, Jerry Li</dc:creator>
    </item>
    <item>
      <title>Scalable Neighborhood Local Search for Single-Machine Scheduling with Family Setup Times</title>
      <link>https://arxiv.org/abs/2409.00771</link>
      <description>arXiv:2409.00771v2 Announce Type: replace 
Abstract: In this work, we study the task of scheduling jobs on a single machine with sequence dependent family setup times under the goal of minimizing the makespan, that is, the completion time of the last job in the schedule. This notoriously NP-hard problem is highly relevant in practical productions and requires heuristics that provide good solutions quickly in order to deal with large instances. In this paper, we present a heuristic based on the approach of parameterized local search. That is, we aim to replace a given solution by a better solution having distance at most $k$ in a pre-defined distance measure. This is done multiple times in a hill-climbing manner, until a locally optimal solution is reached. We analyze the trade-off between the allowed distance $k$ and the algorithm's running time for four natural distance measures. Example of allowed operations for our considered distance measures are: swapping $k$ pairs of jobs in the sequence, or rearranging $k$ consecutive jobs. For two distance measures, we show that finding an improvement for given $k$ can be done in $f(k) \cdot n^{\mathcal{O}(1)}$ time, while such a running time for the other two distance measures is unlikely. We provide a preliminary experimental evaluation of our local search approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.00771v2</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Fri, 06 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kaja Balzereit, Niels Gr\"uttemeier, Nils Morawietz, Dennis Reinhardt, Stefan Windmann, Petra Wolf</dc:creator>
    </item>
  </channel>
</rss>
