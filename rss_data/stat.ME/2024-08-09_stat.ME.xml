<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.ME updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.ME</link>
    <description>stat.ME updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.ME" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 09 Aug 2024 04:00:05 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 09 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Testing for a general changepoint in psychometric studies: changes detection and sample size planning</title>
      <link>https://arxiv.org/abs/2408.04056</link>
      <description>arXiv:2408.04056v1 Announce Type: new 
Abstract: This paper introduces a new method for change detection in psychometric studies based on the recently introduced pseudo Score statistic, for which the sampling distribution under the alternative hypothesis has been determined. Our approach has the advantage of simplicity in its computation, eliminating the need for resampling or simulations to obtain critical values. Additionally, it comes with a known null/alternative distribution, facilitating easy calculations for power levels and sample size planning. The paper indeed also discusses the topic of power analysis in segmented regression, namely the estimation of sample size or power level when the study data being collected focuses on a covariate expected to affect the mean response via a piecewise relationship with an unknown breakpoint. We run simulation results showing that our method outperforms other Tests for a Change Point (TFCP) with both normally distributed and binary data and carry out a real SAT Critical reading data analysis. The proposed test contributes to the framework of psychometric research, and it is available on the Comprehensive R Archive Network (CRAN) and in a more user-friendly Shiny App, both illustrated at the end of the paper.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04056v1</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Nicoletta D'Angelo</dc:creator>
    </item>
    <item>
      <title>A robust approach for generalized linear models based on maximum Lq-likelihood procedure</title>
      <link>https://arxiv.org/abs/2408.04176</link>
      <description>arXiv:2408.04176v1 Announce Type: new 
Abstract: In this paper we propose a procedure for robust estimation in the context of generalized linear models based on the maximum Lq-likelihood method. Alongside this, an estimation algorithm that represents a natural extension of the usual iteratively weighted least squares method in generalized linear models is presented. It is through the discussion of the asymptotic distribution of the proposed estimator and a set of statistics for testing linear hypothesis that it is possible to define standardized residuals using the mean-shift outlier model. In addition, robust versions of deviance function and the Akaike information criterion are defined with the aim of providing tools for model selection. Finally, the performance of the proposed methodology is illustrated through a simulation study and analysis of a real dataset.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04176v1</guid>
      <category>stat.ME</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Felipe Osorio, Manuel Galea, Patricia Gimenez</dc:creator>
    </item>
    <item>
      <title>Hypothesis testing for general network models</title>
      <link>https://arxiv.org/abs/2408.04213</link>
      <description>arXiv:2408.04213v1 Announce Type: new 
Abstract: The network data has attracted considerable attention in modern statistics. In research on complex network data, one key issue is finding its underlying connection structure given a network sample. The methods that have been proposed in literature usually assume that the underlying structure is a known model. In practice, however, the true model is usually unknown, and network learning procedures based on these methods may suffer from model misspecification. To handle this issue, based on the random matrix theory, we first give a spectral property of the normalized adjacency matrix under a mild condition. Further, we establish a general goodness-of-fit test procedure for the unweight and undirected network. We prove that the null distribution of the proposed statistic converges in distribution to the standard normal distribution. Theoretically, this testing procedure is suitable for nearly all popular network models, such as stochastic block models, and latent space models. Further, we apply the proposed method to the degree-corrected mixed membership model and give a sequential estimator of the number of communities. Both simulation studies and real-world data examples indicate that the proposed method works well.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04213v1</guid>
      <category>stat.ME</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kang Fu, Jianwei Hu, Seydou Keita</dc:creator>
    </item>
    <item>
      <title>BayesFBHborrow: An R Package for Bayesian borrowing for time-to-event data from a flexible baseline hazard</title>
      <link>https://arxiv.org/abs/2408.04327</link>
      <description>arXiv:2408.04327v1 Announce Type: new 
Abstract: There is currently a focus on statistical methods which can use external trial information to help accelerate the discovery, development and delivery of medicine. Bayesian methods facilitate borrowing which is "dynamic" in the sense that the similarity of the data helps to determine how much information is used. We propose a Bayesian semiparameteric model, which allows the baseline hazard to take any form through an ensemble average. We introduce priors to smooth the posterior baseline hazard improving both model estimation and borrowing characteristics. A "lump-and-smear" borrowing prior accounts for non-exchangable historical data and helps reduce the maximum type I error in the presence of prior-data conflict. In this article, we present BayesFBHborrow, an R package, which enables the user to perform Bayesian borrowing with a historical control dataset in a semiparameteric time-to-event model. User-defined hyperparameters smooth an ensemble averaged posterior baseline hazard. The model offers the specification of lump-and-smear priors on the commensurability parameter where the associated hyperparameters can be chosen according to the users tolerance for difference between the log baseline hazards. We demonstrate the performance of our Bayesian flexible baseline hazard model on a simulated and real world dataset.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04327v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Sophia Axillus, Alex Lewin, Darren Scott</dc:creator>
    </item>
    <item>
      <title>Analysing symbolic data by pseudo-marginal methods</title>
      <link>https://arxiv.org/abs/2408.04419</link>
      <description>arXiv:2408.04419v1 Announce Type: new 
Abstract: Symbolic data analysis (SDA) aggregates large individual-level datasets into a small number of distributional summaries, such as random rectangles or random histograms. Inference is carried out using these summaries in place of the original dataset, resulting in computational gains at the loss of some information. In likelihood-based SDA, the likelihood function is characterised by an integral with a large exponent, which limits the method's utility as for typical models the integral unavailable in closed form. In addition, the likelihood function is known to produce biased parameter estimates in some circumstances. Our article develops a Bayesian framework for SDA methods in these settings that resolves the issues resulting from integral intractability and biased parameter estimation using pseudo-marginal Markov chain Monte Carlo methods. We develop an exact but computationally expensive method based on path sampling and the block-Poisson estimator, and a much faster, but approximate, method based on Taylor expansion. Through simulation and real-data examples we demonstrate the performance of the developed methods, showing large reductions in computation time compared to the full-data analysis, with only a small loss of information.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04419v1</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yu Yang, Matias Quiroz, Boris Beranger, Robert Kohn, Scott A. Sisson</dc:creator>
    </item>
    <item>
      <title>Better Locally Private Sparse Estimation Given Multiple Samples Per User</title>
      <link>https://arxiv.org/abs/2408.04313</link>
      <description>arXiv:2408.04313v1 Announce Type: cross 
Abstract: Previous studies yielded discouraging results for item-level locally differentially private linear regression with $s^*$-sparsity assumption, where the minimax rate for $nm$ samples is $\mathcal{O}(s^{*}d / nm\varepsilon^2)$. This can be challenging for high-dimensional data, where the dimension $d$ is extremely large. In this work, we investigate user-level locally differentially private sparse linear regression. We show that with $n$ users each contributing $m$ samples, the linear dependency of dimension $d$ can be eliminated, yielding an error upper bound of $\mathcal{O}(s^{*2} / nm\varepsilon^2)$. We propose a framework that first selects candidate variables and then conducts estimation in the narrowed low-dimensional space, which is extendable to general sparse estimation problems with tight error bounds. Experiments on both synthetic and real datasets demonstrate the superiority of the proposed methods. Both the theoretical and empirical results suggest that, with the same number of samples, locally private sparse estimation is better conducted when multiple samples per user are available.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04313v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>stat.ME</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>ICML2024 Proceedings</arxiv:journal_reference>
      <dc:creator>Yuheng Ma, Ke Jia, Hanfang Yang</dc:creator>
    </item>
    <item>
      <title>Multimodal data integration and cross-modal querying via orchestrated approximate message passing</title>
      <link>https://arxiv.org/abs/2407.19030</link>
      <description>arXiv:2407.19030v2 Announce Type: replace 
Abstract: The need for multimodal data integration arises naturally when multiple complementary sets of features are measured on the same sample. Under a dependent multifactor model, we develop a fully data-driven orchestrated approximate message passing algorithm for integrating information across these feature sets to achieve statistically optimal signal recovery. In practice, these reference data sets are often queried later by new subjects that are only partially observed. Leveraging on asymptotic normality of estimates generated by our data integration method, we further develop an asymptotically valid prediction set for the latent representation of any such query subject. We demonstrate the prowess of both the data integration and the prediction set construction algorithms on a tri-modal single-cell dataset.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.19030v2</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sagnik Nandy, Zongming Ma</dc:creator>
    </item>
  </channel>
</rss>
