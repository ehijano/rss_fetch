<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 01 Oct 2024 03:15:30 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 30 Sep 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Reinforcement Learning for Finite Space Mean-Field Type Games</title>
      <link>https://arxiv.org/abs/2409.18152</link>
      <description>arXiv:2409.18152v1 Announce Type: new 
Abstract: Mean field type games (MFTGs) describe Nash equilibria between large coalitions: each coalition consists of a continuum of cooperative agents who maximize the average reward of their coalition while interacting non-cooperatively with a finite number of other coalitions. Although the theory has been extensively developed, we are still lacking efficient and scalable computational methods. Here, we develop reinforcement learning methods for such games in a finite space setting with general dynamics and reward functions. We start by proving that MFTG solution yields approximate Nash equilibria in finite-size coalition games. We then propose two algorithms. The first is based on quantization of the mean-field spaces and Nash Q-learning. We provide convergence and stability analysis. We then propose an deep reinforcement learning algorithm, which can scale to larger spaces. Numerical examples on 5 environments show the scalability and the efficiency of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.18152v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 30 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kai Shao, Jiacheng Shen, Chijie An, Mathieu Lauri\`ere</dc:creator>
    </item>
    <item>
      <title>Non-cooperative rational synthesis problem for probabilistic strategies</title>
      <link>https://arxiv.org/abs/2409.18155</link>
      <description>arXiv:2409.18155v1 Announce Type: new 
Abstract: We study the decidability and complexity of non-cooperative rational synthesis problem (abbreviated as NCRSP) for some classes of probabilistic strategies. We show that NCRSP for stationary strategies and Muller objectives is in 3-EXPTIME, and if we restrict the strategies of environment players to be positional, NCRSP becomes NEXPSPACE solvable. On the other hand, NCRSP_&gt;, which is a variant of NCRSP, is shown to be undecidable even for pure finite-state strategies and terminal reachability objectives. Finally, we show that NCRSP becomes EXPTIME solvable if we restrict the memory of a strategy to be the most recently visited t vertices where t is linear in the size of the game.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.18155v1</guid>
      <category>cs.GT</category>
      <category>cs.FL</category>
      <pubDate>Mon, 30 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>So Koide, Yoshiaki Takata, Hiroyuki Seki</dc:creator>
    </item>
    <item>
      <title>Intrinsic Robustness of Prophet Inequality to Strategic Reward Signaling</title>
      <link>https://arxiv.org/abs/2409.18269</link>
      <description>arXiv:2409.18269v1 Announce Type: new 
Abstract: Prophet inequality concerns a basic optimal stopping problem and states that simple threshold stopping policies -- i.e., accepting the first reward larger than a certain threshold -- can achieve tight $\frac{1}{2}$-approximation to the optimal prophet value. Motivated by its economic applications, this paper studies the robustness of this approximation to natural strategic manipulations in which each random reward is associated with a self-interested player who may selectively reveal his realized reward to the searcher in order to maximize his probability of being selected.
  We say a threshold policy is $\alpha$(-strategically)-robust if it (a) achieves the $\alpha$-approximation to the prophet value for strategic players; and (b) meanwhile remains a $\frac{1}{2}$-approximation in the standard non-strategic setting. Starting with a characterization of each player's optimal information revealing strategy, we demonstrate the intrinsic robustness of prophet inequalities to strategic reward signaling through the following results: (1) for arbitrary reward distributions, there is a threshold policy that is $\frac{1-\frac{1}{e}}{2}$-robust, and this ratio is tight; (2) for i.i.d. reward distributions, there is a threshold policy that is $\frac{1}{2}$-robust, which is tight for the setting; and (3) for log-concave (but non-identical) reward distributions, the $\frac{1}{2}$-robustness can also be achieved under certain regularity assumptions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.18269v1</guid>
      <category>cs.GT</category>
      <pubDate>Mon, 30 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wei Tang, Haifeng Xu, Ruimin Zhang, Derek Zhu</dc:creator>
    </item>
    <item>
      <title>Improved Hardness Results for the Clearing Problem in Financial Networks with Credit Default Swaps</title>
      <link>https://arxiv.org/abs/2409.18717</link>
      <description>arXiv:2409.18717v1 Announce Type: new 
Abstract: We study computational problems in financial networks of banks connected by debt contracts and credit default swaps (CDSs). A main problem is to determine \emph{clearing} payments, for instance right after some banks have been exposed to a financial shock. Previous works have shown the $\varepsilon$-approximate version of the problem to be $\mathrm{PPAD}$-complete and the exact problem $\mathrm{FIXP}$-complete. We show that $\mathrm{PPAD}$-hardness hold when $\varepsilon \approx 0.101$, improving the previously best bound significantly. Due to the fact that the clearing problem typically does not have a unique solution, or that it may not have a solution at all in the presence of default costs, several natural decision problems are also of great interest. We show two such problems to be $\exists\mathbb{R}$-complete, complementing previous $\mathrm{NP}$-hardness results for the approximate setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.18717v1</guid>
      <category>cs.GT</category>
      <category>q-fin.RM</category>
      <pubDate>Mon, 30 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Simon Dohn, Kristoffer Arnsfelt Hansen, Asger Klinkby</dc:creator>
    </item>
    <item>
      <title>Facility Location Problem with Aleatory Agents</title>
      <link>https://arxiv.org/abs/2409.18817</link>
      <description>arXiv:2409.18817v1 Announce Type: new 
Abstract: In this paper, we introduce and study the Facility Location Problem with Aleatory Agents (FLPAA), where the facility accommodates n agents larger than the number of agents reporting their preferences, namely n_r. The spare capacity is used by n_u=n-n_r aleatory agents sampled from a probability distribution \mu. The goal of FLPAA is to find a location that minimizes the ex-ante social cost, which is the expected cost of the n_u agents sampled from \mu plus the cost incurred by the agents reporting their position. We investigate the mechanism design aspects of the FLPAA under the assumption that the Mechanism Designer (MD) lacks knowledge of the distribution $\mu$ but can query k quantiles of \mu. We explore the trade-off between acquiring more insights into the probability distribution and designing a better-performing mechanism, which we describe through the strong approximation ratio (SAR). The SAR of a mechanism measures the highest ratio between the cost of the mechanisms and the cost of the optimal solution on the worst-case input x and worst-case distribution \mu, offering a metric for efficiency that does not depend on \mu. We divide our study into four different information settings: the zero information case, in which the MD has access to no quantiles; the median information case, in which the MD has access to the median of \mu; the n_u-quantile information case, in which the MD has access to n_u quantiles of its choice, and the k-quantile information case, in which the MD has access to k&lt;n_u quantiles of its choice. For all frameworks, we propose a mechanism that is optimal or achieves a small constant SAR and pairs it with a lower bound on the SAR. In most cases, the lower bound matches the upper bound, thus no truthful mechanism can achieve a lower SAR. Lastly, we extend the FLPAA to include instances in which we must locate two facilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.18817v1</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <pubDate>Mon, 30 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gennaro Auricchio, Jie Zhang</dc:creator>
    </item>
    <item>
      <title>Describing Deferred Acceptance and Strategyproofness to Participants: Experimental Analysis</title>
      <link>https://arxiv.org/abs/2409.18166</link>
      <description>arXiv:2409.18166v1 Announce Type: cross 
Abstract: We conduct an incentivized lab experiment to test participants' ability to understand the DA matching mechanism and the strategyproofness property, conveyed in different ways. We find that while many participants can (using a novel GUI) learn DA's mechanics and calculate its outcomes, such understanding does not imply understanding of strategyproofness (as measured by specially designed tests). However, a novel menu description of strategyproofness conveys this property significantly better than other treatments. While behavioral effects are small on average, participants with levels of strategyproofness understanding above a certain threshold play the classical dominant strategy at very high rates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.18166v1</guid>
      <category>econ.GN</category>
      <category>cs.GT</category>
      <category>q-fin.EC</category>
      <pubDate>Mon, 30 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yannai A. Gonczarowski, Ori Heffetz, Guy Ishai, Clayton Thomas</dc:creator>
    </item>
    <item>
      <title>VickreyFeedback: Cost-efficient Data Construction for Reinforcement Learning from Human Feedback</title>
      <link>https://arxiv.org/abs/2409.18417</link>
      <description>arXiv:2409.18417v1 Announce Type: cross 
Abstract: This paper addresses the cost-efficiency aspect of Reinforcement Learning from Human Feedback (RLHF). RLHF leverages datasets of human preferences over outputs of large language models (LLM) to instill human expectations into LLMs. While preference annotation comes with a monetized cost, the economic utility of a preference dataset has not been considered by far. What exacerbates this situation is that given complex intransitive or cyclic relationships in preference datasets, existing algorithms for fine-tuning LLMs are still far from capturing comprehensive preferences. This raises severe cost-efficiency concerns in production environments, where preference data accumulate over time. In this paper, we see the fine-tuning of LLMs as a monetized economy and introduce an auction mechanism to improve the efficiency of the preference data collection in dollar terms. We show that introducing an auction mechanism can play an essential role in enhancing the cost-efficiency of RLHF while maintaining satisfactory model performance. Experimental results demonstrate that our proposed auction-based protocol is cost-efficient for fine-tuning LLMs by concentrating on high-quality feedback.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.18417v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.GT</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Mon, 30 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Guoxi Zhang, Jiuding Duan</dc:creator>
    </item>
    <item>
      <title>Computing Voting Rules with Elicited Incomplete Votes</title>
      <link>https://arxiv.org/abs/2402.11104</link>
      <description>arXiv:2402.11104v2 Announce Type: replace 
Abstract: Motivated by the difficulty of specifying complete ordinal preferences over a large set of $m$ candidates, we study voting rules that are computable by querying voters about $t &lt; m$ candidates. Generalizing prior works that focused on specific instances of this problem, our paper fully characterizes the set of positional scoring rules that can be computed for any $1 \leq t &lt; m$, which, notably, does not include plurality. We then extend this to show a similar impossibility result for single transferable vote (elimination voting). These negative results are information-theoretic and agnostic to the number of queries. Finally, for scoring rules that are computable with limited-sized queries, we give parameterized upper and lower bounds on the number of such queries a deterministic or randomized algorithm must make to determine the score-maximizing candidate. While there is no gap between our bounds for deterministic algorithms, identifying the exact query complexity for randomized algorithms is a challenging open problem, of which we solve one special case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.11104v2</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <pubDate>Mon, 30 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel Halpern, Safwan Hossain, Jamie Tucker-Foltz</dc:creator>
    </item>
  </channel>
</rss>
