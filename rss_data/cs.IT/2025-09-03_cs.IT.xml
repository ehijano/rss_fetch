<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.IT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.IT</link>
    <description>cs.IT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.IT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 04 Sep 2025 01:31:46 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Newton-Flow Particle Filters based on Generalized Cram\'er Distance</title>
      <link>https://arxiv.org/abs/2509.00182</link>
      <description>arXiv:2509.00182v1 Announce Type: new 
Abstract: We propose a recursive particle filter for high-dimensional problems that inherently never degenerates. The state estimate is represented by deterministic low-discrepancy particle sets. We focus on the measurement update step, where a likelihood function is used for representing the measurement and its uncertainty. This likelihood is progressively introduced into the filtering procedure by homotopy continuation over an artificial time. A generalized Cram\'er distance between particle sets is derived in closed form that is differentiable and invariant to particle order. A Newton flow then continually minimizes this distance over artificial time and thus smoothly moves particles from prior to posterior density. The new filter is surprisingly simple to implement and very efficient. It just requires a prior particle set and a likelihood function, never estimates densities from samples, and can be used as a plugin replacement for classic approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.00182v1</guid>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.IT</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Uwe D. Hanebeck</dc:creator>
    </item>
    <item>
      <title>New Constructions of Optimal $(r,\delta)$-LRCs via Algebraic Function Fields</title>
      <link>https://arxiv.org/abs/2509.00302</link>
      <description>arXiv:2509.00302v1 Announce Type: new 
Abstract: Constructing optimal $(r,\delta)$-LRCs that attain the Singleton-type bound is an active and important research direction, particularly due to their practical applications in distributed storage systems. In this paper, we focus on the construction of optimal $(r,\delta)$-LRCs with flexible minimum distances, especially for the case $\delta \geq 3$. We first extend a general framework -- originally proposed by Li \textit{et al.} (IEEE Trans. Inf. Theory, vol. 65, no. 1, 2019) and Ma and Xing (J. Comb. Theory Ser. A., vol. 193, 2023) -- for constructing optimal $r$-LRCs via automorphism groups of elliptic function fields to the case of $(r,\delta)$-LRCs. This newly extended general framework relies on certain conditions concerning the group law of elliptic curves. By carefully selecting elliptic function fields suitable for this framework, we arrive at several families of explicit $q$-ary optimal $(r,3)$-LRCs and $(2,\delta)$-LRCs with lengths slightly less than $q + 2\sqrt{q}$. Next, by employing automorphism groups of hyperelliptic function fields of genus $2$, we develop a framework for constructing optimal $(r,3)$-LRCs and obtain a family of explicit $q$-ary optimal $(4,3)$-LRCs with code lengths slightly below $q+4\sqrt{q}$. We then consider the construction of optimal $(r,\delta)$-LRCs via hyperelliptic function fields of arbitrary genus $g \geq 2$, yielding a class of explicit $q$-ary optimal $(g+1-g',g+1+g')$-LRCs for $0 \leq g' \leq g-1$ with lengths up to $q + 2g\sqrt{q}$. Finally, applying certain superelliptic curves derived from modified Norm-Trace curves, we construct two families of explicit optimal $(r,\delta)$-LRCs with even longer code lengths and more flexible parameters. Notably, many of the newly constructed optimal $(r,\delta)$-LRCs attain the largest known lengths among existing constructions with flexible minimum distances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.00302v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuan Gao, Haoming Shi, Weijun Fang</dc:creator>
    </item>
    <item>
      <title>Deep Complex-valued Neural-Network Modeling and Optimization of Stacked Intelligent Surfaces</title>
      <link>https://arxiv.org/abs/2509.00340</link>
      <description>arXiv:2509.00340v1 Announce Type: new 
Abstract: We propose a complex-valued neural-network (CV-NN) framework to optimally configure stacked intelligent surfaces (SIS) in next-generation multi-antenna systems. Unlike conventional solutions that separately tune analog metasurface phases or rely strictly on SVD-based orthogonal decompositions, our method models each SIS element as a unit-modulus complex-velued neuron in an end-to-end differentiable pipeline. This approach avoids enforcing channel orthogonality and instead allows for richer wavefront designs that can target a wide range of system objectives, such as maximizing spectral efficiency and minimizing detection errors, all within a single optimization framework. Moreover, by exploiting a fully differentiable neural-network formulation and GPU-based auto-differentiation, our approach can rapidly train SIS configurations for realistic, high-dimensional channels, enabling near-online adaptation. Our framework also naturally accommodates hybrid analog-digital beamforming and recovers classical SVD solutions as a special case. Numerical evaluations under Rician channels demonstrate that CV-NN SIS optimization outperforms state-of-the-art schemes in throughput, error performance, and robustness to channel variation, opening the door to more flexible and powerful wave-domain control for future 6G networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.00340v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Abdullah Zayat, Omran Abbas, Loic Markley, Anas Chaaban</dc:creator>
    </item>
    <item>
      <title>QoS-Driven Satellite Constellation Design for LEO Satellite Internet of Things</title>
      <link>https://arxiv.org/abs/2509.00345</link>
      <description>arXiv:2509.00345v1 Announce Type: new 
Abstract: Low Earth orbit (LEO) satellite Internet of Things (IoT) has been identified as one of the important components of the sixth-generation (6G) non-terrestrial networks (NTN) to provide ubiquitous connectivity. Due to the low orbit altitude and high mobility, a massive number of satellites are required to form a global continuous coverage constellation, leading to a high construction cost. To this end, this paper proposes a LEO satellite IoT constellation design algorithm with the goal of minimizing the total cost while satisfying quality of service (QoS) requirements in terms of coverage ratio and communication quality. Specifically, with a novel fitness function and efficient algorithm's operators, the proposed algorithm converges more quickly and achieves lower constellation construction cost compared to baseline algorithms under the same QoS requirements. Theoretical analysis proves the global and fast convergence of the proposed algorithm due to a novel fitness function. Finally, extensive simulation results confirm the effectiveness of the proposed algorithm in LEO satellite IoT constellation design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.00345v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ming Ying, Xiaoming Chen, Qiao Qi, Zhaoyang Zhang</dc:creator>
    </item>
    <item>
      <title>Coverage and Rate Performance Analysis of Multi-RIS-Assisted Dual-Hop mmWave Networks</title>
      <link>https://arxiv.org/abs/2509.00717</link>
      <description>arXiv:2509.00717v1 Announce Type: new 
Abstract: Millimeter-wave (mmWave) communication, which operates at high frequencies, has gained extensive research interest due to its significantly wide spectrum and short wavelengths. However, mmWave communication suffers from the notable drawbacks as follows: i) The mmWave signals are sensitive to the blockage, which is caused by the weak diffraction ability of mmWave propagation; ii) Even though the introduction of reconfigurable intelligent surfaces (RISs) can overcome the performance degradation caused by serve path loss, the location of users and RISs as well as their densities incur a significant impact on the coverage and rate performance; iii) When the RISs' density is very high, i.e., the network becomes extremely dense, a user sees several line-of-sight RISs and thus experiences significant interference, which degrades the system performance. Motivated by the challenges above, we first analyze distributed multi-RISaided mmWave communication system over Nakagami-m fading from the stochastic geometry perspective. To be specific, we analyze the end-to-end (E2E) signal-to-interference-plus-noiseratio (SINR) coverage and rate performance of the system. To improve the system performance in terms of the E2E SINR coverage probability and rate, we study the optimization of the phase-shifting control of the distributed RISs and optimize the E2E SINR coverage particularly when deploying a large number of reflecting elements in RISs. To facilitate the study, we optimize the dynamic association criterion between the RIS and destination. Furthermore, we optimize the multi-RIS-user association based on the physical distances between the RISs and destination by exploiting the maximum-ratio transmission.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.00717v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuwen Cao, Xiaowen Wu, Jiguang He, Tomoaki Ohtsuki, Tony Q. S. Quek</dc:creator>
    </item>
    <item>
      <title>Movable Antenna-Enhanced Secure Communication: Opportunities, Challenges, and Solutions</title>
      <link>https://arxiv.org/abs/2509.00894</link>
      <description>arXiv:2509.00894v1 Announce Type: new 
Abstract: The broadcast nature of wireless communication renders it inherently vulnerable to security threats such as jamming and eavesdropping. While traditional array beamforming techniques help to mitigate these threats, they usually incur high hardware and processing costs, particularly in large-scale arrays with fixed-position antennas (FPAs). In contrast, movable antenna (MA) arrays can fully exploit the channel variation in spatial regions by enabling flexible antenna movement, which has emerged as a promising technology for secure communications. This article provides a magazine-type overview of MA-aided secure communications. Specifically, we first illuminate the promising application scenarios for MA-enhanced secure communication systems. Then, we examine the security advantages of MAs over conventional FPA systems, fundamentally stemming from their ability to adjust channel correlations between legitimate users, eavesdroppers, and jammers. Furthermore, we discuss important technical challenges and their potential solutions related to MA hardware architecture, channel acquisition, and antenna position optimization to realize secure transmissions. Finally, several promising directions for MA-aided secure communications are presented to inspire future research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.00894v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yaodong Ma, Kai Liu, Lipeng Zhu, Yanming Liu, Yanbo Zhu, Daniel Benevides da Costa</dc:creator>
    </item>
    <item>
      <title>Movable Antenna Empowered Secure Near-Field MIMO Communications</title>
      <link>https://arxiv.org/abs/2509.00901</link>
      <description>arXiv:2509.00901v1 Announce Type: new 
Abstract: This paper investigates movable antenna (MA) empowered secure transmission in near-field multiple-input multiple-output (MIMO) communication systems, where the base station (BS) equipped with an MA array transmits confidential information to a legitimate user under the threat of a potential eavesdropper. To enhance physical layer security (PLS) of the considered system, we aim to maximize the secrecy rate by jointly designing the hybrid digital and analog beamformers, as well as the positions of MAs at the BS. To solve the formulated non-convex problem with highly coupled variables, an alternating optimization (AO)-based algorithm is introduced by decoupling the original problem into two separate subproblems. Specifically, for the subproblem of designing hybrid beamformers, a semi-closed-form solution for the fully-digital beamformer is first derived by a weighted minimum mean-square error (WMMSE)-based algorithm. Subsequently, the digital and analog beamformers are determined by approximating the fully-digital beamformer through the manifold optimization (MO) technique. For the MA positions design subproblem, we utilize the majorization-minimization (MM) algorithm to iteratively optimize each MA's position while keeping others fixed. Extensive simulation results validate the considerable benefits of the proposed MA-aided near-field beam focusing approach in enhancing security performance compared to the traditional far-field and/or the fixed position antenna (FPA)-based systems. In addition, the proposed scheme can realize secure transmission even if the eavesdropper is located in the same direction as the user and closer to the BS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.00901v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yaodong Ma, Kai Liu, Yanming Liu, Lipeng Zhu</dc:creator>
    </item>
    <item>
      <title>Maximum a Posteriori Probability (MAP) Joint Carrier Frequency Offset (CFO) and Channel Estimation for MIMO Channels with Spatial and Temporal Correlations</title>
      <link>https://arxiv.org/abs/2509.01032</link>
      <description>arXiv:2509.01032v1 Announce Type: new 
Abstract: We consider time varying MIMO fading channels with known spatial and temporal correlation and solve the problem of joint carrier frequency offset (CFO) and channel estimation with prior distributions. The maximum a posteriori probability (MAP) joint estimation is proved to be equivalent to a separate MAP estimation of the CFO followed by minimum mean square error (MMSE) estimation of the channel while treating the estimated CFO as true. The MAP solution is useful to take advantage of the estimates from the previous data packet. A low complexity universal CFO estimation algorithm is extended from the time invariant case to the time varying case. Unlike past algorithms, the universal algorithm does not need phase unwrapping to take advantage of the full range of symbol correlation and achieves the derived Bayesian Cram\'er-Rao lower bound (BCRLB) in almost all SNR range. We provide insight on the the relation among the temporal correlation coefficient of the fading, the CFO estimation performance, and the pilot signal structure. An unexpected observation is that the BCRLB is not a monotone function of the temporal correlation and is strongly influenced by the pilot signal structures. A simple rearrangement of the 0's and 1's in the pilot signal matrix will render the BCRLB from being non-monotone to being monotone in certain temporal correlation ranges. Since the BCRLB is shown to be achieved by the proposed algorithm, it provides a guideline for pilot signal design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.01032v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ibrahim Khalife, Ali Abbasi, Zhe Feng, Mingda Zhou, Xinming Huang, Youjian Liu</dc:creator>
    </item>
    <item>
      <title>On the Resilience of Direction-Shift Keying Against Phase Noise and Short Channel Coherence Time at mmWave Frequencies</title>
      <link>https://arxiv.org/abs/2509.01103</link>
      <description>arXiv:2509.01103v1 Announce Type: new 
Abstract: The rapid variation of the wireless channel (short channel coherence time) and the phase noise are two prominent concerns in Millimeter-wave (mmWave) and sub-Terahertz systems communication systems. Equalizing the channel effect and tracking the phase noise necessitate dense pilot insertion. Direction-Shift Keying (DSK), a recent variant of Spatial Modulation (SM), addresses these challenges by encoding information in the Direction-of-Arrival (DoA) using a distributed antenna system (DAS), rather than relying on amplitude or phase. DSK has been shown to extend coherence time by up to four orders of magnitude. Despite its promise, existing DSK studies are largely simulation-based and limited to simplified roadside unit scenarios and mobile device (MD) equipped with only two antennas. DSK's performance in general settings, along with the fundamental laws governing its behavior, such as coherence time and resilience to phase noise, remain open problems. In this paper, we derive the structure of the optimal detector for the case of $M$-antenna MD. Then, we establish the governing law for DSK's coherence time, termed the Direction Coherence Time (DCT), defining the the temporal duration over which the DoA remains approximately invariant. We analytically establish that DCT scales with $d/v$ (transmitter-receiver distance over velocity), while the Channel Coherence Time (CCT) scales with $\lambda/v$, revealing a coherence time gain on the order of $d/\lambda$ (equivalent to more than four orders of magnitude.) Furthermore, we prove that DSK inherently cancels the phase noise, requiring no additional compensation. Analytical predictions are validated through simulations, confirming the robustness and scalability of DSK in high-frequency mobile environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.01103v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohaned Chraiti, Ozgur Ercetin, Ali Ghrayeb, Ali Gorcin</dc:creator>
    </item>
    <item>
      <title>From One-Dimensional Codes to Two-Dimensional Codes: A Universal Framework for the Bounded-Weight Constraint</title>
      <link>https://arxiv.org/abs/2509.01240</link>
      <description>arXiv:2509.01240v1 Announce Type: new 
Abstract: Recent developments in storage- especially in the area of resistive random access memory (ReRAM)- are attempting to scale the storage density by regarding the information data as two-dimensional (2D), instead of one-dimensional (1D). Correspondingly, new types of 2D constraints are introduced into the input information data to improve the system reliability. While 1D constraints have been extensively investigated in the literature, the study for 2D constraints is much less profound. Particularly, given a constraint $\mathcal{F}$ and a design of 1D codes whose codewords satisfy $\mathcal{F}$, the problem of constructing efficient 2D codes, such that every row and every column in every codeword satisfy $\mathcal{F}$, has been a challenge. This work provides an efficient solution to the challenging coding problem above for the binary bounded-weight constrained codes that restrict the maximum number of $1$'s (called {\em weight}). Formally, we propose a universal framework to design 2D codes that guarantee the weight of every row and every column of length $n$ to be at most $f(n)$ for any given function $f(n)$. We show that if there exists a design of capacity-approaching 1D codes, then our method also provides capacity-approaching 2D codes for all $f=\omega(\log n)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.01240v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Viet Hai Le, Thanh Phong Pham, Tuan Thanh Nguyen, Kui Cai, Kees A. Schouhamer Immink</dc:creator>
    </item>
    <item>
      <title>Hierarchical Maximum Entropy via the Renormalization Group</title>
      <link>https://arxiv.org/abs/2509.01424</link>
      <description>arXiv:2509.01424v1 Announce Type: new 
Abstract: Hierarchical structures, which include multiple levels, are prevalent in statistical and machine-learning models as well as physical systems. Extending the foundational result that the maximum entropy distribution under mean constraints is given by the exponential Gibbs-Boltzmann form, we introduce the framework of "hierarchical maximum entropy" to address these multilevel models. We demonstrate that Pareto optimal distributions, which maximize entropies across all levels of hierarchical transformations, can be obtained via renormalization-group procedures from theoretical physics. This is achieved by formulating multilevel extensions of the Gibbs variational principle and the Donsker-Varadhan variational representation of entropy. Moreover, we explore settings with hierarchical invariances that significantly simplify the renormalization-group procedures, enhancing computational efficiency: quadratic modular loss functions, logarithmic loss functions, and nearest-neighbor loss functions. This is accomplished through the introduction of the concept of parameter flows, which serves as an analog to renormalization flows in renormalization group theory. This work connects ideas from probability theory, information theory, and statistical mechanics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.01424v1</guid>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amir R. Asadi</dc:creator>
    </item>
    <item>
      <title>Learning to Ask: Decision Transformers for Adaptive Quantitative Group Testing</title>
      <link>https://arxiv.org/abs/2509.01723</link>
      <description>arXiv:2509.01723v1 Announce Type: new 
Abstract: We consider the problem of quantitative group testing (QGT), where the goal is to recover a sparse binary vector from aggregate subset-sum queries: each query selects a subset of indices and returns the sum of those entries. Information-theoretic results suggest that adaptivity could yield up to a twofold reduction in the total number of required queries, yet no algorithm has surpassed the non-adaptive bound, leaving its practical benefit an open question. In this paper, we reduce the QGT problem to an integer-vector recovery task whose dimension scales with the sparsity of the original problem rather than its full ambient size. We then formulate this reduced recovery task as an offline reinforcement learning problem and employ Decision Transformers to solve it adaptively. By combining these two steps, we obtain an effective end-to-end method for solving the QGT problem. Our experiments show that, for the first time in the literature, our adaptive algorithm reduces the average number of queries below the well-known non-adaptive information-theoretic bound, demonstrating that adaptivity can indeed reduce the number of queries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.01723v1</guid>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mahdi Soleymani, Tara Javidi</dc:creator>
    </item>
    <item>
      <title>On the Analysis of Random Linear Streaming Codes in Stochastic Channels</title>
      <link>https://arxiv.org/abs/2509.01894</link>
      <description>arXiv:2509.01894v1 Announce Type: new 
Abstract: Random Linear Streaming Codes (RLSCs) can dramatically reduce the queuing delay of block codes in real-time services. In this paper, we aim to explore the fundamental limit of large-field-size RLSCs in stochastic symbol erasure channels (SEC). The Non-systematic RLSCs (NRLSCs) in i.i.d. SEC has been analyzed in [Pinwen Su et al. 2022]. In this work, we first derive the closed-form expression on the exact error probability of NRLSCs in Gilbert-Elliott symbol erasure channels (G-ESEC). Compared to i.i.d SEC, the erasure probability of G-ESEC depends on channel state, thus transitions between the states should be considered. To deal with the stochastic state transitions, we introduce two novel techniques. (i) To account for the impact of switching states on probability terms, we find and leverage the recursive structure of the state transition traces. (ii) To obtain the expected number of error timeslots, we derive the stationary initial distribution of the states, and formulate iterative equation to characterize the expectation terms. Then we analyze the Systematic RLSCs (SRLSCs) in a special SEC, i.e., the packet erasure channel (PEC). In this scenario, SRLSCs could save some source symbols which should have exceeded the decoding delay in NRLSCs, and thus could significantly reduce the error probability. To this point, our contributions are two-folds. (i) Through a case study, we find a counter-intuitive phenomenon that SRLSCs can cause unexpected error events comparing to NRLSCs in some erasure patterns. Then we fully characterize the error event of SRLSCs for any erasure pattern. (ii) For i.i.d. PEC, we derive an analytical expression on exact error probability of SRLSCs when length of memory approaches infinity and coding rate equals to 1/2. Simulations are conducted to verify the accuracy of our analysis and compare the performance of NRLSCs, SRLSCs, and existing streaming codes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.01894v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kai Huang, Wenjie Guan, Xiaoran Wang, Jinbei Zhang, Kechao Cai</dc:creator>
    </item>
    <item>
      <title>MUSE-FM: Multi-task Environment-aware Foundation Model for Wireless Communications</title>
      <link>https://arxiv.org/abs/2509.01967</link>
      <description>arXiv:2509.01967v1 Announce Type: new 
Abstract: Recent advancements in foundation models (FMs) have attracted increasing attention in the wireless communication domain. Leveraging the powerful multi-task learning capability, FMs hold the promise of unifying multiple tasks of wireless communication with a single framework. with a single framework. Nevertheless, existing wireless FMs face limitations in the uniformity to address multiple tasks with diverse inputs/outputs across different communication scenarios.In this paper, we propose a MUlti-taSk Environment-aware FM (MUSE-FM) with a unified architecture to handle multiple tasks in wireless communications, while effectively incorporating scenario information.Specifically, to achieve task uniformity, we propose a unified prompt-guided data encoder-decoder pair to handle data with heterogeneous formats and distributions across different tasks. Besides, we integrate the environmental context as a multi-modal input, which serves as prior knowledge of environment and channel distributions and facilitates cross-scenario feature extraction. Simulation results illustrate that the proposed MUSE-FM outperforms existing methods for various tasks, and its prompt-guided encoder-decoder pair improves the scalability for new task configurations. Moreover, the incorporation of environment information improves the ability to adapt to different scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.01967v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tianyue Zheng, Jiajia Guo, Linglong Dai, Shi Jin, Jun Zhang</dc:creator>
    </item>
    <item>
      <title>Next-Generation Sustainable Wireless Systems: Energy Efficiency Meets Environmental Impact</title>
      <link>https://arxiv.org/abs/2509.02395</link>
      <description>arXiv:2509.02395v1 Announce Type: new 
Abstract: Aligning with the global mandates pushing towards advanced technologies with reduced resource consumption and environmental impacts, the sustainability of wireless networks becomes a significant concern in 6G systems. To address this concern, a native integration of sustainability into the operations of next-generation networks through novel designs and metrics is necessary. Nevertheless, existing wireless sustainability efforts remain limited to energy-efficient network designs which fail to capture the environmental impact of such systems. In this paper, a novel sustainability metric is proposed that captures emissions per bit, providing a rigorous measure of the environmental foot- print associated with energy consumption in 6G networks. This metric also captures how energy, computing, and communication resource parameters influence the reduction of emissions per bit. Then, the problem of allocating the energy, computing and communication resources is posed as a multi-objective (MO) optimization problem. To solve the resulting non-convex problem, our framework leverages MO reinforcement learning (MORL) to maximize the novel sustainability metric alongside minimizing energy consumption and average delays in successfully delivering the data, all while adhering to constraints on energy resource capacity. The proposed MORL methodology computes a global policy that achieves a Pareto-optimal tradeoff among multiple objectives, thereby balancing environmental sustainability with network performance. Simulation results show that the proposed approach reduces the average emissions per bit by around 26% compared to state-of-the-art methods that do not explicitly integrate carbon emissions into their control objectives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.02395v1</guid>
      <category>cs.IT</category>
      <category>cs.NI</category>
      <category>math.IT</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christo Kurisummoottil Thomas, Omar Hashash, Kimia Ehsani, Walid Saad</dc:creator>
    </item>
    <item>
      <title>Practical Channel Estimation for Pinching-Antenna Systems: Serial vs. Parallel and Downlink vs. Uplink?</title>
      <link>https://arxiv.org/abs/2509.02403</link>
      <description>arXiv:2509.02403v1 Announce Type: new 
Abstract: The practical channel estimation in uplink pinching-antenna systems is investigated, in which an electromagnetic-compliant in-waveguide transmission model is exhibited, incorporating both bidirectional power splitting, cumulative power leakage, and waveguide attenuation. Based on this model, the paper investigates two antenna activation protocols for channel estimation: a serial protocol based on one-by-one antenna activation and a parallel protocol utilizing a binary S-Matrix activation. The serial protocol is characterized by its superior numerical stability but a lack of array gain, whereas the parallel protocol theoretically offers array gain but suffers from severe performance degradation due to structural crosstalk from the non-orthogonal S-Matrix and ill-conditioning from cumulative leakage. Furthermore, the paper analyzes the fundamental commonalities and asymmetries between uplink and downlink channel estimation in pinching-antenna systems. Numerical results demonstrate that 1) in an ideal lossless model, the parallel protocol is superior to the serial protocol due to the array gain from simultaneous energy collection in uplink transmission; 2) in a practical model with physical losses, the serial protocol outperforms the parallel protocol, as the performance of the parallel protocol is degraded by the numerical instability from cumulative leakage, which outweighs the benefit of array gain; 3) For downlink channel estimation, the serial protocol is more suitable because it avoids bidirectional power splitting, while the parallel protocol is more suitable for the uplink as it can make full use of array gain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.02403v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jian Xiao</dc:creator>
    </item>
    <item>
      <title>Feasibility Guaranteed Learning-to-Optimize in Wireless Communication Resource Allocation</title>
      <link>https://arxiv.org/abs/2509.02417</link>
      <description>arXiv:2509.02417v1 Announce Type: new 
Abstract: The emergence of 6G wireless communication enables massive edge device access and supports real-time intelligent services such as the Internet of things (IoT) and vehicle-to-everything (V2X). However, the surge in edge devices connectivity renders wireless resource allocation (RA) tasks as large-scale constrained optimization problems, whereas the stringent real-time requirement poses significant computational challenge for traditional algorithms. To address the challenge, feasibility guaranteed learning-to-optimize (L2O) techniques have recently gained attention. These learning-based methods offer efficient alternatives to conventional solvers by directly learning mappings from system parameters to feasible and near-optimal solutions. This article provide a comprehensive review of L2O model designs and feasibility enforcement techniques and investigates the application of constrained L2O in wireless RA systems and. The paper also presents a case study to benchmark different L2O approaches in weighted sum rate problem, and concludes by identifying key challenges and future research directions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.02417v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hanwen Zhang, Haijian Sun</dc:creator>
    </item>
    <item>
      <title>A Novel Coded Caching Scheme for Partially Cooperative Device-to-Device Networks</title>
      <link>https://arxiv.org/abs/2509.02532</link>
      <description>arXiv:2509.02532v1 Announce Type: new 
Abstract: Device-to-device (D2D) communication is one of the most promising techniques for future wireless cellular communication systems. This paper considers coded caching in a partially cooperative wireless D2D network, where only a subset of users transmit during delivery, while all users request files. The non-transmitting users are referred to as selfish users. All existing schemes that do not require knowledge of the identity of selfish users before content placement are limited to the high-memory regime, particularly when the number of selfish users is large. We propose a novel coded caching scheme for a partially cooperative D2D network that operates in all feasible memory regimes, regardless of the number of selfish users. We also derive a lower bound on the transmission load of a partially cooperative D2D coded caching scheme. Using this bound, the proposed scheme is shown to be optimal in the high-memory regime.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.02532v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rashid Ummer N. T., K. K. Krishnan Namboodiri, B. Sundar Rajan</dc:creator>
    </item>
    <item>
      <title>Continuous Donoho-Elad Spark Uncertainty Principle</title>
      <link>https://arxiv.org/abs/2509.00001</link>
      <description>arXiv:2509.00001v1 Announce Type: cross 
Abstract: Donoho and Elad \textit{[Proc. Natl. Acad. Sci. USA, 2003]} introduced the important notion of the spark of a frame, using which they derived a fundamental uncertainty principle. Based on spark, they also provided a necessary and sufficient condition for the uniqueness of sparse solutions to the NP-hard $\ell_0$-minimization problem. In this nano note, we show that the notion of spark can be extended to linear maps whose domains are measure spaces. Using this generalization, we derive an uncertainty principle and provide a sufficient condition for the existence of sparse solutions to linear systems on measure spaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.00001v1</guid>
      <category>math.OC</category>
      <category>cs.IT</category>
      <category>math.FA</category>
      <category>math.IT</category>
      <category>math.PR</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>K. Mahesh Krishna</dc:creator>
    </item>
    <item>
      <title>A Fluid Antenna Enabled Physical Layer Key Generation for Next-G Wireless Networks</title>
      <link>https://arxiv.org/abs/2509.00018</link>
      <description>arXiv:2509.00018v1 Announce Type: cross 
Abstract: As a promising physical layer security technique, physical layer key generation (PLKG) enables legitimate users to obtain secret keys from wireless channel without security infrastructures. However, in harsh propagation environments, the channel characteristic becomes unsatisfactory, the key generation rate (KGR) is significantly deteriorated. In this paper, we propose a novel fluid antenna (FA) enabled PLKG system to address this challenge. Specifically, we first derive the closed-form expression of the KGR for FA array, and then jointly optimize the precoding matrix and the antenna positions via a particle swarm optimization (PSO) algorithm. Next, to further reduce the computational complexity of the optimization procedure, we develop an alternating optimization (AO) algorithm, which combines the projected gradient descent (PGD) and the PSO. Simulation results demonstrate that by exploiting the additional spatial degree of freedom (DoF), our FA enabled PLKG system is superior to the benchmarks, such as the conventional fixed-position antenna (FPA) array and the reconfigurable intelligent surface (RIS). It is worth highlighting that compared to the conventional uniform planar antenna (UPA), the FA enabled PLKG achieves a 35.42\% KGR performance improvement under PSO algorithm and a 67.73\% KGR performance improvement under AO algorithm, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.00018v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.CR</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiacheng Guo, Ning Gao, Yiping Zuo, Hao Xu, Shi Jin, Kai Kit Wong</dc:creator>
    </item>
    <item>
      <title>Enhanced R\'{e}nyi Entropy-Based Post-Quantum Key Agreement with Provable Security and Information-Theoretic Guarantees</title>
      <link>https://arxiv.org/abs/2509.00104</link>
      <description>arXiv:2509.00104v1 Announce Type: cross 
Abstract: This paper presents an enhanced post-quantum key agreement protocol based on R\'{e}nyi entropy, addressing vulnerabilities in the original construction while preserving information-theoretic security properties. We develop a theoretical framework leveraging entropy-preserving operations and secret-shared verification to achieve provable security against quantum adversaries. Through entropy amplification techniques and quantum-resistant commitments, the protocol establishes $2^{128}$ quantum security guarantees under the quantum random oracle model. Key innovations include a confidentiality-preserving verification mechanism using distributed polynomial commitments, tightened min-entropy bounds with guaranteed non-negativity, and composable security proofs in the quantum universal composability framework. Unlike computational approaches, our method provides information-theoretic security without hardness assumptions while maintaining polynomial complexity. Theoretical analysis demonstrates resilience against known quantum attack vectors, including Grover-accelerated brute force and quantum memory attacks. The protocol achieves parameterization for 128-bit quantum security with efficient $\mathcal{O}(n^2)$ communication complexity. Extensions to secure multiparty computation and quantum network applications are established, providing a foundation for long-term cryptographic security. All security claims are derived from mathematical proofs; this theoretical work presents no experimental validation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.00104v1</guid>
      <category>cs.CR</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>quant-ph</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ruopengyu Xu, Chenglian Liu</dc:creator>
    </item>
    <item>
      <title>DSDE: Dynamic Speculative Decoding with KLD Stability for Real-World Serving</title>
      <link>https://arxiv.org/abs/2509.01083</link>
      <description>arXiv:2509.01083v1 Announce Type: cross 
Abstract: Speculative decoding accelerates large language model inference, but its reliance on a fixed speculation length is suboptimal in large-batch serving environments with diverse requests. This paper explores a new direction for dynamic adaptation by investigating a novel class of post-hoc, diagnostic signals. We propose Dynamic Speculative Decoding Engine (DSDE), a training-free framework built on two primary components: (1) a predictive signal based on the variance of the Kullback-Leibler (KLD) divergence, which diagnoses the generation's regional stability, and (2) an adaptive speculation length cap to mitigate the straggler problem in per-sequence decoding. Experiments demonstrate the potential of using KLD-based stability signals for dynamic adaptation. An algorithm guided by these signals achieves end-to-end latency competitive with leading baselines and exhibits superior robustness across diverse workloads. This robustness is particularly valuable in challenging low-acceptance-rate regimes, where the proposed signal maintains its diagnostic utility. Collectively, these findings validate post-hoc signals as a valuable component for building more robust and intelligent LLM inference systems, and highlight a promising direction for future research on dynamic speculation length adaptation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.01083v1</guid>
      <category>cs.DC</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mingyu Yang, Jae-Young Choi, Kihyo Moon, Minsung Jang, Eunjoo Joen</dc:creator>
    </item>
    <item>
      <title>Robust Stochastic Outperformance under Kullback-Leibler Ambiguity</title>
      <link>https://arxiv.org/abs/2509.01346</link>
      <description>arXiv:2509.01346v1 Announce Type: cross 
Abstract: We study the worst-case probability that $Y$ outperforms a benchmark $X$ when the law of $Y$ lies in a Kullback-Leibler neighbourhood of the benchmark. The max-min problem over couplings admits a tractable dual (via optimal transport), whose optimiser is an exponential tilt of the benchmark law. The resulting solution reduces to a one-parameter family indexed by regulizer $\lambda$, which controls the KL information budget and induces an increasing transfer of probability mass from lower to higher outcomes. The formulation can be evaluated from the baseline distribution and may serve as a distribution-wide scenario generation environment as well as a basis for robust performance assessment.
  Keywords: exponential tilting; optimal transport; stochastic dominance; stress testing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.01346v1</guid>
      <category>math.PR</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ozan H\"ur</dc:creator>
    </item>
    <item>
      <title>Mixture of Balanced Information Bottlenecks for Long-Tailed Visual Recognition</title>
      <link>https://arxiv.org/abs/2509.01804</link>
      <description>arXiv:2509.01804v1 Announce Type: cross 
Abstract: Deep neural networks (DNNs) have achieved significant success in various applications with large-scale and balanced data. However, data in real-world visual recognition are usually long-tailed, bringing challenges to efficient training and deployment of DNNs. Information bottleneck (IB) is an elegant approach for representation learning. In this paper, we propose a balanced information bottleneck (BIB) approach, in which loss function re-balancing and self-distillation techniques are integrated into the original IB network. BIB is thus capable of learning a sufficient representation with essential label-related information fully preserved for long-tailed visual recognition. To further enhance the representation learning capability, we also propose a novel structure of mixture of multiple balanced information bottlenecks (MBIB), where different BIBs are responsible for combining knowledge from different network layers. MBIB facilitates an end-to-end learning strategy that trains representation and classification simultaneously from an information theory perspective. We conduct experiments on commonly used long-tailed datasets, including CIFAR100-LT, ImageNet-LT, and iNaturalist 2018. Both BIB and MBIB reach state-of-the-art performance for long-tailed visual recognition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.01804v1</guid>
      <category>cs.CV</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yifan Lan, Xin Cai, Jun Cheng, Shan Tan</dc:creator>
    </item>
    <item>
      <title>The Price of Sparsity: Sufficient Conditions for Sparse Recovery using Sparse and Sparsified Measurements</title>
      <link>https://arxiv.org/abs/2509.01809</link>
      <description>arXiv:2509.01809v1 Announce Type: cross 
Abstract: We consider the problem of recovering the support of a sparse signal using noisy projections. While extensive work has been done on the dense measurement matrix setting, the sparse setting remains less explored. In this work, we establish sufficient conditions on the sample size for successful sparse recovery using sparse measurement matrices. Bringing together our result with previously known necessary conditions, we discover that, in the regime where $ds/p \rightarrow +\infty$, sparse recovery in the sparse setting exhibits a phase transition at an information-theoretic threshold of $n_{\text{INF}}^{\text{SP}} = \Theta\left(s\log\left(p/s\right)/\log\left(ds/p\right)\right)$, where $p$ denotes the signal dimension, $s$ the number of non-zero components of the signal, and $d$ the expected number of non-zero components per row of measurement. This expression makes the price of sparsity explicit: restricting each measurement to $d$ non-zeros inflates the required sample size by a factor of $\log{s}/\log\left(ds/p\right)$, revealing a precise trade-off between sampling complexity and measurement sparsity. Additionally, we examine the effect of sparsifying an originally dense measurement matrix on sparse signal recovery. We prove in the regime of $s = \alpha p$ and $d = \psi p$ with $\alpha, \psi \in \left(0,1\right)$ and $\psi$ small that a sample of size $n^{\text{Sp-ified}}_{\text{INF}} = \Theta\left(p / \psi^2\right)$ is sufficient for recovery, subject to a certain uniform integrability conjecture, the proof of which is work in progress.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.01809v1</guid>
      <category>stat.ML</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Youssef Chaabouni, David Gamarnik</dc:creator>
    </item>
    <item>
      <title>AoI-based Scheduling of Correlated Sources for Timely Inference</title>
      <link>https://arxiv.org/abs/2509.01926</link>
      <description>arXiv:2509.01926v1 Announce Type: cross 
Abstract: We investigate a real-time remote inference system where multiple correlated sources transmit observations over a communication channel to a receiver. The receiver utilizes these observations to infer multiple time-varying targets. Due to limited communication resources, the delivered observations may not be fresh. To quantify data freshness, we employ the Age of Information (AoI) metric. To minimize the inference error, we aim to design a signal-agnostic scheduling policy that leverages AoI without requiring knowledge of the actual target values or the source observations. This scheduling problem is a restless multi-armed bandit (RMAB) problem with a non-separable penalty function. Unlike traditional RMABs, the correlation among sources introduces a unique challenge: the penalty function of each source depends on the AoI of other correlated sources, preventing decomposition of the problem into multiple independent Markov Decision Processes (MDPs), a key step in applying traditional RMAB solutions. To address this, we propose a novel approach by approximating the penalty function of each source and establish an analytical bound on the approximation error. We then develop scheduling policies for two scenarios: (i) full knowledge of the penalty functions and (ii) no knowledge of the penalty functions. For the case of known penalty functions, we present an upper bound on the optimality gap of our policy in the asymptotic regime. For the case of unknown penalty functions and signal distributions, we develop an online learning approach that utilizes bandit feedback to learn an online Maximum Gain First (MGF) policy. Simulation results demonstrate the effectiveness of our proposed policies in minimizing inference error and achieving scalability in the number of sources.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.01926v1</guid>
      <category>cs.NI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Md Kamran Chowdhury Shisher, Vishrant Tripathi, Mung Chiang, Christopher G. Brinton</dc:creator>
    </item>
    <item>
      <title>Dual Target-Mounted RISs-Assisted ISAC Against Eavesdropping and Malicious Interference</title>
      <link>https://arxiv.org/abs/2509.02030</link>
      <description>arXiv:2509.02030v1 Announce Type: cross 
Abstract: The synergy between integrated sensing and communication (ISAC) and reconfigurable intelligent surfaces (RISs) unlocks novel applications and advanced services for next-generation wireless networks, yet also introduces new security challenges. In this study, a novel dual target-mounted RISs-assisted ISAC scheme is proposed, where a base station with ISAC capability performs sensing of two unmanned aerial vehicle (UAV) targets, one of which is legitimate and the other is eavesdropper, while communicating with the users through an RIS mounted on the legitimate UAV target. The proposed scheme addresses dual security threats posed by a hostile UAV target: eavesdropping on legitimate user communications and random interference attacks launched by a malicious RIS mounted on this eavesdropper UAV target, aiming to disrupt secure transmissions. A non-convex optimization problem maximizing the secrecy rate of the users is formulated, and a semi-definite relaxation (SDR)-based two-stage solution is developed to optimize the transmit beamforming matrix of the base station and the phase shift coefficients of the legitimate RIS. Extensive computer simulations are conducted to evaluate the robustness of the proposed solution under various system configurations. The proposed system's communication performance is assessed using the secrecy rate metric, while the sensing performance is evaluated through the signal-to-interference-plus-noise ratio and the Cramer-Rao bound (CRB) for angle-of-departure (AoD) estimation of the eavesdropper UAV target.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.02030v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zehra Yigit, Sefa Kayraklik, Ertugrul Basar, Ali Gorcin</dc:creator>
    </item>
    <item>
      <title>Beamforming Design for Pinching Antenna Systems with Multiple Receive Antennas</title>
      <link>https://arxiv.org/abs/2509.02166</link>
      <description>arXiv:2509.02166v1 Announce Type: cross 
Abstract: Next-generation networks require intelligent and robust channel conditions to support ultra-high data rates, seamless connectivity, and large-scale device deployments in dynamic environments. While flexible antenna technologies such as fluid and movable antennas offer some degree of adaptability, their limited reconfiguration range and structural rigidity reduce their effectiveness in restoring line-of-sight (LoS) links. As a complementary solution, pinching antenna systems (PASs) enable fine-grained, hardware-free control of radiation locations along a waveguide, offering enhanced flexibility in challenging propagation environments, especially under non-LoS (NLoS) conditions. This paper introduces a general and novel modeling framework for downlink PASs targeting users equipped with multiple receive antennas, addressing a practical yet underexplored scenario in the existing literature. Specifically, we first derive an analytical relationship between the received signal-to-noise ratio and the pinching antenna (PA) positions, and based on this, we propose a two-layer placement strategy. First, we optimize the central radiation point using large-scale channel characteristics, and then we use a heuristic compressed placement algorithm to approximate phase alignment across multiple receive antennas and select a spatially compact set of active elements. Simulation results demonstrate notable performance gains over conventional single-antenna schemes, particularly in short-range scenarios with dense PAs and widely spaced user antennas.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.02166v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Enzhi Zhou, Yue Xiao, Ziyue Liu, Sotiris A. Tegos, Panagiotis D. Diamantoulakis, George K. Karagiannidis</dc:creator>
    </item>
    <item>
      <title>Tree algorithms for set reconciliation</title>
      <link>https://arxiv.org/abs/2509.02373</link>
      <description>arXiv:2509.02373v1 Announce Type: cross 
Abstract: In this work, a set reconciliation setting is considered in which two parties have similar sets that they would like to reconcile. In particular, we focus on a divide-and-conquer strategy known as partitioned set reconciliation (PSR), in which the sets to be reconciled are successively partitioned until they contain a number of differences below some predetermined value. Borrowing techniques from tree-algorithms for random-access protocols, we present and analyze a novel set reconciliation scheme that we term enhanced partitioned set reconciliation (EPSR). This approach improves the efficiency in terms of overhead, i.e., it yields a lower communication cost, while keeping the same time and communication round complexity as PSR. Additionally, we simulate the performance of the proposed algorithm in an event-driven simulator. Our findings indicate that this novel protocol nearly halves the communication cost of PSR while maintaining the same time complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.02373v1</guid>
      <category>cs.NI</category>
      <category>cs.DS</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Francisco L\'azaro, \v{C}edomir Stefanovi\'c</dc:creator>
    </item>
    <item>
      <title>Federated learning over physical channels: adaptive algorithms with near-optimal guarantees</title>
      <link>https://arxiv.org/abs/2509.02538</link>
      <description>arXiv:2509.02538v1 Announce Type: cross 
Abstract: In federated learning, communication cost can be significantly reduced by transmitting the information over the air through physical channels. In this paper, we propose a new class of adaptive federated stochastic gradient descent (SGD) algorithms that can be implemented over physical channels, taking into account both channel noise and hardware constraints. We establish theoretical guarantees for the proposed algorithms, demonstrating convergence rates that are adaptive to the stochastic gradient noise level. We also demonstrate the practical effectiveness of our algorithms through simulation studies with deep learning models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.02538v1</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <category>stat.ML</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rui Zhang, Wenlong Mou</dc:creator>
    </item>
    <item>
      <title>Construction of 2-D Z-Complementary Array Code Sets with Flexible Lengths for Different System Requirements</title>
      <link>https://arxiv.org/abs/2109.00970</link>
      <description>arXiv:2109.00970v4 Announce Type: replace 
Abstract: In this paper, we propose a new and optimal construction of two-dimensional (2-D) Z-complementary array code set (ZCACS) using multivariable extended Boolean functions (EBFs). The proposed 2-D arrays have many applications in modern wireless communications, such as multi-carrier code division multiple access (MC-CDMA), massive multiple input multiple output (mMIMO), etc. The main theoretical problem for sequences and 2-D arrays for application in MC-CDMA lies in the efficient construction of such sequences and arrays, which have low peak-to-mean envelope power ratio (PMEPR) and flexible parameter values. The PMEPR measures the power efficiency of the concerned system and hence has been an important research topic for past several years. The proposed construction produces a better PMEPR upper bound than the existing constructions. We also propose a tighter upper bound for the set size which translates more number of supported users in the communication system. We show that for some special cases, the proposed code set is optimal with respect to that bound. Finally, We derive 2-D Golay complementary array set (GCAS) and Golay complementary set (GCS) from the proposed construction, which has significant application in uniform rectangular array (URA)-based massive multiple-input multiple-output (mMIMO) system to achieve omnidirectional transmission. The simulation result shows the performance benefits of the derived arrays. In essence, we show that the flexibility of the parameters of the proposed 2-D ZCACS makes it a good candidate for practical use cases, both in theory and simulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2109.00970v4</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Abhishek Roy</dc:creator>
    </item>
    <item>
      <title>A Theory of Semantic Communication</title>
      <link>https://arxiv.org/abs/2212.01485</link>
      <description>arXiv:2212.01485v4 Announce Type: replace 
Abstract: Semantic communication is an emerging research area that has gained a wide range of attention recently. Despite this growing interest, there remains a notable absence of a comprehensive and widely-accepted framework for characterizing semantic communication. This paper introduces a new conceptualization of semantic communication and formulates two fundamental problems, which we term language exploitation and language design. Our contention is that the challenge of language design can be effectively situated within the broader framework of joint source-channel coding theory, underpinned by a comprehensive end-to-end distortion metric. To tackle the language exploitation problem, we put forth three approaches: semantic encoding, semantic decoding, and a synergistic combination of both in the form of combined semantic encoding and decoding. Furthermore, we establish the semantic distortion-cost region as a critical framework for assessing the language exploitation problem. For each of the three proposed approaches, the achievable distortion-cost region is characterized. Overall, this paper aims to shed light on the intricate dynamics of semantic communication, paving the way for a deeper understanding of this evolving field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.01485v4</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yulin Shao, Qi Cao, Deniz Gunduz</dc:creator>
    </item>
    <item>
      <title>Randomly Punctured Reed-Solomon Codes Achieve the List Decoding Capacity over Polynomial-Size Alphabets</title>
      <link>https://arxiv.org/abs/2304.01403</link>
      <description>arXiv:2304.01403v3 Announce Type: replace 
Abstract: This paper shows that, with high probability, randomly punctured Reed-Solomon codes over fields of polynomial size achieve the list decoding capacity. More specifically, we prove that for any $\epsilon&gt;0$ and $R\in (0,1)$, with high probability, randomly punctured Reed-Solomon codes of block length $n$ and rate $R$ are $\left(1-R-\epsilon, O({1}/{\epsilon})\right)$ list decodable over alphabets of size at least $2^{\mathrm{poly}(1/\epsilon)}n^2$. This extends the recent breakthrough of Brakensiek, Gopi, and Makam (STOC 2023) that randomly punctured Reed-Solomon codes over fields of exponential size attain the generalized Singleton bound of Shangguan and Tamo (STOC 2020).</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.01403v3</guid>
      <category>cs.IT</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <category>math.IT</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zeyu Guo, Zihan Zhang</dc:creator>
    </item>
    <item>
      <title>Joint Signal and Topology Optimization for Maximum Instantaneous Field Intensity</title>
      <link>https://arxiv.org/abs/2409.16293</link>
      <description>arXiv:2409.16293v4 Announce Type: replace 
Abstract: This paper introduces a computational approach to identify performance constraints in the time-domain, offering a way to design systems in pulse operation. This work presents a comprehensive application of convex optimization to determine fundamental bounds on time-domain waveforms. The approach is applied to arbitrarily polarized multiport antennas and arrays, demonstrating their capability in maximizing peak radiation intensity in a specified direction and time under energy constraints. This methodology allows us to consider matching, which is crucial in such applications. To highlight the generality of the approach, receiving systems are also studied on an example of maximizing the local field for antiferromagnetic memory switching. Thanks to its efficacy, this work enables joint optimization of excitation and system parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.16293v4</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jakub Liska, Lukas Jelinek, Miloslav Capek</dc:creator>
    </item>
    <item>
      <title>Considerate Ramp Secret Sharing</title>
      <link>https://arxiv.org/abs/2412.17987</link>
      <description>arXiv:2412.17987v3 Announce Type: replace 
Abstract: In this work we revisit the fundamental findings by Chen et al. in [5] on general information transfer in linear ramp secret sharing schemes to conclude that their method not only gives a way to establish worst case leakage [5, 25] and best case recovery [5, 19], but can also lead to additional insight on non-qualifying sets for any prescribed amount of information. We then apply this insight to schemes defined from monomial-Cartesian codes and by doing so we demonstrate that the good schemes from Sec.\ IV in [14] have a second layer of security. Elaborating further, when given a designed recovery number, in a new construction the focus is entirely on ensuring that the access structure possesses desirable second layer security, rather on what is the worst case information leakage in terms of number of participants. The particular structure of largest possible sets being not able to determine given amount of information suggests that we call such schemes considerate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17987v3</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Olav Geil</dc:creator>
    </item>
    <item>
      <title>Umlaut information</title>
      <link>https://arxiv.org/abs/2503.18910</link>
      <description>arXiv:2503.18910v2 Announce Type: replace 
Abstract: The sphere-packing bound quantifies the error exponent for noisy channel coding for rates above a critical value. Here, we study the zero-rate limit of the sphere-packing bound and show that it has an intriguing single-letter form, which we call the umlaut information of the channel, inspired by the lautum information introduced by Palomar and Verd\'u. Unlike the latter quantity, we show that the umlaut information is additive for parallel uses of channels. We show that it has a twofold operational interpretation: as the zero-rate error exponent of non-signalling-assisted coding on the one hand, and as the zero-rate error exponent of list decoding in the large list limit on the other.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.18910v2</guid>
      <category>cs.IT</category>
      <category>math-ph</category>
      <category>math.IT</category>
      <category>math.MP</category>
      <category>quant-ph</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Filippo Girardi, Aadil Oufkir, Bartosz Regula, Marco Tomamichel, Mario Berta, Ludovico Lami</dc:creator>
    </item>
    <item>
      <title>Energy Efficiency Maximization for Movable Antenna Communication Systems</title>
      <link>https://arxiv.org/abs/2506.07129</link>
      <description>arXiv:2506.07129v2 Announce Type: replace 
Abstract: This paper investigates energy efficiency maximization for movable antenna (MA)-aided multi-user uplink communication systems by considering the time delay and energy consumption incurred by practical antenna movement. We first examine the special case with a single user and propose an optimization algorithm based on the one-dimensional (1D) exhaustive search to maximize the user's energy efficiency. Moreover, we derive an upper bound on the energy efficiency and analyze the conditions required to achieve this performance bound under different numbers of channel paths. Then, for the general multi-user scenario, we propose an iterative algorithm to fairly maximize the minimum energy efficiency among all users. Simulation results demonstrate the effectiveness of the proposed scheme in improving energy efficiency compared to existing MA schemes that do not account for movement-related costs, as well as the conventional fixed-position antenna (FPA) scheme. In addition, the results show the robustness of the proposed scheme to imperfect channel state information (CSI) and provide valuable insights for practical system deployment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.07129v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TWC.2025.3597735</arxiv:DOI>
      <dc:creator>Jingze Ding, Zijian Zhou, Lipeng Zhu, Yuping Zhao, Bingli Jiao, Rui Zhang</dc:creator>
    </item>
    <item>
      <title>Joint Time-Position Statistics and Fisher Information in Drift-Diffusion Molecular Channels</title>
      <link>https://arxiv.org/abs/2508.18680</link>
      <description>arXiv:2508.18680v2 Announce Type: replace 
Abstract: This letter derives a closed-form joint distribution of the first arrival time (FAT) and first arrival position (FAP) in diffusion-based molecular communication (MC) systems with drift. Unlike prior work that studied FAT or FAP separately, we obtain an explicit joint probability density function under constant drift and isotropic diffusion in arbitrary dimensions, revealing a nontrivial spatiotemporal coupling. Based on this result, we compute the Fisher information matrix (FIM) and show that joint observations enable estimation of lateral drift and improve sensitivity to diffusion -- capabilities not attainable with time-only or position-only models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.18680v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yun-Feng Lo, Yen-Chi Lee</dc:creator>
    </item>
    <item>
      <title>Quantum state testing beyond the polarizing regime and quantum triangular discrimination</title>
      <link>https://arxiv.org/abs/2303.01952</link>
      <description>arXiv:2303.01952v5 Announce Type: replace-cross 
Abstract: The complexity class Quantum Statistical Zero-Knowledge ($\mathsf{QSZK}$) captures computational difficulties of the time-bounded quantum state testing problem with respect to the trace distance, deciding whether $\mathrm{T}(\rho_0,\rho_1)$ is at least $\alpha$ or at most $\beta$, known as the Quantum State Distinguishability Problem ($\mathrm{QSDP}$) introduced by Watrous (FOCS 2002). However, $\mathrm{QSDP}[\alpha,\beta]$ is in $\mathsf{QSZK}$ only within the constant polarizing regime, where $\alpha$ and $\beta$ are constants satisfying $\alpha^2 &gt; \beta$ (rather than $\alpha &gt; \beta$), similar to its classical counterpart shown by Sahai and Vadhan (JACM 2003) due to the polarization lemma (error reduction for $\mathrm{SDP}$).
  Recently, Berman, Degwekar, Rothblum, and Vasudevan (TCC 2019) extended the $\mathsf{SZK}$ containment of $\mathrm{SDP}$ beyond the polarizing regime via the time-bounded distribution testing problems with respect to the triangular discrimination and the Jensen-Shannon divergence. Our work introduces proper quantum analogs for these problems by defining quantum counterparts for triangular discrimination. We investigate whether the quantum analogs behave similarly to their classical counterparts and examine the limitations of existing approaches to polarization regarding quantum distances. These new $\mathsf{QSZK}$-complete problems improve $\mathsf{QSZK}$ containments of $\mathrm{QSDP}$ beyond the polarizing regime and establish a simple $\mathsf{QSZK}$-hardness for the quantum entropy difference problem ($\mathrm{QEDP}$) defined by Ben-Aroya, Schwartz, and Ta-Shma (ToC 2010). Furthermore, we prove that $\mathrm{QSDP}$ with some exponentially small errors is in $\mathsf{PP}$, while the same problem without error is in $\mathsf{NQP}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.01952v5</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yupan Liu</dc:creator>
    </item>
    <item>
      <title>On an analogue of the doubling method in coding theory</title>
      <link>https://arxiv.org/abs/2503.10201</link>
      <description>arXiv:2503.10201v2 Announce Type: replace-cross 
Abstract: It is well known that there is a deep relationship between codes and lattices. Concepts from coding theory are related to concepts of lattice theory as, for example, weight enumerators to theta series, MacWilliams identity to Jacobi identity, and Gleason's theorem to Hecke's theorem. In this framework, higher-genus (or multiple) weight enumerators are related to Siegel theta series, which opens up the possibility of introducing concepts from the theory of higher-rank modular forms to coding theory. There has been important work in this direction, for example Runge introduced a coding theory analogue of Siegel's $\Phi$-operator and Nebe analogues of Hecke operators. In this paper, we show that the celebrated Doubling Method from the theory of higher-rank modular forms has a coding theory analogue. Given the impact that the Doubling Method has had in the study of higher-rank modular forms, one may expect that its analogue may prove useful to the study of higher-genus weight enumerators. In this paper we use it to solve an analogue of the "basis problem". That is, we express "cuspidal" polynomials which are invariant under a Clifford-Weil type group as an explicit linear combination of higher-genus weight enumerators of self-dual codes of that type.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.10201v2</guid>
      <category>math.NT</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thanasis Bouganis, Jolanta Marzec-Ballesteros</dc:creator>
    </item>
    <item>
      <title>From Tokens to Thoughts: How LLMs and Humans Trade Compression for Meaning</title>
      <link>https://arxiv.org/abs/2505.17117</link>
      <description>arXiv:2505.17117v4 Announce Type: replace-cross 
Abstract: Humans organize knowledge into compact categories through semantic compression by mapping diverse instances to abstract representations while preserving meaning (e.g., robin and blue jay are both birds; most birds can fly). These concepts reflect a trade-off between expressive fidelity and representational simplicity. Large Language Models (LLMs) demonstrate remarkable linguistic abilities, yet whether their internal representations strike a human-like trade-off between compression and semantic fidelity is unclear. We introduce a novel information-theoretic framework, drawing from Rate-Distortion Theory and the Information Bottleneck principle, to quantitatively compare these strategies. Analyzing token embeddings from a diverse suite of LLMs against seminal human categorization benchmarks, we uncover key divergences. While LLMs form broad conceptual categories that align with human judgment, they struggle to capture the fine-grained semantic distinctions crucial for human understanding. More fundamentally, LLMs demonstrate a strong bias towards aggressive statistical compression, whereas human conceptual systems appear to prioritize adaptive nuance and contextual richness, even if this results in lower compressional efficiency by our measures. These findings illuminate critical differences between current AI and human cognitive architectures, guiding pathways toward LLMs with more human-aligned conceptual representations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.17117v4</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chen Shani, Liron Soffer, Dan Jurafsky, Yann LeCun, Ravid Shwartz-Ziv</dc:creator>
    </item>
    <item>
      <title>Relaying Quantum Information</title>
      <link>https://arxiv.org/abs/2507.06770</link>
      <description>arXiv:2507.06770v2 Announce Type: replace-cross 
Abstract: Quantum relays are central to both quantum communication and distributed quantum computing, enabling long-distance transmission and modular architectures. Unlike classical repeaters, quantum repeaters preserve coherence without amplifying quantum information, relying on entanglement swapping and quantum error correction to overcome loss and decoherence. In this work, we investigate the transmission of quantum information via quantum relay channels. Our three-terminal relay model captures the trade-off between repeater-assisted and repeaterless communication strategies. Specifically, we propose a partial decode-forward strategy, in which quantum ``message system" consists of two components. The first component is decoded by the relay and then sent to the destination receiver, whereas the second component is decoded by the destination receiver without the relay's help. We analyze both entanglement-assisted and unassisted scenarios. As a special case, the full decode-forward strategy is recovered, with the relay decoding, re-encoding, and forwarding the entire message. Our framework allows for different entanglement topologies between the transmitter, the relay and the destination receiver, recovering known results on entanglement-assisted and unassisted communication. Furthermore, we discuss the interpretation of coding with quantum side information. These findings provide a foundation for designing secure, efficient, and reliable quantum networks and for realizing practical quantum repeaters and long-range quantum key distribution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.06770v2</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yigal Ilin, Uzi Pereg</dc:creator>
    </item>
    <item>
      <title>Graded Transformers</title>
      <link>https://arxiv.org/abs/2507.20108</link>
      <description>arXiv:2507.20108v2 Announce Type: replace-cross 
Abstract: We introduce the Graded Transformer framework, a new class of sequence models that embeds algebraic inductive biases through grading transformations on vector spaces. Extending Graded Neural Networks (GNNs), we propose two architectures: the Linearly Graded Transformer (LGT) and the Exponentially Graded Transformer (EGT). These models apply parameterized scaling operators, governed by fixed or learnable grading tuples and in the case of EGT exponential factors, to encode hierarchical structure in attention and representation layers and to improve efficiency for structured data.
  We establish rigorous guarantees, including universal approximation theorems for continuous and Sobolev functions, reduced sample complexity via effective VC dimension bounds, Lipschitz continuity of graded operations, and robustness to perturbations. A graded loss ensures gradient stability and alignment with domain priors during optimization. By treating grades as differentiable parameters, the framework enables adaptive feature prioritization, overcoming limitations of fixed grades in earlier models.
  The Graded Transformer provides a mathematically principled approach to hierarchical learning and neuro-symbolic reasoning. Applications include algebraic geometry (moduli spaces and zeta functions), physics (multiscale systems), natural language processing (syntactic parsing), biological sequence analysis (variant prediction), robotics and autonomous systems (safety-critical prioritization), the automotive industry (certifiable AI for ADAS), and blockchain and financial cryptography (secure coding and structured prediction).</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.20108v2</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>stat.ML</category>
      <pubDate>Wed, 03 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tony Shaska Sr</dc:creator>
    </item>
  </channel>
</rss>
