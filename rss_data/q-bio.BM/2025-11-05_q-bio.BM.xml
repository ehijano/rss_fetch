<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.BM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.BM</link>
    <description>q-bio.BM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.BM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 05 Nov 2025 05:01:00 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 05 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>DL4Proteins Jupyter Notebooks Teach how to use Artificial Intelligence for Biomolecular Structure Prediction and Design</title>
      <link>https://arxiv.org/abs/2511.02128</link>
      <description>arXiv:2511.02128v1 Announce Type: new 
Abstract: Computational methods for predicting and designing biomolecular structures are increasingly powerful. While previous approaches relied on physics-based modeling, modern tools, such as AlphaFold2 in CASP14, leverage artificial intelligence (AI) to achieve significantly improved performance. The growing impact of AI-based tools in protein science necessitates enhanced educational materials that improve AI literacy among both established scientists seeking to deepen their expertise and new researchers entering the field. To address this need, we developed DL4Proteins, a series of ten interactive notebook modules that introduce fundamental machine learning (ML) concepts, guide users through training ML models for protein-related tasks, and ultimately present cutting-edge protein structure prediction and design pipelines. With nothing more than a web browser, learners can now access state-of-the-art computational tools employed by professional protein engineers - ranging from all-atom protein design to fine-tuning protein language models for biophysically relevant functional tasks. By increasing accessibility, this notebook series broadens participation in AI-driven protein research. The complete notebook series is publicly available at https://github.com/Graylab/DL4Proteins-notebooks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.02128v1</guid>
      <category>q-bio.BM</category>
      <pubDate>Wed, 05 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Chungyoun, Gabe Au, Britnie Carpentier, Sreevarsha Puvada, Courtney Thomas, Jeffrey J. Gray</dc:creator>
    </item>
    <item>
      <title>Machine Learning for RNA Secondary Structure Prediction: a review of current methods and challenges</title>
      <link>https://arxiv.org/abs/2511.02622</link>
      <description>arXiv:2511.02622v1 Announce Type: new 
Abstract: Predicting the secondary structure of RNA is a core challenge in computational biology, essential for understanding molecular function and designing novel therapeutics. The field has evolved from foundational but accuracy-limited thermodynamic approaches to a new data-driven paradigm dominated by machine learning and deep learning. These models learn folding patterns directly from data, leading to significant performance gains. This review surveys the modern landscape of these methods, covering single-sequence, evolutionary-based, and hybrid models that blend machine learning with biophysics. A central theme is the field's "generalization crisis," where powerful models were found to fail on new RNA families, prompting a community-wide shift to stricter, homology-aware benchmarking. In response to the underlying challenge of data scarcity, RNA foundation models have emerged, learning from massive, unlabeled sequence corpora to improve generalization. Finally, we look ahead to the next set of major hurdles-including the accurate prediction of complex motifs like pseudoknots, scaling to kilobase-length transcripts, incorporating the chemical diversity of modified nucleotides, and shifting the prediction target from static structures to the dynamic ensembles that better capture biological function. We also highlight the need for a standardized, prospective benchmarking system to ensure unbiased validation and accelerate progress.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.02622v1</guid>
      <category>q-bio.BM</category>
      <category>physics.bio-ph</category>
      <category>physics.comp-ph</category>
      <pubDate>Wed, 05 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Giuseppe Sacco, Giovanni Bussi, Guido Sanguinetti</dc:creator>
    </item>
    <item>
      <title>STAR-VAE: Latent Variable Transformers for Scalable and Controllable Molecular Generation</title>
      <link>https://arxiv.org/abs/2511.02769</link>
      <description>arXiv:2511.02769v1 Announce Type: cross 
Abstract: The chemical space of drug-like molecules is vast, motivating the development of generative models that must learn broad chemical distributions, enable conditional generation by capturing structure-property representations, and provide fast molecular generation. Meeting the objectives depends on modeling choices, including the probabilistic modeling approach, the conditional generative formulation, the architecture, and the molecular input representation. To address the challenges, we present STAR-VAE (Selfies-encoded, Transformer-based, AutoRegressive Variational Auto Encoder), a scalable latent-variable framework with a Transformer encoder and an autoregressive Transformer decoder. It is trained on 79 million drug-like molecules from PubChem, using SELFIES to guarantee syntactic validity. The latent-variable formulation enables conditional generation: a property predictor supplies a conditioning signal that is applied consistently to the latent prior, the inference network, and the decoder. Our contributions are: (i) a Transformer-based latent-variable encoder-decoder model trained on SELFIES representations; (ii) a principled conditional latent-variable formulation for property-guided generation; and (iii) efficient finetuning with low-rank adapters (LoRA) in both encoder and decoder, enabling fast adaptation with limited property and activity data. On the GuacaMol and MOSES benchmarks, our approach matches or exceeds baselines, and latent-space analyses reveal smooth, semantically structured representations that support both unconditional exploration and property-aware generation. On the Tartarus benchmarks, the conditional model shifts docking-score distributions toward stronger predicted binding. These results suggest that a modernized, scale-appropriate VAE remains competitive for molecular generation when paired with principled conditioning and parameter-efficient finetuning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.02769v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>q-bio.BM</category>
      <pubDate>Wed, 05 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Bum Chul Kwon, Ben Shapira, Moshiko Raboh, Shreyans Sethi, Shruti Murarka, Joseph A Morrone, Jianying Hu, Parthasarathy Suryanarayanan</dc:creator>
    </item>
    <item>
      <title>Gradient GA: Gradient Genetic Algorithm for Drug Molecular Design</title>
      <link>https://arxiv.org/abs/2502.09860</link>
      <description>arXiv:2502.09860v2 Announce Type: replace 
Abstract: Molecular discovery has brought great benefits to the chemical industry. Various molecule design techniques are developed to identify molecules with desirable properties. Traditional optimization methods, such as genetic algorithms, continue to achieve state-of-the-art results across multiple molecular design benchmarks. However, these techniques rely solely on random walk exploration, which hinders both the quality of the final solution and the convergence speed. To address this limitation, we propose a novel approach called Gradient Genetic Algorithm (Gradient GA), which incorporates gradient information from the objective function into genetic algorithms. Instead of random exploration, each proposed sample iteratively progresses toward an optimal solution by following the gradient direction. We achieve this by designing a differentiable objective function parameterized by a neural network and utilizing the Discrete Langevin Proposal to enable gradient guidance in discrete molecular spaces. Experimental results demonstrate that our method significantly improves both convergence speed and solution quality, outperforming cutting-edge techniques. For example, it achieves up to a 25% improvement in the top-10 score over the vanilla genetic algorithm. The code is publicly available at https://github.com/debadyuti23/GradientGA.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.09860v2</guid>
      <category>q-bio.BM</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Wed, 05 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chris Zhuang, Debadyuti Mukherjee, Yingzhou Lu, Tianfan Fu, Ruqi Zhang</dc:creator>
    </item>
    <item>
      <title>Scalable and Cost-Efficient de Novo Template-Based Molecular Generation</title>
      <link>https://arxiv.org/abs/2506.19865</link>
      <description>arXiv:2506.19865v2 Announce Type: replace 
Abstract: Template-based molecular generation offers a promising avenue for drug design by ensuring generated compounds are synthetically accessible through predefined reaction templates and building blocks. In this work, we tackle three core challenges in template-based GFlowNets: (1) minimizing synthesis cost, (2) scaling to large building block libraries, and (3) effectively utilizing small fragment sets. We propose Recursive Cost Guidance, a backward policy framework that employs auxiliary machine learning models to approximate synthesis cost and viability. This guidance steers generation toward low-cost synthesis pathways, significantly enhancing cost-efficiency, molecular diversity, and quality, especially when paired with an Exploitation Penalty that balances the trade-off between exploration and exploitation. To enhance performance in smaller building block libraries, we develop a Dynamic Library mechanism that reuses intermediate high-reward states to construct full synthesis trees. Our approach establishes state-of-the-art results in template-based molecular generation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.19865v2</guid>
      <category>q-bio.BM</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Wed, 05 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Piotr Gai\'nski, Oussama Boussif, Andrei Rekesh, Dmytro Shevchuk, Ali Parviz, Mike Tyers, Robert A. Batey, Micha{\l} Koziarski</dc:creator>
    </item>
    <item>
      <title>Excitonic Coupling and Photon Antibunching in Venus Yellow Fluorescent Protein Dimers: A Lindblad Master Equation Approach</title>
      <link>https://arxiv.org/abs/2508.14233</link>
      <description>arXiv:2508.14233v4 Announce Type: replace-cross 
Abstract: Strong excitonic coupling and photon antibunching (AB) have been observed together in Venus yellow fluorescent protein dimers and currently lack a cohesive theoretical explanation. In 2019, Kim et al. demonstrated Davydov splitting in circular dichroism spectra, revealing strong J-like coupling, while antibunched fluorescence emission was confirmed by combined antibunching--fluorescence correlation spectroscopy (AB/FCS fingerprinting). To investigate the implications of this coexistence, Venus yellow fluorescent protein (YFP) dimer population dynamics are modeled within a Lindblad master equation framework, testing its ability to cope with typical, data-informed, Venus YFP dimer time and energy values. Simulations predict multiple-femtosecond (fs) decoherence, yielding bright/dark state mixtures consistent with antibunched fluorescence emission at room temperature. Thus, excitonic coupling and photon AB in Venus YFP dimers are reconciled without invoking long-lived quantum coherence. However, clear violations of several Lindblad approximation validity conditions appear imminent, calling for careful modifications to choices of standard system and bath definitions and parameter values.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.14233v4</guid>
      <category>quant-ph</category>
      <category>cond-mat.mes-hall</category>
      <category>physics.bio-ph</category>
      <category>physics.optics</category>
      <category>q-bio.BM</category>
      <pubDate>Wed, 05 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ian T. Abrahams</dc:creator>
    </item>
    <item>
      <title>Generative AI for Biosciences: Emerging Threats and Roadmap to Biosecurity</title>
      <link>https://arxiv.org/abs/2510.15975</link>
      <description>arXiv:2510.15975v2 Announce Type: replace-cross 
Abstract: The rapid adoption of generative artificial intelligence (GenAI) in the biosciences is transforming biotechnology, medicine, and synthetic biology. Yet this advancement is intrinsically linked to new vulnerabilities, as GenAI lowers the barrier to misuse and introduces novel biosecurity threats, such as generating synthetic viral proteins or toxins. These dual-use risks are often overlooked, as existing safety guardrails remain fragile and can be circumvented through deceptive prompts or jailbreak techniques. In this Perspective, we first outline the current state of GenAI in the biosciences and emerging threat vectors ranging from jailbreak attacks and privacy risks to the dual-use challenges posed by autonomous AI agents. We then examine urgent gaps in regulation and oversight, drawing on insights from 130 expert interviews across academia, government, industry, and policy. A large majority ($\approx 76$\%) expressed concern over AI misuse in biology, and 74\% called for the development of new governance frameworks. Finally, we explore technical pathways to mitigation, advocating a multi-layered approach to GenAI safety. These defenses include rigorous data filtering, alignment with ethical principles during development, and real-time monitoring to block harmful requests. Together, these strategies provide a blueprint for embedding security throughout the GenAI lifecycle. As GenAI becomes integrated into the biosciences, safeguarding this frontier requires an immediate commitment to both adaptive governance and secure-by-design technologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.15975v2</guid>
      <category>cs.CR</category>
      <category>q-bio.BM</category>
      <pubDate>Wed, 05 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Zaixi Zhang, Souradip Chakraborty, Amrit Singh Bedi, Emilin Mathew, Varsha Saravanan, Le Cong, Alvaro Velasquez, Sheng Lin-Gibson, Megan Blewett, Dan Hendrycs, Alex John London, Ellen Zhong, Ben Raphael, Adji Bousso Dieng, Jian Ma, Eric Xing, Russ Altman, George Church, Mengdi Wang</dc:creator>
    </item>
  </channel>
</rss>
