<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 03 Feb 2025 05:01:03 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Vagus nerve stimulation as a modulator of feedforward and feedback neural transmission</title>
      <link>https://arxiv.org/abs/2501.18770</link>
      <description>arXiv:2501.18770v1 Announce Type: new 
Abstract: Vagus nerve stimulation (VNS) has emerged as a promising therapeutic intervention across various neurological and psychiatric conditions, including epilepsy, depression, and stroke rehabilitation; however, its mechanisms of action on neural circuits remain incompletely understood. Here, we present a novel theoretical framework based on predictive coding that conceptualizes VNS effects through differential modulation of feedforward and feedback neural circuits. Based on recent evidence, we propose that VNS shifts the balance between feedforward and feedback processing through multiple neuromodulatory systems, resulting in enhanced feedforward signal transmission. This framework integrates anatomical pathways, receptor distributions, and physiological responses to explain the influence of the VNS on neural dynamics across different spatial and temporal scales. VNS may facilitate neural plasticity and adaptive behavior through acetylcholine and noradrenaline (norepinephrine), which differentially modulate feedforward and feedback signaling. This mechanistic understanding serves as a basis for interpreting the cognitive and therapeutic outcomes across different clinical conditions. Our perspective provides a unified theoretical framework for understanding circuit-specific VNS effects and suggests new directions for investigating their therapeutic mechanisms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18770v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shinichi Kumagai, Tomoyo Isoguchi Shiramatsu, Kensuke Kawai, Hirokazu Takahashi</dc:creator>
    </item>
    <item>
      <title>Dissociated Neuronal Cultures as Model Systems for Self-Organized Prediction</title>
      <link>https://arxiv.org/abs/2501.18772</link>
      <description>arXiv:2501.18772v1 Announce Type: new 
Abstract: Dissociated neuronal cultures provide a simplified yet effective model system for investigating self-organized prediction and information processing in neural networks. This review consolidates current research demonstrating that these in vitro networks display fundamental computational capabilities, including predictive coding, adaptive learning, goal-directed behavior, and deviance detection. We examine how these cultures develop critical dynamics optimized for information processing, detail the mechanisms underlying learning and memory formation, and explore the relevance of the free energy principle within these systems. Building on these insights, we discuss how findings from dissociated neuronal cultures inform the design of neuromorphic and reservoir computing architectures, with the potential to enhance energy efficiency and adaptive functionality in artificial intelligence. The reduced complexity of neuronal cultures allows for precise manipulation and systematic investigation, bridging theoretical frameworks with practical implementations in bio-inspired computing. Finally, we highlight promising future directions, emphasizing advancements in three-dimensional culture techniques, multi-compartment models, and brain organoids that deepen our understanding of hierarchical and predictive processes in both biological and artificial systems. This review aims to provide a comprehensive overview of how dissociated neuronal cultures contribute to neuroscience and artificial intelligence, ultimately paving the way for biologically inspired computing solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18772v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amit Yaron, Zhuo Zhang, Dai Akita, Tomoyo Isoguchi Shiramatsu, Zenas Chao, Hirokazu Takahashi</dc:creator>
    </item>
    <item>
      <title>Multilayer Networks in Neuroimaging</title>
      <link>https://arxiv.org/abs/2501.19024</link>
      <description>arXiv:2501.19024v1 Announce Type: new 
Abstract: Recent advances in network science, applied to \textit{in vivo} brain recordings, have paved the way for better understanding of the structure and function of the brain. However, despite its obvious usefulness in neuroscience, traditional network science lacks tools for -- so important -- simultaneous investigation of the inter-relationship between the two domains. In this chapter, I explore the increasing role of multilayer networks in building brain generative models and abilities of such models to uncover the full information about the brain complex spatiotemporal interactions that span across multiple scales and modalities. First, I begin with the theoretical foundation of brain networks accompanied by a brief overview of traditional networks and their role in constructing multilayer network models. Then, I delve into the applications of multilayer networks in neuroscience, particularly in deciphering structure-function relationship, modelling diseases, and integrating multi-scale and multi-modal data. Finally, I demonstrate how incorporating the multilayer framework into network neuroscience has brought to light previously hidden features of brain networks and, how multilayer networks can provide new insights and a description of the structure and function of the brain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.19024v1</guid>
      <category>q-bio.NC</category>
      <category>q-bio.QM</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vesna Vuksanovic</dc:creator>
    </item>
    <item>
      <title>Stiff-sloppy analysis of brain networks to reveal individual differences in task performance</title>
      <link>https://arxiv.org/abs/2501.19106</link>
      <description>arXiv:2501.19106v1 Announce Type: new 
Abstract: Understanding how brain networks recruit resources during cognitive tasks is key to explaining individual differences in task performance. Brain network parameters-including activity levels of regions and their connectivity-reflect the integration and segregation of functional subnetworks underlying task processing. However, the complexity and high dimensionality of these parameters pose a significant barrier to identifying functionally relevant individual differences. Here, we introduce stiff-sloppy analysis as a framework for uncovering the stiff parameter combinations that critically influence task-state brain dynamics, exemplified by working memory. Using the pairwise maximum entropy model (PMEM) calibrated to fMRI data and Fisher Information Matrix (FIM) analysis, we reveal that the stiff dimensions of the model parameters capture the most relevant integration and segregation processes of the default mode network and the working memory network. Individual differences along these stiff neural dimensions consistently correlate with working memory performance. Notably, stiff parameters robustly predicted working memory performance, even when the less sensitive ("sloppy") parameters were excluded. This study establishes stiff-sloppy analysis as a powerful approach to identify cognition-related brain networks, bridging neural dynamics and behavior and offering new avenues for personalized neuroscience including therapeutic innovation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.19106v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sida Chen, Qianyuan Tang, Taro Toyoizumi, Werner Sommer, Lianchun Yu, Changsong Zhou</dc:creator>
    </item>
    <item>
      <title>Full-Head Segmentation of MRI with Abnormal Brain Anatomy: Model and Data Release</title>
      <link>https://arxiv.org/abs/2501.18716</link>
      <description>arXiv:2501.18716v1 Announce Type: cross 
Abstract: The goal of this work was to develop a deep network for whole-head segmentation, including clinical MRIs with abnormal anatomy, and compile the first public benchmark dataset for this purpose. We collected 91 MRIs with volumetric segmentation labels for a diverse set of human subjects (4 normal, 32 traumatic brain injuries, and 57 strokes). These clinical cases are characterized by extended cerebrospinal fluid (CSF) in regions normally containing the brain. Training labels were generated by manually correcting initial automated segmentations for skin/scalp, skull, CSF, gray matter, white matter, air cavity, and extracephalic air. We developed a MultiAxial network consisting of three 2D U-Net models that operate independently in sagittal, axial, and coronal planes and are then combined to produce a single 3D segmentation. The MultiAxial network achieved test-set Dice scores of 0.88 (median plus-minus 0.04). For brain tissue, it significantly outperforms existing brain segmentation methods (MultiAxial: 0.898 plus-minus 0.041, SynthSeg: 0.758 plus-minus 0.054, BrainChop: 0.757 plus-minus 0.125). The MultiAxial network gains in robustness by avoiding the need for coregistration with an atlas. It performed well in regions with abnormal anatomy and on images that have been de-identified. It enables more robust current flow modeling when incorporated into ROAST, a widely-used modeling toolbox for transcranial electric stimulation. We are releasing a state-of-the-art model for whole-head MRI segmentation, along with a dataset of 61 clinical MRIs and training labels, including non-brain structures. Together, the model and data may serve as a benchmark for future efforts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18716v1</guid>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>eess.IV</category>
      <category>q-bio.NC</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Andrew M Birnbaum, Adam Buchwald, Peter Turkeltaub, Adam Jacks, Yu Huang, Abhisheck Datta, Lucas C Parra, Lukas A Hirsch</dc:creator>
    </item>
    <item>
      <title>Solving Inverse Problem for Multi-armed Bandits via Convex Optimization</title>
      <link>https://arxiv.org/abs/2501.18945</link>
      <description>arXiv:2501.18945v1 Announce Type: cross 
Abstract: We consider the inverse problem of multi-armed bandits (IMAB) that are widely used in neuroscience and psychology research for behavior modelling. We first show that the IMAB problem is not convex in general, but can be relaxed to a convex problem via variable transformation. Based on this result, we propose a two-step sequential heuristic for (approximately) solving the IMAB problem. We discuss a condition where our method provides global solution to the IMAB problem with certificate, as well as approximations to further save computing time. Numerical experiments indicate that our heuristic method is more robust than directly solving the IMAB problem via repeated local optimization, and can achieve the performance of Monte Carlo methods within a significantly decreased running time. We provide the implementation of our method based on CVXPY, which allows straightforward application by users not well versed in convex optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18945v1</guid>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>q-bio.NC</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hao Zhu, Joschka Boedecker</dc:creator>
    </item>
    <item>
      <title>The role of oscillations in grid cells' toroidal topology</title>
      <link>https://arxiv.org/abs/2501.19262</link>
      <description>arXiv:2501.19262v1 Announce Type: cross 
Abstract: Persistent homology applied to the activity of grid cells in the Medial Entorhinal Cortex suggests that this activity lies on a toroidal manifold. By analyzing real data and a simple model, we show that neural oscillations play a key role in the appearance of this toroidal topology. To quantitatively monitor how changes in spike trains influence the topology of the data, we first define a robust measure for the degree of toroidality of a dataset. Using this measure, we find that small perturbations ($\sim$ 100 ms) of spike times have little influence on both the toroidality and the hexagonality of the ratemaps. Jittering spikes by $\sim$ 100-500 ms, however, destroys the toroidal topology, while still having little impact on grid scores. These critical jittering time scales fall in the range of the periods of oscillations between the theta and eta bands. We thus hypothesized that these oscillatory modulations of neuronal spiking play a key role in the appearance and robustness of toroidal topology and the hexagonal spatial selectivity is not sufficient. We confirmed this hypothesis using a simple model for the activity of grid cells, consisting of an ensemble of independent rate-modulated Poisson processes. When these rates were modulated by oscillations, the network behaved similarly to the real data in exhibiting toroidal topology, even when the position of the fields were perturbed. In the absence of oscillations, this similarity was substantially lower. Furthermore, we find that the experimentally recorded spike trains indeed exhibit temporal modulations at the eta and theta bands, and that the ratio of the power in the eta band to that of the theta band, $A_{\eta}/A_{\theta}$, correlates with the critical jittering time at which the toroidal topology disappears.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.19262v1</guid>
      <category>q-bio.QM</category>
      <category>q-bio.NC</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1371/journal.pcbi.1012776</arxiv:DOI>
      <arxiv:journal_reference>di Sarra G, Jha S, Roudi Y (2025) The role of oscillations in grid cells' toroidal topology. PLOS Computational Biology 21(1):e1012776</arxiv:journal_reference>
      <dc:creator>Giovanni di Sarra, Siddharth Jha, Yasser Roudi</dc:creator>
    </item>
    <item>
      <title>Comparative prospects of imaging methods for whole-brain mammalian connectomics</title>
      <link>https://arxiv.org/abs/2405.10488</link>
      <description>arXiv:2405.10488v4 Announce Type: replace 
Abstract: Mammalian whole-brain connectomes are a foundational ingredient for holistic understanding of brains. Indeed, imaging connectomes at sufficient resolution to densely reconstruct cellular morphology and synapses represents a longstanding goal in neuroscience. Mouse connectomes could soon come within reach while human connectomes remain a more distant yet still worthy goal. Though the technologies needed to reconstruct whole-brain connectomes have not yet reached full maturity, they are advancing rapidly. Close examination of these technologies may help plan connectomics projects. Here, we quantitatively compare imaging technologies that have potential to enable whole-brain mammalian connectomics. We perform calculations on electron microscopy (EM) techniques and expansion light-sheet fluorescence microscopy (ExLSFM) methods. We consider techniques that have sufficient resolution to identify all synapses and sufficient speed to be relevant for whole mammalian brains. We offer this analysis as a resource for those considering how to organize efforts towards imaging whole-brain mammalian connectomes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10488v4</guid>
      <category>q-bio.NC</category>
      <category>q-bio.QM</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Logan Thrasher Collins, Todd Huffman, Randal Koene</dc:creator>
    </item>
    <item>
      <title>Learning Human-Aligned Representations with Contrastive Learning and Generative Similarity</title>
      <link>https://arxiv.org/abs/2405.19420</link>
      <description>arXiv:2405.19420v3 Announce Type: replace-cross 
Abstract: Humans rely on effective representations to learn from few examples and abstract useful information from sensory data. Inducing such representations in machine learning models has been shown to improve their performance on various benchmarks such as few-shot learning and robustness. However, finding effective training procedures to achieve that goal can be challenging as psychologically rich training data such as human similarity judgments are expensive to scale, and Bayesian models of human inductive biases are often intractable for complex, realistic domains. Here, we address this challenge by leveraging a Bayesian notion of generative similarity whereby two data points are considered similar if they are likely to have been sampled from the same distribution. This measure can be applied to complex generative processes, including probabilistic programs. We incorporate generative similarity into a contrastive learning objective to enable learning of embeddings that express human cognitive representations. We demonstrate the utility of our approach by showing that it can be used to capture human-like representations of shape regularity, abstract Euclidean geometric concepts, and semantic hierarchies for natural images.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.19420v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>q-bio.NC</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Raja Marjieh, Sreejan Kumar, Declan Campbell, Liyi Zhang, Gianluca Bencomo, Jake Snell, Thomas L. Griffiths</dc:creator>
    </item>
    <item>
      <title>Inverse decision-making using neural amortized Bayesian actors</title>
      <link>https://arxiv.org/abs/2409.03710</link>
      <description>arXiv:2409.03710v2 Announce Type: replace-cross 
Abstract: Bayesian observer and actor models have provided normative explanations for many behavioral phenomena in perception, sensorimotor control, and other areas of cognitive science and neuroscience. They attribute behavioral variability and biases to interpretable entities such as perceptual and motor uncertainty, prior beliefs, and behavioral costs. However, when extending these models to more naturalistic tasks with continuous actions, solving the Bayesian decision-making problem is often analytically intractable. Inverse decision-making, i.e. performing inference over the parameters of such models given behavioral data, is computationally even more difficult. Therefore, researchers typically constrain their models to easily tractable components, such as Gaussian distributions or quadratic cost functions, or resort to numerical approximations. To overcome these limitations, we amortize the Bayesian actor using a neural network trained on a wide range of parameter settings in an unsupervised fashion. Using the pre-trained neural network enables performing efficient gradient-based Bayesian inference of the Bayesian actor model's parameters. We show on synthetic data that the inferred posterior distributions are in close alignment with those obtained using analytical solutions where they exist. Where no analytical solution is available, we recover posterior distributions close to the ground truth. We then show how our method allows for principled model comparison and how it can be used to disentangle factors that may lead to unidentifiabilities between priors and costs. Finally, we apply our method to empirical data from three sensorimotor tasks and compare model fits with different cost functions to show that it can explain individuals' behavioral patterns.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.03710v2</guid>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <category>stat.ML</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dominik Straub, Tobias F. Niehues, Jan Peters, Constantin A. Rothkopf</dc:creator>
    </item>
    <item>
      <title>BLEND: Behavior-guided Neural Population Dynamics Modeling via Privileged Knowledge Distillation</title>
      <link>https://arxiv.org/abs/2410.13872</link>
      <description>arXiv:2410.13872v2 Announce Type: replace-cross 
Abstract: Modeling the nonlinear dynamics of neuronal populations represents a key pursuit in computational neuroscience. Recent research has increasingly focused on jointly modeling neural activity and behavior to unravel their interconnections. Despite significant efforts, these approaches often necessitate either intricate model designs or oversimplified assumptions. Given the frequent absence of perfectly paired neural-behavioral datasets in real-world scenarios when deploying these models, a critical yet understudied research question emerges: how to develop a model that performs well using only neural activity as input at inference, while benefiting from the insights gained from behavioral signals during training?
  To this end, we propose BLEND, the behavior-guided neural population dynamics modeling framework via privileged knowledge distillation. By considering behavior as privileged information, we train a teacher model that takes both behavior observations (privileged features) and neural activities (regular features) as inputs. A student model is then distilled using only neural activity. Unlike existing methods, our framework is model-agnostic and avoids making strong assumptions about the relationship between behavior and neural activity. This allows BLEND to enhance existing neural dynamics modeling architectures without developing specialized models from scratch. Extensive experiments across neural population activity modeling and transcriptomic neuron identity prediction tasks demonstrate strong capabilities of BLEND, reporting over 50% improvement in behavioral decoding and over 15% improvement in transcriptomic neuron identity prediction after behavior-guided distillation. Furthermore, we empirically explore various behavior-guided distillation strategies within the BLEND framework and present a comprehensive analysis of effectiveness and implications for model performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.13872v2</guid>
      <category>cs.NE</category>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhengrui Guo, Fangxu Zhou, Wei Wu, Qichen Sun, Lishuang Feng, Jinzhuo Wang, Hao Chen</dc:creator>
    </item>
  </channel>
</rss>
