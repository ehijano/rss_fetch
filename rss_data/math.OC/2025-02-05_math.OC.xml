<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 05 Feb 2025 05:00:02 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>New General Fixed-Point Approach to Compute the Resolvent of Composite Operators</title>
      <link>https://arxiv.org/abs/2502.01664</link>
      <description>arXiv:2502.01664v1 Announce Type: new 
Abstract: In this paper, we propose a new general and stable fixed-point approach to compute the resolvents of the composition of a set-valued maximal monotone operator with a linear bounded mapping. Weak, strong and linear convergence of the proposed algorithms are obtained. Advantages of our method over the existing approaches are also thoroughly analyzed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01664v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Samir Adly, Ba Khiet Le</dc:creator>
    </item>
    <item>
      <title>Transient Stability-Constrained OPF: Neural Network Surrogate Models and Pricing Stability</title>
      <link>https://arxiv.org/abs/2502.01844</link>
      <description>arXiv:2502.01844v1 Announce Type: new 
Abstract: A Transient Stability-Constrained Optimal Power Flow (TSC-OPF) problem is proposed that enforces frequency stability constraints using Neural Network (NN) surrogate models. NNs are trained using a novel model-driven active sampling algorithm that iteratively generates NN training data located near the stability boundary and contained within the feasible set of the Alternating Current Optimal Power Flow (AC-OPF) problem. In the context of wholesale electricity markets, pricing structures are analyzed along with their dependencies on the selected input features to the NN surrogate model. An important insight identifies a trade-off between the accuracy of the NN surrogate model and sensible locational pricing structures. NN surrogate models for frequency stability are validated by ensuring the resulting TSC-OPF solution is stable over randomly generated load samples using a small Hawaii test case. The proposed TSC-OPF problem is shown to significantly enhance frequency stability at low computational cost and low financial cost to the system. For certain selections of NN inputs, the TSC-OPF problem is able to stabilize all load scenarios for which the solution to the AC-OPF problem resulted in instability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01844v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Manuel Garcia, Nicole LoGiudice, Robert Parker, Russell Bent</dc:creator>
    </item>
    <item>
      <title>Optimizing Impulsive Releases in Species Competition Models</title>
      <link>https://arxiv.org/abs/2502.01879</link>
      <description>arXiv:2502.01879v1 Announce Type: new 
Abstract: This study focuses on optimizing species release $S_2$ to control species population $S_1$ through impulsive release strategies. We investigate the conditions required to remove species $S_1$, which is equivalent to the establishment of $S_2$. The research includes a theoretical analysis that examines the positivity, existence, and uniqueness of solutions and the conditions for the global stability of the $S_1$-free solution. In addition, we formulate an optimal control problem to maximize the effectiveness of $S_2$ releases, manage the population of $S_1$, and minimize the costs associated with this intervention strategy. Numerical simulations are conducted to validate the proposed theories and allow visualization of population dynamics under various releases scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01879v1</guid>
      <category>math.OC</category>
      <category>q-bio.PE</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>J\'essica C. S. Alves, Sergio M. Oliva, Christian E. Schaerer</dc:creator>
    </item>
    <item>
      <title>Invariant Kernels: Rank Stabilization and Generalization Across Dimensions</title>
      <link>https://arxiv.org/abs/2502.01886</link>
      <description>arXiv:2502.01886v1 Announce Type: new 
Abstract: Symmetry arises often when learning from high dimensional data. For example, data sets consisting of point clouds, graphs, and unordered sets appear routinely in contemporary applications, and exhibit rich underlying symmetries. Understanding the benefits of symmetry on the statistical and numerical efficiency of learning algorithms is an active area of research. In this work, we show that symmetry has a pronounced impact on the rank of kernel matrices. Specifically, we compute the rank of a polynomial kernel of fixed degree that is invariant under various groups acting independently on its two arguments. In concrete circumstances, including the three aforementioned examples, symmetry dramatically decreases the rank making it independent of the data dimension. In such settings, we show that a simple regression procedure is minimax optimal for estimating an invariant polynomial from finitely many samples drawn across different dimensions. We complete the paper with numerical experiments that illustrate our findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01886v1</guid>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mateo D\'iaz, Dmitriy Drusvyatskiy, Jack Kendrick, Rekha R. Thomas</dc:creator>
    </item>
    <item>
      <title>Robust Cislunar Low-Thrust Trajectory Optimization under Uncertainties via Sequential Covariance Steering</title>
      <link>https://arxiv.org/abs/2502.01907</link>
      <description>arXiv:2502.01907v1 Announce Type: new 
Abstract: Spacecraft operations are influenced by uncertainties such as dynamics modeling, navigation, and maneuver execution errors. Although mission design has traditionally incorporated heuristic safety margins to mitigate the effect of uncertainties, particularly before/after crucial events, it is yet unclear whether this practice will scale in the cislunar region, which features locally chaotic nonlinear dynamics and involves frequent lunar flybys. This paper applies chance-constrained covariance steering and sequential convex programming to simultaneously design an optimal trajectory and trajectory correction policy that can probabilistically guarantee safety constraints under the assumed physical/navigational error models. The results show that the proposed method can effectively control the state uncertainty in a highly nonlinear environment and provide a trajectory with better local stability properties than a trajectory designed without considering uncertainties. The framework allows faster computation and lossless covariance propagation compared to existing methods, enabling a rapid and accurate comparison of $\Delta V_{99}$ costs for different uncertainty parameters. We demonstrate the algorithm on several transfers in the Earth-Moon Circular Restricted Three Body Problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01907v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Naoya Kumagai, Kenshiro Oguri</dc:creator>
    </item>
    <item>
      <title>The Ball-Proximal (="Broximal") Point Method: a New Algorithm, Convergence Theory, and Applications</title>
      <link>https://arxiv.org/abs/2502.02002</link>
      <description>arXiv:2502.02002v1 Announce Type: new 
Abstract: Non-smooth and non-convex global optimization poses significant challenges across various applications, where standard gradient-based methods often struggle. We propose the Ball-Proximal Point Method, Broximal Point Method, or Ball Point Method (BPM) for short - a novel algorithmic framework inspired by the classical Proximal Point Method (PPM) (Rockafellar, 1976), which, as we show, sheds new light on several foundational optimization paradigms and phenomena, including non-convex and non-smooth optimization, acceleration, smoothing, adaptive stepsize selection, and trust-region methods. At the core of BPM lies the ball-proximal ("broximal") operator, which arises from the classical proximal operator by replacing the quadratic distance penalty by a ball constraint. Surprisingly, and in sharp contrast with the sublinear rate of PPM in the nonsmooth convex regime, we prove that BPM converges linearly and in a finite number of steps in the same regime. Furthermore, by introducing the concept of ball-convexity, we prove that BPM retains the same global convergence guarantees under weaker assumptions, making it a powerful tool for a broader class of potentially non-convex optimization problems. Just like PPM plays the role of a conceptual method inspiring the development of practically efficient algorithms and algorithmic elements, e.g., gradient descent, adaptive step sizes, acceleration (Ahn &amp; Sra, 2020), and "W" in AdamW (Zhuang et al., 2022), we believe that BPM should be understood in the same manner: as a blueprint and inspiration for further development.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02002v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Kaja Gruntkowska, Hanmin Li, Aadi Rane, Peter Richt\'arik</dc:creator>
    </item>
    <item>
      <title>A Steepest Gradient Method with Nonmonotone Adaptive Step-sizes for the Nonconvex Minimax and Multi-Objective Optimization Problems</title>
      <link>https://arxiv.org/abs/2502.02010</link>
      <description>arXiv:2502.02010v1 Announce Type: new 
Abstract: This paper proposes a new steepest gradient descent method for solving nonconvex finite minimax problems using non-monotone adaptive step sizes and providing proof of convergence results in cases of the nonconvex, quasiconvex, and pseudoconvex differentiate component functions. The proposed method is applied using a referenced-based approach to solve the nonconvex multiobjective programming problems. The convergence to weakly efficient or Pareto stationary solutions is proved for pseudoconvex or quasiconvex multiobjective optimization problems, respectively. A variety of numerical experiments are provided for each scenario to verify the correctness of the theoretical results corresponding to the algorithms proposed for the minimax and multiobjective optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02010v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nguyen Duc Anh, Tran Ngoc Thang</dc:creator>
    </item>
    <item>
      <title>On Squared-Variable Formulations for Nonlinear Semidefinite programming</title>
      <link>https://arxiv.org/abs/2502.02099</link>
      <description>arXiv:2502.02099v1 Announce Type: new 
Abstract: In optimization problems involving smooth functions and real and matrix variables, that contain matrix semidefiniteness constraints, consider the following change of variables: Replace the positive semidefinite matrix $X \in \mathbb{S}^d$, where $\mathbb{S}^d$ is the set of symmetric matrices in $\mathbb{R}^{d\times d}$, by a matrix product $FF^\top$, where $F \in \mathbb{R}^{d \times d}$ or $F \in \mathbb{S}^d$. The formulation obtained in this way is termed ``squared variable," by analogy with a similar idea that has been proposed for real (scalar) variables. It is well known that points satisfying first-order conditions for the squared-variable reformulation do not necessarily yield first-order points for the original problem. There are closer correspondences between second-order points for the squared-variable reformulation and the original formulation. These are explored in this paper, along with correspondences between local minimizers of the two formulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02099v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lijun Ding, Stephen J. Wright</dc:creator>
    </item>
    <item>
      <title>Backcasting Policies in Transport Systems as an Optimal Control Problem : An Example with Electric Vehicle Purchase Incentives</title>
      <link>https://arxiv.org/abs/2502.02204</link>
      <description>arXiv:2502.02204v1 Announce Type: new 
Abstract: This study represents a first attempt to build a backcasting methodology to identify the optimal policy roadmaps in transport systems. Specifically, it considers a passenger car fleet subsystem, modelling its evolution and greenhouse gas emissions. The policy decision under consideration is the monetary incentive to the purchase of electric vehicles. This process is cast as an optimal control problem with the objective to minimize the total budget of the state and reach a desired CO$_2$ target. A case study applied to Metropolitan France is presented to illustrate the approach. Additionally, alternative policy scenarios are also analyzed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02204v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vinith Lakshmanan, Xavier Guichet, Antonio Sciarretta</dc:creator>
    </item>
    <item>
      <title>A Fast and Convergent Algorithm for Unassigned Distance Geometry Problems</title>
      <link>https://arxiv.org/abs/2502.02280</link>
      <description>arXiv:2502.02280v1 Announce Type: new 
Abstract: In this paper, we propose a fast and convergent algorithm to solve unassigned distance geometry problems (uDGP). Technically, we construct a novel quadratic measurement model by leveraging $\ell_0$-norm instead of $\ell_1$-norm in the literature. To solve the nonconvex model, we establish its optimality conditions and develop a fast iterative hard thresholding (IHT) algorithm. Theoretically, we rigorously prove that the whole generated sequence converges to the L-stationary point with the help of the Kurdyka-Lojasiewicz (KL) property. Numerical studies on the turnpike and beltway problems validate its superiority over existing $\ell_1$-norm-based method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02280v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jun Fun, Xiaoya Shan, Xianchao Xiu</dc:creator>
    </item>
    <item>
      <title>Coreset-Based Task Selection for Sample-Efficient Meta-Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2502.02332</link>
      <description>arXiv:2502.02332v1 Announce Type: new 
Abstract: We study task selection to enhance sample efficiency in model-agnostic meta-reinforcement learning (MAML-RL). Traditional meta-RL typically assumes that all available tasks are equally important, which can lead to task redundancy when they share significant similarities. To address this, we propose a coreset-based task selection approach that selects a weighted subset of tasks based on how diverse they are in gradient space, prioritizing the most informative and diverse tasks. Such task selection reduces the number of samples needed to find an $\epsilon$-close stationary solution by a factor of O(1/$\epsilon$). Consequently, it guarantees a faster adaptation to unseen tasks while focusing training on the most relevant tasks. As a case study, we incorporate task selection to MAML-LQR (Toso et al., 2024b), and prove a sample complexity reduction proportional to O(log(1/$\epsilon$)) when the task specific cost also satisfy gradient dominance. Our theoretical guarantees underscore task selection as a key component for scalable and sample-efficient meta-RL. We numerically validate this trend across multiple RL benchmark problems, illustrating the benefits of task selection beyond the LQR baseline.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02332v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Donglin Zhan, Leonardo F. Toso, James Anderson</dc:creator>
    </item>
    <item>
      <title>Stochastic optimal control problems with measurable coefficients via $L^p$-viscosity solutions and applications to optimal advertising models</title>
      <link>https://arxiv.org/abs/2502.02352</link>
      <description>arXiv:2502.02352v1 Announce Type: new 
Abstract: We consider fully non-linear stochastic optimal control problems in infinite horizon with measurable coefficients and uniformly elliptic diffusion. Using the theory of $L^p$-viscosity solutions, we show existence of an $L^p$-viscosity solution $v\in W_{\rm loc}^{2,p}$ of the Hamilton-Jacobi-Bellman (HJB) equation, which, in turn, is also a strong solution (i.e. it satisfies the HJB equation pointwise a.e.). We are then led to prove verification theorems, providing necessary and sufficient conditions for optimality. These results allow us to construct optimal feedback controls. We use the theory developed to solve a stochastic optimal control problem arising in economics within the context of optimal advertising.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02352v1</guid>
      <category>math.OC</category>
      <category>econ.GN</category>
      <category>math.PR</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Filippo de Feo</dc:creator>
    </item>
    <item>
      <title>On The Concurrence of Layer-wise Preconditioning Methods and Provable Feature Learning</title>
      <link>https://arxiv.org/abs/2502.01763</link>
      <description>arXiv:2502.01763v1 Announce Type: cross 
Abstract: Layer-wise preconditioning methods are a family of memory-efficient optimization algorithms that introduce preconditioners per axis of each layer's weight tensors. These methods have seen a recent resurgence, demonstrating impressive performance relative to entry-wise ("diagonal") preconditioning methods such as Adam(W) on a wide range of neural network optimization tasks. Complementary to their practical performance, we demonstrate that layer-wise preconditioning methods are provably necessary from a statistical perspective. To showcase this, we consider two prototypical models, linear representation learning and single-index learning, which are widely used to study how typical algorithms efficiently learn useful features to enable generalization. In these problems, we show SGD is a suboptimal feature learner when extending beyond ideal isotropic inputs $\mathbf{x} \sim \mathsf{N}(\mathbf{0}, \mathbf{I})$ and well-conditioned settings typically assumed in prior work. We demonstrate theoretically and numerically that this suboptimality is fundamental, and that layer-wise preconditioning emerges naturally as the solution. We further show that standard tools like Adam preconditioning and batch-norm only mildly mitigate these issues, supporting the unique benefits of layer-wise preconditioning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01763v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thomas T. Zhang, Behrad Moniri, Ansh Nagwekar, Faraz Rahman, Anton Xue, Hamed Hassani, Nikolai Matni</dc:creator>
    </item>
    <item>
      <title>Uniform attraction and exit problems for stochastic damped wave equations</title>
      <link>https://arxiv.org/abs/2502.01783</link>
      <description>arXiv:2502.01783v1 Announce Type: cross 
Abstract: We consider a class of wave equations with constant damping and polynomial nonlinearities that are perturbed by small, multiplicative, space-time white noise. The equations are defined on a one-dimensional bounded interval with Dirichlet boundary conditions, continuous initial position and distributional initial velocity. In the first part of this work, we study the corresponding deterministic dynamics and prove that certain neighborhoods of asymptotically stable equilibria are uniformly attracting in the topology of uniform convergence. Then, we consider exit problems for local solutions of the stochastic damped wave equations from bounded domains $D$ of uniform attraction. Using tools from large deviations along with novel controllability results, we obtain logarithmic asymptotics for exit times and exit places, in the vanishing noise limit, that are expressed in terms of the corresponding quasipotential. In doing so, we develop arguments that take into account the lack of both smoothing and exact controllability that are inherent to the problem at hand. Moreover, our exit time results provide asymptotic lower bounds for the mean explosion time of local solutions. We introduce a novel notion of "regular" boundary points allowing to avoid the question of boundary smoothness in infinite dimensions and leading to the proof of a large deviations lower bound for the exit place. We illustrate this notion by providing explicit examples for different classes of domains $D$. Conditions under which lower and upper bounds for exit time and exit place logarithmic asymptotic hold, are also presented. In addition, we obtain deterministic stability results for linear damped wave equations that are of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01783v1</guid>
      <category>math.PR</category>
      <category>math.AP</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ioannis Gasteratos, Michael Salins, Konstantinos Spiliopoulos</dc:creator>
    </item>
    <item>
      <title>Score as Action: Fine-Tuning Diffusion Generative Models by Continuous-time Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2502.01819</link>
      <description>arXiv:2502.01819v1 Announce Type: cross 
Abstract: Reinforcement learning from human feedback (RLHF), which aligns a diffusion model with input prompt, has become a crucial step in building reliable generative AI models. Most works in this area use a discrete-time formulation, which is prone to induced errors, and often not applicable to models with higher-order/black-box solvers. The objective of this study is to develop a disciplined approach to fine-tune diffusion models using continuous-time RL, formulated as a stochastic control problem with a reward function that aligns the end result (terminal state) with input prompt. The key idea is to treat score matching as controls or actions, and thereby making connections to policy optimization and regularization in continuous-time RL. To carry out this idea, we lay out a new policy optimization framework for continuous-time RL, and illustrate its potential in enhancing the value networks design space via leveraging the structural property of diffusion models. We validate the advantages of our method by experiments in downstream tasks of fine-tuning large-scale Text2Image models of Stable Diffusion v1.5.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01819v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hanyang Zhao, Haoxian Chen, Ji Zhang, David D. Yao, Wenpin Tang</dc:creator>
    </item>
    <item>
      <title>Containment Control Approach for Steering Opinion in a Social Network</title>
      <link>https://arxiv.org/abs/2502.01847</link>
      <description>arXiv:2502.01847v1 Announce Type: cross 
Abstract: The paper studies the problem of steering multi-dimensional opinion in a social network. Assuming the society of desire consists of stubborn and regular agents, stubborn agents are considered as leaders who specify the desired opinion distribution as a distributed reward or utility function. In this context, each regular agent is seen as a follower, updating its bias on the initial opinion and influence weights by averaging their observations of the rewards their influencers have received. Assuming random graphs with reducible and irreducible topology specify the influences on regular agents, opinion evolution is represented as a containment control problem in which stability and convergence to the final opinion are proven.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01847v1</guid>
      <category>eess.SY</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hossein Rastgoftar</dc:creator>
    </item>
    <item>
      <title>Determining inscribability of polytopes via rank minimization based on slack matrices</title>
      <link>https://arxiv.org/abs/2502.01878</link>
      <description>arXiv:2502.01878v1 Announce Type: cross 
Abstract: A polytope is inscribable if there is a realization where all vertices lie on the sphere. In this paper, we provide a necessary and sufficient condition for a polytope to be inscribable. Based on this condition, we characterize the problem of determining inscribability as a minimum rank optimization problem using slack matrices. We propose an SDP approximation for the minimum rank optimization problem and prove that it is tight for certain classes of polytopes. Given a polytope, we provide three algorithms to determine its inscribability. All the optimization problems and algorithms we propose in this paper depend on the number of vertices and facets but are independent of the dimension of the polytope. Numerical results demonstrate our SDP approximation's efficiency, accuracy, and robustness for determining inscribability of simplicial polytopes of dimensions $4\le d\le 8$ with vertices $n\le 10$, revealing its potential in high dimensions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01878v1</guid>
      <category>math.CO</category>
      <category>math.OC</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yiwen Chen, Jo\~ao Gouveia, Warren Hare, Amy Wiebe</dc:creator>
    </item>
    <item>
      <title>Multimaterial topology optimization for finite strain elastoplasticity: theory, methods, and applications</title>
      <link>https://arxiv.org/abs/2502.02052</link>
      <description>arXiv:2502.02052v1 Announce Type: cross 
Abstract: Plasticity is inherent to many engineering materials such as metals. While it can degrade the load-carrying capacity of structures via material yielding, it can also protect structures through plastic energy dissipation. To fully harness plasticity, here we present the theory, method, and application of a topology optimization framework that simultaneously optimizes structural geometries and material phases to customize the stiffness, strength, and structural toughness of designs experiencing finite strain elastoplasticity. The framework accurately predicts structural responses by employing a rigorous, mechanics-based elastoplasticity theory that ensures isochoric plastic flow. It also effectively identifies optimal material phase distributions using a gradient-based optimizer, where gradient information is obtained via a reversed adjoint method to address history dependence, along with automatic differentiation to compute the complex partial derivatives. We demonstrate the framework by optimizing a range of 2D and 3D elastoplastic structures, including energy-dissipating dampers, load-carrying beams, impact-resisting bumpers, and cold working profiled sheets. These optimized multimaterial structures reveal important mechanisms for improving design performance under large deformation, such as the transition from kinematic to isotropic hardening with increasing displacement amplitudes and the formation of twisted regions that concentrate stress, enhancing plastic energy dissipation. Through the superior performance of these optimized designs, we demonstrate the framework's effectiveness in tailoring elastoplastic responses across various spatial configurations, material types, hardening behaviors, and combinations of candidate materials. This work offers a systematic approach for optimizing next-generation multimaterial structures with elastoplastic behaviors under large deformations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02052v1</guid>
      <category>cs.CE</category>
      <category>math.OC</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yingqi Jia, Xiaojia Shelly Zhang</dc:creator>
    </item>
    <item>
      <title>How Memory in Optimization Algorithms Implicitly Modifies the Loss</title>
      <link>https://arxiv.org/abs/2502.02132</link>
      <description>arXiv:2502.02132v1 Announce Type: cross 
Abstract: In modern optimization methods used in deep learning, each update depends on the history of previous iterations, often referred to as memory, and this dependence decays fast as the iterates go further into the past. For example, gradient descent with momentum has exponentially decaying memory through exponentially averaged past gradients. We introduce a general technique for identifying a memoryless algorithm that approximates an optimization algorithm with memory. It is obtained by replacing all past iterates in the update by the current one, and then adding a correction term arising from memory (also a function of the current iterate). This correction term can be interpreted as a perturbation of the loss, and the nature of this perturbation can inform how memory implicitly (anti-)regularizes the optimization dynamics. As an application of our theory, we find that Lion does not have the kind of implicit anti-regularization induced by memory that AdamW does, providing a theory-based explanation for Lion's better generalization performance recently documented.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02132v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matias D. Cattaneo, Boris Shigida</dc:creator>
    </item>
    <item>
      <title>Exact Sequence Classification with Hardmax Transformers</title>
      <link>https://arxiv.org/abs/2502.02270</link>
      <description>arXiv:2502.02270v1 Announce Type: cross 
Abstract: We prove that hardmax attention transformers perfectly classify datasets of $N$ labeled sequences in $\mathbb{R}^d$, $d\geq 2$. Specifically, given $N$ sequences with an arbitrary but finite length in $\mathbb{R}^d$, we construct a transformer with $\mathcal{O}(N)$ blocks and $\mathcal{O}(Nd)$ parameters perfectly classifying this dataset. Our construction achieves the best complexity estimate to date, independent of the length of the sequences, by innovatively alternating feed-forward and self-attention layers and by capitalizing on the clustering effect inherent to the latter. Our novel constructive method also uses low-rank parameter matrices within the attention mechanism, a common practice in real-life transformer implementations. Consequently, our analysis holds twofold significance: it substantially advances the mathematical theory of transformers and it rigorously justifies their exceptional real-world performance in sequence classification tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02270v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Albert Alcalde, Giovanni Fantuzzi, Enrique Zuazua</dc:creator>
    </item>
    <item>
      <title>Circular Microalgae-Based Carbon Control for Net Zero</title>
      <link>https://arxiv.org/abs/2502.02382</link>
      <description>arXiv:2502.02382v1 Announce Type: cross 
Abstract: The alteration of the climate in various areas of the world is of increasing concern since climate stability is a necessary condition for human survival as well as every living organism. The main reason of climate change is the greenhouse effect caused by the accumulation of carbon dioxide in the atmosphere. In this paper, we design a networked system underpinned by compartmental dynamical thermodynamics to circulate the atmospheric carbon dioxide. Specifically, in the carbon dioxide emitter compartment, we develop an initial-condition-dependent finite-time stabilizing controller that guarantees stability within a desired time leveraging the system property of affinity in the control. Then, to compensate for carbon emissions we show that a cultivation of microalgae with a volume 625 times bigger than the one of the carbon emitter is required. To increase the carbon uptake of the microalgae, we implement the nonaffine-in-the-control microalgae dynamical equations as an environment of a state-of-the-art library for reinforcement learning (RL), namely, Stable-Baselines3, and then, through the library, we test the performance of eight RL algorithms for training a controller that maximizes the microalgae absorption of carbon through the light intensity. All the eight controllers increased the carbon absorption of the cultivation during a training of 200,000 time steps with a maximum episode length of 200 time steps and with no termination conditions. This work is a first step towards approaching net zero as a classical and learning-based network control problem. The source code is publicly available.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02382v1</guid>
      <category>math.DS</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Federico Zocco, Joan Garc\'ia, Wassim M. Haddad</dc:creator>
    </item>
    <item>
      <title>A weak convergence approach to large deviations for stochastic approximations</title>
      <link>https://arxiv.org/abs/2502.02529</link>
      <description>arXiv:2502.02529v1 Announce Type: cross 
Abstract: The theory of stochastic approximations form the theoretical foundation for studying convergence properties of many popular recursive learning algorithms in statistics, machine learning and statistical physics. Large deviations for stochastic approximations provide asymptotic estimates of the probability that the learning algorithm deviates from its expected path, given by a limit ODE, and the large deviation rate function gives insights to the most likely way that such deviations occur.
  In this paper we prove a large deviation principle for general stochastic approximations with state-dependent Markovian noise and decreasing step size. Using the weak convergence approach to large deviations, we generalize previous results for stochastic approximations and identify the appropriate scaling sequence for the large deviation principle. We also give a new representation for the rate function, in which the rate function is expressed as an action functional involving the family of Markov transition kernels. Examples of learning algorithms that are covered by the large deviation principle include stochastic gradient descent, persistent contrastive divergence and the Wang-Landau algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02529v1</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Henrik Hult, Adam Lindhe, Pierre Nyquist, Guo-Jhen Wu</dc:creator>
    </item>
    <item>
      <title>Singular stochastic control problems motivated by the optimal sustainable exploitation of an ecosystem</title>
      <link>https://arxiv.org/abs/2008.05576</link>
      <description>arXiv:2008.05576v3 Announce Type: replace 
Abstract: We derive the explicit solutions to singular stochastic control problems of the monotone follower type with (a) an expected discounted criterion, (b) an expected ergodic criterion and (c) a pathwise ergodic criterion. These problems have been motivated by the optimal sustainable exploitation of an ecosystem, such as a natural fishery. Under general assumptions on the diffusion coefficients, the discounting rate function, the running payoff function and the marginal profit of control action, we show that the optimal strategies are of a threshold type. We solve the three problems by first constructing suitable solutions to their associated HJB equations, which take the form of quasi-variational inequalities with gradient constraints. In the cases of the ergodic control problems, we also use a suitable new variational argument. Furthermore, we establish the convergence of the solution of the discounted control problem to the one of the ergodic control problems as the discounting rate function tends to 0 in an Abelian sense.</description>
      <guid isPermaLink="false">oai:arXiv.org:2008.05576v3</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gechun Liang, Zhesheng Liu, Mihail Zervos</dc:creator>
    </item>
    <item>
      <title>Error bound and exact penalty method for optimization problems with nonnegative orthogonal constraint</title>
      <link>https://arxiv.org/abs/2111.03457</link>
      <description>arXiv:2111.03457v5 Announce Type: replace 
Abstract: This paper is concerned with a class of optimization problems with the nonnegative orthogonal constraint, in which the objective function is $L$-smooth on an open set containing the Stiefel manifold ${\rm St}(n,r)$. We derive a locally Lipschitzian error bound for the feasible points without zero rows when $n&gt;r&gt;1$, and when $n&gt;r=1$ or $n=r$ achieve a global Lipschitzian error bound. Then, we show that the penalty problem induced by the elementwise $\ell_1$-norm distance to the nonnegative cone is a global exact penalty, and so is the one induced by its Moreau envelope under a lower second-order calmness of the objective function. A practical penalty algorithm is developed by solving approximately a series of smooth penalty problems with a retraction-based nonmonotone line-search proximal gradient method, and any cluster point of the generated sequence is shown to be a stationary point of the original problem. Numerical comparisons with the ALM \citep{Wen13} and the exact penalty method \citep{JiangM22} indicate that our penalty method has an advantage in terms of the quality of solutions despite taking a little more time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2111.03457v5</guid>
      <category>math.OC</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1093/imanum/drac084</arxiv:DOI>
      <dc:creator>Yitian Qian, Shaohua Pan, Lianghai Xiao</dc:creator>
    </item>
    <item>
      <title>Monge-Kantorovich interpolation with constraints and application to a parking problem</title>
      <link>https://arxiv.org/abs/2207.14261</link>
      <description>arXiv:2207.14261v2 Announce Type: replace 
Abstract: We consider optimal transport problems where the cost for transporting a given probability measure $\mu_0$ to another one $\mu_1$ consists of two parts: the first one measures the transportation from $\mu_0$ to an intermediate (pivot) measure $\mu$ to be determined (and subject to various constraints), and the second one measures the transportation from $\mu$ to $\mu_1$. This leads to Monge-Kantorovich interpolation problems under constraints for which we establish various properties of the optimal pivot measures $\mu$. Considering the more general situation where only some part of the mass uses the intermediate stop leads to a mathematical model for the optimal location of a parking region around a city. Numerical simulations, based on entropic regularization, are presented both for the optimal parking regions and for Monge-Kantorovich constrained interpolation problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2207.14261v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.4171/ifb/514</arxiv:DOI>
      <dc:creator>Giuseppe Buttazzo, Guillaume Carlier, Katharina Eichinger</dc:creator>
    </item>
    <item>
      <title>Sampled-data funnel control and its use for safe continual learning</title>
      <link>https://arxiv.org/abs/2303.00523</link>
      <description>arXiv:2303.00523v5 Announce Type: replace 
Abstract: We propose a novel sampled-data output-feedback controller for nonlinear systems of arbitrary relative degree that ensures reference tracking within prescribed error bounds. We provide explicit bounds on the maximum input signal and the required uniform sampling time. A key strength of this approach is its capability to serve as a safety filter for various learning-based controller designs, enabling the use of learning techniques in safety-critical applications. We illustrate its versatility by integrating it with two different controllers: a reinforcement learning controller and a non-parametric predictive controller based on Willems et al.'s fundamental lemma. Numerical simulations illustrate effectiveness of the combined controller design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.00523v5</guid>
      <category>math.OC</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Lukas Lanza, Dario Dennst\"adt, Karl Worthmann, Philipp Schmitz, G\"ok\c{c}en Devlet \c{S}en, Stephan Trenn, Manuel Schaller</dc:creator>
    </item>
    <item>
      <title>ADMM-Tracking Gradient for Distributed Optimization over Asynchronous and Unreliable Networks</title>
      <link>https://arxiv.org/abs/2309.14142</link>
      <description>arXiv:2309.14142v3 Announce Type: replace 
Abstract: In this paper, we propose a novel distributed algorithm for consensus optimization over networks and a robust extension tailored to deal with asynchronous agents and packet losses. Indeed, to robustly achieve dynamic consensus on the solution estimates and the global descent direction, we embed in our algorithms a distributed implementation of the Alternating Direction Method of Multipliers (ADMM). Such a mechanism is suitably interlaced with a local proportional action steering each agent estimate to the solution of the original consensus optimization problem. First, in the case of ideal networks, by using tools from system theory, we prove the linear convergence of the scheme with strongly convex costs. Then, by exploiting the averaging theory, we extend such a first result to prove that the robust extension of our method preserves linear convergence in the case of asynchronous agents and packet losses. Further, by using the notion of Input-to-State Stability, we also guarantee the robustness of the schemes with respect to additional, generic errors affecting the agents' updates. Finally, some numerical simulations confirm our theoretical findings and compare our algorithms with other distributed schemes in terms of speed and robustness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.14142v3</guid>
      <category>math.OC</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Guido Carnevale, Nicola Bastianello, Giuseppe Notarstefano, Ruggero Carli</dc:creator>
    </item>
    <item>
      <title>Continuity of Filters for Discrete-Time Control Problems Defined by Explicit Equations</title>
      <link>https://arxiv.org/abs/2311.12184</link>
      <description>arXiv:2311.12184v3 Announce Type: replace 
Abstract: Discrete time control systems whose dynamics and observations are described by stochastic equations are common in engineering, operations research, health care, and economics. For example, stochastic filtering problems are usually defined via stochastic equations. These problems can be reduced to Markov decision processes (MDPs) whose states are posterior state distributions, and transition probabilities for such MDPs are sometimes called filters. This paper investigates sufficient conditions on transition and observation functions for the original problems to guarantee weak continuity of the filter. Under mild conditions on cost functions, weak continuity implies the existence of optimal policies minimizing the expected total costs, the validity of optimality equations, and convergence of value iterations to optimal values. This paper uses recent results on weak continuity of filters for partially observable MDPs defined by transition and observation probabilities. It develops a criterion of weak continuity of transition probabilities and a sufficient condition for continuity in total variation of transition probabilities. The results are illustrated with applications to filtering problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.12184v3</guid>
      <category>math.OC</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Eugene A. Feinberg, Sayaka Ishizawa, Pavlo O. Kasyanov, David N. Kraemer</dc:creator>
    </item>
    <item>
      <title>Scaling Mixed-Integer Programming for Certification of Neural Network Controllers Using Bounds Tightening</title>
      <link>https://arxiv.org/abs/2403.17874</link>
      <description>arXiv:2403.17874v2 Announce Type: replace 
Abstract: Neural networks offer a computationally efficient approximation of model predictive control, but they lack guarantees on the resulting controlled system's properties. Formal certification of neural networks is crucial for ensuring safety, particularly in safety-critical domains such as autonomous vehicles. One approach to formally certify properties of neural networks is to solve a mixed-integer program based on the network. This approach suffers from scalability issues due to the complexity of solving the resulting mixed-integer programs. Nevertheless, these issues can be (partially) mitigated via bound-tightening techniques prior to forming the mixed-integer program, which results in tighter formulations and faster optimisation. This paper presents bound-tightening techniques in the context of neural network explicit control policies. Bound tightening is particularly important when considering problems spanning multiple time steps of a controlled system, as the bounds must be propagated through the problem depth. Several strategies for bound tightening are evaluated in terms of both computational complexity and tightness of the bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.17874v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Philip Sosnin, Calvin Tsay</dc:creator>
    </item>
    <item>
      <title>Fisher-Rao Gradient Flows of Linear Programs and State-Action Natural Policy Gradients</title>
      <link>https://arxiv.org/abs/2403.19448</link>
      <description>arXiv:2403.19448v2 Announce Type: replace 
Abstract: Kakade's natural policy gradient method has been studied extensively in recent years, showing linear convergence with and without regularization. We study another natural gradient method based on the Fisher information matrix of the state-action distributions which has received little attention from the theoretical side. Here, the state-action distributions follow the Fisher-Rao gradient flow inside the state-action polytope with respect to a linear potential. Therefore, we study Fisher-Rao gradient flows of linear programs more generally and show linear convergence with a rate that depends on the geometry of the linear program. Equivalently, this yields an estimate on the error induced by entropic regularization of the linear program which improves existing results. We extend these results and show sublinear convergence for perturbed Fisher-Rao gradient flows and natural gradient flows up to an approximation error. In particular, these general results cover the case of state-action natural policy gradients.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.19448v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.NA</category>
      <category>stat.ML</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Johannes M\"uller, Semih \c{C}ayc{\i}, Guido Mont\'ufar</dc:creator>
    </item>
    <item>
      <title>Tricks from the Trade for Large-Scale Markdown Pricing: Heuristic Cut Generation for Lagrangian Decomposition</title>
      <link>https://arxiv.org/abs/2404.02996</link>
      <description>arXiv:2404.02996v2 Announce Type: replace 
Abstract: In automated decision making processes in the online fashion industry, the 'predict-then-optimize' paradigm is frequently applied, particularly for markdown pricing strategies. This typically involves a mixed-integer optimization step, which is crucial for maximizing profit and merchandise volume. In practice, the size and complexity of the optimization problem is prohibitive for using off-the-shelf solvers for mixed integer programs and specifically tailored approaches are a necessity. Our paper introduces specific heuristics designed to work alongside decomposition methods, leading to almost-optimal solutions. These heuristics, which include both primal heuristic methods and a cutting plane generation technique within a Lagrangian decomposition framework, are the core focus of the present paper. We provide empirical evidence for their effectiveness, drawing on real-world applications at Zalando SE, one of Europe's leading online fashion retailers, highlighting the practical value of our work. The contributions of this paper are deeply ingrained into Zalando's production environment to its large-scale catalog ranging in the millions of products and improving weekly profits by millions of Euros.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02996v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Robert Streeck, Torsten Gellert, Andreas Schmitt, Asya Dipkaya, Vladimir Fux, Tim Januschowski, Timo Berthold</dc:creator>
    </item>
    <item>
      <title>A continuous-time violation-free multi-agent optimization algorithm and its applications to safe distributed control</title>
      <link>https://arxiv.org/abs/2404.07571</link>
      <description>arXiv:2404.07571v2 Announce Type: replace 
Abstract: In this work, we propose a continuous-time distributed optimization algorithm with guaranteed zero coupling constraint violation and apply it to safe distributed control in the presence of multiple control barrier functions (CBF). The optimization problem is defined over a network that collectively minimizes a separable cost function with coupled linear constraints. An equivalent optimization problem with auxiliary decision variables and a decoupling structure is proposed. A sensitivity analysis demonstrates that the subgradient information can be computed using local information. This then leads to a subgradient algorithm for updating the auxiliary variables. A case with sparse coupling constraints is further considered, and it is shown to have better memory and communication efficiency. For the specific case of a CBF-induced time-varying quadratic program (QP), an update law is proposed that achieves finite-time convergence. Numerical results involving a static resource allocation problem and a safe coordination problem for a multi-agent system demonstrate the efficiency and effectiveness of our proposed algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07571v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiao Tan, Changxin Liu, Karl H. Johansson, Dimos V. Dimarogonas</dc:creator>
    </item>
    <item>
      <title>Regular Subgradients of Marginal Functions with Applications to Calculus and Bilevel Programming</title>
      <link>https://arxiv.org/abs/2405.20737</link>
      <description>arXiv:2405.20737v2 Announce Type: replace 
Abstract: The paper addresses the study and applications of a broad class of extended-real-valued functions, known as optimal value or marginal functions, which are frequently appeared in variational analysis, parametric optimization, and a variety of applications. Functions of this type are intrinsically nonsmooth and require the usage of tools of generalized differentiation. The main results of this paper provide novel evaluations and exact calculations of regular/Fr\'echet subgradients and their singular counterparts for general classes of marginal functions via their given data. The obtained results are applied to establishing new calculus rules for such subgradients and necessary optimality conditions in bilevel programming</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20737v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Le Phuoc Hai, Felipe Lara, Boris S. Mordukhovich</dc:creator>
    </item>
    <item>
      <title>A Characterization for Tightness of the Sparse Moment-SOS Hierarchy</title>
      <link>https://arxiv.org/abs/2406.06882</link>
      <description>arXiv:2406.06882v2 Announce Type: replace 
Abstract: This paper studies the sparse Moment-SOS hierarchy of relaxations for solving sparse polynomial optimization problems. We show that this sparse hierarchy is tight if and only if the objective can be written as a sum of sparse nonnegative polynomials, each of which belongs to the sum of the ideal and quadratic module generated by the corresponding sparse constraints. Based on this characterization, we give several sufficient conditions for the sparse Moment-SOS hierarchy to be tight. In particular, we show that this sparse hierarchy is tight under some assumptions such as convexity, optimality conditions or finiteness of constraining sets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06882v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiawang Nie, Zheng Qu, Xindong Tang, Linghao Zhang</dc:creator>
    </item>
    <item>
      <title>Method for finding solution to "quasidifferentiable" differential inclusion</title>
      <link>https://arxiv.org/abs/2406.15384</link>
      <description>arXiv:2406.15384v2 Announce Type: replace 
Abstract: The paper explores the differential inclusion of a special form. It is supposed that the support function of the set in the right-hand side of an inclusion may contain the sum of the maximum and the minimum of the finite number of continuously differentiable (in phase coordinates) functions. It is required to find a trajectory that would satisfy differential inclusion with the boundary conditions prescribed and simultaneously lie on the surface given. We give substantial examples of problems where such differential inclusions may occur: models of discontinuous systems, linear control systems where the control function or/and disturbance of the right-hand side is/are known to be subject to some nonsmooth (in phase vector) constraints, some real mechanical models and differential inclusions per se with special geometrical structure of the right-hand side. The initial problem is reduced to a variational one. It is proved that the resulting functional to be minimized is quasidifferentiable. The necessary minimum conditions in terms of quasidifferential are formulated. The (modified) steepest (or the quasidifferential) descent method in a classical form is then applied to find stationary points of the functional obtained. Herewith, the functional is constructed in such a way that one can verify whether the stationary point constructed is indeed a global minimum point of the problem. The ``weak'' convergence of the method proposed is proved for some particular cases. The method constructed is illustrated by numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15384v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexander Fominyh</dc:creator>
    </item>
    <item>
      <title>An accelerated gradient method with adaptive restart for convex multiobjective optimization problems</title>
      <link>https://arxiv.org/abs/2501.07863</link>
      <description>arXiv:2501.07863v4 Announce Type: replace 
Abstract: In this work, based on the continuous time approach, we propose an accelerated gradient method with adaptive residual restart for convex multiobjective optimization problems. For the first, we derive rigorously the continuous limit of the multiobjective accelerated proximal gradient method by Tanabe et al. [Comput. Optim. Appl., 2023]. It is a second-order ordinary differential equation (ODE) that involves a special projection operator and can be viewed as an extension of the ODE by Su et al. [J. Mach. Learn. Res., 2016] for Nesterov acceleration. Then, we introduce a novel accelerated multiobjective gradient (AMG) flow with tailored time scaling that adapts automatically to the convex case and the strongly convex case, and the exponential decay rate of a merit function along with the solution trajectory of AMG flow is established via the Lyapunov analysis. After that, we consider an implicit-explicit time discretization and obtain an accelerated multiobjective gradient method with a convex quadratic programming subproblem. The fast sublinear rate and linear rate are proved respectively for convex and strongly convex problems. In addition, we present an efficient residual based adaptive restart technique to overcome the oscillation issue and improve the convergence significantly. Numerical results are provided to validate the practical performance of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.07863v4</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hao Luo, Liping Tang, Xinmin Yang</dc:creator>
    </item>
    <item>
      <title>Sparsity-driven Aggregation of Mixed Integer Programs</title>
      <link>https://arxiv.org/abs/2502.01192</link>
      <description>arXiv:2502.01192v2 Announce Type: replace 
Abstract: Cutting planes are crucial for the performance of branch-and-cut algorithms for solving mixed-integer programming (MIP) problems, and linear row aggregation has been successfully applied to better leverage the potential of several major families of MIP cutting planes. This paper formulates the problem of finding good quality aggregations as an $\ell_0$-norm minimization problem and employs a combination of the lasso method and iterative reweighting to efficiently find sparse solutions corresponding to good aggregations. A comparative analysis of the proposed algorithm and the state-of-the-art greedy heuristic approach is presented, showing that the greedy heuristic implements a stepwise selection algorithm for the $\ell_0$-norm minimization problem. Further, we present an example where our approach succeeds, whereas the standard heuristic fails to find an aggregation with desired properties. The algorithm is implemented within the constraint integer programming solver SCIP, and computational experiments on the MIPLIB 2017 benchmark show that although the algorithm leads to slowdowns on relatively ``easier'' instances, our aggregation approach decreases the mean running time on a subset of challenging instances and leads to smaller branch-and-bound trees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01192v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Liding Xu, Gioni Mexi, Ksenia Bestuzheva</dc:creator>
    </item>
    <item>
      <title>Deep learning adaptive Model Predictive Control of Fed-Batch Cultivations</title>
      <link>https://arxiv.org/abs/2502.01488</link>
      <description>arXiv:2502.01488v2 Announce Type: replace 
Abstract: Bioprocesses are often characterised by nonlinear and uncertain dynamics, posing particular challenges for model predictive control (MPC) algorithms due to their computational demands when applied to nonlinear systems. Recent advances in optimal control theory have demonstrated that concepts from convex optimisation, tube MPC, and differences of convex functions (DC) enable efficient, robust online process control. Our approach is based on DC decompositions of nonlinear dynamics and successive linearisations around predicted trajectories. By convexity, the linearisation errors have tight bounds and can be treated as bounded disturbances within a robust tube MPC framework. We describe a systematic, data-driven method for computing DC model representations using deep learning neural networks with a special convex structure, and explain how the resulting MPC optimisation can be solved using convex programming. For the problem of maximising product formation in a cultivation with uncertain model parameters, we design a controller that ensures robust constraint satisfaction and allows online estimation of unknown model parameters. Our results indicate that this method is a promising solution for computationally tractable, robust MPC of bioprocesses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01488v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Niels Krausch, Martin Doff-Sotta, Mark Cannon, Peter Neubauer, Mariano Nicolas Cruz Bournazou</dc:creator>
    </item>
    <item>
      <title>Control Barrier Functions for Collision Avoidance Between Strongly Convex Regions</title>
      <link>https://arxiv.org/abs/2306.13259</link>
      <description>arXiv:2306.13259v2 Announce Type: replace-cross 
Abstract: In this paper, we focus on non-conservative collision avoidance between robots and obstacles with control affine dynamics and convex shapes. System safety is defined using the minimum distance between the safe regions associated with robots and obstacles. However, collision avoidance using the minimum distance as a control barrier function (CBF) can pose challenges because the minimum distance is implicitly defined by an optimization problem and thus nonsmooth in general. We identify a class of state-dependent convex sets, defined as strongly convex maps, for which the minimum distance is continuously differentiable, and the distance derivative can be computed using KKT solutions of the minimum distance problem. In particular, our formulation allows for ellipsoid-polytope collision avoidance and convex set algebraic operations on strongly convex maps. We show that the KKT solutions for strongly convex maps can be rapidly and accurately updated along state trajectories using a KKT solution ODE. Lastly, we propose a QP incorporating the CBF constraints and prove strong safety under minimal assumptions on the QP structure. We validate our approach in simulation on a quadrotor system navigating through an obstacle-filled corridor and demonstrate that CBF constraints can be enforced in real time for state-dependent convex sets without overapproximations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.13259v2</guid>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Akshay Thirugnanam, Jun Zeng, Koushil Sreenath</dc:creator>
    </item>
    <item>
      <title>Approximating Competitive Equilibrium by Nash Welfare</title>
      <link>https://arxiv.org/abs/2402.09994</link>
      <description>arXiv:2402.09994v2 Announce Type: replace-cross 
Abstract: We explore the relationship between two popular concepts in the allocation of divisible items: competitive equilibrium (CE) and allocations with maximum Nash welfare, i.e., allocations where the weighted geometric mean of the utilities is maximal. When agents have homogeneous concave utility functions, these two concepts coincide: the classical Eisenberg-Gale convex program that maximizes Nash welfare over feasible allocations yields a competitive equilibrium. However, these two concepts diverge for non-homogeneous utilities. From a computational perspective, maximizing Nash welfare amounts to solving a convex program for any concave utility functions, computing CE becomes PPAD-hard already for separable piecewise linear concave (SPLC) utilities.
  We introduce the concept of Gale-substitute utility functions, which is an analogue of the weak gross substitutes (WGS) property for the so-called Gale demand system. For Gale-substitutes utilities, we show that any allocation maximizing Nash welfare provides an approximate-CE with surprisingly strong guarantees, where every agent gets at least half the maximum utility they can get at any CE, and is approximately envy-free. Gale-substitutes include utility functions where computing CE is PPAD hard, such as all separable concave utilities and the previously studied non-separable class of Leontief-free utilities. We introduce a broad new class of utility functions called generalized network utilities based on the generalized flow model. This class includes SPLC and Leontief-free utilities, and we show that all such utilities are Gale-substitutes.
  Conversely, although some agents may get much higher utility at a Nash welfare maximizing allocation than at a CE, we show a price of anarchy type result: for general concave utilities, every CE achieves at least $(1/e)^{1/e} &gt; 0.69$ fraction of the maximum Nash welfare, and this factor is tight.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.09994v2</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jugal Garg, Yixin Tao, L\'aszl\'o A. V\'egh</dc:creator>
    </item>
    <item>
      <title>Statistical Mechanics of Dynamical System Identification</title>
      <link>https://arxiv.org/abs/2403.01723</link>
      <description>arXiv:2403.01723v2 Announce Type: replace-cross 
Abstract: Recovering dynamical equations from observed noisy data is the central challenge of system identification. We develop a statistical mechanics approach to analyze sparse equation discovery algorithms, which typically balance data fit and parsimony via hyperparameter tuning. In this framework, statistical mechanics offers tools to analyze the interplay between complexity and fitness similarly to that of entropy and energy in physical systems. To establish this analogy, we define the hyperparameter optimization procedure as a two-level Bayesian inference problem that separates variable selection from coefficient inference and enables the computation of the posterior parameter distribution in closed form. Our approach provides uncertainty quantification, crucial in the low-data limit that is frequently encountered in real-world applications. A key advantage of employing statistical mechanical concepts, such as free energy and the partition function, is to connect the large data limit to thermodynamic limit and characterize the sparsity- and noise-induced phase transitions that delineate correct from incorrect identification. We thus provide a method for closed-loop inference, estimating the noise in a given model and checking if the model is tolerant to that noise amount. This perspective of sparse equation discovery is versatile and can be adapted to various other equation discovery algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.01723v2</guid>
      <category>cond-mat.stat-mech</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>physics.comp-ph</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrei A. Klishin, Joseph Bakarji, J. Nathan Kutz, Krithika Manohar</dc:creator>
    </item>
    <item>
      <title>Towards Stable Machine Learning Model Retraining via Slowly Varying Sequences</title>
      <link>https://arxiv.org/abs/2403.19871</link>
      <description>arXiv:2403.19871v5 Announce Type: replace-cross 
Abstract: We consider the problem of retraining machine learning (ML) models when new batches of data become available. Existing approaches greedily optimize for predictive power independently at each batch, without considering the stability of the model's structure or analytical insights across retraining iterations. We propose a model-agnostic framework for finding sequences of models that are stable across retraining iterations. We develop a mixed-integer optimization formulation that is guaranteed to recover Pareto optimal models (in terms of the predictive power-stability trade-off) with good generalization properties, as well as an efficient polynomial-time algorithm that performs well in practice. We focus on retaining consistent analytical insights-which is important to model interpretability, ease of implementation, and fostering trust with users-by using custom-defined distance metrics that can be directly incorporated into the optimization problem. We evaluate our framework across models (regression, decision trees, boosted trees, and neural networks) and application domains (healthcare, vision, and language), including deployment in a production pipeline at a major US hospital. We find that, on average, a 2% reduction in predictive power leads to a 30% improvement in stability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.19871v5</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Dimitris Bertsimas, Vassilis Digalakis Jr, Yu Ma, Phevos Paschalidis</dc:creator>
    </item>
    <item>
      <title>BiLO: Bilevel Local Operator Learning for PDE inverse problems</title>
      <link>https://arxiv.org/abs/2404.17789</link>
      <description>arXiv:2404.17789v4 Announce Type: replace-cross 
Abstract: We propose a new neural network based method for solving inverse problems for partial differential equations (PDEs) by formulating the PDE inverse problem as a bilevel optimization problem. At the upper level, we minimize the data loss with respect to the PDE parameters. At the lower level, we train a neural network to locally approximate the PDE solution operator in the neighborhood of a given set of PDE parameters, which enables an accurate approximation of the descent direction for the upper level optimization problem. The lower level loss function includes the L2 norms of both the residual and its derivative with respect to the PDE parameters. We apply gradient descent simultaneously on both the upper and lower level optimization problems, leading to an effective and fast algorithm. The method, which we refer to as BiLO (Bilevel Local Operator learning), is also able to efficiently infer unknown functions in the PDEs through the introduction of an auxiliary variable. Through extensive experiments over multiple PDE systems, we demonstrate that our method enforces strong PDE constraints, is robust to sparse and noisy data, and eliminates the need to balance the residual and the data loss, which is inherent to the soft PDE constraints in many existing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17789v4</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ray Zirui Zhang, Xiaohui Xie, John S. Lowengrub</dc:creator>
    </item>
    <item>
      <title>Error dynamics of mini-batch gradient descent with random reshuffling for least squares regression</title>
      <link>https://arxiv.org/abs/2406.03696</link>
      <description>arXiv:2406.03696v2 Announce Type: replace-cross 
Abstract: We study the discrete dynamics of mini-batch gradient descent with random reshuffling for least squares regression. We show that the training and generalization errors depend on a sample cross-covariance matrix $Z$ between the original features $X$ and a set of new features $\widetilde{X}$ in which each feature is modified by the mini-batches that appear before it during the learning process in an averaged way. Using this representation, we establish that the dynamics of mini-batch and full-batch gradient descent agree up to leading order with respect to the step size using the linear scaling rule. However, mini-batch gradient descent with random reshuffling exhibits a subtle dependence on the step size that a gradient flow analysis cannot detect, such as converging to a limit that depends on the step size. By comparing $Z$, a non-commutative polynomial of random matrices, with the sample covariance matrix of $X$ asymptotically, we demonstrate that batching affects the dynamics by resulting in a form of shrinkage on the spectrum.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.03696v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jackie Lok, Rishi Sonthalia, Elizaveta Rebrova</dc:creator>
    </item>
    <item>
      <title>Asymptotic and Finite Sample Analysis of Nonexpansive Stochastic Approximations with Markovian Noise</title>
      <link>https://arxiv.org/abs/2409.19546</link>
      <description>arXiv:2409.19546v4 Announce Type: replace-cross 
Abstract: Stochastic approximation is an important class of algorithms, and a large body of previous analysis focuses on stochastic approximations driven by contractive operators, which is not applicable in some important reinforcement learning settings. This work instead investigates stochastic approximations with merely nonexpansive operators. In particular, we study nonexpansive stochastic approximations with Markovian noise, providing both asymptotic and finite sample analysis. Key to our analysis are a few novel bounds of noise terms resulting from the Poisson equation. As an application, we prove, for the first time, that the classical tabular average reward temporal difference learning converges to a sample path dependent fixed point.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19546v4</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ethan Blaser, Shangtong Zhang</dc:creator>
    </item>
    <item>
      <title>Reinforcement Learning for a Discrete-Time Linear-Quadratic Control Problem with an Application</title>
      <link>https://arxiv.org/abs/2412.05906</link>
      <description>arXiv:2412.05906v2 Announce Type: replace-cross 
Abstract: We study the discrete-time linear-quadratic (LQ) control model using reinforcement learning (RL). Using entropy to measure the cost of exploration, we prove that the optimal feedback policy for the problem must be Gaussian type. Then, we apply the results of the discrete-time LQ model to solve the discrete-time mean-variance asset-liability management problem and prove our RL algorithm's policy improvement and convergence. Finally, a numerical example sheds light on the theoretical results established using simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05906v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lucky Li</dc:creator>
    </item>
    <item>
      <title>Edge of Stochastic Stability: Revisiting the Edge of Stability for SGD</title>
      <link>https://arxiv.org/abs/2412.20553</link>
      <description>arXiv:2412.20553v3 Announce Type: replace-cross 
Abstract: Recent findings by Cohen et al., 2021, demonstrate that when training neural networks with full-batch gradient descent with a step size of $\eta$, the largest eigenvalue $\lambda_{\max}$ of the full-batch Hessian consistently stabilizes at $\lambda_{\max} = 2/\eta$. These results have significant implications for convergence and generalization. This, however, is not the case of mini-batch stochastic gradient descent (SGD), limiting the broader applicability of its consequences. We show that SGD trains in a different regime we term Edge of Stochastic Stability (EoSS). In this regime, what stabilizes at $2/\eta$ is *Batch Sharpness*: the expected directional curvature of mini-batch Hessians along their corresponding stochastic gradients. As a consequence $\lambda_{\max}$--which is generally smaller than Batch Sharpness--is suppressed, aligning with the long-standing empirical observation that smaller batches and larger step sizes favor flatter minima. We further discuss implications for mathematical modeling of SGD trajectories.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.20553v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arseniy Andreyev, Pierfrancesco Beneventano</dc:creator>
    </item>
  </channel>
</rss>
