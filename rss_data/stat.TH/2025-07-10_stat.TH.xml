<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.TH updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.TH</link>
    <description>stat.TH updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.TH" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 11 Jul 2025 04:04:29 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>On the pointwise and sup-norm errors for local regression estimators</title>
      <link>https://arxiv.org/abs/2507.07132</link>
      <description>arXiv:2507.07132v1 Announce Type: new 
Abstract: In this paper, we analyze the behavior of various non-parametric local regression estimators, i.e. estimators that are based on local averaging, for estimating a Lipschitz regression function at a fixed point, or in sup-norm.
  We first prove some deviation bounds for local estimators that can be indexed by a VC class of sets in the covariates space. We then introduce the general concept of shape-regular local maps, corresponding to the situation where the local averaging is done on sets which, in some sense, have ``almost isotropic'' shapes. On the one hand, we prove that, in general, shape-regularity is necessary to achieve the minimax rates of convergence. On the other hand, we prove that it is sufficient to ensure the optimal rates, up to some logarithmic factors.
  Next, we prove some deviation bounds for specific estimators, that are based on data-dependent local maps, such as nearest neighbors, their recent prototype variants, as well as a new algorithm, which is a modified and generalized version of CART, and that is minimax rate optimal in sup-norm. In particular, the latter algorithm is based on a random tree construction that depends on both the covariates and the response data. For each of the estimators, we provide insights on the shape-regularity of their respective local maps. Finally, we conclude the paper by establishing some probability bounds for local estimators based on purely random trees, such as centered, uniform or Mondrian trees. Again, we discuss the relations between the rates of the estimators and the shape-regularity of their local maps.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.07132v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>J\'er\'emy Bettinger, Fran\c{c}ois Portier, Adrien Saumard</dc:creator>
    </item>
    <item>
      <title>Computational barriers for permutation-based problems, and cumulants of weakly dependent random variables</title>
      <link>https://arxiv.org/abs/2507.07946</link>
      <description>arXiv:2507.07946v1 Announce Type: new 
Abstract: In many high-dimensional problems,polynomial-time algorithms fall short of achieving the statistical limits attainable without computational constraints. A powerful approach to probe the limits of polynomial-time algorithms is to study the performance of low-degree polynomials. The seminal work of arXiv:2008.02269 connects low-degree lower bounds to multivariate cumulants. Prior works arXiv:2308.15728, arXiv:2506.13647 leverage independence among latent variables to bound cumulants. However, such approaches break down for problems with latent structure lacking independence, such as those involving random permutations. To address this important restriction, we develop a technique to upper-bound cumulants under weak dependencies, such as those arising from sampling without replacement or random permutations. To show-case the effectiveness of our approach, we uncover evidence of statistical-computational gaps in multiple feature matching and in seriation problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.07946v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bertrand Even, Christophe Giraud, Nicolas Verzelen</dc:creator>
    </item>
    <item>
      <title>Class conditional conformal prediction for multiple inputs by p-value aggregation</title>
      <link>https://arxiv.org/abs/2507.07150</link>
      <description>arXiv:2507.07150v1 Announce Type: cross 
Abstract: Conformal prediction methods are statistical tools designed to quantify uncertainty and generate predictive sets with guaranteed coverage probabilities. This work introduces an innovative refinement to these methods for classification tasks, specifically tailored for scenarios where multiple observations (multi-inputs) of a single instance are available at prediction time. Our approach is particularly motivated by applications in citizen science, where multiple images of the same plant or animal are captured by individuals. Our method integrates the information from each observation into conformal prediction, enabling a reduction in the size of the predicted label set while preserving the required class-conditional coverage guarantee. The approach is based on the aggregation of conformal p-values computed from each observation of a multi-input. By exploiting the exact distribution of these p-values, we propose a general aggregation framework using an abstract scoring function, encompassing many classical statistical tools. Knowledge of this distribution also enables refined versions of standard strategies, such as majority voting. We evaluate our method on simulated and real data, with a particular focus on Pl@ntNet, a prominent citizen science platform that facilitates the collection and identification of plant species through user-submitted images.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.07150v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jean-Baptiste Fermanian (IMAG, IROKO), Mohamed Hebiri (LAMA), Joseph Salmon (IMAG, IROKO)</dc:creator>
    </item>
    <item>
      <title>Way More Than the Sum of Their Parts: From Statistical to Structural Mixtures</title>
      <link>https://arxiv.org/abs/2507.07343</link>
      <description>arXiv:2507.07343v1 Announce Type: cross 
Abstract: We show that mixtures comprised of multicomponent systems typically are much more structurally complex than the sum of their parts; sometimes, infinitely more complex. We contrast this with the more familiar notion of statistical mixtures, demonstrating how statistical mixtures miss key aspects of emergent hierarchical organization. This leads us to identify a new kind of structural complexity inherent in multicomponent systems and to draw out broad consequences for system ergodicity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.07343v1</guid>
      <category>cond-mat.stat-mech</category>
      <category>cs.LG</category>
      <category>math.DS</category>
      <category>math.ST</category>
      <category>nlin.CD</category>
      <category>stat.TH</category>
      <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>James P. Crutchfield</dc:creator>
    </item>
    <item>
      <title>Manifolds with kinks and the asymptotic behavior of the graph Laplacian operator with Gaussian kernel</title>
      <link>https://arxiv.org/abs/2507.07751</link>
      <description>arXiv:2507.07751v1 Announce Type: cross 
Abstract: We introduce manifolds with kinks, a class of manifolds with possibly singular boundary that notably contains manifolds with smooth boundary and corners. We derive the asymptotic behavior of the Graph Laplace operator with Gaussian kernel and its deterministic limit on these spaces as bandwidth goes to zero. We show that this asymptotic behavior is determined by the inward sector of the tangent space and, as special cases, we derive its behavior near interior and singular points. Lastly, we show the validity of our theoretical results using numerical simulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.07751v1</guid>
      <category>math.DG</category>
      <category>math.SP</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Susovan Pal, David Tewodrose</dc:creator>
    </item>
    <item>
      <title>Spectral Estimators for Structured Generalized Linear Models via Approximate Message Passing</title>
      <link>https://arxiv.org/abs/2308.14507</link>
      <description>arXiv:2308.14507v4 Announce Type: replace 
Abstract: We consider the problem of parameter estimation in a high-dimensional generalized linear model. Spectral methods obtained via the principal eigenvector of a suitable data-dependent matrix provide a simple yet surprisingly effective solution. However, despite their wide use, a rigorous performance characterization, as well as a principled way to preprocess the data, are available only for unstructured (i.i.d.\ Gaussian and Haar orthogonal) designs. In contrast, real-world data matrices are highly structured and exhibit non-trivial correlations. To address the problem, we consider correlated Gaussian designs capturing the anisotropic nature of the features via a covariance matrix $\Sigma$. Our main result is a precise asymptotic characterization of the performance of spectral estimators. This allows us to identify the optimal preprocessing that minimizes the number of samples needed for parameter estimation. Surprisingly, such preprocessing is universal across a broad set of designs, which partly addresses a conjecture on optimal spectral estimators for rotationally invariant models. Our principled approach vastly improves upon previous heuristic methods, including for designs common in computational imaging and genetics. The proposed methodology, based on approximate message passing, is broadly applicable and opens the way to the precise characterization of spiked matrices and of the corresponding spectral methods in a variety of settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.14507v4</guid>
      <category>math.ST</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yihan Zhang, Hong Chang Ji, Ramji Venkataramanan, Marco Mondelli</dc:creator>
    </item>
    <item>
      <title>Posterior Concentration for Gaussian Process Priors under Rescaled and Hierarchical Mat\'ern and Confluent Hypergeometric Covariance Functions</title>
      <link>https://arxiv.org/abs/2312.07502</link>
      <description>arXiv:2312.07502v3 Announce Type: replace 
Abstract: In nonparameteric Bayesian approaches, Gaussian stochastic processes can serve as priors on real-valued function spaces. Existing literature on the posterior convergence rates under Gaussian process priors shows that it is possible to achieve optimal or near-optimal posterior contraction rates if the smoothness of the Gaussian process matches that of the target function. Among those priors, Gaussian processes with a parametric Mat\'ern covariance function is particularly notable in that its degree of smoothness can be determined by a dedicated smoothness parameter. \citet{ma2022beyond} recently introduced a new family of covariance functions called the Confluent Hypergeometric (CH) class that simultaneously possess two parameters: one controls the tail index of the polynomially decaying covariance function, and the other parameter controls the degree of mean-squared smoothness analogous to the Mat\'ern class. In this paper, we show that with proper choice of rescaling parameters in the Mat\'ern and CH covariance functions, it is possible to obtain the minimax optimal posterior contraction rate for $\eta$-regular functions for nonparametric regression model with fixed design. Unlike the previous results for unrescaled cases, the smoothness parameter of the covariance function need not equal $\eta$ for achieving the optimal minimax rate, for either rescaled Mat\'ern or rescaled CH covariances, illustrating a key benefit for rescaling. We also consider a fully Bayesian treatment of the rescaling parameters and show the resulting posterior distributions still contract at the minimax-optimal rate. The resultant hierarchical Bayesian procedure is fully adaptive to the unknown true smoothness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.07502v3</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiao Fang, Anindya Bhadra</dc:creator>
    </item>
    <item>
      <title>Estimation of Out-of-Sample Sharpe Ratio for High Dimensional Portfolio Optimization</title>
      <link>https://arxiv.org/abs/2406.03954</link>
      <description>arXiv:2406.03954v3 Announce Type: replace 
Abstract: Portfolio optimization aims at constructing a realistic portfolio with significant out-of-sample performance, which is typically measured by the out-of-sample Sharpe ratio. However, due to in-sample optimism, it is inappropriate to use the in-sample estimated covariance to evaluate the out-of-sample Sharpe, especially in the high dimensional settings. In this paper, we propose a novel method to estimate the out-of-sample Sharpe ratio using only in-sample data, based on random matrix theory. Furthermore, portfolio managers can use the estimated out-of-sample Sharpe as a criterion to decide the best tuning for constructing their portfolios. Specifically, we consider the classical framework of Markowits mean-variance portfolio optimization {under} high dimensional regime of $p/n \to c \in (0,\infty)$, where $p$ is the portfolio dimension and $n$ is the number of samples or time points. We propose to correct the sample covariance by a regularization matrix and provide a consistent estimator of its Sharpe ratio. The new estimator works well under either of the following conditions: (1) bounded covariance spectrum, (2) arbitrary number of diverging spikes when $c &lt; 1$, and (3) fixed number of diverging spikes with weak requirement on their diverging speed when $c \ge 1$. We can also extend the results to construct global minimum variance portfolio and correct out-of-sample efficient frontier. We demonstrate the effectiveness of our approach through comprehensive simulations and real data experiments. Our results highlight the potential of this methodology as a useful tool for portfolio optimization in high dimensional settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.03954v3</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Xuran Meng, Yuan Cao, Weichen Wang</dc:creator>
    </item>
    <item>
      <title>Assumption-Lean Honest Inference for $Z$-functionals</title>
      <link>https://arxiv.org/abs/2407.12278</link>
      <description>arXiv:2407.12278v3 Announce Type: replace 
Abstract: We develop a general assumption-lean framework for constructing uniformly valid confidence sets for functionals defined by moment equalities, referred to as $Z$-functionals. Our approach combines self-normalized statistics with a test inversion principle, enabling honest inference under mild regularity conditions and without explicit variance estimation. To enhance geometric tractability, we propose novel split-normalized and Gateaux-normalized statistics that yield computationally feasible and interpretable confidence sets. A central contribution of this work is a comprehensive non-asymptotic width analysis: we derive high-probability upper bounds on the diameter of the proposed confidence sets, and quantify their proximity to Wald intervals under minimal assumptions. Applications to high-dimensional non-sparse linear and generalized linear regression demonstrate that our procedures achieve valid coverage and near-optimal rate of convergence for the width/diameter, while the classical methods including Wald and bootstrap fail.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12278v3</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Woonyoung Chang, Arun Kumar Kuchibhotla</dc:creator>
    </item>
    <item>
      <title>Parameter Estimation for Partially Observed Affine and Polynomial Processes</title>
      <link>https://arxiv.org/abs/2503.05590</link>
      <description>arXiv:2503.05590v2 Announce Type: replace 
Abstract: This paper is devoted to parameter estimation for partially observed polynomial state space models. This class includes discretely observed affine or more generally polynomial Markov processes. The polynomial structure allows for the explicit computation of a Gaussian quasi-likelihood estimator and its asymptotic covariance matrix. We show consistency and asymptotic normality of the estimating sequence and provide explicitly computable expressions for the corresponding asymptotic covariance matrix.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.05590v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jan Kallsen, Ivo Richert</dc:creator>
    </item>
    <item>
      <title>New Three Different Generators for Constructing New Three Different Bivariate Copulas</title>
      <link>https://arxiv.org/abs/2504.11993</link>
      <description>arXiv:2504.11993v2 Announce Type: replace 
Abstract: In this paper, the author introduces new methods to construct Archimedean copulas. The generator of each copula fulfills the sufficient conditions as regards the boundary and being continuous, decreasing, and convex. Each inverse generator also fulfills the necessary conditions as regards the boundary conditions, marginal uniformity, and 2-increasing properties. Although these copulas satisfy these conditions, they have some limitations. They do not cover the entire dependency spectrum, ranging from perfect negative dependency to perfect positive dependency, passing through the independence state</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.11993v2</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Iman Mohamed Attia</dc:creator>
    </item>
    <item>
      <title>Gaussian approximation for non-linearity parameter estimation in perturbed random fields on the sphere</title>
      <link>https://arxiv.org/abs/2507.05074</link>
      <description>arXiv:2507.05074v2 Announce Type: replace 
Abstract: The nonlinear parameter measures the amplitude of primordial non-Gaussianity in the cosmic microwave background radiation (CMB), offering a crucial test of early universe models. While standard single field inflation predicts nearly Gaussian fluctuations, more complex scenarios yield subtle non Gaussian signals, particularly captured by the CMB bispectrum. In the local model, these signals arise through a quadratic correction to a Gaussian field. To estimate the nonlinear parameter, we adopt a Komatsu Spergel Wandelt (KSW) type estimator, based on spherical harmonics and Wigner 3j symbols, and adapted to narrow band configurations that depend on the range of multipoles considered. In this paper, we rigorously study its asymptotic properties by applying fourth-moment theorems from Wiener chaos theory. More in detail, we establish a quantitative central limit theorem for the KSW estimator, with an explicit convergence rate controlled by number of admissible multipoles. Our results establish both theoretical guarantees and practical robustness for high resolution CMB analyses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.05074v2</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Claudio Durastanti</dc:creator>
    </item>
    <item>
      <title>Scale Dilation Dynamics in Flexible Bandwidth Needlet Constructions</title>
      <link>https://arxiv.org/abs/2507.05075</link>
      <description>arXiv:2507.05075v2 Announce Type: replace 
Abstract: Flexible bandwidth needlets offer a versatile multiscale framework for analyzing functions on the sphere. A key element in their construction is the dilation sequence, which controls how the multipole consecutive scales are spaced and overlapped. At any resolution level, this sequence determines the center positions of the needlet weight functions and influences their localization in the spatial domain and spectral concentration properties by means of the relative bandwidth ratio. In this paper, we explore the different asymptotic regimes that arise when the dilation sequence exhibits shrinking, stable (standard), or spreading behavior. Moreover, we assume the dilation sequence grows regularly enough to ensure well-defined asymptotic properties. For each regime, we characterize the impact on the geometry of the center scales and the shape of the multipole windows, with particular attention to their overlap structure and spectral coverage. These insights help to clarify the trade-offs between localization, redundancy, and scalability in the design of needlet-type systems, particularly in relation to the study of the asymptotic uncorrelation of needlet coefficients when applied to random fields.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.05075v2</guid>
      <category>math.ST</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.TH</category>
      <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Claudio Durastanti</dc:creator>
    </item>
    <item>
      <title>Inference for Rank-Rank Regressions</title>
      <link>https://arxiv.org/abs/2310.15512</link>
      <description>arXiv:2310.15512v4 Announce Type: replace-cross 
Abstract: The slope coefficient in a rank-rank regression is a popular measure of intergenerational mobility. In this article, we first show that commonly used inference methods for this slope parameter are invalid. Second, when the underlying distribution is not continuous, the OLS estimator and its asymptotic distribution may be highly sensitive to how ties in the ranks are handled. Motivated by these findings we develop a new asymptotic theory for the OLS estimator in a general class of rank-rank regression specifications without imposing any assumptions about the continuity of the underlying distribution. We then extend the asymptotic theory to other regressions involving ranks that have been used in empirical work. Finally, we apply our new inference methods to two empirical studies on intergenerational mobility, highlighting the practical implications of our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.15512v4</guid>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Denis Chetverikov, Daniel Wilhelm</dc:creator>
    </item>
    <item>
      <title>Finite Sample Analysis of Distribution-Free Confidence Ellipsoids for Linear Regression</title>
      <link>https://arxiv.org/abs/2409.08801</link>
      <description>arXiv:2409.08801v2 Announce Type: replace-cross 
Abstract: The least squares (LS) estimate is the archetypical solution of linear regression problems. The asymptotic Gaussianity of the scaled LS error is often used to construct approximate confidence ellipsoids around the LS estimate, however, for finite samples these ellipsoids do not come with strict guarantees, unless some strong assumptions are made on the noise distributions. The paper studies the distribution-free Sign-Perturbed Sums (SPS) ellipsoidal outer approximation (EOA) algorithm which can construct non-asymptotically guaranteed confidence ellipsoids under mild assumptions, such as independent and symmetric noise terms. These ellipsoids have the same center and orientation as the classical asymptotic ellipsoids, only their radii are different, which radii can be computed by convex optimization. Here, we establish high probability non-asymptotic upper bounds for the sizes of SPS outer ellipsoids for linear regression problems and show that the volumes of these ellipsoids decrease at the optimal rate. Finally, the difference between our theoretical bounds and the empirical sizes of the regions are investigated experimentally.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08801v2</guid>
      <category>eess.SP</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Szabolcs Szentp\'eteri, Bal\'azs Csan\'ad Cs\'aji</dc:creator>
    </item>
    <item>
      <title>Proofs for Folklore Theorems on the Radon-Nikodym Derivative</title>
      <link>https://arxiv.org/abs/2501.18374</link>
      <description>arXiv:2501.18374v3 Announce Type: replace-cross 
Abstract: In this technical report, rigorous statements and formal proofs are presented for both foundational and advanced folklore theorems on the Radon-Nikodym derivative. The cases of conditional and marginal probability measures are carefully considered, which leads to an identity involving the sum of mutual and lautum information suggesting a new interpretation for such a sum.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18374v3</guid>
      <category>cs.IT</category>
      <category>math.HO</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yaiza Bermudez, Gaetan Bisson, I\~naki Esnaola, Samir M. Perlaza</dc:creator>
    </item>
    <item>
      <title>Parametric Scaling Law of Tuning Bias in Conformal Prediction</title>
      <link>https://arxiv.org/abs/2502.03023</link>
      <description>arXiv:2502.03023v2 Announce Type: replace-cross 
Abstract: Conformal prediction is a popular framework of uncertainty quantification that constructs prediction sets with coverage guarantees. To uphold the exchangeability assumption, many conformal prediction methods necessitate an additional holdout set for parameter tuning. Yet, the impact of violating this principle on coverage remains underexplored, making it ambiguous in practical applications. In this work, we empirically find that the tuning bias - the coverage gap introduced by leveraging the same dataset for tuning and calibration, is negligible for simple parameter tuning in many conformal prediction methods. In particular, we observe the scaling law of the tuning bias: this bias increases with parameter space complexity and decreases with calibration set size. Formally, we establish a theoretical framework to quantify the tuning bias and provide rigorous proof for the scaling law of the tuning bias by deriving its upper bound. In the end, we discuss how to reduce the tuning bias, guided by the theories we developed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03023v2</guid>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hao Zeng, Kangdao Liu, Bingyi Jing, Hongxin Wei</dc:creator>
    </item>
    <item>
      <title>It's Hard to Be Normal: The Impact of Noise on Structure-agnostic Estimation</title>
      <link>https://arxiv.org/abs/2507.02275</link>
      <description>arXiv:2507.02275v2 Announce Type: replace-cross 
Abstract: Structure-agnostic causal inference studies how well one can estimate a treatment effect given black-box machine learning estimates of nuisance functions (like the impact of confounders on treatment and outcomes). Here, we find that the answer depends in a surprising way on the distribution of the treatment noise. Focusing on the partially linear model of \citet{robinson1988root}, we first show that the widely adopted double machine learning (DML) estimator is minimax rate-optimal for Gaussian treatment noise, resolving an open problem of \citet{mackey2018orthogonal}. Meanwhile, for independent non-Gaussian treatment noise, we show that DML is always suboptimal by constructing new practical procedures with higher-order robustness to nuisance errors. These \emph{ACE} procedures use structure-agnostic cumulant estimators to achieve $r$-th order insensitivity to nuisance errors whenever the $(r+1)$-st treatment cumulant is non-zero. We complement these core results with novel minimax guarantees for binary treatments in the partially linear model. Finally, using synthetic demand estimation experiments, we demonstrate the practical benefits of our higher-order robust estimators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.02275v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jikai Jin, Lester Mackey, Vasilis Syrgkanis</dc:creator>
    </item>
    <item>
      <title>On the rate of convergence to the Boolean extreme value distribution under the von Mises condition</title>
      <link>https://arxiv.org/abs/2507.06580</link>
      <description>arXiv:2507.06580v2 Announce Type: replace-cross 
Abstract: We investigate the rate of convergence toward the Boolean extreme value distribution which is the universal limiting law for the normalized spectral maximum of Boolean independent positive operators, under the von Mises condition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.06580v2</guid>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuki Ueda</dc:creator>
    </item>
  </channel>
</rss>
