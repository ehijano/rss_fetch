<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CR updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CR</link>
    <description>cs.CR updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CR" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 25 Mar 2025 03:02:35 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>SoK: Trusted Execution in SoC-FPGAs</title>
      <link>https://arxiv.org/abs/2503.16612</link>
      <description>arXiv:2503.16612v1 Announce Type: new 
Abstract: Trusted Execution Environments (TEEs) have emerged at the forefront of edge computing to combat the lack of trust between system components. Field Programmable Gate Arrays (FPGAs) are commonly used as edge computers but were not created with security as a primary consideration. Thus, FPGA-based edge computers are increasingly the target of cyberattacks. We analyze the existing literature to systematize the applications and features of FPGA-based TEEs. We identified 27 primary studies related to different types of System-on-Chip FPGA-based TEEs. Across a wide range of applications and features, the availability of extensible solutions is limited. Most solutions focus on specific features and applications, whereas few solutions focus on feature-rich, comprehensive TEEs that can be utilized across computer systems. Whether TEEs are specific or extensible, the paucity of published studies provides evidence of research gaps. This SoK delineates these gaps revealing opportunities for researchers and developers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16612v1</guid>
      <category>cs.CR</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Garrett Perkins, Benjamin Macht, Lucas Ritzdorf, Tristan Running Crane, Brock LaMeres, Clemente Izurieta, Ann Marie Reinhold</dc:creator>
    </item>
    <item>
      <title>Visualizing Privacy-Relevant Data Flows in Android Applications</title>
      <link>https://arxiv.org/abs/2503.16640</link>
      <description>arXiv:2503.16640v1 Announce Type: new 
Abstract: Android applications collecting data from users must protect it according to the current legal frameworks. Such data protection has become even more important since in 2018 the European Union rolled out the General Data Protection Regulation (GDPR). Since app developers are not legal experts, they find it difficult to integrate privacy-aware practices into source code development. Despite these legal obligations, developers have limited tool support to reason about data protection throughout their app development process.
  This paper explores the use of static program slicing and software visualization to analyze privacy-relevant data flows in Android apps. We introduce SliceViz, a web tool that analyzes an Android app by slicing all privacy-relevant data sources detected in the source code on the back-end. It then helps developers by visualizing these privacy-relevant program slices.
  We conducted a user study with 12 participants demonstrating that SliceViz effectively aids developers in identifying privacy-relevant properties in Android apps.
  Our findings indicate that program slicing can be employed to identify and reason about privacy-relevant data flows in Android applications. With further usability improvements, developers can be better equipped to handle privacy-sensitive information.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16640v1</guid>
      <category>cs.CR</category>
      <category>cs.SE</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mugdha Khedkar, Michael Schlichtig, Santhosh Mohan, Eric Bodden</dc:creator>
    </item>
    <item>
      <title>Practical Acoustic Eavesdropping On Typed Passphrases</title>
      <link>https://arxiv.org/abs/2503.16719</link>
      <description>arXiv:2503.16719v1 Announce Type: new 
Abstract: Cloud services have become an essential infrastructure for enterprises and individuals. Access to these cloud services is typically governed by Identity and Access Management systems, where user authentication often relies on passwords. While best practices dictate the implementation of multi-factor authentication, it's a reality that many such users remain solely protected by passwords. This reliance on passwords creates a significant vulnerability, as these credentials can be compromised through various means, including side-channel attacks. This paper exploits keyboard acoustic emanations to infer typed natural language passphrases via unsupervised learning, necessitating no previous training data. Whilst this work focuses on short passphrases, it is also applicable to longer messages, such as confidential emails, where the margin for error is much greater, than with passphrases, making the attack even more effective in such a setting. Unlike traditional attacks that require physical access to the target device, acoustic side-channel attacks can be executed within the vicinity, without the user's knowledge, offering a worthwhile avenue for malicious actors. Our findings replicate and extend previous work, confirming that cross-correlation audio preprocessing outperforms methods like mel-frequency-cepstral coefficients and fast-fourier transforms in keystroke clustering. Moreover, we show that partial passphrase recovery through clustering and a dictionary attack can enable faster than brute-force attacks, further emphasizing the risks posed by this attack vector.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16719v1</guid>
      <category>cs.CR</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Darren F\"urst, Andreas A{\ss}muth</dc:creator>
    </item>
    <item>
      <title>CoBRA: A Universal Strategyproof Confirmation Protocol for Quorum-based Proof-of-Stake Blockchains</title>
      <link>https://arxiv.org/abs/2503.16783</link>
      <description>arXiv:2503.16783v1 Announce Type: new 
Abstract: We present a formal analysis of quorum-based State Machine Replication (SMR) protocols in Proof-of-Stake (PoS) systems under a hybrid threat model comprising honest, Byzantine, and rational validators. Our analysis of traditional quorum-based protocols establishes two fundamental impossibility results: (1) in partially synchronous networks, no quorum-based protocol can achieve SMR when rational and Byzantine validators comprise more than $1/3$ of participants, and (2) in synchronous networks, SMR remains impossible when rational and Byzantine validators comprise $2/3$ or more of participants.
  To overcome these limitations, we propose two complementary solutions in our hybrid model. First, we introduce a protocol that enforces a bound on the volume of the total transacted amount that is finalized within any time window $\Delta$ and prove that this bound is necessary for secure SMR protocols in our model. Second, we present the \emph{strongest chain rule}, which enables efficient finalization of transactions when the majority of honest participants provably support the SMR execution. Through empirical analysis of Ethereum and Cosmos networks, we demonstrate that validator participation consistently exceeds the required ${5}/{6}$ threshold, establishing the practical feasibility of our solution in production PoS systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16783v1</guid>
      <category>cs.CR</category>
      <category>cs.DC</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zeta Avarikioti, Eleftherios Kokoris Kogias, Ray Neiheiser, Christos Stefo</dc:creator>
    </item>
    <item>
      <title>Efficient and Expressive Public Key Authenticated Encryption with Keyword Search in Multi-user Scenarios</title>
      <link>https://arxiv.org/abs/2503.16828</link>
      <description>arXiv:2503.16828v1 Announce Type: new 
Abstract: Public key authenticated encryption with keyword search (PAEKS) represents a significant advancement of secure and searchable data sharing in public network systems, such as medical systems. It can effectively mitigate the risk of keyword guessing attacks (KGA), which is a critical issue in public key encryption with keyword search (PEKS). However, in scenarios with a large number of users, the enforced point-to-point access control necessitates that the data sender encrypt the same keyword using the public keys of multiple receivers to create indexes, while the data receiver also must generate trapdoors of size linear to senders in the system. The burden on users aiming for efficient data sharing is considerable, as the overheads increase linearly with the number of users. Furthermore, the majority of current PAEKS schemes lack expressive search functions, including conjunctions, disjunctions, or any monotone boolean formulas, which are prevalent in practical applications. To tackle the abovementioned challenges, we propose an efficient and expressive PAEKS scheme. In efficiency, one auxiliary server is integrated to assist users in generating indexes and trapdoors. Users encrypt with their respective private keys along with the public keys of the servers, facilitating secure and searchable data sharing while significantly minimizing overhead. Additionally, the LSSS is employed to implement expressive search, including monotone boolean queries. We also obfuscate the mapping relationship associated with the LSSS matrix to the keywords, thereby enhancing the privacy protection. Security analysis alongside theoretical and experimental evaluations of our scheme illustrates its practicality and efficiency in multi-user data sharing scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16828v1</guid>
      <category>cs.CR</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiayin Cai, Xingwen Zhao, Dexin Li, Hui Li, Kai Fan</dc:creator>
    </item>
    <item>
      <title>Early-MFC: Enhanced Flow Correlation Attacks on Tor via Multi-view Triplet Networks with Early Network Traffic</title>
      <link>https://arxiv.org/abs/2503.16847</link>
      <description>arXiv:2503.16847v1 Announce Type: new 
Abstract: Flow correlation attacks is an efficient network attacks, aiming to expose those who use anonymous network services, such as Tor. Conducting such attacks during the early stages of network communication is particularly critical for scenarios demanding rapid decision-making, such as cybercrime detection or financial fraud prevention. Although recent studies have made progress in flow correlation attacks techniques, research specifically addressing flow correlation with early network traffic flow remains limited. Moreover, due to factors such as model complexity, training costs, and real-time requirements, existing technologies cannot be directly applied to flow correlation with early network traffic flow. In this paper, we propose flow correlation attack with early network traffic, named Early-MFC, based on multi-view triplet networks. The proposed approach extracts multi-view traffic features from the payload at the transport layer and the Inter-Packet Delay. It then integrates multi-view flow information, converting the extracted features into shared embeddings. By leveraging techniques such as metric learning and contrastive learning, the method optimizes the embeddings space by ensuring that similar flows are mapped closer together while dissimilar flows are positioned farther apart. Finally, Bayesian decision theory is applied to determine flow correlation, enabling high-accuracy flow correlation with early network traffic flow. Furthermore, we investigate flow correlation attacks under extra-early network traffic flow conditions. To address this challenge, we propose Early-MFC+, which utilizes payload data to construct embedded feature representations, ensuring robust performance even with minimal packet availability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16847v1</guid>
      <category>cs.CR</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yali Yuan, Qianqi Niu, Yachao Yuan</dc:creator>
    </item>
    <item>
      <title>Towards LLM Guardrails via Sparse Representation Steering</title>
      <link>https://arxiv.org/abs/2503.16851</link>
      <description>arXiv:2503.16851v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have demonstrated remarkable performance in natural language generation tasks, yet their uncontrolled outputs pose significant ethical and safety risks. Recently, representation engineering methods have shown promising results in steering model behavior by modifying the rich semantic information encoded in activation vectors. However, due to the difficulty of precisely disentangling semantic directions within high-dimensional representation space, existing approaches suffer from three major limitations: lack of fine-grained control, quality degradation of generated content, and poor interpretability. To address these challenges, we propose a sparse encoding-based representation engineering method, named SRE, which decomposes polysemantic activations into a structured, monosemantic feature space. By leveraging sparse autoencoding, our approach isolates and adjusts only task-specific sparse feature dimensions, enabling precise and interpretable steering of model behavior while preserving content quality. We validate our method on three critical domains, i.e., safety, fairness, and truthfulness using the open-source LLM Gemma-2-2B-it. Experimental results show that SRE achieves superior controllability while maintaining the overall quality of generated content (i.e., controllability and quality), demonstrating its effectiveness as a fine-grained and interpretable activation steering framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16851v1</guid>
      <category>cs.CR</category>
      <category>cs.CL</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zeqing He, Zhibo Wang, Huiyu Xu, Kui Ren</dc:creator>
    </item>
    <item>
      <title>CleanStack: A New Dual-Stack for Defending Against Stack-Based Memory Corruption Attacks</title>
      <link>https://arxiv.org/abs/2503.16950</link>
      <description>arXiv:2503.16950v1 Announce Type: new 
Abstract: Stack-based memory corruption vulnerabilities have
  long been exploited by attackers to execute arbitrary code
  or perform unauthorized memory operations. Various defense
  mechanisms have been introduced to mitigate stack memory
  errors, but they typically focus on specific attack types, incur
  substantial performance overhead, or suffer from compatibility
  limitations.In this paper, we present CleanStack, an efficient,
  highly compatible, and comprehensive stack protection mech anism. CleanStack isolates stack objects influenced by external
  input from other safe stack objects, thereby preventing attackers
  from modifying return addresses via controlled stack objects.
  Additionally, by randomizing the placement of tainted stack
  objects within the Unclean Stack, CleanStack mitigates non control data attacks by preventing attackers from predicting the
  stack layout.A key component of CleanStack is the identifica tion of tainted stack objects. We analyze both static program
  analysis and heuristic methods for this purpose. To maximize
  compatibility, we adopt a heuristic approach and implement
  CleanStack within the LLVM compiler framework, applying it to
  SPEC CPU2017 benchmarks and a real-world application.Our
  security evaluation demonstrates that CleanStack significantly
  reduces the exploitability of stack-based memory errors by
  providing a dual-stack system with isolation and randomization.
  Performance evaluation results indicate that CleanStack incurs
  an execution overhead of only 1.73% on the SPEC CPU2017
  benchmark while introducing a minimal memory overhead of
  just 0.04%. Compared to existing stack protection techniques,
  CleanStack achieves an optimal balance between protection
  coverage, runtime overhead, and compatibility, making it one
  of the most comprehensive and efficient stack security solutions
  to date.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16950v1</guid>
      <category>cs.CR</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lei Chong</dc:creator>
    </item>
    <item>
      <title>EVSOAR: Security Orchestration, Automation and Response via EV Charging Stations</title>
      <link>https://arxiv.org/abs/2503.16984</link>
      <description>arXiv:2503.16984v1 Announce Type: new 
Abstract: Vehicle cybersecurity has emerged as a critical concern, driven by the innovation in the automotive industry, e.g., automomous, electric, or connnected vehicles. Current efforts to address these challenges are constrained by the limited computational resources of vehicles and the reliance on connected infrastructures. This motivated the foundation of Vehicle Security Operations Centers (VSOCs) that extend IT-based Security Operations Centers (SOCs) to cover the entire automotive ecosystem, both the in-vehicle and off-vehicle scopes. Security Orchestration, Automation, and Response (SOAR) tools are considered key for impelementing an effective cybersecurity solution. However, existing state-of-the-art solutions depend on infrastructure networks such as 4G, 5G, and WiFi, which often face scalability and congestion issues. To address these limitations, we propose a novel SOAR architecture EVSOAR that leverages the EV charging stations for connectivity and computing to enhance vehicle cybersecurity. Our EV-specific SOAR architecture enables real-time analysis and automated responses to cybersecurity threats closer to the EV, reducing the cellular latency, bandwidth, and interference limitations. Our experimental results demonstrate a significant improvement in latency, stability, and scalability through the infrastructure and the capacity to deploy computationally intensive applications, that are otherwise infeasible within the resource constraints of individual vehicles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16984v1</guid>
      <category>cs.CR</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Tadeu Freitas, Erick Silva, Rehana Yasmin, Ali Shoker, Manuel E. Correia, Rolando Martins, Paulo Esteves-Verissimo</dc:creator>
    </item>
    <item>
      <title>Privacy Enhanced QKD Networks: Zero Trust Relay Architecture based on Homomorphic Encryption</title>
      <link>https://arxiv.org/abs/2503.17011</link>
      <description>arXiv:2503.17011v1 Announce Type: new 
Abstract: Quantum key distribution (QKD) enables unconditionally secure symmetric key exchange between parties. However, terrestrial fibre-optic links face inherent distance constraints due to quantum signal degradation. Traditional solutions to overcome these limits rely on trusted relay nodes, which perform intermediate re-encryption of keys using one-time pad (OTP) encryption. This approach, however, exposes keys as plaintext at each relay, requiring significant trust and stringent security controls at every intermediate node. These "trusted" relays become a security liability if compromised.
  To address this issue, we propose a zero-trust relay design that applies fully homomorphic encryption (FHE) to perform intermediate OTP re-encryption without exposing plaintext keys, effectively mitigating the risks associated with potentially compromised or malicious relay nodes. Additionally, the architecture enhances crypto-agility by incorporating external quantum random number generators, thus decoupling key generation from specific QKD hardware and reducing vulnerabilities tied to embedded key-generation modules.
  The solution is designed with the existing European Telecommunication Standards Institute (ETSI) QKD standards in mind, enabling straightforward integration into current infrastructures. Its feasibility has been successfully demonstrated through a hybrid network setup combining simulated and commercially available QKD equipment. The proposed zero-trust architecture thus significantly advances the scalability and practical security of large-scale QKD networks, greatly reducing reliance on fully trusted infrastructure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.17011v1</guid>
      <category>cs.CR</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Aitor Brazaola-Vicario, Oscar Lage, Julen Bernab\'e-Rodr\'iguez, Eduardo Jacob, Jasone Astorga</dc:creator>
    </item>
    <item>
      <title>ATHENA: An In-vehicle CAN Intrusion Detection Framework Based on Physical Characteristics of Vehicle Systems</title>
      <link>https://arxiv.org/abs/2503.17067</link>
      <description>arXiv:2503.17067v1 Announce Type: new 
Abstract: With the growing interconnection between In-Vehicle Networks (IVNs) and external environments, intelligent vehicles are increasingly vulnerable to sophisticated external network attacks. This paper proposes ATHENA, the first IVN intrusion detection framework that adopts a vehicle-cloud integrated architecture to achieve better security performance for the resource-constrained vehicular environment. Specifically, in the cloud with sufficient resources, ATHENA uses the clustering method of multi-distribution mixture model combined with deep data mining technology to generate the raw Payload Rule Bank of IVN CAN messages, and then improves the rule quality with the help of exploitation on the first-principled physical knowledge of the vehicle system, after which the payload rules are periodically sent to the vehicle terminal. At the vehicle terminal, a simple LSTM component is used to generate the Time Rule Bank representing the long-term time series dependencies and the periodic characteristics of CAN messages, but not for any detection tasks as in traditional usage scenarios, where only the generated time rules are the candidates for further IVN intrusion detection tasks. Based on both the payload and time rules generated from cloud and vehicle terminal, ATHENA can achieve efficient intrusion detection capability by simple rule-base matching operations, rather than using complex black-box reasoning of resource-intensive neural network models, which is in fact only used for rule logic generation phase instead of the actual intrusion detection phase in our framework. Comparative experimental results on the ROAD dataset, which is current the most outstanding real-world in-vehicle CAN dataset covering new instances of sophisticated and stealthy masquerade attacks, demonstrate ATHENA significantly outperforms the state-of-the-art IVN intrusion detection methods in detecting complex attacks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.17067v1</guid>
      <category>cs.CR</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kai Wang, Zhen Sun, Bailing Wang, Qilin Fan, Ming Li, Hongke Zhang</dc:creator>
    </item>
    <item>
      <title>Semigroup-homomorphic Signature</title>
      <link>https://arxiv.org/abs/2503.17137</link>
      <description>arXiv:2503.17137v1 Announce Type: new 
Abstract: In 2002, Johnson et al. posed an open problem at the Cryptographers' Track of the RSA Conference: how to construct a secure homomorphic signature on a semigroup, rather than on a group. In this paper, we introduce, for the first time, a semigroup-homomorphic signature scheme. Under certain conditions, we prove that the security of this scheme is based on the hardness of the Short Integer Solution (SIS) problem and is tightly secure. Furthermore, we extend it to a linear semigroup-homomorphic signature scheme over lattices, and this scheme can also ensure privacy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.17137v1</guid>
      <category>cs.CR</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Heng Guo, Kun Tian, Fengxia Liu, Zhiyong Zheng</dc:creator>
    </item>
    <item>
      <title>Jailbreaking the Non-Transferable Barrier via Test-Time Data Disguising</title>
      <link>https://arxiv.org/abs/2503.17198</link>
      <description>arXiv:2503.17198v1 Announce Type: new 
Abstract: Non-transferable learning (NTL) has been proposed to protect model intellectual property (IP) by creating a "non-transferable barrier" to restrict generalization from authorized to unauthorized domains. Recently, well-designed attack, which restores the unauthorized-domain performance by fine-tuning NTL models on few authorized samples, highlights the security risks of NTL-based applications. However, such attack requires modifying model weights, thus being invalid in the black-box scenario. This raises a critical question: can we trust the security of NTL models deployed as black-box systems? In this work, we reveal the first loophole of black-box NTL models by proposing a novel attack method (dubbed as JailNTL) to jailbreak the non-transferable barrier through test-time data disguising. The main idea of JailNTL is to disguise unauthorized data so it can be identified as authorized by the NTL model, thereby bypassing the non-transferable barrier without modifying the NTL model weights. Specifically, JailNTL encourages unauthorized-domain disguising in two levels, including: (i) data-intrinsic disguising (DID) for eliminating domain discrepancy and preserving class-related content at the input-level, and (ii) model-guided disguising (MGD) for mitigating output-level statistics difference of the NTL model. Empirically, when attacking state-of-the-art (SOTA) NTL models in the black-box scenario, JailNTL achieves an accuracy increase of up to 55.7% in the unauthorized domain by using only 1% authorized samples, largely exceeding existing SOTA white-box attacks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.17198v1</guid>
      <category>cs.CR</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yongli Xiang, Ziming Hong, Lina Yao, Dadong Wang, Tongliang Liu</dc:creator>
    </item>
    <item>
      <title>Cyber Campaign Fractals -- Geometric Analysis of Hierarchical Cyber Attack Taxonomies</title>
      <link>https://arxiv.org/abs/2503.17219</link>
      <description>arXiv:2503.17219v1 Announce Type: new 
Abstract: This paper introduces a novel mathematical framework for analyzing cyber threat campaigns through fractal geometry. By conceptualizing hierarchical taxonomies (MITRE ATT&amp;CK, DISARM) as snowflake-like structures with tactics, techniques, and sub-techniques forming concentric layers, we establish a rigorous method for campaign comparison using Hutchinson's Theorem and Hausdorff distance metrics. Evaluation results confirm that our fractal representation preserves hierarchical integrity while providing a dimensionality-based complexity assessment that correlates with campaign complexity. The proposed methodology bridges taxonomy-driven cyber threat analysis and computational geometry, providing analysts with both mathematical rigor and interpretable visualizations for addressing the growing complexity of adversarial operations across multiple threat domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.17219v1</guid>
      <category>cs.CR</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ronan Mouchoux, Fran\c{c}ois Moerman</dc:creator>
    </item>
    <item>
      <title>UAV Resilience Against Stealthy Attacks</title>
      <link>https://arxiv.org/abs/2503.17298</link>
      <description>arXiv:2503.17298v1 Announce Type: new 
Abstract: Unmanned aerial vehicles (UAVs) depend on untrusted software components to automate dangerous or critical missions, making them a desirable target for attacks. Some work has been done to prevent an attacker who has either compromised a ground control station or parts of a UAV's software from sabotaging the vehicle, but not both. We present an architecture running a UAV software stack with runtime monitoring and seL4-based software isolation that prevents attackers from both exploiting software bugs and utilizing stealthy attacks. Our architecture retrofits legacy UAVs and secures the popular MAVLink protocol, making wide adoption possible.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.17298v1</guid>
      <category>cs.CR</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arthur Amorim, Max Taylor, Trevor Kann, Gary T. Leavens, William L. Harrison, Lance Joneckis</dc:creator>
    </item>
    <item>
      <title>Bugdar: AI-Augmented Secure Code Review for GitHub Pull Requests</title>
      <link>https://arxiv.org/abs/2503.17302</link>
      <description>arXiv:2503.17302v1 Announce Type: new 
Abstract: As software systems grow increasingly complex, ensuring security during development poses significant challenges. Traditional manual code audits are often expensive, time-intensive, and ill-suited for fast-paced workflows, while automated tools frequently suffer from high false-positive rates, limiting their reliability. To address these issues, we introduce Bugdar, an AI-augmented code review system that integrates seamlessly into GitHub pull requests, providing near real-time, context-aware vulnerability analysis. Bugdar leverages fine-tunable Large Language Models (LLMs) and Retrieval Augmented Generation (RAGs) to deliver project-specific, actionable feedback that aligns with each codebase's unique requirements and developer practices. Supporting multiple programming languages, including Solidity, Move, Rust, and Python, Bugdar demonstrates exceptional efficiency, processing an average of 56.4 seconds per pull request or 30 lines of code per second. This is significantly faster than manual reviews, which could take hours per pull request. By facilitating a proactive approach to secure coding, Bugdar reduces the reliance on manual reviews, accelerates development cycles, and enhances the security posture of software systems without compromising productivity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.17302v1</guid>
      <category>cs.CR</category>
      <category>cs.HC</category>
      <category>cs.SE</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>John Naulty, Eason Chen, Joy Wang, George Digkas, Kostas Chalkias</dc:creator>
    </item>
    <item>
      <title>CVE-Bench: A Benchmark for AI Agents' Ability to Exploit Real-World Web Application Vulnerabilities</title>
      <link>https://arxiv.org/abs/2503.17332</link>
      <description>arXiv:2503.17332v1 Announce Type: new 
Abstract: Large language model (LLM) agents are increasingly capable of autonomously conducting cyberattacks, posing significant threats to existing applications. This growing risk highlights the urgent need for a real-world benchmark to evaluate the ability of LLM agents to exploit web application vulnerabilities. However, existing benchmarks fall short as they are limited to abstracted Capture the Flag competitions or lack comprehensive coverage. Building a benchmark for real-world vulnerabilities involves both specialized expertise to reproduce exploits and a systematic approach to evaluating unpredictable threats. To address this challenge, we introduce CVE-Bench, a real-world cybersecurity benchmark based on critical-severity Common Vulnerabilities and Exposures. In CVE-Bench, we design a sandbox framework that enables LLM agents to exploit vulnerable web applications in scenarios that mimic real-world conditions, while also providing effective evaluation of their exploits. Our evaluation shows that the state-of-the-art agent framework can resolve up to 13% of vulnerabilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.17332v1</guid>
      <category>cs.CR</category>
      <category>cs.AI</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuxuan Zhu, Antony Kellermann, Dylan Bowman, Philip Li, Akul Gupta, Adarsh Danda, Richard Fang, Conner Jensen, Eric Ihli, Jason Benn, Jet Geronimo, Avi Dhir, Sudhit Rao, Kaicheng Yu, Twm Stone, Daniel Kang</dc:creator>
    </item>
    <item>
      <title>OpenAI's Approach to External Red Teaming for AI Models and Systems</title>
      <link>https://arxiv.org/abs/2503.16431</link>
      <description>arXiv:2503.16431v1 Announce Type: cross 
Abstract: Red teaming has emerged as a critical practice in assessing the possible risks of AI models and systems. It aids in the discovery of novel risks, stress testing possible gaps in existing mitigations, enriching existing quantitative safety metrics, facilitating the creation of new safety measurements, and enhancing public trust and the legitimacy of AI risk assessments. This white paper describes OpenAI's work to date in external red teaming and draws some more general conclusions from this work. We describe the design considerations underpinning external red teaming, which include: selecting composition of red team, deciding on access levels, and providing guidance required to conduct red teaming. Additionally, we show outcomes red teaming can enable such as input into risk assessment and automated evaluations. We also describe the limitations of external red teaming, and how it can fit into a broader range of AI model and system evaluations. Through these contributions, we hope that AI developers and deployers, evaluation creators, and policymakers will be able to better design red teaming campaigns and get a deeper look into how external red teaming can fit into model deployment and evaluation processes. These methods are evolving and the value of different methods continues to shift as the ecosystem around red teaming matures and models themselves improve as tools for red teaming.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16431v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.CR</category>
      <category>cs.HC</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lama Ahmad, Sandhini Agarwal, Michael Lampe, Pamela Mishkin</dc:creator>
    </item>
    <item>
      <title>Big Help or Big Brother? Auditing Tracking, Profiling, and Personalization in Generative AI Assistants</title>
      <link>https://arxiv.org/abs/2503.16586</link>
      <description>arXiv:2503.16586v1 Announce Type: cross 
Abstract: Generative AI (GenAI) browser assistants integrate powerful capabilities of GenAI in web browsers to provide rich experiences such as question answering, content summarization, and agentic navigation. These assistants, available today as browser extensions, can not only track detailed browsing activity such as search and click data, but can also autonomously perform tasks such as filling forms, raising significant privacy concerns. It is crucial to understand the design and operation of GenAI browser extensions, including how they collect, store, process, and share user data. To this end, we study their ability to profile users and personalize their responses based on explicit or inferred demographic attributes and interests of users. We perform network traffic analysis and use a novel prompting framework to audit tracking, profiling, and personalization by the ten most popular GenAI browser assistant extensions. We find that instead of relying on local in-browser models, these assistants largely depend on server-side APIs, which can be auto-invoked without explicit user interaction. When invoked, they collect and share webpage content, often the full HTML DOM and sometimes even the user's form inputs, with their first-party servers. Some assistants also share identifiers and user prompts with third-party trackers such as Google Analytics. The collection and sharing continues even if a webpage contains sensitive information such as health or personal information such as name or SSN entered in a web form. We find that several GenAI browser assistants infer demographic attributes such as age, gender, income, and interests and use this profile--which carries across browsing contexts--to personalize responses. In summary, our work shows that GenAI browser assistants can and do collect personal and sensitive information for profiling and personalization with little to no safeguards.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16586v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.CR</category>
      <category>cs.CY</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yash Vekaria (UC Davis), Aurelio Loris Canino (Mediterranea University of Reggio Calabria), Jonathan Levitsky (UC Davis), Alex Ciechonski (University College London), Patricia Callejo (Universidad Carlos III de Madrid), Anna Maria Mandalari (University College London), Zubair Shafiq (UC Davis)</dc:creator>
    </item>
    <item>
      <title>Revisiting DRAM Read Disturbance: Identifying Inconsistencies Between Experimental Characterization and Device-Level Studies</title>
      <link>https://arxiv.org/abs/2503.16749</link>
      <description>arXiv:2503.16749v1 Announce Type: cross 
Abstract: Modern DRAM is vulnerable to read disturbance (e.g., RowHammer and RowPress) that significantly undermines the robust operation of the system. Repeatedly opening and closing a DRAM row (RowHammer) or keeping a DRAM row open for a long period of time (RowPress) induces bitflips in nearby unaccessed DRAM rows. Prior works on DRAM read disturbance either 1) perform experimental characterization using commercial-off-the-shelf (COTS) DRAM chips to demonstrate the high-level characteristics of the read disturbance bitflips, or 2) perform device-level simulations to understand the low-level error mechanisms of the read disturbance bitflips.
  In this paper, we attempt to align and cross-validate the real-chip experimental characterization results and state-of-the-art device-level studies of DRAM read disturbance. To do so, we first identify and extract the key bitflip characteristics of RowHammer and RowPress from the device-level error mechanisms studied in prior works. Then, we perform experimental characterization on 96 COTS DDR4 DRAM chips that directly match the data and access patterns studied in the device-level works. Through our experiments, we identify fundamental inconsistencies in the RowHammer and RowPress bitflip directions and access pattern dependence between experimental characterization results and the device-level error mechanisms.
  Based on our results, we hypothesize that either 1) the retention failure based DRAM architecture reverse-engineering methodologies do not fully work on modern DDR4 DRAM chips, or 2) existing device-level works do not fully uncover all the major read disturbance error mechanisms. We hope our findings inspire and enable future works to build a more fundamental and comprehensive understanding of DRAM read disturbance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16749v1</guid>
      <category>cs.AR</category>
      <category>cs.CR</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haocong Luo, \.Ismail Emir Y\"uksel, Ataberk Olgun, A. Giray Ya\u{g}l{\i}k\c{c}{\i}, Onur Mutlu</dc:creator>
    </item>
    <item>
      <title>Governance of Ledger-Anchored Decentralized Identifiers</title>
      <link>https://arxiv.org/abs/2503.16972</link>
      <description>arXiv:2503.16972v1 Announce Type: cross 
Abstract: A Decentralized Identifier (DID) empowers an entity to prove control over a unique and self-issued identifier without relying on any identity provider. The public key material for the proof is encoded into an associated DID document (DDO). This is preferable shared via a distributed ledger because it guarantees algorithmically that everyone has access to the latest state of any tamper-proof DDO but only the entities in control of a DID are able to update theirs. Yet, it is possible to grant deputies the authority to update the DDO on behalf of the DID owner. However, the DID specification leaves largely open on how authorizations over a DDO are managed and enforced among multiple deputies. This article investigates what it means to govern a DID and discusses various forms of how a DID can be controlled by potentially more than one entity. It also presents a prototype of a DID-conform identifier management system where a selected set of governance policies are deployed as Smart Contracts. The article highlights the critical role of governance for the trustworthy and flexible deployment of ledger-anchored DIDs across various domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16972v1</guid>
      <category>cs.NI</category>
      <category>cs.CR</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sandro Rodriguez Garzon, Carlo Segat, Axel K\"upper</dc:creator>
    </item>
    <item>
      <title>Friend or Foe? Navigating and Re-configuring "Snipers' Alley"</title>
      <link>https://arxiv.org/abs/2503.16992</link>
      <description>arXiv:2503.16992v1 Announce Type: cross 
Abstract: In a 'digital by default' society, essential services must be accessed online. This opens users to digital deception not only from criminal fraudsters but from a range of actors in a marketised digital economy. Using grounded empirical research from northern England, we show how supposedly 'trusted' actors, such as governments,(re)produce the insecurities and harms that they seek to prevent. Enhanced by a weakening of social institutions amid a drive for efficiency and scale, this has built a constricted, unpredictable digital channel. We conceptualise this as a "snipers' alley". Four key snipers articulated by participants' lived experiences are examined: 1) Governments; 2) Business; 3) Criminal Fraudsters; and 4) Friends and Family to explore how snipers are differentially experienced and transfigure through this constricted digital channel. We discuss strategies to re-configure the alley, and how crafting and adopting opportunity models can enable more equitable forms of security for all.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16992v1</guid>
      <category>cs.HC</category>
      <category>cs.CR</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3706598.3713317</arxiv:DOI>
      <dc:creator>Andrew C Dwyer, Lizzie Coles-Kemp, Clara Crivellaro, Claude P R Heath</dc:creator>
    </item>
    <item>
      <title>Temporal-Guided Spiking Neural Networks for Event-Based Human Action Recognition</title>
      <link>https://arxiv.org/abs/2503.17132</link>
      <description>arXiv:2503.17132v1 Announce Type: cross 
Abstract: This paper explores the promising interplay between spiking neural networks (SNNs) and event-based cameras for privacy-preserving human action recognition (HAR). The unique feature of event cameras in capturing only the outlines of motion, combined with SNNs' proficiency in processing spatiotemporal data through spikes, establishes a highly synergistic compatibility for event-based HAR. Previous studies, however, have been limited by SNNs' ability to process long-term temporal information, essential for precise HAR. In this paper, we introduce two novel frameworks to address this: temporal segment-based SNN (\textit{TS-SNN}) and 3D convolutional SNN (\textit{3D-SNN}). The \textit{TS-SNN} extracts long-term temporal information by dividing actions into shorter segments, while the \textit{3D-SNN} replaces 2D spatial elements with 3D components to facilitate the transmission of temporal information. To promote further research in event-based HAR, we create a dataset, \textit{FallingDetection-CeleX}, collected using the high-resolution CeleX-V event camera $(1280 \times 800)$, comprising 7 distinct actions. Extensive experimental results show that our proposed frameworks surpass state-of-the-art SNN methods on our newly collected dataset and three other neuromorphic datasets, showcasing their effectiveness in handling long-range temporal information for event-based HAR.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.17132v1</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>cs.CR</category>
      <category>cs.NE</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Siyuan Yang, Shilin Lu, Shizheng Wang, Meng Hwa Er, Zengwei Zheng, Alex C. Kot</dc:creator>
    </item>
    <item>
      <title>On Privately Estimating a Single Parameter</title>
      <link>https://arxiv.org/abs/2503.17252</link>
      <description>arXiv:2503.17252v1 Announce Type: cross 
Abstract: We investigate differentially private estimators for individual parameters within larger parametric models. While generic private estimators exist, the estimators we provide repose on new local notions of estimand stability, and these notions allow procedures that provide private certificates of their own stability. By leveraging these private certificates, we provide computationally and statistical efficient mechanisms that release private statistics that are, at least asymptotically in the sample size, essentially unimprovable: they achieve instance optimal bounds. Additionally, we investigate the practicality of the algorithms both in simulated data and in real-world data from the American Community Survey and US Census, highlighting scenarios in which the new procedures are successful and identifying areas for future work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.17252v1</guid>
      <category>cs.LG</category>
      <category>cs.CR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hilal Asi, John C. Duchi, Kunal Talwar</dc:creator>
    </item>
    <item>
      <title>A Stateless and Secure Delivery versus Payment across two Blockchains</title>
      <link>https://arxiv.org/abs/2311.05966</link>
      <description>arXiv:2311.05966v4 Announce Type: replace 
Abstract: We propose a lean and functional transaction scheme to establish a secure delivery-versus-payment across two blockchains, where a) no intermediary is required and b) the operator of the payment chain/payment system has a small overhead and does not need to store state. The main idea comes with two requirements: First, the payment chain operator hosts a stateless decryption service that allows decrypting messages with his secret key. Second, a "Payment Contract" is deployed on the payment chain that implements a function
  transferAndDecrypt(uint id, address from, address to, string keyEncryptedSuccess, string keyEncryptedFail)
  that processes the payment and emits the decrypted key depending on the success or failure of the transaction. The respective key can then trigger an associated transaction, e.g. claiming delivery by the buyer or re-claiming the locked asset by the seller. The contract interfaces described here are available as ERC 7573. A reference implementation of the decryption oracle is available via GitLab.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.05966v4</guid>
      <category>cs.CR</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Christian P. Fries, Peter Kohl-Landgraf</dc:creator>
    </item>
    <item>
      <title>HAL 9000: a Risk Manager for ITSs</title>
      <link>https://arxiv.org/abs/2311.09449</link>
      <description>arXiv:2311.09449v2 Announce Type: replace 
Abstract: HAL 9000 is an Intrusion Tolerant Systems (ITSs) Risk Manager, which assesses configuration risks against potential intrusions. It utilizes gathered threat knowledge and remains operational, even in the absence of updated information. Based on its advice, the ITSs can dynamically and proactively adapt to recent threats to minimize and mitigate future intrusions from malicious adversaries. Our goal is to reduce the risk linked to the exploitation of recently uncovered vulnerabilities that have not been classified and/or do not have a script to reproduce the exploit, considering the potential that they may have already been exploited as zero-day exploits. Our experiments demonstrate that the proposed solution can effectively learn and replicate National Vulnerability Database's evaluation process with 99% accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.09449v2</guid>
      <category>cs.CR</category>
      <category>cs.AI</category>
      <category>cs.OS</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TPS-ISA62245.2024.00044</arxiv:DOI>
      <dc:creator>Tadeu Freitas, Carlos Novo, Joao Soares, Ines Dutra, Manuel E. Correia, Behnam Shariati, Rolando Martins</dc:creator>
    </item>
    <item>
      <title>PMANet: Malicious URL detection via post-trained language model guided multi-level feature attention network</title>
      <link>https://arxiv.org/abs/2311.12372</link>
      <description>arXiv:2311.12372v2 Announce Type: replace 
Abstract: The proliferation of malicious URLs has made their detection crucial for enhancing network security. While pre-trained language models offer promise, existing methods struggle with domain-specific adaptability, character-level information, and local-global encoding integration. To address these challenges, we propose PMANet, a pre-trained Language Model-Guided multi-level feature attention network. PMANet employs a post-training process with three self-supervised objectives: masked language modeling, noisy language modeling, and domain discrimination, effectively capturing subword and character-level information. It also includes a hierarchical representation module and a dynamic layer-wise attention mechanism for extracting features from low to high levels. Additionally, spatial pyramid pooling integrates local and global features. Experiments on diverse scenarios, including small-scale data, class imbalance, and adversarial attacks, demonstrate PMANet's superiority over state-of-the-art models, achieving a 0.9941 AUC and correctly detecting all 20 malicious URLs in a case study. Code and data are available at https://github.com/Alixyvtte/Malicious-URL-Detection-PMANet.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.12372v2</guid>
      <category>cs.CR</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruitong Liu, Yanbin Wang, Haitao Xu, Zhan Qin, Fan Zhang, Yiwei Liu, Zheng Cao</dc:creator>
    </item>
    <item>
      <title>TransURL: Improving malicious URL detection with multi-layer Transformer encoding and multi-scale pyramid features</title>
      <link>https://arxiv.org/abs/2312.00508</link>
      <description>arXiv:2312.00508v3 Announce Type: replace 
Abstract: Machine learning progress is advancing the detection of malicious URLs. However, advanced Transformers applied to URLs face difficulties in extracting local information, character-level details, and structural relationships. To address these challenges, we propose a novel approach for malicious URL detection, named TransURL. This method is implemented by co-training the character-aware Transformer with three feature modules: Multi-Layer Encoding, Multi-Scale Feature Learning, and Spatial Pyramid Attention. This specialized Transformer enables TransURL to extract embeddings with character-level information from URL token sequences, with the three modules aiding the fusion of multi-layer Transformer encodings and the capture of multi-scale local details and structural relationships. The proposed method is evaluated across several challenging scenarios, including class imbalance learning, multi-classification, cross-dataset testing, and adversarial sample attacks. Experimental results demonstrate a significant improvement compared to previous methods. For instance, it achieved a peak F1-score improvement of 40% in class-imbalanced scenarios and surpassed the best baseline by 14.13% in accuracy for adversarial attack scenarios. Additionally, a case study demonstrated that our method accurately identified all 30 active malicious web pages, whereas two previous state-of-the-art methods missed 4 and 7 malicious web pages, respectively. The codes and data are available at: https://github.com/Vul-det/TransURL/.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.00508v3</guid>
      <category>cs.CR</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.comnet.2024.11070</arxiv:DOI>
      <arxiv:journal_reference>Computer Networks 253 (2024) 110707</arxiv:journal_reference>
      <dc:creator>Ruitong Liu, Yanbin Wang, Zhenhao Guo, Haitao Xu, Zhan Qin, Wenrui Ma, Fan Zhang</dc:creator>
    </item>
    <item>
      <title>Vul-LMGNNs: Fusing language models and online-distilled graph neural networks for code vulnerability detection</title>
      <link>https://arxiv.org/abs/2404.14719</link>
      <description>arXiv:2404.14719v2 Announce Type: replace 
Abstract: Code Language Models (codeLMs) and Graph Neural Networks (GNNs) are widely used in code vulnerability detection. However, GNNs often rely on aggregating information from adjacent nodes, limiting structural information propagation across layers. While codeLMs can supplement GNNs with semantic information, existing integration methods underexplore their collaborative potential. To address these challenges, we propose Vul-LMGNNs, integrating pre-trained codeLMs with GNNs to enable cross-layer propagation of semantic and structural information. Vul-LMGNNs leverage Code Property Graphs (CPGs) to incorporate syntax, control flow, and data dependencies, using gated GNNs for structural extraction. An online knowledge distillation (KD) mechanism allows a student GNN to capture structural information from a trained counterpart via alternating training. Additionally, an "implicit-explicit" joint training framework leverages codeLMs to initialize embeddings and propagate code semantics. In the explicit phase, it performs late fusion via linear interpolation. Evaluations on real-world vulnerability datasets show Vul-LMGNNs outperform 17 state-of-the-art approaches. Source code is available at: https://github.com/Vul-LMGNN/vul-LMGNN.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.14719v2</guid>
      <category>cs.CR</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.inffus.2024.102748</arxiv:DOI>
      <arxiv:journal_reference>Information Fusion 115 (2025) 102748 Information Fusion 115 (2025) 102748 Information Fusion 115 (2025) 102748</arxiv:journal_reference>
      <dc:creator>Ruitong Liu, Yanbin Wang, Haitao Xu, Jianguo Sun, Fan Zhang, Peiyue Li, Zhenhao Guo</dc:creator>
    </item>
    <item>
      <title>An Attack on $p$-adic Lattice Public-key Cryptosystems and Signature Schemes</title>
      <link>https://arxiv.org/abs/2409.08774</link>
      <description>arXiv:2409.08774v2 Announce Type: replace 
Abstract: Lattices have many significant applications in cryptography. In 2021, the $p$-adic signature scheme and public-key encryption cryptosystem were introduced. They are based on the Longest Vector Problem (LVP) and the Closest Vector Problem (CVP) in $p$-adic lattices. These problems are considered to be challenging and there are no known deterministic polynomial time algorithms to solve them. In this paper, we improve the LVP algorithm in local fields. The modified LVP algorithm is a deterministic polynomial time algorithm when the field is totally ramified and $p$ is a polynomial in the rank of the input lattice. We utilize this algorithm to attack the above schemes so that we are able to forge a valid signature of any message and decrypt any ciphertext. Although these schemes are broken, this work does not mean that $p$-adic lattices are not suitable in constructing cryptographic primitives. We propose some possible modifications to avoid our attack at the end of this paper.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08774v2</guid>
      <category>cs.CR</category>
      <category>math.NT</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chi Zhang</dc:creator>
    </item>
    <item>
      <title>Near Exact Privacy Amplification for Matrix Mechanisms</title>
      <link>https://arxiv.org/abs/2410.06266</link>
      <description>arXiv:2410.06266v2 Announce Type: replace 
Abstract: We study the problem of computing the privacy parameters for DP machine learning when using privacy amplification via random batching and noise correlated across rounds via a correlation matrix $\textbf{C}$ (i.e., the matrix mechanism). Past work on this problem either only applied to banded $\textbf{C}$, or gave loose privacy parameters. In this work, we give a framework for computing near-exact privacy parameters for any lower-triangular, non-negative $\textbf{C}$. Our framework allows us to optimize the correlation matrix $\textbf{C}$ while accounting for amplification, whereas past work could not. Empirically, we show this lets us achieve smaller RMSE on prefix sums than the previous state-of-the-art (SOTA). We also show that we can improve on the SOTA performance on deep learning tasks. Our two main technical tools are (i) using Monte Carlo accounting to bypass composition, which was the main technical challenge for past work, and (ii) a "balls-in-bins" batching scheme that enables easy privacy analysis and is closer to practical random batching than Poisson sampling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06266v2</guid>
      <category>cs.CR</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christopher A. Choquette-Choo, Arun Ganesh, Saminul Haque, Thomas Steinke, Abhradeep Thakurta</dc:creator>
    </item>
    <item>
      <title>SATA: A Paradigm for LLM Jailbreak via Simple Assistive Task Linkage</title>
      <link>https://arxiv.org/abs/2412.15289</link>
      <description>arXiv:2412.15289v2 Announce Type: replace 
Abstract: Large language models (LLMs) have made significant advancements across various tasks, but their safety alignment remain a major concern. Exploring jailbreak prompts can expose LLMs' vulnerabilities and guide efforts to secure them. Existing methods primarily design sophisticated instructions for the LLM to follow, or rely on multiple iterations, which could hinder the performance and efficiency of jailbreaks. In this work, we propose a novel jailbreak paradigm, Simple Assistive Task Linkage (SATA), which can effectively circumvent LLM safeguards and elicit harmful responses. Specifically, SATA first masks harmful keywords within a malicious query to generate a relatively benign query containing one or multiple [MASK] special tokens. It then employs a simple assistive task such as a masked language model task or an element lookup by position task to encode the semantics of the masked keywords. Finally, SATA links the assistive task with the masked query to jointly perform the jailbreak. Extensive experiments show that SATA achieves state-of-the-art performance and outperforms baselines by a large margin. Specifically, on AdvBench dataset, with mask language model (MLM) assistive task, SATA achieves an overall attack success rate (ASR) of 85% and harmful score (HS) of 4.57, and with element lookup by position (ELP) assistive task, SATA attains an overall ASR of 76% and HS of 4.43.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.15289v2</guid>
      <category>cs.CR</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaoning Dong, Wenbo Hu, Wei Xu, Tianxing He</dc:creator>
    </item>
    <item>
      <title>SPDZCoder: Combining Expert Knowledge with LLMs for Generating Privacy-Computing Code</title>
      <link>https://arxiv.org/abs/2501.00363</link>
      <description>arXiv:2501.00363v2 Announce Type: replace 
Abstract: Privacy computing receives increasing attention but writing privacy computing code remains challenging for developers due to limited library functions, necessitating function implementation from scratch, and data-oblivious requirement, contradicting intuitive thinking and usual practices of programmers. Automating the generation of privacy computing code with Large Language Models can streamline development effort and lower the barrier to using privacy computing frameworks. However, existing LLMs still encounter challenges in code translation for privacy-preserving computation, such as translating Python to MP-SPDZ, due to the scarcity of MP-SPDZ data required for effective pre-training or fine-tuning. Moreover, the lack of a benchmark further complicates the evaluation of translation quality. To address the limitations, this work proposes SPDZCoder, a rule-based framework that combines LLMs with expert knowledge for generating privacy-computing code without requiring additional training data. Specifically, SPDZCoder employ a rigorous procedure for collecting high-quality expert knowledge to represent the semantic-expressing differences between Python and MP-SPDZ, and to derive transformation rules for translating Python to MP-SPDZ based on these knowledge. Then, SPDZCoder progressively converts Python code into MP-SPDZ code using transformation rules in a three stage pipeline. To evaluate SPDZCoder, we manually constructed a benchmark dataset, SPDZEval, which comprises six data splits, each representing a distinct class of challenging tasks in MP-SPDZ implementation. Extensive experiments show that SPDZCoder achieves superior performance, significantly surpassing baselines in pass@1 and pass@2. Specifically, SPDZCoder attains an overall correctness of 85.94% and 92.01% in pass@1 and pass@2, respectively, whereas the best-performing baseline achieves 63.58% and 76.36%, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.00363v2</guid>
      <category>cs.CR</category>
      <category>cs.SE</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaoning Dong, Peilin Xin, Jia Li, Wei Xu</dc:creator>
    </item>
    <item>
      <title>Automated Selfish Mining Analysis for DAG-based PoW Consensus Protocols</title>
      <link>https://arxiv.org/abs/2501.10888</link>
      <description>arXiv:2501.10888v2 Announce Type: replace 
Abstract: Selfish mining is strategic rule-breaking to maximize rewards in proof-of-work protocols. Markov Decision Processes (MDPs) are the preferred tool for finding optimal strategies in Bitcoin and similar linear chain protocols. Protocols increasingly adopt DAG-based chain structures, for which MDP analysis is more involved. To date, researchers have tailored specific MDPs for each protocol. Protocol design suffers long feedback loops, as each protocol change implies manual work on the MDP. To overcome this, we propose a generic attack model that covers a wide range of protocols, including Ethereum Proof-of-Work, GhostDAG, and Parallel Proof-of-Work. Our approach is modular: we specify each protocol as a concise program, and our tooling then derives and solves the selfish mining MDP automatically.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10888v2</guid>
      <category>cs.CR</category>
      <category>cs.DC</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Patrik Keller</dc:creator>
    </item>
    <item>
      <title>Zero Trust Architecture: A Systematic Literature Review</title>
      <link>https://arxiv.org/abs/2503.11659</link>
      <description>arXiv:2503.11659v2 Announce Type: replace 
Abstract: The increasing complexity of digital ecosystems and evolving cybersecurity threats have highlighted the limitations of traditional perimeter-based security models, leading to the growing adoption of Zero Trust Architecture (ZTA). ZTA operates on the principle of "never trust, always verify", enforcing continuous authentication, conditional access, dynamic trust evaluation, and the principle of least privilege to enhance security across diverse domains. This study applies the PRISMA framework to analyze 10 years of research (2016-2025) on ZTA, presenting a systematic literature review (SLR) that synthesizes its applications, enabling technologies, and associated challenges. It provides a detailed taxonomy that organizes ZTA's application domains, together with the emerging technologies that facilitate its implementation, and critically examines the barriers to ZTA adoption. Additionally, the study traces the historical evolution of ZTA alongside notable events and publications trends while highlighting some potential factors for the surge over the past few years. This comprehensive analysis serves as a practical guide for researchers and practitioners seeking to leverage ZTA for stronger, more adaptive security frameworks in a rapidly shifting threat landscape.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.11659v2</guid>
      <category>cs.CR</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Muhammad Liman Gambo, Ahmad Almulhem</dc:creator>
    </item>
    <item>
      <title>Temporal-Spatial Attention Network (TSAN) for DoS Attack Detection in Network Traffic</title>
      <link>https://arxiv.org/abs/2503.16047</link>
      <description>arXiv:2503.16047v2 Announce Type: replace 
Abstract: Denial-of-Service (DoS) attacks remain a critical threat to network security, disrupting services and causing significant economic losses. Traditional detection methods, including statistical and rule-based models, struggle to adapt to evolving attack patterns. To address this challenge, we propose a novel Temporal-Spatial Attention Network (TSAN) architecture for detecting Denial of Service (DoS) attacks in network traffic. By leveraging both temporal and spatial features of network traffic, our approach captures complex traffic patterns and anomalies that traditional methods might miss. The TSAN model incorporates transformer-based temporal encoding, convolutional spatial encoding, and a cross-attention mechanism to fuse these complementary feature spaces. Additionally, we employ multi-task learning with auxiliary tasks to enhance the model's robustness. Experimental results on the NSL-KDD dataset demonstrate that TSAN outperforms state-of-the-art models, achieving superior accuracy, precision, recall, and F1-score while maintaining computational efficiency for real-time deployment. The proposed architecture offers an optimal balance between detection accuracy and computational overhead, making it highly suitable for real-world network security applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16047v2</guid>
      <category>cs.CR</category>
      <category>cs.AI</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bisola Faith Kayode, Akinyemi Sadeeq Akintola, Oluwole Fagbohun, Egonna Anaesiuba-Bristol, Onyekachukwu Ojumah, Oluwagbade Odimayo, Toyese Oloyede, Aniema Inyang, Teslim Kazeem, Habeeb Alli, Udodirim Ibem Offia, Prisca Chinazor Amajuoyi</dc:creator>
    </item>
    <item>
      <title>Automated Market Makers in Cryptoeconomic Systems: A Taxonomy and Archetypes</title>
      <link>https://arxiv.org/abs/2309.12818</link>
      <description>arXiv:2309.12818v3 Announce Type: replace-cross 
Abstract: Designing automated market makers (AMMs) is crucial for decentralized token exchanges in cryptoeconomic systems. At the intersection of software engineering and economics, AMM design is complex and, if done incorrectly, can lead to financial risks and inefficiencies. We developed an AMM taxonomy for systematically comparing AMM designs and propose three AMM archetypes that meet key requirements for token issuance and exchange. This work bridges software engineering and economic perspectives, providing insights to help developers design AMMs tailored to diverse use cases and foster sustainable cryptoeconomic systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.12818v3</guid>
      <category>q-fin.TR</category>
      <category>cs.CR</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel Kirste, Niclas Kannengie{\ss}er, Ricky Lamberty, Ali Sunyaev</dc:creator>
    </item>
    <item>
      <title>EmojiPrompt: Generative Prompt Obfuscation for Privacy-Preserving Communication with Cloud-based LLMs</title>
      <link>https://arxiv.org/abs/2402.05868</link>
      <description>arXiv:2402.05868v3 Announce Type: replace-cross 
Abstract: Cloud-based Large Language Models (LLMs) such as ChatGPT have become increasingly integral to daily operations. Nevertheless, they also introduce privacy concerns: firstly, numerous studies underscore the risks to user privacy posed by jailbreaking cloud-based LLMs; secondly, the LLM service providers have access to all user data, which deters individuals from confidently utilizing such services. To address such concerns, we propose a simple yet effective paradigm, EmojiPrompt, to protect user privacy. At its core, EmojiPrompt performs generative transformation, obfuscating private data within prompts with linguistic and non-linguistic elements before submitting them to cloud-based LLMs. We evaluate EmojiPrompt's performance across 8 datasets from various domains. We also propose simulated inference attacks to assess EmojiPrompt's ability to preserve user privacy. The results demonstrate that EmojiPrompt effectively obfuscates user private data, while largely maintaining, or even enhancing, performances compared to the unobfuscated version. Furthermore, EmojiPrompt's atomic-level obfuscation allows it to function exclusively with cloud-based LLMs. For source code, please refer to: https://github.com/agiresearch/EmojiCrypt.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.05868v3</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.CR</category>
      <category>cs.IR</category>
      <category>cs.LG</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sam Lin, Wenyue Hua, Zhenting Wang, Mingyu Jin, Lizhou Fan, Yongfeng Zhang</dc:creator>
    </item>
    <item>
      <title>Exact Recovery Guarantees for Parameterized Nonlinear System Identification Problem under Sparse Disturbances or Semi-Oblivious Attacks</title>
      <link>https://arxiv.org/abs/2409.00276</link>
      <description>arXiv:2409.00276v3 Announce Type: replace-cross 
Abstract: In this work, we study the problem of learning a nonlinear dynamical system by parameterizing its dynamics using basis functions. We assume that disturbances occur at each time step with an arbitrary probability $p$, which models the sparsity level of the disturbance vectors over time. These disturbances are drawn from an arbitrary, unknown probability distribution, which may depend on past disturbances, provided that it satisfies a zero-mean assumption. The primary objective of this paper is to learn the system's dynamics within a finite time and analyze the sample complexity as a function of $p$. To achieve this, we examine a LASSO-type non-smooth estimator, and establish necessary and sufficient conditions for its well-specifiedness and the uniqueness of the global solution to the underlying optimization problem. We then provide exact recovery guarantees for the estimator under two distinct conditions: boundedness and Lipschitz continuity of the basis functions. We show that finite-time exact recovery is achieved with high probability, even when $p$ approaches 1. Unlike prior works, which primarily focus on independent and identically distributed (i.i.d.) disturbances and provide only asymptotic guarantees for system learning, this study presents the first finite-time analysis of nonlinear dynamical systems under a highly general disturbance model. Our framework allows for possible temporal correlations in the disturbances and accommodates semi-oblivious adversarial attacks, significantly broadening the scope of existing theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.00276v3</guid>
      <category>math.OC</category>
      <category>cs.CR</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Haixiang Zhang, Baturalp Yalcin, Javad Lavaei, Eduardo D. Sontag</dc:creator>
    </item>
    <item>
      <title>Human-in-the-Loop Generation of Adversarial Texts: A Case Study on Tibetan Script</title>
      <link>https://arxiv.org/abs/2412.12478</link>
      <description>arXiv:2412.12478v3 Announce Type: replace-cross 
Abstract: DNN-based language models perform excellently on various tasks, but even SOTA LLMs are susceptible to textual adversarial attacks. Adversarial texts play crucial roles in multiple subfields of NLP. However, current research has the following issues. (1) Most textual adversarial attack methods target rich-resourced languages. How do we generate adversarial texts for less-studied languages? (2) Most textual adversarial attack methods are prone to generating invalid or ambiguous adversarial texts. How do we construct high-quality adversarial robustness benchmarks? (3) New language models may be immune to part of previously generated adversarial texts. How do we update adversarial robustness benchmarks? To address the above issues, we introduce HITL-GAT, a system based on a general approach to human-in-the-loop generation of adversarial texts. HITL-GAT contains four stages in one pipeline: victim model construction, adversarial example generation, high-quality benchmark construction, and adversarial robustness evaluation. Additionally, we utilize HITL-GAT to make a case study on Tibetan script which can be a reference for the adversarial research of other less-studied languages.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.12478v3</guid>
      <category>cs.CL</category>
      <category>cs.CR</category>
      <category>cs.HC</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xi Cao, Yuan Sun, Jiajun Li, Quzong Gesang, Nuo Qun, Tashi Nyima</dc:creator>
    </item>
    <item>
      <title>PA-CFL: Privacy-Adaptive Clustered Federated Learning for Transformer-Based Sales Forecasting on Heterogeneous Retail Data</title>
      <link>https://arxiv.org/abs/2503.12220</link>
      <description>arXiv:2503.12220v2 Announce Type: replace-cross 
Abstract: Federated learning (FL) enables retailers to share model parameters for demand forecasting while maintaining privacy. However, heterogeneous data across diverse regions, driven by factors such as varying consumer behavior, poses challenges to the effectiveness of federated learning. To tackle this challenge, we propose Privacy-Adaptive Clustered Federated Learning (PA-CFL) tailored for demand forecasting on heterogeneous retail data. By leveraging differential privacy and feature importance distribution, PA-CFL groups retailers into distinct ``bubbles'', each forming its own federated learning system to effectively isolate data heterogeneity. Within each bubble, Transformer models are designed to predict local sales for each client. Our experiments demonstrate that PA-CFL significantly surpasses FedAvg and outperforms local learning in demand forecasting performance across all participating clients. Compared to local learning, PA-CFL achieves a 5.4% improvement in R^2, a 69% reduction in RMSE, and a 45% decrease in MAE. Our approach enables effective FL through adaptive adjustments to diverse noise levels and the range of clients participating in each bubble. By grouping participants and proactively filtering out high-risk clients, PA-CFL mitigates potential threats to the FL system. The findings demonstrate PA-CFL's ability to enhance federated learning in time series prediction tasks with heterogeneous data, achieving a balance between forecasting accuracy and privacy preservation in retail applications. Additionally, PA-CFL's capability to detect and neutralize poisoned data from clients enhances the system's robustness and reliability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.12220v2</guid>
      <category>cs.LG</category>
      <category>cs.CR</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yunbo Long, Liming Xu, Ge Zheng, Alexandra Brintrup</dc:creator>
    </item>
  </channel>
</rss>
