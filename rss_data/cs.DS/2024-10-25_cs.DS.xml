<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 25 Oct 2024 04:00:12 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Putting Off the Catching Up: Online Joint Replenishment Problem with Holding and Backlog Costs</title>
      <link>https://arxiv.org/abs/2410.18535</link>
      <description>arXiv:2410.18535v1 Announce Type: new 
Abstract: We study an online generalization of the classic Joint Replenishment Problem (JRP) that models the trade-off between ordering costs, holding costs, and backlog costs in supply chain planning systems. A retailer places orders to a supplier for multiple items over time: each request is for some item that the retailer needs in the future, and has an arrival time and a soft deadline. If a request is served before its deadline, the retailer pays a holding cost per unit of the item until the deadline. However, if a request is served after its deadline, the retailer pays a backlog cost per unit. Each service incurs a fixed joint service cost and a fixed item-dependent cost for every item included in a service. These fixed costs are the same irrespective of the units of each item ordered. The goal is to schedule services to satisfy all the online requests while minimizing the sum of the service costs, the holding costs, and the backlog costs.
  Constant competitive online algorithms have been developed for two special cases: the make-to-order version when the deadlines are equal to arrival times (Buchbinder et al., 2013), and the make-to-stock version with hard deadlines with zero holding costs (Bienkowski et al., 2014). Our general model with holding and backlog costs has not been investigated earlier, and no online algorithms are known even in the make-to-stock version with hard deadlines and non-zero holding costs. We develop a new online algorithm for the general version of online JRP with both holding and backlog costs and establish that it is 30-competitive. Along the way, we develop a 3-competitive algorithm for the single-item case that we build on to get our final result. Our algorithm uses a greedy strategy and its competitiveness is shown using a dual fitting analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.18535v1</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Benjamin Moseley, Aidin Niaparast, R. Ravi</dc:creator>
    </item>
    <item>
      <title>Stronger adversaries grow cheaper forests: online node-weighted Steiner problems</title>
      <link>https://arxiv.org/abs/2410.18542</link>
      <description>arXiv:2410.18542v1 Announce Type: new 
Abstract: We propose a $O(\log k \log n)$-competitive randomized algorithm for online node-weighted Steiner forest. This is essentially optimal and significantly improves over the previous bound of $O(\log^2 k \log n)$ by Hajiaghayi et al. [2017]. In fact, our result extends to the more general prize-collecting setting, improving over previous works by a poly-logarithmic factor. Our key technical contribution is a randomized online algorithm for set cover and non-metric facility location in a new adversarial model which we call semi-adaptive adversaries. As a by-product of our techniques, we obtain the first deterministic $O(\log |C| \log |F|)$-competitive algorithm for non-metric facility location.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.18542v1</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sander Borst, Marek Eli\'a\v{s}, Moritz Venzin</dc:creator>
    </item>
    <item>
      <title>Counting Locally Optimal Tours in the TSP</title>
      <link>https://arxiv.org/abs/2410.18650</link>
      <description>arXiv:2410.18650v1 Announce Type: new 
Abstract: We show that the problem of counting the number of 2-optimal tours in instances of the Travelling Salesperson Problem (TSP) on complete graphs is #P-complete. In addition, we show that the expected number of 2-optimal tours in random instances of the TSP on complete graphs is $O(1.2098^n \sqrt{n!})$. Based on numerical experiments, we conjecture that the true bound is at most $O(\sqrt{n!})$, which is approximately the square root of the total number of tours.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.18650v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bodo Manthey, Jesse van Rhijn</dc:creator>
    </item>
    <item>
      <title>Recognizing Sumsets is NP-Complete</title>
      <link>https://arxiv.org/abs/2410.18661</link>
      <description>arXiv:2410.18661v1 Announce Type: new 
Abstract: Sumsets are central objects in additive combinatorics. In 2007, Granville asked whether one can efficiently recognize whether a given set $S$ is a sumset, i.e. whether there is a set $A$ such that $A+A=S$. Granville suggested an algorithm that takes exponential time in the size of the given set, but can we do polynomial or even linear time? This basic computational question is indirectly asking a fundamental structural question: do the special characteristics of sumsets allow them to be efficiently recognizable? In this paper, we answer this question negatively by proving that the problem is NP-complete. Specifically, our results hold for integer sets and over any finite field. Assuming the Exponential Time Hypothesis, our lower bound becomes $2^{\Omega(n^{1/4})}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.18661v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amir Abboud, Nick Fischer, Ron Safier, Nathan Wallheimer</dc:creator>
    </item>
    <item>
      <title>Deterministic Edge Connectivity and Max Flow using Subquadratic Cut Queries</title>
      <link>https://arxiv.org/abs/2410.18704</link>
      <description>arXiv:2410.18704v1 Announce Type: new 
Abstract: We give the first deterministic algorithm that makes sub-quadratic queries to find the global min-cut of a simple graph in the cut query model. Given an $n$-vertex graph $G$, our algorithm makes $\widetilde{O}(n^{5/3})$ queries to compute the global min-cut in $G$. As a key ingredient, we also show an algorithm for finding $s$-$t$ max-flows of size $\widetilde{O}(n)$ in $\widetilde{O}(n^{5/3})$ queries. We also show efficient cut-query implementations of versions of expander decomposition and isolating cuts, which may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.18704v1</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aditya Anand, Thatchaphol Saranurak, Yunfan Wang</dc:creator>
    </item>
    <item>
      <title>Deterministic $(2/3-\varepsilon)$-Approximation of Matroid Intersection using Nearly-Linear Independence-Oracle Queries</title>
      <link>https://arxiv.org/abs/2410.18820</link>
      <description>arXiv:2410.18820v1 Announce Type: new 
Abstract: In the matroid intersection problem, we are given two matroids $\mathcal{M}_1 = (V, \mathcal{I}_1)$ and $\mathcal{M}_2 = (V, \mathcal{I}_2)$ defined on the same ground set $V$ of $n$ elements, and the objective is to find a common independent set $S \in \mathcal{I}_1 \cap \mathcal{I}_2$ of largest possible cardinality, denoted by $r$. In this paper, we consider a deterministic matroid intersection algorithm with only a nearly linear number of independence oracle queries. Our contribution is to present a deterministic $O(\frac{n}{\varepsilon} + r \log r)$-independence-query $(2/3-\varepsilon)$-approximation algorithm for any $\varepsilon &gt; 0$. Our idea is very simple: we apply a recent $\tilde{O}(n \sqrt{r}/\varepsilon)$-independence-query $(1 - \varepsilon)$-approximation algorithm of Blikstad [ICALP 2021], but terminate it before completion. Moreover, we also present a semi-streaming algorithm for $(2/3 -\varepsilon)$-approximation of matroid intersection in $O(1/\varepsilon)$ passes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.18820v1</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tatsuya Terao</dc:creator>
    </item>
    <item>
      <title>Packing Short Cycles</title>
      <link>https://arxiv.org/abs/2410.18878</link>
      <description>arXiv:2410.18878v1 Announce Type: new 
Abstract: Cycle packing is a fundamental problem in optimization, graph theory, and algorithms. Motivated by recent advancements in finding vertex-disjoint paths between a specified set of vertices that either minimize the total length of the paths [Bj\"orklund, Husfeldt, ICALP 2014; Mari, Mukherjee, Pilipczuk, and Sankowski, SODA 2024] or request the paths to be shortest [Lochet, SODA 2021], we consider the following cycle packing problems: Min-Sum Cycle Packing and Shortest Cycle Packing.
  In Min-Sum Cycle Packing, we try to find, in a weighted undirected graph, $k$ vertex-disjoint cycles of minimum total weight. Our first main result is an algorithm that, for any fixed $k$, solves the problem in polynomial time. We complement this result by establishing the W[1]-hardness of Min-Sum Cycle Packing parameterized by $k$. The same results hold for the version of the problem where the task is to find $k$ edge-disjoint cycles.
  Our second main result concerns Shortest Cycle Packing, which is a special case of Min-Sum Cycle Packing that asks to find a packing of $k$ shortest cycles in a graph. We prove this problem to be fixed-parameter tractable (FPT) when parameterized by $k$ on weighted planar graphs. We also obtain a polynomial kernel for the edge-disjoint variant of the problem on planar graphs. Deciding whether Min-Sum Cycle Packing is FPT on planar graphs and whether Shortest Cycle Packing is FPT on general graphs remain challenging open questions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.18878v1</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matthias Bentert, Fedor V. Fomin, Petr A. Golovach, Tuukka Korhonen, William Lochet, Fahad Panolan, M. S. Ramanujan, Saket Saurabh, Kirill Simonov</dc:creator>
    </item>
    <item>
      <title>Connectivity Labeling Schemes for Edge and Vertex Faults via Expander Hierarchies</title>
      <link>https://arxiv.org/abs/2410.18885</link>
      <description>arXiv:2410.18885v1 Announce Type: new 
Abstract: We consider the problem of assigning short labels to the vertices and edges of a graph $G$ so that given any query $\langle s,t,F\rangle$ with $|F|\leq f$, we can determine whether $s$ and $t$ are still connected in $G-F$, given only the labels of $F\cup\{s,t\}$. This problem has been considered when $F\subset E$ (edge faults), where correctness is guaranteed with high probability (w.h.p.) or deterministically, and when $F\subset V$ (vertex faults), both w.h.p.~and deterministically. Our main results are as follows.
  [Deterministic Edge Faults.] We give a new deterministic labeling scheme for edge faults that uses $\tilde{O}(\sqrt{f})$-bit labels, which can be constructed in polynomial time. This improves on Dory and Parter's [PODC 2021] existential bound of $O(f\log n)$ (requiring exponential time to compute) and the efficient $\tilde{O}(f^2)$-bit scheme of Izumi, Emek, Wadayama, and Masuzawa [PODC 2023]. Our construction uses an improved edge-expander hierarchy and a distributed coding technique based on Reed-Solomon codes.
  [Deterministic Vertex Faults.] We improve Parter, Petruschka, and Pettie's [STOC 2024] deterministic $O(f^7\log^{13} n)$-bit labeling scheme for vertex faults to $O(f^4\log^{7.5} n)$ bits, using an improved vertex-expander hierarchy and better sparsification of shortcut graphs.
  [Randomized Edge/Verex Faults.] We improve the size of Dory and Parter's [PODC 2021] randomized edge fault labeling scheme from $O(\min\{f+\log n, \log^3 n\})$ bits to $O(\min\{f+\log n, \log^2 n\log f\})$ bits, shaving a $\log n/\log f$ factor. We also improve the size of Parter, Petruschka, and Pettie's [STOC 2024] randomized vertex fault labeling scheme from $O(f^3\log^5 n)$ bits to $O(f^2\log^6 n)$ bits, which comes closer to their $\Omega(f)$-bit lower bound.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.18885v1</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yaowei Long, Seth Pettie, Thatchaphol Saranurak</dc:creator>
    </item>
    <item>
      <title>Testing Support Size More Efficiently Than Learning Histograms</title>
      <link>https://arxiv.org/abs/2410.18915</link>
      <description>arXiv:2410.18915v1 Announce Type: new 
Abstract: Consider two problems about an unknown probability distribution $p$:
  1. How many samples from $p$ are required to test if $p$ is supported on $n$ elements or not? Specifically, given samples from $p$, determine whether it is supported on at most $n$ elements, or it is "$\epsilon$-far" (in total variation distance) from being supported on $n$ elements.
  2. Given $m$ samples from $p$, what is the largest lower bound on its support size that we can produce?
  The best known upper bound for problem (1) uses a general algorithm for learning the histogram of the distribution $p$, which requires $\Theta(\tfrac{n}{\epsilon^2 \log n})$ samples. We show that testing can be done more efficiently than learning the histogram, using only $O(\tfrac{n}{\epsilon \log n} \log(1/\epsilon))$ samples, nearly matching the best known lower bound of $\Omega(\tfrac{n}{\epsilon \log n})$. This algorithm also provides a better solution to problem (2), producing larger lower bounds on support size than what follows from previous work. The proof relies on an analysis of Chebyshev polynomial approximations outside the range where they are designed to be good approximations, and the paper is intended as an accessible self-contained exposition of the Chebyshev polynomial method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.18915v1</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Renato Ferreira Pinto Jr., Nathaniel Harms</dc:creator>
    </item>
    <item>
      <title>Matching Composition and Efficient Weight Reduction in Dynamic Matching</title>
      <link>https://arxiv.org/abs/2410.18936</link>
      <description>arXiv:2410.18936v1 Announce Type: new 
Abstract: We consider the foundational problem of maintaining a $(1-\varepsilon)$-approximate maximum weight matching (MWM) in an $n$-node dynamic graph undergoing edge insertions and deletions. We provide a general reduction that reduces the problem on graphs with a weight range of $\mathrm{poly}(n)$ to $\mathrm{poly}(1/\varepsilon)$ at the cost of just an additive $\mathrm{poly}(1/\varepsilon)$ in update time. This improves upon the prior reduction of Gupta-Peng (FOCS 2013) which reduces the problem to a weight range of $\varepsilon^{-O(1/\varepsilon)}$ with a multiplicative cost of $O(\log n)$.
  When combined with a reduction of Bernstein-Dudeja-Langley (STOC 2021) this yields a reduction from dynamic $(1-\varepsilon)$-approximate MWM in bipartite graphs with a weight range of $\mathrm{poly}(n)$ to dynamic $(1-\varepsilon)$-approximate maximum cardinality matching in bipartite graphs at the cost of a multiplicative $\mathrm{poly}(1/\varepsilon)$ in update time, thereby resolving an open problem in [GP'13; BDL'21]. Additionally, we show that our approach is amenable to MWM problems in streaming, shared-memory work-depth, and massively parallel computation models. We also apply our techniques to obtain an efficient dynamic algorithm for rounding weighted fractional matchings in general graphs. Underlying our framework is a new structural result about MWM that we call the "matching composition lemma" and new dynamic matching subroutines that may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.18936v1</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aaron Bernstein, Jiale Chen, Aditi Dudeja, Zachary Langley, Aaron Sidford, Ta-Wei Tu</dc:creator>
    </item>
    <item>
      <title>Quantum linear system algorithm with optimal queries to initial state preparation</title>
      <link>https://arxiv.org/abs/2410.18178</link>
      <description>arXiv:2410.18178v1 Announce Type: cross 
Abstract: Quantum algorithms for linear systems produce the solution state $A^{-1}|b\rangle$ by querying two oracles: $O_A$ that block encodes the coefficient matrix and $O_b$ that prepares the initial state. We present a quantum linear system algorithm making $\mathbf{\Theta}\left(1/\sqrt{p}\right)$ queries to $O_b$, which is optimal in the success probability, and $\mathbf{O}\left(\kappa\log\left(1/p\right)\left(\log\log\left(1/p\right)+\log\left({1}/{\epsilon}\right)\right)\right)$ queries to $O_A$, nearly optimal in all parameters including the condition number and accuracy. Notably, our complexity scaling of initial state preparation holds even when $p$ is not known $\textit{a priori}$. This contrasts with recent results achieving $\mathbf{O}\left(\kappa\log\left({1}/{\epsilon}\right)\right)$ complexity to both oracles, which, while optimal in $O_A$, is highly suboptimal in $O_b$ as $\kappa$ can be arbitrarily larger than $1/\sqrt{p}$. In various applications such as solving differential equations, preparing ground states of operators with real spectra, and estimating and transforming eigenvalues of non-normal matrices, we can further improve the dependence on $p$ using a block preconditioning scheme to nearly match or outperform best previous results based on other methods, which also furnishes an extremely simple quantum linear system algorithm with an optimal query complexity to $O_A$. Underlying our results is a new Variable Time Amplitude Amplification algorithm with Tunable thresholds (Tunable VTAA), which fully characterizes generic nested amplitude amplifications, improves the $\ell_1$-norm input cost scaling of Ambainis to an $\ell_{\frac{2}{3}}$-quasinorm scaling, and admits a deterministic amplification schedule for the quantum linear system problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.18178v1</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guang Hao Low, Yuan Su</dc:creator>
    </item>
    <item>
      <title>Locally seeded embeddings, and Ramsey numbers of bipartite graphs with sublinear bandwidth</title>
      <link>https://arxiv.org/abs/2410.18223</link>
      <description>arXiv:2410.18223v1 Announce Type: cross 
Abstract: A seminal result of Lee asserts that the Ramsey number of any bipartite $d$-degenerate graph $H$ satisfies $\log r(H) = \log n + O(d)$. In particular, this bound applies to every bipartite graph of maximal degree $\Delta$. It remains a compelling challenge to identify conditions that guarantee that an $n$-vertex graph $H$ has Ramsey number linear in $n$, independently of $\Delta$. Our contribution is a characterization of bipartite graphs with linear-size Ramsey numbers in terms of graph bandwidth, a notion of local connectivity. We prove that for any $n$-vertex bipartite graph $H$ with maximal degree at most $\Delta$ and bandwidth $b(H)$ at most $\exp(-C\Delta\log\Delta)\,n$, we have $\log r(H) = \log n + O(1)$. This characterization is nearly optimal: for every $\Delta$ there exists an $n$-vertex bipartite graph $H$ of degree at most $\Delta$ and $b(H) \leq \exp(-c\Delta)\,n$, such that $\log r(H) = \log n + \Omega(\Delta)$. We also provide bounds interpolating between these two bandwidth regimes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.18223v1</guid>
      <category>math.CO</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dylan J. Altschuler, Han Huang, Konstantin Tikhomirov</dc:creator>
    </item>
    <item>
      <title>How to Design a Quantum Streaming Algorithm Without Knowing Anything About Quantum Computing</title>
      <link>https://arxiv.org/abs/2410.18922</link>
      <description>arXiv:2410.18922v1 Announce Type: cross 
Abstract: A series of work [GKK+08, Kal22, KPV24] has shown that asymptotic advantages in space complexity are possible for quantum algorithms over their classical counterparts in the streaming model. We give a simple quantum sketch that encompasses all these results, allowing them to be derived from entirely classical algorithms using our quantum sketch as a black box. The quantum sketch and its proof of correctness are designed to be accessible to a reader with no background in quantum computation, relying on only a small number of self-contained quantum postulates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.18922v1</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>John Kallaugher, Ojas Parekh, Nadezhda Voronova</dc:creator>
    </item>
    <item>
      <title>Learning $k$-body Hamiltonians via compressed sensing</title>
      <link>https://arxiv.org/abs/2410.18928</link>
      <description>arXiv:2410.18928v1 Announce Type: cross 
Abstract: We study the problem of learning a $k$-body Hamiltonian with $M$ unknown Pauli terms that are not necessarily geometrically local. We propose a protocol that learns the Hamiltonian to precision $\epsilon$ with total evolution time ${\mathcal{O}}(M^{1/2+1/p}/\epsilon)$ up to logarithmic factors, where the error is quantified by the $\ell^p$-distance between Pauli coefficients. Our learning protocol uses only single-qubit control operations and a GHZ state initial state, is non-adaptive, is robust against SPAM errors, and performs well even if $M$ and $k$ are not precisely known in advance or if the Hamiltonian is not exactly $M$-sparse. Methods from the classical theory of compressed sensing are used for efficiently identifying the $M$ terms in the Hamiltonian from among all possible $k$-body Pauli operators. We also provide a lower bound on the total evolution time needed in this learning task, and we discuss the operational interpretations of the $\ell^1$ and $\ell^2$ error metrics. In contrast to previous works, our learning protocol requires neither geometric locality nor any other relaxed locality conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.18928v1</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Muzhou Ma, Steven T. Flammia, John Preskill, Yu Tong</dc:creator>
    </item>
    <item>
      <title>Language Edit Distance &amp; Scored Parsing: Faster Algorithms &amp; Connection to Fundamental Graph Problems</title>
      <link>https://arxiv.org/abs/1411.7315</link>
      <description>arXiv:1411.7315v4 Announce Type: replace 
Abstract: Given a context free language $\mathcal{L(G)}$ over alphabet $\Sigma$ and a string $s \in \Sigma^*$, {\em the language edit distance} problem seeks the minimum number of edits (insertions, deletions and substitutions) required to convert $s$ into a valid member of $\mathcal{L(G)}$. The well-known dynamic programming algorithm solves this problem in $O(n^3)$ time (ignoring grammar size) where $n$ is the string length [Aho, Peterson 1972, Myers 1985]. Despite its numerous applications, to date there exists no algorithm that computes exact or approximate language edit distance problem in true subcubic time.
  In this paper we give the first such algorithm that approximates language edit distance in subcubic time. For any arbitrary $\epsilon &gt; 0$, our algorithm runs in $\tilde{O}(\frac{n^{2.491}}{\epsilon^2})$ time and returns an estimate within a multiplicative approximation factor of $(1+\epsilon)$. Moreover, an additive $\epsilon n$ approximation can be computed in $O(\frac{n^2}{\epsilon^{0.825}})$ time.
  To complement our upper bound results, we show that exact computation of language edit distance with insertion-only edits in truly subcubic time will imply a truly subcubic algorithm for all-pairs shortest paths which is a long-standing open question in computer science.</description>
      <guid isPermaLink="false">oai:arXiv.org:1411.7315v4</guid>
      <category>cs.DS</category>
      <category>cs.FL</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tomasz Kociumaka, Barna Saha</dc:creator>
    </item>
    <item>
      <title>Accelerating ERM for data-driven algorithm design using output-sensitive techniques</title>
      <link>https://arxiv.org/abs/2204.03569</link>
      <description>arXiv:2204.03569v3 Announce Type: replace 
Abstract: Data-driven algorithm design is a promising, learning-based approach for beyond worst-case analysis of algorithms with tunable parameters. An important open problem is the design of computationally efficient data-driven algorithms for combinatorial algorithm families with multiple parameters. As one fixes the problem instance and varies the parameters, the "dual" loss function typically has a piecewise-decomposable structure, i.e. is well-behaved except at certain sharp transition boundaries. In this work we initiate the study of techniques to develop efficient ERM learning algorithms for data-driven algorithm design by enumerating the pieces of the sum dual loss functions for a collection of problem instances. The running time of our approach scales with the actual number of pieces that appear as opposed to worst case upper bounds on the number of pieces. Our approach involves two novel ingredients -- an output-sensitive algorithm for enumerating polytopes induced by a set of hyperplanes using tools from computational geometry, and an execution graph which compactly represents all the states the algorithm could attain for all possible parameter values. We illustrate our techniques by giving algorithms for pricing problems, linkage-based clustering and dynamic-programming based sequence alignment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2204.03569v3</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maria-Florina Balcan, Christopher Seiler, Dravyansh Sharma</dc:creator>
    </item>
    <item>
      <title>Maximizing a Submodular Function with Bounded Curvature under an Unknown Knapsack Constraint</title>
      <link>https://arxiv.org/abs/2209.09668</link>
      <description>arXiv:2209.09668v3 Announce Type: replace 
Abstract: This paper studies the problem of maximizing a monotone submodular function under an unknown knapsack constraint. A solution to this problem is a policy that decides which item to pack next based on the past packing history. The robustness factor of a policy is the worst case ratio of the solution obtained by following the policy and an optimal solution that knows the knapsack capacity. We develop a policy with a robustness factor that is decreasing in the curvature $c$ of the submodular function. For the extreme cases $c=0$ corresponding to an additive objective function, it matches a previously known and best possible robustness factor of $1/2$. For the other extreme case of $c=1$ it yields a robustness factor of $\approx 0.35$ improving over the best previously known robustness factor of $\approx 0.06$.
  The analysis of our policy relies on a greedy algorithm that is a slight modification of Wolsey's greedy algorithm for the submodular knapsack problem with a known knapsack constraint. We obtain tight approximation guarantees for both of these algorithms in the setting of a submodular objective function with curvature $c$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.09668v3</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Max Klimm, Martin Knaack</dc:creator>
    </item>
    <item>
      <title>Near-optimal hierarchical matrix approximation from matrix-vector products</title>
      <link>https://arxiv.org/abs/2407.04686</link>
      <description>arXiv:2407.04686v2 Announce Type: replace 
Abstract: We describe a randomized algorithm for producing a near-optimal hierarchical off-diagonal low-rank (HODLR) approximation to an $n\times n$ matrix $\mathbf{A}$, accessible only though matrix-vector products with $\mathbf{A}$ and $\mathbf{A}^{\mathsf{T}}$. We prove that, for the rank-$k$ HODLR approximation problem, our method achieves a $(1+\beta)^{\log(n)}$-optimal approximation in expected Frobenius norm using $O(k\log(n)/\beta^3)$ matrix-vector products. In particular, the algorithm obtains a $(1+\varepsilon)$-optimal approximation with $O(k\log^4(n)/\varepsilon^3)$ matrix-vector products, and for any constant $c$, an $n^c$-optimal approximation with $O(k \log(n))$ matrix-vector products. Apart from matrix-vector products, the additional computational cost of our method is just $O(n \operatorname{poly}(\log(n), k, \beta))$. We complement the upper bound with a lower bound, which shows that any matrix-vector query algorithm requires at least $\Omega(k\log(n) + k/\varepsilon)$ queries to obtain a $(1+\varepsilon)$-optimal approximation.
  Our algorithm can be viewed as a robust version of widely used "peeling" methods for recovering HODLR matrices and is, to the best of our knowledge, the first matrix-vector query algorithm to enjoy theoretical worst-case guarantees for approximation by any hierarchical matrix class. To control the propagation of error between levels of hierarchical approximation, we introduce a new perturbation bound for low-rank approximation, which shows that the widely used Generalized Nystr\"om method enjoys inherent stability when implemented with noisy matrix-vector products. We also introduce a novel randomly perforated matrix sketching method to further control the error in the peeling algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04686v2</guid>
      <category>cs.DS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>SIAM Symposium on Discrete Algorithms (SODA 2025)</arxiv:journal_reference>
      <dc:creator>Tyler Chen, Feyza Duman Keles, Diana Halikias, Cameron Musco, Christopher Musco, David Persson</dc:creator>
    </item>
    <item>
      <title>Tight Bounds and Phase Transitions for Incremental and Dynamic Retrieval</title>
      <link>https://arxiv.org/abs/2410.10002</link>
      <description>arXiv:2410.10002v2 Announce Type: replace 
Abstract: Retrieval data structures are data structures that answer key-value queries without paying the space overhead of explicitly storing keys. The problem can be formulated in four settings (static, value-dynamic, incremental, or dynamic), each of which offers different levels of dynamism to the user. In this paper, we establish optimal bounds for the final two settings (incremental and dynamic) in the case of a polynomial universe. Our results complete a line of work that has spanned more than two decades, and also come with a surprise: the incremental setting, which has long been viewed as essentially equivalent to the dynamic one, actually has a phase transition, in which, as the value size $v$ approaches $\log n$, the optimal space redundancy actually begins to shrink, going from roughly $n \log \log n$ (which has long been thought to be optimal) all the way down to $\Theta(n)$ (which is the optimal bound even for the seemingly much-easier value-dynamic setting).</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10002v2</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>William Kuszmaul, Aaron Putterman, Tingqiang Xu, Hangrui Zhou, Renfei Zhou</dc:creator>
    </item>
    <item>
      <title>Bidirectional Dijkstra's Algorithm is Instance-Optimal</title>
      <link>https://arxiv.org/abs/2410.14638</link>
      <description>arXiv:2410.14638v2 Announce Type: replace 
Abstract: While Dijkstra's algorithm has near-optimal time complexity for the problem of finding the shortest $st$-path, in practice, other algorithms are often superior on huge graphs. A prominent such example is the bidirectional search, which executes Dijkstra's algorithm from both endpoints in parallel and stops when these executions meet.
  In this paper, we give a strong theoretical justification for the use of such bidirectional search algorithms. We prove that for weighted multigraphs, both directed and undirected, a careful implementation of bidirectional search is instance-optimal with respect to the number of edges it explores. That is, we prove that no correct algorithm can outperform our implementation of bidirectional search on any single instance by more than a constant factor. For unweighted graphs, we show that bidirectional search is instace-optimal up to a factor of $O(\Delta)$ where $\Delta$ is the maximum degree of the graph. We also show that this is the best possible.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14638v2</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bernhard Haeupler, Richard Hlad\'ik, Vaclav Rozhon, Robert E. Tarjan, Jakub T\v{e}tek</dc:creator>
    </item>
    <item>
      <title>Tight Bounds on the Message Complexity of Distributed Tree Verification</title>
      <link>https://arxiv.org/abs/2401.11991</link>
      <description>arXiv:2401.11991v2 Announce Type: replace-cross 
Abstract: We consider the message complexity of verifying whether a given subgraph of the communication network forms a tree with specific properties both in the KT-$\rho$ (nodes know their $\rho$-hop neighborhood, including node IDs) and the KT-$0$ (nodes do not have this knowledge) models. We develop a rather general framework that helps in establishing tight lower bounds for various tree verification problems. We also consider two different verification requirements: namely that every node detects in the case the input is incorrect, as well as the requirement that at least one node detects. The results are stronger than previous ones in the sense that we assume that each node knows the number $n$ of nodes in the graph (in some cases) or an $\alpha$ approximation of $n$ (in other cases). For spanning tree verification, we show that the message complexity inherently depends on the quality of the given approximation of $n$: We show a tight lower bound of $\Omega(n^2)$ for the case $\alpha \ge \sqrt{2}$ and a much better upper bound (i.e., $O(n \log n)$) when nodes are given a tighter approximation. On the other hand, our framework also yields an $\Omega(n^2)$ lower bound on the message complexity of verifying a minimum spanning tree (MST), which reveals a polynomial separation between ST verification and MST verification. This result holds for randomized algorithms with perfect knowledge of the network size, and even when just one node detects illegal inputs, thus improving over the work of Kor, Korman, and Peleg (2013). For verifying a $d$-approximate BFS tree, we show that the same lower bound holds even if nodes know $n$ exactly, however, the lower bound is sensitive to $d$, which is the stretch parameter.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.11991v2</guid>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shay Kutten, Peter Robinson, Ming Ming Tan</dc:creator>
    </item>
    <item>
      <title>Strongly-polynomial time and validation analysis of policy gradient methods</title>
      <link>https://arxiv.org/abs/2409.19437</link>
      <description>arXiv:2409.19437v2 Announce Type: replace-cross 
Abstract: This paper proposes a novel termination criterion, termed the advantage gap function, for finite state and action Markov decision processes (MDP) and reinforcement learning (RL). By incorporating this advantage gap function into the design of step size rules and deriving a new linear rate of convergence that is independent of the stationary state distribution of the optimal policy, we demonstrate that policy gradient methods can solve MDPs in strongly-polynomial time. To the best of our knowledge, this is the first time that such strong convergence properties have been established for policy gradient methods. Moreover, in the stochastic setting, where only stochastic estimates of policy gradients are available, we show that the advantage gap function provides close approximations of the optimality gap for each individual state and exhibits a sublinear rate of convergence at every state. The advantage gap function can be easily estimated in the stochastic case, and when coupled with easily computable upper bounds on policy values, they provide a convenient way to validate the solutions generated by policy gradient methods. Therefore, our developments offer a principled and computable measure of optimality for RL, whereas current practice tends to rely on algorithm-to-algorithm or baselines comparisons with no certificate of optimality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19437v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Fri, 25 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Caleb Ju, Guanghui Lan</dc:creator>
    </item>
  </channel>
</rss>
