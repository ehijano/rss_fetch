<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 18 Sep 2025 04:00:09 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 18 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>GTA -- An ATSP Method: Shifting the Bottleneck from Algorithm to RAM</title>
      <link>https://arxiv.org/abs/2509.13327</link>
      <description>arXiv:2509.13327v1 Announce Type: new 
Abstract: We present a scalable, high-performance algorithm that deterministically solves large-scale instances of the Traveling Salesman problem (in its asymmetric version, ATSP) to optimality using commercially available computing hardware. By combining an efficient heuristic warm start, capable of achieving near-optimality within seconds in some cases, with a subtour elimination strategy that removes the need for traditional MTZ constraints, our approach consistently resolves instances up to 5,000 nodes (approximately 25 million binary variables) in record time on widely accessible computers, with eight logical processors. We demonstrate reproducible results with convergence rates comparable to those of high-performance computing frameworks. Real-time iteration tracking and an adaptable interface allow seamless integration into scheduling workflows in logistics, bioinformatics, and astronomy. Designed to streamline solutions to large-scale TSP problems across disciplines, our approach is benchmarked against widely used public datasets, offering a deterministic, resource-efficient alternative to conventional solvers that rely on supercomputing hardware. Our GTA (Gurobi Tabu Algorithm) algorithm is a fundamental shift of TSP solution bottleneck from algorithmic complexity to the underlying hardware (RAM and system memory), which is a highly desirable characteristic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.13327v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 18 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wissam Nakhle</dc:creator>
    </item>
    <item>
      <title>Hardness of Dynamic Core and Truss Decompositions</title>
      <link>https://arxiv.org/abs/2509.13584</link>
      <description>arXiv:2509.13584v1 Announce Type: new 
Abstract: The k-core of a graph is its maximal subgraph with minimum degree at least k, and the core value of a vertex u is the largest k for which u is contained in the k-core of the graph. Among cohesive subgraphs, k-core and its variants have received a lot of attention recently, particularly on dynamic graphs, as reported by Hanauer, Henzinger, and Schulz in their recent survey on dynamic graph algorithms. We answer questions on k-core stated in the survey, proving that there is no efficient dynamic algorithm for k-core or to find (2 - {\epsilon})-approximations for the core values, unless we can improve decade-long state-of-the-art algorithms in many areas including matrix multiplication and satisfiability, based on the established OMv and SETH conjectures. Some of our results show that there is no dynamic algorithm for k-core asymptotically faster than the trivial ones. This explains why most recent research papers in this area focus not on a generic efficient dynamic algorithm, but on finding a bounded algorithm, which is fast when few core values change per update. However, we also prove that such bounded algorithms do not exist, based on the OMv conjecture. We present lower bounds also for a directed version of the problem, and for the edge variant of the problem, known as k-truss. On the positive side, we present a polylogarithmic dynamic algorithm for 2-core.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.13584v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Thu, 18 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yan S. Couto, Cristina G. Fernandes</dc:creator>
    </item>
    <item>
      <title>On Solving Asymmetric Diagonally Dominant Linear Systems in Sublinear Time</title>
      <link>https://arxiv.org/abs/2509.13891</link>
      <description>arXiv:2509.13891v1 Announce Type: new 
Abstract: We initiate a study of solving a row/column diagonally dominant (RDD/CDD) linear system $Mx=b$ in sublinear time, with the goal of estimating $t^{\top}x^*$ for a given vector $t\in R^n$ and a specific solution $x^*$. This setting naturally generalizes the study of sublinear-time solvers for symmetric diagonally dominant (SDD) systems [AKP19] to the asymmetric case.
  Our first contributions are characterizations of the problem's mathematical structure. We express a solution $x^*$ via a Neumann series, prove its convergence, and upper bound the truncation error on this series through a novel quantity of $M$, termed the maximum $p$-norm gap. This quantity generalizes the spectral gap of symmetric matrices and captures how the structure of $M$ governs the problem's computational difficulty.
  For systems with bounded maximum $p$-norm gap, we develop a collection of algorithmic results for locally approximating $t^{\top}x^*$ under various scenarios and error measures. We derive these results by adapting the techniques of random-walk sampling, local push, and their bidirectional combination, which have proved powerful for special cases of solving RDD/CDD systems, particularly estimating PageRank and effective resistance on graphs. Our general framework yields deeper insights, extended results, and improved complexity bounds for these problems. Notably, our perspective provides a unified understanding of Forward Push and Backward Push, two fundamental approaches for estimating random-walk probabilities on graphs.
  Our framework also inherits the hardness results for sublinear-time SDD solvers and local PageRank computation, establishing lower bounds on the maximum $p$-norm gap or the accuracy parameter. We hope that our work opens the door for further study into sublinear solvers, local graph algorithms, and directed spectral graph theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.13891v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 18 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tsz Chiu Kwok, Zhewei Wei, Mingji Yang</dc:creator>
    </item>
    <item>
      <title>Outperforming Dijkstra on Sparse Graphs: The Lightning Network Use Case</title>
      <link>https://arxiv.org/abs/2509.13448</link>
      <description>arXiv:2509.13448v1 Announce Type: cross 
Abstract: Efficient routing is critical for payment channel networks (PCNs) such as the Lightning Network (LN), where most clients currently rely on Dijkstra-based algorithms for payment pathfinding. While Dijkstra's algorithm has long been regarded as optimal on sparse graphs, recent theoretical work challenges this view. The new Bounded Multi-Source Shortest Path (BMSSP) algorithm by Duan et al. theoretically achieves $O(m~log^{2/3}~n)$ runtime, which is asymptotically faster than Dijkstra's $O(m + n~log~n)$ on sparse directed graphs. In this paper, we implement BMSSP on Rust and compare its performance against Dijkstra's using real LN topology data. Our evaluation, based on multiple randomized trials and statistical tests, shows that current implementations of BMSSP do not significantly outperform Dijkstra's in practice, and speedups are smaller than what theory predicts, possibly due to implementation and constant factor overheads. These results provide the first empirical evidence of BMSSP's potential to accelerate LN routing and inform future optimizations of PCN pathfinding algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.13448v1</guid>
      <category>cs.PF</category>
      <category>cs.DS</category>
      <category>cs.SI</category>
      <pubDate>Thu, 18 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Danila Valko, Rohan Paranjpe, Jorge Marx G\'omez</dc:creator>
    </item>
    <item>
      <title>Smaller Circuits for Bit Addition</title>
      <link>https://arxiv.org/abs/2509.13966</link>
      <description>arXiv:2509.13966v1 Announce Type: cross 
Abstract: Bit addition arises virtually everywhere in digital circuits: arithmetic operations, increment/decrement operators, computing addresses and table indices, and so on. Since bit addition is such a basic task in Boolean circuit synthesis, a lot of research has been done on constructing efficient circuits for various special cases of it. A vast majority of these results are devoted to optimizing the circuit depth (also known as delay).
  In this paper, we investigate the circuit size (also known as area) over the full binary basis of bit addition. Though most of the known circuits are built from Half Adders and Full Adders, we show that, in many interesting scenarios, these circuits have suboptimal size. Namely, we improve an upper bound $5n-3m$ to $4.5n-2m$, where $n$ is the number of input bits and $m$ is the number of output bits. In the regimes where $m$ is small compared to $n$ (for example, for computing the sum of $n$ bits or multiplying two $n$-bit integers), this leads to $10\%$ improvement.
  We complement our theoretical result by an open-source implementation of generators producing circuits for bit addition and multiplication. The generators allow one to produce the corresponding circuits in two lines of code and to compare them to existing designs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.13966v1</guid>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>cs.LO</category>
      <pubDate>Thu, 18 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mikhail Goncharov, Alexander S. Kulikov, Georgie Levtsov</dc:creator>
    </item>
    <item>
      <title>Algorithms for Optimizing Acyclic Queries</title>
      <link>https://arxiv.org/abs/2509.14144</link>
      <description>arXiv:2509.14144v1 Announce Type: cross 
Abstract: Most research on query optimization has centered on binary join algorithms like hash join and sort-merge join. However, recent years have seen growing interest in theoretically optimal algorithms, notably Yannakakis' algorithm. These algorithms rely on join trees, which differ from the operator trees for binary joins and require new optimization techniques. We propose three approaches to constructing join trees for acyclic queries. First, we give an algorithm to enumerate all join trees of an alpha-acyclic query by edits with amortized constant delay, which forms the basis of a cost-based optimizer for acyclic joins. Second, we show that the Maximum Cardinality Search algorithm by Tarjan and Yannakakis constructs a unique shallowest join tree, rooted at any relation, for a Berge-acyclic query; this tree enables parallel execution of large join queries. Finally, we prove that any connected left-deep linear plan for a gamma-acyclic query can be converted into a join tree by a simple algorithm, allowing reuse of optimization infrastructure developed for binary joins.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14144v1</guid>
      <category>cs.DB</category>
      <category>cs.DS</category>
      <pubDate>Thu, 18 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zheng Luo, Wim Van den Broeck, Guy Van den Broeck, Yisu Remy Wang</dc:creator>
    </item>
    <item>
      <title>Parameterized Maximum Node-Disjoint Paths</title>
      <link>https://arxiv.org/abs/2404.14849</link>
      <description>arXiv:2404.14849v2 Announce Type: replace 
Abstract: We revisit the Maximum Node-Disjoint Paths problem, the natural optimization version of Node-Disjoint Paths, where we are given a graph $G$, $k$ pairs of vertices $(s_i, t_i)$ and an integer $\ell$, and are asked whether there exist at least $\ell$ vertex-disjoint paths in $G$ whose endpoints are given pairs. We present several results, with an emphasis towards FPT approximation.
  Our main positive contribution is to show that the problem's intractability can be overcome using approximation and that for several of the structural parameters for which the problem is hard, most notably tree-depth, it admits an efficient FPT approximation scheme, returning a $(1-\varepsilon)$-approximate solution in time $f(td,\varepsilon)n^{O(1)}$. We manage to obtain these results by comprehensively mapping out the structural parameters for which the problem is FPT if $\ell$ is also a parameter, hence showing that understanding $\ell$ as a parameter is key to the problem's approximability. This, in turn, is a problem we are able to solve via a surprisingly simple color-coding algorithm, which relies on identifying an insightful problem-specific variant of the natural parameter, namely the number of vertices used in the solution.
  A natural question is whether the FPT approximation algorithm we devised for tree-depth can be extended to pathwidth. We resolve this negatively, showing that under the Parameterized Inapproximability Hypothesis no FPT approximation scheme for this parameter is possible, even in time $f(pw,\varepsilon)n^{g(\varepsilon)}$, thus precisely determining the parameter border where the problem transitions from ``hard but approximable'' to ``inapproximable''.
  Lastly, we strengthen existing lower bounds by replacing W[1]-hardness by XNLP-completeness for parameter pathwidth, and improving the $n^{o(\sqrt{td})}$ ETH-based lower bound for tree-depth to $n^{o(td)}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.14849v2</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Thu, 18 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael Lampis, Manolis Vasilakis</dc:creator>
    </item>
    <item>
      <title>Deterministic Algorithm and Faster Algorithm for Submodular Maximization subject to a Matroid Constraint</title>
      <link>https://arxiv.org/abs/2408.03583</link>
      <description>arXiv:2408.03583v3 Announce Type: replace 
Abstract: We study the problem of maximizing a monotone submodular function subject to a matroid constraint, and present for it a deterministic non-oblivious local search algorithm that has an approximation guarantee of $1 - 1/e - \varepsilon$ (for any $\varepsilon &gt; 0$) and query complexity of $\tilde{O}_\varepsilon(nr)$, where $n$ is the size of the ground set and $r$ is the rank of the matroid. Our algorithm vastly improves over the previous state-of-the-art $0.5008$-approximation deterministic algorithm, and in fact, shows that there is no separation between the approximation guarantees that can be obtained by deterministic and randomized algorithms for the problem considered. The query complexity of our algorithm can be improved to $\tilde{O}_\varepsilon(n + r\sqrt{n})$ using randomization, which is nearly-linear for $r = O(\sqrt{n})$, and is always at least as good as the previous state-of-the-art algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.03583v3</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <pubDate>Thu, 18 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Niv Buchbinder, Moran Feldman</dc:creator>
    </item>
    <item>
      <title>An Optimal Algorithm for the Stacker Crane Problem on Fixed Topologies</title>
      <link>https://arxiv.org/abs/2410.06764</link>
      <description>arXiv:2410.06764v2 Announce Type: replace 
Abstract: The Stacker Crane Problem (SCP) is a variant of the Traveling Salesman Problem. In SCP, pairs of pickup and delivery points are designated on a graph, and a crane must visit these points to move objects from each pickup location to its respective delivery point. The goal is to minimize the total distance traveled. SCP is known to be NP-hard, even on trees. The only positive results, in terms of polynomial-time solvability, apply to graphs that are topologically equivalent to a path or a cycle.
  We propose an algorithm that is optimal for each fixed topology, running in near-linear time. This is achieved by demonstrating that the problem is fixed-parameter tractable (FPT) when parameterized by both the cycle rank and the number of branch vertices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06764v2</guid>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Thu, 18 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yike Chen, Ke Shi, Chao Xu</dc:creator>
    </item>
    <item>
      <title>Cut-Query Algorithms with Few Rounds</title>
      <link>https://arxiv.org/abs/2506.20412</link>
      <description>arXiv:2506.20412v2 Announce Type: replace 
Abstract: In the cut-query model, the algorithm can access the input graph $G=(V,E)$ only via cut queries that report, given a set $S\subseteq V$, the total weight of edges crossing the cut between $S$ and $V\setminus S$. This model was introduced by Rubinstein, Schramm and Weinberg [ITCS'18] and its investigation has so far focused on the number of queries needed to solve optimization problems, such as global minimum cut. We turn attention to the round complexity of cut-query algorithms, and show that several classical problems can be solved in this model with only a constant number of rounds.
  Our main results are algorithms for finding a minimum cut in a graph, that offer different tradeoffs between round complexity and query complexity, where $n=|V|$ and $\delta(G)$ denotes the minimum degree of $G$: (i) $\tilde{O}(n^{4/3})$ cut queries in two rounds in unweighted graphs; (ii) $\tilde{O}(rn^{1+1/r}/\delta(G)^{1/r})$ queries in $2r+1$ rounds for any integer $r\ge 1$ again in unweighted graphs; and (iii) $\tilde{O}(rn^{1+(1+\log_n W)/r})$ queries in $4r+3$ rounds for any $r\ge1$ in weighted graphs. We also provide algorithms that find a minimum $(s,t)$-cut and approximate the maximum cut in a few rounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.20412v2</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 18 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yotam Kenneth-Mordoch, Robert Krauthgamer</dc:creator>
    </item>
    <item>
      <title>Pathfinding in Self-Deleting Graphs</title>
      <link>https://arxiv.org/abs/2507.12047</link>
      <description>arXiv:2507.12047v2 Announce Type: replace 
Abstract: In this paper, we study the problem of pathfinding on traversal-dependent graphs, i.e., graphs whose edges change depending on the previously visited vertices. In particular, we study \emph{self-deleting graphs}, introduced by Carmesin et al. (Sarah Carmesin, David Woller, David Parker, Miroslav Kulich, and Masoumeh Mansouri. The Hamiltonian cycle and travelling salesperson problems with traversal-dependent edge deletion. J. Comput. Sci.), which consist of a graph $G=(V, E)$ and a function $f\colon V\rightarrow 2^E$, where $f(v)$ is the set of edges that will be deleted after visiting the vertex $v$. In the \textsc{(Shortest) Self-Deleting $s$-$t$-path} problem we are given a self-deleting graph and its vertices $s$ and $t$, and we are asked to find a (shortest) path from $s$ to $t$, such that it does not traverse an edge in $f(v)$ after visiting $v$ for any vertex $v$.
  We prove that \textsc{Self-Deleting $s$-$t$-path} is NP-hard even if the given graph is outerplanar, bipartite, has maximum degree $3$, bandwidth $2$ and $|f(v)|\leq 1$ for each vertex $v$. We show that \textsc{Shortest Self-Deleting $s$-$t$-path} is W[1]-complete parameterized by the length of the sought path and that \textsc{Self-Deleting $s$-$t$-path} is \W{1}-complete parameterized by the vertex cover number, feedback vertex set number and treedepth. We also show that the problem becomes FPT when we parameterize by the maximum size of $f(v)$ and several structural parameters. Lastly, we show that the problem does not admit a polynomial kernel even for parameterization by the vertex cover number and the maximum size of $f(v)$ combined already on 2-outerplanar graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.12047v2</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 18 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4230/LIPIcs.ISAAC.2025.19</arxiv:DOI>
      <arxiv:journal_reference>36th International Symposium on Algorithms and Computation (ISAAC 2025). Article No. 19; pp. 19:1--19:15; LIPIcs vol. 359, Dagstuhl Publishing, Germany</arxiv:journal_reference>
      <dc:creator>Michal Dvo\v{r}\'ak, Du\v{s}an Knop, Michal Opler, Jan Pokorn\'y, Ond\v{r}ej Such\'y, Krisztina Szil\'agyi</dc:creator>
    </item>
    <item>
      <title>On estimating the trace of quantum state powers</title>
      <link>https://arxiv.org/abs/2410.13559</link>
      <description>arXiv:2410.13559v3 Announce Type: replace-cross 
Abstract: We investigate the computational complexity of estimating the trace of quantum state powers $\text{tr}(\rho^q)$ for an $n$-qubit mixed quantum state $\rho$, given its state-preparation circuit of size $\text{poly}(n)$. This quantity is closely related to and often interchangeable with the Tsallis entropy $\text{S}_q(\rho) = \frac{1-\text{tr}(\rho^q)}{q-1}$, where $q = 1$ corresponds to the von Neumann entropy. For any non-integer $q \geq 1 + \Omega(1)$, we provide a quantum estimator for $\text{S}_q(\rho)$ with time complexity $\text{poly}(n)$, exponentially improving the prior best results of $\exp(n)$ due to Acharya, Issa, Shende, and Wagner (ISIT 2019), Wang, Guan, Liu, Zhang, and Ying (TIT 2024), and Wang, Zhang, and Li (TIT 2024), and Wang and Zhang (ESA 2024). Our speedup is achieved by introducing efficiently computable uniform approximations of positive power functions into quantum singular value transformation.
  Our quantum algorithm reveals a sharp phase transition between the case of $q=1$ and constant $q&gt;1$ in the computational complexity of the Quantum $q$-Tsallis Entropy Difference Problem (TsallisQED$_q$), particularly deciding whether the difference $\text{S}_q(\rho_0) - \text{S}_q(\rho_1)$ is at least $0.001$ or at most $-0.001$:
  - For any $1+\Omega(1) \leq q \leq 2$, TsallisQED$_q$ is $\mathsf{BQP}$-complete, which implies that Purity Estimation is also $\mathsf{BQP}$-complete.
  - For any $1 \leq q \leq 1 + \frac{1}{n-1}$, TsallisQED$_q$ is $\mathsf{QSZK}$-hard, leading to hardness of approximating the von Neumann entropy because $\text{S}_q(\rho) \leq \text{S}(\rho)$, as long as $\mathsf{BQP} \subsetneq \mathsf{QSZK}$.
  The hardness results are derived from reductions based on new inequalities for the quantum $q$-Jensen-(Shannon-)Tsallis divergence with $1\leq q \leq 2$, which are of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.13559v3</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Thu, 18 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1137/1.9781611978322.28</arxiv:DOI>
      <arxiv:journal_reference>Proceedings of the 2025 Annual ACM-SIAM Symposium on Discrete Algorithms (SODA), pp. 947-993, 2025</arxiv:journal_reference>
      <dc:creator>Yupan Liu, Qisheng Wang</dc:creator>
    </item>
    <item>
      <title>Efficient Classical Sampling from Gaussian Boson Sampling Distributions on Unweighted Graphs</title>
      <link>https://arxiv.org/abs/2505.02445</link>
      <description>arXiv:2505.02445v2 Announce Type: replace-cross 
Abstract: Gaussian Boson Sampling (GBS) is a promising candidate for demonstrating quantum computational advantage and can be applied to solving graph-related problems. In this work, we propose Markov chain Monte Carlo-based algorithms to sample from GBS distributions on undirected, unweighted graphs. Our main contribution is a double-loop variant of Glauber dynamics, whose stationary distribution matches the GBS distribution. We further prove that it mixes in polynomial time for dense graphs using a refined canonical path argument. Numerically, we conduct experiments on unweighted graphs with 256 vertices, larger than the scales in former GBS experiments as well as classical simulations. In particular, we show that both the single-loop and double-loop Glauber dynamics improve the performance of original random search and simulated annealing algorithms for the max-Hafnian and densest $k$-subgraph problems up to 10$\times$. Overall, our approach offers both theoretical guarantees and practical advantages for efficient classical sampling from GBS distributions on unweighted graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02445v2</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <pubDate>Thu, 18 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yexin Zhang, Shuo Zhou, Xinzhao Wang, Ziruo Wang, Ziyi Yang, Rui Yang, Yecheng Xue, Tongyang Li</dc:creator>
    </item>
    <item>
      <title>Polynomial-Time Approximation Schemes via Utility Alignment: Unit-Demand Pricing and More</title>
      <link>https://arxiv.org/abs/2506.20030</link>
      <description>arXiv:2506.20030v2 Announce Type: replace-cross 
Abstract: This paper derives polynomial-time approximation schemes for several NP-hard stochastic optimization problems from the algorithmic mechanism design and operations research literatures. The problems we consider involve a principal or seller optimizing with respect to a subsequent choice by an agent or buyer. These include posted pricing for a unit-demand buyer with independent values (Chawla et al., 2007, Cai and Daskalakis, 2011), assortment optimization with independent utilities (Talluri and van Ryzin, 2004), and delegated choice (Khodabakhsh et al., 2024). Our results advance the state of the art for each of these problems. For unit-demand pricing with discrete distributions, our multiplicative PTAS improves on the additive PTAS of Cai and Daskalakis, and we additionally give a PTAS for the unbounded regular case, improving on the latter paper's QPTAS. For assortment optimization, no constant approximation was previously known. For delegated choice, we improve on both the $3$-approximation for the case with no outside option and the super-constant-approximation with an outside option.
  A key technical insight driving our results is an economically meaningful property we term utility alignment. Informally, a problem is utility aligned if, at optimality, the principal derives most of their utility from realizations where the agent's utility is also high. Utility alignment allows the algorithm designer to focus on maximizing performance on realizations with high agent utility, which is often an algorithmically simpler task. We prove utility alignment results for all the problems mentioned above, including strong results for unit-demand pricing and delegation, as well as a weaker but very broad guarantee that holds for many other problems under very mild conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.20030v2</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <pubDate>Thu, 18 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Robin Bowers, Marius Garbea, Emmanouil Pountourakis, Samuel Taggart</dc:creator>
    </item>
  </channel>
</rss>
