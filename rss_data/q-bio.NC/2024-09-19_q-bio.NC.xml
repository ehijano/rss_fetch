<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 20 Sep 2024 04:00:14 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 20 Sep 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Compensatory Mechanisms in Non-principal Multimedia Learning: The Interplay of Local and Global Information Processing</title>
      <link>https://arxiv.org/abs/2409.12593</link>
      <description>arXiv:2409.12593v1 Announce Type: new 
Abstract: Educational multimedia has become increasingly important in modern learning environments because of its cost-effectiveness and ability to overcome the temporal and spatial limitations of traditional methods. However, the complex cognitive processes involved in multimedia learning pose challenges in understanding its neural mechanisms. This study employs network neuroscience to investigate how multimedia design principles influence the underlying neural mechanisms by examining interactions among various brain regions. Two distinct multimedia programs were constructed using identical auditory content but differing visual designs: one adhered to five guidelines for optimizing multimedia instruction, referred to as principal multimedia, while the other intentionally violated these guidelines, referred to as non-principal multimedia. Cortical functional brain networks were then extracted from EEG data to evaluate local and global information processing across the two conditions. Network measurements revealed that principal networks exhibited more efficient local information processing, whereas non-principal networks demonstrated enhanced global information processing and hub formation. Network modularity analysis also indicated two distinct modular organizations, with modules in non-principal networks displaying higher integration and lower segregation than those in principal networks, aligning with initial findings. These observations suggest that the brain may employ compensatory mechanisms to enhance learning and manage cognitive load despite less effective instructional designs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.12593v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Fri, 20 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohammadhosein Ostadi Varnosfaderani, Masoumeh Golmohamadian, Alireza Bosaghzadeh, S. Hamid Amiri, Reza Ebrahimpour</dc:creator>
    </item>
    <item>
      <title>EEG-based Decoding of Selective Visual Attention in Superimposed Videos</title>
      <link>https://arxiv.org/abs/2409.12562</link>
      <description>arXiv:2409.12562v1 Announce Type: cross 
Abstract: Selective attention enables humans to efficiently process visual stimuli by enhancing important locations or objects and filtering out irrelevant information. Locating visual attention is a fundamental problem in neuroscience with potential applications in brain-computer interfaces. Conventional paradigms often use synthetic stimuli or static images, but visual stimuli in real life contain smooth and highly irregular dynamics. In this study, we show that these irregular dynamics in natural videos can be decoded from electroencephalography (EEG) signals to perform selective visual attention decoding. To this end, we propose an experimental paradigm in which participants attend to one of two superimposed videos, each showing a center-aligned person performing a stage act. We then train a stimulus-informed decoder to extract EEG signal components that are correlated with the motion patterns of the attended object, and show that this decoder can be used on unseen data to detect which of both objects is attended. Eye movements are also found to be correlated to the motion patterns in the attended video, despite the spatial overlap between the target and the distractor. We further show that these eye movements do not dominantly drive the EEG-based decoding and that complementary information exists in EEG and gaze data. Moreover, our results indicate that EEG also captures information about unattended objects. To our knowledge, this study is the first to explore EEG-based selective visual attention decoding on natural videos, opening new possibilities for experiment design in related fields.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.12562v1</guid>
      <category>eess.SP</category>
      <category>q-bio.NC</category>
      <pubDate>Fri, 20 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuanyuan Yao, Wout De Swaef, Simon Geirnaert, Alexander Bertrand</dc:creator>
    </item>
    <item>
      <title>How the (Tensor-) Brain uses Embeddings and Embodiment to Encode Senses and Decode Symbols</title>
      <link>https://arxiv.org/abs/2409.12846</link>
      <description>arXiv:2409.12846v1 Announce Type: cross 
Abstract: The tensor brain has been introduced as a computational model for perception and memory. We provide an overview of the tensor brain model, including recent developments. The tensor brain has two major layers: the representation layer and the index layer. The representation layer is a model for the subsymbolic global workspace from consciousness research. The state of the representation layer is the cognitive brain state. The index layer contains symbols for concepts, time instances, and predicates. In a bottom-up operation, the cognitive brain state is encoded by the index layer as symbolic labels. In a top-down operation, symbols are decoded and written to the representation layer. This feeds to earlier processing layers as embodiment. The top-down operation became the basis for semantic memory. The embedding vector of a concept forms the connection weights between its index and the representation layer. The embedding is the signature or ``DNA'' of a concept, which is decoded by the brain when its index is activated. It integrates all that is known about a concept from different experiences, modalities, and symbolic decodings. Although being computational, it has been suggested that the tensor brain might be related to the actual operation of the brain. The sequential nature of symbol generation might have been a prerequisite to the generation of natural language. We describe an attention mechanism and discuss multitasking by multiplexing. We emphasize the inherent multimodality of the tensor brain. Finally, we discuss embedded and symbolic reasoning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.12846v1</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <category>q-bio.NC</category>
      <pubDate>Fri, 20 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Volker Tresp, Hang Li</dc:creator>
    </item>
    <item>
      <title>The time is ripe to reverse engineer an entire nervous system: simulating behavior from neural interactions</title>
      <link>https://arxiv.org/abs/2308.06578</link>
      <description>arXiv:2308.06578v5 Announce Type: replace 
Abstract: Just like electrical engineers understand how microprocessors execute programs in terms of how transistor currents are affected by their inputs, neuroscientists want to understand behavior production in terms of how neuronal outputs are affected by their inputs and internal states. This dependency of neuronal outputs on inputs can be described by a state-dependent input-output (IO)-function. However, to reliably identify these IO-functions, we need to perturb each input and combinations of inputs while observing all the outputs. Here, we argue that such completeness is possible in C. elegans; a complete description that goes all the way from the activity of every neuron to predict behavior. The established and growing toolkit of optophysiology can non-invasively capture and control every neuron's activity and scale to countless experiments. The information from many such experiments can be pooled while capturing the inter-individual variability because neuronal identity and function are largely conserved across individuals. Just like electrical engineers use transistor IO-functions to simulate program execution, we argue that neuronal IO-functions could be used to simulate the impressive breadth of brain states and behaviors of C. elegans.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.06578v5</guid>
      <category>q-bio.NC</category>
      <pubDate>Fri, 20 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Gal Haspel (NJIT), Ben Baker (Colby College), Isabel Beets (KU Leuven), Edward S Boyden (MIT), Jeffrey Brown (MIT), George Church (Harvard University), Netta Cohen (University of Leeds), Daniel Colon-Ramos (Yale University), Eva Dyer (Georgia Institute of Technology), Christopher Fang-Yen (Ohio State University), Steven Flavell (MIT), Miriam B Goodman (Stanford University), Anne C Hart (Brown University), Eduardo J Izquierdo (Rose-Hulman Institute of Technology), Konstantinos Kagias (MIT), Shawn Lockery (University of Oregon), Yangning Lu (MIT), Adam Marblestone (Convergent Research), Jordan Matelsky (University of Pennsylvania), Brett Mensh (Optimize Science), Talmo D Pereira (Salk Institute), Hanspeter Pfister (Harvard University), Kanaka Rajan (Harvard Medical School), Horacio G Rotstein (NJIT), Monika Scholz (Max Planck Institute for Neurobiology of Behavior), Joshua W. Shaevitz (Princeton University), Eli Shlizerman (University of Washington), Quilee Simeon (MIT), Michael A Skuhersky (MIT), Vineet Tiruvadi (Hume AI), Vivek Venkatachalam (Northeastern University), Donglai Wei (Boston College), Brock Wester (Johns Hopkins APL), Guangyu Robert Yang (MIT), Eviatar Yemini (UMass), Manuel Zimmer (University of Vienna), Konrad P Kording (University of Pennsylvania)</dc:creator>
    </item>
    <item>
      <title>Cross-domain Fiber Cluster Shape Analysis for Language Performance Cognitive Score Prediction</title>
      <link>https://arxiv.org/abs/2403.19001</link>
      <description>arXiv:2403.19001v3 Announce Type: replace-cross 
Abstract: Shape plays an important role in computer graphics, offering informative features to convey an object's morphology and functionality. Shape analysis in brain imaging can help interpret structural and functionality correlations of the human brain. In this work, we investigate the shape of the brain's 3D white matter connections and its potential predictive relationship to human cognitive function. We reconstruct brain connections as sequences of 3D points using diffusion magnetic resonance imaging (dMRI) tractography. To describe each connection, we extract 12 shape descriptors in addition to traditional dMRI connectivity and tissue microstructure features. We introduce a novel framework, Shape--fused Fiber Cluster Transformer (SFFormer), that leverages a multi-head cross-attention feature fusion module to predict subject-specific language performance based on dMRI tractography. We assess the performance of the method on a large dataset including 1065 healthy young adults. The results demonstrate that both the transformer-based SFFormer model and its inter/intra feature fusion with shape, microstructure, and connectivity are informative, and together, they improve the prediction of subject-specific language performance scores. Overall, our results indicate that the shape of the brain's connections is predictive of human language function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.19001v3</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>eess.IV</category>
      <category>q-bio.NC</category>
      <pubDate>Fri, 20 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yui Lo, Yuqian Chen, Dongnan Liu, Wan Liu, Leo Zekelman, Fan Zhang, Yogesh Rathi, Nikos Makris, Alexandra J. Golby, Weidong Cai, Lauren J. O'Donnell</dc:creator>
    </item>
    <item>
      <title>A simple mathematical theory for Simple Volatile Memristors and their spiking circuits</title>
      <link>https://arxiv.org/abs/2404.08647</link>
      <description>arXiv:2404.08647v2 Announce Type: replace-cross 
Abstract: In pursuit of neuromorphic (brain-inspired) devices, memristors (memory-resistors) have emerged as effective components for emulating neuronal circuitry. Here we formally define a class of Simple Volatile Memristors (SVMs) based on a simple conductance equation of motion from which we build a simple mathematical theory on the dynamics of isolated SVMs and SVM-based spiking circuits. Notably, SVMs include various fluidic iontronic devices that have recently garnered significant interest due to their unique quality of operating within the same medium as the brain. Specifically we show that symmetric SVMs produce non self-crossing current-voltage hysteresis loops, while asymmetric SVMs produce self-crossing loops. Additionally, we derive a general expression for the enclosed area in a loop, providing a relation between the voltage frequency and the SVM memory timescale. These general results are shown to materialise in physical finite-element calculations of microfluidic memristors. An SVM-based circuit has been proposed that exhibits all-or-none and tonic neuronal spiking. We generalise and analyse this spiking circuit, characterising it as a two-dimensional dynamical system. Moreover, we demonstrate that stochastic effects can induce novel neuronal firing modes absent in the deterministic case. Through our analysis, the circuit dynamics are well understood, while retaining its explicit link with the physically plausible underlying system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08647v2</guid>
      <category>cond-mat.soft</category>
      <category>q-bio.NC</category>
      <pubDate>Fri, 20 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.chaos.2024.115320</arxiv:DOI>
      <arxiv:journal_reference>Chaos, Solitons &amp; Fractals (2024), Vol. 186, 115320</arxiv:journal_reference>
      <dc:creator>T. M. Kamsma, R. van Roij, C. Spitoni</dc:creator>
    </item>
  </channel>
</rss>
