<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.OS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.OS</link>
    <description>cs.OS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.OS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 01 Apr 2025 03:13:55 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 31 Mar 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Saving Storage Space Using Files on the Web</title>
      <link>https://arxiv.org/abs/2503.22089</link>
      <description>arXiv:2503.22089v1 Announce Type: new 
Abstract: As conventional storage density reaches its physical limits, the cost of a gigabyte of storage is no longer plummeting, but rather has remained mostly flat for the past decade. Meanwhile, file sizes continue to grow, leading to ever fuller drives. When a user's storage is full, they must disrupt their workflow to laboriously find large files that are good candidates for deletion. Separately, the web acts as a distributed storage network, providing free access to petabytes of redundant files across 200 million websites. An automated method of restoring files from the web would enable more efficient storage management, since files readily recoverable from the web would make good candidates for removal. Despite this, there are no prescribed methods for automatically detecting these files and ensuring their easy recoverability from the web, as little is known about either the biggest files of users or their origins on the web. This study thus seeks to determine what files consume the most space in users' storage, and from this, to propose an automated method to select candidate files for removal. Our investigations show 989 MB of storage per user can be saved by inspecting preexisting metadata of their 25 largest files alone, with file recovery from the web 3 months later. This demonstrates the feasibility of applying such a method in a climate of increasingly scarce local storage resources.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.22089v1</guid>
      <category>cs.OS</category>
      <category>cs.NI</category>
      <pubDate>Mon, 31 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kevin Saric, Gowri Sankar Ramachandran, Raja Jurdak, Surya Nepal</dc:creator>
    </item>
  </channel>
</rss>
