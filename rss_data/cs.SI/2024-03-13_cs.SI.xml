<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.SI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.SI</link>
    <description>cs.SI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.SI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 13 Mar 2024 04:00:19 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 13 Mar 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Online Misogyny Against Female Candidates in the 2022 Brazilian Elections: A Threat to Women's Political Representation?</title>
      <link>https://arxiv.org/abs/2403.07523</link>
      <description>arXiv:2403.07523v1 Announce Type: new 
Abstract: Technology-facilitated gender-based violence has become a global threat to women's political representation and democracy. Understanding how online hate affects its targets is thus paramount. We analyse 10 million tweets directed at female candidates in the Brazilian election in 2022 and examine their reactions to online misogyny. Using a self-trained machine learning classifier to detect Portuguese misogynistic tweets and a quantitative analysis of the candidates' tweeting behaviour, we investigate how the number of misogynistic attacks received alters the online activity of the female candidates. We find that young and left-wing candidates and candidates with higher visibility online received significantly more attacks. Furthermore, we find that an increase in misogynistic attacks in the previous week is associated with a decrease in female candidates' tweets in the following week. This potentially threatens their equal participation in public opinion building and silences women's voices in political discourse.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07523v1</guid>
      <category>cs.SI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luise Kocha, Raji Ghawi, J\"urgen Pfeffer, Janina Isabel Steinert</dc:creator>
    </item>
    <item>
      <title>How Language, Culture, and Geography shape Online Dialogue: Insights from Koo</title>
      <link>https://arxiv.org/abs/2403.07531</link>
      <description>arXiv:2403.07531v1 Announce Type: new 
Abstract: Koo is a microblogging platform based in India launched in 2020 with the explicit aim of catering to non-Western communities in their vernacular languages. With a near-complete dataset totalling over 71M posts and 399M user interactions, we show how Koo has attracted users from several countries including India, Nigeria and Brazil, but with variable levels of sustained user engagement. We highlight how Koo's interaction network has been shaped by multiple country-specific migrations and displays strong divides between linguistic and cultural communities, for instance, with English-speaking communities from India and Nigeria largely isolated from one another. Finally, we analyse the content shared by each linguistic community and identify cultural patterns that promote similar discourses across language groups. Our study raises the prospect that a multilingual and politically diverse platform like Koo may be able to cultivate vernacular communities that have, historically, not been prioritised by US-based social media platforms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07531v1</guid>
      <category>cs.SI</category>
      <category>physics.soc-ph</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amin Mekacher, Max Falkenberg, Andrea Baronchelli</dc:creator>
    </item>
    <item>
      <title>Stochastic gradient descent-based inference for dynamic network models with attractors</title>
      <link>https://arxiv.org/abs/2403.07124</link>
      <description>arXiv:2403.07124v1 Announce Type: cross 
Abstract: In Coevolving Latent Space Networks with Attractors (CLSNA) models, nodes in a latent space represent social actors, and edges indicate their dynamic interactions. Attractors are added at the latent level to capture the notion of attractive and repulsive forces between nodes, borrowing from dynamical systems theory. However, CLSNA reliance on MCMC estimation makes scaling difficult, and the requirement for nodes to be present throughout the study period limit practical applications. We address these issues by (i) introducing a Stochastic gradient descent (SGD) parameter estimation method, (ii) developing a novel approach for uncertainty quantification using SGD, and (iii) extending the model to allow nodes to join and leave over time. Simulation results show that our extensions result in little loss of accuracy compared to MCMC, but can scale to much larger networks. We apply our approach to the longitudinal social networks of members of US Congress on the social media platform X. Accounting for node dynamics overcomes selection bias in the network and uncovers uniquely and increasingly repulsive forces within the Republican Party.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07124v1</guid>
      <category>stat.ME</category>
      <category>cs.SI</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hancong Pan, Xiaojing Zhu, Cantay Caliskan, Dino P. Christenson, Konstantinos Spiliopoulos, Dylan Walker, Eric D. Kolaczyk</dc:creator>
    </item>
    <item>
      <title>Breaking Political Filter Bubbles via Social Comparison</title>
      <link>https://arxiv.org/abs/2403.07150</link>
      <description>arXiv:2403.07150v1 Announce Type: cross 
Abstract: Online social platforms allow users to filter out content they do not like. According to selective exposure theory, people tend to view content they agree with more to get more self-assurance. This causes people to live in ideological filter bubbles. We report on a user study that encourages users to break the political filter bubble of their Twitter feed by reading more diverse viewpoints through social comparison. The user study is conducted using political-bias analyzing and Twitter-mirroring tools to compare the political slant of what a user reads and what other Twitter users read about a topic, and in general. The results show that social comparison can have a great impact on users' reading behavior by motivating them to read viewpoints from the opposing political party.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07150v1</guid>
      <category>cs.HC</category>
      <category>cs.SI</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Nouran Soliman, Motahhare Eslami, Karrie Karahalios</dc:creator>
    </item>
    <item>
      <title>Monitoring AI-Modified Content at Scale: A Case Study on the Impact of ChatGPT on AI Conference Peer Reviews</title>
      <link>https://arxiv.org/abs/2403.07183</link>
      <description>arXiv:2403.07183v1 Announce Type: cross 
Abstract: We present an approach for estimating the fraction of text in a large corpus which is likely to be substantially modified or produced by a large language model (LLM). Our maximum likelihood model leverages expert-written and AI-generated reference texts to accurately and efficiently examine real-world LLM-use at the corpus level. We apply this approach to a case study of scientific peer review in AI conferences that took place after the release of ChatGPT: ICLR 2024, NeurIPS 2023, CoRL 2023 and EMNLP 2023. Our results suggest that between 6.5% and 16.9% of text submitted as peer reviews to these conferences could have been substantially modified by LLMs, i.e. beyond spell-checking or minor writing updates. The circumstances in which generated text occurs offer insight into user behavior: the estimated fraction of LLM-generated text is higher in reviews which report lower confidence, were submitted close to the deadline, and from reviewers who are less likely to respond to author rebuttals. We also observe corpus-level trends in generated text which may be too subtle to detect at the individual level, and discuss the implications of such trends on peer review. We call for future interdisciplinary work to examine how LLM use is changing our information and knowledge practices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07183v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weixin Liang, Zachary Izzo, Yaohui Zhang, Haley Lepp, Hancheng Cao, Xuandong Zhao, Lingjiao Chen, Haotian Ye, Sheng Liu, Zhi Huang, Daniel A. McFarland, James Y. Zou</dc:creator>
    </item>
    <item>
      <title>Graph Data Condensation via Self-expressive Graph Structure Reconstruction</title>
      <link>https://arxiv.org/abs/2403.07294</link>
      <description>arXiv:2403.07294v1 Announce Type: cross 
Abstract: With the increasing demands of training graph neural networks (GNNs) on large-scale graphs, graph data condensation has emerged as a critical technique to relieve the storage and time costs during the training phase. It aims to condense the original large-scale graph to a much smaller synthetic graph while preserving the essential information necessary for efficiently training a downstream GNN. However, existing methods concentrate either on optimizing node features exclusively or endeavor to independently learn node features and the graph structure generator. They could not explicitly leverage the information of the original graph structure and failed to construct an interpretable graph structure for the synthetic dataset. To address these issues, we introduce a novel framework named \textbf{G}raph Data \textbf{C}ondensation via \textbf{S}elf-expressive Graph Structure \textbf{R}econstruction (\textbf{GCSR}). Our method stands out by (1) explicitly incorporating the original graph structure into the condensing process and (2) capturing the nuanced interdependencies between the condensed nodes by reconstructing an interpretable self-expressive graph structure. Extensive experiments and comprehensive analysis validate the efficacy of the proposed method across diverse GNN models and datasets. Our code is available at https://www.dropbox.com/scl/fi/2aonyp5ln5gisdqtjimu8/GCSR.zip?rlkey=11cuwfpsf54wxiiktu0klud0x&amp;dl=0</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07294v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.SI</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhanyu Liu, Chaolv Zeng, Guanjie Zheng</dc:creator>
    </item>
    <item>
      <title>Maximum Defective Clique Computation: Improved Time Complexities and Practical Performance</title>
      <link>https://arxiv.org/abs/2403.07561</link>
      <description>arXiv:2403.07561v1 Announce Type: cross 
Abstract: The concept of $k$-defective clique, a relaxation of clique by allowing up-to $k$ missing edges, has been receiving increasing interests recently. Although the problem of finding the maximum $k$-defective clique is NP-hard, several practical algorithms have been recently proposed in the literature, with kDC being the state of the art. kDC not only runs the fastest in practice, but also achieves the best time complexity. Specifically, it runs in $O^*(\gamma_k^n)$ time when ignoring polynomial factors; here, $\gamma_k$ is a constant that is smaller than two and only depends on $k$, and $n$ is the number of vertices in the input graph $G$. In this paper, we propose the kDC-Two algorithm to improve the time complexity as well as practical performance. kDC-Two runs in $O^*( (\alpha\Delta)^{k+2} \gamma_{k-1}^\alpha)$ time when the maximum $k$-defective clique size $\omega_k(G)$ is at least $k+2$, and in $O^*(\gamma_{k-1}^n)$ time otherwise, where $\alpha$ and $\Delta$ are the degeneracy and maximum degree of $G$, respectively. In addition, with slight modification, kDC-Two also runs in $O^*( (\alpha\Delta)^{k+2} (k+1)^{\alpha+k+1-\omega_k(G)})$ time by using the degeneracy gap $\alpha+k+1-\omega_k(G)$ parameterization; this is better than $O^*( (\alpha\Delta)^{k+2}\gamma_{k-1}^\alpha)$ when $\omega_k(G)$ is close to the degeneracy-based upper bound $\alpha+k+1$. Finally, to further improve the practical performance, we propose a new degree-sequence-based reduction rule that can be efficiently applied, and theoretically demonstrate its effectiveness compared with those proposed in the literature. Extensive empirical studies on three benchmark graph collections show that our algorithm outperforms the existing fastest algorithm by several orders of magnitude.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07561v1</guid>
      <category>cs.DS</category>
      <category>cs.SI</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lijun Chang</dc:creator>
    </item>
    <item>
      <title>Public emotional dynamics toward AIGC content generation across social media platform</title>
      <link>https://arxiv.org/abs/2312.03779</link>
      <description>arXiv:2312.03779v2 Announce Type: replace 
Abstract: Given the widespread popularity of interactive AI models like ChatGPT, public opinion on emerging artificial intelligence generated content(AIGC) has been extensively debated. Pessimists believe that AIGC will replace humans in the future, and optimists think that it will further liberate productivity. Public emotions play a crucial role on social media platforms. They can provide valuable insights into the public's opinions, attitudes, and behaviors. There is a lack of research on the analysis of social group emotions triggered by AIGC content, and even more on the cross-platform differences of group emotions. This study fills the research gap by connecting the theory of group dynamics with emotions in social media. Specifically, we develop a scientific group emotion calculation and visualization system based on chains of communication. The system is capable of crawling data in real time and presenting the current state of group emotions in a fine-grained manner. We then analyze which group dynamic factors drive different public emotions towards nine AIGC products on the three most popular social media platforms in China. Finally, we obtain four main findings. First, Douyin is the only platform with negative group emotion on emerging AI technologies. Second, Weibo users prefer extreme emotions more than others. Third, the group emotion varies by education and age. It is negatively correlated with senior high school or lower and 25 or younger, and positively correlated with bachelor's degree or higher and 26-35. Fourth, the group emotion polarization increases with more posts without comments and celebrity publishers. By analyzing the key dynamic factors of group emotions to AIGC on various social media platforms, we can improve our products and services, develop more effective marketing strategies, and create more accurate and effective AI models to solve complex problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.03779v2</guid>
      <category>cs.SI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qinglan Wei, Jiayi Li, Yuan Zhang</dc:creator>
    </item>
    <item>
      <title>Online disinformation in the 2020 U.S. Election: swing vs. safe states</title>
      <link>https://arxiv.org/abs/2402.18664</link>
      <description>arXiv:2402.18664v2 Announce Type: replace 
Abstract: For U.S. presidential elections, most states use the so-called winner-take-all system, in which the state's presidential electors are awarded to the winning political party in the state after a popular vote phase, regardless of the actual margin of victory. Therefore, election campaigns are especially intense in states where there is no clear direction on which party will be the winning party. These states are often referred to as swing states. To measure the impact of such an election law on the campaigns, we analyze the Twitter activity surrounding the 2020 US preelection debate, with a particular focus on the spread of disinformation. We find that about 88% of the online traffic was associated with swing states. In addition, the sharing of links to unreliable news sources is significantly more prevalent in tweets associated with swing states: in this case, untrustworthy tweets are predominantly generated by automated accounts. Furthermore, we observe that the debate is mostly led by two main communities, one with a predominantly Republican affiliation and the other with accounts of different political orientations. Most of the disinformation comes from the former.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.18664v2</guid>
      <category>cs.SI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Manuel Pratelli, Marinella Petrocchi, Fabio Saracco, Rocco De Nicola</dc:creator>
    </item>
    <item>
      <title>Understanding how social discussion platforms like Reddit are influencing financial behavior</title>
      <link>https://arxiv.org/abs/2403.04298</link>
      <description>arXiv:2403.04298v2 Announce Type: replace 
Abstract: This study proposes content and interaction analysis techniques for a large repository created from social media content. Though we have presented our study for a large platform dedicated to discussions around financial topics, the proposed methods are generic and applicable to all platforms. Along with an extension of topic extraction method using Latent Dirichlet Allocation, we propose a few measures to assess user participation, influence and topic affinities specifically. Our study also maps user-generated content to components of behavioral finance. While these types of information are usually gathered through surveys, it is obvious that large scale data analysis from social media can reveal many potentially unknown or rare insights. Characterising users based on their platform behavior to provide critical insights about how communities are formed and trust is established in these platforms using graphical analysis is also studied.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.04298v2</guid>
      <category>cs.SI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/WI-IAT55865.2022.00096</arxiv:DOI>
      <arxiv:journal_reference>IEEE/WIC/ACM International Joint Conference on Web Intelligence and Intelligent Agent Technology (WI-IAT) 2022 (pp. 612-619)</arxiv:journal_reference>
      <dc:creator>Sachin Thukral, Suyash Sangwan, Arnab Chatterjee, Lipika Dey, Aaditya Agrawal, Pramit Kumar Chandra, Animesh Mukherjee</dc:creator>
    </item>
    <item>
      <title>Generating insights about financial asks from Reddit posts and user interactions</title>
      <link>https://arxiv.org/abs/2403.04308</link>
      <description>arXiv:2403.04308v2 Announce Type: replace 
Abstract: As an increasingly large number of people turn to platforms like Reddit, YouTube, Twitter, Instagram, etc. for financial advice, generating insights about the content generated and interactions taking place within these platforms have become a key research question. This study proposes content and interaction analysis techniques for a large repository created from social media content, where people interactions are centered around financial information exchange. We propose methods for content analysis that can generate human-interpretable insights using topic-centered clustering and multi-document abstractive summarization. We share details of insights generated from our experiments with a large repository of data gathered from subreddit for personal finance. We have also explored the use of ChatGPT and Vicuna for generating responses to queries and compared them with human responses. The methods proposed in this work are generic and applicable to all large social media platforms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.04308v2</guid>
      <category>cs.SI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3625007.3627313</arxiv:DOI>
      <dc:creator>Sachin Thukral, Suyash Sangwan, Vipul Chauhan, Arnab Chatterjee, Lipika Dey</dc:creator>
    </item>
    <item>
      <title>Navigating the Post-API Dilemma Search Engine Results Pages Present a Biased View of Social Media Data</title>
      <link>https://arxiv.org/abs/2401.15479</link>
      <description>arXiv:2401.15479v2 Announce Type: replace-cross 
Abstract: Recent decisions to discontinue access to social media APIs are having detrimental effects on Internet research and the field of computational social science as a whole. This lack of access to data has been dubbed the Post-API era of Internet research. Fortunately, popular search engines have the means to crawl, capture, and surface social media data on their Search Engine Results Pages (SERP) if provided the proper search query, and may provide a solution to this dilemma. In the present work we ask: does SERP provide a complete and unbiased sample of social media data? Is SERP a viable alternative to direct API-access? To answer these questions, we perform a comparative analysis between (Google) SERP results and nonsampled data from Reddit and Twitter/X. We find that SERP results are highly biased in favor of popular posts; against political, pornographic, and vulgar posts; are more positive in their sentiment; and have large topical gaps. Overall, we conclude that SERP is not a viable alternative to social media API access.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.15479v2</guid>
      <category>cs.IR</category>
      <category>cs.CL</category>
      <category>cs.SI</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amrit Poudel, Tim Weninger</dc:creator>
    </item>
    <item>
      <title>NetInfoF Framework: Measuring and Exploiting Network Usable Information</title>
      <link>https://arxiv.org/abs/2402.07999</link>
      <description>arXiv:2402.07999v2 Announce Type: replace-cross 
Abstract: Given a node-attributed graph, and a graph task (link prediction or node classification), can we tell if a graph neural network (GNN) will perform well? More specifically, do the graph structure and the node features carry enough usable information for the task? Our goals are (1) to develop a fast tool to measure how much information is in the graph structure and in the node features, and (2) to exploit the information to solve the task, if there is enough. We propose NetInfoF, a framework including NetInfoF_Probe and NetInfoF_Act, for the measurement and the exploitation of network usable information (NUI), respectively. Given a graph data, NetInfoF_Probe measures NUI without any model training, and NetInfoF_Act solves link prediction and node classification, while two modules share the same backbone. In summary, NetInfoF has following notable advantages: (a) General, handling both link prediction and node classification; (b) Principled, with theoretical guarantee and closed-form solution; (c) Effective, thanks to the proposed adjustment to node similarity; (d) Scalable, scaling linearly with the input size. In our carefully designed synthetic datasets, NetInfoF correctly identifies the ground truth of NUI and is the only method being robust to all graph scenarios. Applied on real-world datasets, NetInfoF wins in 11 out of 12 times on link prediction compared to general GNN baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.07999v2</guid>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Meng-Chieh Lee, Haiyang Yu, Jian Zhang, Vassilis N. Ioannidis, Xiang Song, Soji Adeshina, Da Zheng, Christos Faloutsos</dc:creator>
    </item>
  </channel>
</rss>
