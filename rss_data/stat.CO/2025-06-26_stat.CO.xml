<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.CO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.CO</link>
    <description>stat.CO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.CO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 26 Jun 2025 04:03:06 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 26 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Introducing RobustiPy: An efficient next generation multiversal library with model selection, averaging, resampling, and explainable artificial intelligence</title>
      <link>https://arxiv.org/abs/2506.19958</link>
      <description>arXiv:2506.19958v1 Announce Type: cross 
Abstract: We present RobustiPy, a next generation Python-based framework for model uncertainty quantification and multiverse analysis, released under the GNU GPL v3.0. Through the integration of efficient bootstrap-based confidence intervals, combinatorial exploration of dependent-variable specifications, model selection and averaging, and two complementary joint-inference routines, RobustiPy transcends existing uncertainty-quantification tools. Its design further supports rigorous out-of-sample evaluation and apportions the predictive contribution of each covariate. We deploy the library across five carefully constructed simulations and ten empirically grounded case studies drawn from high-impact literature and teaching examples, including a novel re-analysis of "unexplained discrepancies" in famous prior work. To illustrate its performance, we time-profile RobustiPy over roughly 672 million simulated linear regressions. These applications showcase how RobustiPy not only accelerates robust inference but also deepens our interpretive insight into model sensitivity across the vast analytical multiverse within which scientists operate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.19958v1</guid>
      <category>stat.ME</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <pubDate>Thu, 26 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Daniel Valdenegro Ibarra, Jiani Yan, Duiyi Dai, Charles Rahal</dc:creator>
    </item>
    <item>
      <title>hdbayes: An R Package for Bayesian Analysis of Generalized Linear Models Using Historical Data</title>
      <link>https://arxiv.org/abs/2506.20060</link>
      <description>arXiv:2506.20060v1 Announce Type: cross 
Abstract: There has been increased interest in the use of historical data to formulate informative priors in regression models. While many such priors for incorporating historical data have been proposed, adoption is limited due to access to software. Where software does exist, the implementations between different methods could be vastly different, making comparisons between methods difficult. In this paper, we introduce the R package hdbayes, an implementation of the power prior, normalized power prior, Bayesian hierarchical model, robust meta-analytic prior, commensurate prior, and latent exchangeability prior for generalized linear models. The bulk of the package is written in the Stan programming language, with user-friendly R wrapper functions to call samplers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.20060v1</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Thu, 26 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ethan M. Alt, Xinxin Chen, Luiz M. Carvalho, Joseph G. Ibrahim</dc:creator>
    </item>
    <item>
      <title>Scalable Subset Selection in Linear Mixed Models</title>
      <link>https://arxiv.org/abs/2506.20425</link>
      <description>arXiv:2506.20425v1 Announce Type: cross 
Abstract: Linear mixed models (LMMs), which incorporate fixed and random effects, are key tools for analyzing heterogeneous data, such as in personalized medicine or adaptive marketing. Nowadays, this type of data is increasingly wide, sometimes containing thousands of candidate predictors, necessitating sparsity for prediction and interpretation. However, existing sparse learning methods for LMMs do not scale well beyond tens or hundreds of predictors, leaving a large gap compared with sparse methods for linear models, which ignore random effects. This paper closes the gap with a new $\ell_0$ regularized method for LMM subset selection that can run on datasets containing thousands of predictors in seconds to minutes. On the computational front, we develop a coordinate descent algorithm as our main workhorse and provide a guarantee of its convergence. We also develop a local search algorithm to help traverse the nonconvex optimization surface. Both algorithms readily extend to subset selection in generalized LMMs via a penalized quasi-likelihood approximation. On the statistical front, we provide a finite-sample bound on the Kullback-Leibler divergence of the new method. We then demonstrate its excellent performance in synthetic experiments and illustrate its utility on two datasets from biology and journalism.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.20425v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <pubDate>Thu, 26 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ryan Thompson, Matt P. Wand, Joanna J. J. Wang</dc:creator>
    </item>
    <item>
      <title>Anytime-Valid Inference in Adaptive Experiments: Covariate Adjustment and Balanced Power</title>
      <link>https://arxiv.org/abs/2506.20523</link>
      <description>arXiv:2506.20523v1 Announce Type: cross 
Abstract: Adaptive experiments have become central to modern experimental design, enabling researchers to efficiently identify optimal treatments, improve statistical power, and maximize respondent welfare. However, adaptive experiments compromise valid inference and leave sub-optimal treatments underpowered. We introduce two methodological advances for adaptive experimentation. First, covariate-adjusted Mixture Adaptive Design (MADCovar) achieves substantial improvements in average treatment effect (ATE) precision by incorporating covariate adjustment within an anytime-valid inference framework. Second, power-modified MAD (MADMod) reallocates sample to underpowered treatment arms, improving statistical power across all treatments while maintaining error control. Both methods provide anytime-valid guarantees, enabling continuous monitoring without inflating Type 1 error rates. Simulation studies and empirical analyses demonstrate that MADCovar delivers significant precision gains and that MADMod ensures robust inference even for suboptimal treatments. Together, these methods address key limitations of adaptive experiments and equip researchers with practical tools for precise and reliable causal inference. Our proposed methods are implemented through an open-source software package.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.20523v1</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <category>stat.CO</category>
      <pubDate>Thu, 26 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel Molitor, Samantha Gold</dc:creator>
    </item>
    <item>
      <title>Inference for Error-Prone Count Data: Estimation under a Binomial Convolution Framework</title>
      <link>https://arxiv.org/abs/2506.20596</link>
      <description>arXiv:2506.20596v1 Announce Type: cross 
Abstract: Measurement error in count data is common but underexplored in the literature, particularly in contexts where observed scores are bounded and arise from discrete scoring processes. Motivated by applications in oral reading fluency assessment, we propose a binomial convolution framework that extends binary misclassification models to settings where only the aggregate number of correct responses is observed, and errors may involve both overcounting and undercounting the number of events. The model accommodates distinct true positive and true negative accuracy rates and preserves the bounded nature of the data.
  Assuming the availability of both contaminated and error-free scores on a subset of items, we develop and compare three estimation strategies: maximum likelihood estimation (MLE), linear regression, and generalized method of moments (GMM). Extensive simulations show that MLE is most accurate when the model is correctly specified but is computationally intensive and less robust to misspecification. Regression is simple and stable but less precise, while GMM offers a compromise in model dependence, though it is sensitive to outliers.
  In practice, this framework supports improved inference in unsupervised settings where contaminated scores serve as inputs to downstream analyses. By quantifying accuracy rates, the model enables score corrections even when no specific outcome is yet defined. We demonstrate its utility using real oral reading fluency data, comparing human and AI-generated scores. Findings highlight the practical implications of estimator choice and underscore the importance of explicitly modeling asymmetric measurement error in count data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.20596v1</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Thu, 26 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuqiu Yang, Christina Vu, Cornelis J. Potgieter, Xinlei Wang, Akihito Kamata</dc:creator>
    </item>
    <item>
      <title>GIST: Gibbs self-tuning for locally adaptive Hamiltonian Monte Carlo</title>
      <link>https://arxiv.org/abs/2404.15253</link>
      <description>arXiv:2404.15253v4 Announce Type: replace 
Abstract: We introduce a novel and flexible framework for constructing locally adaptive Hamiltonian Monte Carlo (HMC) samplers by Gibbs sampling the algorithm's tuning parameters conditionally based on the position and momentum at each step. For adaptively sampling path lengths, our Gibbs self-tuning (GIST) approach encompasses randomized HMC, multinomial HMC, the No-U-Turn Sampler (NUTS), and the Apogee-to-Apogee Path Sampler as special cases. We exemplify the GIST framework with a novel alternative to NUTS for locally adapting path lengths, evaluated with an exact Hamiltonian for a high-dimensional, ill-conditioned Gaussian measure and with the leapfrog integrator for a suite of diverse models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15253v4</guid>
      <category>stat.CO</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Thu, 26 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nawaf Bou-Rabee, Bob Carpenter, Milo Marsden</dc:creator>
    </item>
    <item>
      <title>A Stability Framework for Parameter Selection in the Minimum Covariance Determinant Problem</title>
      <link>https://arxiv.org/abs/2401.14359</link>
      <description>arXiv:2401.14359v5 Announce Type: replace-cross 
Abstract: The Minimum Covariance Determinant (MCD) method is a widely adopted tool for robust estimation and outlier detection. In this paper, we introduce MCD model selection based on the notion of stability. Our best subset method leverages prior best practices such as statistical depths for initialization and concentration steps for subset refinement. Our contribution lies in constructing a bootstrap procedure to estimate the instability of the best subset algorithm. The instability path offers insights into a dataset's inlier/outlier structure and facilitates suitable choice of the subset size. We rigorously benchmark the proposed framework against existing MCD variants and illustrate its practical utility on several real-world datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.14359v5</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Thu, 26 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qiang Heng, Hui Shen, Kenneth Lange</dc:creator>
    </item>
    <item>
      <title>Gradient-Free Sequential Bayesian Experimental Design via Interacting Particle Systems</title>
      <link>https://arxiv.org/abs/2504.13320</link>
      <description>arXiv:2504.13320v2 Announce Type: replace-cross 
Abstract: We introduce a gradient-free framework for Bayesian Optimal Experimental Design (BOED) in sequential settings, aimed at complex systems where gradient information is unavailable. Our method combines Ensemble Kalman Inversion (EKI) for design optimization with the Affine-Invariant Langevin Dynamics (ALDI) sampler for efficient posterior sampling-both of which are derivative-free and ensemble-based. To address the computational challenges posed by nested expectations in BOED, we propose variational Gaussian and parametrized Laplace approximations that provide tractable upper and lower bounds on the Expected Information Gain (EIG). These approximations enable scalable utility estimation in high-dimensional spaces and PDE-constrained inverse problems. We demonstrate the performance of our framework through numerical experiments ranging from linear Gaussian models to PDE-based inference tasks, highlighting the method's robustness, accuracy, and efficiency in information-driven experimental design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.13320v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.CO</category>
      <pubDate>Thu, 26 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Robert Gruhlke, Matei Hanu, Claudia Schillings, Philipp Wacker</dc:creator>
    </item>
    <item>
      <title>gcor: A Python Implementation of Categorical Gini Correlation and Its Inference</title>
      <link>https://arxiv.org/abs/2506.19230</link>
      <description>arXiv:2506.19230v2 Announce Type: replace-cross 
Abstract: Categorical Gini Correlation (CGC), introduced by Dang et al. (2020), is a novel dependence measure designed to quantify the association between a numerical variable and a categorical variable. It has appealing properties compared to existing dependence measures, such as zero correlation mutually implying independence between the variables. It has also shown superior performance over existing methods when applied to feature screening for classification. This article presents a Python implementation for computing CGC, constructing confidence intervals, and performing independence tests based on it. Efficient algorithms have been implemented for all procedures, and they have been optimized using vectorization and parallelization to enhance computational efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.19230v2</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Thu, 26 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sameera Hewage</dc:creator>
    </item>
  </channel>
</rss>
