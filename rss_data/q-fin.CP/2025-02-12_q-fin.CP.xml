<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-fin.CP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-fin.CP</link>
    <description>q-fin.CP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-fin.CP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 13 Feb 2025 02:43:05 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>OrderFusion: Encoding Orderbook for Probabilistic Intraday Price Prediction</title>
      <link>https://arxiv.org/abs/2502.06830</link>
      <description>arXiv:2502.06830v1 Announce Type: new 
Abstract: Efficient and reliable probabilistic prediction of intraday electricity prices is essential to manage market uncertainties and support robust trading strategies. However, current methods often suffer from parameter inefficiencies, as they fail to fully exploit the potential of modeling interdependencies between bids and offers in the orderbook, requiring a large number of parameters for representation learning. Furthermore, these methods face the quantile crossing issue, where upper quantiles fall below the lower quantiles, resulting in unreliable probabilistic predictions. To address these two challenges, we propose an encoding method called OrderFusion and design a hierarchical multi-quantile head. The OrderFusion encodes the orderbook into a 2.5D representation, which is processed by a tailored jump cross-attention backbone to capture the interdependencies of bids and offers, enabling parameter-efficient learning. The head sets the median quantile as an anchor and predicts multiple quantiles hierarchically, ensuring reliability by enforcing monotonicity between quantiles through non-negative functions. Extensive experiments and ablation studies are conducted on four price indices: 60-min ID3, 60-min ID1, 15-min ID3, and 15-min ID1 using the German orderbook over three years to ensure a fair evaluation. The results confirm that our design choices improve overall performance, offering a parameter-efficient and reliable solution for probabilistic intraday price prediction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06830v1</guid>
      <category>q-fin.CP</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Runyao Yu, Yuchen Tao, Fabian Leimgruber, Tara Esterl, Jochen L. Cremer</dc:creator>
    </item>
    <item>
      <title>A nested MLMC framework for efficient simulations on FPGAs</title>
      <link>https://arxiv.org/abs/2502.07123</link>
      <description>arXiv:2502.07123v1 Announce Type: new 
Abstract: Multilevel Monte Carlo (MLMC) reduces the total computational cost of financial option pricing by combining SDE approximations with multiple resolutions. This paper explores a further avenue for reducing cost and improving power efficiency through the use of low precision calculations on configurable hardware devices such as Field-Programmable Gate Arrays (FPGAs). We propose a new framework that exploits approximate random variables and fixed-point operations with optimised precision to generate most SDE paths with a lower cost and reduce the overall cost of the MLMC framework. We first discuss several methods for the cheap generation of approximate random Normal increments. To set the bit-width of variables in the path generation we then propose a rounding error model and optimise the precision of all variables on each MLMC level. With these key improvements, our proposed framework offers higher computational savings than the existing mixed-precision MLMC frameworks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.07123v1</guid>
      <category>q-fin.CP</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Irina-Beatrice Haas, Michael B. Giles</dc:creator>
    </item>
    <item>
      <title>Integrating the implied regularity into implied volatility models: A study on free arbitrage model</title>
      <link>https://arxiv.org/abs/2502.07518</link>
      <description>arXiv:2502.07518v1 Announce Type: new 
Abstract: Implied volatility IV is a key metric in financial markets, reflecting market expectations of future price fluctuations. Research has explored IV's relationship with moneyness, focusing on its connection to the implied Hurst exponent H. Our study reveals that H approaches 1/2 when moneyness equals 1, marking a critical point in market efficiency expectations. We developed an IV model that integrates H to capture these dynamics more effectively. This model considers the interaction between H and the underlying-to-strike price ratio S/K, crucial for capturing IV variations based on moneyness. Using Optuna optimization across multiple indexes, the model outperformed SABR and fSABR in accuracy. This approach provides a more detailed representation of market expectations and IV-H dynamics, improving options pricing and volatility forecasting while enhancing theoretical and pratcical financial analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.07518v1</guid>
      <category>q-fin.CP</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Daniele Angelini, Fabrizio Di Sciorio</dc:creator>
    </item>
    <item>
      <title>TRADES: Generating Realistic Market Simulations with Diffusion Models</title>
      <link>https://arxiv.org/abs/2502.07071</link>
      <description>arXiv:2502.07071v2 Announce Type: cross 
Abstract: Financial markets are complex systems characterized by high statistical noise, nonlinearity, and constant evolution. Thus, modeling them is extremely hard. We address the task of generating realistic and responsive Limit Order Book (LOB) market simulations, which are fundamental for calibrating and testing trading strategies, performing market impact experiments, and generating synthetic market data. Previous works lack realism, usefulness, and responsiveness of the generated simulations. To bridge this gap, we propose a novel TRAnsformer-based Denoising Diffusion Probabilistic Engine for LOB Simulations (TRADES). TRADES generates realistic order flows conditioned on the state of the market, leveraging a transformer-based architecture that captures the temporal and spatial characteristics of high-frequency market data. There is a notable absence of quantitative metrics for evaluating generative market simulation models in the literature. To tackle this problem, we adapt the predictive score, a metric measured as an MAE, by training a stock price predictive model on synthetic data and testing it on real data. We compare TRADES with previous works on two stocks, reporting an x3.27 and x3.47 improvement over SoTA according to the predictive score, demonstrating that we generate useful synthetic market data for financial downstream tasks. We assess TRADES's market simulation realism and responsiveness, showing that it effectively learns the conditional data distribution and successfully reacts to an experimental agent, giving sprout to possible calibrations and evaluations of trading strategies and market impact experiments. We developed DeepMarket, the first open-source Python framework for market simulation with deep learning. Our repository includes a synthetic LOB dataset composed of TRADES's generates simulations. We release the code at github.com/LeonardoBerti00/DeepMarket.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.07071v2</guid>
      <category>q-fin.TR</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>q-fin.CP</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Leonardo Berti, Bardh Prenkaj, Paola Velardi</dc:creator>
    </item>
    <item>
      <title>TWICE: What Advantages Can Low-Resource Domain-Specific Embedding Model Bring? - A Case Study on Korea Financial Texts</title>
      <link>https://arxiv.org/abs/2502.07131</link>
      <description>arXiv:2502.07131v1 Announce Type: cross 
Abstract: Domain specificity of embedding models is critical for effective performance. However, existing benchmarks, such as FinMTEB, are primarily designed for high-resource languages, leaving low-resource settings, such as Korean, under-explored. Directly translating established English benchmarks often fails to capture the linguistic and cultural nuances present in low-resource domains. In this paper, titled TWICE: What Advantages Can Low-Resource Domain-Specific Embedding Models Bring? A Case Study on Korea Financial Texts, we introduce KorFinMTEB, a novel benchmark for the Korean financial domain, specifically tailored to reflect its unique cultural characteristics in low-resource languages. Our experimental results reveal that while the models perform robustly on a translated version of FinMTEB, their performance on KorFinMTEB uncovers subtle yet critical discrepancies, especially in tasks requiring deeper semantic understanding, that underscore the limitations of direct translation. This discrepancy highlights the necessity of benchmarks that incorporate language-specific idiosyncrasies and cultural nuances. The insights from our study advocate for the development of domain-specific evaluation frameworks that can more accurately assess and drive the progress of embedding models in low-resource settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.07131v1</guid>
      <category>cs.CL</category>
      <category>q-fin.CP</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yewon Hwang, Sungbum Jung, Hanwool Lee, Sara Yu</dc:creator>
    </item>
  </channel>
</rss>
