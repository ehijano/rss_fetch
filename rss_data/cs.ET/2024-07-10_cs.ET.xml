<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.ET updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.ET</link>
    <description>cs.ET updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.ET" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 11 Jul 2024 04:00:20 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 11 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Analyzing Machine Learning Performance in a Hybrid Quantum Computing and HPC Environment</title>
      <link>https://arxiv.org/abs/2407.07294</link>
      <description>arXiv:2407.07294v1 Announce Type: new 
Abstract: We explored the possible benefits of integrating quantum simulators in a "hybrid" quantum machine learning (QML) workflow that uses both classical and quantum computations in a high-performance computing (HPC) environment. Here, we used two Oak Ridge Leadership Computing Facility HPC systems, Andes (a commodity-type Linux cluster) and Frontier (an HPE Cray EX supercomputer), along with quantum computing simulators from PennyLane and IBMQ to evaluate a hybrid QML program -- using a "ground up" approach. Using 1 GPU on Frontier, we found ~56% and ~77% speedups when compared to using Frontier's CPU and a local, non-HPC system, respectively. Analyzing performance on a larger dataset using multiple threads, the Frontier GPUs performed ~92% and ~48% faster than the Andes and Frontier CPUs, respectively. More impressively, this is a ~226% speedup over a local, non-HPC system's runtime using the same simulator and number of threads. We hope that this proof of concept will motivate more intensive hybrid QC/HPC scaling studies in the future.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.07294v1</guid>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <category>quant-ph</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Samuel T. Bieberich, Michael A. Sandoval</dc:creator>
    </item>
    <item>
      <title>The Quantum Imitation Game: Reverse Engineering of Quantum Machine Learning Models</title>
      <link>https://arxiv.org/abs/2407.07237</link>
      <description>arXiv:2407.07237v1 Announce Type: cross 
Abstract: Quantum Machine Learning (QML) amalgamates quantum computing paradigms with machine learning models, providing significant prospects for solving complex problems. However, with the expansion of numerous third-party vendors in the Noisy Intermediate-Scale Quantum (NISQ) era of quantum computing, the security of QML models is of prime importance, particularly against reverse engineering, which could expose trained parameters and algorithms of the models. We assume the untrusted quantum cloud provider is an adversary having white-box access to the transpiled user-designed trained QML model during inference. Reverse engineering (RE) to extract the pre-transpiled QML circuit will enable re-transpilation and usage of the model for various hardware with completely different native gate sets and even different qubit technology. Such flexibility may not be obtained from the transpiled circuit which is tied to a particular hardware and qubit technology. The information about the number of parameters, and optimized values can allow further training of the QML model to alter the QML model, tamper with the watermark, and/or embed their own watermark or refine the model for other purposes. In this first effort to investigate the RE of QML circuits, we perform RE and compare the training accuracy of original and reverse-engineered Quantum Neural Networks (QNNs) of various sizes. We note that multi-qubit classifiers can be reverse-engineered under specific conditions with a mean error of order 1e-2 in a reasonable time. We also propose adding dummy fixed parametric gates in the QML models to increase the RE overhead for defense. For instance, adding 2 dummy qubits and 2 layers increases the overhead by ~1.76 times for a classifier with 2 qubits and 3 layers with a performance overhead of less than 9%. We note that RE is a very powerful attack model which warrants further efforts on defenses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.07237v1</guid>
      <category>quant-ph</category>
      <category>cs.CR</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Archisman Ghosh, Swaroop Ghosh</dc:creator>
    </item>
    <item>
      <title>Machine Learning Assisted Design of mmWave Wireless Transceiver Circuits</title>
      <link>https://arxiv.org/abs/2407.07458</link>
      <description>arXiv:2407.07458v1 Announce Type: cross 
Abstract: As fifth-generation (5G) and upcoming sixth-generation (6G) communications exhibit tremendous demands in providing high data throughput with a relatively low latency, millimeter-wave (mmWave) technologies manifest themselves as the key enabling components to achieve the envisioned performance and tasks. In this context, mmWave integrated circuits (IC) have attracted significant research interests over the past few decades, ranging from individual block design to complex system design. However, the highly nonlinear properties and intricate trade-offs involved render the design of analog or RF circuits a complicated process. The rapid evolution of fabrication technology also results in an increasingly long time allocated in the design process due to more stringent requirements. In this thesis, 28-GHz transceiver circuits are first investigated with detailed schematics and associated performance metrics. In this case, two target systems comprising heterogeneous individual blocks are selected and demonstrated on both the transmitter and receiver sides. Subsequently, some conventional and large-scale machine learning (ML) approaches are integrated into the design pipeline of the chosen systems to predict circuit parameters based on desired specifications, thereby circumventing the typical time-consuming iterations found in traditional methods. Finally, some potential research directions are discussed from the perspectives of circuit design and ML algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.07458v1</guid>
      <category>eess.SY</category>
      <category>cs.ET</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xuzhe Zhao</dc:creator>
    </item>
  </channel>
</rss>
