<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 27 Jan 2026 03:39:35 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Online Computation of Palindromes and Suffix Trees on Tries</title>
      <link>https://arxiv.org/abs/2601.16485</link>
      <description>arXiv:2601.16485v1 Announce Type: new 
Abstract: We consider the problems of computing maximal palindromes and distinct palindromes in a trie. A trie is a natural generalization of a string, which can be seen as a single-path tree. There is a linear-time offline algorithm to compute maximal palindromes and distinct palindromes in a given (static) trie whose edge-labels are drawn from a linearly-sortable alphabet [Mieno et al., ISAAC 2022]. In this paper, we tackle problems of palindrome enumeration on dynamic tries which support leaf additions and leaf deletions. We propose the first sub-quadratic algorithms to enumerate palindromes in a dynamic trie. For maximal palindromes, we propose an algorithm that runs in $O(N \min(\log h, \sigma))$ time and uses $O(N)$ space, where $N$ is the maximum number of edges in the trie, $\sigma$ is the size of the alphabet, and $h$ is the height of the trie. For distinct palindromes, we develop several online algorithms based on different algorithmic frameworks, including approaches using the EERTREE (a.k.a. palindromic tree) and the suffix tree of a trie. These algorithms support leaf insertions and deletions in the trie and achieve different time and space trade-offs. Furthermore, as a by-product, we present online algorithms to construct the suffix tree and the EERTREE of the input trie, which is of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.16485v1</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hiroki Shibata, Mitsuru Funakoshi, Takuya Mieno, Masakazu Ishihata, Yuto Nakashima, Shunsuke Inenaga, Hideo Bannai, Masayuki Takeda</dc:creator>
    </item>
    <item>
      <title>Recovering Communities in Structured Random Graphs</title>
      <link>https://arxiv.org/abs/2601.16910</link>
      <description>arXiv:2601.16910v1 Announce Type: new 
Abstract: The problem of recovering planted community structure in random graphs has received a lot of attention in the literature on the stochastic block model, where the input is a random graph in which edges crossing between different communities appear with smaller probability than edges induced by communities. The communities themselves form a collection of vertex-disjoint sparse cuts in the expected graph, and can be recovered, often exactly, from a sample as long as a separation condition on the intra- and inter-community edge probabilities is satisfied.
  In this paper, we ask whether the presence of a large number of overlapping sparsest cuts in the expected graph still allows recovery. For example, the $d$-dimensional hypercube graph admits $d$ distinct (balanced) sparsest cuts, one for every coordinate. Can these cuts be identified given a random sample of the edges of the hypercube where each edge is present independently with some probability $p\in (0, 1)$? We show that this is the case, in a very strong sense: the sparsest balanced cut in a sample of the hypercube at rate $p=C\log d/d$ for a sufficiently large constant $C$ is $1/\text{poly}(d)$-close to a coordinate cut with high probability. This is asymptotically optimal and allows approximate recovery of all $d$ cuts simultaneously. Furthermore, for an appropriate sample of hypercube-like graphs recovery can be made exact. The proof is essentially a strong hypercube cut sparsification bound that combines a theorem of Friedgut, Kalai and Naor on boolean functions whose Fourier transform concentrates on the first level of the Fourier spectrum with Karger's cut counting argument.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.16910v1</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Kapralov, Luca Trevisan, Weronika Wrzos-Kaminska</dc:creator>
    </item>
    <item>
      <title>Conditionally Tight Algorithms for Maximum k-Coverage and Partial k-Dominating Set via Arity-Reducing Hypercuts</title>
      <link>https://arxiv.org/abs/2601.16923</link>
      <description>arXiv:2601.16923v1 Announce Type: new 
Abstract: We revisit the classic Maximum $k$-Coverage problem: Determine the largest number $t$ of elements that can be covered by choosing $k$ sets from a given family $\mathcal{F} = \{S_1,\dots, S_n\}$ of a size-$u$ universe. A notable special case is Partial $k$-Dominating Set, where one chooses $k$ vertices in a graph to maximize the number of dominated vertices.
  Extensive research has established strong hardness results for various aspects of Maximum $k$-Coverage, such as tight inapproximability results, $W[2]$-hardness, and a conditionally tight worst-case running time of $n^{k\pm o(1)}$. In this paper we ask: (1) Can this time bound be improved for small $t$, at least for Partial $k$-Dominating Set, ideally to time~$t^{k\pm O(1)}$? (2) More ambitiously, can we even determine the best-possible running time of Maximum $k$-Coverage with respect to the perhaps most natural parameters: the universe size $u$, the maximum set size $s$, and the maximum frequency $f$?
  We successfully resolve both questions. (1) We give an algorithm that solves Partial $k$-Dominating Set in time $O(nt + t^{\frac{2\omega}{3} k+O(1)})$ if $\omega \ge 2.25$ and time $O(nt+ t^{\frac{3}{2} k+O(1)})$ if $\omega \le 2.25$, where $\omega \le 2.372$ is the matrix multiplication exponent. From this we derive a time bound that is conditionally optimal, regardless of $\omega$, based on the well-established $k$-clique and 3-uniform hyperclique hypotheses from fine-grained complexity. We also obtain matching upper and lower bounds for sparse graphs. To address (2) we design an algorithm for Maximum $k$-Coverage running in time
  $$
  \min \left\{ (f\cdot \min\{\sqrt[3]{u}, \sqrt{s}\})^k + \min\{n,f\cdot \min\{\sqrt{u}, s\}\}^{k\omega/3}, n^k\right\}
  \cdot g(k)n^{\pm O(1)}, $$ and, surprisingly, further show that this complicated time bound is also conditionally optimal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.16923v1</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nick Fischer, Marvin K\"unnemann, Mirza Redzic</dc:creator>
    </item>
    <item>
      <title>The Geometry of Coalition Power: Majorization, Lattices, and Displacement in Multiwinner Elections</title>
      <link>https://arxiv.org/abs/2601.16723</link>
      <description>arXiv:2601.16723v1 Announce Type: cross 
Abstract: How much influence can a coordinated coalition exert in a multiwinner Top-$k$ election under a positional scoring rule? We study the maximum displacement problem: with coalition size $m$, how many of the current top-$k$ winners can be forced out? We show coalition power decomposes into two independent prefix-majorization constraints, capturing how much the coalition can (i) boost outsiders and (ii) suppress weak winners. For arbitrary scoring rules these prefix inequalities are tight, efficiently checkable necessary conditions (exact in the continuous relaxation).
  For common-step arithmetic-progression (AP) score ladders, including Borda, truncated Borda, $k$-approval/$k$-veto, plurality, and multi-level rules such as $3$--$2$--$1$, we prove a Majorization--Lattice Theorem: feasible aggregate score vectors are exactly the integer points satisfying the Block--HLP prefix-sum capacity constraints plus a single global congruence condition modulo the step size $g$. For Borda ($g=1$) the congruence vanishes, yielding a pure prefix-majorization test.
  This characterization yields an $O(k'\log k')$ exact feasibility oracle for displacing $k'$ winners, and an $O(k(\log k)^2\log(mx))$ algorithm (via dual-envelope binary search) for computing the maximum achievable displacement $k^\ast$. Experiments on Mallows profiles and PrefLib elections confirm exact cutoffs, diminishing returns, and substantial gains over baseline heuristics; for $g&gt;1$ they also demonstrate the predicted congruence effect, where prefix-only tests produce false positives. The oracle scales to extreme instances, processing $10^9$ candidates in under 28 seconds (memory permitting).</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.16723v1</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qian Guo, Yidan Hu, Rui Zhang</dc:creator>
    </item>
    <item>
      <title>The Art of Being Difficult: Combining Human and AI Strengths to Find Adversarial Instances for Heuristics</title>
      <link>https://arxiv.org/abs/2601.16849</link>
      <description>arXiv:2601.16849v1 Announce Type: cross 
Abstract: We demonstrate the power of human-LLM collaboration in tackling open problems in theoretical computer science. Focusing on combinatorial optimization, we refine outputs from the FunSearch algorithm [Romera-Paredes et al., Nature 2023] to derive state-of-the-art lower bounds for standard heuristics. Specifically, we target the generation of adversarial instances where these heuristics perform poorly. By iterating on FunSearch's outputs, we identify improved constructions for hierarchical $k$-median clustering, bin packing, the knapsack problem, and a generalization of Lov\'asz's gasoline problem - some of these have not seen much improvement for over a decade, despite intermittent attention. These results illustrate how expert oversight can effectively extrapolate algorithmic insights from LLM-based evolutionary methods to break long-standing barriers.
  Our findings demonstrate that while LLMs provide critical initial patterns, human expertise is essential for transforming these patterns into mathematically rigorous and insightful constructions. This work highlights that LLMs are a strong collaborative tool in mathematics and computer science research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.16849v1</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Henri Nikoleit, Ankit Anand, Anurag Murty Naredla, Heiko R\"oglin</dc:creator>
    </item>
    <item>
      <title>Faster algorithms for packing forests in graphs and related problems</title>
      <link>https://arxiv.org/abs/2409.20314</link>
      <description>arXiv:2409.20314v3 Announce Type: replace 
Abstract: We consider several problems related to packing forests in graphs. The first one is to find $k$ edge-disjoint forests in a directed graph $G$ of maximal size such that the indegree of each vertex in these forests is at most $k$. We describe a min-max characterization for this problem and show that it can be solved in almost linear time for fixed $k$, extending the algorithm of [Gabow, 1995]. Specifically, the complexity is $O(k \delta m \log n)$, where $n, m$ are the number of vertices and edges in $G$ respectively, and $\delta = \max\{1, k - k_G\}$, where $k_G$ is the edge connectivity of the graph. Using our solution to this problem, we improve complexities for two existing applications:
  (1) $k$-forest problem: find $k$ forests in an undirected graph $G$ maximizing the number of edges in their union. We show how to solve this problem in $O(k^3 \min\{kn, m\} \log^2 n + k \cdot{\rm MAXFLOW}(m, m) \log n)$ time, breaking the $O_k(n^{3/2})$ complexity barrier of previously known approaches.
  (2) Directed edge-connectivity augmentation problem: find a smallest set of directed edges whose addition to the given directed graph makes it strongly $k$-connected. We improve the deterministic complexity for this problem from $O(k \delta (m+\delta n)\log n)$ [Gabow, STOC 1994] to $O(k \delta m \log n)$. A similar approach with the same complexity also works for the undirected version of the problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.20314v3</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pavel Arkhipov, Vladimir Kolmogorov</dc:creator>
    </item>
    <item>
      <title>Complexity Gaps between Point and Interval Temporal Graphs for some Reachability Problems</title>
      <link>https://arxiv.org/abs/2501.11380</link>
      <description>arXiv:2501.11380v2 Announce Type: replace 
Abstract: Temporal graphs arise when modeling interactions that evolve over time. They usually come in several flavors, depending on the number of parameters used to describe the temporal aspects of the interactions: time of appearance, duration, delay of transmission. In the point model, edges appear at specific points in time, whereas in the more general interval model, edges can be present over specific time intervals. In both models, the delay for traversing an edge can change with each edge appearance. When time is discrete, the two models are equivalent in the sense that the presence of an edge during an interval is equivalent to a sequence of point-in-time occurrences of the edge. However, this transformation can drastically change the size of the input and has implications for complexity. Indeed, we show a gap between the two models with respect to the complexity of the classical problem of computing a fastest temporal path from a source vertex to a target vertex, i.e. a path where edges can be traversed one after another in time and such that the total duration from source to target is minimized. It can be solved in near-linear time in the point model, while we show that the interval model requires quadratic time under classical assumptions of fine-grained complexity. With respect to linear time, our lower bound implies a factor of the number of vertices, while the best known algorithm has a factor of the number of underlying edges. We also show a similar complexity gap for computing a shortest temporal path, i.e. a temporal path with a minimum number of edges. Here our lower bound matches known upper bounds up to a logarithmic factor. Interestingly, we show that near-linear time for fastest temporal path computation is possible in the interval model when it is restricted to uniform delay zero, i.e., when traversing an edge is instantaneous. However, this special case is not exempt from our lower bound for shortest temporal path computation. These two results should be contrasted with the computation of a foremost temporal path, i.e., a temporal path that arrives as early as possible. It is well known that this computation can be solved in near-linear time in both models. We also show that there is no gap in testing the all-to-all temporal connectivity of a temporal graph. We demonstrate a quadratic lower bound that applies to both the interval and point models and aligns with the existing upper bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11380v2</guid>
      <category>cs.DS</category>
      <category>math.CO</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guillaume Aubian (IRIF), Filippo Brunelli (JRC), Feodor F Dragan (UniBuc, ICI), Guillaume Ducoffe (UniBuc, ICI), Michel Habib (IRIF), Allen Ibiapina (IRIF), Laurent Viennot (DI-ENS, ARGO)</dc:creator>
    </item>
    <item>
      <title>Quantum generalizations of Glauber and Metropolis dynamics</title>
      <link>https://arxiv.org/abs/2405.20322</link>
      <description>arXiv:2405.20322v2 Announce Type: replace-cross 
Abstract: Classical Markov Chain Monte Carlo methods have been essential for simulating statistical physical systems and have proven well applicable to other systems with many degrees of freedom. Motivated by the statistical physics origins, Chen, Kastoryano, and Gily\'en [CKG23] proposed a continuous-time quantum thermodynamic analogue to Glauber dynamics that is (i) exactly detailed balanced, (ii) efficiently implementable, and (iii) quasi-local for geometrically local systems. Physically, their construction resembles the dissipative dynamics arising from weak system-bath interaction. In this work, we give an efficiently implementable discrete-time counterpart to any continuous-time quantum Gibbs sampler. Our construction preserves the desirable features (i)-(iii) while does not decrease the spectral gap. Also, we give an alternative highly coherent quantum generalization of detailed balanced dynamics that resembles another physically derived master equation, and propose a smooth interpolation between this and earlier constructions. Moreover, we show how to make earlier Metropolis-style Gibbs samplers (which estimate energies both before and after jumps) exactly detailed balanced. We study generic properties of all constructions, including the uniqueness of the fixed point, the (quasi-)locality of the resulting operators. Finally, we prove that the spectral gap of our new highly coherent Gibbs sampler is constant at high temperatures, thereby it mixes fast. We hope that our systematic approach to quantum Glauber and Metropolis dynamics will lead to widespread applications in various domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20322v2</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andr\'as Gily\'en, Chi-Fang Chen, Joao F. Doriguello, Michael J. Kastoryano</dc:creator>
    </item>
    <item>
      <title>Optimizing Sparse SYK</title>
      <link>https://arxiv.org/abs/2506.09037</link>
      <description>arXiv:2506.09037v2 Announce Type: replace-cross 
Abstract: Finding the ground state of strongly-interacting fermionic systems is often the prerequisite for fully understanding both quantum chemistry and condensed matter systems. The Sachdev--Ye--Kitaev (SYK) model is a representative example of such a system; it is particularly interesting not only due to the existence of efficient quantum algorithms preparing approximations to the ground state such as Hastings--O'Donnell (STOC 2022), but also known no-go results for many classical ansatzes in preparing low-energy states. However, this quantum-classical separation is known to \emph{not} persist when the SYK model is sufficiently sparsified, i.e., when terms in the model are discarded with probability $1-p$, where $p=\Theta(1/n^3)$ and $n$ is the system size. This raises the question of how robust the quantum and classical complexities of the SYK model are to sparsification.
  In this work we initiate the study of the sparse SYK model where $p \in [\Theta(1/n^3),1]$ and show there indeed exists a certain robustness of sparsification. We prove that with high probability, Gaussian states achieve only a $\Theta(1/\sqrt{n})$-factor approximation to the true ground state energy of sparse SYK for all $p\geq\Omega(\log n/n^2)$, and that Gaussian states cannot achieve constant-factor approximations unless $p \leq O(\log^2 n/n^3)$. Additionally, we prove that the quantum algorithm of Hastings--O'Donnell still achieves a constant-factor approximation to the ground state energy when $p\geq\Omega(\log n/n)$. Combined, these show a provable separation between classical algorithms outputting Gaussian states and efficient quantum algorithms for the goal of finding approximate sparse SYK ground states whenever $p \geq \Omega(\log n/n)$, extending the analogous $p=1$ result of Hastings--O'Donnell.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.09037v2</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matthew Ding, Robbie King, Bobak T. Kiani, Eric R. Anschuetz</dc:creator>
    </item>
    <item>
      <title>Minimum Envy Graphical House Allocation Beyond Identical Valuations</title>
      <link>https://arxiv.org/abs/2601.15864</link>
      <description>arXiv:2601.15864v2 Announce Type: replace-cross 
Abstract: House allocation is an extremely well-studied problem in the field of fair allocation, where the goal is to assign $n$ houses to $n$ agents while satisfying certain fairness criterion, e.g., envy-freeness. To model social interactions, the Graphical House Allocation framework introduces a social graph $G$, in which each vertex corresponds to an agent, and an edge $(u, v)$ corresponds to the potential of agent $u$ to envy the agent $v$, based on their allocations and valuations. In undirected social graphs, the potential for envy is in both the directions. In the Minimum Envy Graphical House Allocation (ME-GHA) problem, given a set of $n$ agents, $n$ houses, a social graph, and agent's valuation functions, the goal is to find an allocation that minimizes the total envy summed up over all the edges of $G$. Recent work, [Hosseini et al., AAMAS 2023, AAMAS 2024] studied ME-GHA in the regime of polynomial-time algorithms, and designed exact and approximation algorithms, for certain graph classes under identical agent valuations. We initiate the study of \gha with non-identical valuations, a setting that has so far remained unexplored. We investigate the multivariate (parameterized) complexity of \gha by identifying structural restrictions on the social graph and valuation functions that yield tractability. We also design moderately exponential-time algorithms for several graph classes, and a polynomial-time algorithm for {binary valuations that returns an allocation with envy at most one when the social graph has maximum degree at most one.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.15864v2</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tanmay Inamdar, Pallavi Jain, Pranjal Pandey</dc:creator>
    </item>
  </channel>
</rss>
