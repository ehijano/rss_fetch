<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.EM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.EM</link>
    <description>econ.EM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.EM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 27 Aug 2025 01:39:35 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Nonlinear Impulse Response Functions and Local Projections</title>
      <link>https://arxiv.org/abs/2305.18145</link>
      <description>arXiv:2305.18145v2 Announce Type: replace 
Abstract: The goal of this paper is to extend the nonparametric estimation of Impulse Response Functions (IRF) by means of local projections in the nonlinear dynamic framework. We discuss the existence of a nonlinear autoregressive representation for Markov processes and explain how their IRFs are directly linked to the Nonlinear Local Projection (NLP), as in the case for the linear setting. We present a fully nonparametric LP estimator in the one dimensional nonlinear framework, compare its asymptotic properties to that of IRFs implied by the nonlinear autoregressive model and show that the two approaches are asymptotically equivalent. This extends the well-known result in the linear autoregressive model by Plagborg-Moller and Wolf (2017). We also consider extensions to the multivariate framework through the lens of semiparametric models, and demonstrate that the indirect approach by the NLP is less accurate than the direct estimation approach of the IRF.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.18145v2</guid>
      <category>econ.EM</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christian Gourieroux, Quinlan Lee</dc:creator>
    </item>
    <item>
      <title>Inference on Multiple Winners with Applications to Economic Mobility</title>
      <link>https://arxiv.org/abs/2410.19212</link>
      <description>arXiv:2410.19212v4 Announce Type: replace 
Abstract: This paper considers the problem of inference on multiple winners. In our setting, a winner is defined abstractly as any population whose rank according to some random quantity, such as an estimated treatment effect, a measure of value-added, or benefit (net of cost), falls in a pre-specified range of values. As such, this framework generalizes the inference on a single winner setting previously considered in Andrews et al. (2023), in which a winner is understood to be the single population whose rank according to some random quantity is highest. We show that this richer setting accommodates a broad variety of empirically-relevant applications. We develop a two-step method for inference in the spirit of Romano et al. (2014), which we compare to existing methods or their natural generalizations to this setting. We first show the finite-sample validity of this method in a normal location model and then develop asymptotic counterparts to these results by proving uniform validity over a large class of distributions satisfying a weak uniform integrability condition. Importantly, our results permit degeneracy in the covariance matrix of the limiting distribution, which arises naturally in many applications. In an application to the literature on economic mobility, we find that it is difficult to distinguish between high and low mobility census tracts when correcting for selection. Finally, we demonstrate the practical relevance of our theoretical results through an extensive set of simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.19212v4</guid>
      <category>econ.EM</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Andreas Petrou-Zeniou, Azeem M. Shaikh</dc:creator>
    </item>
    <item>
      <title>Simultaneous Inference Bands for Autocorrelations</title>
      <link>https://arxiv.org/abs/2503.18560</link>
      <description>arXiv:2503.18560v2 Announce Type: replace 
Abstract: Sample autocorrelograms typically come with significance bands (non-rejection regions) for the null hypothesis of no temporal correlation. These bands have two shortcomings. First, they build on pointwise intervals and suffer from joint undercoverage (overrejection) under the null hypothesis. Second, if this null is clearly violated one would rather prefer to see confidence bands to quantify estimation uncertainty. We propose and discuss both simultaneous significance bands and simultaneous confidence bands for time series and series of regression residuals. They are as easy to construct as their pointwise counterparts and at the same time provide an intuitive and visual quantification of sampling uncertainty as well as valid statistical inference. For regression residuals, we show that for static regressions the asymptotic variances underlying the construction of the bands are the same as those for observed time series, and for dynamic regressions (with lagged endogenous regressors) we show how they need to be adjusted. We study theoretical properties of simultaneous significance bands and two types of simultaneous confidence bands (sup-t and Bonferroni) and analyse their finite-sample performance in a simulation study. Finally, we illustrate the use of the bands in an application to monthly US inflation and residuals from Phillips curve regressions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.18560v2</guid>
      <category>econ.EM</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Uwe Hassler, Marc-Oliver Pohle, Tanja Zahn</dc:creator>
    </item>
    <item>
      <title>Assignment at the Frontier: Identifying the Frontier Structural Function and Bounding Mean Deviations</title>
      <link>https://arxiv.org/abs/2504.19832</link>
      <description>arXiv:2504.19832v4 Announce Type: replace 
Abstract: This paper analyzes a model in which an outcome equals a frontier function of inputs minus a nonnegative unobserved deviation. We allow the deviation's distribution to depend on inputs, thereby allowing for endogeneity. If zero lies in the support of the deviation given inputs -- an assumption we term assignment at the frontier -- then the frontier is identified by the supremum of the outcome at those inputs, obviating the need for instrumental variables. We then estimate the frontier, allowing for random error whose distribution may also depend on inputs. Finally, we derive a lower bound on the mean deviation, using only variance and skewness, that is robust to a scarcity of data near the frontier. We apply our methods to estimate a firm-level frontier production function and mean inefficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19832v4</guid>
      <category>econ.EM</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dan Ben-Moshe, David Genesove</dc:creator>
    </item>
    <item>
      <title>The purpose of an estimator is what it does: Misspecification, estimands, and over-identification</title>
      <link>https://arxiv.org/abs/2508.13076</link>
      <description>arXiv:2508.13076v2 Announce Type: replace 
Abstract: In over-identified models, misspecification -- the norm rather than exception -- fundamentally changes what estimators estimate. Different estimators imply different estimands rather than different efficiency for the same target. A review of recent applications of generalized method of moments in the American Economic Review suggests widespread acceptance of this fact: There is little formal specification testing and widespread use of estimators that would be inefficient were the model correct, including the use of "hand-selected" moments and weighting matrices. Motivated by these observations, we review and synthesize recent results on estimation under model misspecification, providing guidelines for transparent and robust empirical research. We also provide a new theoretical result, showing that Hansen's J-statistic measures, asymptotically, the range of estimates achievable at a given standard error. Given the widespread use of inefficient estimators and the resulting researcher degrees of freedom, we thus particularly recommend the broader reporting of J-statistics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.13076v2</guid>
      <category>econ.EM</category>
      <category>stat.ME</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Isaiah Andrew, Jiafeng Chen, Otavio Tecchio</dc:creator>
    </item>
    <item>
      <title>Factorial Difference-in-Differences</title>
      <link>https://arxiv.org/abs/2407.11937</link>
      <description>arXiv:2407.11937v4 Announce Type: replace-cross 
Abstract: We formulate factorial difference-in-differences (FDID) as a research design that extends the canonical difference-in-differences (DID) to settings without clean controls. Such situations often arise when researchers exploit cross-sectional variation in a baseline factor and temporal variation in an event affecting all units. In these applications, the exact estimand is often unspecified and justification for using the DID estimator is unclear. We formalize FDID by characterizing its data structure, target parameters, and identifying assumptions. Framing FDID as a factorial design with two factors -- the baseline factor G and the exposure level Z, we define effect modification and causal moderation as the associative and causal effects of G on the effect of Z. Under standard DID assumptions, including no anticipation and parallel trends, the DID estimator identifies effect modification but not causal moderation. To identify the latter, we propose an additional factorial parallel trends assumption. We also show that the canonical DID is a special case of FDID under an exclusion restriction. We extend the framework to conditionally valid assumptions and clarify regression-based implementations. We then discuss extensions to repeated cross-sectional data and continuous G. We illustrate the approach with an empirical example on the role of social capital in famine relief in China.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.11937v4</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yiqing Xu, Anqi Zhao, Peng Ding</dc:creator>
    </item>
  </channel>
</rss>
