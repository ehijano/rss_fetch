<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CC</link>
    <description>cs.CC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 07 Nov 2024 05:00:11 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Algebraic metacomplexity and representation theory</title>
      <link>https://arxiv.org/abs/2411.03444</link>
      <description>arXiv:2411.03444v1 Announce Type: new 
Abstract: We prove that in the algebraic metacomplexity framework, the decomposition of metapolynomials into their isotypic components can be implemented efficiently, namely with only a quasipolynomial blowup in the circuit size. This means that many existing algebraic complexity lower bound proofs can be efficiently converted into isotypic lower bound proofs via highest weight metapolynomials, a notion studied in geometric complexity theory. In the context of algebraic natural proofs, our result means that without loss of generality algebraic natural proofs can be assumed to be isotypic. Our proof is built on the Poincar\'e--Birkhoff--Witt theorem for Lie algebras and on Gelfand--Tsetlin theory, for which we give the necessary comprehensive background.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03444v1</guid>
      <category>cs.CC</category>
      <category>math.AG</category>
      <category>math.RT</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maxim van den Berg, Pranjal Dutta, Fulvio Gesmundo, Christian Ikenmeyer, Vladimir Lysikov</dc:creator>
    </item>
    <item>
      <title>Condensing Against Online Adversaries</title>
      <link>https://arxiv.org/abs/2411.04115</link>
      <description>arXiv:2411.04115v1 Announce Type: new 
Abstract: We investigate the task of deterministically condensing randomness from Online Non-Oblivious Symbol Fixing (oNOSF) sources, a natural model for which extraction is impossible [AORSV, EUROCRYPT'20]. A $(g,\ell)$-oNOSF source is a sequence of $\ell$ blocks where at least $g$ of the blocks are good (independent and have some min-entropy) and the remaining bad blocks are controlled by an online adversary where each bad block can be arbitrarily correlated with any block that appears before it.
  The existence of condensers was studied in [CGR, FOCS'24]. They proved condensing impossibility results for various values of $g, \ell$ and showed the existence of condensers matching the impossibility results in the case when $n$ is extremely large compared to $\ell$.
  In this work, we make significant progress on proving the existence of condensers with strong parameters in almost all parameter regimes, even when $n$ is a large enough constant and $\ell$ is growing. This almost resolves the question of the existence of condensers for oNOSF sources, except when $n$ is a small constant.
  We construct the first explicit condensers for oNOSF sources, achieve parameters that match the existential results of [CGR, FOCS'24], and obtain an improved construction for transforming low-entropy oNOSF sources into uniform ones.
  We find applications of our results to collective coin flipping and sampling, well-studied problems in fault-tolerant distributed computing. We use our condensers to provide simple protocols for these problems.
  To understand the case of small $n$, we focus on $n=1$ which corresponds to online non-oblivious bit-fixing (oNOBF) sources. We initiate a study of a new, natural notion of influence of Boolean functions which we call online influence. We establish tight bounds on the total online influence of Boolean functions, implying extraction lower bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04115v1</guid>
      <category>cs.CC</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eshan Chattopadhyay, Mohit Gurumukhani, Noam Ringach</dc:creator>
    </item>
    <item>
      <title>On the (Classical and Quantum) Fine-Grained Complexity of Log-Approximate CVP and Max-Cut</title>
      <link>https://arxiv.org/abs/2411.04124</link>
      <description>arXiv:2411.04124v1 Announce Type: new 
Abstract: We show a linear sized reduction from the Maximum Cut Problem (Max-Cut) with completeness $1 - \varepsilon$ and soundness $1 - \varepsilon^{1/2}$ to the $\gamma$-Approximate Closest Vector Problem under any finite $\ell_p$-norm including $p = 2$.
  This reduction implies two headline results: (i) We show that any sub-exponential time (classical or quantum) algorithm for the $o(\sqrt{\log n}^{\frac{1}{p}})$-Approximate Closest Vector Problem in any finite $\ell_p$-norm implies a faster than the state-of-the-art (by Arora, Barak, and Steurer [\textit{Journal of the ACM}, 2015]) sub-exponential time (classical or quantum) algorithm for Max-Cut. This fills the gap between the results by Bennett, Golovnev, and Stephens-Davidowitz [\textit{FOCS} 2017] which had an almost optimal runtime lower bound but a very small approximation factor and the results by Dinur, Kindler, Raz, and Safra [\textit{Combinatorica}, 2003] which had an almost optimal approximation factor but small runtime lower bound, albeit using a different underlying hard problem; (ii) in combination with the classical results of Aggarwal and Kumar [\textit{FOCS} 2023] and our quantization of those results, there are no fine-grained reductions from $k$-SAT to Max-Cut with one-sided error, nor are there non-adaptive fine-grained (classical or quantum) reductions with two-sided error, unless the polynomial hierarchy collapses (or unless $\mathrm{NP} \subseteq \mathrm{pr} \text{-} \mathrm{QSZK}$ in the quantum case). The second result poses a significant barrier against proving the fine-grained complexity of Max-Cut using the Strong Exponential Time Hypothesis (or the Quantum Strong Exponential Time Hypothesis).</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04124v1</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>quant-ph</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jeremy Ahrens Huang, Young Kun Ko, Chunhao Wang</dc:creator>
    </item>
    <item>
      <title>Complexity Theory for Quantum Promise Problems</title>
      <link>https://arxiv.org/abs/2411.03716</link>
      <description>arXiv:2411.03716v1 Announce Type: cross 
Abstract: Quantum computing introduces many problems rooted in physics, asking to compute information from input quantum states. Determining the complexity of these problems has implications for both computer science and physics. However, as existing complexity theory primarily addresses problems with classical inputs and outputs, it lacks the framework to fully capture the complexity of quantum-input problems. This gap is relevant when studying the relationship between quantum cryptography and complexity theory, especially within Impagliazzo's five worlds framework, as characterizing the security of quantum cryptographic primitives requires complexity classes for problems involving quantum inputs. To bridge this gap, we examine the complexity theory of quantum promise problems, which determine if input quantum states have certain properties. We focus on complexity classes p/mBQP, p/mQ(C)MA, $\mathrm{p/mQSZK_{hv}}$, p/mQIP, and p/mPSPACE, where "p/mC" denotes classes with pure (p) or mixed (m) states corresponding to any classical class C. We establish structural results, including complete problems, search-to-decision reductions, and relationships between classes. Notably, our findings reveal differences from classical counterparts, such as p/mQIP $\neq$ p/mPSPACE and $\mathrm{mcoQSZK_{hv}} \neq \mathrm{mQSZK_{hv}}$. As an application, we apply this framework to cryptography, showing that breaking one-way state generators, pseudorandom states, and EFI is bounded by mQCMA or $\mathrm{mQSZK_{hv}}$. We also show that the average-case hardness of $\mathrm{pQCZK_{hv}}$ implies the existence of EFI. These results provide new insights into Impagliazzo's worlds, establishing a connection between quantum cryptography and quantum promise complexity theory. We also extend our findings to quantum property testing and unitary synthesis, highlighting further applications of this new framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03716v1</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Nai-Hui Chia, Kai-Min Chung, Tzu-Hsiang Huang, Jhih-Wei Shih</dc:creator>
    </item>
    <item>
      <title>On the satisfiability of random $3$-SAT formulas with $k$-wise independent clauses</title>
      <link>https://arxiv.org/abs/2411.03813</link>
      <description>arXiv:2411.03813v1 Announce Type: cross 
Abstract: The problem of identifying the satisfiability threshold of random $3$-SAT formulas has received a lot of attention during the last decades and has inspired the study of other threshold phenomena in random combinatorial structures. The classical assumption in this line of research is that, for a given set of $n$ Boolean variables, each clause is drawn uniformly at random among all sets of three literals from these variables, independently from other clauses. Here, we keep the uniform distribution of each clause, but deviate significantly from the independence assumption and consider richer families of probability distributions. For integer parameters $n$, $m$, and $k$, we denote by $\DistFamily_k(n,m)$ the family of probability distributions that produce formulas with $m$ clauses, each selected uniformly at random from all sets of three literals from the $n$ variables, so that the clauses are $k$-wise independent. Our aim is to make general statements about the satisfiability or unsatisfiability of formulas produced by distributions in $\DistFamily_k(n,m)$ for different values of the parameters $n$, $m$, and $k$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03813v1</guid>
      <category>math.CO</category>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ioannis Caragiannis, Nick Gravin, Zhile Jiang</dc:creator>
    </item>
    <item>
      <title>Rescheduling after vehicle failures in the multi-depot rural postman problem with rechargeable and reusable vehicles</title>
      <link>https://arxiv.org/abs/2411.04073</link>
      <description>arXiv:2411.04073v1 Announce Type: cross 
Abstract: We present a centralized auction algorithm to solve the Multi-Depot Rural Postman Problem with Rechargeable and Reusable Vehicles (MD-RPP-RRV), focusing on rescheduling arc routing after vehicle failures. The problem involves finding heuristically obtained best feasible routes for multiple rechargeable and reusable vehicles with capacity constraints capable of performing multiple trips from multiple depots, with the possibility of vehicle failures. Our algorithm auctions the failed trips to active (non-failed) vehicles through local auctioning, modifying initial routes to handle dynamic vehicle failures efficiently. When a failure occurs, the algorithm searches for the best active vehicle to perform the failed trip and inserts the trip into that vehicle's route, which avoids a complete rescheduling and reduces the computational effort. We compare the algorithm's solutions against offline optimal solutions obtained from solving a Mixed Integer Linear Programming (MILP) formulation using the Gurobi solver; this formulation assumes that perfect information about the vehicle failures and failure times is given. The results demonstrate that the centralized auction algorithm produces solutions that are, in some cases, near optimal; moreover, the execution time for the proposed approach is much more consistent and is, for some instances, orders of magnitude less than the execution time of the Gurobi solver. The theoretical analysis provides an upper bound for the competitive ratio and computational complexity of our algorithm, offering a formal performance guarantee in dynamic failure scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04073v1</guid>
      <category>cs.RO</category>
      <category>cs.CC</category>
      <category>cs.MA</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Eashwar Sathyamurthy, Jeffrey W. Herrmann, Shapour Azarm</dc:creator>
    </item>
    <item>
      <title>Revisiting BQP with Non-Collapsing Measurements</title>
      <link>https://arxiv.org/abs/2411.04085</link>
      <description>arXiv:2411.04085v1 Announce Type: cross 
Abstract: The study of non-collapsing measurements was initiated by Aaronson, Bouland, Fitzsimons, and Lee, who showed that BQP, when equipped with the ability to perform non-collapsing measurements (denoted as PDQP), contains both BQP and SZK, yet still requires $\Omega (N^{1/4})$ queries to find an element in an unsorted list.
  By formulating an alternative equivalent model of PDQP, we prove the positive weighted adversary method, obtaining a variety of new lower bounds and establishing a trade-off between queries and non-collapsing measurements. The method allows us to examine the well-studied majority and element distinctness problems, while also tightening the bound for the search problem to $\Theta (N^{1/3})$. Additionally, we explore related settings, obtaining tight bounds in BQP with the ability to copy arbitrary states (called CBQP) and PDQP with non-adaptive queries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04085v1</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>David Miloschewsky, Supartha Podder</dc:creator>
    </item>
    <item>
      <title>Fourier Analysis of Iterative Algorithms</title>
      <link>https://arxiv.org/abs/2404.07881</link>
      <description>arXiv:2404.07881v2 Announce Type: replace 
Abstract: We study a general class of nonlinear iterative algorithms which includes power iteration, belief propagation and approximate message passing, and many forms of gradient descent. When the input is a random matrix with i.i.d. entries, we use Boolean Fourier analysis to analyze these algorithms as low-degree polynomials in the entries of the input matrix. Each symmetrized Fourier character represents all monomials with a certain shape as specified by a small graph, which we call a Fourier diagram.
  We prove fundamental asymptotic properties of the Fourier diagrams: over the randomness of the input, all diagrams with cycles are negligible; the tree-shaped diagrams form a basis of asymptotically independent Gaussian vectors; and, when restricted to the trees, iterative algorithms exactly follow an idealized Gaussian dynamic. We use this to prove a state evolution formula, giving a "complete" asymptotic description of the algorithm's trajectory.
  The restriction to tree-shaped monomials mirrors the assumption of the cavity method, a 40-year-old non-rigorous technique in statistical physics which has served as one of the most important techniques in the field. We demonstrate how to implement cavity method derivations by 1) restricting the iteration to its tree approximation, and 2) observing that heuristic cavity method-type arguments hold rigorously on the simplified iteration. Our proofs use combinatorial arguments similar to the trace method from random matrix theory.
  Finally, we push the diagram analysis to a number of iterations that scales with the dimension $n$ of the input matrix, proving that the tree approximation still holds for a simple variant of power iteration all the way up to $n^{\Omega(1)}$ iterations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07881v2</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chris Jones, Lucas Pesenti</dc:creator>
    </item>
    <item>
      <title>Rounding Large Independent Sets on Expanders</title>
      <link>https://arxiv.org/abs/2405.10238</link>
      <description>arXiv:2405.10238v2 Announce Type: replace-cross 
Abstract: We develop a new approach for approximating large independent sets when the input graph is a one-sided spectral expander - that is, the uniform random walk matrix of the graph has its second eigenvalue bounded away from 1. Consequently, we obtain a polynomial time algorithm to find linear-sized independent sets in one-sided expanders that are almost $3$-colorable or are promised to contain an independent set of size $(1/2-\epsilon)n$. Our second result above can be refined to require only a weaker vertex expansion property with an efficient certificate. In a surprising contrast to our algorithmic result, we observe that the analogous task of finding a linear-sized independent set in almost $4$-colorable one-sided expanders (even when the second eigenvalue is $o_n(1)$) is NP-hard, assuming the Unique Games Conjecture.
  All prior algorithms that beat the worst-case guarantees for this problem rely on bottom eigenspace enumeration techniques (following the classical spectral methods of Alon and Kahale) and require two-sided expansion, meaning a bounded number of negative eigenvalues of magnitude $\Omega(1)$. Such techniques naturally extend to almost $k$-colorable graphs for any constant $k$, in contrast to analogous guarantees on one-sided expanders, which are Unique Games-hard to achieve for $k \geq 4$.
  Our rounding builds on the method of simulating multiple samples from a pseudo-distribution introduced by Bafna et. al. for rounding Unique Games instances. The key to our analysis is a new clustering property of large independent sets in expanding graphs - every large independent set has a larger-than-expected intersection with some member of a small list - and its formalization in the low-degree sum-of-squares proof system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10238v2</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mitali Bafna, Jun-Ting Hsieh, Pravesh K. Kothari</dc:creator>
    </item>
    <item>
      <title>Sensitivity Lower Bounds for Approximaiton Algorithms</title>
      <link>https://arxiv.org/abs/2411.02744</link>
      <description>arXiv:2411.02744v2 Announce Type: replace-cross 
Abstract: Sensitivity measures how much the output of an algorithm changes, in terms of Hamming distance, when part of the input is modified. While approximation algorithms with low sensitivity have been developed for many problems, no sensitivity lower bounds were previously known for approximation algorithms. In this work, we establish the first polynomial lower bound on the sensitivity of (randomized) approximation algorithms for constraint satisfaction problems (CSPs) by adapting the probabilistically checkable proof (PCP) framework to preserve sensitivity lower bounds. From this, we derive polynomial sensitivity lower bounds for approximation algorithms for a variety of problems, including maximum clique, minimum vertex cover, and maximum cut.
  Given the connection between sensitivity and distributed algorithms, our sensitivity lower bounds also allow us to recover various round complexity lower bounds for distributed algorithms in the LOCAL model. Additionally, we present new lower bounds for distributed CSPs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.02744v2</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Noah Fleming, Yuichi Yoshida</dc:creator>
    </item>
    <item>
      <title>Practical, optimal preparation of general quantum state with exponentially improved robustness</title>
      <link>https://arxiv.org/abs/2411.02782</link>
      <description>arXiv:2411.02782v2 Announce Type: replace-cross 
Abstract: Quantum state preparation, as a general process of loading classical data to quantum device, is essential for end-to-end implementation of quantum algorithms. Yet, existing methods suffer from either high circuit depth or complicated hardware, limiting their practicality and robustness. In this work, we overcome these limitations with a bucket-brigade approach. The tree architectures of our hardware represents the simplest connectivity required for achieving sub-exponential circuit depth. Leveraging the bucket-brigade mechanism that can suppress the error propagation between different branches, our approach exhibit exponential improvement on the robustness compared to existing depth-optimal methods. More specifically, the infidelity scales as $O(\text{polylog}(N))$ with data size $N$, as oppose to $O(N)$ for conventional methods. Moreover, our approach is the first to simultaneously achieve linear Clifford$+T$ circuit depth, gate count number, and space-time allocation. These advancements offer the opportunity for processing big data in both near-term and fault-tolerant quantum devices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.02782v2</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>physics.comp-ph</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiao-Ming Zhang</dc:creator>
    </item>
  </channel>
</rss>
