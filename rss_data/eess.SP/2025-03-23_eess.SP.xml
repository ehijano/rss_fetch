<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>eess.SP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/eess.SP</link>
    <description>eess.SP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/eess.SP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 24 Mar 2025 04:00:16 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Multifractal analysis based on the weak scaling exponent and applications to MEG recordings in neuroscience</title>
      <link>https://arxiv.org/abs/2503.16892</link>
      <description>arXiv:2503.16892v1 Announce Type: new 
Abstract: We develop the mathematical properties of a multifractal analysis of data based on the weak scaling exponent. The advantage of this analysis is that it does not require any a priori global regularity assumption on the analyzed signal, in contrast with the previously used H{\"o}lder or p-exponents. As an illustration, we show that this technique allows one to perform a multifractal analysis of MEG signals, which records electromagnetic brain activity, that was not theoretically valid using the formerly introduced methods based on H{\"o}lder or p-exponents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16892v1</guid>
      <category>eess.SP</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Patrice Abry (Phys-ENS), Phipippe Ciuciu (NEUROSPIN, MIND), Merlin Dumeur (NEUROSPIN), St\'ephane Jaffard (LAMA), Guillaume Sa\"es (LAMA)</dc:creator>
    </item>
    <item>
      <title>mmTracking: Trajectory Tracking for Uplink mmWave Devices with Multi-Path Doppler Difference of Arrival</title>
      <link>https://arxiv.org/abs/2503.16909</link>
      <description>arXiv:2503.16909v1 Announce Type: new 
Abstract: This paper presents a method, namely mmTracking, for device trajectory tracking in a millimeter wave (mmWave) communication system. In mmTracking, the base station (BS) relies on one line-of-sight (LoS) path and at least two non-line-of-sight (NLoS) paths, which are reflected off two walls respectively, of the uplink channel to track the location of a mobile device versus time. There are at least three radio frequency (RF) chains at the BS. Analog phased array with narrow and adjustable receive beam is connected to each RF chain to capture one signal path, where the angle of arrival (AoA) can be roughly estimated. Due to the carrier frequency offset between the transmitter and the BS, the Doppler frequency of each path could hardly be estimated accurately. Instead, the differences of Doppler frequencies of the three paths can be estimated with much better accuracy. Therefore, a trajectory tracking method based on the Doppler difference and AoA estimations is proposed in mmTracking. Experimental results in a typical indoor environment demonstrate that the average error of transmitter localization and trajectory tracking is less than 20 cm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16909v1</guid>
      <category>eess.SP</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cheng Lin, Chao Yu, Xiaowei Xu, Rui Wang</dc:creator>
    </item>
    <item>
      <title>Efficient Deployment of Deep MIMO Detection Using Learngene</title>
      <link>https://arxiv.org/abs/2503.16931</link>
      <description>arXiv:2503.16931v1 Announce Type: new 
Abstract: Deep learning (DL) has introduced a new paradigm in multiple-input multiple-output (MIMO) detection, balancing performance and complexity. However, the practical deployment of DL-based detectors is hindered by poor generalization, necessitating costly retraining for different devices and scenarios. To address this challenge, this paper presents a novel knowledge transfer technique, termed learngene, for the design of a DL-based MIMO detector and proposes an efficient deployment framework. The proposed detector, SDNet, leverages zero-forcing detection outputs and least squares-estimated channel state information (CSI) as inputs. It is further optimized through a collective-individual paradigm to enhance knowledge transfer. In this paradigm, learngene, a reusable neural network (NN) segment, encapsulates detection meta-knowledge acquired from large-scale collective models trained by manufacturers. This segment can then be distributed to device-specific teams. By integrating learngene into different lightweight individual models, detection meta-knowledge is efficiently transferred across heterogeneous NNs, enabling adaptation to diverse devices and scenarios. Simulation results demonstrate that the proposed scheme enhances performance, enables rapid adaptation, and ensures high scalability, with transferred parameters comprising only 10.8% of the total model size.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16931v1</guid>
      <category>eess.SP</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jinya Zhang, Jiajia Guo, Xiangyi Li, Chao-Kai Wen, Xin Geng, Shi Jin</dc:creator>
    </item>
    <item>
      <title>Minimum Mean Squared Error Holographic Beamforming for Sum-Rate Maximization</title>
      <link>https://arxiv.org/abs/2503.17205</link>
      <description>arXiv:2503.17205v1 Announce Type: new 
Abstract: This paper studies the problem of hybrid holographic beamforming for sum-rate maximization in a communication system assisted by a reconfigurable holographic surface. Existing methodologies predominantly rely on gradient-based or approximation techniques necessitating iterative optimization for each update of the holographic response, which imposes substantial computational overhead. To address these limitations, we establish a mathematical relationship between the mean squared error (MSE) criterion and the holographic response of the RHS to enable alternating optimization based on the minimum MSE (MMSE). Our analysis demonstrates that this relationship exhibits a quadratic dependency on each element of the holographic beamformer. Exploiting this property, we derive closed-form optimal expressions for updating the holographic beamforming weights. Our complexity analysis indicates that the proposed approach exhibits only linear complexity in terms of the RHS size, thus, ensuring scalability for large-scale deployments. The presented simulation results validate the effectiveness of our MMSE-based holographic approach, providing useful insights.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.17205v1</guid>
      <category>eess.SP</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chandan Kumar Sheemar, Wali Ullah Khan, George C. Alexandropoulos, Manzoor Ahmed, Symeon Chatzinotas</dc:creator>
    </item>
    <item>
      <title>On the Sensing Performance of FMCW-based Integrated Sensing and Communications with Arbitrary Constellations</title>
      <link>https://arxiv.org/abs/2503.17215</link>
      <description>arXiv:2503.17215v1 Announce Type: new 
Abstract: Integrated sensing and communications (ISAC) is expected to play a major role in numerous future applications, e.g., smart cities. Leveraging native radar signals like the frequency modulated continuous wave (FMCW) waveform additionally for data transmission offers a highly efficient use of valuable physical radio frequency (RF) resources allocated for automotive radar applications. In this paper, we propose the adoption of higher-order modulation formats for data modulation onto an FMCW waveform and provide a comprehensive overview of the entire signal processing chain. We evaluate the impact of each component on the overall sensing performance. While alignment algorithms are essential for removing the information signal at the sensing receiver, they also introduce significant dispersion to the received signal. We analyze this effect in detail. Notably, we demonstrate that the impact of non-constant amplitude modulation on sensing performance is statistically negligible when the complete signal processing chain is considered. This finding highlights the potential for achieving high data rates in FMCW-ISAC systems without compromising the sensing capabilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.17215v1</guid>
      <category>eess.SP</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniel Gil Gaviria, Benedikt Geiger, Charlotte Muth, Laurent Schmalen</dc:creator>
    </item>
    <item>
      <title>Cross-Band Modulation Design for Hybrid RF-Optical Systems</title>
      <link>https://arxiv.org/abs/2503.17296</link>
      <description>arXiv:2503.17296v1 Announce Type: new 
Abstract: We present a novel cross-band modulation framework that combines 3D modulation in the RF domain with intensity modulation and direct detection in the optical domain, the first such integration to enhance communication reliability. By harnessing cross-band diversity, the framework optimizes symbol mapping across RF and optical links, significantly boosting mutual information (MI) and reducing symbol error probability (SEP). Two practical modulation schemes implement this framework, both using quadrature amplitude modulation in the RF subsystem. The first is a linear cross-band mapping scheme, where RF symbols are mapped to optical intensity values via an analytically tractable optimization that ensures O(1) detection complexity while minimizing SEP. The second employs a deep neural network-generated (DNN-Gen) 3D constellation with a custom loss function that adaptively optimizes symbol placement to maximize MI and minimize SEP. Although DNN-Gen incurs higher computational complexity than the linear approach, it adapts the 3D constellation to varying signal-to-noise ratios, yielding significant performance gains. Furthermore, we derive a theoretical MI benchmark for the linear scheme, offering insights into the fundamental limits of RF-optical cross-band communication. Extensive Monte Carlo simulations confirm that both schemes outperform SoA cross-band modulation techniques, including cross-band pulse amplitude modulation, with notable improvements. Additionally, DNN-Gen maintains high performance over a range of RF SNRs, lessening the need for exhaustive training at every operating condition. Overall, these results establish our cross-band modulation framework as a scalable, high-performance solution for next-generation hybrid RF-optical networks, balancing low complexity with optimized symbol mapping to maximize system reliability and efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.17296v1</guid>
      <category>eess.SP</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thrassos K. Oikonomou, Sotiris A. Tegos, Panagiotis D. Diamantoulakis, George K. Karagiannidis</dc:creator>
    </item>
    <item>
      <title>Bridging Structural Dynamics and Biomechanics: Human Motion Estimation through Footstep-Induced Floor Vibrations</title>
      <link>https://arxiv.org/abs/2503.16455</link>
      <description>arXiv:2503.16455v1 Announce Type: cross 
Abstract: Quantitative estimation of human joint motion in daily living spaces is essential for early detection and rehabilitation tracking of neuromusculoskeletal disorders (e.g., Parkinson's) and mitigating trip and fall risks for older adults. Existing approaches involve monitoring devices such as cameras, wearables, and pressure mats, but have operational constraints such as direct line-of-sight, carrying devices, and dense deployment. To overcome these limitations, we leverage gait-induced floor vibration to estimate lower-limb joint motion (e.g., ankle, knee, and hip flexion angles), allowing non-intrusive and contactless gait health monitoring in people's living spaces. To overcome the high uncertainty in lower-limb movement given the limited information provided by the gait-induced floor vibrations, we formulate a physics-informed graph to integrate domain knowledge of gait biomechanics and structural dynamics into the model. Specifically, different types of nodes represent heterogeneous information from joint motions and floor vibrations; Their connecting edges represent the physiological relationships between joints and forces governed by gait biomechanics, as well as the relationships between forces and floor responses governed by the structural dynamics. As a result, our model poses physical constraints to reduce uncertainty while allowing information sharing between the body and the floor to make more accurate predictions. We evaluate our approach with 20 participants through a real-world walking experiment. We achieved an average of 3.7 degrees of mean absolute error in estimating 12 joint flexion angles (38% error reduction from baseline), which is comparable to the performance of cameras and wearables in current medical practices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16455v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>eess.SP</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yiwen Dong, Jessica Rose, Hae Young Noh</dc:creator>
    </item>
    <item>
      <title>Transformer-based Wireless Symbol Detection Over Fading Channels</title>
      <link>https://arxiv.org/abs/2503.16594</link>
      <description>arXiv:2503.16594v1 Announce Type: cross 
Abstract: Pre-trained Transformers, through in-context learning (ICL), have demonstrated exceptional capabilities to adapt to new tasks using example prompts without model update. Transformer-based wireless receivers, where prompts consist of the pilot data in the form of transmitted and received signal pairs, have shown high detection accuracy when pilot data are abundant. However, pilot information is often costly and limited in practice. In this work, we propose the DEcision Feedback INcontExt Detection (DEFINED) solution as a new wireless receiver design, which bypasses channel estimation and directly performs symbol detection using the (sometimes extremely) limited pilot data. The key innovation in DEFINED is the proposed decision feedback mechanism in ICL, where we sequentially incorporate the detected symbols into the prompts as pseudo-labels to improve the detection for subsequent symbols. Furthermore, we proposed another detection method where we combine ICL with Semi-Supervised Learning (SSL) to extract information from both labeled and unlabeled data during inference, thus avoiding the errors propagated during the decision feedback process of the original DEFINED. Extensive experiments across a broad range of wireless communication settings demonstrate that a small Transformer trained with DEFINED or IC-SSL achieves significant performance improvements over conventional methods, in some cases only needing a single pilot pair to achieve similar performance of the latter with more than 4 pilot pairs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16594v1</guid>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <category>stat.ML</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Li Fan, Jing Yang, Cong Shen</dc:creator>
    </item>
    <item>
      <title>Sparking Curiosity in Digital System Design Lectures with Take Home Labs</title>
      <link>https://arxiv.org/abs/2503.16625</link>
      <description>arXiv:2503.16625v1 Announce Type: cross 
Abstract: Digital system design lectures are mandatory in the electrical and electronics engineering curriculum. Besides HDL simulators and viewers, FPGA boards are necessary for the real implementation of HDL, which were previously costly for students. With the emergence of low-cost FPGA boards, the use of take-home labs is increasing. The COVID-19 pandemic has further accelerated this process. Traditional lab sessions have limitations, prompting the exploration of take-home lab kits to enhance learning flexibility and engagement. This study aims to evaluate the effectiveness of a low-cost take-home lab kit, consisting of a Tang Nano 9K FPGA board and a Saleae Logic Analyzer, in improving students' practical skills and sparking curiosity in digital system design. The research was conducted in the EEE 303 Digital Design lecture. Students used the Tang Nano 9K FPGA and Saleae Logic Analyzer for a term project involving PWM signal generation. Data was collected through a survey assessing the kit's impact on learning and engagement. Positive Acceptance: 75% of students agreed or strongly agreed that the take-home lab kit was beneficial. Preference for Lab Types: 60% of students preferred classical weekly lab hours over take-home labs. Increased Curiosity: 65% of students conducted additional, unassigned experiments, indicating heightened interest and engagement. The take-home lab kit effectively aids in learning practical aspects of digital system design and stimulates curiosity, though some students prefer traditional lab sessions for group work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16625v1</guid>
      <category>cs.CY</category>
      <category>eess.SP</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Senol Gulgonul</dc:creator>
    </item>
    <item>
      <title>UAV-Relay Assisted RSMA Fluid Antenna System: Outage Probability Analysis</title>
      <link>https://arxiv.org/abs/2503.16751</link>
      <description>arXiv:2503.16751v1 Announce Type: cross 
Abstract: This letter studies the impact of fluid antenna system (FAS) technology on the performance of unmanned aerial vehicle (UAV)-assisted multiuser communication networks. Specifically, we consider a scenario where a fixed-position antenna (FPA) base station (BS) serves K FAS-equipped users with the assistance of a UAV acting as an aerial relay. The BS employs rate-splitting multiple access (RSMA), while the UAV operates in half-duplex (HD) mode using the decode-and-forward (DF) strategy. For this system, we derive a compact analytical expression for the outage probability (OP) and its asymptotic behavior in the high signal-to-noise ratio (SNR) regime, leveraging the multivariate t-distribution. Our results show how deploying FAS at ground users (GUs) in UAV-aided communications improves overall system performance compared to using FPA GUs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16751v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Farshad Rostami Ghadi, Masoud Kaveh, Francisco Hernando-Gallego, Diego Martin, Kai-Kit Wong, Chan-Byoung Chae</dc:creator>
    </item>
    <item>
      <title>A Pathway to Near Tissue Computing through Processing-in-CTIA Pixels for Biomedical Applications</title>
      <link>https://arxiv.org/abs/2503.16798</link>
      <description>arXiv:2503.16798v1 Announce Type: cross 
Abstract: Near-tissue computing requires sensor-level processing of high-resolution images, essential for real-time biomedical diagnostics and surgical guidance. To address this need, we introduce a novel Capacitive Transimpedance Amplifier-based In-Pixel Computing (CTIA-IPC) architecture. Our design leverages CTIA pixels that are widely used for biomedical imaging owing to the inherent advantages of excellent linearity, low noise, and robust operation under low-light conditions. We augment CTIA pixels with IPC to enable precise deep learning computations including multi-channel, multi-bit convolution operations along with integrated batch normalization (BN) and Rectified Linear Unit (ReLU) functionalities in the peripheral ADC (Analog to Digital Converters). This design improves the linearity of Multiply and Accumulate (MAC) operations while enhancing computational efficiency. Leveraging 3D integration to embed pixel circuitry and weight storage, CTIA-IPC maintains pixel density comparable to standard CTIA designs. Moreover, our algorithm-circuit co-design approach enables efficient real-time diagnostics and AI-driven medical analysis. Evaluated on the EndoVis tissu dataset (1280x1024), CTIA-IPC achieves approximately 12x reduction in data bandwidth, yielding segmentation IoUs of 75.91% (parts), and 28.58% (instrument)-a minimal accuracy reduction (1.3%-2.5%) compared to baseline methods. Achieving 1.98 GOPS throughput and 3.39 GOPS/W efficiency, our CTIA-IPC architecture offers a promising computational framework tailored specifically for biomedical near-tissue computing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16798v1</guid>
      <category>eess.IV</category>
      <category>eess.SP</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zihan Yin, Subhradip Chakraborty, Ankur Singh, Chengwei Zhou, Gourav Datta, Akhilesh Jaiswal</dc:creator>
    </item>
    <item>
      <title>Vision Transformer Based Semantic Communications for Next Generation Wireless Networks</title>
      <link>https://arxiv.org/abs/2503.17275</link>
      <description>arXiv:2503.17275v1 Announce Type: cross 
Abstract: In the evolving landscape of 6G networks, semantic communications are poised to revolutionize data transmission by prioritizing the transmission of semantic meaning over raw data accuracy. This paper presents a Vision Transformer (ViT)-based semantic communication framework that has been deliberately designed to achieve high semantic similarity during image transmission while simultaneously minimizing the demand for bandwidth. By equipping ViT as the encoder-decoder framework, the proposed architecture can proficiently encode images into a high semantic content at the transmitter and precisely reconstruct the images, considering real-world fading and noise consideration at the receiver. Building on the attention mechanisms inherent to ViTs, our model outperforms Convolution Neural Network (CNNs) and Generative Adversarial Networks (GANs) tailored for generating such images. The architecture based on the proposed ViT network achieves the Peak Signal-to-noise Ratio (PSNR) of 38 dB, which is higher than other Deep Learning (DL) approaches in maintaining semantic similarity across different communication environments. These findings establish our ViT-based approach as a significant breakthrough in semantic communications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.17275v1</guid>
      <category>eess.IV</category>
      <category>cs.CV</category>
      <category>eess.SP</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Muhammad Ahmed Mohsin, Muhammad Jazib, Zeeshan Alam, Muhmmad Farhan Khan, Muhammad Saad, Muhammad Ali Jamshed</dc:creator>
    </item>
    <item>
      <title>Noise Variance Estimation Using Asymptotic Residual in Compressed Sensing</title>
      <link>https://arxiv.org/abs/2009.13678</link>
      <description>arXiv:2009.13678v3 Announce Type: replace 
Abstract: In compressed sensing, measurements are typically contaminated by additive noise, and therefore, information about the noise variance is often needed to design algorithms. In this paper, we propose a method for estimating the unknown noise variance in compressed sensing problems. The proposed method, called asymptotic residual matching (ARM), estimates the noise variance from a single measurement vector on the basis of the asymptotic result for the $\ell_{1}$ optimization problem. Specifically, we derive the asymptotic residual corresponding to the $\ell_{1}$ optimization and show that it depends on the noise variance. The proposed ARM approach obtains the estimate by comparing the asymptotic residual with the actual one, which can be obtained by empirical reconstruction without the information on the noise variance. For the proposed ARM, we also propose a method to choose a reasonable parameter based on the asymptotic residual. Simulation results show that the proposed noise variance estimation outperforms several conventional methods, especially when the problem size is small. We also show that, by using the proposed method, we can tune the regularization parameter of the $\ell_{1}$ optimization to achieve good reconstruction performance, even when the noise variance is unknown.</description>
      <guid isPermaLink="false">oai:arXiv.org:2009.13678v3</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1561/116.00000215</arxiv:DOI>
      <arxiv:journal_reference>APSIPA Transactions on Signal and Information Processing, vol. 12, no. 1, e46, Nov. 2023</arxiv:journal_reference>
      <dc:creator>Ryo Hayakawa</dc:creator>
    </item>
    <item>
      <title>Knowledge Transfer based Evolutionary Deep Neural Network for Intelligent Fault Diagnosis</title>
      <link>https://arxiv.org/abs/2109.13479</link>
      <description>arXiv:2109.13479v5 Announce Type: replace 
Abstract: A faster response with commendable accuracy in intelligent systems is essential for the reliability and smooth operations of industrial machines. Two main challenges affect the design of such intelligent systems: (i) the selection of a suitable model and (ii) domain adaptation if there is a continuous change in operating conditions. Therefore, we propose an evolutionary Net2Net transformation (EvoN2N) that finds the best suitable DNN architecture with limited availability of labeled data samples. Net2Net transformation-based quick learning algorithm has been used in the evolutionary framework of Non-dominated sorting genetic algorithm II to obtain the best DNN architecture. Net2Net transformation-based quick learning algorithm uses the concept of knowledge transfer from one generation to the next for faster fitness evaluation. The proposed framework can obtain the best model for intelligent fault diagnosis without a long and time-consuming search process. The proposed framework has been validated on the Case Western Reserve University dataset, the Paderborn University dataset, and the gearbox fault detection dataset under different operating conditions. The best models obtained are capable of demonstrating an excellent diagnostic performance and classification accuracy of almost up to 100% for most of the operating conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2109.13479v5</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arun K. Sharma, Nishchal K. Verma</dc:creator>
    </item>
    <item>
      <title>Simultaneous Optimized Orthogonal Matching Pursuit with Application to ECG Compression</title>
      <link>https://arxiv.org/abs/2406.03316</link>
      <description>arXiv:2406.03316v2 Announce Type: replace 
Abstract: A greedy pursuit strategy which finds a common basis for approximating a set of similar signals is proposed. The strategy extends the Optimized Orthogonal Matching Pursuit approach to selecting the subspace containing the approximation of all the signals in the set. The method, called Simultaneous Optimized Orthogonal Matching Pursuit, is stepwise optimal in the sense of minimizing at each iteration the mean error norm of the joint approximation. When applied to compression of electrocardiograms, significant gains over other transformation based compression techniques are demonstrated on the MIT-BIH Arrhythmia dataset.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.03316v2</guid>
      <category>eess.SP</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Laura Rebollo-Neira</dc:creator>
    </item>
    <item>
      <title>Survival Analysis with Machine Learning for Predicting Li-ion Battery Remaining Useful Life</title>
      <link>https://arxiv.org/abs/2503.13558</link>
      <description>arXiv:2503.13558v2 Announce Type: replace 
Abstract: The accurate prediction of RUL for lithium-ion batteries is crucial for enhancing the reliability and longevity of energy storage systems. Traditional methods for RUL prediction often struggle with issues such as data sparsity, varying battery chemistries, and the inability to capture complex degradation patterns over time. In this study, we propose a survival analysis-based framework combined with deep learning models to predict the RUL of lithium-ion batteries. Specifically, we utilize five advanced models: the Cox-type models (Cox, CoxPH, and CoxTime) and two machine-learning-based models (DeepHit and MTLR). These models address the challenges of accurate RUL estimation by transforming raw time-series battery data into survival data, including key degradation indicators such as voltage, current, and internal resistance. Advanced feature extraction techniques enhance the model's robustness in diverse real-world scenarios, including varying charging conditions and battery chemistries. Our models are tested using 10-fold cross-validation, ensuring generalizability and minimizing overfitting. Experimental results show that our survival-based framework significantly improves RUL prediction accuracy compared to traditional methods, providing a reliable tool for battery management and maintenance optimization. This study contributes to the advancement of predictive maintenance in battery technology, offering valuable insights for both researchers and industry practitioners aiming to enhance the operational lifespan of lithium-ion batteries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13558v2</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jingyuan Xue, Longfei Wei, Fang Sheng, Yuxin Gao, Jianfei Zhang</dc:creator>
    </item>
    <item>
      <title>Leveraging MoE-based Large Language Model for Zero-Shot Multi-Task Semantic Communication</title>
      <link>https://arxiv.org/abs/2503.15722</link>
      <description>arXiv:2503.15722v2 Announce Type: replace 
Abstract: Multi-task semantic communication (SC) can reduce the computational resources in wireless systems since retraining is not required when switching between tasks. However, existing approaches typically rely on task-specific embeddings to identify the intended task, necessitating retraining the entire model when given a new task. Consequently, this drives the need for a multi-task SC system that can handle new tasks without additional training, known as zero-shot learning. Inspired by the superior zero-shot capabilities of large language models (LLMs), we leverage pre-trained instruction-tuned LLMs, referred to as fine-tuned language net (FLAN), to improve the generalization capability. We incorporate a mixture-of-experts (MoE) architecture in the FLAN model and propose MoE-FLAN-SC architecture for multi-task SC systems. Our proposed MoE-FLAN-SC architecture can further improve the performance of FLAN-T5 model without increasing the computational cost. Moreover, we design a multi-task feature extraction module (FEM) which can adaptively extract relevant features across various tasks given the provided features and signal-to-noise ratio (SNR). Simulation results show that our proposed MoE-FLAN-SC architecture outperforms three state-of-the-art models in terms of the average accuracy on four different unseen tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.15722v2</guid>
      <category>eess.SP</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sin-Yu Huang, Renjie Liao, Vincent W. S. Wong</dc:creator>
    </item>
    <item>
      <title>Large Language Models are Zero-Shot Recognizers for Activities of Daily Living</title>
      <link>https://arxiv.org/abs/2407.01238</link>
      <description>arXiv:2407.01238v3 Announce Type: replace-cross 
Abstract: The sensor-based recognition of Activities of Daily Living (ADLs) in smart home environments enables several applications in the areas of energy management, safety, well-being, and healthcare. ADLs recognition is typically based on deep learning methods requiring large datasets to be trained. Recently, several studies proved that Large Language Models (LLMs) effectively capture common-sense knowledge about human activities. However, the effectiveness of LLMs for ADLs recognition in smart home environments still deserves to be investigated. In this work, we propose ADL-LLM, a novel LLM-based ADLs recognition system. ADLLLM transforms raw sensor data into textual representations, that are processed by an LLM to perform zero-shot ADLs recognition. Moreover, in the scenario where a small labeled dataset is available, ADL-LLM can also be empowered with few-shot prompting. We evaluated ADL-LLM on two public datasets, showing its effectiveness in this domain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.01238v3</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>eess.SP</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gabriele Civitarese, Michele Fiori, Priyankar Choudhary, Claudio Bettini</dc:creator>
    </item>
    <item>
      <title>Babel: A Scalable Pre-trained Model for Multi-Modal Sensing via Expandable Modality Alignment</title>
      <link>https://arxiv.org/abs/2407.17777</link>
      <description>arXiv:2407.17777v2 Announce Type: replace-cross 
Abstract: This paper presents Babel, the expandable modality alignment model, specially designed for multi-modal sensing. While there has been considerable work on multi-modality alignment, they all struggle to effectively incorporate multiple sensing modalities due to the data scarcity constraints. How to utilize multi-modal data with partial pairings in sensing remains an unresolved challenge. Babel tackles this challenge by introducing the concept of expandable modality alignment. The key idea involves transforming the N-modality alignment into a series of binary-modality alignments. Novel techniques are also proposed to further mitigate data scarcity issue and balance the contribution of the newly incorporated modality with the previously established modality alignment during the expandable alignment process. We provide the comprehensive implementation. In the pre-training phase, Babel currently aligns 6 sensing modalities, namely Wi-Fi, mmWave, IMU, LiDAR, video, and depth. For the deployment phase, as a foundation model, any single or combination of aligned modalities could be selected from Babel and applied to downstream tasks. Evaluation demonstrates Babel's outstanding performance on eight human activity recognition datasets, compared to a broad range of baselines e.g., the SOTA single-modal sensing networks, multi-modal sensing framework, and multi-modal large language models. Babel not only improves the performance of individual modality sensing (12% averaged accuracy improvement), but also effectively fuses multiple available modalities (up to 22% accuracy increase). Case studies also highlight emerging application scenarios empowered by Babel, including cross-modality retrieval (i.e., sensing imaging), and bridging LLM for sensing comprehension.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.17777v2</guid>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shenghong Dai, Shiqi Jiang, Yifan Yang, Ting Cao, Mo Li, Suman Banerjee, Lili Qiu</dc:creator>
    </item>
    <item>
      <title>The Future of IPTV: Security, AI Integration, 5G, and Next-Gen Streaming</title>
      <link>https://arxiv.org/abs/2503.13450</link>
      <description>arXiv:2503.13450v2 Announce Type: replace-cross 
Abstract: The evolution of Internet Protocol Television (IPTV) has transformed the landscape of digital broadcasting by leveraging high-speed internet connectivity to deliver high-quality multimedia content. IPTV provides a dynamic and interactive television experience through managed networks, ensuring superior Quality of Service (QoS) compared to open-network Internet TV. This study explores the technical infrastructure of IPTV, including its network architecture, data compression techniques, and the role of protocols such as IGMP and RTSP. It also examines security challenges, including encryption, digital rights management (DRM), and authentication mechanisms that safeguard IPTV services from unauthorized access and piracy. Moreover, the paper analyzes the distinctions between IPTV and open-network Internet TV, highlighting their respective advantages and limitations in terms of service control, bandwidth optimization, and content security. The integration of artificial intelligence (AI) and machine learning (ML) in IPTV enhances personalized content recommendations and predictive analytics, leading to improved user engagement and efficient network management. Additionally, emerging technologies such as 5G and cloud-based IPTV services are explored for their potential to further revolutionize the industry. While IPTV presents a robust alternative to traditional broadcasting, challenges such as bandwidth constraints, cybersecurity threats, and regulatory compliance remain significant. The study concludes that IPTV's future success will depend on advancements in network infrastructure, AI-driven optimizations, and strategic regulatory adaptations. As IPTV continues to evolve, hybrid models integrating IPTV and open-network streaming services are expected to enhance content accessibility, security, and overall user experience.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13450v2</guid>
      <category>cs.NI</category>
      <category>eess.IV</category>
      <category>eess.SP</category>
      <pubDate>Mon, 24 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Georgios Giannakopoulos, Peter Adegbenro, Maria Antonnette Perez</dc:creator>
    </item>
  </channel>
</rss>
