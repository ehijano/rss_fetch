<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 08 Nov 2024 05:00:10 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Neuroradiological features of traumatic encephalopathy syndrome using MRI and FDG-PET imaging: a case series in Australia</title>
      <link>https://arxiv.org/abs/2411.04334</link>
      <description>arXiv:2411.04334v1 Announce Type: new 
Abstract: Objectives: This study examined whether currently existing clinical structural magnetic resonance imaging (MRI) and fluorodeoxyglucose positron emission tomography (18FDG-PET) capabilities and board-certified radiologists' reports and interpretations can assist with traumatic encephalopathy syndrome (TES) diagnosis. Design: retrospective case series. Setting: this study assessed six patients with TES criteria recruited from the Sydney area, Australia Main outcomes: patients' clinical history and clinical presentation along TES diagnostic criteria, board-certified radiologist reports of structural MRI and 18FDG-PET. Results: one patient was classified as possible CTE, and the others were classified as probable CTE with significant RHI exposure history and a spectrum of cognitive deficits and other neuropsychiatric disturbances consistent with TES diagnostic criteria. Most common radiological features included atrophy of posterior superior parietal region and Evans Index &gt; 0.25. FDG-PET's pattern of common regions of hypometabolism and differing hypometabolism across participants suggested that FDG-PET and structural MRI have the potential for stratifying different TES stages. Conclusions: this study highlights the potential of a combined clinical and radiological approach using solely current capabilities to improve TES diagnosis and suggests a larger study. Such expanded investigation is crucial for advancing the ante-mortem diagnosis and management of CTE.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04334v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Rowena Mobbs, Fatima Nasrallah, Xuan Vinh To, John Magnussen, Jennifer Batchelor, Edward Hsiao, Mark Walterfang</dc:creator>
    </item>
    <item>
      <title>More variable circadian rhythms in epilepsy: a retrospective cross-sectional study using long-term heart rate recordings from wearable sensors</title>
      <link>https://arxiv.org/abs/2411.04634</link>
      <description>arXiv:2411.04634v1 Announce Type: new 
Abstract: Background: The circadian rhythm aligns physiology and behaviour with the 24-hour light-dark cycle, and its disruption is linked to neurological disorders such as epilepsy. However, how to best quantify circadian disruption remains unclear, as it can manifest across various properties and timescales. A promising but under-explored approach is to assess the intra-individual variability in circadian rhythms over timescales of weeks to years. This is yet to be studied in epilepsy.
  Methods: We retrospectively used wearable smartwatch data (Fitbit) from 143 people with epilepsy (PWE) and 31 controls. For each participant, we extracted the circadian oscillation underlying their heart rate time series and analysed the intra-individual variability of three circadian properties: period, acrophase, and amplitude.
  Findings: We found increased intra-individual variability in period (77 min vs. 62 min, z=3.32, p&lt;0.001) and acrophase (68 min vs. 54 min, z=2.97, p=0.003) for PWE compared to controls, but not in amplitude (1.98 bpm vs. 2.05 bpm, z=-0.66, p=0.51). For PWE, we did not find any correlations between seizure frequency and intra-individual variability in circadian properties, or any difference between weeks with and without seizures.
  Interpretation: This finding indicates that the circadian rhythm of heart rate is more variable for people with epilepsy and that this can be detected using a wearable device. However, we were unable to find any associations with seizure frequency or occurrence, suggesting intra-individual variability could be another manifestation of epilepsy aetiology. Future work should investigate the combined role of anti-seizure medications, demographics, co-morbidities, and health behaviours in driving the increased intra-individual variability of circadian properties in epilepsy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04634v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Billy C. Smith, Christopher Thornton, Rachel E. Stirling, Guillermo M. Besne, Nathan Evans, Peter N. Taylor, Philippa J. Karoly, Yujiang Wang</dc:creator>
    </item>
    <item>
      <title>Dynamic-Attention-based EEG State Transition Modeling for Emotion Recognition</title>
      <link>https://arxiv.org/abs/2411.04568</link>
      <description>arXiv:2411.04568v1 Announce Type: cross 
Abstract: Electroencephalogram (EEG)-based emotion decoding can objectively quantify people's emotional state and has broad application prospects in human-computer interaction and early detection of emotional disorders. Recently emerging deep learning architectures have significantly improved the performance of EEG emotion decoding. However, existing methods still fall short of fully capturing the complex spatiotemporal dynamics of neural signals, which are crucial for representing emotion processing. This study proposes a Dynamic-Attention-based EEG State Transition (DAEST) modeling method to characterize EEG spatiotemporal dynamics. The model extracts spatiotemporal components of EEG that represent multiple parallel neural processes and estimates dynamic attention weights on these components to capture transitions in brain states. The model is optimized within a contrastive learning framework for cross-subject emotion recognition. The proposed method achieved state-of-the-art performance on three publicly available datasets: FACED, SEED, and SEED-V. It achieved 75.4% accuracy in the binary classification of positive and negative emotions and 59.3% in nine-class discrete emotion classification on the FACED dataset, 88.1% in the three-class classification of positive, negative, and neutral emotions on the SEED dataset, and 73.6% in five-class discrete emotion classification on the SEED-V dataset. The learned EEG spatiotemporal patterns and dynamic transition properties offer valuable insights into neural dynamics underlying emotion processing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04568v1</guid>
      <category>cs.HC</category>
      <category>eess.SP</category>
      <category>q-bio.NC</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Xinke Shen, Runmin Gan, Kaixuan Wang, Shuyi Yang, Qingzhu Zhang, Quanying Liu, Dan Zhang, Sen Song</dc:creator>
    </item>
    <item>
      <title>Multiscale cortical morphometry reveals pronounced regional and scale-dependent variations across the lifespan</title>
      <link>https://arxiv.org/abs/2311.13501</link>
      <description>arXiv:2311.13501v4 Announce Type: replace 
Abstract: Motivation: Characterising the changes in cortical morphology across the lifespan is fundamental for a range of research and clinical applications. Most studies to date have found a monotonic decrease in commonly used morphometrics, such as cortical thickness and volume, across the entire brain with increasing age. Any regional variations reported are subtle changes in the rate of decrease. However, these descriptions of morphological changes have been limited to a single length scale. Here, we delineate the morphological changes associated with the healthy lifespan in multiscale morphometrics.
  Methods: We applied multiscale morphometric analysis to structural MRI from subjects aged 6-88 years from NKI (n=833) and CamCAN (n=641). These multiscale morphometrics were obtained at both the cortical hemisphere and lobe level.
  Results: On the level of whole cortical hemispheres, lifespan trajectories show diverging and even opposing trends at different spatial scales, in contrast to the monotonic decreases of volume and thickness described so far. Importantly, larger scales displayed most dramatic changes across the lifespan (up to 60%). More pronounced lobal differences in lifespan trajectories also became apparent in scales over 0.7mm. In a proof-of-principle application in brain age prediction, we also demonstrate added information contributed by multiscale morphometrics.
  Conclusion: Our study provides a comprehensive multiscale description of lifespan effects on cortical morphology in an age range from 6-88~years. In future, this can form the foundations for a normative model to compare individuals or cohorts, hence identifying multiscale morphological abnormalities. Our results reveal the complementary information contained in different spatial scales, suggesting that morphometrics should not be considered on a single scale, but as functions of length scale.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.13501v4</guid>
      <category>q-bio.NC</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Karoline Leiberg, Timo Blattner, Bethany Little, Victor B. B. Mello, Fernanda H. P. de Moraes, Christian Rummel, Peter N. Taylor, Bruno Mota, Yujiang Wang</dc:creator>
    </item>
    <item>
      <title>SciOps: Achieving Productivity and Reliability in Data-Intensive Research</title>
      <link>https://arxiv.org/abs/2401.00077</link>
      <description>arXiv:2401.00077v2 Announce Type: replace 
Abstract: Scientists are increasingly leveraging advances in instruments, automation, and collaborative tools to scale up their experiments and research goals, leading to new bursts of discovery. Various scientific disciplines, including neuroscience, have adopted key technologies to enhance collaboration, reproducibility, and automation. Drawing inspiration from advancements in the software industry, we present a roadmap to enhance the reliability and scalability of scientific operations for diverse research teams tackling large and complex projects. We introduce a five-level Capability Maturity Model describing the principles of rigorous scientific operations in projects ranging from small-scale exploratory studies to large-scale, multi-disciplinary research endeavors. Achieving higher levels of operational maturity necessitates the adoption of new, technology-enabled methodologies, which we refer to as SciOps. This concept is derived from the DevOps methodologies that have revolutionized the software industry. SciOps involves digital research environments that seamlessly integrate computational, automation, and AI-driven efforts throughout the research cycle-from experimental design and data collection to analysis and dissemination, ultimately leading to closed-loop discovery. This maturity model offers a framework for assessing and improving operational practices in multidisciplinary research teams, guiding them towards greater efficiency and effectiveness in scientific inquiry.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.00077v2</guid>
      <category>q-bio.NC</category>
      <category>cs.CY</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Erik C. Johnson, Thinh T. Nguyen, Benjamin K. Dichter, Frank Zappulla, Montgomery Kosma, Kabilar Gunalan, Yaroslav O. Halchenko, Shay Q. Neufeld, Kristen Ratan, Nicholas J. Edwards, Susanne Ressl, Sarah R. Heilbronner, Michael Schirner, Petra Ritter, Brock Wester, Satrajit Ghosh, Maryann E. Martone, Franco Pestilli, Dimitri Yatsenko</dc:creator>
    </item>
    <item>
      <title>A minimal model of cognition based on oscillatory and current-based reinforcement processes</title>
      <link>https://arxiv.org/abs/2402.02520</link>
      <description>arXiv:2402.02520v3 Announce Type: replace 
Abstract: Building mathematical models of brains is difficult because of the sheer complexity of the problem. One potential starting point is through basal cognition, which gives abstract representation of a range of organisms without central nervous systems, including fungi, slime moulds and bacteria. We propose one such model, demonstrating how a combination of oscillatory and current-based reinforcement processes can be used to couple resources in an efficient manner, mimicking the way these organisms function. A key ingredient in our model, not found in previous basal cognition models, is that we explicitly model oscillations in the number of particles (i.e. the nutrients, chemical signals or similar, which make up the biological system) and the flow of these particles within the modelled organisms. Using this approach, we find that our model builds efficient solutions, provided the environmental oscillations are sufficiently out of phase. We further demonstrate that amplitude differences can promote efficient solutions and that the system is robust to frequency differences. In the context of these findings, we discuss connections between our model and basal cognition in biological systems and slime moulds, in particular, how oscillations might contribute to self-organised problem-solving by these organisms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.02520v3</guid>
      <category>q-bio.NC</category>
      <category>cs.SI</category>
      <category>math.DS</category>
      <category>nlin.AO</category>
      <category>physics.bio-ph</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Linn\'ea Gyllingberg, Yu Tian, David J. T. Sumpter</dc:creator>
    </item>
    <item>
      <title>Temporal Complexity of a Hopfield-Type Neural Model in Random and Scale-Free Graphs</title>
      <link>https://arxiv.org/abs/2406.12895</link>
      <description>arXiv:2406.12895v3 Announce Type: replace 
Abstract: The Hopfield network model and its generalizations were introduced as a model of associative, or content-addressable, memory. They were widely investigated both as an unsupervised learning method in artificial intelligence and as a model of biological neural dynamics in computational neuroscience. The complexity features of biological neural networks have attracted the scientific community's interest for the last two decades. More recently, concepts and tools borrowed from complex network theory were applied to artificial neural networks and learning, thus focusing on the topological aspects. However, the temporal structure is also a crucial property displayed by biological neural networks and investigated in the framework of systems displaying complex intermittency. The Intermittency-Driven Complexity (IDC) approach indeed focuses on the metastability of self-organized states, whose signature is a power-decay in the inter-event time distribution or a scaling behaviour in the related event-driven diffusion processes. The investigation of IDC in neural dynamics and its relationship with network topology is still in its early stages. In this work, we present the preliminary results of an IDC analysis carried out on a bio-inspired Hopfield-type neural network comparing two different connectivities, i.e., scale-free vs. random network topology. We found that random networks can trigger complexity features similar to that of scale-free networks, even if with some differences and for different parameter values, in particular for different noise levels</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12895v3</guid>
      <category>q-bio.NC</category>
      <category>cond-mat.dis-nn</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.NA</category>
      <category>nlin.AO</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Marco Cafiso, Paolo Paradisi</dc:creator>
    </item>
    <item>
      <title>BrainSegFounder: Towards 3D Foundation Models for Neuroimage Segmentation</title>
      <link>https://arxiv.org/abs/2406.10395</link>
      <description>arXiv:2406.10395v3 Announce Type: replace-cross 
Abstract: The burgeoning field of brain health research increasingly leverages artificial intelligence (AI) to interpret and analyze neurological data. This study introduces a novel approach towards the creation of medical foundation models by integrating a large-scale multi-modal magnetic resonance imaging (MRI) dataset derived from 41,400 participants in its own. Our method involves a novel two-stage pretraining approach using vision transformers. The first stage is dedicated to encoding anatomical structures in generally healthy brains, identifying key features such as shapes and sizes of different brain regions. The second stage concentrates on spatial information, encompassing aspects like location and the relative positioning of brain structures. We rigorously evaluate our model, BrainFounder, using the Brain Tumor Segmentation (BraTS) challenge and Anatomical Tracings of Lesions After Stroke v2.0 (ATLAS v2.0) datasets. BrainFounder demonstrates a significant performance gain, surpassing the achievements of the previous winning solutions using fully supervised learning. Our findings underscore the impact of scaling up both the complexity of the model and the volume of unlabeled training data derived from generally healthy brains, which enhances the accuracy and predictive capabilities of the model in complex neuroimaging tasks with MRI. The implications of this research provide transformative insights and practical applications in healthcare and make substantial steps towards the creation of foundation models for Medical AI. Our pretrained models and training code can be found at https://github.com/lab-smile/GatorBrain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.10395v3</guid>
      <category>eess.IV</category>
      <category>cs.CV</category>
      <category>q-bio.NC</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Joseph Cox, Peng Liu, Skylar E. Stolte, Yunchao Yang, Kang Liu, Kyle B. See, Huiwen Ju, Ruogu Fang</dc:creator>
    </item>
  </channel>
</rss>
