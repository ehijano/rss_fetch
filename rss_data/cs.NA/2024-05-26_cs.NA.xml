<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NA</link>
    <description>cs.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 27 May 2024 04:01:39 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 27 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Convergence analysis of a weak Galerkin finite element method on a Bakhvalov-type mesh for a singularly perturbed convection-diffusion equation in 2D</title>
      <link>https://arxiv.org/abs/2405.15136</link>
      <description>arXiv:2405.15136v1 Announce Type: new 
Abstract: In this paper, we propose a weak Galerkin finite element method (WG) for solving singularly perturbed convection-diffusion problems on a Bakhvalov-type mesh in 2D. Our method is flexible and allows the use of discontinuous approximation functions on the meshe. An error estimate is devised in a suitable norm and the optimal convergence order is obtained. Finally, numerical experiments are given to support the theory and to show the efficiency of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15136v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shicheng Liu, Xiangyun Meng, Qilong Zhai</dc:creator>
    </item>
    <item>
      <title>Adaptive Finite Element Method for a Nonlinear Helmholtz Equation with High Wave Number</title>
      <link>https://arxiv.org/abs/2405.15344</link>
      <description>arXiv:2405.15344v1 Announce Type: new 
Abstract: A nonlinear Helmholtz (NLH) equation with high frequencies and corner singularities is discretized by the linear finite element method (FEM). After deriving some wave-number-explicit stability estimates and the singularity decomposition for the NLH problem, a priori stability and error estimates are established for the FEM on shape regular meshes including the case of locally refined meshes. Then a posteriori upper and lower bounds using a new residual-type error estimator, which is equivalent to the standard one, are derived for the FE solutions to the NLH problem. These a posteriori estimates have confirmed a significant fact that is also valid for the NLH problem, namely the residual-type estimator seriously underestimates the error of the FE solution in the preasymptotic regime, which was first observed by Babu\v{s}ka et al. [Int J Numer Methods Eng 40 (1997)] for a one-dimensional linear problem. Based on the new a posteriori error estimator, both the convergence and the quasi-optimality of the resulting adaptive finite element algorithm are proved the first time for the NLH problem, when the initial mesh size lying in the preasymptotic regime. Finally, numerical examples are presented to validate the theoretical findings and demonstrate that applying the continuous interior penalty (CIP) technique with appropriate penalty parameters can reduce the pollution errors efficiently. In particular, the nonlinear phenomenon of optical bistability with Gaussian incident waves is successfully simulated by the adaptive CIPFEM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15344v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Run Jiang, Haijun Wu, Yifeng Xu, Jun Zou</dc:creator>
    </item>
    <item>
      <title>On Phase Unwrapping via Digital Wavefront Sensors</title>
      <link>https://arxiv.org/abs/2405.15419</link>
      <description>arXiv:2405.15419v1 Announce Type: new 
Abstract: In this paper, we consider a new class of methods for phase unwrapping of 2D images based on digital wavefront sensors. Mathematically, many wavefront sensors produce the same measurements of incoming wavefronts regardless of whether they are wrapped or not. Since typical reconstructors for these sensors are optimized to compute smooth wavefronts, it is possible to digitally ``propagate'' a wrapped phase through such a sensor, resulting in a smooth unwrapped phase. First, we show how this principle can be applied for phase unwrapping using digital Shack-Hartmann and Fourier-type wavefront sensors. Then, we apply our methods to an unwrapping problem appearing in a real-world adaptive optics project currently under development, and compare the results to those obtained with other state-of-the-art algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15419v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Simon Hubmer, Victoria Hutterer, Ronny Ramlau, Ekaterina Sherina, Bernadett Stadler</dc:creator>
    </item>
    <item>
      <title>Time-Harmonic Optical Flow with Applications in Elastography</title>
      <link>https://arxiv.org/abs/2405.15507</link>
      <description>arXiv:2405.15507v1 Announce Type: new 
Abstract: In this paper, we propose mathematical models for reconstructing the optical flow in time-harmonic elastography. In this image acquisition technique, the object undergoes a special time-harmonic oscillation with known frequency so that only the spatially varying amplitude of the velocity field has to be determined. This allows for a simpler multi-frame optical flow analysis using Fourier analytic tools in time. We propose three variational optical flow models and show how their minimization can be tackled via Fourier transform in time. Numerical examples with synthetic as well as real-world data demonstrate the benefits of our approach.
  Keywords: optical flow, elastography, Fourier transform, iteratively reweighted least squares, Horn--Schunck method</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15507v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Oleh Melnyk, Michael Quellmalz, Gabriele Steidl, Noah Jaitner, Jakob Jordan, Ingolf Sack</dc:creator>
    </item>
    <item>
      <title>Using covariance extension equation to solve the Nevanlinna-Pick interpolation with degree constraint</title>
      <link>https://arxiv.org/abs/2405.15533</link>
      <description>arXiv:2405.15533v1 Announce Type: new 
Abstract: Nevanlinna-Pick interpolation problem has been widely studied in recent decades, however, the known algorithm is not simplistic and robust enough. This paper provide a new method to solve the Nevanlinna-Pick interpolation problem with degree constraint. It is based on the covariance extension equation proposed by Byrnes and Lindquist. A reformulation of the Nevanlinna-Pick interpolation problem is achieved and then solved by continuation method. This method need not calculate the initial value and a numerical example illustrates robustness and effciency of the proposed procedure</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15533v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cui Yufang</dc:creator>
    </item>
    <item>
      <title>Non-diffusive neural network method for hyperbolic conservation laws</title>
      <link>https://arxiv.org/abs/2405.15559</link>
      <description>arXiv:2405.15559v1 Announce Type: new 
Abstract: In this paper we develop a non-diffusive neural network (NDNN) algorithm for accurately solving weak solutions to hyperbolic conservation laws. The principle is to construct these weak solutions by computing smooth local solutions in subdomains bounded by discontinuity lines (DLs), the latter defined from the Rankine-Hugoniot jump conditions. The proposed approach allows to efficiently consider an arbitrary number of entropic shock waves, shock wave generation, as well as wave interactions. Some numerical experiments are presented to illustrate the strengths and properties of the algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15559v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Emmanuel Lorin, Arian Novruzi</dc:creator>
    </item>
    <item>
      <title>Uniform $\mathcal{H}$-matrix Compression with Applications to Boundary Integral Equations</title>
      <link>https://arxiv.org/abs/2405.15573</link>
      <description>arXiv:2405.15573v1 Announce Type: new 
Abstract: Boundary integral equation formulations of elliptic partial differential equations lead to dense system matrices when discretized, yet they are data-sparse. Using the $\mathcal{H}$-matrix format, this sparsity is exploited to achieve $\mathcal{O}(N\log N)$ complexity for storage and multiplication by a vector. This is achieved purely algebraically, based on low-rank approximations of subblocks, and hence the format is also applicable to a wider range of problems. The $\mathcal{H}^2$-matrix format improves the complexity to $\mathcal{O}(N)$ by introducing a recursive structure onto subblocks on multiple levels. However, in practice this comes with a large proportionality constant, making the $\mathcal{H}^2$-matrix format advantageous mostly for large problems. In this paper we investigate the usefulness of a matrix format that lies in between these two: Uniform $\mathcal{H}$-matrices. An algebraic compression algorithm is introduced to transform a regular $\mathcal{H}$-matrix into a uniform $\mathcal{H}$-matrix, which maintains the asymptotic complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15573v1</guid>
      <category>math.NA</category>
      <category>cs.MS</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kobe Bruyninckx, Daan Huybrechs, Karl Meerbergen</dc:creator>
    </item>
    <item>
      <title>Balanced truncation with conformal maps</title>
      <link>https://arxiv.org/abs/2405.15656</link>
      <description>arXiv:2405.15656v1 Announce Type: new 
Abstract: We consider the problem of constructing reduced models for large scale systems with poles in general domains in the complex plane (as opposed to, e.g., the open left-half plane or the open unit disk). Our goal is to design a model reduction scheme, building upon theoretically established methodologies, yet encompassing this new class of models. To this aim, we develop a balanced truncation framework through conformal maps to handle poles in general domains. The major difference from classical balanced truncation resides in the formulation of the Gramians. We show that these new Gramians can still be computed by solving modified Lyapunov equations for specific conformal maps. A numerical algorithm to perform balanced truncation with conformal maps is developed and is tested on three numerical examples, namely a heat model, the Schr\"odinger equation, and the undamped linear wave equation, the latter two having spectra on the imaginary axis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15656v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alessandro Borghi, Tobias Breiten, Serkan Gugercin</dc:creator>
    </item>
    <item>
      <title>Stratified Sampling Algorithms for Machine Learning Methods in Solving Two-scale Partial Differential Equations</title>
      <link>https://arxiv.org/abs/2405.15686</link>
      <description>arXiv:2405.15686v1 Announce Type: new 
Abstract: Partial differential equations (PDEs) with multiple scales or those defined over sufficiently large domains arise in various areas of science and engineering and often present problems when approximating the solutions numerically. Machine learning techniques are a relatively recent method for solving PDEs. Despite the increasing number of machine learning strategies developed to approximate PDEs, many remain focused on relatively small domains. When scaling the equations, a large domain is naturally obtained, especially when the solution exhibits multiscale characteristics. This study examines two-scale equations whose solution structures exhibit distinct characteristics: highly localized in some regions and significantly flat in others. These two regions must be adequately addressed over a large domain to approximate the solution more accurately. We focus on the vanishing gradient problem given by the diminishing gradient zone of the activation function over large domains and propose a stratified sampling algorithm to address this problem. We compare the uniform random classical sampling method over the entire domain and the proposed stratified sampling method. The numerical results confirm that the proposed method yields more accurate and consistent solutions than classical methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15686v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eddel El\'i Ojeda Avil\'es, Daniel Olmos-Liceaga, Jae-Hun Jung</dc:creator>
    </item>
    <item>
      <title>A Higher Order Local Mesh Method for Approximating Laplacians on Unknown Manifolds</title>
      <link>https://arxiv.org/abs/2405.15735</link>
      <description>arXiv:2405.15735v1 Announce Type: new 
Abstract: In this work, we introduce a numerical method for approximating arbitrary differential operators on vector fields in the weak form given point cloud data sampled randomly from a $d$ dimensional manifold embedded in $\mathbb{R}^n$. This method generalizes the local linear mesh method to the local curved mesh method, thus, allowing for the estimation of differential operators with nontrivial Christoffer symbols, such as the Bochner or Hodge Laplacians. In particular, we leverage the potentially small intrinsic dimension of the manifold $(d \ll n)$ to construct local parameterizations that incorporate both local meshes and higher-order curvature information. The former is constructed using low dimensional meshes obtained from local data projected to the tangent spaces, while the latter is obtained by fitting local polynomials with the generalized moving least squares. Theoretically, we prove the weak and spectral convergence rates for the proposed method for the estimation of the Bochner Laplacian. We provide numerical results supporting the theoretical convergence rates for the Bochner and Hodge Laplacians on simple manifolds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15735v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>John Wilson Peoples, John Harlim</dc:creator>
    </item>
    <item>
      <title>Spectral Image Data Fusion for Multisource Data Augmentation</title>
      <link>https://arxiv.org/abs/2405.14883</link>
      <description>arXiv:2405.14883v1 Announce Type: cross 
Abstract: Multispectral and hyperspectral images are increasingly popular in different research fields, such as remote sensing, astronomical imaging, or precision agriculture. However, the amount of free data available to perform machine learning tasks is relatively small. Moreover, artificial intelligence models developed in the area of spectral imaging require input images with a fixed spectral signature, expecting the data to have the same number of spectral bands or the same spectral resolution. This requirement significantly reduces the number of usable sources that can be used for a given model. The scope of this study is to introduce a methodology for spectral image data fusion, in order to allow machine learning models to be trained and/or used on data from a larger number of sources, thus providing better generalization. For this purpose, we propose different interpolation techniques, in order to make multisource spectral data compatible with each other. The interpolation outcomes are evaluated through various approaches. This includes direct assessments using surface plots and metrics such as a Custom Mean Squared Error (CMSE) and the Normalized Difference Vegetation Index (NDVI). Additionally, indirect evaluation is done by estimating their impact on machine learning model training, particularly for semantic segmentation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14883v1</guid>
      <category>cs.CV</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Roberta Iuliana Luca, Alexandra Baicoianu, Ioana Cristina Plajer</dc:creator>
    </item>
    <item>
      <title>Message-Passing Monte Carlo: Generating low-discrepancy point sets via Graph Neural Networks</title>
      <link>https://arxiv.org/abs/2405.15059</link>
      <description>arXiv:2405.15059v1 Announce Type: cross 
Abstract: Discrepancy is a well-known measure for the irregularity of the distribution of a point set. Point sets with small discrepancy are called low-discrepancy and are known to efficiently fill the space in a uniform manner. Low-discrepancy points play a central role in many problems in science and engineering, including numerical integration, computer vision, machine perception, computer graphics, machine learning, and simulation. In this work, we present the first machine learning approach to generate a new class of low-discrepancy point sets named Message-Passing Monte Carlo (MPMC) points. Motivated by the geometric nature of generating low-discrepancy point sets, we leverage tools from Geometric Deep Learning and base our model on Graph Neural Networks. We further provide an extension of our framework to higher dimensions, which flexibly allows the generation of custom-made points that emphasize the uniformity in specific dimensions that are primarily important for the particular problem at hand. Finally, we demonstrate that our proposed model achieves state-of-the-art performance superior to previous methods by a significant margin. In fact, MPMC points are empirically shown to be either optimal or near-optimal with respect to the discrepancy for every dimension and the number of points for which the optimal discrepancy can be determined.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15059v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>T. Konstantin Rusch, Nathan Kirk, Michael M. Bronstein, Christiane Lemieux, Daniela Rus</dc:creator>
    </item>
    <item>
      <title>Computational analysis on a linkage between generalized logit dynamic and discounted mean field game</title>
      <link>https://arxiv.org/abs/2405.15180</link>
      <description>arXiv:2405.15180v1 Announce Type: cross 
Abstract: Logit dynamics are dynamical systems describing transitions and equilibria of actions of interacting players under uncertainty. An uncertainty is embodied in logit dynamic as a softmax type function often called a logit function originating from a maximization problem subjected to an entropic penalization. This study provides another explanation for the generalized logit dynamic, particularly its logit function and player's heterogeneity, based on a discounted mean field game subjected to the costly decision making of a representative player. A large discount limit of the mean field game is argued to yield a logit dynamic. Further, mean field games that lead to classical and generalized logit dynamics are clarified and their well posedness is discussed. Additionally, numerical methods based on a finite difference discretization for computing generalized logit dynamics and corresponding mean field games are presented. Numerical methods are applied to two problems arising in the management of resources and environment; one involves an inland fisheries management problem with legal and illegal anglers, while the other is a sustainable tourism problem. Particularly, cases that possibly lack the regularity condition to be satisfied for the unique existence of stationary solutions are computationally discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15180v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hidekazu Yoshioka</dc:creator>
    </item>
    <item>
      <title>Seeing the World through an Antenna's Eye: Reception Quality Visualization Using Incomplete Technical Signal Information</title>
      <link>https://arxiv.org/abs/2405.15253</link>
      <description>arXiv:2405.15253v1 Announce Type: cross 
Abstract: We come up with a novel application for image analysis methods in the context of direction dependent signal characteristics. For this purpose, we describe an inpainting approach adding benefit to technical signal information which are typically only used for monitoring and control purposes in ground station operations. Recalling the theoretical properties of the employed inpainting technique and appropriate modeling allow us to demonstrate the usefulness of our approach for satellite data reception quality assessment. In our application, we show the advantages of inpainting products over raw data as well as the rich potential of the visualization of technical signal information.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15253v1</guid>
      <category>cs.CV</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.data-an</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Leif Bergerhoff</dc:creator>
    </item>
    <item>
      <title>2D discrete Yang-Mills equations on the torus</title>
      <link>https://arxiv.org/abs/2405.15315</link>
      <description>arXiv:2405.15315v1 Announce Type: cross 
Abstract: In this paper, we introduce a discretization scheme for the Yang-Mills equations in the two-dimensional case using a framework based on discrete exterior calculus. Within this framework, we define discrete versions of the exterior covariant derivative operator and its adjoint, which capture essential geometric features similar to their continuous counterparts. Our focus is on discrete models defined on a combinatorial torus, where the discrete Yang-Mills equations are presented in the form of both a system of difference equations and a matrix form.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15315v1</guid>
      <category>math-ph</category>
      <category>cs.NA</category>
      <category>math.MP</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Volodymyr Sushch</dc:creator>
    </item>
    <item>
      <title>Learning from Linear Algebra: A Graph Neural Network Approach to Preconditioner Design for Conjugate Gradient Solvers</title>
      <link>https://arxiv.org/abs/2405.15557</link>
      <description>arXiv:2405.15557v1 Announce Type: cross 
Abstract: Large linear systems are ubiquitous in modern computational science. The main recipe for solving them is iterative solvers with well-designed preconditioners. Deep learning models may be used to precondition residuals during iteration of such linear solvers as the conjugate gradient (CG) method. Neural network models require an enormous number of parameters to approximate well in this setup. Another approach is to take advantage of small graph neural networks (GNNs) to construct preconditioners of the predefined sparsity pattern. In our work, we recall well-established preconditioners from linear algebra and use them as a starting point for training the GNN. Numerical experiments demonstrate that our approach outperforms both classical methods and neural network-based preconditioning. We also provide a heuristic justification for the loss function used and validate our approach on complex datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15557v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vladislav Trifonov, Alexander Rudikov, Oleg Iliev, Ivan Oseledets, Ekaterina Muravleva</dc:creator>
    </item>
    <item>
      <title>MicroAdam: Accurate Adaptive Optimization with Low Space Overhead and Provable Convergence</title>
      <link>https://arxiv.org/abs/2405.15593</link>
      <description>arXiv:2405.15593v1 Announce Type: cross 
Abstract: We propose a new variant of the Adam optimizer [Kingma and Ba, 2014] called MICROADAM that specifically minimizes memory overheads, while maintaining theoretical convergence guarantees. We achieve this by compressing the gradient information before it is fed into the optimizer state, thereby reducing its memory footprint significantly. We control the resulting compression error via a novel instance of the classical error feedback mechanism from distributed optimization [Seide et al., 2014, Alistarh et al., 2018, Karimireddy et al., 2019] in which the error correction information is itself compressed to allow for practical memory gains. We prove that the resulting approach maintains theoretical convergence guarantees competitive to those of AMSGrad, while providing good practical performance. Specifically, we show that MICROADAM can be implemented efficiently on GPUs: on both million-scale (BERT) and billion-scale (LLaMA) models, MicroAdam provides practical convergence competitive to that of the uncompressed Adam baseline, with lower memory usage and similar running time. Our code is available at https://github.com/IST-DASLab/MicroAdam.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15593v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ionut-Vlad Modoranu, Mher Safaryan, Grigory Malinovsky, Eldar Kurtic, Thomas Robert, Peter Richtarik, Dan Alistarh</dc:creator>
    </item>
    <item>
      <title>Reducing the cost of posterior sampling in linear inverse problems via task-dependent score learning</title>
      <link>https://arxiv.org/abs/2405.15643</link>
      <description>arXiv:2405.15643v1 Announce Type: cross 
Abstract: Score-based diffusion models (SDMs) offer a flexible approach to sample from the posterior distribution in a variety of Bayesian inverse problems. In the literature, the prior score is utilized to sample from the posterior by different methods that require multiple evaluations of the forward mapping in order to generate a single posterior sample. These methods are often designed with the objective of enabling the direct use of the unconditional prior score and, therefore, task-independent training. In this paper, we focus on linear inverse problems, when evaluation of the forward mapping is computationally expensive and frequent posterior sampling is required for new measurement data, such as in medical imaging. We demonstrate that the evaluation of the forward mapping can be entirely bypassed during posterior sample generation. Instead, without introducing any error, the computational effort can be shifted to an offline task of training the score of a specific diffusion-like random process. In particular, the training is task-dependent requiring information about the forward mapping but not about the measurement data. It is shown that the conditional score corresponding to the posterior can be obtained from the auxiliary score by suitable affine transformations. We prove that this observation generalizes to the framework of infinite-dimensional diffusion models introduced recently and provide numerical analysis of the method. Moreover, we validate our findings with numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15643v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fabian Schneider, Duc-Lam Duong, Matti Lassas, Maarten V. de Hoop, Tapio Helin</dc:creator>
    </item>
    <item>
      <title>Taming Score-Based Diffusion Priors for Infinite-Dimensional Nonlinear Inverse Problems</title>
      <link>https://arxiv.org/abs/2405.15676</link>
      <description>arXiv:2405.15676v1 Announce Type: cross 
Abstract: This work introduces a sampling method capable of solving Bayesian inverse problems in function space. It does not assume the log-concavity of the likelihood, meaning that it is compatible with nonlinear inverse problems. The method leverages the recently defined infinite-dimensional score-based diffusion models as a learning-based prior, while enabling provable posterior sampling through a Langevin-type MCMC algorithm defined on function spaces. A novel convergence analysis is conducted, inspired by the fixed-point methods established for traditional regularization-by-denoising algorithms and compatible with weighted annealing. The obtained convergence bound explicitly depends on the approximation error of the score; a well-approximated score is essential to obtain a well-approximated posterior. Stylized and PDE-based examples are provided, demonstrating the validity of our convergence analysis. We conclude by presenting a discussion of the method's challenges related to learning the score and computational complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15676v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lorenzo Baldassari, Ali Siahkoohi, Josselin Garnier, Knut Solna, Maarten V. de Hoop</dc:creator>
    </item>
    <item>
      <title>On the convergence of discrete dynamic unbalanced transport models</title>
      <link>https://arxiv.org/abs/2310.09420</link>
      <description>arXiv:2310.09420v2 Announce Type: replace 
Abstract: A generalized unbalanced optimal transport distance ${\rm WB}_{\Lambda}$ on matrix-valued measures $\mathcal{M}(\Omega,\mathbb{S}_+^n)$ was defined in [arXiv:2011.05845] \`{a} la Benamou-Brenier, which extends the Kantorovich-Bures and the Wasserstein-Fisher-Rao distances. In this work, we investigate the convergence properties of the discrete transport problems associated with ${\rm WB}_{\Lambda}$. We first present a convergence framework for abstract discretization. Then, we propose a specific discretization scheme that aligns with this framework, under the assumption that the initial and final distributions are absolutely continuous with respect to the Lebesgue measure. Moreover, thanks to the static formulation, we show that such an assumption can be removed for the Wasserstein-Fisher-Rao distance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.09420v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bowen Li, Jun Zou</dc:creator>
    </item>
    <item>
      <title>Approximately well-balanced Discontinuous Galerkin methods using bases enriched with Physics-Informed Neural Networks</title>
      <link>https://arxiv.org/abs/2310.14754</link>
      <description>arXiv:2310.14754v2 Announce Type: replace 
Abstract: This work concerns the enrichment of Discontinuous Galerkin (DG) bases, so that the resulting scheme provides a much better approximation of steady solutions to hyperbolic systems of balance laws. The basis enrichment leverages a prior - an approximation of the steady solution - which we propose to compute using a Physics-Informed Neural Network (PINN). To that end, after presenting the classical DG scheme, we show how to enrich its basis with a prior. Convergence results and error estimates follow, in which we prove that the basis with prior does not change the order of convergence, and that the error constant is improved. To construct the prior, we elect to use parametric PINNs, which we introduce, as well as the algorithms to construct a prior from PINNs. We finally perform several validation experiments on four different hyperbolic balance laws to highlight the properties of the scheme. Namely, we show that the DG scheme with prior is much more accurate on steady solutions than the DG scheme without prior, while retaining the same approximation quality on unsteady solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.14754v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Emmanuel Franck, Victor Michel-Dansac, Laurent Navoret</dc:creator>
    </item>
    <item>
      <title>An unfitted high-order HDG method for two-fluid Stokes flow with exact NURBS geometries</title>
      <link>https://arxiv.org/abs/2312.14328</link>
      <description>arXiv:2312.14328v2 Announce Type: replace 
Abstract: A high-order, degree-adaptive hybridizable discontinuous Galerkin (HDG) method is presented for two-fluid incompressible Stokes flows, with boundaries and interfaces described using NURBS. The NURBS curves are embedded in a fixed Cartesian grid, yielding an unfitted HDG scheme capable of treating the exact geometry of the boundaries/interfaces, circumventing the need for fitted, high-order, curved meshes. The framework of the NURBS-enhanced finite element method (NEFEM) is employed for accurate quadrature along immersed NURBS and in elements cut by NURBS curves. A Nitsche's formulation is used to enforce Dirichlet conditions on embedded surfaces, yielding unknowns only on the mesh skeleton as in standard HDG, without introducing any additional degree of freedom on non-matching boundaries/interfaces. The resulting unfitted HDG-NEFEM method combines non-conforming meshes, exact NURBS geometry and high-order approximations to provide high-fidelity results on coarse meshes, independent of the geometric features of the domain. Numerical examples illustrate the optimal accuracy and robustness of the method, even in the presence of badly cut cells or faces, and its suitability to simulate microfluidic systems from CAD geometries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.14328v2</guid>
      <category>math.NA</category>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <category>physics.flu-dyn</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stefano Piccardo, Matteo Giacomini, Antonio Huerta</dc:creator>
    </item>
    <item>
      <title>New limiter regions for multidimensional flows</title>
      <link>https://arxiv.org/abs/2402.08395</link>
      <description>arXiv:2402.08395v2 Announce Type: replace 
Abstract: Accurate transport algorithms are crucial for computational fluid dynamics and more accurate and efficient schemes are always in development. One dimensional limiting is commonly employed to suppress nonphysical oscillations. However, the application of such limiters can reduce accuracy. It is important to identify the weakest set of sufficient conditions required on the limiter as to allow the development of successful numerical algorithms.
  The main goal of this paper is to identify new less restrictive sufficient conditions for flux form in-compressible advection to remain monotonic. We identify additional necessary conditions for incompressible flux form advection to be monotonic, demonstrating that the Spekreijse limiter region is not sufficient for incompressible flux form advection to remain monotonic. Then a convex combination argument is used to derive new sufficient conditions that are less restrictive than the Sweby region for a discrete maximum principle. This allows the introduction of two new more general limiter regions suitable for flux form incompressible advection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.08395v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.flu-dyn</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>James Woodfield, Hilary Weller, Colin J Cotter</dc:creator>
    </item>
    <item>
      <title>Sparsity-promoting hierarchical Bayesian model for EIT with a blocky target</title>
      <link>https://arxiv.org/abs/2404.19115</link>
      <description>arXiv:2404.19115v2 Announce Type: replace 
Abstract: The electrical impedance tomography (EIT) problem of estimating the unknown conductivity distribution inside a domain from boundary current or voltage measurements requires the solution of a nonlinear inverse problem. Sparsity promoting hierarchical Bayesian models have been shown to be very effective in the recovery of almost piecewise constant solutions in linear inverse problems. We demonstrate that by exploiting linear algebraic considerations it is possible to organize the calculation for the Bayesian solution of the nonlinear EIT inverse problem via finite element methods with sparsity promoting priors in a computationally efficient manner. The proposed approach uses the Iterative Alternating Sequential (IAS) algorithm for the solution of the linearized problems. Within the IAS algorithm, a substantial reduction in computational complexity is attained by exploiting the low dimensionality of the data space and an adjoint formulation of the Tikhonov regularized solution that constitutes part of the iterative updating scheme. Numerical tests illustrate the computational efficiency of the proposed algorithm. The paper sheds light also on the convexity properties of the objective function of the maximum a posteriori (MAP) estimation problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.19115v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniela Calvetti, Monica Pragliola, Erkki Somersalo</dc:creator>
    </item>
    <item>
      <title>An ALE numerical method with HLLC-2D solver for the two-phase flow ejecta transporting model</title>
      <link>https://arxiv.org/abs/2405.06046</link>
      <description>arXiv:2405.06046v2 Announce Type: replace 
Abstract: This work presents an arbitrary Lagrangian Eulerian (ALE) method for the compressible two-phase flow ejecta transporting model with the HLLC-2D Riemann solver. We focus on researching the precise equation to describe the interactions between particle phase and flow phase. The calculation of the momentum and energy exchange across two phases is the key point during the procedure, which can be capable of maintaining the conservation of this system. For particles, tracking their trajectories within the mesh and elements is essential. Thereafter an ALE method instead of Lagrangian scheme is derived for the discretization of the equation to perform better with the complex motion of particles and flow. We apply the HLLC-2D Riemann solver to substitute the HLLC solver which relaxes the limitation for continuous fluxes along the edge. Meanwhile we propose a method for searching particles and provide a CFL-like condition based on this. Finally, we show some numerical tests to analysis the influence of particles on fluid and get a following effect between two phases. The model and the numerical method are validated through numerical tests to show its robustness and accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.06046v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jianqiao Zhang, Wei Yan, Xianggui Li</dc:creator>
    </item>
    <item>
      <title>The Jacobi Eigenvalue Algorithm for Computing the Eigenvalues of a Dual Quaternion Hermitian Matrix</title>
      <link>https://arxiv.org/abs/2405.13649</link>
      <description>arXiv:2405.13649v2 Announce Type: replace 
Abstract: In this paper, we generalize the Jacobi eigenvalue algorithm to compute all eigenvalues and eigenvectors of a dual quaternion Hermitian matrix and show the convergence. We also propose a three-step Jacobi eigenvalue algorithm to compute the eigenvalues when a dual quaternion Hermitian matrix has two eigenvalues with identical standard parts but different dual parts and prove the convergence. Numerical experiments are presented to illustrate the efficiency and stability of the proposed Jacobi eigenvalue algorithm compaired to the power method and the Rayleigh quotient iteration method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.13649v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yongjun Chen, Liping Zhang</dc:creator>
    </item>
    <item>
      <title>Spectral analysis of block preconditioners for double saddle-point linear systems with application to PDE-constrained optimization</title>
      <link>https://arxiv.org/abs/2405.14605</link>
      <description>arXiv:2405.14605v2 Announce Type: replace 
Abstract: In this paper, we describe and analyze the spectral properties of a symmetric positive definite inexact block preconditioner for a class of symmetric, double saddle-point linear systems.
  We develop a spectral analysis of the preconditioned matrix, showing that its eigenvalues can be described in terms of the roots of a cubic polynomial with real coefficients.
  We illustrate the efficiency of the proposed preconditioners, and verify the theoretical bounds, in solving large-scale PDE-constrained optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14605v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luca Bergamaschi, Angeles Martinez, John Pearson, Andreas Potschka</dc:creator>
    </item>
    <item>
      <title>A nonsmooth primal-dual method with interwoven PDE constraint solver</title>
      <link>https://arxiv.org/abs/2211.04807</link>
      <description>arXiv:2211.04807v3 Announce Type: replace-cross 
Abstract: We introduce an efficient first-order primal-dual method for the solution of nonsmooth PDE-constrained optimization problems. We achieve this efficiency through not solving the PDE or its linearisation on each iteration of the optimization method. Instead, we run the method interwoven with a simple conventional linear system solver (Jacobi, Gauss-Seidel, conjugate gradients), always taking only one step of the linear system solver for each step of the optimization method. The control parameter is updated on each iteration as determined by the optimization method. We prove linear convergence under a second-order growth condition, and numerically demonstrate the performance on a variety of PDEs related to inverse problems involving boundary measurements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.04807v3</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bj{\o}rn Jensen, Tuomo Valkonen</dc:creator>
    </item>
    <item>
      <title>Leveraging joint sparsity in hierarchical Bayesian learning</title>
      <link>https://arxiv.org/abs/2303.16954</link>
      <description>arXiv:2303.16954v2 Announce Type: replace-cross 
Abstract: We present a hierarchical Bayesian learning approach to infer jointly sparse parameter vectors from multiple measurement vectors. Our model uses separate conditionally Gaussian priors for each parameter vector and common gamma-distributed hyper-parameters to enforce joint sparsity. The resulting joint-sparsity-promoting priors are combined with existing Bayesian inference methods to generate a new family of algorithms. Our numerical experiments, which include a multi-coil magnetic resonance imaging application, demonstrate that our new approach consistently outperforms commonly used hierarchical Bayesian methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.16954v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1137/23M156255X</arxiv:DOI>
      <arxiv:journal_reference>SIAM-ASA J Uncertain Quantif 12(2), 2024</arxiv:journal_reference>
      <dc:creator>Jan Glaubitz, Anne Gelb</dc:creator>
    </item>
    <item>
      <title>Invariant subspaces and PCA in nearly matrix multiplication time</title>
      <link>https://arxiv.org/abs/2311.10459</link>
      <description>arXiv:2311.10459v3 Announce Type: replace-cross 
Abstract: Approximating invariant subspaces of generalized eigenvalue problems (GEPs) is a fundamental computational problem at the core of machine learning and scientific computing. It is, for example, the root of Principal Component Analysis (PCA) for dimensionality reduction, data visualization, and noise filtering, and of Density Functional Theory (DFT), arguably the most popular method to calculate the electronic structure of materials. For a Hermitian definite GEP $HC=SC\Lambda$, let $\Pi_k$ be the true spectral projector on the invariant subspace that is associated with the $k$ smallest (or largest) eigenvalues. Given $H,$ $S$, an integer $k$, and accuracy $\varepsilon\in(0,1)$, we show that we can compute a matrix $\widetilde\Pi_k$ such that $\lVert\Pi_k-\widetilde\Pi_k\rVert_2\leq \varepsilon$, in $O\left( n^{\omega+\eta}\mathrm{polylog}(n,\varepsilon^{-1},\kappa(S),\mathrm{gap}_k^{-1}) \right)$ bit operations in the floating point model with probability $1-1/n$. Here, $\eta&gt;0$ is arbitrarily small, $\omega\lesssim 2.372$ is the matrix multiplication exponent, $\kappa(S)=\lVert S\rVert_2\lVert S^{-1}\rVert_2$, and $\mathrm{gap}_k$ is the gap between eigenvalues $k$ and $k+1$. To the best of our knowledge, this is the first end-to-end analysis achieving such "forward-error" approximation guarantees with nearly $O(n^{\omega+\eta})$ bit complexity, improving classical $\widetilde O(n^3)$ eigensolvers, even for the regular case $(S=I)$. Our methods rely on a new $O(n^{\omega+\eta})$ stability analysis for the Cholesky factorization, and a new smoothed analysis for computing spectral gaps, which can be of independent interest. Ultimately, we obtain new matrix multiplication-type bit complexity upper bounds for PCA problems, including classical PCA and (randomized) low-rank approximation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.10459v3</guid>
      <category>cs.DS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Aleksandros Sobczyk, Marko Mladenovi\'c, Mathieu Luisier</dc:creator>
    </item>
    <item>
      <title>Finite elements for Mat\'ern-type random fields: Uncertainty in computational mechanics and design optimization</title>
      <link>https://arxiv.org/abs/2403.03658</link>
      <description>arXiv:2403.03658v2 Announce Type: replace-cross 
Abstract: This work highlights an approach for incorporating realistic uncertainties into scientific computing workflows based on finite elements, focusing on applications in computational mechanics and design optimization. We leverage Mat\'ern-type Gaussian random fields (GRFs) generated using the SPDE method to model aleatoric uncertainties, including environmental influences, variating material properties, and geometric ambiguities. Our focus lies on delivering practical GRF realizations that accurately capture imperfections and variations and understanding how they impact the predictions of computational models and the topology of optimized designs. We describe a numerical algorithm based on solving a generalized SPDE to sample GRFs on arbitrary meshed domains. The algorithm leverages established techniques and integrates seamlessly with the open-source finite element library MFEM and associated scientific computing workflows, like those found in industrial and national laboratory settings. Our solver scales efficiently for large-scale problems and supports various domain types, including surfaces and embedded manifolds. We showcase its versatility through biomechanics and topology optimization applications. The flexibility and efficiency of SPDE-based GRF generation empower us to run large-scale optimization problems on 2D and 3D domains, including finding optimized designs on embedded surfaces, and to generate topologies beyond the reach of conventional techniques. Moreover, these capabilities allow us to model geometric uncertainties of reconstructed submanifolds, such as the surfaces of cerebral aneurysms. In addition to offering benefits in these specific domains, the proposed techniques transcend specific applications and generalize to arbitrary forward and backward problems in uncertainty quantification involving finite elements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.03658v2</guid>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tobias Duswald, Brendan Keith, Boyan Lazarov, Socratis Petrides, Barbara Wohlmuth</dc:creator>
    </item>
    <item>
      <title>An 808 Line Phasor-Based Dehomogenisation Matlab Code For Multi-Scale Topology Optimisation</title>
      <link>https://arxiv.org/abs/2405.14321</link>
      <description>arXiv:2405.14321v2 Announce Type: replace-cross 
Abstract: This work presents an 808-line Matlab educational code for combined multi-scale topology optimisation and phasor-based dehomogenisation titled deHomTop808. The multi-scale formulation utilises homogenisation of optimal microstructures to facilitate efficient coarse-scale optimisation. Dehomogenisation allows for a high-resolution single-scale reconstruction of the optimised multi-scale structure, achieving minor losses in structural performance, at a fraction of the computational cost, compared to its large-scale topology optimisation counterpart. The presented code utilises stiffness optimal Rank-2 microstructures to minimise the compliance of a single-load case problem, subject to a volume fraction constraint. By exploiting the inherent efficiency benefits of the phasor-based dehomogenisation procedure, on-the-fly dehomogenisation to a single-scale structure is obtained. The presented code includes procedures for structural verification of the final dehomogenised structure by comparison to the multi-scale solution. The code is introduced in terms of the underlying theory and its major components, including examples and potential extensions, and can be downloaded from https://github.com/peterdorffler/deHomTop808.git.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14321v2</guid>
      <category>cs.MS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rebekka Varum Woldseth, Ole Sigmund, Peter D{\o}rffler Ladegaard Jensen</dc:creator>
    </item>
  </channel>
</rss>
