<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.ST updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.ST</link>
    <description>math.ST updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.ST" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 19 Dec 2024 05:00:17 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Variable selection for partially linear single-index varying-coefficient model</title>
      <link>https://arxiv.org/abs/2412.13468</link>
      <description>arXiv:2412.13468v1 Announce Type: new 
Abstract: This paper focuses on variable selection for a partially linear single-index varying-coefficient model. A regularized variable selection procedure by combining basis function approximations with SCAD penalty is proposed. It can simultaneously select significant variables in the parametric and nonparametric components and estimate the nonzero regression coefficients and coefficient functions. The consistency of the variable selection procedure and the oracle property of the penalized least-squares estimators for high-dimensional data are established. Some simulations and the real data analysis are constructed to illustrate the finite sample performances of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13468v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lijuan Han, Liugen Xue, Junshan Xie</dc:creator>
    </item>
    <item>
      <title>On consistent estimation of dimension values</title>
      <link>https://arxiv.org/abs/2412.13898</link>
      <description>arXiv:2412.13898v1 Announce Type: new 
Abstract: The problem of estimating, from a random sample of points, the dimension of a compact subset S of the Euclidean space is considered. The emphasis is put on consistency results in the statistical sense. That is, statements of convergence to the true dimension value when the sample size grows to infinity. Among the many available definitions of dimension, we have focused (on the grounds of its statistical tractability) on three notions: the Minkowski dimension, the correlation dimension and the, perhaps less popular, concept of pointwise dimension. We prove the statistical consistency of some natural estimators of these quantities. Our proofs partially rely on the use of an instrumental estimator formulated in terms of the empirical volume function Vn (r), defined as the Lebesgue measure of the set of points whose distance to the sample is at most r. In particular, we explore the case in which the true volume function V (r) of the target set S is a polynomial on some interval starting at zero. An empirical study is also included. Our study aims to provide some theoretical support, and some practical insights, for the problem of deciding whether or not the set S has a dimension smaller than that of the ambient space. This is a major statistical motivation of the dimension studies, in connection with the so-called Manifold Hypothesis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13898v1</guid>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alejandro Cholaquidis, Antonio Cuevas, Beatriz Pateiro-L\'opez</dc:creator>
    </item>
    <item>
      <title>Modeling coskewness with zero correlation and correlation with zero coskewness</title>
      <link>https://arxiv.org/abs/2412.13362</link>
      <description>arXiv:2412.13362v1 Announce Type: cross 
Abstract: This paper shows that one needs to be careful when making statements on potential links between correlation and coskewness. Specifically, we first show that, on the one hand, it is possible to observe any possible values of coskewness among symmetric random variables but zero pairwise correlations of these variables. On the other hand, it is also possible to have zero coskewness and any level of correlation. Second, we generalize this result to the case of arbitrary marginal distributions showing the absence of a general link between rank correlation and standardized rank coskewness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13362v1</guid>
      <category>math.PR</category>
      <category>econ.TH</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Carole Bernard, Jinghui Chen, Steven Vanduffel</dc:creator>
    </item>
    <item>
      <title>On the Maximum and Minimum of a Multivariate Poisson Distribution</title>
      <link>https://arxiv.org/abs/2412.13535</link>
      <description>arXiv:2412.13535v1 Announce Type: cross 
Abstract: In this paper, we investigate the cumulative distribution functions (CDFs) of the maximum and minimum of multivariate Poisson distributions with three dependence structures, namely, the common shock, comonotonic shock and thinning-dependence models. In particular, we formulate the definition of a thinning-dependent multivariate Poisson distribution based on Wang and Yuen (2005). We derive explicit CDFs of the maximum and minimum of the multivariate Poisson random vectors and conduct asymptotic analyses on them. Our results reveal the substantial difference between the three dependence structures for multivariate Poisson distribution and may suggest an alternative method for studying the dependence for other multivariate distributions. We further provide numerical examples demonstrating obtained results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13535v1</guid>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zheng Liu, Feifan Shi, Jing Yao, Yang Yang</dc:creator>
    </item>
    <item>
      <title>Optimal Exact Recovery in Semi-Supervised Learning: A Study of Spectral Methods and Graph Convolutional Networks</title>
      <link>https://arxiv.org/abs/2412.13754</link>
      <description>arXiv:2412.13754v1 Announce Type: cross 
Abstract: We delve into the challenge of semi-supervised node classification on the Contextual Stochastic Block Model (CSBM) dataset. Here, nodes from the two-cluster Stochastic Block Model (SBM) are coupled with feature vectors, which are derived from a Gaussian Mixture Model (GMM) that corresponds to their respective node labels. With only a subset of the CSBM node labels accessible for training, our primary objective becomes the accurate classification of the remaining nodes. Venturing into the transductive learning landscape, we, for the first time, pinpoint the information-theoretical threshold for the exact recovery of all test nodes in CSBM. Concurrently, we design an optimal spectral estimator inspired by Principal Component Analysis (PCA) with the training labels and essential data from both the adjacency matrix and feature vectors. We also evaluate the efficacy of graph ridge regression and Graph Convolutional Networks (GCN) on this synthetic dataset. Our findings underscore that graph ridge regression and GCN possess the ability to achieve the information threshold of exact recovery in a manner akin to the optimal estimator when using the optimal weighted self-loops. This highlights the potential role of feature learning in augmenting the proficiency of GCN, especially in the realm of semi-supervised learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13754v1</guid>
      <category>cs.LG</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hai-Xiao Wang, Zhichao Wang</dc:creator>
    </item>
    <item>
      <title>Asymptotic Normality of Log Likelihood Ratio and Fundamental Limit of the Weak Detection for Spiked Wigner Matrices</title>
      <link>https://arxiv.org/abs/2203.00821</link>
      <description>arXiv:2203.00821v4 Announce Type: replace 
Abstract: We consider the problem of detecting the presence of a signal in a rank-one spiked Wigner model. For general non-Gaussian noise, assuming that the signal is drawn from the Rademacher prior, we prove that the log likelihood ratio (LR) of the spiked model against the null model converges to a Gaussian when the signal-to-noise ratio is below a certain threshold. The threshold is optimal in the sense that the reliable detection is possible by a transformed principal component analysis (PCA) above it. From the mean and the variance of the limiting Gaussian for the log-LR, we compute the limit of the sum of the Type-I error and the Type-II error of the likelihood ratio test. We also prove similar results for a rank-one spiked IID model where the noise is asymmetric but the signal is symmetric.</description>
      <guid isPermaLink="false">oai:arXiv.org:2203.00821v4</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hye Won Chung, Jiho Lee, Ji Oon Lee</dc:creator>
    </item>
    <item>
      <title>Clique and cycle frequencies in a sparse random graph model with overlapping communities</title>
      <link>https://arxiv.org/abs/1911.12827</link>
      <description>arXiv:1911.12827v4 Announce Type: replace-cross 
Abstract: A statistical network model with overlapping communities can be generated as a superposition of mutually independent random graphs of varying size. The model is parameterized by the number of nodes, the number of communities, and the joint distribution of the community size and the edge probability. This model admits sparse parameter regimes with power-law limiting degree distributions and non-vanishing clustering coefficients. This article presents large-scale approximations of clique and cycle frequencies for graph samples generated by the model, which are valid for regimes with unbounded numbers of overlapping communities. Our results reveal the growth rates of these subgraph frequencies and show that their theoretical densities can be reliably estimated from data.</description>
      <guid isPermaLink="false">oai:arXiv.org:1911.12827v4</guid>
      <category>math.PR</category>
      <category>cs.SI</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1080/15326349.2024.2313987</arxiv:DOI>
      <arxiv:journal_reference>Stochastic Models 40(4): 634-658 (2024)</arxiv:journal_reference>
      <dc:creator>Tommi Gr\"ohn, Joona Karjalainen, Lasse Leskel\"a</dc:creator>
    </item>
    <item>
      <title>Metric Entropy-Free Sample Complexity Bounds for Sample Average Approximation in Convex Stochastic Programming</title>
      <link>https://arxiv.org/abs/2401.00664</link>
      <description>arXiv:2401.00664v5 Announce Type: replace-cross 
Abstract: This paper studies sample average approximation (SAA) in solving convex or strongly convex stochastic programming (SP) problems. Under some common regularity conditions, we show -- perhaps for the first time -- that SAA's sample complexity can be completely free from any quantification of metric entropy (such as the logarithm of the covering number), leading to a significantly more efficient rate with dimensionality $d$ than most existing results. From the newly established complexity bounds, an important revelation is that SAA and the canonical stochastic mirror descent (SMD) method, two mainstream solution approaches to SP, entail almost identical rates of sample efficiency, lifting a theoretical discrepancy of SAA from SMD by the order of $O(d)$. Furthermore, this paper explores non-Lipschitzian scenarios where SAA maintains provable efficacy but the corresponding results for SMD remain mostly unexplored, indicating the potential of SAA's better applicability in some irregular settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.00664v5</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hongcheng Liu, Jindong Tong</dc:creator>
    </item>
    <item>
      <title>The VOROS: Lifting ROC curves to 3D</title>
      <link>https://arxiv.org/abs/2402.18689</link>
      <description>arXiv:2402.18689v2 Announce Type: replace-cross 
Abstract: While the area under the ROC curve is perhaps the most common measure that is used to rank the relative performance of different binary classifiers, longstanding field folklore has noted that it can be a measure that ill-captures the benefits of different classifiers when either the actual class values or misclassification costs are highly unbalanced between the two classes. We introduce a new ROC surface, and the VOROS, a volume over this ROC surface, as a natural way to capture these costs, by lifting the ROC curve to 3D. Compared to previous attempts to generalize the ROC curve, our formulation also provides a simple and intuitive way to model the scenario when only ranges, rather than exact values, are known for possible class imbalance and misclassification costs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.18689v2</guid>
      <category>cs.LG</category>
      <category>math.MG</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christopher Ratigan, Lenore Cowen</dc:creator>
    </item>
  </channel>
</rss>
