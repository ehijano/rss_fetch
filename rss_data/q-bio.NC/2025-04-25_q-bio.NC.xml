<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 25 Apr 2025 04:00:34 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Can deep neural networks learn biological vision?</title>
      <link>https://arxiv.org/abs/2504.16940</link>
      <description>arXiv:2504.16940v1 Announce Type: new 
Abstract: Deep neural networks (DNNs) once showed increasing alignment with primate neural responses as they improved on computer vision benchmarks. This trend raised the exciting possibility that better models of biological vision would come as a byproduct of the deep learning revolution in artificial intelligence. However, the trend has reversed over recent years as DNNs have scaled to human or superhuman recognition accuracy, a divergence that may stem from modern DNNs learning to rely on different visual features than primates to solve tasks. Where will better computational models of biological vision come from? We propose that vision science must break from artificial intelligence to develop algorithms that are designed with biological visual systems in mind instead of internet data benchmarks. We predict that the next generation of deep learning models of biological vision will be trained with data diets, training routines, and objectives that are closer to those that shape human vision than those that are in use today.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16940v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Drew Linsley, Pinyuan Feng, Thomas Serre</dc:creator>
    </item>
    <item>
      <title>On the robustness of the emergent spatiotemporal dynamics in biophysically realistic and phenomenological whole-brain models at multiple network resolutions</title>
      <link>https://arxiv.org/abs/2504.17491</link>
      <description>arXiv:2504.17491v1 Announce Type: new 
Abstract: The human brain is a complex dynamical system which displays a wide range of macroscopic and mesoscopic patterns of neural activity, whose mechanistic origin remains poorly understood. Whole-brain modelling allows us to explore candidate mechanisms causing the observed patterns. However, it is not fully established how the choice of model type and the networks' resolution influence the simulation results, hence, it remains unclear, to which extent conclusions drawn from these results are limited by modelling artefacts. Here, we compare the dynamics of a biophysically realistic, linear-nonlinear cascade model of whole-brain activity with a phenomenological Wilson-Cowan model using three structural connectomes based on the Schaefer parcellation scheme with 100, 200, and 500 nodes. Both neural mass models implement the same mechanistic hypotheses, which specifically address the interaction between excitation, inhibition, and a slow adaptation current, which affects the excitatory populations. We quantify the emerging dynamical states in detail and investigate how consistent results are across the different model variants. Then we apply both model types to the specific phenomenon of slow oscillations, which are a prevalent brain rhythm during deep sleep. We investigate the consistency of model predictions when exploring specific mechanistic hypotheses about the effects of both short- and long-range connections and of the antero-posterior structural connectivity gradient on key properties of these oscillations. Overall, our results demonstrate that the coarse-grained dynamics are robust to changes in both model type and network resolution. In some cases, however, model predictions do not generalize. Thus, some care must be taken when interpreting model results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.17491v1</guid>
      <category>q-bio.NC</category>
      <category>nlin.AO</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Cristiana Dimulescu, Ronja Str\"omsd\"orfer, Agnes Fl\"oel, Klaus Obermayer</dc:creator>
    </item>
    <item>
      <title>Brain Morphology Normative modelling platform for abnormality and Centile estimation: Brain MoNoCle</title>
      <link>https://arxiv.org/abs/2406.01107</link>
      <description>arXiv:2406.01107v4 Announce Type: replace 
Abstract: Normative models of brain structure estimate the effects of covariates such as age and sex using large samples of healthy controls. These models can then be applied to e.g. smaller clinical cohorts to distinguish disease effects from other covariates. However, these advanced statistical modelling approaches can be difficult to access, and processing large healthy cohorts is computationally demanding. Thus, accessible platforms with pre-trained normative models are needed.
  We present such a platform for brain morphology analysis as an open-source web application https://cnnplab.shinyapps.io/BrainMoNoCle/, with six key features: (i) user-friendly web interface, (ii) individual and group outputs, (iii) multi-site analysis, (iv) regional and whole-brain analysis, (v) integration with existing tools, and (vi) featuring multiple morphology metrics.
  Using a diverse sample of 3,276 healthy controls across 21 sites, we pre-trained normative models on various metrics. We validated the models with a small sample of individuals with bipolar disorder, showing outputs that aligned closely with existing literature only after applying our normative modelling. Using a cohort of people with temporal lobe epilepsy, we showed that individual-level abnormalities were in line with seizure lateralisation. Finally, with the ability to investigate multiple morphology measures in the same framework, we found that biological covariates are better explained in specific morphology measures, and for applications, only some measures are sensitive to the disease process.
  Our platform offers a comprehensive framework to analyse brain morphology in clinical and research settings. Validations confirm the superiority of normative models and the advantage of investigating a range of brain morphology metrics together.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01107v4</guid>
      <category>q-bio.NC</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bethany Little, Nida Alyas, Alexander Surtees, Gavin P Winston, John S Duncan, David A Cousins, John-Paul Taylor, Peter Taylor, Karoline Leiberg, Yujiang Wang</dc:creator>
    </item>
    <item>
      <title>Deep Generative Model-Based Generation of Synthetic Individual-Specific Brain MRI Segmentations</title>
      <link>https://arxiv.org/abs/2504.12352</link>
      <description>arXiv:2504.12352v2 Announce Type: replace 
Abstract: To the best of our knowledge, all existing methods that can generate synthetic brain magnetic resonance imaging (MRI) scans for a specific individual require detailed structural or volumetric information about the individual's brain. However, such brain information is often scarce, expensive, and difficult to obtain. In this paper, we propose the first approach capable of generating synthetic brain MRI segmentations -- specifically, 3D white matter (WM), gray matter (GM), and cerebrospinal fluid (CSF) segmentations -- for individuals using their easily obtainable and often readily available demographic, interview, and cognitive test information. Our approach features a novel deep generative model, CSegSynth, which outperforms existing prominent generative models, including conditional variational autoencoder (C-VAE), conditional generative adversarial network (C-GAN), and conditional latent diffusion model (C-LDM). We demonstrate the high quality of our synthetic segmentations through extensive evaluations. Also, in assessing the effectiveness of the individual-specific generation, we achieve superior volume prediction, with mean absolute errors of only 36.44mL, 29.20mL, and 35.51mL between the ground-truth WM, GM, and CSF volumes of test individuals and those volumes predicted based on generated individual-specific segmentations, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.12352v2</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <category>eess.IV</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruijie Wang, Luca Rossetto, Susan M\'erillat, Christina R\"ocke, Mike Martin, Abraham Bernstein</dc:creator>
    </item>
  </channel>
</rss>
