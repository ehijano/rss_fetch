<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.LO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.LO</link>
    <description>cs.LO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.LO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 30 Sep 2025 03:32:56 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Can Large Language Models Autoformalize Kinematics?</title>
      <link>https://arxiv.org/abs/2509.21840</link>
      <description>arXiv:2509.21840v1 Announce Type: new 
Abstract: Autonomous cyber-physical systems like robots and self-driving cars could greatly benefit from using formal methods to reason reliably about their control decisions. However, before a problem can be solved it needs to be stated. This requires writing a formal physics model of the cyber-physical system, which is a complex task that traditionally requires human expertise and becomes a bottleneck.
  This paper experimentally studies whether Large Language Models (LLMs) can automate the formalization process. A 20 problem benchmark suite is designed drawing from undergraduate level physics kinematics problems. In each problem, the LLM is provided with a natural language description of the objects' motion and must produce a model in differential game logic (dGL). The model is (1) syntax checked and iteratively refined based on parser feedback, and (2) semantically evaluated by checking whether symbolically executing the dGL formula recovers the solution to the original physics problem. A success rate of 70% (best over 5 samples) is achieved. We analyze failing cases, identifying directions for future improvement. This provides a first quantitative baseline for LLM-based autoformalization from natural language to a hybrid games logic with continuous dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.21840v1</guid>
      <category>cs.LO</category>
      <category>cs.AI</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aditi Kabra, Jonathan Laurent, Sagar Bharadwaj, Ruben Martins, Stefan Mitsch, Andr\'e Platzer</dc:creator>
    </item>
    <item>
      <title>A Correct by Construction Fault Tolerant Voter for Input Selection of a Control System</title>
      <link>https://arxiv.org/abs/2509.22236</link>
      <description>arXiv:2509.22236v1 Announce Type: new 
Abstract: Safety-critical systems use redundant input units to improve their reliability and fault tolerance. A voting logic is then used to select a reliable input from the redundant sources. A fault detection and isolation rules help in selecting input units that can participate in voting. This work deals with the formal requirement formulation, design, verification and synthesis of a generic voting unit for an $N$-modular redundant measurement system used for control applications in avionics systems. The work follows a correct-by-construction approach, using the Rocq theorem prover.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22236v1</guid>
      <category>cs.LO</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Arif Ali AP, Jasine Babu, Deepa Sara John</dc:creator>
    </item>
    <item>
      <title>Specifying an Obligation Taxonomy in the Non-Markovian Situation Calculus</title>
      <link>https://arxiv.org/abs/2509.22533</link>
      <description>arXiv:2509.22533v1 Announce Type: new 
Abstract: Over more than three decades, the Situation Calculus has established itself as an elegant, powerful, and concise formalism for specifying dynamical domains as well as for reasoning about the effects of actions of those domains both in the world and in the mental state of the modelled agents. Moreover, it has also been established that the preconditions of a given action and its effects may be determined entirely by the current situation alone, or they may be determined by past situations as well. When past situations are involved in determining action preconditions and effects, resulting theories are non-Markovian. Assuming a specification of actions that produce obligations, we consider using non-Markovian control in the Situation Calculus to specify different notions of obligations found in the literature. These notions have been specified using Event Calculus; but, as far as we know, they have never been specified using the Situation Calculus. The specifications in this paper yield intuitive properties that ensure the correctness of the whole endeavour.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22533v1</guid>
      <category>cs.LO</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Kalonji Kalala, Iluju Kiringa, Tet Yeap</dc:creator>
    </item>
    <item>
      <title>Logic of Hypotheses: from Zero to Full Knowledge in Neurosymbolic Integration</title>
      <link>https://arxiv.org/abs/2509.21663</link>
      <description>arXiv:2509.21663v1 Announce Type: cross 
Abstract: Neurosymbolic integration (NeSy) blends neural-network learning with symbolic reasoning. The field can be split between methods injecting hand-crafted rules into neural models, and methods inducing symbolic rules from data. We introduce Logic of Hypotheses (LoH), a novel language that unifies these strands, enabling the flexible integration of data-driven rule learning with symbolic priors and expert knowledge. LoH extends propositional logic syntax with a choice operator, which has learnable parameters and selects a subformula from a pool of options. Using fuzzy logic, formulas in LoH can be directly compiled into a differentiable computational graph, so the optimal choices can be learned via backpropagation. This framework subsumes some existing NeSy models, while adding the possibility of arbitrary degrees of knowledge specification. Moreover, the use of Goedel fuzzy logic and the recently developed Goedel trick yields models that can be discretized to hard Boolean-valued functions without any loss in performance. We provide experimental analysis on such models, showing strong results on tabular data and on the Visual Tic-Tac-Toe NeSy task, while producing interpretable decision rules.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.21663v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Davide Bizzaro, Alessandro Daniele</dc:creator>
    </item>
    <item>
      <title>Transformers Can Learn Connectivity in Some Graphs but Not Others</title>
      <link>https://arxiv.org/abs/2509.22343</link>
      <description>arXiv:2509.22343v1 Announce Type: cross 
Abstract: Reasoning capability is essential to ensure the factual correctness of the responses of transformer-based Large Language Models (LLMs), and robust reasoning about transitive relations is instrumental in many settings, such as causal inference. Hence, it is essential to investigate the capability of transformers in the task of inferring transitive relations (e.g., knowing A causes B and B causes C, then A causes C). The task of inferring transitive relations is equivalent to the task of connectivity in directed graphs (e.g., knowing there is a path from A to B, and there is a path from B to C, then there is a path from A to C). Past research focused on whether transformers can learn to infer transitivity from in-context examples provided in the input prompt. However, transformers' capability to infer transitive relations from training examples and how scaling affects the ability is unexplored. In this study, we seek to answer this question by generating directed graphs to train transformer models of varying sizes and evaluate their ability to infer transitive relations for various graph sizes. Our findings suggest that transformers are capable of learning connectivity on "grid-like'' directed graphs where each node can be embedded in a low-dimensional subspace, and connectivity is easily inferable from the embeddings of the nodes. We find that the dimensionality of the underlying grid graph is a strong predictor of transformers' ability to learn the connectivity task, where higher-dimensional grid graphs pose a greater challenge than low-dimensional grid graphs. In addition, we observe that increasing the model scale leads to increasingly better generalization to infer connectivity over grid graphs. However, if the graph is not a grid graph and contains many disconnected components, transformers struggle to learn the connectivity task, especially when the number of components is large.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22343v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.LO</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amit Roy, Abulhair Saparov</dc:creator>
    </item>
    <item>
      <title>Ontological foundations for contrastive explanatory narration of robot plans</title>
      <link>https://arxiv.org/abs/2509.22493</link>
      <description>arXiv:2509.22493v1 Announce Type: cross 
Abstract: Mutual understanding of artificial agents' decisions is key to ensuring a trustworthy and successful human-robot interaction. Hence, robots are expected to make reasonable decisions and communicate them to humans when needed. In this article, the focus is on an approach to modeling and reasoning about the comparison of two competing plans, so that robots can later explain the divergent result. First, a novel ontological model is proposed to formalize and reason about the differences between competing plans, enabling the classification of the most appropriate one (e.g., the shortest, the safest, the closest to human preferences, etc.). This work also investigates the limitations of a baseline algorithm for ontology-based explanatory narration. To address these limitations, a novel algorithm is presented, leveraging divergent knowledge between plans and facilitating the construction of contrastive narratives. Through empirical evaluation, it is observed that the explanations excel beyond the baseline method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22493v1</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <category>cs.IR</category>
      <category>cs.LO</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alberto Olivares-Alarcos, Sergi Foix, J\'ulia Borr\`as, Gerard Canal, Guillem Aleny\`a</dc:creator>
    </item>
    <item>
      <title>Formalizing Mason-Stothers Theorem and its Corollaries in Lean 4</title>
      <link>https://arxiv.org/abs/2408.15180</link>
      <description>arXiv:2408.15180v2 Announce Type: replace 
Abstract: The ABC conjecture implies many conjectures and theorems in number theory, including the celebrated Fermat's Last Theorem. Mason-Stothers Theorem is a function field analogue of the ABC conjecture that admits a much more elementary proof with many interesting consequences, including a polynomial version of Fermat's Last Theorem. While years of dedicated effort are expected for a full formalization of Fermat's Last Theorem, the simple proof of Mason-Stothers Theorem and its corollaries calls for an immediate formalization.
  We formalize an elementary proof by Snyder in Lean 4, and also formalize many consequences of Mason-Stothers, including nonsolvability of Fermat-Cartan equations in polynomials, nonparametrizability of a certain elliptic curve, and Davenport's Theorem. We compare our work to existing formalizations of the Mason-Stothers by Eberl in Isabelle and Wagemaker in Lean 3 respectively. Our formalization has been integrated into the mathlib library of Lean 4.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.15180v2</guid>
      <category>cs.LO</category>
      <category>math.RA</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jineon Baek, Seewoo Lee</dc:creator>
    </item>
    <item>
      <title>An adequacy theorem between mixed powerdomains and probabilistic concurrency (extended version)</title>
      <link>https://arxiv.org/abs/2409.15920</link>
      <description>arXiv:2409.15920v3 Announce Type: replace 
Abstract: We present an adequacy theorem for a concurrent extension of probabilistic GCL. The underlying denotational semantics is based on the so-called mixed powerdomains, which combine non-determinism with probabilistic behaviour. The theorem itself is formulated via M. Smyth's idea of treating observable properties as open sets of a topological space. The proof hinges on a 'topological generalisation' of K\"onig's lemma in the setting of probabilistic programming (a result that is proved in the paper as well).
  One application of the theorem is that it entails semi-decidability w.r.t. whether a concurrent program satisfies an observable property (written in a certain form). This is related to M. Escard\'o's conjecture about semi-decidability w.r.t. may and must probabilistic testing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.15920v3</guid>
      <category>cs.LO</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Renato Neves</dc:creator>
    </item>
    <item>
      <title>On the $p$-adic Skolem Problem</title>
      <link>https://arxiv.org/abs/2504.14413</link>
      <description>arXiv:2504.14413v2 Announce Type: replace 
Abstract: The Skolem Problem asks to determine whether a given linear recurrence sequence (LRS) has a zero term. Showing decidability of this problem is equivalent to giving an effective proof of the Skolem-Mahler-Lech Theorem, which asserts that a non-degenerate LRS has finitely many zeros. The latter result was proven over 90 years ago via an ineffective method showing that such an LRS has only finitely many $p$-adic zeros. In this paper we consider the problem of determining whether a given LRS has a $p$-adic zero, as well as the corresponding function problem of computing exact representations of all $p$-adic zeros. We present algorithms for both problems and report on their implementation. The output of the algorithms is unconditionally correct, and termination is guaranteed subject to the $p$-adic Schanuel Conjecture (a standard number-theoretic hypothesis concerning the $p$-adic exponential function). While these algorithms do not solve the Skolem Problem, they can be exploited to find natural-number and rational zeros under additional hypotheses. To illustrate this, we apply our results to show decidability of the Simultaneous Skolem Problem (determine whether two coprime linear recurrences have a common natural-number zero), again subject to the $p$-adic Schanuel Conjecture.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14413v2</guid>
      <category>cs.LO</category>
      <category>math.NT</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Piotr Bacik, Jo\"el Ouaknine, David Purser, James Worrell</dc:creator>
    </item>
    <item>
      <title>Logical Inferentialism &amp; Attacks on Classical Logic</title>
      <link>https://arxiv.org/abs/2506.04295</link>
      <description>arXiv:2506.04295v2 Announce Type: replace 
Abstract: This paper undertakes a foundational inquiry into logical inferentialism with particular emphasis on the normative standards it establishes and the implications these pose for classical logic. The central question addressed herein is: 'What is Logical Inferentialism &amp; How do its Standards challenge Classical Logic?' In response, the study begins with a survey of the three principal proof systems that is, David Hilbert's axiomatic systems and Gerhard Gentzen's natural deduction and his sequent calculus, thus situating logical inferentialism within a broader proof-theoretic landscape. The investigation then turns to the core tenets of logical inferentialism by focusing on the role of introduction and elimination rules in determining the meaning of logical constants. Through this framework, natural deduction is evaluated as a system that satisfies key inferentialist virtues including harmony, conservativeness and the subformula property. Ultimately, the paper presents challenges to classical logic from intuitionist and revisionist perspectives by arguing that certain classical principles fail to uphold inferentialist standards, consequently undermining their legitimacy within a meaning-theoretic framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04295v2</guid>
      <category>cs.LO</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.4236/ojpp.2025.154048</arxiv:DOI>
      <arxiv:journal_reference>Open Journal of Philosophy. Vol.15. No.4. pp. 788-813 (2025)</arxiv:journal_reference>
      <dc:creator>Khashayar Irani</dc:creator>
    </item>
    <item>
      <title>Generative Logic: A New Computer Architecture for Deterministic Reasoning and Knowledge Generation</title>
      <link>https://arxiv.org/abs/2508.00017</link>
      <description>arXiv:2508.00017v2 Announce Type: replace 
Abstract: We present Generative Logic (GL), a deterministic architecture that starts from user-supplied axiomatic definitions (and, optionally, a list of simple facts for counterexample (CE) construction), written in a minimalist Mathematical Programming Language (MPL), and systematically explores their deductive neighborhood. Definitions are compiled into a distributed grid of simple Logic Blocks (LBs) that exchange messages; whenever the premises of an inference rule unify, a new fact is emitted with full provenance to its sources, yielding replayable, auditable proof graphs. A prototype software implementation instantiates the workflow on first-order Peano arithmetic. Starting only from the Peano axioms, GL enumerates conjectures, applies normalization, type, and CE filter, and automatically reconstructs machine-checkable proofs of foundational arithmetic laws, including associativity and commutativity of addition, associativity and commutativity of multiplication, and distributivity. On commodity hardware, the prover phase requires approximately 7 seconds; a complete run finishes in about 5 minutes. Generated proofs export to navigable HTML so that every inference step can be inspected independently. We outline a hardware-software co-design path toward massively parallel realizations and describe prospective integration with probabilistic models (e.g., large language models) for auto-formalization and conjecture seeding. The Python, C++, and MPL code to reproduce the Peano experiments, along with the full proof graphs in HTML as well as machine-readable text format, are available in the project's GitHub repository at github.com/Generative-Logic/GL commit 56c9233 and are permanently archived at doi:10.5281/zenodo.17206386.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00017v2</guid>
      <category>cs.LO</category>
      <category>cs.AI</category>
      <category>cs.AR</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nikolai Sergeev</dc:creator>
    </item>
    <item>
      <title>VeriFlow: Modeling Distributions for Neural Network Verification</title>
      <link>https://arxiv.org/abs/2406.14265</link>
      <description>arXiv:2406.14265v2 Announce Type: replace-cross 
Abstract: Formal verification has emerged as a promising method to ensure the safety and reliability of neural networks. However, many relevant properties, such as fairness or global robustness, pertain to the entire input space. If one applies verification techniques naively, the neural network is checked even on inputs that do not occur in the real world and have no meaning. To tackle this shortcoming, we propose the VeriFlow architecture as a flow-based density model tailored to allow any verification approach to restrict its search to some data distribution of interest. We argue that our architecture is particularly well suited for this purpose because of two major properties. First, we show that the transformation that is defined by our model is piecewise affine. Therefore, the model allows the usage of verifiers based on constraint solving with linear arithmetic. Second, upper density level sets (UDL) of the data distribution are definable via linear constraints in the latent space. As a consequence, representations of UDLs specified by a given probability are effectively computable in the latent space. This property allows for effective verification with a fine-grained, probabilistically interpretable control of how a-typical the inputs subject to verification are.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.14265v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <category>cs.SC</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Faried Abu Zaid, Daniel Neider, Mustafa Yal\c{c}{\i}ner</dc:creator>
    </item>
    <item>
      <title>Measurability in the Fundamental Theorem of Statistical Learning</title>
      <link>https://arxiv.org/abs/2410.10243</link>
      <description>arXiv:2410.10243v3 Announce Type: replace-cross 
Abstract: The Fundamental Theorem of Statistical Learning states that a hypothesis space is PAC learnable if and only if its VC dimension is finite. For the agnostic model of PAC learning, the literature so far presents proofs of this theorem that often tacitly impose several measurability assumptions on the involved sets and functions. We scrutinize these proofs from a measure-theoretic perspective in order to explicitly extract the assumptions needed for a rigorous argument. This leads to a sound statement as well as a detailed and self-contained proof of the Fundamental Theorem of Statistical Learning in the agnostic setting, showcasing the minimal measurability requirements needed. As the Fundamental Theorem of Statistical Learning underpins a wide range of further theoretical developments, our results are of foundational importance: A careful analysis of measurability aspects is essential, especially when the theorem is used in settings where measure-theoretic subtleties play a role. We particularly discuss applications in Model Theory, considering NIP and o-minimal structures. Our main theorem presents sufficient conditions for the PAC learnability of hypothesis spaces defined over o-minimal expansions of the reals. This class of hypothesis spaces covers all artificial neural networks for binary classification that use commonly employed activation functions like ReLU and the sigmoid function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10243v3</guid>
      <category>cs.LG</category>
      <category>cs.LO</category>
      <category>math.LO</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Lothar Sebastian Krapp, Laura Wirth</dc:creator>
    </item>
    <item>
      <title>The STAR-XAI Protocol: A Framework for Inducing and Verifying Agency, Reasoning, and Reliability in AI Agents</title>
      <link>https://arxiv.org/abs/2509.17978</link>
      <description>arXiv:2509.17978v2 Announce Type: replace-cross 
Abstract: The "black box" nature of Large Reasoning Models (LRMs) presents critical limitations in reliability and transparency, fueling the debate around the "illusion of thinking" and the challenge of state hallucinations in agentic systems. In response, we introduce The STAR-XAI Protocol (Socratic, Transparent, Agentic, Reasoning - for eXplainable Artificial Intelligence), a novel operational methodology for training and operating verifiably reliable AI agents. Our method reframes the human-AI interaction as a structured Socratic dialogue governed by an explicit, evolving symbolic rulebook (the Consciousness Transfer Package - CTP) and a suite of integrity protocols, including a state-locking Checksum that eradicates internal state corruption. Through an exhaustive case study in the complex strategic game "Caps i Caps," we demonstrate that this "Clear Box" framework transforms an opaque LRM into a disciplined strategist. The agent not only exhibits the emergence of complex tactics, such as long-term planning, but also achieves ante-hoc transparency by justifying its intentions before acting. Crucially, it demonstrates Second-Order Agency by identifying and correcting flaws in its own supervisor-approved plans, leading to empirically-proven, 100% reliable state tracking and achieving "zero hallucinations by design." The STAR-XAI Protocol thus offers a practical pathway toward building AI agents that are not just high-performing but intrinsically auditable, trustworthy, and reliable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.17978v2</guid>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Antoni Guasch, Maria Isabel Valdez</dc:creator>
    </item>
  </channel>
</rss>
