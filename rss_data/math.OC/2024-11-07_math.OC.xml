<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 08 Nov 2024 02:44:33 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>ADMM for 0/1 D-Opt and MESP relaxations</title>
      <link>https://arxiv.org/abs/2411.03461</link>
      <description>arXiv:2411.03461v1 Announce Type: new 
Abstract: The 0/1 D-optimality problem and the Maximum-Entropy Sampling problem are two well-known NP-hard discrete maximization problems in experimental design. Algorithms for exact optimization (of moderate-sized instances) are based on branch-and-bound. The best upper-bounding methods are based on convex relaxation. We present ADMM (Alternating Direction Method of Multipliers) algorithms for solving these relaxations and experimentally demonstrate their practical value.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03461v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gabriel Ponte, Marcia Fampa, Jon Lee, Luze Xu</dc:creator>
    </item>
    <item>
      <title>Forecasting Outside the Box: Application-Driven Optimal Pointwise Forecasts for Stochastic Optimization</title>
      <link>https://arxiv.org/abs/2411.03520</link>
      <description>arXiv:2411.03520v1 Announce Type: new 
Abstract: The exponential growth in data availability in recent years has led to new formulations of data-driven optimization problems. One such formulation is that of stochastic optimization problems with contextual information, where the goal is to optimize the expected value of a certain function given some contextual information (also called features) that accompany the main data of interest. The contextual information then allows for a better estimation of the quantity of interest via machine learning methods, thereby leading to better solutions. Oftentimes, however, machine learning methods yield just a pointwise estimate instead of an entire distribution. In this paper we show that, when the problem to be solved is a class of two-stage stochastic programs (namely, those with fixed recourse matrix and fixed costs), under mild assumptions the problem can be solved with just one scenario. While such a scenario - which does not have be unique - is usually unknown, we present an integrated learning and optimization procedure that yields the best approximation of that scenario within the modeler's pre-specified set of parameterized forecast functions. Numerical results conducted with inventory problems from the literature (with synthetic data) as well as a bike-sharing problem with real data demonstrate that the proposed approach performs well when compared to benchmark methods from the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03520v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Tito Homem-de-Mello, Juan Valencia, Felipe Lagos, Guido Lagos</dc:creator>
    </item>
    <item>
      <title>The Differentiable Feasibility Pump</title>
      <link>https://arxiv.org/abs/2411.03535</link>
      <description>arXiv:2411.03535v1 Announce Type: new 
Abstract: Although nearly 20 years have passed since its conception, the feasibility pump algorithm remains a widely used heuristic to find feasible primal solutions to mixed-integer linear problems. Many extensions of the initial algorithm have been proposed. Yet, its core algorithm remains centered around two key steps: solving the linear relaxation of the original problem to obtain a solution that respects the constraints, and rounding it to obtain an integer solution. This paper shows that the traditional feasibility pump and many of its follow-ups can be seen as gradient-descent algorithms with specific parameters. A central aspect of this reinterpretation is observing that the traditional algorithm differentiates the solution of the linear relaxation with respect to its cost. This reinterpretation opens many opportunities for improving the performance of the original algorithm. We study how to modify the gradient-update step as well as extending its loss function. We perform extensive experiments on MIPLIB instances and show that these modifications can substantially reduce the number of iterations needed to find a solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03535v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matteo Cacciola, Alexandre Forel, Antonio Frangioni, Andrea Lodi</dc:creator>
    </item>
    <item>
      <title>Efficient Data-Driven Leverage Score Sampling Algorithm for the Minimum Volume Covering Ellipsoid Problem in Big Data</title>
      <link>https://arxiv.org/abs/2411.03617</link>
      <description>arXiv:2411.03617v1 Announce Type: new 
Abstract: The Minimum Volume Covering Ellipsoid (MVCE) problem, characterised by $n$ observations in $d$ dimensions where $n \gg d$, can be computationally very expensive in the big data regime. We apply methods from randomised numerical linear algebra to develop a data-driven leverage score sampling algorithm for solving MVCE, and establish theoretical error bounds and a convergence guarantee. Assuming the leverage scores follow a power law decay, we show that the computational complexity of computing the approximation for MVCE is reduced from $\mathcal{O}(nd^2)$ to $\mathcal{O}(nd + \text{poly}(d))$, which is a significant improvement in big data problems. Numerical experiments demonstrate the efficacy of our new algorithm, showing that it substantially reduces computation time and yields near-optimal solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03617v1</guid>
      <category>math.OC</category>
      <category>stat.CO</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Elizabeth Harris, Ali Eshragh, Bishnu Lamichhane, Jordan Shaw-Carmody, Elizabeth Stojanovski</dc:creator>
    </item>
    <item>
      <title>On a probabilistic global optimizer derived from the Walker slice sampling</title>
      <link>https://arxiv.org/abs/2411.03851</link>
      <description>arXiv:2411.03851v1 Announce Type: new 
Abstract: This article presents a zeroth order probabilistic global optimization algorithm -- SwiftNav -- for (not necessarily convex) functions over a compact domain. A discretization procedure is deployed on the compact domain, starting with a small step-size $h &gt; 0$ and subsequently adaptively refining it in the course of a simulated annealing routine utilizing the Walker slice and the Gibbs sampler, in order to identify a set of global optimizers up to good precision. SwiftNav is parallelizable, which helps with scalability as the dimension of decision variables increases. Several numerical experiments are included here to demonstrate the effectiveness and accuracy of SwiftNav in high-dimensional benchmark optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03851v1</guid>
      <category>math.OC</category>
      <category>cs.MS</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aditya Gupta, Souvik Das, Debasish Chatterjee</dc:creator>
    </item>
    <item>
      <title>Variational Barzilai-Borwein Method</title>
      <link>https://arxiv.org/abs/2411.03899</link>
      <description>arXiv:2411.03899v1 Announce Type: new 
Abstract: The Barzilai-Borwein (BB) method is an effective gradient method for solving unconstrained optimization problems. Based on the observation of two classical BB step sizes, by constructing a variational least squares model, we propose a new class of BB step sizes, each of which still has the quasi-Newton property. The original BB step sizes are two special cases of the new step sizes. Numerical experiments verify the effectiveness of the new step sizes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03899v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xin Xu</dc:creator>
    </item>
    <item>
      <title>An optimal control problem for Maxwell's equations</title>
      <link>https://arxiv.org/abs/2411.03963</link>
      <description>arXiv:2411.03963v1 Announce Type: new 
Abstract: This article is concerned with the optimal boundary control of the Maxwell system. We consider a Bolza problem, where the quadratic functional to be minimized penalizes the electromagnetic field at a given final time. Since the state is weighted in the energy space topology -- a physically realistic choice --, the property that the optimal cost operator does satisfy the Riccati equation (RE) corresponding to the optimization problem is missed, just like in the case of other significant hyperbolic partial differential equations; however, we prove that this Riccati operator as well as the optimal solution can be recovered by means of approximating problems for which the optimal synthesis holds via proper differential Riccati equations. In the case of zero conductivity, an explicit representation of the optimal pair is valid which does not demand the well-posedness of the RE, instead.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03963v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Francesca Bucci, Matthias Eller</dc:creator>
    </item>
    <item>
      <title>Uniform-in-time mean-field limit estimate for the Consensus-Based Optimization</title>
      <link>https://arxiv.org/abs/2411.03986</link>
      <description>arXiv:2411.03986v1 Announce Type: new 
Abstract: We establish a uniform-in-time estimate for the mean-field convergence of the Consensus-Based Optimization (CBO) algorithm by rescaling the consensus point in the dynamics with a small parameter $\kappa \in (0,1)$. This uniform-in-time estimate is essential, as CBO convergence relies on a sufficiently large time horizon and is crucial for ensuring stable, reliable long-term convergence, the latter being key to the practical effectiveness of CBO methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03986v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hui Huang, Hicham Kouhkouh</dc:creator>
    </item>
    <item>
      <title>Tensor train solution to uncertain optimization problems with shared sparsity penalty</title>
      <link>https://arxiv.org/abs/2411.03989</link>
      <description>arXiv:2411.03989v1 Announce Type: new 
Abstract: We develop both first and second order numerical optimization methods to solve non-smooth optimization problems featuring a shared sparsity penalty, constrained by differential equations with uncertainty. To alleviate the curse of dimensionality we use tensor product approximations. To handle the non-smoothness of the objective function we introduce a smoothed version of the shared sparsity objective. We consider both a benchmark elliptic PDE constraint, and a more realistic topology optimization problem. We demonstrate that the error converges linearly in iterations and the smoothing parameter, and faster than algebraically in the number of degrees of freedom, consisting of the number of quadrature points in one variable and tensor ranks. Moreover, in the topology optimization problem, the smoothed shared sparsity penalty actually reduces the tensor ranks compared to the unpenalised solution. This enables us to find a sparse high-resolution design under a high-dimensional uncertainty.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03989v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Harbir Antil, Sergey Dolgov, Akwum Onwunta</dc:creator>
    </item>
    <item>
      <title>Stabilization to trajectories of nonisothermal Cahn-Hilliard equations</title>
      <link>https://arxiv.org/abs/2411.04018</link>
      <description>arXiv:2411.04018v1 Announce Type: new 
Abstract: In this work, it is proven the semiglobal exponential stabilization to time-dependent trajectories of the nonisothermal Cahn-Hilliard equations. In the model, the input controls are given by explicit feedback operators that involve appropriate oblique projections. The actuators are given by a finite number of indicator functions. The results also hold for the isothermal Cahn-Hilliard system. Numerical simulations are shown that illustrate the stabilizing performance of the proposed input feedback operators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04018v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Behzad Azmi, Marvin Fritz, S\'ergio S. Rodrigues</dc:creator>
    </item>
    <item>
      <title>A networked small-gain theorem based on discrete-time diagonal stability</title>
      <link>https://arxiv.org/abs/2411.03380</link>
      <description>arXiv:2411.03380v1 Announce Type: cross 
Abstract: We present a new sufficient condition for finite-gain $L_2$ input-to-output stability of a networked system. The condition requires a matrix, that combines information on the $L_2$ gains of the sub-systems and their interconnections, to be discrete-time diagonally stable (DTDS). We show that the new result generalizes the standard small gain theorem for the negative feedback connection of two sub-systems. An important advantage of the new result is that known sufficient conditions for DTDS can be applied to derive sufficient conditions for networked input-to-output stability. We demonstrate this using several examples. We also derive a new necessary and sufficient condition for a matrix that is a rank one perturbation of a Schur diagonal matrix to be DTDS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03380v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ron Ofir, Michael Margaliot</dc:creator>
    </item>
    <item>
      <title>Chorded Cycle Facets of Clique Partitioning Polytopes</title>
      <link>https://arxiv.org/abs/2411.03407</link>
      <description>arXiv:2411.03407v1 Announce Type: cross 
Abstract: The $q$-chorded $k$-cycle inequalities are a class of valid inequalities for the clique partitioning polytope. It is known that for $q = 2$ or $q = \tfrac{k-1}{2}$, these inequalities induce facets of the clique partitioning polytope if and only if $k$ is odd. We solve the open problem of characterizing such facets for arbitrary $k$ and $q$. More specifically, we prove that the $q$-chorded $k$-cycle inequalities induce facets of the clique partitioning polytope if and only if two conditions are satisfied: $k = 1$ mod $q$, and if $k=3q+1$ then $q=3$ or $q$ is even. This establishes the existence of many facets induced by $q$-chorded $k$-cycle inequalities beyond those previously known.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03407v1</guid>
      <category>cs.DM</category>
      <category>math.OC</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jannik Irmai, Lucas Fabian Naumann, Bjoern Andres</dc:creator>
    </item>
    <item>
      <title>Increasing the Hardness of Posiform Planting Using Random QUBOs for Programmable Quantum Annealer Benchmarking</title>
      <link>https://arxiv.org/abs/2411.03626</link>
      <description>arXiv:2411.03626v1 Announce Type: cross 
Abstract: Posiform planting is a method for constructing QUBO problems with a single unique planted solution that can be tailored to arbitrary connectivity graphs. In this study we investigate making posiform planted QUBOs computationally harder by fusing many smaller random discrete coefficient spin-glass Ising models, whose global minimum energy is computed classically using classical binary integer programming optimization software, with posiform-planted QUBOs. The single unique ground-state solution of the resulting QUBO problem is the concatenation of (exactly one of) the ground-states of each of the smaller problems. We apply these modified posiform planted QUBOs to the task of benchmarking programmable D-Wave quantum annealers. The proposed method enables generating binary variable combinatorial optimization problems that cover the entire quantum annealing processor hardware graph, have a unique solution, are entirely hardware-graph-native, and can have tunable computational hardness. We benchmark the capabilities of three D-Wave superconducting qubit quantum annealing processors, having from 563 up to 5627 qubits, to sample the optimal unique planted solution of problems generated by our proposed method and compare them against simulated annealing and Gurobi. We find that the D-Wave QPU ground-state sampling success rate does not change with respect to the size of the random QUBOs we employ. Surprisingly, we find that some of these classes of QUBOs are solved at very high success rates at short annealing times compared to longer annealing times for the Zephyr connectivity graph QPUs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03626v1</guid>
      <category>quant-ph</category>
      <category>math.OC</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Elijah Pelofske, Georg Hahn, Hristo Djidjev</dc:creator>
    </item>
    <item>
      <title>Variational Inference on the Boolean Hypercube with the Quantum Entropy</title>
      <link>https://arxiv.org/abs/2411.03759</link>
      <description>arXiv:2411.03759v1 Announce Type: cross 
Abstract: In this paper, we derive variational inference upper-bounds on the log-partition function of pairwise Markov random fields on the Boolean hypercube, based on quantum relaxations of the Kullback-Leibler divergence. We then propose an efficient algorithm to compute these bounds based on primal-dual optimization. An improvement of these bounds through the use of ''hierarchies,'' similar to sum-of-squares (SoS) hierarchies is proposed, and we present a greedy algorithm to select among these relaxations. We carry extensive numerical experiments and compare with state-of-the-art methods for this inference problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03759v1</guid>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eliot Beyler (SIERRA), Francis Bach (SIERRA)</dc:creator>
    </item>
    <item>
      <title>Koopman-based control using sum-of-squares optimization: Improved stability guarantees and data efficiency</title>
      <link>https://arxiv.org/abs/2411.03875</link>
      <description>arXiv:2411.03875v1 Announce Type: cross 
Abstract: In this paper, we propose a novel controller design approach for unknown nonlinear systems using the Koopman operator. In particular, we use the recently proposed stability- and certificate-oriented extended dynamic mode decomposition (SafEDMD) architecture to generate a data-driven bilinear surrogate model with certified error bounds. Then, by accounting for the obtained error bounds in a controller design based on the bilinear system, one can guarantee closed-loop stability for the true nonlinear system. While existing approaches over-approximate the bilinearity of the surrogate model, thus introducing conservatism and providing only local guarantees, we explicitly account for the bilinearity by using sum-of-squares (SOS) optimization in the controller design. More precisely, we parametrize a rational controller stabilizing the error-affected bilinear surrogate model and, consequently, the underlying nonlinear system. The resulting SOS optimization problem provides explicit data-driven controller design conditions for unknown nonlinear systems based on semidefinite programming. Our approach significantly reduces conservatism by establishing a larger region of attraction and improved data efficiency. The proposed method is evaluated using numerical examples, demonstrating its advantages over existing approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03875v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Robin Str\"asser, Julian Berberich, Frank Allg\"ower</dc:creator>
    </item>
    <item>
      <title>Direct Adaptive Control of Grid-Connected Power Converters via Output-Feedback Data-Enabled Policy Optimization</title>
      <link>https://arxiv.org/abs/2411.03909</link>
      <description>arXiv:2411.03909v1 Announce Type: cross 
Abstract: Power electronic converters are gradually becoming the main components of modern power systems due to the increasing integration of renewable energy sources. However, power converters may become unstable when interacting with the complex and time-varying power grid. To deal with this problem, an adaptive control design scheme for power converters is preferable, which can capture the closed-loop dynamical interaction between the converter and the grid via online data. In this paper, we propose an adaptive data-driven control method, called data-enabled policy optimization (DeePO), to stabilize power converters by using only online input-output data. Our contributions are threefold. First, we propose a covariance parameterization of partially observed linear systems with input-output data. Second, we develop a DeePO algorithm, which updates the parameterized policy with data-based gradient descent to achieve computationally efficient adaptive control. Third, we use high-fidelity simulations to verify that DeePO can effectively stabilize grid-connected power converters and quickly adapt to the changes in the power grid.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03909v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Feiran Zhao, Ruohan Leng, Linbin Huang, Huanhai Xin, Keyou You, Florian D\"orfler</dc:creator>
    </item>
    <item>
      <title>Dynamic Virtual Inertia and Damping Control for Zero-Inertia Grids</title>
      <link>https://arxiv.org/abs/2411.03998</link>
      <description>arXiv:2411.03998v1 Announce Type: cross 
Abstract: In this paper virtual synchronous generation (VSG) approach is investigated in application to low- and zero-inertia grids operated by grid-forming (GFM) inverters. The key idea here is to introduce dynamic inertia and damping constants in order to keep power gird stable during different types of faults, islanding or large power balance oscillations. In order to achieve such robustness, we introduce frequency and phase angle shift functions to VSG along with dynamics virtual generator parameters. The stability of such approach is theoretically proven and theoretical results are supported by detailed case studies in RTDS (Real-Time Digital Simulator) NovaCor 1.0 with GFM inverters dynamics simulated with 1-3 microseconds timestep using two-level universal inverter model. Case studies include all aforementioned types of faults and demonstrate increased power grid robustness and survivability in comparison with traditional synchronous generation of comparable size.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03998v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Oleg O. Khamisov, Stepan P. Vasilev</dc:creator>
    </item>
    <item>
      <title>Interpretable and Efficient Data-driven Discovery and Control of Distributed Systems</title>
      <link>https://arxiv.org/abs/2411.04098</link>
      <description>arXiv:2411.04098v1 Announce Type: cross 
Abstract: Effectively controlling systems governed by Partial Differential Equations (PDEs) is crucial in several fields of Applied Sciences and Engineering. These systems usually yield significant challenges to conventional control schemes due to their nonlinear dynamics, partial observability, high-dimensionality once discretized, distributed nature, and the requirement for low-latency feedback control. Reinforcement Learning (RL), particularly Deep RL (DRL), has recently emerged as a promising control paradigm for such systems, demonstrating exceptional capabilities in managing high-dimensional, nonlinear dynamics. However, DRL faces challenges including sample inefficiency, robustness issues, and an overall lack of interpretability. To address these issues, we propose a data-efficient, interpretable, and scalable Dyna-style Model-Based RL framework for PDE control, combining the Sparse Identification of Nonlinear Dynamics with Control (SINDy-C) algorithm and an autoencoder (AE) framework for the sake of dimensionality reduction of PDE states and actions. This novel approach enables fast rollouts, reducing the need for extensive environment interactions, and provides an interpretable latent space representation of the PDE forward dynamics. We validate our method on two PDE problems describing fluid flows - namely, the 1D Burgers equation and 2D Navier-Stokes equations - comparing it against a model-free baseline, and carrying out an extensive analysis of the learned dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04098v1</guid>
      <category>cs.LG</category>
      <category>cs.CE</category>
      <category>math.OC</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Florian Wolf, Nicol\`o Botteghi, Urban Fasel, Andrea Manzoni</dc:creator>
    </item>
    <item>
      <title>Second-order optimality conditions for the bilinear optimal control of a degenerate equation</title>
      <link>https://arxiv.org/abs/2212.11046</link>
      <description>arXiv:2212.11046v2 Announce Type: replace 
Abstract: The main purpose of this paper is the study of second-order optimality conditions for the bilinear control of a strongly degenerate parabolic equation. The equation is degenerate at the boundary of the spatial domain. The well-posedness of the state equation, as well as weak maximum principles are established. We prove some differentiability properties of the control-to-state operator and the existence of optimal solutions. Finally, we derive first- and second-order optimality conditions for the system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.11046v2</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1080/00036811.2023.2299714</arxiv:DOI>
      <arxiv:journal_reference>Applicable Analysis, 2024</arxiv:journal_reference>
      <dc:creator>Cyrille Kenne, Landry Djomegne, Pascal Zongo</dc:creator>
    </item>
    <item>
      <title>Exponential convergence rates for momentum stochastic gradient descent in the overparametrized setting</title>
      <link>https://arxiv.org/abs/2302.03550</link>
      <description>arXiv:2302.03550v2 Announce Type: replace 
Abstract: We prove explicit bounds on the exponential rate of convergence for the momentum stochastic gradient descent scheme (MSGD) for arbitrary, fixed hyperparameters (learning rate, friction parameter) and its continuous-in-time counterpart in the context of non-convex optimization. In the small step-size regime and in the case of flat minima or large noise intensities, these bounds prove faster convergence of MSGD compared to plain stochastic gradient descent (SGD). The results are shown for objective functions satisfying a local Polyak-Lojasiewicz inequality and under assumptions on the variance of MSGD that are satisfied in overparametrized settings. Moreover, we analyze the optimal choice of the friction parameter and show that the MSGD process almost surely converges to a local minimum.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.03550v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Benjamin Gess, Sebastian Kassing</dc:creator>
    </item>
    <item>
      <title>Pre-trained Mixed Integer Optimization through Multi-variable Cardinality Branching</title>
      <link>https://arxiv.org/abs/2305.12352</link>
      <description>arXiv:2305.12352v2 Announce Type: replace 
Abstract: In this paper, we propose a Pre-trained Mixed Integer Optimization framework (PreMIO) that accelerates online mixed integer program (MIP) solving with offline datasets and machine learning models. Our method is based on a data-driven multi-variable cardinality branching procedure that splits the MIP feasible region using hyperplanes chosen by the concentration inequalities. Unlike most previous ML+MIP approaches that either require complicated implementation or suffer from a lack of theoretical justification, our method is simple, flexible, provable, and explainable. Numerical experiments on both classical OR benchmark datasets and real-life instances validate the efficiency of our proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.12352v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yanguang Chen, Wenzhi Gao, Dongdong Ge, Yinyu Ye</dc:creator>
    </item>
    <item>
      <title>On Squared-Variable Formulations</title>
      <link>https://arxiv.org/abs/2310.01784</link>
      <description>arXiv:2310.01784v2 Announce Type: replace 
Abstract: We revisit a formulation technique for inequality constrained optimization problems that has been known for decades: the substitution of squared variables for nonnegative variables. Using this technique, inequality constraints are converted to equality constraints via the introduction of a squared-slack variable. Such formulations have the superficial advantage that inequality constraints can be dispensed with altogether. But there are clear disadvantages, not least being that first-order optimal points for the squared-variable reformulation may not correspond to first-order optimal points for the original problem, because the Lagrange multipliers may have the wrong sign. Extending previous results, this paper shows that points satisfying approximate second-order optimality conditions for the squared-variable reformulation also, under certain conditions, satisfy approximate second-order optimality conditions for the original formulation, and vice versa. Such results allow us to adapt complexity analysis of methods for equality constrained optimization to account for inequality constraints. On the algorithmic side, we examine squared-variable formulations for several interesting problem classes, including bound-constrained quadratic programming, linear programming, and nonnegative matrix factorization. We show that algorithms built on these formulations are surprisingly competitive with standard methods. For linear programming, we examine the relationship between the squared-variable approach and primal-dual interior-point methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.01784v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lijun Ding, Stephen J. Wright</dc:creator>
    </item>
    <item>
      <title>Stochastic Weakly Convex Optimization Beyond Lipschitz Continuity</title>
      <link>https://arxiv.org/abs/2401.13971</link>
      <description>arXiv:2401.13971v2 Announce Type: replace 
Abstract: This paper considers stochastic weakly convex optimization without the standard Lipschitz continuity assumption. Based on new adaptive regularization (stepsize) strategies, we show that a wide class of stochastic algorithms, including the stochastic subgradient method, preserve the $\mathcal{O} ( 1 / \sqrt{K})$ convergence rate with constant failure rate. Our analyses rest on rather weak assumptions: the Lipschitz parameter can be either bounded by a general growth function of $\|x\|$ or locally estimated through independent random samples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.13971v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Wenzhi Gao, Qi Deng</dc:creator>
    </item>
    <item>
      <title>A First-Order Gradient Approach for the Connectivity Analysis of Markov Chains</title>
      <link>https://arxiv.org/abs/2403.11744</link>
      <description>arXiv:2403.11744v2 Announce Type: replace 
Abstract: Weighted graphs are commonly used to model various complex systems, including social networks, power grids, transportation networks, and biological systems. In many applications, the connectivity of these networks can be expressed through the Mean First Passage Times (MFPTs) of a Markov chain modeling a random walker on the graph. In this paper, we generalize the network metrics based on Markov chains' MFPTs and extend them to networks affected by uncertainty, in which edges may fail and hence not be present according to a pre-determined stochastic model. To find optimally connected Markov chains, we present a parameterization-free method for optimizing the MFPTs of the Markov chain. More specifically, we present an efficient Simultaneous Perturbation Stochastic Approximation (SPSA) algorithm in the context of Markov chain optimization. The proposed algorithm is suitable for both fixed and random networks. Using various numerical experiments, we demonstrate scalability compared to established benchmarks. Importantly, our algorithm finds an optimal solution without requiring prior knowledge of edge failure probabilities, allowing for an online optimization approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11744v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christian P. C. Franssen, Alessandro Zocca, Bernd F. Heidergott</dc:creator>
    </item>
    <item>
      <title>An $\alpha$-potential game framework for $N$-player dynamic games</title>
      <link>https://arxiv.org/abs/2403.16962</link>
      <description>arXiv:2403.16962v4 Announce Type: replace 
Abstract: This paper proposes and studies a general form of dynamic $N$-player non-cooperative games called $\alpha$-potential games, where the change of a player's value function upon her unilateral deviation from her strategy is equal to the change of an $\alpha$-potential function up to an error $\alpha$. Analogous to the static potential game (which corresponds to $\alpha=0$), the $\alpha$-potential game framework is shown to reduce the challenging task of finding $\alpha$-Nash equilibria for a dynamic game to minimizing the $\alpha$-potential function. Moreover, an analytical characterization of $\alpha$-potential functions is established, with $\alpha$ represented in terms of the magnitude of the asymmetry of value functions' second-order derivatives. For stochastic differential games in which the state dynamic is a controlled diffusion, $\alpha$ is characterized in terms of the number of players, the choice of admissible strategies, and the intensity of interactions and the level of heterogeneity among players. Two classes of stochastic differential games, namely distributed games and games with mean field interactions, are analyzed to highlight the dependence of $\alpha$ on general game characteristics that are beyond the mean-field paradigm, which focuses on the limit of $N$ with homogeneous players. To analyze the $\alpha$-NE, the associated optimization problem is embedded into a conditional McKean-Vlasov control problem. A verification theorem is established to construct $\alpha$-NE based on solutions to an infinite-dimensional Hamilton-Jacobi-Bellman equation, which is reduced to a system of ordinary differential equations for linear-quadratic games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16962v4</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xin Guo, Xinyu Li, Yufei Zhang</dc:creator>
    </item>
    <item>
      <title>Measurized Markov Decision Processes Part I: The Discounted Infinite Horizon Criterion</title>
      <link>https://arxiv.org/abs/2405.03888</link>
      <description>arXiv:2405.03888v3 Announce Type: replace 
Abstract: In this paper, we explore lifting Markov Decision Processes (MDPs) to the space of probability measures and consider the so-called measurized MDPs: deterministic processes where states are probability measures on the original state space, and actions are stochastic kernels on the original action space. Bertsekas and Shreve studied similar deterministic MDPs in the context of universally measurable policies. Here, we cast lifted MDPs within the semicontinuous-semicompact framework of Hernandez-Lerma and Lasserre. This makes the lifted framework more accessible as it entails (i) optimal Borel-measurable value functions and policies, (ii) reasonably mild assumptions that are easier to verify than those in the universally-measurable framework, and (iii) simpler proofs. In addition, we showcase the untapped potential of lifted MDPs by demonstrating how the measurized framework enables the incorporation of constraints and value function approximations that are not available from the standard MDP setting. Finally, we introduce a novel algebraic lifting procedure for any MDP, offering a systematic approach to derive measurized formulations. We use this method to show how non-deterministic measure-valued MDPs can emerge from lifting MDPs impacted by external random shocks. In this paper, we focus on the discounted infinite-horizon criterion, whereas in Part II we focus on the long-run average reward case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03888v3</guid>
      <category>math.OC</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel Adelman, Alba V. Olivares-Nadal</dc:creator>
    </item>
    <item>
      <title>Speeding-up Large-scale LP Energy System Models: Using Graph-theory to Remove the Overhead Cost of Flexible Modeling</title>
      <link>https://arxiv.org/abs/2407.05451</link>
      <description>arXiv:2407.05451v2 Announce Type: replace 
Abstract: Energy system models are crucial for planning, supporting, and understanding energy transition pathways. Flexible energy modelling tools have emerged to provide practitioners, planners, and decision-makers with various alternatives to represent diverse energy systems, including green hydrogen or exclusively renewable-powered storage assets. The increased interaction between energy sectors, temporal resolution, and extensive geographical scopes have led to large-scale problems posing significant computational challenges. Despite improvements in computing power and linear programming (LP) solvers, large-scale LP models are often simplified, sacrificing fidelity to speed up solutions. This paper aims to debunk the misconception that an LP model's simplicity cannot be improved without sacrificing fidelity. We propose exploiting the graph nature of energy systems using a single building block, the Energy Asset, to reduce computational complexity. By using only one building block, the Energy Asset, we avoid intermediary assets and connections, thus reducing the number of variables by 26% and constraints by 35%. This approach naturally speeds up solving times by 1.27 times without sacrificing model fidelity. Our illustrative case study demonstrates these improvements compared to traditional two-building-block approaches. This paper aims to raise awarenes in the energy modelling community about the quality of LP models and shows that not all LPs are created equal. Our proposed method speeds up energy system models regardless of anticipated advances in software and hardware, allowing for the solution of larger and more detailed models with existing technology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.05451v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Diego A. Tejada-Arango, German Morales-Espana, Juha Kiviluoma</dc:creator>
    </item>
    <item>
      <title>Gradient Methods with Online Scaling</title>
      <link>https://arxiv.org/abs/2411.01803</link>
      <description>arXiv:2411.01803v2 Announce Type: replace 
Abstract: We introduce a framework to accelerate the convergence of gradient-based methods with online learning. The framework learns to scale the gradient at each iteration through an online learning algorithm and provably accelerates gradient-based methods asymptotically. In contrast with previous literature, where convergence is established based on worst-case analysis, our framework provides a strong convergence guarantee with respect to the optimal scaling matrix for the iteration trajectory. For smooth strongly convex optimization, our results provide an $O(\kappa^\star \log(1/\varepsilon)$) complexity result, where $\kappa^\star$ is the condition number achievable by the optimal preconditioner, improving on the previous $O(\sqrt{n}\kappa^\star \log(1/\varepsilon))$ result. In particular, a variant of our method achieves superlinear convergence on convex quadratics. For smooth convex optimization, we show for the first time that the widely-used hypergradient descent heuristic improves on the convergence of gradient descent.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.01803v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Wenzhi Gao, Ya-Chi Chu, Yinyu Ye, Madeleine Udell</dc:creator>
    </item>
    <item>
      <title>Fully Distributed Adaptive Nash Equilibrium Seeking Algorithm for Constrained Noncooperative Games with Prescribed Performance</title>
      <link>https://arxiv.org/abs/2411.02719</link>
      <description>arXiv:2411.02719v2 Announce Type: replace 
Abstract: This paper investigates a fully distributed adaptive Nash equilibrium (NE) seeking algorithm for constrained noncooperative games with prescribed-time stability. On the one hand, prescribed-time stability for the proposed NE seeking algorithm is obtained by using an adaptive penalty technique, a time-varying control gain and a cosine-related time conversion function, which extends the prior asymptotic stability result. On the other hand, uncoordinated integral adaptive gains are incorporated in order to achieve the fully distribution of the algorithm. Finally, the theoretical result is validated through a numerical simulation based on a standard power market scenario.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.02719v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sichen Qian</dc:creator>
    </item>
    <item>
      <title>Contraction Theory for Nonlinear Stability Analysis and Learning-based Control: A Tutorial Overview</title>
      <link>https://arxiv.org/abs/2110.00675</link>
      <description>arXiv:2110.00675v4 Announce Type: replace-cross 
Abstract: Contraction theory is an analytical tool to study differential dynamics of a non-autonomous (i.e., time-varying) nonlinear system under a contraction metric defined with a uniformly positive definite matrix, the existence of which results in a necessary and sufficient characterization of incremental exponential stability of multiple solution trajectories with respect to each other. By using a squared differential length as a Lyapunov-like function, its nonlinear stability analysis boils down to finding a suitable contraction metric that satisfies a stability condition expressed as a linear matrix inequality, indicating that many parallels can be drawn between well-known linear systems theory and contraction theory for nonlinear systems. Furthermore, contraction theory takes advantage of a superior robustness property of exponential stability used in conjunction with the comparison lemma. This yields much-needed safety and stability guarantees for neural network-based control and estimation schemes, without resorting to a more involved method of using uniform asymptotic stability for input-to-state stability. Such distinctive features permit systematic construction of a contraction metric via convex optimization, thereby obtaining an explicit exponential bound on the distance between a time-varying target trajectory and solution trajectories perturbed externally due to disturbances and learning errors. The objective of this paper is therefore to present a tutorial overview of contraction theory and its advantages in nonlinear stability analysis of deterministic and stochastic systems, with an emphasis on deriving formal robustness and stability guarantees for various learning-based and data-driven automatic control methods. In particular, we provide a detailed review of techniques for finding contraction metrics and associated control and estimation laws using deep neural networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2110.00675v4</guid>
      <category>cs.LG</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.arcontrol.2021.10.001</arxiv:DOI>
      <arxiv:journal_reference>Annual Reviews in Control; Volume 52; 2021; Pages 135-169; ISSN 1367-5788,</arxiv:journal_reference>
      <dc:creator>Hiroyasu Tsukamoto, Soon-Jo Chung, Jean-Jacques E. Slotine</dc:creator>
    </item>
    <item>
      <title>Nonlinear Distributionally Robust Optimization</title>
      <link>https://arxiv.org/abs/2306.03202</link>
      <description>arXiv:2306.03202v3 Announce Type: replace-cross 
Abstract: This article focuses on a class of distributionally robust optimization (DRO) problems where, unlike the growing body of the literature, the objective function is potentially nonlinear in the distribution. Existing methods to optimize nonlinear functions in probability space use the Frechet derivatives, which present theoretical and computational challenges. Motivated by this, we propose an alternative notion for the derivative and corresponding smoothness based on Gateaux (G)-derivative for generic risk measures. These concepts are explained via three running risk measure examples of variance, entropic risk, and risk on finite support sets. We then propose a G-derivative-based Frank-Wolfe (FW) algorithm for generic nonlinear optimization problems in probability spaces and establish its convergence under the proposed notion of smoothness in a completely norm-independent manner. We use the set-up of the FW algorithm to devise a methodology to compute a saddle point of the nonlinear DRO problem. Finally, we validate our theoretical results on two cases of the $entropic$ and $variance$ risk measures in the context of portfolio selection problems. In particular, we analyze their regularity conditions and "sufficient statistic", compute the respective FW-oracle in various settings, and confirm the theoretical outcomes through numerical validation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.03202v3</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammed Rayyan Sheriff, Peyman Mohajerin Esfahani</dc:creator>
    </item>
    <item>
      <title>Scalable Approximate Optimal Diagonal Preconditioning</title>
      <link>https://arxiv.org/abs/2312.15594</link>
      <description>arXiv:2312.15594v2 Announce Type: replace-cross 
Abstract: We consider the problem of finding the optimal diagonal preconditioner for a positive definite matrix. Although this problem has been shown to be solvable and various methods have been proposed, none of the existing approaches are scalable to matrices of large dimension, or when access is limited to black-box matrix-vector products, thereby significantly limiting their practical application. In view of these challenges, we propose practical algorithms applicable to finding approximate optimal diagonal preconditioners of large sparse systems. Our approach is based on the idea of dimension reduction, and combines techniques from semi-definite programming (SDP), random projection, semi-infinite programming (SIP), and column generation. Numerical experiments demonstrate that our method scales to sparse matrices of size greater than $10^7$. Notably, our approach is efficient and implementable using only black-box matrix-vector product operations, making it highly practical for a wide variety of applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.15594v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenzhi Gao, Zhaonan Qu, Madeleine Udell, Yinyu Ye</dc:creator>
    </item>
    <item>
      <title>Communication-Efficient Adaptive Batch Size Strategies for Distributed Local Gradient Methods</title>
      <link>https://arxiv.org/abs/2406.13936</link>
      <description>arXiv:2406.13936v2 Announce Type: replace-cross 
Abstract: Modern deep neural networks often require distributed training with many workers due to their large size. As the number of workers increases, communication overheads become the main bottleneck in data-parallel minibatch stochastic gradient methods with per-iteration gradient synchronization. Local gradient methods like Local SGD reduce communication by only synchronizing model parameters and/or gradients after several local steps. Despite an understanding of their convergence and the importance of batch sizes for training efficiency and generalization, optimal batch sizes for local gradient methods are difficult to determine. We introduce adaptive batch size strategies for local gradient methods that increase batch sizes adaptively to reduce minibatch gradient variance. We provide convergence guarantees under homogeneous data conditions and support our claims with image classification and language modeling experiments, demonstrating the effectiveness of our strategies for both training efficiency and generalization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.13936v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tim Tsz-Kit Lau, Weijian Li, Chenwei Xu, Han Liu, Mladen Kolar</dc:creator>
    </item>
    <item>
      <title>Reducing Matroid Optimization to Basis Search</title>
      <link>https://arxiv.org/abs/2408.04118</link>
      <description>arXiv:2408.04118v2 Announce Type: replace-cross 
Abstract: Matroids provide one of the most elegant structures for algorithm design. This is best identified by the Edmonds-Rado theorem relating the success of the simple greedy algorithm to the anatomy of the optimal basis of a matroid [Edm71; Rad57]. As a response, much energy has been devoted to understanding a matroid's computational properties. Yet, less is understood where parallel algorithms are concerned. In response, we initiate the study of parallel matroid optimization in the adaptive complexity model [BS18]. First, we reexamine Bor\r{u}vka's classical minimum weight spanning tree algorithm [Bor26b; Bor26a] in the abstract language of matroid theory, and identify a new certificate of optimality for the basis of any matroid as a result. In particular, a basis is optimal if and only if it contains the points of minimum weight in every circuit of the dual matroid. Hence, we can witnesses whether any specific point belongs to the optimal basis via a test for local optimality in a circuit of the dual matroid, thereby revealing a general design paradigm towards parallel matroid optimization. To instantiate this paradigm, we use the special structure of a binary matroid to identify an optimization scheme with low adaptivity. Here, our key technical step is reducing optimization to the simpler task of basis search in the binary matroid, using only logarithmic overhead of adaptive rounds of queries to independence oracles. Consequentially, we compose our reduction with the parallel basis search method of [KUW88] to obtain an algorithm for finding the optimal basis of a binary matroid terminating in sublinearly many adaptive rounds of queries to an independence oracle. To the authors' knowledge, this is the first algorithm for matroid optimization to outperform the greedy algorithm in terms of adaptive complexity in the independence query model without assuming the matroid is encoded by a graph.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04118v2</guid>
      <category>cs.DS</category>
      <category>cs.DC</category>
      <category>cs.DM</category>
      <category>math.OC</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Robert Streit, Vijay K. Garg</dc:creator>
    </item>
    <item>
      <title>Distributed Binary Optimization with In-Memory Computing: An Application for the SAT Problem</title>
      <link>https://arxiv.org/abs/2409.09152</link>
      <description>arXiv:2409.09152v2 Announce Type: replace-cross 
Abstract: In-memory computing (IMC) has been shown to be a promising approach for solving binary optimization problems while significantly reducing energy and latency. Building on the advantages of parallel computation, we propose an IMC-compatible parallelism framework inspired by parallel tempering (PT), enabling cross-replica communication to improve the performance of IMC solvers. This framework enables an IMC solver not only to improve performance beyond what can be achieved through parallelization, but also affords greater flexibility for the search process with low hardware overhead. We justify that the framework can be applied to almost any IMC solver. We demonstrate the effectiveness of the framework for the Boolean satisfiability (SAT) problem, using the WalkSAT heuristic as a proxy for existing IMC solvers. The resulting PT-inspired cooperative WalkSAT (PTIC-WalkSAT) algorithm outperforms the traditional WalkSAT heuristic in terms of the iterations-to-solution in 76.3% of the tested problem instances and its na\"ive parallel variant (PA-WalkSAT) does so in 68.4% of the instances. An estimate of the energy overhead of the PTIC framework for two hardware accelerator architectures indicates that in both cases the overhead of running the PTIC framework would be less than 1% of the total energy required to run each accelerator.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.09152v2</guid>
      <category>cs.ET</category>
      <category>cs.AR</category>
      <category>math.OC</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiangyi Zhang, Ignacio Rozada, Fabian B\"ohm, Elisabetta Valiante, Moslem Noori, Thomas Van Vaerenbergh, Chan-Woo Yang, Giacomo Pedretti, Masoud Mohseni, Raymond Beausoleil</dc:creator>
    </item>
    <item>
      <title>LDAdam: Adaptive Optimization from Low-Dimensional Gradient Statistics</title>
      <link>https://arxiv.org/abs/2410.16103</link>
      <description>arXiv:2410.16103v3 Announce Type: replace-cross 
Abstract: We introduce LDAdam, a memory-efficient optimizer for training large models, that performs adaptive optimization steps within lower dimensional subspaces, while consistently exploring the full parameter space during training. This strategy keeps the optimizer's memory footprint to a fraction of the model size. LDAdam relies on a new projection-aware update rule for the optimizer states that allows for transitioning between subspaces, i.e., estimation of the statistics of the projected gradients. To mitigate the errors due to low-rank projection, LDAdam integrates a new generalized error feedback mechanism, which explicitly accounts for both gradient and optimizer state compression. We prove the convergence of LDAdam under standard assumptions, and show that LDAdam allows for accurate and efficient fine-tuning and pre-training of language models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.16103v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas Robert, Mher Safaryan, Ionut-Vlad Modoranu, Dan Alistarh</dc:creator>
    </item>
    <item>
      <title>An Efficient Dynamic Resource Allocation Framework for Evolutionary Bilevel Optimization</title>
      <link>https://arxiv.org/abs/2410.24081</link>
      <description>arXiv:2410.24081v2 Announce Type: replace-cross 
Abstract: Bilevel optimization problems are characterized by an interactive hierarchical structure, where the upper level seeks to optimize its strategy while simultaneously considering the response of the lower level. Evolutionary algorithms are commonly used to solve complex bilevel problems in practical scenarios, but they face significant resource consumption challenges due to the nested structure imposed by the implicit lower-level optimality condition. This challenge becomes even more pronounced as problem dimensions increase. Although recent methods have enhanced bilevel convergence through task-level knowledge sharing, further efficiency improvements are still hindered by redundant lower-level iterations that consume excessive resources while generating unpromising solutions. To overcome this challenge, this paper proposes an efficient dynamic resource allocation framework for evolutionary bilevel optimization, named DRC-BLEA. Compared to existing approaches, DRC-BLEA introduces a novel competitive quasi-parallel paradigm, in which multiple lower-level optimization tasks, derived from different upper-level individuals, compete for resources. A continuously updated selection probability is used to prioritize execution opportunities to promising tasks. Additionally, a cooperation mechanism is integrated within the competitive framework to further enhance efficiency and prevent premature convergence. Experimental results compared with chosen state-of-the-art algorithms demonstrate the effectiveness of the proposed method. Specifically, DRC-BLEA achieves competitive accuracy across diverse problem sets and real-world scenarios, while significantly reducing the number of function evaluations and overall running time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.24081v2</guid>
      <category>cs.NE</category>
      <category>math.OC</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Dejun Xu, Kai Ye, Zimo Zheng, Tao Zhou, Gary G. Yen, Min Jiang</dc:creator>
    </item>
  </channel>
</rss>
