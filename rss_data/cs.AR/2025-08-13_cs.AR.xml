<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.AR updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.AR</link>
    <description>cs.AR updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.AR" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 14 Aug 2025 04:00:13 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Re-thinking Memory-Bound Limitations in CGRAs</title>
      <link>https://arxiv.org/abs/2508.09570</link>
      <description>arXiv:2508.09570v1 Announce Type: new 
Abstract: Coarse-Grained Reconfigurable Arrays (CGRAs) are specialized accelerators commonly employed to boost performance in workloads with iterative structures. Existing research typically focuses on compiler or architecture optimizations aimed at improving CGRA performance, energy efficiency, flexibility, and area utilization, under the idealistic assumption that kernels can access all data from Scratchpad Memory (SPM). However, certain complex workloads-particularly in fields like graph analytics, irregular database operations, and specialized forms of high-performance computing (e.g., unstructured mesh simulations)-exhibit irregular memory access patterns that hinder CGRA utilization, sometimes dropping below 1.5%, making the CGRA memory-bound. To address this challenge, we conduct a thorough analysis of the underlying causes of performance degradation, then propose a redesigned memory subsystem and refine the memory model. With both microarchitectural and theoretical optimization, our solution can effectively manage irregular memory accesses through CGRA-specific runahead execution mechanism and cache reconfiguration techniques. Our results demonstrate that we can achieve performance comparable to the original SPM-only system while requiring only 1.27% of the storage size. The runahead execution mechanism achieves an average 3.04x speedup (up to 6.91x), with cache reconfiguration technique providing an additional 6.02% improvement, significantly enhancing CGRA performance for irregular memory access patterns.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.09570v1</guid>
      <category>cs.AR</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3760386</arxiv:DOI>
      <arxiv:journal_reference>ACM Transactions on Embedded Computing Systems 2025</arxiv:journal_reference>
      <dc:creator>Xiangfeng Liu, Zhe Jiang, Anzhen Zhu, Xiaomeng Han, Mingsong Lyu, Qingxu Deng, Nan Guan</dc:creator>
    </item>
    <item>
      <title>A Limits Study of Memory-side Tiering Telemetry</title>
      <link>https://arxiv.org/abs/2508.09351</link>
      <description>arXiv:2508.09351v1 Announce Type: cross 
Abstract: Increasing workload demands and emerging technologies necessitate the use of various memory and storage tiers in computing systems. This paper presents results from a CXL-based Experimental Memory Request Logger that reveals precise memory access patterns at runtime without interfering with the running workloads. We use it for software emulation of future memory telemetry hardware. By combining reactive placement based on data address monitoring, proactive data movement, and compiler hints, a Hotness Monitoring Unit (HMU) within memory modules can greatly improve memory tiering solutions. Analysis of page placement using profiled access counts on a Deep Learning Recommendation Model (DLRM) indicates a potential 1.94x speedup over Linux NUMA balancing tiering, and only a 3% slowdown compared to Host-DRAM allocation while offloading over 90% of pages to CXL memory. The study underscores the limitations of existing tiering strategies in terms of coverage and accuracy, and makes a strong case for programmable, device-level telemetry as a scalable and efficient solution for future memory systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.09351v1</guid>
      <category>cs.OS</category>
      <category>cs.AR</category>
      <category>cs.PF</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Vinicius Petrucci, Felippe Zacarias, David Roberts</dc:creator>
    </item>
    <item>
      <title>MiCo: End-to-End Mixed Precision Neural Network Co-Exploration Framework for Edge AI</title>
      <link>https://arxiv.org/abs/2508.09500</link>
      <description>arXiv:2508.09500v1 Announce Type: cross 
Abstract: Quantized Neural Networks (QNN) with extremely low-bitwidth data have proven promising in efficient storage and computation on edge devices. To further reduce the accuracy drop while increasing speedup, layer-wise mixed-precision quantization (MPQ) becomes a popular solution. However, existing algorithms for exploring MPQ schemes are limited in flexibility and efficiency. Comprehending the complex impacts of different MPQ schemes on post-training quantization and quantization-aware training results is a challenge for conventional methods. Furthermore, an end-to-end framework for the optimization and deployment of MPQ models is missing in existing work.
  In this paper, we propose the MiCo framework, a holistic MPQ exploration and deployment framework for edge AI applications. The framework adopts a novel optimization algorithm to search for optimal quantization schemes with the highest accuracies while meeting latency constraints. Hardware-aware latency models are built for different hardware targets to enable fast explorations. After the exploration, the framework enables direct deployment from PyTorch MPQ models to bare-metal C codes, leading to end-to-end speedup with minimal accuracy drops.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.09500v1</guid>
      <category>cs.LG</category>
      <category>cs.AR</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zijun Jiang, Yangdi Lyu</dc:creator>
    </item>
    <item>
      <title>Low-latency D-MIMO Localization using Distributed Scalable Message-Passing Algorithm</title>
      <link>https://arxiv.org/abs/2508.09546</link>
      <description>arXiv:2508.09546v1 Announce Type: cross 
Abstract: Distributed MIMO and integrated sensing and communication are expected to be key technologies in future wireless systems, enabling reliable, low-latency communication and accurate localization. Dedicated localization solutions must support distributed architecture, provide scalability across different system configurations and meet strict latency requirements. We present a scalable message-passing localization method and architecture co-designed for a panel-based distributed MIMO system and network topology, in which interconnected units operate without centralized processing. This method jointly detects line-of-sight paths to distributed units from multipath measurements in dynamic scenarios, localizes the agent, and achieves very low latency. Additionally, we introduce a cycle-accurate system latency model based on implemented FPGA operations, and show important insights into processing latency and hardware utilization and system-level trade-offs. We compare our method to a multipath-based localization method and show that it can achieve similar localization performance, with wide enough distribution of array elements, while offering lower latency and computational complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.09546v1</guid>
      <category>eess.SP</category>
      <category>cs.AR</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Dumitra Iancu, Liang Liu, Ove Edfors, Erik Leitinger, Xuhong Li</dc:creator>
    </item>
    <item>
      <title>ControlPULPlet: A Flexible Real-time Multi-core RISC-V Controller for 2.5D Systems-in-package</title>
      <link>https://arxiv.org/abs/2410.15985</link>
      <description>arXiv:2410.15985v2 Announce Type: replace 
Abstract: The growing complexity of real-time control algorithms with increasing performance demands, along with the shift to 2.5D technology, drive the need for scalable controllers to manage chiplets' coupled operation in 2.5D systems-in-package. These controllers must offer real-time computing capabilities, as well as System-in-package (SiP) compatible IO interfaces for communicating with the controlled dies. Due to real-time constraints, a key challenge is minimizing the performance penalty of die-to-die communication with respect to native on-chip control interfaces. We address this challenge with ControlPULPlet, an open-source, real-time multi-core RISC-V controller designed specifically for SiP integration. ControlPULPlet features a 32-bit CV32RT core for fast interrupt handling and a specialized direct memory access engine to automate periodic sensor readout. A tightly-coupled programmable multi-core cluster for acceleration of advanced control algorithms is integrated through a dedicated AXI4 port. A flexible AXI4-compatible die-to-die (D2D) link enables efficient communication in 2.5D SiPs. We implemented and fabricated ControlPULPlet as a silicon demonstrator called Kairos in TSMC's 65nm CMOS. Kairos runs model predictive control algorithms at up to 290 MHz in a 30 mW power envelope. The D2D link attains a peak duplex transfer rate of 51 Gbit/s at 200 MHz, at the minimal costs of just 7.6 kGE in PHY area per channel, adding just 2.9% to the total system area.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15985v2</guid>
      <category>cs.AR</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alessandro Ottaviano, Robert Balas, Tim Fischer, Thomas Benz, Andrea Bartolini, Luca Benini</dc:creator>
    </item>
    <item>
      <title>Reimagining Voltage-Controlled Cryogenic Boolean Logic Paradigm with Quantum-Enhanced Josephson Junction FETs</title>
      <link>https://arxiv.org/abs/2508.00295</link>
      <description>arXiv:2508.00295v2 Announce Type: replace-cross 
Abstract: The growing demand for ultra low power computing and the emergence of quantum technologies have intensified interest in cryogenic electronics, particularly superconducting devices.Despite their promise, current controlled superconducting components face fundamental challenges in cascadability, limiting their effectiveness in complex logic architectures.To overcome this, recent efforts have focused on developing gate tunable superconducting devices, such as Josephson junction field effect transistors (JJFETs).However, achieving robust control and sufficient supercurrent gain, both critical for transistor-like performance in logic circuits remains a key challenge.A recent advancement in JJFET design, based on InAs and GaSb heterostructures, demonstrates enhanced gain and favorable device characteristics suitable for circuit integration.Building on this innovation, we propose and analyze fundamental voltage controlled logic topologies using the quantum enhanced JJFET. We develop a Verilog A based circuit compatible compact model of the quantum enhanced JJFET which accurately captures the experimentally observed device characteristics.To ensure cascadability, our logic circuits incorporate the multilayered Heater Nanocryotron (nTron), a superconducting nanowire-based thermal switch.Through simulation based analysis, we demonstrate the successful implementation of fundamental logic gates, including NOT, NAND, and NOR. Furthermore, we design a 3 input majority gate, which plays a pivotal role in quantum and reversible computing due to its universality.Finally, to demonstrate the cascadability of our proposed logic topology, we demonstrate the operation of a 2 input XOR gate based on our designed JJFET based NOT, NAND, and NOR gate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00295v2</guid>
      <category>cs.ET</category>
      <category>cs.AR</category>
      <category>physics.app-ph</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Md Mazharul Islam, Diego Ferrer, Shamiul Alam, Juan P. Mendez, Denis Mamaluy, Wei Pan, Ahmedullah Aziz</dc:creator>
    </item>
  </channel>
</rss>
