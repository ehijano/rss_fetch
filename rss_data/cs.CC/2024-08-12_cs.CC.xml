<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CC</link>
    <description>cs.CC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 13 Aug 2024 04:00:01 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 13 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>The complexity of strong conflict-free vertex-connection $k$-colorability</title>
      <link>https://arxiv.org/abs/2408.05865</link>
      <description>arXiv:2408.05865v1 Announce Type: new 
Abstract: We study a new variant of graph coloring by adding a connectivity constraint. A path in a vertex-colored graph is called conflict-free if there is a color that appears exactly once on its vertices. A connected graph $G$ is said to be strongly conflict-free vertex-connection $k$-colorable if $G$ admits a vertex $k$-coloring such that any two distinct vertices of $G$ are connected by a conflict-free $shortest$ path.
  Among others, we show that deciding whether a given graph is strongly conflict-free vertex-connection $3$-colorable is NP-complete even when restricted to $3$-colorable graphs with diameter $3$, radius $2$ and domination number $3$, and, assuming the Exponential Time Hypothesis (ETH), cannot be solved in $2^{o(n)}$ time on such restricted input graphs with $n$ vertices. This hardness result is quite strong when compared to the ordinary $3$-COLORING problem: it is known that $3$-COLORING is solvable in polynomial time in graphs with bounded domination number, and assuming ETH, cannot be solved in $2^{o(\sqrt{n})}$ time in $n$-vertex graphs with diameter $3$ and radius $2$. On the positive side, we point out that a strong conflict-free vertex-connection coloring with minimum color number of a given split graph or a co-bipartite graph can be computed in polynomial time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05865v1</guid>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sun-Yuan Hsieh, Hoang-Oanh Le, Van Bang Le, Sheng-Lung Peng</dc:creator>
    </item>
    <item>
      <title>Gromov's Approximating Tree and the All-Pairs Bottleneck Paths Problem</title>
      <link>https://arxiv.org/abs/2408.05338</link>
      <description>arXiv:2408.05338v1 Announce Type: cross 
Abstract: Given a pointed metric space $(X,\mathsf{dist}, w)$ on $n$ points, its Gromov's approximating tree is a 0-hyperbolic pseudo-metric space $(X,\mathsf{dist}_T)$ such that $\mathsf{dist}(x,w)=\mathsf{dist}_T(x,w)$ and $\mathsf{dist}(x, y)-2 \delta \log_2n \leq \mathsf{dist}_T (x, y) \leq \mathsf{dist}(x, y)$ for all $x, y \in X$ where $\delta$ is the Gromov hyperbolicity of $X$. On the other hand, the all pairs bottleneck paths (APBP) problem asks, given an undirected graph with some capacities on its edges, to find the maximal path capacity between each pair of vertices. In this note, we prove:
  $\bullet$ Computing Gromov's approximating tree for a metric space with $n+1$ points from its matrix of distances reduces to solving the APBP problem on an connected graph with $n$ vertices.
  $\bullet$ There is an explicit algorithm that computes Gromov's approximating tree for a graph from its adjacency matrix in quadratic time.
  $\bullet$ Solving the APBP problem on a weighted graph with $n$ vertices reduces to finding Gromov's approximating tree for a metric space with $n+1$ points from its distance matrix.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05338v1</guid>
      <category>cs.CG</category>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>math.CO</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anders Cornect, Eduardo Mart\'inez-Pedroza</dc:creator>
    </item>
    <item>
      <title>Quantum Annealing-Based Algorithm for Efficient Coalition Formation Among LEO Satellites</title>
      <link>https://arxiv.org/abs/2408.06007</link>
      <description>arXiv:2408.06007v1 Announce Type: cross 
Abstract: The increasing number of Low Earth Orbit (LEO) satellites, driven by lower manufacturing and launch costs, is proving invaluable for Earth observation missions and low-latency internet connectivity. However, as the number of satellites increases, the number of communication links to maintain also rises, making the management of this vast network increasingly challenging and highlighting the need for clustering satellites into efficient groups as a promising solution. This paper formulates the clustering of LEO satellites as a coalition structure generation (CSG) problem and leverages quantum annealing to solve it. We represent the satellite network as a graph and obtain the optimal partitions using a hybrid quantum-classical algorithm called GCS-Q. The algorithm follows a top-down approach by iteratively splitting the graph at each step using a quadratic unconstrained binary optimization (QUBO) formulation. To evaluate our approach, we utilize real-world three-line element set (TLE/3LE) data for Starlink satellites from Celestrak. Our experiments, conducted using the D-Wave Advantage annealer and the state-of-the-art solver Gurobi, demonstrate that the quantum annealer significantly outperforms classical methods in terms of runtime while maintaining the solution quality. The performance achieved with quantum annealers surpasses the capabilities of classical computers, highlighting the transformative potential of quantum computing in optimizing the management of large-scale satellite networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06007v1</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>cs.MA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Supreeth Mysore Venkatesh, Antonio Macaluso, Marlon Nuske, Matthias Klusch, Andreas Dengel</dc:creator>
    </item>
    <item>
      <title>Computability of Classification and Deep Learning: From Theoretical Limits to Practical Feasibility through Quantization</title>
      <link>https://arxiv.org/abs/2408.06212</link>
      <description>arXiv:2408.06212v1 Announce Type: cross 
Abstract: The unwavering success of deep learning in the past decade led to the increasing prevalence of deep learning methods in various application fields. However, the downsides of deep learning, most prominently its lack of trustworthiness, may not be compatible with safety-critical or high-responsibility applications requiring stricter performance guarantees. Recently, several instances of deep learning applications have been shown to be subject to theoretical limitations of computability, undermining the feasibility of performance guarantees when employed on real-world computers. We extend the findings by studying computability in the deep learning framework from two perspectives: From an application viewpoint in the context of classification problems and a general limitation viewpoint in the context of training neural networks. In particular, we show restrictions on the algorithmic solvability of classification problems that also render the algorithmic detection of failure in computations in a general setting infeasible. Subsequently, we prove algorithmic limitations in training deep neural networks even in cases where the underlying problem is well-behaved. Finally, we end with a positive observation, showing that in quantized versions of classification and deep network training, computability restrictions do not arise or can be overcome to a certain degree.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06212v1</guid>
      <category>cs.LG</category>
      <category>cs.CC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Holger Boche, Vit Fojtik, Adalbert Fono, Gitta Kutyniok</dc:creator>
    </item>
    <item>
      <title>Tolerant testing stabilizer states</title>
      <link>https://arxiv.org/abs/2408.06289</link>
      <description>arXiv:2408.06289v1 Announce Type: cross 
Abstract: We consider the following task: suppose an algorithm is given copies of an unknown $n$-qubit quantum state $|\psi\rangle$ promised $(i)$ $|\psi\rangle$ is $\varepsilon_1$-close to a stabilizer state in fidelity or $(ii)$ $|\psi\rangle$ is $\varepsilon_2$-far from all stabilizer states, decide which is the case. We give a $\textsf{poly}(1/\varepsilon_1)$-sample and $n\cdot \textsf{poly}(1/\varepsilon_1)$-time algorithm for this task for every $\varepsilon_1&gt;0$ and $\varepsilon_2\leq 2^{-\textsf{poly}(1/\varepsilon_1)}$. Our proof includes a new definition of Gowers norm for quantum states, an inverse theorem for the Gowers-$3$ norm of states and new bounds on stabilizer covering for structured subsets of Paulis using results in additive combinatorics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06289v1</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Srinivasan Arunachalam, Arkopal Dutt</dc:creator>
    </item>
    <item>
      <title>On bounded depth proofs for Tseitin formulas on the grid; revisited</title>
      <link>https://arxiv.org/abs/2209.05839</link>
      <description>arXiv:2209.05839v2 Announce Type: replace 
Abstract: We study Frege proofs using depth-$d$ Boolean formulas for the Tseitin contradiction on $n \times n$ grids. We prove that if each line in the proof is of size $M$ then the number of lines is exponential in $n/(\log M)^{O(d)}$. This strengthens a recent result of Pitassi et al. [PRT22]. The key technical step is a multi-switching lemma extending the switching lemma of H\r{a}stad [H\r{a}s20] for a space of restrictions related to the Tseitin contradiction. The strengthened lemma also allows us to improve the lower bound for standard proof size of bounded depth Frege refutations from exponential in $\tilde \Omega (n^{1/59d})$ to exponential in $\tilde \Omega (n^{1/d})$. This strengthens the bounds given in the preliminary version of this paper [HR22].</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.05839v2</guid>
      <category>cs.CC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Johan H\r{a}stad, Kilian Risse</dc:creator>
    </item>
    <item>
      <title>A Graphical #SAT Algorithm for Formulae with Small Clause Density</title>
      <link>https://arxiv.org/abs/2212.08048</link>
      <description>arXiv:2212.08048v2 Announce Type: replace 
Abstract: We study the counting version of the Boolean satisfiability problem #SAT using the ZH-calculus, a graphical language originally introduced to reason about quantum circuits. Using this, we generalize #SAT to a weighted variant we call #SAT+-, which is complete for the class GapP. We show there is an efficient linear-time reduction from #SAT to #2SAT+-, unlike previous reductions from #SAT to #2SAT which blow up the size of the formula by a polynomial factor. Our main conceptual contribution is that introducing weights to #SAT allows for more efficient translations, and we use this to remove the dependence on clause width k in this case. We observe that DPLL-style algorithms for #2SAT can be adapted to #2SAT+- directly and hence the best-known upper bounds for #2SAT apply. Applying an upper bound for #2SAT in terms of variables gives us upper bounds for #SAT in terms of clauses and variables that are better than O*(2^n) for small clause densities of m/n &lt; 2.25, and improve on previous average-case and worst-case bounds for k &gt;= 6 and k &gt;= 4, respectively. Applying a similar bound in terms of clauses produces a bound of O*(1.1740^L) in terms of the length of the formula. These are, to our knowledge, the first non-trivial upper bounds for #SAT that is independent of clause size, and in terms of formula length, respectively. Based on a result of Kutzkov, we find an improved bound on #3SAT for 1.2577 &lt; m/n &lt;= 7/3. Finally, we use this technique to find an upper bound on the complexity of calculating amplitudes of quantum circuits in terms of the total number of gates. Our results demonstrate that graphical reasoning can lead to new algorithmic insights, even outside the domain of quantum computing that the calculus was intended for.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.08048v2</guid>
      <category>cs.CC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.406.7</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 406, 2024, pp. 137-161</arxiv:journal_reference>
      <dc:creator>Tuomas Laakkonen (Quantinuum), Konstantinos Meichanetzidis (Quantinuum), John van de Wetering (University of Amsterdam)</dc:creator>
    </item>
    <item>
      <title>On the complexity of isomorphism problems for tensors, groups, and polynomials III: actions by classical groups</title>
      <link>https://arxiv.org/abs/2306.03135</link>
      <description>arXiv:2306.03135v2 Announce Type: replace 
Abstract: We study the complexity of isomorphism problems for d-way arrays, or tensors, under natural actions by classical groups such as orthogonal, unitary, and symplectic groups. Such problems arise naturally in statistical data analysis and quantum information. We study two types of complexity-theoretic questions. First, for a fixed action type (isomorphism, conjugacy, etc.), we relate the complexity of the isomorphism problem over a classical group to that over the general linear group. Second, for a fixed group type (orthogonal, unitary, or symplectic), we compare the complexity of the decision problems for different actions.
  Our main results are as follows. First, for orthogonal and symplectic groups acting on 3-way arrays, the isomorphism problems reduce to the corresponding problem over the general linear group. Second, for orthogonal and unitary groups, the isomorphism problems of five natural actions on 3-way arrays are polynomial-time equivalent, and the d-tensor isomorphism problem reduces to the 3-tensor isomorphism problem for any fixed d&gt;3. For unitary groups, the preceding result implies that LOCC classification of tripartite quantum states is at least as difficult as LOCC classification of d-partite quantum states for any d. Lastly, we also show that the graph isomorphism problem reduces to the tensor isomorphism problem over orthogonal and unitary groups.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.03135v2</guid>
      <category>cs.CC</category>
      <category>math.AG</category>
      <category>math.RT</category>
      <category>quant-ph</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhili Chen, Joshua A. Grochow, Youming Qiao, Gang Tang, Chuanqi Zhang</dc:creator>
    </item>
    <item>
      <title>On Pigeonhole Principles and Ramsey in TFNP</title>
      <link>https://arxiv.org/abs/2401.12604</link>
      <description>arXiv:2401.12604v2 Announce Type: replace 
Abstract: We show that the TFNP problem RAMSEY is not black-box reducible to PIGEON, refuting a conjecture of Goldberg and Papadimitriou in the black-box setting. We prove this by giving reductions to RAMSEY from a new family of TFNP problems that correspond to generalized versions of the pigeonhole principle, and then proving that these generalized versions cannot be reduced to PIGEON. Formally, we define t-PPP as the class of total NP-search problems reducible to finding a t-collision in a mapping from (t-1)N+1 pigeons to N holes. These classes are closely related to multi-collision resistant hash functions in cryptography. We show that the generalized pigeonhole classes form a hierarchy as t increases, and also give a natural condition on the parameters t1, t2 that captures exactly when t1-PPP and t2-PPP collapse in the black-box setting. Finally, we prove other inclusion and separation results between these generalized PIGEON problems and other previously studied TFNP subclasses, such as PLS, PPA and PLC. Our separation results rely on new lower bounds in propositional proof complexity based on pseudoexpectation operators, which may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.12604v2</guid>
      <category>cs.CC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Siddhartha Jain, Jiawei Li, Robert Robere, Zhiyang Xun</dc:creator>
    </item>
    <item>
      <title>The computational power of discrete chemical reaction networks with bounded executions</title>
      <link>https://arxiv.org/abs/2405.08649</link>
      <description>arXiv:2405.08649v3 Announce Type: replace 
Abstract: Chemical reaction networks (CRNs) model systems where molecules interact according to a finite set of reactions such as $A + B \to C$, representing that if a molecule of $A$ and $B$ collide, they disappear and a molecule of $C$ is produced. CRNs can compute Boolean-valued predicates $\phi:\mathbb{N}^d \to \{0,1\}$ and integer-valued functions $f:\mathbb{N}^d \to \mathbb{N}$; for instance $X_1 + X_2 \to Y$ computes the function $\min(x_1,x_2)$.
  We study the computational power of execution bounded CRNs, in which only a finite number of reactions can occur from the initial configuration (e.g., ruling out reversible reactions such as $A \rightleftharpoons B$). The power and composability of such CRNs depend crucially on some other modeling choices that do not affect the computational power of CRNs with unbounded executions, namely whether an initial leader is present, and whether (for predicates) all species are required to "vote" for the Boolean output. If the CRN starts with an initial leader, and can allow only the leader to vote, then all semilinear predicates and functions can be stably computed in $O(n \log n)$ parallel time by execution bounded CRNs.
  However, if no initial leader is allowed, all species vote, and the CRN is "noncollapsing" (does not shrink from initially large to final $O(1)$ size configurations), then execution bounded CRNs are severely limited, able to compute only eventually constant predicates. A key tool is to characterize execution bounded CRNs as precisely those with a nonnegative linear potential function that is strictly decreased by every reaction, a result that may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.08649v3</guid>
      <category>cs.CC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David Doty, Ben Heckmann</dc:creator>
    </item>
    <item>
      <title>On the NP-Hardness Approximation Curve for Max-2Lin(2)</title>
      <link>https://arxiv.org/abs/2408.04832</link>
      <description>arXiv:2408.04832v2 Announce Type: replace 
Abstract: In the Max-2Lin(2) problem you are given a system of equations on the form $x_i + x_j \equiv b \pmod{2}$, and your objective is to find an assignment that satisfies as many equations as possible. Let $c \in [0.5, 1]$ denote the maximum fraction of satisfiable equations. In this paper we construct a curve $s (c)$ such that it is NP-hard to find a solution satisfying at least a fraction $s$ of equations. This curve either matches or improves all of the previously known inapproximability NP-hardness results for Max-2Lin(2). In particular, we show that if $c \geqslant 0.9232$ then $\frac{1 - s (c)}{1 - c} &gt; 1.48969$, which improves the NP-hardness inapproximability constant for the min deletion version of Max-2Lin(2). Our work complements the work of O'Donnell and Wu that studied the same question assuming the Unique Games Conjecture.
  Similar to earlier inapproximability results for Max-2Lin(2), we use a gadget reduction from the $(2^k - 1)$-ary Hadamard predicate. Previous works used $k$ ranging from $2$ to $4$. Our main result is a procedure for taking a gadget for some fixed $k$, and use it as a building block to construct better and better gadgets as $k$ tends to infinity. Our method can be used to boost the result of both smaller gadgets created by hand $(k = 3)$ or larger gadgets constructed using a computer $(k = 4)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04832v2</guid>
      <category>cs.CC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bj\"orn Martinsson</dc:creator>
    </item>
    <item>
      <title>Optimising quantum circuits is generally hard</title>
      <link>https://arxiv.org/abs/2310.05958</link>
      <description>arXiv:2310.05958v3 Announce Type: replace-cross 
Abstract: In order for quantum computations to be done as efficiently as possible it is important to optimise the number of gates used in the underlying quantum circuits. In this paper we find that many gate optimisation problems for approximately universal quantum circuits are NP-hard. In particular, we show that optimising the T-count or T-depth in Clifford+T circuits, which are important metrics for the computational cost of executing fault-tolerant quantum computations, is NP-hard by reducing the problem to Boolean satisfiability. With a similar argument we show that optimising the number of CNOT gates or Hadamard gates in a Clifford+T circuit is also NP-hard. Again varying the same argument we also establish the hardness of optimising the number of Toffoli gates in a reversible classical circuit. We find an upper bound to the problems of T-count and Toffoli-count of $\text{NP}^{\text{NQP}}$. Finally, we also show that for any non-Clifford gate $G$ it is NP-hard to optimise the $G$-count over the Clifford+$G$ gate set, where we only have to match the target unitary within some small distance in the operator norm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.05958v3</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>John van de Wetering, Matt Amy</dc:creator>
    </item>
    <item>
      <title>Computing Balanced Solutions for Large International Kidney Exchange Schemes When Cycle Length Is Unbounded</title>
      <link>https://arxiv.org/abs/2312.16653</link>
      <description>arXiv:2312.16653v2 Announce Type: replace-cross 
Abstract: In kidney exchange programmes (KEP) patients may swap their incompatible donors leading to cycles of kidney transplants. Nowadays, countries try to merge their national patient-donor pools leading to international KEPs (IKEPs). As shown in the literature, long-term stability of an IKEP can be achieved through a credit-based system. In each round, every country is prescribed a "fair" initial allocation of kidney transplants. The initial allocation, which we obtain by using solution concepts from cooperative game theory, is adjusted by incorporating credits from the previous round, yielding the target allocation. The goal is to find, in each round, an optimal solution that closely approximates this target allocation. There is a known polynomial-time algorithm for finding an optimal solution that lexicographically minimizes the country deviations from the target allocation if only $2$-cycles (matchings) are permitted. In practice, kidney swaps along longer cycles may be performed. However, the problem of computing optimal solutions for maximum cycle length $\ell$ is NP-hard for every $\ell\geq 3$. This situation changes back to polynomial time once we allow unbounded cycle length. However, in contrast to the case where $\ell=2$, we show that for $\ell=\infty$, lexicographical minimization is only polynomial-time solvable under additional conditions (assuming P $\neq$ NP). Nevertheless, the fact that the optimal solutions themselves can be computed in polynomial time if $\ell=\infty$ still enables us to perform a large scale experimental study for showing how stability and total social welfare are affected when we set $\ell=\infty$ instead of $\ell=2$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.16653v2</guid>
      <category>cs.GT</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>M\'arton Benedek, P\'eter Bir\'o, Gergely Cs\'aji, Matthew Johnson, Dani\"el Paulusma, Xin Ye</dc:creator>
    </item>
  </channel>
</rss>
