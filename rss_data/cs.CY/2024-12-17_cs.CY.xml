<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CY updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CY</link>
    <description>cs.CY updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CY" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 17 Dec 2024 05:00:15 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Impact of Shoe Parameters on Gait Using Wearables</title>
      <link>https://arxiv.org/abs/2412.10555</link>
      <description>arXiv:2412.10555v1 Announce Type: new 
Abstract: The study of biomechanics during locomotion provides valuable insights into the effects of varying conditions on specific movement patterns. This research focuses on examining the influence of different shoe parameters on walking biomechanics, aiming to understand their impact on gait patterns. To achieve this, various methodologies are explored to estimate human body biomechanics, including computer vision techniques and wearable devices equipped with advanced sensors. Given privacy considerations and the need for robust, accurate measurements, this study employs wearable devices with Inertial Measurement Unit (IMU) sensors. These devices offer a non-invasive, precise, and high-resolution approach to capturing biomechanical data during locomotion. Raw sensor data collected from wearable devices is processed using an Extended Kalman Filter to reduce noise and extract meaningful information. This includes calculating joint angles throughout the gait cycle, enabling a detailed analysis of movement dynamics. The analysis identifies correlations between shoe parameters and key gait characteristics, such as stability, mobility, step time, and propulsion forces. The findings provide deeper insights into how footwear design influences walking efficiency and biomechanics. This study paves the way for advancements in footwear technology and contributes to the development of personalized solutions for enhancing gait performance and mobility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.10555v1</guid>
      <category>cs.CY</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Nadeera Meghapathirana, Oshada Rathnayake, Thisali S Rathnayake, Roshan Godaliyadda, Parakrama Ekanayake, Vijitha Herath</dc:creator>
    </item>
    <item>
      <title>Human-Centric NLP or AI-Centric Illusion?: A Critical Investigation</title>
      <link>https://arxiv.org/abs/2412.10939</link>
      <description>arXiv:2412.10939v1 Announce Type: new 
Abstract: Human-Centric NLP often claims to prioritise human needs and values, yet many implementations reveal an underlying AI-centric focus. Through an analysis of case studies in language modelling, behavioural testing, and multi-modal alignment, this study identifies a significant gap between the ideas of human-centricity and actual practices. Key issues include misalignment with human-centred design principles, the reduction of human factors to mere benchmarks, and insufficient consideration of real-world impacts. The discussion explores whether Human-Centric NLP embodies true human-centred design, emphasising the need for interdisciplinary collaboration and ethical considerations. The paper advocates for a redefinition of Human-Centric NLP, urging a broader focus on real-world utility and societal implications to ensure that language technologies genuinely serve and empower users.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.10939v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.HC</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Piyapath T Spencer</dc:creator>
    </item>
    <item>
      <title>Hybrid Forecasting of Geopolitical Events</title>
      <link>https://arxiv.org/abs/2412.10981</link>
      <description>arXiv:2412.10981v1 Announce Type: new 
Abstract: Sound decision-making relies on accurate prediction for tangible outcomes ranging from military conflict to disease outbreaks. To improve crowdsourced forecasting accuracy, we developed SAGE, a hybrid forecasting system that combines human and machine generated forecasts. The system provides a platform where users can interact with machine models and thus anchor their judgments on an objective benchmark. The system also aggregates human and machine forecasts weighting both for propinquity and based on assessed skill while adjusting for overconfidence. We present results from the Hybrid Forecasting Competition (HFC) - larger than comparable forecasting tournaments - including 1085 users forecasting 398 real-world forecasting problems over eight months. Our main result is that the hybrid system generated more accurate forecasts compared to a human-only baseline which had no machine generated predictions. We found that skilled forecasters who had access to machine-generated forecasts outperformed those who only viewed historical data. We also demonstrated the inclusion of machine-generated forecasts in our aggregation algorithms improved performance, both in terms of accuracy and scalability. This suggests that hybrid forecasting systems, which potentially require fewer human resources, can be a viable approach for maintaining a competitive level of accuracy over a larger number of forecasting questions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.10981v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1002/aaai.12085</arxiv:DOI>
      <arxiv:journal_reference>AI Magazine, Volume 44, Issue 1, Pages 112-128, Spring 2023</arxiv:journal_reference>
      <dc:creator>Daniel M. Benjamin, Fred Morstatter, Ali E. Abbas, Andres Abeliuk, Pavel Atanasov, Stephen Bennett, Andreas Beger, Saurabh Birari, David V. Budescu, Michele Catasta, Emilio Ferrara, Lucas Haravitch, Mark Himmelstein, KSM Tozammel Hossain, Yuzhong Huang, Woojeong Jin, Regina Joseph, Jure Leskovec, Akira Matsui, Mehrnoosh Mirtaheri, Xiang Ren, Gleb Satyukov, Rajiv Sethi, Amandeep Singh, Rok Sosic, Mark Steyvers, Pedro A Szekely, Michael D. Ward, Aram Galstyan</dc:creator>
    </item>
    <item>
      <title>Managing Project Teams in an Online Class of 1000+ Students</title>
      <link>https://arxiv.org/abs/2412.11046</link>
      <description>arXiv:2412.11046v1 Announce Type: new 
Abstract: Team projects in Computer Science (CS) help students build collaboration skills, apply theory, and prepare for real-world software development. Online classes present unique opportunities to transform the accessibility of CS education at scale. Still, the geographical distribution of students and staff adds complexity to forming effective teams, providing consistent feedback, and facilitating peer interactions. We discuss our approach of managing, evaluating, and providing constructive feedback to over 200 project teams, comprising 1000+ graduate students distributed globally, two professors, and 25+ teaching assistants. We deployed and iteratively refined this approach over 10 years while offering the Data and Visual Analytics course (CSE 6242) at Georgia Institute of Technology. Our approach and insights can help others striving to make CS education accessible, especially in online and large-scale settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.11046v1</guid>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nazanin Tabatabaei Anaraki, Taneisha Ng, Gaurav Verma, Yu Fu, Martin O'Connell, Matthew Hull, Susanta Routray, Max Mahdi Roozbahani, Duen Horng Chau</dc:creator>
    </item>
    <item>
      <title>Generative AI regulation can learn from social media regulation</title>
      <link>https://arxiv.org/abs/2412.11335</link>
      <description>arXiv:2412.11335v1 Announce Type: new 
Abstract: There is strong agreement that generative AI should be regulated, but strong disagreement on how to approach regulation. While some argue that AI regulation should mostly rely on extensions of existing laws, others argue that entirely new laws and regulations are needed to ensure that generative AI benefits society. In this paper, I argue that the debates on generative AI regulation can be informed by the debates and evidence on social media regulation. For example, AI companies have faced allegations of political bias regarding the images and text their models produce, similar to the allegations social media companies have faced regarding content ranking on their platforms. First, I compare and contrast the affordances of generative AI and social media to highlight their similarities and differences. Then, I discuss specific policy recommendations based on the evolution of social media and their regulation. These recommendations include investments in: efforts to counter bias and perceptions thereof (e.g., via transparency, researcher access, oversight boards, democratic input, research studies), specific areas of regulatory concern (e.g., youth wellbeing, election integrity) and trust and safety, computational social science research, and a more global perspective. Applying lessons learnt from social media regulation to generative AI regulation can save effort and time, and prevent avoidable mistakes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.11335v1</guid>
      <category>cs.CY</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruth Elisabeth Appel</dc:creator>
    </item>
    <item>
      <title>From Automation to Cognition: Redefining the Roles of Educators and Generative AI in Computing Education</title>
      <link>https://arxiv.org/abs/2412.11419</link>
      <description>arXiv:2412.11419v1 Announce Type: new 
Abstract: Generative Artificial Intelligence (GenAI) offers numerous opportunities to revolutionise teaching and learning in Computing Education (CE). However, educators have expressed concerns that students may over-rely on GenAI and use these tools to generate solutions without engaging in the learning process. While substantial research has explored GenAI use in CE, and many Computer Science (CS) educators have expressed their opinions and suggestions on the subject, there remains little consensus on implementing curricula and assessment changes. In this paper, we describe our experiences with using GenAI in CS-focused educational settings and the changes we have implemented accordingly in our teaching in recent years since the popularisation of GenAI. From our experiences, we propose two primary actions for the CE community: 1) redesign take-home assignments to incorporate GenAI use and assess students on their process of using GenAI to solve a task rather than simply on the final product; 2) redefine the role of educators to emphasise metacognitive aspects of learning, such as critical thinking and self-evaluation. This paper presents and discusses these stances and outlines several practical methods to implement these strategies in CS classrooms. Then, we advocate for more research addressing the concrete impacts of GenAI on CE, especially those evaluating the validity and effectiveness of new teaching practices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.11419v1</guid>
      <category>cs.CY</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tony Haoran Feng, Andrew Luxton-Reilly, Burkhard C. W\"unsche, Paul Denny</dc:creator>
    </item>
    <item>
      <title>"They've Stolen My GPL-Licensed Model!": Toward Standardized and Transparent Model Licensing</title>
      <link>https://arxiv.org/abs/2412.11483</link>
      <description>arXiv:2412.11483v1 Announce Type: new 
Abstract: As model parameter sizes reach the billion-level range and their training consumes zettaFLOPs of computation, components reuse and collaborative development are become increasingly prevalent in the Machine Learning (ML) community. These components, including models, software, and datasets, may originate from various sources and be published under different licenses, which govern the use and distribution of licensed works and their derivatives. However, commonly chosen licenses, such as GPL and Apache, are software-specific and are not clearly defined or bounded in the context of model publishing. Meanwhile, the reused components may also have free-content licenses and model licenses, which pose a potential risk of license noncompliance and rights infringement within the model production workflow. In this paper, we propose addressing the above challenges along two lines: 1) For license analysis, we have developed a new vocabulary for ML workflow management and encoded license rules to enable ontological reasoning for analyzing rights granting and compliance issues. 2) For standardized model publishing, we have drafted a set of model licenses that provide flexible options to meet the diverse needs of model publishing. Our analysis tool is built on Turtle language and Notation3 reasoning engine, envisioned as a first step toward Linked Open Model Production Data. We have also encoded our proposed model licenses into rules and demonstrated the effects of GPL and other commonly used licenses in model publishing, along with the flexibility advantages of our licenses, through comparisons and experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.11483v1</guid>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Moming Duan, Rui Zhao, Linshan Jiang, Nigel Shadbolt, Bingsheng He</dc:creator>
    </item>
    <item>
      <title>Uncovering Student Engagement Patterns in Moodle with Interpretable Machine Learning</title>
      <link>https://arxiv.org/abs/2412.11826</link>
      <description>arXiv:2412.11826v1 Announce Type: new 
Abstract: Understanding and enhancing student engagement through digital platforms is critical in higher education. This study introduces a methodology for quantifying engagement across an entire module using virtual learning environment (VLE) activity log data. Using study session frequency, immediacy, and diversity, we create a cumulative engagement metric and model it against weekly VLE interactions with resources to identify critical periods and resources predictive of student engagement.
  In a case study of a computing module at University College London's Department of Statistical Science, we further examine how delivery methods (online, hybrid, in-person) impact student behaviour. Across nine regression models, we validate the consistency of the random forest model and highlight the interpretive strengths of generalised additive models for analysing engagement patterns.
  Results show weekly VLE clicks as reliable engagement predictors, with early weeks and the first assessment period being key. However, the impact of delivery methods on engagement is inconclusive due to inconsistencies across models. These findings support early intervention strategies to assist students at risk of disengagement. This work contributes to learning analytics research by proposing a refined VLE-based engagement metric and advancing data-driven teaching strategies in higher education.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.11826v1</guid>
      <category>cs.CY</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Laura J. Johnston, Jim E. Griffin, Ioanna Manolopoulou, Takoua Jendoubi</dc:creator>
    </item>
    <item>
      <title>What Can Youth Learn About in One Hour? Examining How Hour of Code Activities Address the Five Big Ideas of Artificial Intelligence</title>
      <link>https://arxiv.org/abs/2412.11911</link>
      <description>arXiv:2412.11911v1 Announce Type: new 
Abstract: The prominence of artificial intelligence and machine learning in everyday life has led to efforts to foster AI literacy for all K-12 students. In this paper, we review how Hour of Code activities engage with the five big ideas of AI, in particular with machine learning and societal impact. We found that a large majority of activities focus on perception and machine learning, with little attention paid to representation and other topics. A surprising finding was the increased attention paid to critical aspects of computing. However, we also observed a limited engagement with hands-on activities. In the discussion, we address how future introductory activities could be designed to offer a broader array of topics, including the development of tools to introduce novices to artificial intelligence and machine learning and the design of more unplugged and collaborative activities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.11911v1</guid>
      <category>cs.CY</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Luis Morales-Navarro, Yasmin B. Kafai, Eric Yang, Asep Suryana</dc:creator>
    </item>
    <item>
      <title>User-Centered Course Reengineering: An Analytical Approach to Enhancing Reading Comprehension in Educational Content</title>
      <link>https://arxiv.org/abs/2412.11944</link>
      <description>arXiv:2412.11944v1 Announce Type: new 
Abstract: Delivering high-quality content is crucial for effective reading comprehension and successful learning. Ensuring educational materials are interpreted as intended by their authors is a persistent challenge, especially with the added complexity of multimedia and interactivity in the digital age. Authors must continuously revise their materials to meet learners' evolving needs. Detecting comprehension barriers and identifying actionable improvements within documents is complex, particularly in education where reading is fundamental. This study presents an analytical framework to help course designers enhance educational content to better support learning outcomes. Grounded in a robust theoretical foundation integrating learning analytics, reading comprehension, and content revision, our approach introduces usage-based document reengineering. This methodology adapts document content and structure based on insights from analyzing digital reading traces-interactions between readers and content. We define reading sessions to capture these interactions and develop indicators to detect comprehension challenges. Our framework enables authors to receive tailored content revision recommendations through an interactive dashboard, presenting actionable insights from reading activity. The proposed approach was implemented and evaluated using data from a European e-learning platform. Evaluations validate the framework's effectiveness, demonstrating its capacity to empower authors with data-driven insights for targeted revisions. The findings highlight the framework's ability to enhance educational content quality, making it more responsive to learners' needs. This research significantly contributes to learning analytics and content optimization, offering practical tools to improve educational outcomes and inform future developments in e-learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.11944v1</guid>
      <category>cs.CY</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Madjid Sadallah</dc:creator>
    </item>
    <item>
      <title>AI-assisted summary of suicide risk Formulation</title>
      <link>https://arxiv.org/abs/2412.10388</link>
      <description>arXiv:2412.10388v1 Announce Type: cross 
Abstract: Background: Formulation, associated with suicide risk assessment, is an individualised process that seeks to understand the idiosyncratic nature and development of an individual's problems. Auditing clinical documentation on an electronic health record (EHR) is challenging as it requires resource-intensive manual efforts to identify keywords in relevant sections of specific forms. Furthermore, clinicians and healthcare professionals often do not use keywords; their clinical language can vary greatly and may contain various jargon and acronyms. Also, the relevant information may be recorded elsewhere. This study describes how we developed advanced Natural Language Processing (NLP) algorithms, a branch of Artificial Intelligence (AI), to analyse EHR data automatically. Method: Advanced Optical Character Recognition techniques were used to process unstructured data sets, such as portable document format (pdf) files. Free text data was cleaned and pre-processed using Normalisation of Free Text techniques. We developed algorithms and tools to unify the free text. Finally, the formulation was checked for the presence of each concept based on similarity using NLP-powered semantic matching techniques. Results: We extracted information indicative of formulation and assessed it to cover the relevant concepts. This was achieved using a Weighted Score to obtain a Confidence Level. Conclusion: The rigour to which formulation is completed is crucial to effectively using EHRs, ensuring correct and timely identification, engagement and interventions that may potentially avoid many suicide attempts and suicides.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.10388v1</guid>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Rajib Rana, Niall Higgins, Kazi N. Haque, John Reilly, Kylie Burke, Kathryn Turner, Anthony R. Pisani, Terry Stedman</dc:creator>
    </item>
    <item>
      <title>Recommendation and Temptation</title>
      <link>https://arxiv.org/abs/2412.10595</link>
      <description>arXiv:2412.10595v1 Announce Type: cross 
Abstract: Traditional recommender systems based on utility maximization and revealed preferences often fail to capture users' dual-self nature, where consumption choices are driven by both long-term benefits (enrichment) and desire for instant gratification (temptation). Consequently, these systems may generate recommendations that fail to provide long-lasting satisfaction to users. To address this issue, we propose a novel user model that accounts for this dual-self behavior and develop an optimal recommendation strategy to maximize enrichment from consumption. We highlight the limitations of historical consumption data in implementing this strategy and present an estimation framework that makes minimal assumptions and leverages explicit user feedback and implicit choice data to overcome these constraints. We evaluate our approach through both synthetic simulations and simulations based on real-world data from the MovieLens dataset. Results demonstrate that our proposed recommender can deliver superior enrichment compared to several competitive baseline algorithms that assume a single utility type and rely solely on revealed preferences. Our work emphasizes the critical importance of optimizing for enrichment in recommender systems, particularly in temptation-laden consumption contexts. Our findings have significant implications for content platforms, user experience design, and the development of responsible AI systems, paving the way for more nuanced and user-centric recommendation approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.10595v1</guid>
      <category>cs.IR</category>
      <category>cs.CY</category>
      <category>cs.GT</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Md Sanzeed Anwar, Paramveer S. Dhillon, Grant Schoenebeck</dc:creator>
    </item>
    <item>
      <title>A Trust-Centric Approach To Quantifying Maturity and Security in Internet Voting Protocols</title>
      <link>https://arxiv.org/abs/2412.10611</link>
      <description>arXiv:2412.10611v1 Announce Type: cross 
Abstract: Voting is a cornerstone of collective participatory decision-making in contexts ranging from political elections to decentralized autonomous organizations (DAOs). Despite the proliferation of internet voting protocols promising enhanced accessibility and efficiency, their evaluation and comparison are complicated by a lack of standardized criteria and unified definitions of security and maturity. Furthermore, socio-technical requirements by decision makers are not structurally taken into consideration when comparing internet voting systems. This paper addresses this gap by introducing a trust-centric maturity scoring framework to quantify the security and maturity of sixteen internet voting systems. A comprehensive trust model analysis is conducted for selected internet voting protocols, examining their security properties, trust assumptions, technical complexity, and practical usability. In this paper we propose the electronic voting maturity framework (EVMF) which supports nuanced assessment that reflects real-world deployment concerns and aids decision-makers in selecting appropriate systems tailored to their specific use-case requirements. The framework is general enough to be applied to other systems, where the aspects of decentralization, trust, and security are crucial, such as digital identity, Ethereum layer-two scaling solutions, and federated data infrastructures. Its objective is to provide an extendable toolkit for policy makers and technology experts alike that normalizes technical and non-technical requirements on a univariate scale.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.10611v1</guid>
      <category>cs.CR</category>
      <category>cs.CY</category>
      <category>cs.DC</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Stanis{\l}aw Bara\'nski, Ben Biedermann, Joshua Ellul</dc:creator>
    </item>
    <item>
      <title>Diagnosing Unknown Attacks in Smart Homes Using Abductive Reasoning</title>
      <link>https://arxiv.org/abs/2412.10738</link>
      <description>arXiv:2412.10738v1 Announce Type: cross 
Abstract: Security attacks are rising, as evidenced by the number of reported vulnerabilities. Among them, unknown attacks, including new variants of existing attacks, technical blind spots or previously undiscovered attacks, challenge enduring security. This is due to the limited number of techniques that diagnose these attacks and enable the selection of adequate security controls. In this paper, we propose an automated technique that detects and diagnoses unknown attacks by identifying the class of attack and the violated security requirements, enabling the selection of adequate security controls. Our technique combines anomaly detection to detect unknown attacks with abductive reasoning to diagnose them. We first model the behaviour of the smart home and its requirements as a logic program in Answer Set Programming (ASP). We then apply Z-Score thresholding to the anomaly scores of an Isolation Forest trained using unlabeled data to simulate unknown attack scenarios. Finally, we encode the network anomaly in the logic program and perform abduction by refutation to identify the class of attack and the security requirements that this anomaly may violate. We demonstrate our technique using a smart home scenario, where we detect and diagnose anomalies in network traffic. We evaluate the precision, recall and F1-score of the anomaly detector and the diagnosis technique against 18 attacks from the ground truth labels provided by two datasets, CICIoT2023 and IoT-23. Our experiments show that the anomaly detector effectively identifies anomalies when the network traces are strong indicators of an attack. When provided with sufficient contextual data, the diagnosis logic effectively identifies true anomalies, and reduces the number of false positives reported by anomaly detectors. Finally, we discuss how our technique can support the selection of adequate security controls.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.10738v1</guid>
      <category>cs.CR</category>
      <category>cs.CY</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kushal Ramkumar, Wanling Cai, John McCarthy, Gavin Doherty, Bashar Nuseibeh, Liliana Pasquale</dc:creator>
    </item>
    <item>
      <title>Navigating Dialectal Bias and Ethical Complexities in Levantine Arabic Hate Speech Detection</title>
      <link>https://arxiv.org/abs/2412.10991</link>
      <description>arXiv:2412.10991v1 Announce Type: cross 
Abstract: Social media platforms have become central to global communication, yet they also facilitate the spread of hate speech. For underrepresented dialects like Levantine Arabic, detecting hate speech presents unique cultural, ethical, and linguistic challenges. This paper explores the complex sociopolitical and linguistic landscape of Levantine Arabic and critically examines the limitations of current datasets used in hate speech detection. We highlight the scarcity of publicly available, diverse datasets and analyze the consequences of dialectal bias within existing resources. By emphasizing the need for culturally and contextually informed natural language processing (NLP) tools, we advocate for a more nuanced and inclusive approach to hate speech detection in the Arab world.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.10991v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ahmed Haj Ahmed, Rui-Jie Yew, Xerxes Minocher, Suresh Venkatasubramanian</dc:creator>
    </item>
    <item>
      <title>Dual Traits in Probabilistic Reasoning of Large Language Models</title>
      <link>https://arxiv.org/abs/2412.11009</link>
      <description>arXiv:2412.11009v1 Announce Type: cross 
Abstract: We conducted three experiments to investigate how large language models (LLMs) evaluate posterior probabilities. Our results reveal the coexistence of two modes in posterior judgment among state-of-the-art models: a normative mode, which adheres to Bayes' rule, and a representative-based mode, which relies on similarity -- paralleling human System 1 and System 2 thinking. Additionally, we observed that LLMs struggle to recall base rate information from their memory, and developing prompt engineering strategies to mitigate representative-based judgment may be challenging. We further conjecture that the dual modes of judgment may be a result of the contrastive loss function employed in reinforcement learning from human feedback. Our findings underscore the potential direction for reducing cognitive biases in LLMs and the necessity for cautious deployment of LLMs in critical areas.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.11009v1</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shenxiong Li, Huaxia Rui</dc:creator>
    </item>
    <item>
      <title>Classification Drives Geographic Bias in Street Scene Segmentation</title>
      <link>https://arxiv.org/abs/2412.11061</link>
      <description>arXiv:2412.11061v1 Announce Type: cross 
Abstract: Previous studies showed that image datasets lacking geographic diversity can lead to biased performance in models trained on them. While earlier work studied general-purpose image datasets (e.g., ImageNet) and simple tasks like image recognition, we investigated geo-biases in real-world driving datasets on a more complex task: instance segmentation. We examined if instance segmentation models trained on European driving scenes (Eurocentric models) are geo-biased. Consistent with previous work, we found that Eurocentric models were geo-biased. Interestingly, we found that geo-biases came from classification errors rather than localization errors, with classification errors alone contributing 10-90% of the geo-biases in segmentation and 19-88% of the geo-biases in detection. This showed that while classification is geo-biased, localization (including detection and segmentation) is geographically robust. Our findings show that in region-specific models (e.g., Eurocentric models), geo-biases from classification errors can be significantly mitigated by using coarser classes (e.g., grouping car, bus, and truck as 4-wheeler).</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.11061v1</guid>
      <category>cs.CV</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rahul Nair, Gabriel Tseng, Esther Rolf, Bhanu Tokas, Hannah Kerner</dc:creator>
    </item>
    <item>
      <title>Navigating Towards Fairness with Data Selection</title>
      <link>https://arxiv.org/abs/2412.11072</link>
      <description>arXiv:2412.11072v1 Announce Type: cross 
Abstract: Machine learning algorithms often struggle to eliminate inherent data biases, particularly those arising from unreliable labels, which poses a significant challenge in ensuring fairness. Existing fairness techniques that address label bias typically involve modifying models and intervening in the training process, but these lack flexibility for large-scale datasets. To address this limitation, we introduce a data selection method designed to efficiently and flexibly mitigate label bias, tailored to more practical needs. Our approach utilizes a zero-shot predictor as a proxy model that simulates training on a clean holdout set. This strategy, supported by peer predictions, ensures the fairness of the proxy model and eliminates the need for an additional holdout set, which is a common requirement in previous methods. Without altering the classifier's architecture, our modality-agnostic method effectively selects appropriate training data and has proven efficient and effective in handling label bias and improving fairness across diverse datasets in experimental evaluations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.11072v1</guid>
      <category>cs.LG</category>
      <category>cs.CY</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yixuan Zhang, Zhidong Li, Yang Wang, Fang Chen, Xuhui Fan, Feng Zhou</dc:creator>
    </item>
    <item>
      <title>Seeing the Forest and the Trees: Solving Visual Graph and Tree Based Data Structure Problems using Large Multimodal Models</title>
      <link>https://arxiv.org/abs/2412.11088</link>
      <description>arXiv:2412.11088v1 Announce Type: cross 
Abstract: Recent advancements in generative AI systems have raised concerns about academic integrity among educators. Beyond excelling at solving programming problems and text-based multiple-choice questions, recent research has also found that large multimodal models (LMMs) can solve Parsons problems based only on an image. However, such problems are still inherently text-based and rely on the capabilities of the models to convert the images of code blocks to their corresponding text. In this paper, we further investigate the capabilities of LMMs to solve graph and tree data structure problems based only on images. To achieve this, we computationally construct and evaluate a novel benchmark dataset comprising 9,072 samples of diverse graph and tree data structure tasks to assess the performance of the GPT-4o, GPT-4v, Gemini 1.5 Pro, Gemini 1.5 Flash, Gemini 1.0 Pro Vision, and Claude 3 model families. GPT-4o and Gemini 1.5 Flash performed best on trees and graphs respectively. GPT-4o achieved 87.6% accuracy on tree samples, while Gemini 1.5 Flash, achieved 56.2% accuracy on graph samples. Our findings highlight the influence of structural and visual variations on model performance. This research not only introduces an LMM benchmark to facilitate replication and further exploration but also underscores the potential of LMMs in solving complex computing problems, with important implications for pedagogy and assessment practices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.11088v1</guid>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.CY</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Sebastian Gutierrez, Irene Hou, Jihye Lee, Kenneth Angelikas, Owen Man, Sophia Mettille, James Prather, Paul Denny, Stephen MacNeil</dc:creator>
    </item>
    <item>
      <title>A Low-cost IoT Architecture to support Urban Mobility for Visually Impaired People</title>
      <link>https://arxiv.org/abs/2412.11363</link>
      <description>arXiv:2412.11363v1 Announce Type: cross 
Abstract: People with visual impairments struggle with urban mobility and independent travel, opening up opportunities for technological advances to improve their quality of life. The Internet of Things (IoT) plays an essential role in bringing improvements and accessibility for visually impaired people. Although alternatives aimed to use IoT in urban mobility, those solutions are still in the initial stages and do not supports urban mobility for people with visual impairment. This paper proposed and evaluated a low-cost IoT architecture that uses Single-Border Computers (SBCs) to support urban mobility. A performance evaluation showcased that our low-cost architecture handles bus trace workload and is suitable for supporting impaired people to get information concerning bus location on Smart Cities scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.11363v1</guid>
      <category>cs.ET</category>
      <category>cs.CY</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.5753/wpeif.2021.17193</arxiv:DOI>
      <dc:creator>N\'adia Aparecida de Oliveira Silva, Rodrigo Moreira, Larissa Ferreira Rodrigues, Rafael Marinho e Silva</dc:creator>
    </item>
    <item>
      <title>Combining Large Language Models with Tutoring System Intelligence: A Case Study in Caregiver Homework Support</title>
      <link>https://arxiv.org/abs/2412.11995</link>
      <description>arXiv:2412.11995v1 Announce Type: cross 
Abstract: Caregivers (i.e., parents and members of a child's caring community) are underappreciated stakeholders in learning analytics. Although caregiver involvement can enhance student academic outcomes, many obstacles hinder involvement, most notably knowledge gaps with respect to modern school curricula. An emerging topic of interest in learning analytics is hybrid tutoring, which includes instructional and motivational support. Caregivers assert similar roles in homework, yet it is unknown how learning analytics can support them. Our past work with caregivers suggested that conversational support is a promising method of providing caregivers with the guidance needed to effectively support student learning. We developed a system that provides instructional support to caregivers through conversational recommendations generated by a Large Language Model (LLM). Addressing known instructional limitations of LLMs, we use instructional intelligence from tutoring systems while conducting prompt engineering experiments with the open-source Llama 3 LLM. This LLM generated message recommendations for caregivers supporting their child's math practice via chat. Few-shot prompting and combining real-time problem-solving context from tutoring systems with examples of tutoring practices yielded desirable message recommendations. These recommendations were evaluated with ten middle school caregivers, who valued recommendations facilitating content-level support and student metacognition through self-explanation. We contribute insights into how tutoring systems can best be merged with LLMs to support hybrid tutoring settings through conversational assistance, facilitating effective caregiver involvement in tutoring systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.11995v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3706468.3706516</arxiv:DOI>
      <dc:creator>Devika Venugopalan, Ziwen Yan, Conrad Borchers, Jionghao Lin, Vincent Aleven</dc:creator>
    </item>
    <item>
      <title>Virtual Agent-Based Communication Skills Training to Facilitate Health Persuasion Among Peers</title>
      <link>https://arxiv.org/abs/2412.12061</link>
      <description>arXiv:2412.12061v1 Announce Type: cross 
Abstract: Many laypeople are motivated to improve the health behavior of their family or friends but do not know where to start, especially if the health behavior is potentially stigmatizing or controversial. We present an approach that uses virtual agents to coach community-based volunteers in health counseling techniques, such as motivational interviewing, and allows them to practice these skills in role-playing scenarios. We use this approach in a virtual agent-based system to increase COVID-19 vaccination by empowering users to influence their social network. In a between-subjects comparative design study, we test the effects of agent system interactivity and role-playing functionality on counseling outcomes, with participants evaluated by standardized patients and objective judges. We find that all versions are effective at producing peer counselors who score adequately on a standardized measure of counseling competence, and that participants were significantly more satisfied with interactive virtual agents compared to passive viewing of the training material. We discuss design implications for interpersonal skills training systems based on our findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.12061v1</guid>
      <category>cs.HC</category>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Farnaz Nouraei, Keith Rebello, Mina Fallah, Prasanth Murali, Haley Matuszak, Valerie Jap, Andrea Parker, Michael Paasche-Orlow, Timothy Bickmore</dc:creator>
    </item>
    <item>
      <title>Semi-automated analysis of audio-recorded lessons: The case of teachers' engaging messages</title>
      <link>https://arxiv.org/abs/2412.12062</link>
      <description>arXiv:2412.12062v1 Announce Type: cross 
Abstract: Engaging messages delivered by teachers are a key aspect of the classroom discourse that influences student outcomes. However, improving this communication is challenging due to difficulties in obtaining observations. This study presents a methodology for efficiently extracting actual observations of engaging messages from audio-recorded lessons. We collected 2,477 audio-recorded lessons from 75 teachers over two academic years. Using automatic transcription and keyword-based filtering analysis, we identified and classified engaging messages. This method reduced the information to be analysed by 90%, optimising the time and resources required compared to traditional manual coding. Subsequent descriptive analysis revealed that the most used messages emphasised the future benefits of participating in school activities. In addition, the use of engaging messages decreased as the academic year progressed. This study offers insights for researchers seeking to extract information from teachers' discourse in naturalistic settings and provides useful information for designing interventions to improve teachers' communication strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.12062v1</guid>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Samuel Falcon, Carmen Alvarez-Alvarez, Jaime Leon</dc:creator>
    </item>
    <item>
      <title>TGDataset: Collecting and Exploring the Largest Telegram Channels Dataset</title>
      <link>https://arxiv.org/abs/2303.05345</link>
      <description>arXiv:2303.05345v2 Announce Type: replace 
Abstract: Telegram is one of the most popular instant messaging apps in today's digital age. In addition to providing a private messaging service, Telegram, with its channels, represents a valid medium for rapidly broadcasting content to a large audience (COVID-19 announcements), but, unfortunately, also for disseminating radical ideologies and coordinating attacks (Capitol Hill riot). This paper presents the TGDataset, a new dataset that includes 120,979 Telegram channels and over 400 million messages, making it the largest collection of Telegram channels to the best of our knowledge. After a brief introduction to the data collection process, we analyze the languages spoken within our dataset and the topic covered by English channels. Finally, we discuss some use cases in which our dataset can be extremely useful to understand better the Telegram ecosystem, as well as to study the diffusion of questionable news. In addition to the raw dataset, we released the scripts we used to analyze the dataset and the list of channels belonging to the network of a new conspiracy theory called Sabmyk.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.05345v2</guid>
      <category>cs.CY</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Massimo La Morgia, Alessandro Mei, Alberto Maria Mongardini</dc:creator>
    </item>
    <item>
      <title>A Call to Arms: AI Should be Critical for Social Media Analysis of Conflict Zones</title>
      <link>https://arxiv.org/abs/2311.00810</link>
      <description>arXiv:2311.00810v2 Announce Type: replace 
Abstract: The massive proliferation of social media data represents a transformative opportunity for conflict studies and for tracking the proliferation and use of weaponry, as conflicts are increasingly documented in these online spaces. At the same time, the scale and types of data available are problematic for traditional open-source intelligence. This paper focuses on identifying specific weapon systems and the insignias of the armed groups using them as documented in the Ukraine war, as these tasks are critical to operational intelligence and tracking weapon proliferation, especially given the scale of international military aid given to Ukraine. The large scale of social media makes manual assessment difficult, however, so this paper presents early work that uses computer vision models to support this task. We demonstrate that these models can both identify weapons embedded in images shared in social media and how the resulting collection of military-relevant images and their post times interact with the offline, real-world conflict. Not only can we then track changes in the prevalence of images of tanks, land mines, military trucks, etc., we find correlations among time series data associated with these images and the daily fatalities in this conflict. This work shows substantial opportunity for examining similar online documentation of conflict contexts, and we also point to future avenues where computer vision can be further improved for these open-source intelligence tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.00810v2</guid>
      <category>cs.CY</category>
      <category>cs.CV</category>
      <category>cs.HC</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Afia Abedin, Abdul Bais, Cody Buntain, Laura Courchesne, Brian McQuinn, Matthew E. Taylor, Muhib Ullah</dc:creator>
    </item>
    <item>
      <title>Emotional Images: Assessing Emotions in Images and Potential Biases in Generative Models</title>
      <link>https://arxiv.org/abs/2411.05985</link>
      <description>arXiv:2411.05985v2 Announce Type: replace 
Abstract: This paper examines potential biases and inconsistencies in emotional evocation of images produced by generative artificial intelligence (AI) models and their potential bias toward negative emotions. In particular, we assess this bias by comparing the emotions evoked by an AI-produced image to the emotions evoked by prompts used to create those images. As a first step, the study evaluates three approaches for identifying emotions in images -- traditional supervised learning, zero-shot learning with vision-language models, and cross-modal auto-captioning -- using EmoSet, a large dataset of image-emotion annotations that categorizes images across eight emotional types. Results show fine-tuned models, particularly Google's Vision Transformer (ViT), significantly outperform zero-shot and caption-based methods in recognizing emotions in images. For a cross-modality comparison, we then analyze the differences between emotions in text prompts -- via existing text-based emotion-recognition models -- and the emotions evoked in the resulting images. Findings indicate that AI-generated images frequently lean toward negative emotional content, regardless of the original prompt. This emotional skew in generative models could amplify negative affective content in digital spaces, perpetuating its prevalence and impact. The study advocates for a multidisciplinary approach to better align AI emotion recognition with psychological insights and address potential biases in generative AI outputs across digital media.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.05985v2</guid>
      <category>cs.CY</category>
      <category>cs.CV</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maneet Mehta, Cody Buntain</dc:creator>
    </item>
    <item>
      <title>A More Advanced Group Polarization Measurement Approach Based on LLM-Based Agents and Graphs</title>
      <link>https://arxiv.org/abs/2411.12196</link>
      <description>arXiv:2411.12196v2 Announce Type: replace 
Abstract: Group polarization is an important research direction in social media content analysis, attracting many researchers to explore this field. Therefore, how to effectively measure group polarization has become a critical topic. Measuring group polarization on social media presents several challenges that have not yet been addressed by existing solutions. First, social media group polarization measurement involves processing vast amounts of text, which poses a significant challenge for information extraction. Second, social media texts often contain hard-to-understand content, including sarcasm, memes, and internet slang. Additionally, group polarization research focuses on holistic analysis, while texts is typically fragmented. To address these challenges, we designed a solution based on a multi-agent system and used a graph-structured Community Sentiment Network (CSN) to represent polarization states. Furthermore, we developed a metric called Community Opposition Index (COI) based on the CSN to quantify polarization. Finally, we tested our multi-agent system through a zero-shot stance detection task and achieved outstanding results. In summary, the proposed approach has significant value in terms of usability, accuracy, and interpretability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.12196v2</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zixin Liu, Ji Zhang, Yiran Ding</dc:creator>
    </item>
    <item>
      <title>Access to care improves EHR reliability and clinical risk prediction model performance</title>
      <link>https://arxiv.org/abs/2412.07712</link>
      <description>arXiv:2412.07712v2 Announce Type: replace 
Abstract: Disparities in access to healthcare have been well-documented in the United States, but their effects on electronic health record (EHR) data reliability and resulting clinical models are poorly understood. Using an All of Us dataset of 134,513 participants, we investigate the effects of access to care on the medical machine learning pipeline, including medical condition rates, data quality, outcome label accuracy, and prediction performance. Our findings reveal that patients with cost constrained or delayed care have worse EHR reliability as measured by patient self-reported conditions for 78% of examined medical conditions. We demonstrate in a prediction task of Type II diabetes incidence that clinical risk predictive performance can be worse for patients without standard care, with balanced accuracy gaps of 3.6 and sensitivity gaps of 9.4 percentage points for those with cost-constrained or delayed care. We evaluate solutions to mitigate these disparities and find that including patient self-reported conditions improved performance for patients with lower access to care, with 11.2 percentage points higher sensitivity, effectively decreasing the performance gap between standard versus delayed or cost-constrained care. These findings provide the first large-scale evidence that healthcare access systematically affects both data reliability and clinical prediction performance. By revealing how access barriers propagate through the medical machine learning pipeline, our work suggests that improving model equity requires addressing both data collection biases and algorithmic limitations. More broadly, this analysis provides an empirical foundation for developing clinical prediction systems that work effectively for all patients, regardless of their access to care.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.07712v2</guid>
      <category>cs.CY</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anna Zink, Hongzhou Luan, Irene Y. Chen</dc:creator>
    </item>
    <item>
      <title>From Division to Unity: A Large-Scale Study on the Emergence of Computational Social Science, 1990-2021</title>
      <link>https://arxiv.org/abs/2412.08087</link>
      <description>arXiv:2412.08087v2 Announce Type: replace 
Abstract: We present a comprehensive study on the emergence of Computational Social Science (CSS) - an interdisciplinary field leveraging computational methods to address social science questions - and its impact on adjacent social sciences. We trained a robust CSS classifier using papers from CSS-focused venues and applied it to 11 million papers spanning 1990 to 2021. Our analysis yielded three key findings. First, there were two critical inflections in the rise of CSS. The first occurred around 2005 when psychology, politics, and sociology began engaging with CSS. The second emerged in approximately 2014 when economics finally joined the trend. Sociology is currently the most engaged with CSS. Second, using the density of yearly knowledge embeddings constructed by advanced transformer models, we observed that CSS initially lacked a cohesive identity. From the early 2000s to 2014, however, it began to form a distinct cluster, creating boundaries between CSS and other social sciences, particularly in politics and sociology. After 2014, these boundaries faded, and CSS increasingly blended with the social sciences. Third, shared data-driven methods homogenized CSS papers across disciplines, with politics and economics showing the most alignment due to the combined influence of CSS and causal identification. Nevertheless, non-CSS papers in sociology, psychology, and politics became more divergent. Taken together, these findings highlight the dynamics of division and unity as new disciplines emerge within existing knowledge landscapes. A live demo of CSS evolution can be found in https://evolution-css.netlify.app/</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.08087v2</guid>
      <category>cs.CY</category>
      <category>cs.DL</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Honglin Bao, Jiawei Zhang, Mingxuan Cao, James A. Evans</dc:creator>
    </item>
    <item>
      <title>Fast and Interpretable Mortality Risk Scores for Critical Care Patients</title>
      <link>https://arxiv.org/abs/2311.13015</link>
      <description>arXiv:2311.13015v2 Announce Type: replace-cross 
Abstract: Prediction of mortality in intensive care unit (ICU) patients typically relies on black box models (that are unacceptable for use in hospitals) or hand-tuned interpretable models (that might lead to the loss in performance). We aim to bridge the gap between these two categories by building on modern interpretable ML techniques to design interpretable mortality risk scores that are as accurate as black boxes. We developed a new algorithm, GroupFasterRisk, which has several important benefits: it uses both hard and soft direct sparsity regularization, it incorporates group sparsity to allow more cohesive models, it allows for monotonicity constraint to include domain knowledge, and it produces many equally-good models, which allows domain experts to choose among them. For evaluation, we leveraged the largest existing public ICU monitoring datasets (MIMIC III and eICU). Models produced by GroupFasterRisk outperformed OASIS and SAPS II scores and performed similarly to APACHE IV/IVa while using at most a third of the parameters. For patients with sepsis/septicemia, acute myocardial infarction, heart failure, and acute kidney failure, GroupFasterRisk models outperformed OASIS and SOFA. Finally, different mortality prediction ML approaches performed better based on variables selected by GroupFasterRisk as compared to OASIS variables. GroupFasterRisk's models performed better than risk scores currently used in hospitals, and on par with black box ML models, while being orders of magnitude sparser. Because GroupFasterRisk produces a variety of risk scores, it allows design flexibility - the key enabler of practical model creation. GroupFasterRisk is a fast, accessible, and flexible procedure that allows learning a diverse set of sparse risk scores for mortality prediction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.13015v2</guid>
      <category>cs.LG</category>
      <category>cs.CY</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chloe Qinyu Zhu, Muhang Tian, Lesia Semenova, Jiachang Liu, Jack Xu, Joseph Scarpa, Cynthia Rudin</dc:creator>
    </item>
    <item>
      <title>RTP-LX: Can LLMs Evaluate Toxicity in Multilingual Scenarios?</title>
      <link>https://arxiv.org/abs/2404.14397</link>
      <description>arXiv:2404.14397v2 Announce Type: replace-cross 
Abstract: Large language models (LLMs) and small language models (SLMs) are being adopted at remarkable speed, although their safety still remains a serious concern. With the advent of multilingual S/LLMs, the question now becomes a matter of scale: can we expand multilingual safety evaluations of these models with the same velocity at which they are deployed? To this end, we introduce RTP-LX, a human-transcreated and human-annotated corpus of toxic prompts and outputs in 28 languages. RTP-LX follows participatory design practices, and a portion of the corpus is especially designed to detect culturally-specific toxic language. We evaluate 10 S/LLMs on their ability to detect toxic content in a culturally-sensitive, multilingual scenario. We find that, although they typically score acceptably in terms of accuracy, they have low agreement with human judges when scoring holistically the toxicity of a prompt; and have difficulty discerning harm in context-dependent scenarios, particularly with subtle-yet-harmful content (e.g. microaggressions, bias). We release this dataset to contribute to further reduce harmful uses of these models and improve their safe deployment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.14397v2</guid>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Adrian de Wynter, Ishaan Watts, Tua Wongsangaroonsri, Minghui Zhang, Noura Farra, Nektar Ege Alt{\i}ntoprak, Lena Baur, Samantha Claudet, Pavel Gajdusek, Can G\"oren, Qilong Gu, Anna Kaminska, Tomasz Kaminski, Ruby Kuo, Akiko Kyuba, Jongho Lee, Kartik Mathur, Petter Merok, Ivana Milovanovi\'c, Nani Paananen, Vesa-Matti Paananen, Anna Pavlenko, Bruno Pereira Vidal, Luciano Strika, Yueh Tsao, Davide Turcato, Oleksandr Vakhno, Judit Velcsov, Anna Vickers, St\'ephanie Visser, Herdyan Widarmanto, Andrey Zaikin, Si-Qing Chen</dc:creator>
    </item>
    <item>
      <title>SocialEyes: Scaling mobile eye-tracking to multi-person social settings</title>
      <link>https://arxiv.org/abs/2407.06345</link>
      <description>arXiv:2407.06345v3 Announce Type: replace-cross 
Abstract: Eye movements provide a window into human behaviour, attention, and interaction dynamics. Challenges in real-world, multi-person environments have, however, restrained eye-tracking research predominantly to single-person, in-lab settings. We developed a system to stream, record, and analyse synchronised data from multiple mobile eye-tracking devices during collective viewing experiences (e.g., concerts, films, lectures). We implemented lightweight operator interfaces for real-time-monitoring, remote-troubleshooting, and gaze-projection from individual egocentric perspectives to a common coordinate space for shared gaze analysis. We tested the system in a live concert and a film screening with 30 simultaneous viewers during each of two public events (N=60). We observe precise time-synchronisation between devices measured through recorded clock-offsets, and accurate gaze-projection in challenging dynamic scenes. Our novel analysis metrics and visualizations illustrate the potential of collective eye-tracking data for understanding collaborative behaviour and social interaction. This advancement promotes ecological validity in eye-tracking research and paves the way for innovative interactive tools.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.06345v3</guid>
      <category>cs.HC</category>
      <category>cs.CE</category>
      <category>cs.CY</category>
      <category>cs.ET</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Shreshth Saxena, Areez Visram, Neil Lobo, Zahid Mirza, Mehak Rafi Khan, Biranugan Pirabaharan, Alexander Nguyen, Lauren K. Fink</dc:creator>
    </item>
    <item>
      <title>Transparent Networks for Multivariate Time Series</title>
      <link>https://arxiv.org/abs/2410.10535</link>
      <description>arXiv:2410.10535v2 Announce Type: replace-cross 
Abstract: Transparent models, which are machine learning models that produce inherently interpretable predictions, are receiving significant attention in high-stakes domains. However, despite much real-world data being collected as time series, there is a lack of studies on transparent time series models. To address this gap, we propose a novel transparent neural network model for time series called Generalized Additive Time Series Model (GATSM). GATSM consists of two parts: 1) independent feature networks to learn feature representations, and 2) a transparent temporal module to learn temporal patterns across different time steps using the feature representations. This structure allows GATSM to effectively capture temporal patterns and handle dynamic-length time series while preserving transparency. Empirical experiments show that GATSM significantly outperforms existing generalized additive models and achieves comparable performance to black-box time series models, such as recurrent neural networks and Transformer. In addition, we demonstrate that GATSM finds interesting patterns in time series. The source code is available at https://github.com/gim4855744/GATSM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10535v2</guid>
      <category>cs.LG</category>
      <category>cs.CY</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Minkyu Kim, Suan Lee, Jinho Kim</dc:creator>
    </item>
    <item>
      <title>No Argument Left Behind: Overlapping Chunks for Faster Processing of Arbitrarily Long Legal Texts</title>
      <link>https://arxiv.org/abs/2410.19184</link>
      <description>arXiv:2410.19184v2 Announce Type: replace-cross 
Abstract: In a context where the Brazilian judiciary system, the largest in the world, faces a crisis due to the slow processing of millions of cases, it becomes imperative to develop efficient methods for analyzing legal texts. We introduce uBERT, a hybrid model that combines Transformer and Recurrent Neural Network architectures to effectively handle long legal texts. Our approach processes the full text regardless of its length while maintaining reasonable computational overhead. Our experiments demonstrate that uBERT achieves superior performance compared to BERT+LSTM when overlapping input is used and is significantly faster than ULMFiT for processing long legal documents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.19184v2</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.5753/stil.2024.245447</arxiv:DOI>
      <dc:creator>Israel Fama, B\'arbara Bueno, Alexandre Alcoforado, Thomas Palmeira Ferraz, Arnold Moya, Anna Helena Reali Costa</dc:creator>
    </item>
    <item>
      <title>Habit Coach: Customising RAG-based chatbots to support behavior change</title>
      <link>https://arxiv.org/abs/2411.19229</link>
      <description>arXiv:2411.19229v2 Announce Type: replace-cross 
Abstract: This paper presents the iterative development of Habit Coach, a GPT-based chatbot designed to support users in habit change through personalized interaction. Employing a user-centered design approach, we developed the chatbot using a Retrieval-Augmented Generation (RAG) system, which enables behavior personalization without retraining the underlying language model (GPT-4). The system leverages document retrieval and specialized prompts to tailor interactions, drawing from Cognitive Behavioral Therapy (CBT) and narrative therapy techniques. A key challenge in the development process was the difficulty of translating declarative knowledge into effective interaction behaviors. In the initial phase, the chatbot was provided with declarative knowledge about CBT via reference textbooks and high-level conversational goals. However, this approach resulted in imprecise and inefficient behavior, as the GPT model struggled to convert static information into dynamic and contextually appropriate interactions. This highlighted the limitations of relying solely on declarative knowledge to guide chatbot behavior, particularly in nuanced, therapeutic conversations. Over four iterations, we addressed this issue by gradually transitioning towards procedural knowledge, refining the chatbot's interaction strategies, and improving its overall effectiveness. In the final evaluation, 5 participants engaged with the chatbot over five consecutive days, receiving individualized CBT interventions. The Self-Report Habit Index (SRHI) was used to measure habit strength before and after the intervention, revealing a reduction in habit strength post-intervention. These results underscore the importance of procedural knowledge in driving effective, personalized behavior change support in RAG-based systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19229v2</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arian Fooroogh Mand Arabi, Cansu Koyuturk, Michael O'Mahony, Raffaella Calati, Dimitri Ognibene</dc:creator>
    </item>
    <item>
      <title>Large Language Models in Politics and Democracy: A Comprehensive Survey</title>
      <link>https://arxiv.org/abs/2412.04498</link>
      <description>arXiv:2412.04498v2 Announce Type: replace-cross 
Abstract: The advancement of generative AI, particularly large language models (LLMs), has a significant impact on politics and democracy, offering potential across various domains, including policymaking, political communication, analysis, and governance. This paper surveys the recent and potential applications of LLMs in politics, examining both their promises and the associated challenges. This paper examines the ways in which LLMs are being employed in legislative processes, political communication, and political analysis. Moreover, we investigate the potential of LLMs in diplomatic and national security contexts, economic and social modeling, and legal applications. While LLMs offer opportunities to enhance efficiency, inclusivity, and decision-making in political processes, they also present challenges related to bias, transparency, and accountability. The paper underscores the necessity for responsible development, ethical considerations, and governance frameworks to ensure that the integration of LLMs into politics aligns with democratic values and promotes a more just and equitable society.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.04498v2</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Goshi Aoki</dc:creator>
    </item>
  </channel>
</rss>
