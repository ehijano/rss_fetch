<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DL updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DL</link>
    <description>cs.DL updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DL" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 11 Jun 2025 04:05:07 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Extracting Information About Publication Venues Using Citation-Informed Transformers</title>
      <link>https://arxiv.org/abs/2506.08199</link>
      <description>arXiv:2506.08199v1 Announce Type: new 
Abstract: Scientific document embeddings contain a variety of rich features which can be harnessed for downstream tasks such as recommendation, ranking, and clustering. We explore which tangible insights can be drawn from scientific document embeddings to understand trends in computer science research featured across nine well-known venues. We collect approximately 60,000 scientific documents published between 2015 and 2023 and analyze their embeddings, which we produce with the SPECTER pre-trained language model. In particular, we examine whether similarity between two venues can be measured using the embeddings of the scientific documents they admit for publication. Our findings indicate that some venues within computer science are indistinguishable when only considering the distributions of their document embeddings. We additionally examine whether any two venues are becoming increasingly similar over time and identify a trend of convergence within some venues in our analysis. We discuss the implications of these results and the potential impact on new scientific contributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.08199v1</guid>
      <category>cs.DL</category>
      <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Brian D. Zimmerman, Joshua Folkins, Olga Vechtomova</dc:creator>
    </item>
    <item>
      <title>No Stupid Questions: An Analysis of Question Query Generation for Citation Recommendation</title>
      <link>https://arxiv.org/abs/2506.08196</link>
      <description>arXiv:2506.08196v1 Announce Type: cross 
Abstract: Existing techniques for citation recommendation are constrained by their adherence to article contents and metadata. We leverage GPT-4o-mini's latent expertise as an inquisitive assistant by instructing it to ask questions which, when answered, could expose new insights about an excerpt from a scientific article. We evaluate the utility of these questions as retrieval queries, measuring their effectiveness in retrieving and ranking masked target documents. In some cases, generated questions ended up being better queries than extractive keyword queries generated by the same model. We additionally propose MMR-RBO, a variation of Maximal Marginal Relevance (MMR) using Rank-Biased Overlap (RBO) to identify which questions will perform competitively with the keyword baseline. As all question queries yield unique result sets, we contend that there are no stupid questions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.08196v1</guid>
      <category>cs.IR</category>
      <category>cs.DL</category>
      <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Brian D. Zimmerman, Julien Aubert-B\'educhaud, Florian Boudin, Akiko Aizawa, Olga Vechtomova</dc:creator>
    </item>
    <item>
      <title>Human-In-The-Loop Workflow for Neuro- Symbolic Scholarly Knowledge Organization</title>
      <link>https://arxiv.org/abs/2506.03221</link>
      <description>arXiv:2506.03221v2 Announce Type: replace 
Abstract: As the volume of scientific literature continues to grow, efficient knowledge organization is an increasingly challenging task. Traditional structuring of scientific content is time-consuming and requires significant domain expertise, increasing the need for tool support. Our goal is to create a Human-in-the-Loop (HITL) workflow that supports researchers in creating and structuring scientific knowledge, leveraging neural models and knowledge graphs, exemplified using the Open Research Knowledge Graph (ORKG). The workflow aims to automate key steps, including data extraction and knowledge structuring, while keeping user oversight through human validation. We developed a modular framework implementing the workflow and evaluated it along the Quality Improvement Paradigm (QIP) with participants from the ORKG user community. The evaluation indicated that the framework is highly usable and provides practical support. It significantly reduces the time and effort required to transition from a research interest to literature-based answers by streamlining the import of information into a knowledge graph. Participants evaluated the framework with an average System Usability Scale (SUS) score of 84.17, an A+ -- the highest achievable rating. They also reported that it improved their time spent, previously between 4 hours and two weeks, down to an average of 24:40 minutes. The tool streamlines the creation of scientific corpora and extraction of structured knowledge for KG integration by leveraging LLMs and user-defined models, significantly accelerating the review process. However, human validation remains essential throughout the extraction process, and future work is needed to improve extraction accuracy and entity linking to existing knowledge resources.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.03221v2</guid>
      <category>cs.DL</category>
      <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lena John, Ahmed Malek Ghanmi, Tim Wittenborg, S\"oren Auer, Oliver Karras</dc:creator>
    </item>
    <item>
      <title>Growth of Science and Women: Methodological Challenges of Using Structured Big Data</title>
      <link>https://arxiv.org/abs/2411.00008</link>
      <description>arXiv:2411.00008v2 Announce Type: replace-cross 
Abstract: In this research, we quantify an inflow of women into science in the past three decades. Structured Big Data allow us to estimate the contribution of women scientists to the growth of science by disciplines (N = STEMM 14 disciplines) and over time (1990-2023). A monolithic segment of STEMM science emerges from this research as divided between the disciplines in which the growth was powerfully driven by women - and the disciplines in which the role of women was marginal. There are four disciplines in which 50% of currently publishing scientists are women; and five disciplines in which more than 50% of currently young scientists are women. But there is also a cluster of four highly mathematized disciplines (MATH, COMP, PHYS, and ENG) in which the growth of science is only marginally driven by women. Digital traces left by scientists in their publications indexed in global datasets open two new dimensions in large-scale academic profession studies: time and gender. The growth of science in Europe was accompanied by growth in the number of women scientists, but with powerful cross-disciplinary and cross-generational differentiations. We examined the share of women scientists coming from ten different age cohorts for 32 European and four comparator countries (the USA, Canada, Australia, and Japan). Our study sample was N = 1,740,985 scientists (including 39.40% women scientists). Three critical methodological challenges of using structured Big Data of the bibliometric type were discussed: gender determination, academic age determination, and discipline determination.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00008v2</guid>
      <category>physics.soc-ph</category>
      <category>cs.DL</category>
      <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marek Kwiek, Lukasz Szymula</dc:creator>
    </item>
    <item>
      <title>LMRPA: Large Language Model-Driven Efficient Robotic Process Automation for OCR</title>
      <link>https://arxiv.org/abs/2412.18063</link>
      <description>arXiv:2412.18063v2 Announce Type: replace-cross 
Abstract: This paper introduces LMRPA, a novel Large Model-Driven Robotic Process Automation (RPA) model designed to greatly improve the efficiency and speed of Optical Character Recognition (OCR) tasks. Traditional RPA platforms often suffer from performance bottlenecks when handling high-volume repetitive processes like OCR, leading to a less efficient and more time-consuming process. LMRPA allows the integration of Large Language Models (LLMs) to improve the accuracy and readability of extracted text, overcoming the challenges posed by ambiguous characters and complex text structures.Extensive benchmarks were conducted comparing LMRPA to leading RPA platforms, including UiPath and Automation Anywhere, using OCR engines like Tesseract and DocTR. The results are that LMRPA achieves superior performance, cutting the processing times by up to 52\%. For instance, in Batch 2 of the Tesseract OCR task, LMRPA completed the process in 9.8 seconds, where UiPath finished in 18.1 seconds and Automation Anywhere finished in 18.7 seconds. Similar improvements were observed with DocTR, where LMRPA outperformed other automation tools conducting the same process by completing tasks in 12.7 seconds, while competitors took over 20 seconds to do the same. These findings highlight the potential of LMRPA to revolutionize OCR-driven automation processes, offering a more efficient and effective alternative solution to the existing state-of-the-art RPA models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.18063v2</guid>
      <category>cs.RO</category>
      <category>cs.DL</category>
      <category>cs.HC</category>
      <category>cs.SE</category>
      <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Osama Hosam Abdellaif, Abdelrahman Nader, Ali Hamdi</dc:creator>
    </item>
  </channel>
</rss>
