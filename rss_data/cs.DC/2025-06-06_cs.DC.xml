<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DC</link>
    <description>cs.DC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 06 Jun 2025 04:00:03 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Fully-Distributed Construction of Byzantine-Resilient Dynamic Peer-to-Peer Networks</title>
      <link>https://arxiv.org/abs/2506.04368</link>
      <description>arXiv:2506.04368v1 Announce Type: new 
Abstract: We address a fundamental problem in Peer-to-Peer (P2P) networks, namely, constructing and maintaining dynamic P2P overlay network topologies with essential properties such as connectivity, low diameter, and high expansion, that are resilient to continuous high churn and the presence of a large number of malicious (Byzantine) nodes. Our main goal is to construct and maintain a sparse (bounded degree) expander topology despite high churn and a large number of Byzantine nodes. Such an expander topology has logarithmic diameter, high expansion, and is robust to churn and the presence of a large number of bad nodes, and facilitates efficient and robust algorithms for fundamental problems in distributed computing, such as agreement, broadcasting, routing, etc.
  Our main contribution is a randomized, fully-distributed dynamic P2P protocol that works with only local initial knowledge and guarantees, with a high probability, the maintenance of a constant degree graph with high expansion even under continuous churn and in the presence of a large number of Byzantine nodes. Our protocol can tolerate up to $o(n/poly\log(n))$ Byzantine nodes (where $n$ is the stable network size). Our protocol is efficient, lightweight, and scalable, and it incurs only $O(poly\log(n))$ overhead for topology maintenance: only polylogarithmic (in $n$) bits need to be processed and sent by each honest node per round, and any honest node's computation cost per round is also polylogarithmic.
  Our protocol can be used as a building block for solving fundamental distributed computing problems in highly dynamic networks, such as Byzantine agreement and Byzantine leader election, and enables fast and scalable algorithms for these problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04368v1</guid>
      <category>cs.DC</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aayush Gupta, Gopal Pandurangan</dc:creator>
    </item>
    <item>
      <title>Knowledge-Guided Attention-Inspired Learning for Task Offloading in Vehicle Edge Computing</title>
      <link>https://arxiv.org/abs/2506.04456</link>
      <description>arXiv:2506.04456v1 Announce Type: new 
Abstract: Vehicle edge computing (VEC) brings abundant computing resources close to vehicles by deploying them at roadside units (RSUs) or base stations, thereby enabling diverse computation-intensive and delay sensitive applications. Existing task offloading strategies are often computationally expensive to execute or generate suboptimal solutions. In this paper, we propose a novel learning-based approach, Knowledge-guided Attention-inspired Task Offloading (KATO), designed to efficiently offload tasks from moving vehicles to nearby RSUs. KATO integrates an attention-inspired encoder-decoder model for selecting a subset of RSUs that can reduce overall task processing time, along with an efficient iterative algorithm for computing optimal task allocation among the selected RSUs. Simulation results demonstrate that KATO achieves optimal or near-optimal performance with significantly lower computational overhead and generalizes well across networks of varying sizes and configurations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04456v1</guid>
      <category>cs.DC</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ke Ma, Junfei Xie</dc:creator>
    </item>
    <item>
      <title>SkimROOT: Accelerating LHC Data Filtering with Near-Storage Processing</title>
      <link>https://arxiv.org/abs/2506.04507</link>
      <description>arXiv:2506.04507v1 Announce Type: new 
Abstract: Data analysis in high-energy physics (HEP) begins with data reduction, where vast datasets are filtered to extract relevant events. At the Large Hadron Collider (LHC), this process is bottlenecked by slow data transfers between storage and compute nodes. To address this, we introduce SkimROOT, a near-data filtering system leveraging Data Processing Units (DPUs) to accelerate LHC data analysis. By performing filtering directly on storage servers and returning only the relevant data, SkimROOT minimizes data movement and reduces processing delays. Our prototype demonstrates significant efficiency gains, achieving a 44.3$\times$ performance improvement, paving the way for faster physics discoveries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04507v1</guid>
      <category>cs.DC</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Narangerelt Batsoyol, Jonathan Guiang, Diego Davila, Aashay Arora, Philip Chang, Frank W\"urthwein, Steven Swanson</dc:creator>
    </item>
    <item>
      <title>FlashDMoE: Fast Distributed MoE in a Single Kernel</title>
      <link>https://arxiv.org/abs/2506.04667</link>
      <description>arXiv:2506.04667v1 Announce Type: new 
Abstract: The computational sparsity of Mixture-of-Experts (MoE) models enables sub-linear growth in compute cost as model size increases, offering a scalable path to training massive neural networks. However, existing implementations suffer from \emph{low GPU utilization}, \emph{significant latency overhead}, and a fundamental \emph{inability to leverage task locality}, primarily due to CPU-managed scheduling, host-initiated communication, and frequent kernel launches. To overcome these limitations, we develop FlashDMoE, a fully GPU-resident MoE operator that fuses expert computation and inter-GPU communication into a \emph{single persistent GPU kernel}. FlashDMoE enables fine-grained pipelining of dispatch, compute, and combine phases, eliminating launch overheads and reducing idle gaps. Its device-initiated communication protocol introduces \emph{payload-efficient} data transfers, significantly shrinking buffer sizes in sparsely activated MoE layers. When evaluated on a single 8-H100 GPU node with MoE models having up to 128 experts and 16K token sequences, FlashDMoE achieves up to \textbf{6}x lower latency, \textbf{5,7}x higher throughput, \textbf{4}x better weak scaling efficiency, and \textbf{9}x higher GPU utilization compared to state-of-the-art baselines, despite using FP32 while baselines use FP16. FlashDMoE demonstrates that principled GPU kernel-hardware co-design is key to unlocking the performance ceiling of large-scale distributed ML workloads.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04667v1</guid>
      <category>cs.DC</category>
      <category>cs.AR</category>
      <category>cs.LG</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Osayamen Jonathan Aimuyo, Byungsoo Oh, Rachee Singh</dc:creator>
    </item>
    <item>
      <title>Distributed system perspective on Backscatter systems</title>
      <link>https://arxiv.org/abs/2506.04833</link>
      <description>arXiv:2506.04833v1 Announce Type: new 
Abstract: Backscatter system is a system based on backscatter communication technology, which is a low cost, low power consumption and easy to deploy communication technology. At present, the backscatter technology is mainly applied to RFID tags and the Internet of Things and other fields. With the rapid development of the Internet of Things, the application of backscatter systems is increasing. Moreover, the backscatter system is essentially a distributed system, but existing research rarely conducts studies and analyses from a distributed perspective. This paper conducts a study on the backscattering system from the perspective of distributed systems, comprehensively reviewing the basic principles of the backscattering system, and analyzing the distributed system architectures of different backscattering systems. Then, it introduces the application scenarios, research status and challenges of the backscattering system, and finally discusses the future research directions of the backscattering system, hoping to provide references for future research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04833v1</guid>
      <category>cs.DC</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jincheng Guan, Jun Zhang</dc:creator>
    </item>
    <item>
      <title>A distributed system perspective on Backscatter systems: A review</title>
      <link>https://arxiv.org/abs/2506.04873</link>
      <description>arXiv:2506.04873v1 Announce Type: new 
Abstract: This review investigates the pivotal role of distributed architectures and intelligent resource allocation in enabling robust and scalable wireless systems, with a particular emphasis on backscatter communication, indoor localization, battery-free networks, and Simultaneous Wireless Information and Power Transfer (SWIPT).</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04873v1</guid>
      <category>cs.DC</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tonghuan Xiao, Jiecheng Zhou</dc:creator>
    </item>
    <item>
      <title>Energy-Optimized Scheduling for AIoT Workloads Using TOPSIS</title>
      <link>https://arxiv.org/abs/2506.04902</link>
      <description>arXiv:2506.04902v1 Announce Type: new 
Abstract: AIoT workloads demand energy-efficient orchestration across cloud-edge infrastructures, but Kubernetes' default scheduler lacks multi-criteria optimization for heterogeneous environments. This paper presents GreenPod, a TOPSIS-based scheduler optimizing pod placement based on execution time, energy consumption, processing core, memory availability, and resource balance. Tested on a heterogeneous Google Kubernetes cluster, GreenPod improves energy efficiency by up to 39.1% over the default Kubernetes (K8s) scheduler, particularly with energy-centric weighting schemes. Medium complexity workloads showed the highest energy savings, despite slight scheduling latency. GreenPod effectively balances sustainability and performance for AIoT applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04902v1</guid>
      <category>cs.DC</category>
      <category>cs.PF</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Preethika Pradeep, Eyhab Al-Masri</dc:creator>
    </item>
    <item>
      <title>Improved Byzantine Agreement under an Adaptive Adversary</title>
      <link>https://arxiv.org/abs/2506.04919</link>
      <description>arXiv:2506.04919v1 Announce Type: new 
Abstract: Byzantine agreement is a fundamental problem in fault-tolerant distributed computing that has been studied intensively for the last four decades. Much of the research has focused on a static Byzantine adversary, where the adversary is constrained to choose the Byzantine nodes in advance of the protocol's execution. This work focuses on the harder case of an adaptive Byzantine adversary that can choose the Byzantine nodes \emph{adaptively} based on the protocol's execution. While efficient $O(\log n)$-round protocols ($n$ is the total number of nodes) are known for the static adversary (Goldwasser, Pavlov, and Vaikuntanathan, FOCS 2006) tolerating up to $t &lt; n/(3+\epsilon)$ Byzantine nodes, $\Omega(t/\sqrt{n \log n})$ rounds is a well-known lower bound for adaptive adversary [Bar-Joseph and Ben-Or, PODC 1998]. The best-known protocol for adaptive adversary runs in $O(t/\log n)$ rounds [Chor and Coan, IEEE Trans. Soft. Engg., 1985].
  This work presents a synchronous randomized Byzantine agreement protocol under an adaptive adversary that improves over previous results. Our protocol works under the powerful \emph{adaptive rushing adversary in the full information model}. That is, we assume that the Byzantine nodes can behave arbitrarily and maliciously, have knowledge about the entire state of the network at every round, including random choices made by all the nodes up to and including the current round, have unlimited computational power, and may collude among themselves. Furthermore, the adversary can \emph{adaptively} corrupt up to $t &lt; n/3$ nodes based on the protocol's execution. We present a simple randomized Byzantine agreement protocol that runs in $O(\min\{t^2\log n/n, t/\log n\})$ rounds that improves over the long-standing bound of $O(t/\log n)$ rounds due to Chor and Coan [IEEE Trans. Soft. Engg., 1985].</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04919v1</guid>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fabien Dufoulon, Gopal Pandurangan</dc:creator>
    </item>
    <item>
      <title>Inference economics of language models</title>
      <link>https://arxiv.org/abs/2506.04645</link>
      <description>arXiv:2506.04645v1 Announce Type: cross 
Abstract: We develop a theoretical model that addresses the economic trade-off between cost per token versus serial token generation speed when deploying LLMs for inference at scale. Our model takes into account arithmetic, memory bandwidth, network bandwidth and latency constraints; and optimizes over different parallelism setups and batch sizes to find the ones that optimize serial inference speed at a given cost per token. We use the model to compute Pareto frontiers of serial speed versus cost per token for popular language models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04645v1</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ege Erdil</dc:creator>
    </item>
    <item>
      <title>A highly scalable numerical framework for reservoir simulation on UG4 platform</title>
      <link>https://arxiv.org/abs/2506.04763</link>
      <description>arXiv:2506.04763v1 Announce Type: cross 
Abstract: The modeling and simulation of multiphase fluid flow receive significant attention in reservoir engineering. Many time discretization schemes for multiphase flow equations are either explicit or semi-implicit, relying on the decoupling between the saturation equation and the pressure equation. In this study, we delve into a fully coupled and fully implicit framework for simulating multiphase flow in heterogeneous porous media, considering gravity and capillary effects. We utilize the Vertex-Centered Finite Volume Method for spatial discretization and propose an efficient implementation of interface conditions for heterogeneous porous media within the current scheme. Notably, we introduce the Linearly Implicit Extrapolation Method (LIMEX) with an error estimator, adapted for the first time to multiphase flow problems. To solve the resulting linear system, we employ the BiCGSTAB method with the Geometric Multigrid (GMG) preconditioner. The implementations of models and methods are based on the open-source software: UG4. The results from parallel computations on the supercomputer demonstrate that the scalability of our proposed framework is sufficient, supporting a scale of thousands of processors with Degrees of Freedom (DoF) extending up to billions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04763v1</guid>
      <category>physics.comp-ph</category>
      <category>cs.DC</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Shuai Lu</dc:creator>
    </item>
    <item>
      <title>Becoming Immutable: How Ethereum is Made</title>
      <link>https://arxiv.org/abs/2506.04940</link>
      <description>arXiv:2506.04940v1 Announce Type: cross 
Abstract: We analyze blocks proposed for inclusion in the Ethereum blockchain during 8 minutes on December 3rd, 2024. Our dataset comprises 38 winning blocks, 15,097 proposed blocks, 10,793 unique transactions, and 2,380,014 transaction-block pairings. We find that exclusive transactions--transactions present only in blocks proposed by a single builder--account for 85% of the fees paid by all transactions included in winning blocks. We also find that a surprisingly large number of user transactions are delayed: although proposed during a bidding cycle, they are not included in the corresponding winning block. Many such delayed transactions are exclusive to a losing builder. We also identify two arbitrage bots trading between decentralized (DEX) and centralized exchanges (CEX). By examining their bidding dynamics, we estimate that the implied price at which these bots trade USDC/WETH and USDT/WETH on CEXes is between 3.4 and 4.2 basis points better than the contemporaneous price reported on Binance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04940v1</guid>
      <category>econ.GN</category>
      <category>cs.DC</category>
      <category>q-fin.EC</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrea Canidio, Vabuk Pahari</dc:creator>
    </item>
    <item>
      <title>Federated Isolation Forest for Efficient Anomaly Detection on Edge IoT Systems</title>
      <link>https://arxiv.org/abs/2506.05138</link>
      <description>arXiv:2506.05138v1 Announce Type: cross 
Abstract: Recently, federated learning frameworks such as Python TestBed for Federated Learning Algorithms and MicroPython TestBed for Federated Learning Algorithms have emerged to tackle user privacy concerns and efficiency in embedded systems. Even more recently, an efficient federated anomaly detection algorithm, FLiForest, based on Isolation Forests has been developed, offering a low-resource, unsupervised method well-suited for edge deployment and continuous learning. In this paper, we present an application of Isolation Forest-based temperature anomaly detection, developed using the previously mentioned federated learning frameworks, aimed at small edge devices and IoT systems running MicroPython. The system has been experimentally evaluated, achieving over 96% accuracy in distinguishing normal from abnormal readings and above 78% precision in detecting anomalies across all tested configurations, while maintaining a memory usage below 160 KB during model training. These results highlight its suitability for resource-constrained environments and edge systems, while upholding federated learning principles of data privacy and collaborative learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.05138v1</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pavle Vasiljevic, Milica Matic, Miroslav Popovic</dc:creator>
    </item>
    <item>
      <title>Tight analyses of first-order methods with error feedback</title>
      <link>https://arxiv.org/abs/2506.05271</link>
      <description>arXiv:2506.05271v1 Announce Type: cross 
Abstract: Communication between agents often constitutes a major computational bottleneck in distributed learning. One of the most common mitigation strategies is to compress the information exchanged, thereby reducing communication overhead. To counteract the degradation in convergence associated with compressed communication, error feedback schemes -- most notably $\mathrm{EF}$ and $\mathrm{EF}^{21}$ -- were introduced. In this work, we provide a tight analysis of both of these methods. Specifically, we find the Lyapunov function that yields the best possible convergence rate for each method -- with matching lower bounds. This principled approach yields sharp performance guarantees and enables a rigorous, apples-to-apples comparison between $\mathrm{EF}$, $\mathrm{EF}^{21}$, and compressed gradient descent. Our analysis is carried out in a simplified yet representative setting, which allows for clean theoretical insights and fair comparison of the underlying mechanisms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.05271v1</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>math.OC</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniel Berg Thomsen, Adrien Taylor, Aymeric Dieuleveut</dc:creator>
    </item>
    <item>
      <title>Efficiently Serving Large Multimodal Models Using EPD Disaggregation</title>
      <link>https://arxiv.org/abs/2501.05460</link>
      <description>arXiv:2501.05460v3 Announce Type: replace 
Abstract: Large Multimodal Models (LMMs) extend Large Language Models (LLMs) by handling diverse inputs such as images, audio, and video, but at the cost of adding a multimodal encoding stage that increases both computational and memory overhead. This step negatively affects key Service Level Objectives (SLOs), such as time to first token (TTFT) and time per output token (TPOT). We introduce Encode-Prefill-Decode (EPD) Disaggregation, a novel framework that separates the encoding, prefill, and decode stages onto dedicated resources. Unlike current systems, which bundle encoding and prefill together, our approach decouples these steps, unlocking new opportunities and optimizations. These include a mechanism to cache multimedia tokens for efficient transfer, a novel way to parallelize the encoding load within a request, a module for optimal resource allocation for disaggregated serving, and a novel role-switching method to handle changing workload characteristics. Experimental evaluations with popular LMMs show substantial gains in memory efficiency (up to 15x lower peak memory utilization), batch sizes (up to 22x larger), 10x more images per request, and 2.2x larger KV caches. Furthermore, it leads to significant improvements in SLO attainment (up to 90-100% improvement) and TTFT (up to 71% reduction), compared to systems that do not disaggregate. The code is available at https://github.com/vbdi/epdserve.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.05460v3</guid>
      <category>cs.DC</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>International Conference on Machine Proceedings of the 42nd International Conference on Machine Learning, Vancouver, Canada. PMLR 267, 2025</arxiv:journal_reference>
      <dc:creator>Gursimran Singh, Xinglu Wang, Yifan Hu, Timothy Yu, Linzi Xing, Wei Jiang, Zhefeng Wang, Xiaolong Bai, Yi Li, Ying Xiong, Yong Zhang, Zhenan Fan</dc:creator>
    </item>
    <item>
      <title>Demystifying Cost-Efficiency in LLM Serving over Heterogeneous GPUs</title>
      <link>https://arxiv.org/abs/2502.00722</link>
      <description>arXiv:2502.00722v2 Announce Type: replace 
Abstract: Recent advancements in Large Language Models (LLMs) have led to increasingly diverse requests, accompanied with varying resource (compute and memory) demands to serve them. However, this in turn degrades the cost-efficiency of LLM serving as common practices primarily rely on homogeneous GPU resources. In response to this problem, this work conducts a thorough study about serving LLMs over heterogeneous GPU resources on cloud platforms. The rationale is that different GPU types exhibit distinct compute and memory characteristics, aligning well with the divergent resource demands of diverse requests. Particularly, through comprehensive benchmarking, we discover that the cost-efficiency of LLM serving can be substantially optimized by meticulously determining GPU composition, deployment configurations, and workload assignments. Subsequently, we design a scheduling algorithm via mixed-integer linear programming, aiming at deducing the most cost-efficient serving plan under the constraints of price budget and real-time GPU availability. Remarkably, our approach effectively outperforms homogeneous and heterogeneous baselines under a wide array of scenarios, covering diverse workload traces, varying GPU availablilities, and multi-model serving. This casts new light on more accessible and efficient LLM serving over heterogeneous cloud resources.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.00722v2</guid>
      <category>cs.DC</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Youhe Jiang, Fangcheng Fu, Xiaozhe Yao, Guoliang He, Xupeng Miao, Ana Klimovic, Bin Cui, Binhang Yuan, Eiko Yoneki</dc:creator>
    </item>
    <item>
      <title>Strong and Hiding Distributed Certification of Bipartiteness</title>
      <link>https://arxiv.org/abs/2502.13854</link>
      <description>arXiv:2502.13854v2 Announce Type: replace 
Abstract: Distributed certification is a framework in distributed computing where nodes in a network jointly verify whether the whole graph satisfies a given property. A locally checkable proof (LCP) is a non-deterministic distributed algorithm used to verify global properties of a graph $G$, involving a prover and a verifier. The prover is a powerful entity that assigns certificates to nodes, which are then locally checked by the verifier.
  An LCP is correct if it satisfies completeness and soundness. Completeness means that, for any graph $G$ satisfying a property $\Pi$, there exists a certificate assignment accepted by all nodes. Soundness ensures that for every graph not satisfying $\Pi$, at least one node rejects any certificate assignment.
  We study how to certify that a graph is bipartite (i.e., $2$-colorable) with an LCP that hides the $2$-coloring from the verifier. An LCP is hiding if no local algorithm can reconstruct the coloring from a valid certificate. Motivated by promise-free separations in the LOCAL model and its variants, we also require strong soundness: in a no-instance, the subgraph induced by accepting nodes must be $2$-colorable. An LCP with completeness, soundness, hiding, and strong soundness is called strong and hiding.
  We show that such LCPs for $2$-coloring exist in specific graph classes, using only $O(\log n)$-size certificates. If the input is a cycle or has a node of degree 1, these LCPs also work in anonymous networks with constant-size certificates.
  We also prove that no strong and hiding LCP exists for general graphs unless node identifiers are available and certificates are of size $\omega(1)$. In anonymous networks, this lower bound holds regardless of the certificate size. We also present a characterization of the hiding property for $k$-coloring, which plays a key role in future investigations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13854v2</guid>
      <category>cs.DC</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Augusto Modanese, Pedro Montealegre, Mart\'in R\'ios-Wilson</dc:creator>
    </item>
    <item>
      <title>Efficient Parallel Scheduling for Sparse Triangular Solvers</title>
      <link>https://arxiv.org/abs/2503.05408</link>
      <description>arXiv:2503.05408v2 Announce Type: replace 
Abstract: We develop and analyze new scheduling algorithms for solving sparse triangular linear systems (SpTRSV) in parallel. Our approach produces highly efficient synchronous schedules for the forward- and backward-substitution algorithm. Compared to state-of-the-art baselines HDagg and SpMP, we achieve a $3.32 \times$ and $1.42 \times$ geometric-mean speed-up, respectively. We achieve this by obtaining an up to $12.07 \times$ geometric-mean reduction in the number of synchronization barriers over HDagg, whilst maintaining a balanced workload, and by applying a matrix reordering step for locality. We show that our improvements are consistent across a variety of input matrices and hardware architectures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.05408v2</guid>
      <category>cs.DC</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Toni B\"ohnlein, P\'al Andr\'as Papp, Raphael S. Steiner, Christos K. Matzoros, A. N. Yzelman</dc:creator>
    </item>
    <item>
      <title>Triton-distributed: Programming Overlapping Kernels on Distributed AI Systems with the Triton Compiler</title>
      <link>https://arxiv.org/abs/2504.19442</link>
      <description>arXiv:2504.19442v3 Announce Type: replace 
Abstract: In this report, we propose Triton-distributed, an extension of existing Triton compiler, to overcome the programming challenges in distributed AI systems. Triton-distributed is the first compiler that supports native overlapping optimizations for distributed AI workloads, providing a good coverage of existing optimizations from different frameworks. First, we integrate communication primitives compliant with the OpenSHMEM standard into the compiler. This enables programmers to utilize these primitives with a higher-level Python programming model. Second, we illustrate how to achieve complex joint optimization of computation, memory access, and communication with the assistance of the compiler. In particular, we show how to use overlapping techniques to hide latency and present our compiler-based programming methods in both single-node and multi-node scenarios. Finally, we showcase the performance of the code generated by our compiler. In a test environment with up to 64 devices, our compiler can fully utilize heterogeneous communication and computation resources to provide effective overlapping and high performance. In many cases, the performance of the generated code can even outperform hand-optimized code. Moreover, the development difficulty and the time cost for development using our compiler are far less than those of low-level programming such as CUDA/C++, which clearly demonstrates significant productivity advantages.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19442v3</guid>
      <category>cs.DC</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Size Zheng, Wenlei Bao, Qi Hou, Xuegui Zheng, Jin Fang, Chenhui Huang, Tianqi Li, Haojie Duanmu, Renze Chen, Ruifan Xu, Yifan Guo, Ningxin Zheng, Ziheng Jiang, Xinyi Di, Dongyang Wang, Jianxi Ye, Haibin Lin, Li-Wen Chang, Liqiang Lu, Yun Liang, Jidong Zhai, Xin Liu</dc:creator>
    </item>
    <item>
      <title>ServeGen: Workload Characterization and Generation of Large Language Model Serving in Production</title>
      <link>https://arxiv.org/abs/2505.09999</link>
      <description>arXiv:2505.09999v2 Announce Type: replace 
Abstract: With the widespread adoption of Large Language Models (LLMs), serving LLM inference requests has become an increasingly important task, attracting active research advancements. Practical workloads play an essential role in this process: they are critical for motivating and benchmarking serving techniques and systems. However, the existing understanding of real-world LLM serving workloads is limited due to the lack of a comprehensive workload characterization. Prior analyses remain insufficient in scale and scope, thus failing to fully capture intricate workload characteristics.
  In this paper, we fill the gap with an in-depth characterization of LLM serving workloads collected from our worldwide cloud inference serving service, covering not only language models but also emerging multimodal and reasoning models, and unveiling important new findings in each case. Moreover, based on our findings, we propose ServeGen, a principled framework for generating realistic LLM serving workloads by composing them on a per-client basis. A practical use case in production validates that ServeGen avoids 50% under-provisioning compared to naive workload generation, demonstrating ServeGen's advantage in performance benchmarking. ServeGen is available at https://github.com/alibaba/ServeGen.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09999v2</guid>
      <category>cs.DC</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Yuxing Xiang, Xue Li, Kun Qian, Wenyuan Yu, Ennan Zhai, Xin Jin</dc:creator>
    </item>
    <item>
      <title>Multi-Event Triggers for Serverless Computing</title>
      <link>https://arxiv.org/abs/2505.21199</link>
      <description>arXiv:2505.21199v2 Announce Type: replace 
Abstract: Function-as-a-Service (FaaS) is an event-driven serverless cloud computing model in which small, stateless functions are invoked in response to events, such as HTTP requests, new database entries, or messages. Current FaaS platform assume that each function invocation corresponds to a single event. However, from an application perspective, it is desirable to invoke functions in response to a collection of events of different types or only with every n\textsuperscript{th} event. To implement this today, a function would need additional state management, e.g., in a database, and custom logic to determine whether its trigger condition is fulfilled and the actual application code should run. In such an implementation, most function invocations would be rendered essentially useless, leading to unnecessarily high resource usage, latency, and cost for applications. In this paper, we introduce multi-event triggers, through which complex conditions for function invocations can be specified. Specifically, we introduce abstractions for invoking functions based on a set of $n$ events and joins of multiple events of different types. This enables application developers to define intricate conditions for function invocations, workflow steps, and complex event processing. Our evaluation with a proof-of-concept prototype shows that this reduces event--invocation latency by 62.5\% in an incident detection use-case and that our system can handle more than 300,000 requests per second on limited hardware, which is sufficient load for implementation in large FaaS platforms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21199v2</guid>
      <category>cs.DC</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Valentin Carl, Trever Schirmer, Niklas Kowallik, Joshua Adamek, Tobias Pfandzelter, Sergio Lucia, David Bermbach</dc:creator>
    </item>
    <item>
      <title>Fast real-time arbitrary waveform generation using graphic processing units</title>
      <link>https://arxiv.org/abs/2403.15582</link>
      <description>arXiv:2403.15582v2 Announce Type: replace-cross 
Abstract: Real-time arbitrary waveform generation (AWG) is essential in various engineering and research applications. This paper introduces a novel AWG architecture using an NVIDIA graphics processing unit (GPU) and a commercially available high-speed digital-to-analog converter (DAC) card, both running on a desktop personal computer (PC). The GPU accelerates the "embarrassingly" data-parallel additive synthesis framework for AWG, and the DAC reconstructs the generated waveform in the analog domain at high speed. The AWG software is developed using the developer-friendly compute unified device architecture (CUDA) runtime application programming interface (API) from NVIDIA. With this architecture, we achieve a 586-fold increase in the speed of computing periodic radio-frequency (rf) arbitrary waveforms compared to a central processing unit (CPU). We also demonstrate two different pathways for dynamically controlling multi-tone rf waveforms, which we characterize by chirping individual single-frequency tones in the multi-tone waveforms. One pathway offers arbitrary simultaneous chirping of 1000 individual Nyquist-limited single-frequency tones at a sampling rate of 280 megasamples per second (MS/s) for a limited time duration of 35 ms. The other pathway offers simultaneous chirping of 340 individual Nyquist-limited single-frequency tones at 50 MS/s, or 55 individual tones at 280 MS/s for an arbitrary duration. Using the latter pathway, we demonstrate control over 5000-tone and 10,000-tone waveforms by chirping all of their constituent tones in groups of up to 100 tones. This AWG architecture is designed for creating large defect-free optical tweezer arrays of single neutral atoms or molecules for quantum simulation and quantum computation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15582v2</guid>
      <category>cond-mat.quant-gas</category>
      <category>cs.DC</category>
      <category>eess.SP</category>
      <category>physics.atom-ph</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TSP.2025.3574958</arxiv:DOI>
      <dc:creator>Juntian Tu, Sarthak Subhankar</dc:creator>
    </item>
    <item>
      <title>A Selective Homomorphic Encryption Approach for Faster Privacy-Preserving Federated Learning</title>
      <link>https://arxiv.org/abs/2501.12911</link>
      <description>arXiv:2501.12911v4 Announce Type: replace-cross 
Abstract: Federated learning (FL) has come forward as a critical approach for privacy-preserving machine learning in healthcare, allowing collaborative model training across decentralized medical datasets without exchanging clients' data. However, current security implementations for these systems face a fundamental trade-off: rigorous cryptographic protections like fully homomorphic encryption (FHE) impose prohibitive computational overhead, while lightweight alternatives risk vulnerable data leakage through model updates. To address this issue, we present FAS (Fast and Secure Federated Learning), a novel approach that strategically combines selective homomorphic encryption, differential privacy, and bitwise scrambling to achieve robust security without compromising practical usability. Our approach eliminates the need for model pretraining phases while dynamically protecting high-risk model parameters through layered encryption and obfuscation. We implemented FAS using the Flower framework and evaluated it on a cluster of eleven physical machines. Our approach was up to 90\% faster than applying FHE on the model weights. In addition, we eliminated the computational overhead that is required by competitors such as FedML-HE and MaskCrypt. Our approach was up to 1.5$\times$ faster than the competitors while achieving comparable security results.
  Experimental evaluations on medical imaging datasets confirm that FAS maintains similar security results to conventional FHE against gradient inversion attacks while preserving diagnostic model accuracy. These results position FAS as a practical solution for latency-sensitive healthcare applications where both privacy preservation and computational efficiency are requirements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12911v4</guid>
      <category>cs.CR</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Abdulkadir Korkmaz, Praveen Rao</dc:creator>
    </item>
    <item>
      <title>Inclusive, Differentially Private Federated Learning for Clinical Data</title>
      <link>https://arxiv.org/abs/2505.22108</link>
      <description>arXiv:2505.22108v2 Announce Type: replace-cross 
Abstract: Federated Learning (FL) offers a promising approach for training clinical AI models without centralizing sensitive patient data. However, its real-world adoption is hindered by challenges related to privacy, resource constraints, and compliance. Existing Differential Privacy (DP) approaches often apply uniform noise, which disproportionately degrades model performance, even among well-compliant institutions. In this work, we propose a novel compliance-aware FL framework that enhances DP by adaptively adjusting noise based on quantifiable client compliance scores. Additionally, we introduce a compliance scoring tool based on key healthcare and security standards to promote secure, inclusive, and equitable participation across diverse clinical settings. Extensive experiments on public datasets demonstrate that integrating under-resourced, less compliant clinics with highly regulated institutions yields accuracy improvements of up to 15% over traditional FL. This work advances FL by balancing privacy, compliance, and performance, making it a viable solution for real-world clinical workflows in global healthcare.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.22108v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CR</category>
      <category>cs.DC</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Santhosh Parampottupadam, Melih Co\c{s}\u{g}un, Sarthak Pati, Maximilian Zenk, Saikat Roy, Dimitrios Bounias, Benjamin Hamm, Sinem Sav, Ralf Floca, Klaus Maier-Hein</dc:creator>
    </item>
  </channel>
</rss>
