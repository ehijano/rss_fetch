<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.ET updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.ET</link>
    <description>cs.ET updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.ET" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 23 Jan 2026 02:37:57 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 22 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>GNN-based Path-aware multi-view Circuit Learning for Technology Mapping</title>
      <link>https://arxiv.org/abs/2601.14286</link>
      <description>arXiv:2601.14286v1 Announce Type: new 
Abstract: Traditional technology mapping suffers from systemic inaccuracies in delay estimation due to its reliance on abstract, technology-agnostic delay models that fail to capture the nuanced timing behavior behavior of real post-mapping circuits. To address this fundamental limitation, we introduce GPA(graph neural network (GNN)-based Path-Aware multi-view circuit learning), a novel GNN framework that learns precise, data-driven delay predictions by synergistically fusing three complementary views of circuit structure: And-Inverter Graphs (AIGs)-based functional encoding, post-mapping technology emphasizes critical timing paths. Trained exclusively on real cell delays extracted from critical paths of industrial-grade post-mapping netlists, GPA learns to classify cut delays with unprecedented accuracy, directly informing smarter mapping decisions. Evaluated on the 19 EPFL combinational benchmarks, GPA achieves 19.9%, 2.1% and 4.1% average delay reduction over the conventional heuristics methods (techmap, MCH) and the prior state-of-the-art ML-based approach SLAP, respectively-without compromising area efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.14286v1</guid>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <pubDate>Thu, 22 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wentao Jiang, Jingxin Wang, Zhang Hu, Zhengyuan Shi, Chengyu Ma, Qiang Xu, Weikang Qian, Zhufei Chu</dc:creator>
    </item>
    <item>
      <title>Analog-to-Stochastic Converter Using Magnetic Tunnel Junction Devices for Vision Chips</title>
      <link>https://arxiv.org/abs/2601.14640</link>
      <description>arXiv:2601.14640v1 Announce Type: new 
Abstract: This paper introduces an analog-to-stochastic converter using a magnetic tunnel junction (MTJ) device for vision chips based on stochastic computation. Stochastic computation has been recently exploited for area-efficient hardware implementation, such as low-density parity-check (LDPC) decoders and image processors. However, power-and-area hungry two-step (analog-to-digital and digital-to-stochastic) converters are required for the analog to stochastic signal conversion. To realize a one-step conversion, an MTJ device is used as it inherently exhibits a probabilistic switching behavior between two resistance states. Exploiting the device-based probabilistic behavior, analog signals can be directly and area-efficiently converted to stochastic signals to mitigate the signal-conversion overhead. The analog-to-stochastic signal conversion is theoretically described and the conversion characteristic is evaluated using device and circuit parameters. In addition, the resistance variability of the MTJ device is considered in order to compensate the variability effect on the signal conversion. Based on the theoretical analysis, the analog-to-stochastic converter is designed in 90nm CMOS and 100nm MTJ technologies and is verified using a SPICE simulator (NS-SPICE) that handles both transistors and MTJ devices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.14640v1</guid>
      <category>cs.ET</category>
      <category>cs.AR</category>
      <pubDate>Thu, 22 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TNANO.2015.2511151</arxiv:DOI>
      <dc:creator>Naoya Onizawa, Daisaku Katagiri, Warren J. Gross, Takahiro Hanyu</dc:creator>
    </item>
    <item>
      <title>Measuring the State of Open Science in Transportation Using Large Language Models</title>
      <link>https://arxiv.org/abs/2601.14429</link>
      <description>arXiv:2601.14429v1 Announce Type: cross 
Abstract: Open science initiatives have strengthened scientific integrity and accelerated research progress across many fields, but the state of their practice within transportation research remains under-investigated. Key features of open science, defined here as data and code availability, are difficult to extract due to the inherent complexity of the field. Previous work has either been limited to small-scale studies due to the labor-intensive nature of manual analysis or has relied on large-scale bibliometric approaches that sacrifice contextual richness. This paper introduces an automatic and scalable feature-extraction pipeline to measure data and code availability in transportation research. We employ Large Language Models (LLMs) for this task and validate their performance against a manually curated dataset and through an inter-rater agreement analysis. We applied this pipeline to examine 10,724 research articles published in the Transportation Research Part series of journals between 2019 and 2024. Our analysis found that only 5% of quantitative papers shared a code repository, 4% of quantitative papers shared a data repository, and about 3% of papers shared both, with trends differing across journals, topics, and geographic regions. We found no significant difference in citation counts or review duration between papers that provided data and code and those that did not, suggesting a misalignment between open science efforts and traditional academic metrics. Consequently, encouraging these practices will likely require structural interventions from journals and funding agencies to supplement the lack of direct author incentives. The pipeline developed in this study can be readily scaled to other journals, representing a critical step toward the automated measurement and monitoring of open science practices in transportation research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.14429v1</guid>
      <category>cs.DL</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.ET</category>
      <pubDate>Thu, 22 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junyi Ji, Ruth Lu, Linda Belkessa, Liming Wang, Silvia Varotto, Yongqi Dong, Nicolas Saunier, Mostafa Ameli, Gregory S. Macfarlane, Bahman Madadi, Cathy Wu</dc:creator>
    </item>
    <item>
      <title>Simulation-Guided Approximate Logic Synthesis Under the Maximum Error Constraint</title>
      <link>https://arxiv.org/abs/2505.16769</link>
      <description>arXiv:2505.16769v2 Announce Type: replace 
Abstract: Approximate computing is an effective computing paradigm for improving the energy efficiency of error-tolerant applications. Approximate logic synthesis (ALS) is an automatic process to generate approximate circuits with reduced area, delay, and power, while satisfying user-specified error constraints. This paper focuses on ALS under the maximum error constraint. As an essential error metric that provides a worst-case error guarantee, the maximum error is crucial for many applications such as image processing and machine learning. This work proposes an efficient simulation-guided ALS flow that handles this constraint. It utilizes logic simulation to 1) prune local approximate changes (LACs) with large errors that violate the error constraint, and 2) accelerate the SAT-based LAC selection process. Furthermore, to enhance scalability, our ALS flow iteratively selects a set of promising LACs satisfying the error constraint to improve efficiency. The experimental results show that compared with the state-of-the-art method, our ALS flow accelerates by 30.6x, and further reduces the circuit area and delay by 18.2% and 4.9%, respectively. Notably, our flow scales to large EPFL benchmarks with up to 38540 nodes, which remain challenging for existing ALS methods tackling maximum error constraint.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.16769v2</guid>
      <category>cs.ET</category>
      <pubDate>Thu, 22 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TCAD.2026.3654911</arxiv:DOI>
      <arxiv:journal_reference>IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems 2026</arxiv:journal_reference>
      <dc:creator>Chang Meng, Weikang Qian, Giovanni De Micheli</dc:creator>
    </item>
    <item>
      <title>A Multi-Stage Augmented Multimodal Interaction Network for Quantifying Fish Feeding Intensity Using Feeding Image, Audio and Water Wave</title>
      <link>https://arxiv.org/abs/2506.14170</link>
      <description>arXiv:2506.14170v2 Announce Type: replace-cross 
Abstract: In recirculating aquaculture systems, accurate and effective assessment of fish feeding intensity is crucial for reducing feed costs and calculating optimal feeding times. However, current studies have limitations in modality selection, feature extraction and fusion, and co-inference for decision making, which restrict further improvement in the accuracy, applicability and reliability of multimodal fusion models. To address this problem, this study proposes a Multi-stage Augmented Multimodal Interaction Network (MAINet) for quantifying fish feeding intensity. Firstly, a general feature extraction framework is proposed to efficiently extract feature information from input image, audio and water wave datas. Second, an Auxiliary-modality Reinforcement Primary-modality Mechanism (ARPM) is designed for inter-modal interaction and generate enhanced features, which consists of a Channel Attention Fusion Network (CAFN) and a Dual-mode Attention Fusion Network (DAFN). Finally, an Evidence Reasoning (ER) rule is introduced to fuse the output results of each modality and make decisions, thereby completing the quantification of fish feeding intensity. The experimental results show that the constructed MAINet reaches 96.76%, 96.78%, 96.79% and 96.79% in accuracy, precision, recall and F1-Score respectively, and its performance is significantly higher than the comparison models. Compared with models that adopt single-modality, dual-modality fusion and different decision-making fusion methods, it also has obvious advantages. Meanwhile, the ablation experiments further verified the key role of the proposed improvement strategy in improving the robustness and feature utilization efficiency of model, which can effectively improve the accuracy of the quantitative results of fish feeding intensity. The dataset is available at: https://huggingface.co/datasets/ShulongZhang/Multimodal_Fish_Feeding_Intensity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.14170v2</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <pubDate>Thu, 22 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shulong Zhang, Mingyuan Yao, Jiayin Zhao, Daoliang Li, Yingyi Chen, Haihua Wang</dc:creator>
    </item>
  </channel>
</rss>
