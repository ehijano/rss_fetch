<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CE</link>
    <description>cs.CE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 18 Jul 2025 04:01:33 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Vector-level Feedforward Control of LPBF Melt Pool Area Using a Physics-Based Thermal Model</title>
      <link>https://arxiv.org/abs/2507.12557</link>
      <description>arXiv:2507.12557v1 Announce Type: new 
Abstract: Laser powder bed fusion (LPBF) is an additive manufacturing technique that has gained popularity thanks to its ability to produce geometrically complex, fully dense metal parts. However, these parts are prone to internal defects and geometric inaccuracies, stemming in part from variations in the melt pool. This paper proposes a novel vector-level feedforward control framework for regulating melt pool area in LPBF. By decoupling part-scale thermal behavior from small-scale melt pool physics, the controller provides a scale-agnostic prediction of melt pool area and efficient optimization over it. This is done by operating on two coupled lightweight models: a finite-difference thermal model that efficiently captures vector-level temperature fields and a reduced-order, analytical melt pool model. Each model is calibrated separately with minimal single-track and 2D experiments, and the framework is validated on a complex 3D geometry in both Inconel 718 and 316L stainless steel. Results showed that feedforward vector-level laser power scheduling reduced geometric inaccuracy in key dimensions by 62%, overall porosity by 16.5%, and photodiode variation by 6.8% on average. Overall, this modular, data-efficient approach demonstrates that proactively compensating for known thermal effects can significantly improve part quality while remaining computationally efficient and readily extensible to other materials and machines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.12557v1</guid>
      <category>cs.CE</category>
      <category>physics.app-ph</category>
      <pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Nicholas Kirschbaum, Nathaniel Wood, Chang-Eun Kim, Thejaswi U. Tumkur, Chinedum Okwudire</dc:creator>
    </item>
    <item>
      <title>IDS-Net: A novel framework for few-shot photovoltaic power prediction with interpretable dynamic selection and feature information fusion</title>
      <link>https://arxiv.org/abs/2507.12745</link>
      <description>arXiv:2507.12745v1 Announce Type: new 
Abstract: With the growing demand for renewable energy, countries are accelerating the construction of photovoltaic (PV) power stations. However, accurately forecasting power data for newly constructed PV stations is extremely challenging due to limited data availability. To this end, we propose a novel interpretable dynamic selection network (IDS-Net) based on feature information fusion to achieve accurate few-shot prediction. This transfer learning framework primarily consists of two parts. In the first stage, we pre-train on the large dataset, utilizing Maximum Mean Discrepancy (MMD) to select the source domain dataset most similar to the target domain data distribution. Subsequently, the ReliefF algorithm is utilized for feature selection, reducing the influence of feature redundancy. Then, the Hampel Identifier (HI) is used for training dataset outlier correction. In the IDS-Net model, we first obtain the initial extracted features from a pool of predictive models. Following this, two separate weighting channels are utilized to determine the interpretable weights for each sub-model and the adaptive selection outcomes, respectively. Subsequently, the extracted feature results from each sub-model are multiplied by their corresponding weights and then summed to obtain the weighted extracted features. Then, we perform cross-embedding on the additional features and fuse them with the extracted weighted features. This fused information is then passed through the MLP (Multi-Layer Perceptron) layer to obtain predictions. In the second stage, we design an end-to-end adaptive transfer learning strategy to obtain the final prediction results on the target dataset. We validate the transfer learning process using two PV power datasets from Hebei province, China, to demonstrate the effectiveness and generalization of our framework and transfer learning strategy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.12745v1</guid>
      <category>cs.CE</category>
      <pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hang Fan, Weican Liu, Zuhan Zhang, Ying Lu, Wencai Run, Dunnan Liu</dc:creator>
    </item>
    <item>
      <title>Quantum-Enhanced Reinforcement Learning with LSTM Forecasting Signals for Optimizing Fintech Trading Decisions</title>
      <link>https://arxiv.org/abs/2507.12835</link>
      <description>arXiv:2507.12835v1 Announce Type: new 
Abstract: Financial trading environments are characterized by high volatility, numerous macroeconomic signals, and dynamically shifting market regimes, where traditional reinforcement learning methods often fail to deliver breakthrough performance. In this study, we design a reinforcement learning framework tailored for financial systems by integrating quantum circuits. We compare (1) the performance of classical A3C versus quantum A3C algorithms, and (2) the impact of incorporating LSTM-based predictions of the following week's economic trends on learning outcomes. The experimental framework adopts a custom Gymnasium-compatible trading environment, simulating discrete trading actions and evaluating rewards based on portfolio feedback. Experimental results show that quantum models - especially when combined with predictive signals - demonstrate superior performance and stability under noisy financial conditions, even with shallow quantum circuit depth.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.12835v1</guid>
      <category>cs.CE</category>
      <pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yen-Ku Liu, Yun-Huei Pan, Pei-Fan Lu, Yun-Cheng Tsai, Samuel Yen-Chi Chen</dc:creator>
    </item>
    <item>
      <title>Agentar-DeepFinance-300K: A Large-Scale Financial Dataset via Systematic Chain-of-Thought Synthesis Optimization</title>
      <link>https://arxiv.org/abs/2507.12901</link>
      <description>arXiv:2507.12901v1 Announce Type: new 
Abstract: Recent advancements in large language models (LLMs) have demonstrated remarkable general reasoning capabilities, holding significant potential for applications in the financial domain, a field that requires robust and reliable reasoning. It has been demonstrated that distilling high-quality chain-of-thought (CoT) rationales from advanced general reasoning models offers a promising and efficient path to the financial reasoning model. However, existing CoT synthesis methods suffer from shallow CoT sampling, leaving the question of how to construct a well-designed knowledge space for finance reasoning unexplored. In this paper, we present \textbf{Agentar-DeepFinance-300K }, a large-scale financial reasoning dataset characterized by its systematic CoT synthesis optimization. We first introduce a comprehensive CoT synthesis pipeline featuring Multi-perspective Knowledge Extraction (MKE) and Self-Corrective Rewriting (SCR) to generate exhaustive and deep financial reasoning trajectories. Furthermore, a systematic investigation, termed CoT Cube, is conducted to analyze critical factors that influence CoT effectiveness, such as necessity, length and synthesizer, yielding valuable insights for high-quality financial CoT construction. Experiments demonstrate that models trained on our Agentar-DeepFinance-300K achieve significant improvements on financial benchmarks. We publicly release Agentar-DeepFinance-300K , hoping to advance the research in financial reasoning models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.12901v1</guid>
      <category>cs.CE</category>
      <pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaoke Zhao, Zhaowen Zhou, Lin Chen, Lihong Wang, Zhiyi Huang, Kaiyuan Zheng, Yanjun Zheng, Xiyang Du, Longfei Liao, Jiawei Liu, Xiang Qi, Bo Zhang, Peng Zhang, Zhe Li, Wei Wang</dc:creator>
    </item>
    <item>
      <title>To What Extent Can Public Equity Indices Statistically Hedge Real Purchasing Power Loss in Compounded Structural Emerging-Market Crises? An Explainable ML-Based Assessment</title>
      <link>https://arxiv.org/abs/2507.13055</link>
      <description>arXiv:2507.13055v1 Announce Type: new 
Abstract: This study investigates the extent to which local public equity indices can statistically hedge real purchasing power loss during compounded structural macro-financial collapses in emerging markets. We employ a non-linear multiplicative real return calculations consistent with Fisher-parity logics for both domestic and foreign investors with a principled quantile regression, tail dependence copula analysis, and Shapley Additive Explanations (SHAP) to assess the explanatory power of macro variables. The analysis focuses on three recent and data-accessible exemplary collapse episodes: Turkey (2018), Nigeria (2020), and Pakistan (2021). Such cases, selected to align with post-2018 improvements in data standardization and crisis comparability, span varied monetary regimes and crisis triggers. Our tail-focused modeling reveals a systematic breakdown in public-equity-based purchasing power protection precisely during simultaneous macroeconomic and monetary dislocations when such protection is most needed. The findings call into question conventional inflation and devaluation hedge presumptions in equity pricing theory, emphasizing the limitations of equity-based protection and the need for context-sensitive strategies during compounded macro-financial distress.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.13055v1</guid>
      <category>cs.CE</category>
      <pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Artem Alkhamov, Boris Kriuk</dc:creator>
    </item>
    <item>
      <title>Kodezi Chronos: A Debugging-First Language Model for Repository-Scale, Memory-Driven Code Understanding</title>
      <link>https://arxiv.org/abs/2507.12482</link>
      <description>arXiv:2507.12482v1 Announce Type: cross 
Abstract: Large Language Models (LLMs) have advanced code generation and software automation, but are fundamentally constrained by limited inference-time context and lack of explicit code structure reasoning. We introduce Kodezi Chronos, a next-generation architecture for autonomous code understanding, debugging, and maintenance, designed to operate across ultra-long contexts comprising entire codebases, histories, and documentation, all without fixed window limits. Kodezi Chronos leverages a multi-level embedding memory engine, combining vector and graph-based indexing with continuous code-aware retrieval. This enables efficient and accurate reasoning over millions of lines of code, supporting repository-scale comprehension, multi-file refactoring, and real-time self-healing actions. Our evaluation introduces a novel Multi Random Retrieval benchmark, specifically tailored to the software engineering domain. Unlike classical retrieval benchmarks, this method requires the model to resolve arbitrarily distant and obfuscated associations across code artifacts, simulating realistic tasks such as variable tracing, dependency migration, and semantic bug localization. Chronos outperforms prior LLMs and code models, demonstrating a 23% improvement in real-world bug detection and reducing debugging cycles by up to 40% compared to traditional sequence-based approaches. By natively interfacing with IDEs and CI/CD workflows, Chronos enables seamless, autonomous software maintenance, elevating code reliability and productivity while reducing manual effort. These results mark a critical advance toward self-sustaining, continuously optimized software ecosystems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.12482v1</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ishraq Khan, Assad Chowdary, Sharoz Haseeb, Urvish Patel</dc:creator>
    </item>
    <item>
      <title>RONOM: Reduced-Order Neural Operator Modeling</title>
      <link>https://arxiv.org/abs/2507.12814</link>
      <description>arXiv:2507.12814v1 Announce Type: cross 
Abstract: Time-dependent partial differential equations are ubiquitous in physics-based modeling, but they remain computationally intensive in many-query scenarios, such as real-time forecasting, optimal control, and uncertainty quantification. Reduced-order modeling (ROM) addresses these challenges by constructing a low-dimensional surrogate model but relies on a fixed discretization, which limits flexibility across varying meshes during evaluation. Operator learning approaches, such as neural operators, offer an alternative by parameterizing mappings between infinite-dimensional function spaces, enabling adaptation to data across different resolutions. Whereas ROM provides rigorous numerical error estimates, neural operator learning largely focuses on discretization convergence and invariance without quantifying the error between the infinite-dimensional and the discretized operators. This work introduces the reduced-order neural operator modeling (RONOM) framework, which bridges concepts from ROM and operator learning. We establish a discretization error bound analogous to those in ROM, and get insights into RONOM's discretization convergence and discretization robustness. Moreover, two numerical examples are presented that compare RONOM to existing neural operators for solving partial differential equations. The results demonstrate that RONOM using standard vector-to-vector neural networks achieves comparable performance in input generalization and superior performance in both spatial super-resolution and discretization robustness, while also offering novel insights into temporal super-resolution scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.12814v1</guid>
      <category>cs.LG</category>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sven Dummer, Dongwei Ye, Christoph Brune</dc:creator>
    </item>
    <item>
      <title>Model-free Forecasting of Rogue Waves using Reservoir Computing</title>
      <link>https://arxiv.org/abs/2506.21918</link>
      <description>arXiv:2506.21918v2 Announce Type: replace 
Abstract: Recent research has demonstrated Reservoir Computing's capability to model various chaotic dynamical systems, yet its application to Hamiltonian systems remains relatively unexplored. This paper investigates the effectiveness of Reservoir Computing in capturing rogue wave dynamics from the nonlinear Schr\"{o}dinger equation, a challenging Hamiltonian system with modulation instability. The model-free approach learns from breather simulations with five unstable modes. A properly tuned parallel Echo State Network can predict dynamics from two distinct testing datasets. The first set is a continuation of the training data, whereas the second set involves a higher-order breather. An investigation of the one-step prediction capability shows remarkable agreement between the testing data and the models. Furthermore, we show that the trained reservoir can predict the propagation of rogue waves over a relatively long prediction horizon, despite facing unseen dynamics. Finally, we introduce a method to significantly improve the Reservoir Computing prediction in autonomous mode, enhancing its long-term forecasting ability. These results advance the application of Reservoir Computing to spatio-temporal Hamiltonian systems and highlight the critical importance of phase space coverage in the design of training data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.21918v2</guid>
      <category>cs.CE</category>
      <category>nlin.PS</category>
      <pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.cnsns.2025.109087</arxiv:DOI>
      <arxiv:journal_reference>CNSNS, Volume 152, Part A, January 2026, 109087</arxiv:journal_reference>
      <dc:creator>Abrari Noor Hasmi, Hadi Susanto</dc:creator>
    </item>
  </channel>
</rss>
