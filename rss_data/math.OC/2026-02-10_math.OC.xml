<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 11 Feb 2026 02:54:18 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Constrained optimal impulse control and inventory model</title>
      <link>https://arxiv.org/abs/2602.07178</link>
      <description>arXiv:2602.07178v1 Announce Type: new 
Abstract: In this article, we consider the deterministic impulsively controlled system with infinite horizon and several discounted objective functionals. The constructed optimal control problem with functional constraints is reformulated as a Markov decision process, leading to (primal) convex and linear programs in the space of so-called occupation measures. We construct the dual programs and investigate the solvability of all the programs. Example of an inventory model illustrates the developed theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07178v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>A. Piunovskiy</dc:creator>
    </item>
    <item>
      <title>Primal-dual algorithm for distributed optimization: A dissipativity-based perspective</title>
      <link>https://arxiv.org/abs/2602.07196</link>
      <description>arXiv:2602.07196v1 Announce Type: new 
Abstract: We study a continuous-time primal-dual algorithm for distributed optimization with nonconvex local cost functions over weight-unbalanced digraphs, and analyze its performance from a dissipativity-based perspective. We first reformulate the algorithm as a Lure type system, consisting of a linear subsystem that relies on the communication topology and the algorithm gains, and a static nonlinear gradient feedback. We then show that the linear subsystem is dissipative with respect to a suitable supply rate, while the nonlinear feedback is not passive. Finally, we establish that, by properly selecting the gains or appropriately designing the communication network, this algorithm converges to an equilibrium at an exponential rate, and thus, achieves an optimal solution to the distributed problem. This work provides new insights into the roles of the network topology, algorithm gains, and cost functions in the performance of a distributed algorithm, and complements existing results from a different viewpoint.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07196v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weijian Li, Panos J. Antsaklis, Hai Lin</dc:creator>
    </item>
    <item>
      <title>Dynamic Interval Scheduling with Random Start and End Times</title>
      <link>https://arxiv.org/abs/2602.07217</link>
      <description>arXiv:2602.07217v1 Announce Type: new 
Abstract: We study sequential interval scheduling when task start and end times are random. The set of tasks and their weights are known in advance, while each task's start and end times are drawn from known discrete distributions and revealed only upon commitment; this also eliminates tasks that conflict with the committed task, and remaining tasks are those that do not conflict. The objective is to maximize the expected weight of a conflict-free schedule. We propose two models that differ in how conflicts are enforced, develop LP relaxations and bounds for each, and present a computational study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07217v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rui Gong, Alejandro Toriello</dc:creator>
    </item>
    <item>
      <title>Solving contextual chance-constrained programming under decision-dependent uncertainty</title>
      <link>https://arxiv.org/abs/2602.07286</link>
      <description>arXiv:2602.07286v1 Announce Type: new 
Abstract: We study contextual chance-constrained programming under decision-dependent uncertainty. In this setting, a decision not only needs to satisfy constraints but also alters the distribution of uncertain outcomes. This dependency makes the problem particularly difficult: because feasibility probabilities vary with decisions, it creates both statistical endogeneity and computational intractability. To address this, we propose a nonparametric approximation method based on Contextual Cluster Weights (CCW). For any given decision and context, CCW constructs a local neighborhood (cluster) of ``similar" historical observations and assigns them equal weight. This approach successfully renders both the objective and chance constraints tractable, while providing uniform-in-decision consistency guarantees. Furthermore, we develop reformulations that use pre-calculated clusters. We show that under a specific nestedness condition, these reformulations yield a convex feasible region, which allows for efficient solving. Experiments, including a case study with JD.com, demonstrate that our method outperforms benchmarks in solution quality, feasibility reliability, and runtime. This framework offers a scalable and data-driven approach for firms to make reliable operational decisions when their actions influence uncertainty. It effectively balances performance, risk, and robustness, while remaining interpretable and implementable in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07286v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Xiangting Liu, Shengran Wang, Kaile Yan, Zhi-Hai Zhang</dc:creator>
    </item>
    <item>
      <title>On the Necessity of Two-Stage Estimation for Learning Dynamical Systems under Both Noise and Node-Wise Attacks</title>
      <link>https://arxiv.org/abs/2602.07288</link>
      <description>arXiv:2602.07288v1 Announce Type: new 
Abstract: The least-squares estimator has achieved considerable success in learning linear dynamical systems from a single trajectory of length $T$. While it attains an optimal error of $\mathcal{O}(1/\sqrt{T})$ under independent zero-mean noise, it lacks robustness and is particularly susceptible to adversarial corruption. In this paper, we consider the identification of a networked system in which every node is subject to both noise and adversarial attacks. We assume that every node is independently corrupted with probability smaller than $0.5$ at each time, placing the overall system under almost-persistent local attack. We first show that no convex one-stage estimator can achieve a consistent estimate as $T$ grows under both noise and attacks. This motivates the development of a two-stage estimation method applied across nodes. In Stage I, we leverage the $\ell_1$-norm estimator and derive an estimation error bound proportional to the noise level $\sigma_w$. This bound is subsequently used to detect and filter out attacks, producing a clean dataset for each node, to which we apply the least-squares estimator in Stage II. The resulting estimation error is on the order $\mathcal{O}(1/\sqrt{T})$ plus the product of $\sigma_w$ and the number of misclassifications. In the event of perfect separability between attack and non-attack data, which occurs when injected attacks are sufficiently large relative to the noise scale, our two-stage estimator is consistent for the true system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07288v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jihun Kim, Javad Lavaei</dc:creator>
    </item>
    <item>
      <title>On Information Controls</title>
      <link>https://arxiv.org/abs/2602.07318</link>
      <description>arXiv:2602.07318v1 Announce Type: new 
Abstract: In this paper we study an optimization problem in which the control is information, more precisely, the control is a $\sigma$-algebra or a filtration. In a dynamic setting, assuming a condition slightly stronger than the (H)-hypothesis for the admissible filtration, we establish the dynamic programming principle and the law invariance of the value function. The latter enables us to define the value function on $\mathcal P_2(\mathcal P_2(\mathbb R^d))$, the space of laws of random probability measures. By using a new It\^o's formula for smooth functions on $\mathcal P_2(\mathcal P_2(\mathbb R^d))$, we characterize the value function of the information control problem through an Hamilton-Jacobi-Bellman equation on this space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07318v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zihao Gu, Jianfeng Zhang</dc:creator>
    </item>
    <item>
      <title>Partial Exponential Turnpike Phenomenon in Linear-Convex Optimal Control</title>
      <link>https://arxiv.org/abs/2602.07476</link>
      <description>arXiv:2602.07476v1 Announce Type: new 
Abstract: This paper studies the long-time behavior of optimal solutions for a class of linear-convex optimal control problems. We focus on a partial exponential turnpike property, established without imposing controllability or stabilizability assumptions, where the turnpike behavior holds only for a subset of initial states. By means of a refined decomposition of the completely uncontrollable dynamics, we derive necessary structural conditions for the turnpike property and explicitly characterize the set of feasible initial states. For each such initial state, we associate a static optimization problem whose unique solution determines the corresponding steady state-control pair. For a class of convex stage cost functions, we prove the partial exponential turnpike property and quantify the convergence rate of the averaged finite-horizon optimal cost toward the steady optimal value.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07476v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jingrui Sun, Lvning Yuan</dc:creator>
    </item>
    <item>
      <title>A Taylor-Bernstein Inner Approximation Algorithm for Path-Constrained Dynamic Optimization</title>
      <link>https://arxiv.org/abs/2602.07507</link>
      <description>arXiv:2602.07507v1 Announce Type: new 
Abstract: A novel inner approximation algorithm is proposed for dynamic optimization problems to ensure strict satisfaction of path constraints. Distinct from traditional methods relying on interval analysis, the proposed algorithm leverages the convex hull property of Bernstein polynomials to tightly bound the polynomial components of the Taylor expansion, while incorporating the Log-Sum-Exp technique to smooth the non-differentiability arising from coefficient maximization. This approach yields a tighter upper bound function compared to interval methods, with a smaller approximation error. Theoretical analysis shows that the algorithm converges in a finite number of steps to a KKT solution of the original problem that satisfies the specified tolerances. Numerical simulations confirm that the proposed algorithm effectively reduces the number of constraints in the approximation problem, improving computational performance while ensuring strict feasibility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07507v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yuan Chang, Lizhong Jiang, Tai-Fang Li, Jun Fu</dc:creator>
    </item>
    <item>
      <title>Mathematical model for sustainable fisheries resource management accounting for size spectrum</title>
      <link>https://arxiv.org/abs/2602.07511</link>
      <description>arXiv:2602.07511v1 Announce Type: new 
Abstract: This paper proposes a novel modelling and control framework for growth models that incorporate a size spectrum in conjunction with numerical computation and extensive field surveys. In fisheries management, the size spectrum, characterized by individual differences in body weight and length, is a critical factor, as it influences the physiology and ecology of fish, as well as the preferences of anglers. However, a comprehensive theoretical framework for fisheries modelling and management that accounts for the size spectrum has yet to be established. We apply a growth model that considers the size spectrum to Plecoglossus altivelis altivelis (Ayu), an important inland fisheries resource in Japan. Additionally, we introduce a novel stochastic control theory for the resource management of Ayu, taking its size spectrum into account. The growth model is calibrated using data collected annually from a river system in Japan. Our control problem addresses the size spectrum of fishing benefits and terminal utility (nonlinear expectation) for sustainability, resulting in a nonstandard problem to which the dynamic programming principle does not apply. We address this difficulty using a time-inconsistent formalism, where solving the control problem is reduced to finding an appropriate solution to a system of nonlinear partial differential equations. We numerically compute the system using the finite difference method and explore the fisheries management of Ayu at the study site.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07511v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hidekazu Yoshioka, Yumi Yoshioka, Motoh Tsujimura, Ayumi Hashiguchi</dc:creator>
    </item>
    <item>
      <title>Averaged Controllability of Time-Fractional Schr\"odinger Equations with Random Quantum Diffusivity</title>
      <link>https://arxiv.org/abs/2602.07514</link>
      <description>arXiv:2602.07514v1 Announce Type: new 
Abstract: This paper addresses the problem of averaged controllability for the time-fractional Schrodinger equation, where the quantum diffusivity parameter is a random variable with a general probability distribution. First, by exploiting the analyticity of the Mittag-Leffler function and Muntz's theorem, we show that the simultaneous null controllability of the system can occur only for a countable set of realizations of the random diffusivity. In particular, this implies the impossibility of simultaneous null controllability for absolutely continuous random diffusivity. Next, we prove the lack of exact averaged controllability for absolutely continuous random variables, irrespective of the control time. Furthermore, we introduce a new two-parameter fractional characteristic function, which allows us to construct a class of random variables satisfying null averaged controllability at any time from any arbitrary sensor set of positive Lebesgue measure. This is achieved using an open-loop control belonging to L^\infty and independent of the random parameter. In particular, we obtain the null controllability of the fractional biharmonic diffusion equation. Finally, we conclude with several remarks and open problems that merit future investigation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07514v1</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jon Asier B\'arcena-Petisco, Salah-Eddine Chorfi, Fouad Et-tahri, Lahcen Maniar</dc:creator>
    </item>
    <item>
      <title>A Two-Layer Framework for Joint Online Configuration Selection and Admission Control</title>
      <link>https://arxiv.org/abs/2602.07663</link>
      <description>arXiv:2602.07663v1 Announce Type: new 
Abstract: We study online configuration selection with admission control problem, which arises in LLM serving, GPU scheduling, and revenue management. In a planning horizon with $T$ periods, we consider a two-layer framework for the decisions made within each time period. In the first layer, the decision maker selects one of the $K$ configurations (ex. quantization, parallelism, fare class) which induces distribution over the reward-resource pair of the incoming request. In the second layer, the decision maker observes the request and then decides whether to accept it or not.
  Benchmarking this framework requires care. We introduce a \textbf{switching-aware fluid oracle} that accounts for the value of mixing configurations over time, provably upper-bounding any online policy. We derive a max-min formulation for evaluating the benchmark, and we characterize saddle points of the max-min problem via primal-dual optimality conditions linking equilibrium, feasibility, and complementarity. This guides the design of \textbf{SP-UCB--OLP} algorithm, which solves an optimistic saddle point problem and achieves $\tilde{O}(\sqrt{KT})$ regret.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07663v1</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Owen Shen, Haoran Xu, Yinyu Ye, Peter Glynn, Patrick Jaillet</dc:creator>
    </item>
    <item>
      <title>Structure Preserving Approximation of Semiconcave Functions</title>
      <link>https://arxiv.org/abs/2602.07770</link>
      <description>arXiv:2602.07770v1 Announce Type: new 
Abstract: This article addresses structure-preserving smooth approximation of semiconcave functions. semiconcave functions are of particular interest because they naturally arise in a variety of variational problems, including {optimal feedback control, game theory, and optimal transport}. We leverage the fact that any semiconcave function can be represented as the {infimum of a countable family of \(C^2\) functions}. This infimum is expressed in a form that allows {approximation by finitely many functions}, combined with {smoothing operations}, such that each element of the approximating sequence remains semiconcave. The {active sets of indices} contributing to the representation of the semiconcave function and its approximations are analyzed in detail. Moreover, we show that the {gradients of the elements in the expansion of the approximating functions form a probability distribution}, a property of particular interest for the {value function in optimal control}. Approximation results are established in \(C(\bar \Omega)\) and in \(W^{1,p}(\Omega)\) for \(p \in [1,\infty)\) and \(p = \infty\). Finally, {numerical results} are presented to illustrate the approach on a test example.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07770v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Karl Kunisch, Donato V\'asquez-Varas</dc:creator>
    </item>
    <item>
      <title>Optimal Control of Unbounded Stochastic Evolution Systems in Hilbert Spaces</title>
      <link>https://arxiv.org/abs/2602.07793</link>
      <description>arXiv:2602.07793v1 Announce Type: new 
Abstract: Optimal control and the associated second-order Hamilton-Jacobi-Bellman (HJB) equation are studied for unbounded stochastic evolution systems in Hilbert spaces. A new notion of viscosity solution, featured by absence of B-continuity, is introduced for the second-order HJB equation in the sense of Crandall and Lions, and is shown to coincide with the classical solutions and to satisfy a stability property. The value functional is proved to be the unique continuous viscosity solution to the second-order HJB equation, with the coefficients being not necessarily B-continuous. Our result provides a new theory of viscosity solutions to the HJB equation for optimal control of stochastic evolutionary equations-driven by a linear unbounded operator-in a Hilbert space, and removes the B-continuity assumption on the coefficients which is used in the existing literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07793v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shanjian Tang, Jianjun Zhou</dc:creator>
    </item>
    <item>
      <title>Biquadratic SOS Rank: Sum of Squares Decompositions and Rank Bounds for Biquadratic Forms</title>
      <link>https://arxiv.org/abs/2602.07844</link>
      <description>arXiv:2602.07844v1 Announce Type: new 
Abstract: We prove that every $3 \times 3$ sum-of-squares (SOS) biquadratic form can be expressed as the sum of at most \textbf{six} squares of bilinear forms, establishing $\mathrm{BSR}(3,3) = 6$. We also determine the exact SOS rank for $4 \times 3$ biquadratic forms: $\mathrm{BSR}(4,3)=7$. These results fit the pattern $\mathrm{BSR}(m,n)=m+n$, leading to the conjecture that this linear formula holds for all $m,n \ge 3$. Furthermore, we extend our geometric-analytic method to general dimensions and show that for any integers $m,n \ge 2$ with $(m,n)\neq(2,2)$, every $m \times n$ SOS biquadratic form is a sum of at most $mn-2$ squares, improving the general upper bound of $mn-1$ established in earlier work. For the $3 \times 3$ case, we provide a complete geometric analysis of the SOS cone structure, and for general dimensions we establish a systematic framework that applies to all $m \times n$ biquadratic forms except the degenerate $(2,2)$ case.
  We note that the lower bound of 6 for $3 \times 3$ forms is achieved by a simple biquadratic form, and for general $m,n\ge 3$, it is known that the maximum SOS rank is at least $m+n$. Our results establish new upper bounds and significantly reduce the gap between the lower and upper bounds for the worst-case SOS rank of biquadratic forms across all dimensions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07844v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chunfeng Cui, Liqun Qi, Yi Xu</dc:creator>
    </item>
    <item>
      <title>Best Approximation Optimal Control for Infeasible Double Integrator and Douglas--Rachford Algorithm</title>
      <link>https://arxiv.org/abs/2602.07851</link>
      <description>arXiv:2602.07851v1 Announce Type: new 
Abstract: We consider the problem of finding (in some sense) the best approximation control for an infeasible double integrator. The control function is constrained by upper and lower bounds that are too tight and thus cause infeasibility. The infeasibility is characterized by a gap function (representing the separation between two constraint sets) whose squared ${\cal L}^2$-norm is to be minimized to find the best approximation control solution. First, we review the existing results for problems involving a general linear control system. Then, for the infeasible double integrator problem, we present an analytical solution for the bang--bang control with at most one switching. The infinite-dimensional optimization problem is reduced to the problem of solving two algebraic equations in two variables, to compute the switching time and gap function. We discuss numerical approaches to solving the system of equations. Finally, we describe the (relaxed) Douglas--Rachford algorithm for the double integrator problem and carry out numerical experiments to illustrate the implementation of the algorithm and test performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07851v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Regina S. Burachik, Bethany I. Caldwell, C. Yal\c{c}{\i}n Kaya, Walaa M. Moursi</dc:creator>
    </item>
    <item>
      <title>Consistent inverse optimal control for infinite time-horizon discounted nonlinear systems under noisy observations</title>
      <link>https://arxiv.org/abs/2602.07874</link>
      <description>arXiv:2602.07874v1 Announce Type: new 
Abstract: Inverse optimal control (IOC) aims to estimate the underlying cost that governs the observed behavior of an expert system. However, in practical scenarios, the collected data is often corrupted by noise, which poses significant challenges for accurate cost function recovery. In this work, we propose an IOC framework that effectively addresses the presence of observation noise. In particular, compared to our previous work \cite{wang2025consistent}, we consider the case of discrete-time, infinite-horizon, discounted MDPs whose transition kernel is only weak Feller. By leveraging the occupation measure framework, we first establish the necessary and sufficient optimality conditions for the expert policy and then construct an infinite dimensional optimization problem based on these conditions. This problem is then approximated by polynomials to get a finite-dimensional numerically solvable one, which relies on the moments of the state-action trajectory's occupation measure. More specifically, the moments are robustly estimated from the noisy observations by a combined misspecified Generalized Method of Moments (GMM) estimator derived from observation model and system dynamics. Consequently, the entire algorithm is based on convex optimization which alleviates the issues that arise from local minima and is asymptotically and statistically consistent. Finally, the performance of the proposed method is illustrated through numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07874v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ziliang Wang, Axel Ringh, Han Zhang</dc:creator>
    </item>
    <item>
      <title>Complexity of Projected Gradient Methods for Strongly Convex Optimization with H\"older Continuous Gradient Terms</title>
      <link>https://arxiv.org/abs/2602.07961</link>
      <description>arXiv:2602.07961v1 Announce Type: new 
Abstract: This paper studies the complexity of projected gradient descent methods for a class of strongly convex constrained optimization problems where the objective function is expressed as a summation of $m$ component functions, each possessing a gradient that is H\"older continuous with an exponent $\alpha_i \in (0, 1]$. Under this formulation, the gradient of the objective function may fail to be globally H\"older continuous, thereby rendering existing complexity results inapplicable to this class of problems. Our theoretical analysis reveals that, in this setting, the complexity of projected gradient methods is determined by $\hat{\alpha} = \min_{i \in \{1, \dotsc, m\}} \alpha_i$. We first prove that, with an appropriately fixed stepsize, the complexity bound for finding an approximate minimizer with a distance to the true minimizer less than $\varepsilon$ is $O (\log (\varepsilon^{-1}) \varepsilon^{2 (\hat{\alpha} - 1) / (1 + \hat{\alpha})})$, which extends the well-known complexity result for $\hat{\alpha} = 1$. Next we show that the complexity bound can be improved to $O (\log (\varepsilon^{-1}) \varepsilon^{2 (\hat{\alpha} - 1) / (1 + 3 \hat{\alpha})})$ if the stepsize is updated by the universal scheme. We illustrate our complexity results by numerical examples arising from elliptic equations with a non-Lipschitz term.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07961v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaojun Chen, C. T. Kelley, Lei Wang</dc:creator>
    </item>
    <item>
      <title>Leader-following Consensus over Jointly Connected Switching Networks is Achievable for Exponentially Unstable Linear Systems</title>
      <link>https://arxiv.org/abs/2602.07975</link>
      <description>arXiv:2602.07975v1 Announce Type: new 
Abstract: The leader-following consensus problem for general linear multi-agent systems over jointly connected switching networks has been a challenging problem and the solvability of the problem has been limited to the class of linear multi-agent systems whose system matrix is marginally stable. This condition is restrictive since it even excludes the most commonly used double-integrator system. This paper presents a breakthrough by demonstrating that leader-following exponential consensus is achievable for general linear multi-agent systems over jointly connected switching networks, even when the system matrix is exponentially unstable. The degree of instability can be explicitly characterized by two key quantities that arise from the jointly connected condition on a switching graph. By exploiting duality, we further show that the output-based distributed observer design problem for a general leader system is solvable over jointly connected switching networks, even when the system matrix is exponentially unstable. This is also in sharp contrast to the existing distributed observers, which rely on the assumption that the leader system is marginally stable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07975v1</guid>
      <category>math.OC</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuhan Chen, Tao Liu, Jie Huang</dc:creator>
    </item>
    <item>
      <title>Sinkhorn Distributionally Robust State Estimation via System Level Synthesis</title>
      <link>https://arxiv.org/abs/2602.08018</link>
      <description>arXiv:2602.08018v1 Announce Type: new 
Abstract: In state estimation tasks, the usual assumption of exactly known disturbance distribution is often unrealistic and renders the estimator fragile in practice. The recently emerging Wasserstein distributionally robust state estimation (DRSE) design can partially mitigate this fragility; however, its worst-case distribution is provably discrete, which deviates from the inherent continuity of real-world distributions and results in over-pessimism. In this work, we develop a new Sinkhorn DRSE design within system level synthesis scheme with the aim of shaping the closed-loop errors under the unknown continuous disturbance distribution. For uncertainty description, we adopt the Sinkhorn ambiguity set that includes an entropic regularizer to penalize non-smooth and discrete distributions within a Wasserstein ball. We present the first result of finite-sample probabilistic guarantee of the Sinkhorn ambiguity set. Then we analyze the limiting properties of our Sinkhorn DRSE design, thereby highlighting its close connection with the generic $\mathcal{H}_2$ design and Wasserstein DRSE. To tackle the min-max optimization problem, we reformulate it as a finite-dimensional convex program through duality theory. By identifying a compact subset of the feasible set guaranteed to enclose the global optimum, we develop a tailored Frank-Wolfe solution algorithm and formally establish its convergence rate. The advantage of Sinkhorn DRSE over existing design schemes is verified through numerical case studies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08018v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yulin Feng, Xianyu Li, Steven X. Ding, Hao Ye, Chao Shang</dc:creator>
    </item>
    <item>
      <title>Approximate Controllability of Nonlocal Stochastic Integrodifferential System in Hilbert Spaces</title>
      <link>https://arxiv.org/abs/2602.08066</link>
      <description>arXiv:2602.08066v1 Announce Type: new 
Abstract: This project investigates the approximate controllability of a class of stochastic integrodifferential equations in Hilbert space with non-local beginning conditions. In a departure from the conventional concerns expressed in the literature, we will not consider compactness or the Lipschitz criteria concerning the nonlocal term. We use the fact that the resolvent operator is compact. We first prove the controllability of the nonlinear system using Schauder's fixed point theorem, a method known for its robustness; as well, we also use Grimmer's resolvent operator theory. Subsequently, we employ the reliable approximation methods and the powerful diagonal argument to determine the approximate controllability of the stochastic system. To conclude, we present an example that validates our theoretical statement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08066v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.sysconle.2025.106122</arxiv:DOI>
      <arxiv:journal_reference>Systems &amp; Control Letters, 2025</arxiv:journal_reference>
      <dc:creator>Mamadou Pathe LY, Ravikumar Kasinathan, Ramkumar Kasinathan, Dimplekumar Chalishajar, Mamadou Abdoul Diop</dc:creator>
    </item>
    <item>
      <title>Skip the Hessian, Keep the Rates: Globalized Semismooth Newton with Lazy Hessian Updates</title>
      <link>https://arxiv.org/abs/2602.08069</link>
      <description>arXiv:2602.08069v1 Announce Type: new 
Abstract: Second-order methods are provably faster than first-order methods, and their efficient implementations for large-scale optimization problems have attracted significant attention. Yet, optimization problems in ML often have nonsmooth derivatives, which makes the existing convergence rate theory of second-order methods inapplicable. In this paper, we propose a new semismooth Newton method (SSN) that enjoys both global convergence rates and asymptotic superlinear convergence without requiring second-order differentiability. Crucially, our method does not require (generalized) Hessians to be evaluated at each iteration but only periodically, and it reuses stale Hessians otherwise (i.e., it performs lazy Hessian updates), saving compute cost and often leading to significant speedups in time, whilst still maintaining strong global and local convergence rate guarantees. We develop our theory in an infinite-dimensional setting and illustrate it with numerical experiments on matrix factorization and neural networks with Lipschitz constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08069v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amal Alphonse, Pavel Dvurechensky, Clemens Sirotenko</dc:creator>
    </item>
    <item>
      <title>Reinforcement Learning Method for Zero-Sum Linear-Quadratic Stochastic Differential Games in Infinite Horizons</title>
      <link>https://arxiv.org/abs/2602.08075</link>
      <description>arXiv:2602.08075v1 Announce Type: new 
Abstract: In this work, we propose, for the first time, a reinforcement learning framework specifically designed for zero-sum linear-quadratic stochastic differential games. This approach offers a generalized solution for scenarios in which accurate system parameters are difficult to obtain, thereby overcoming a key limitation of traditional iterative methods that rely on complete system information. In correspondence with the game-theoretic algebraic Riccati equations associated with the problem, we develop both semi-model-based and model-free reinforcement learning algorithms by combining an iterative solution scheme with dynamic programming principles. Notably, under appropriate rank conditions on data sampling, the convergence of the proposed algorithms is rigorously established through theoretical analysis. Finally, numerical simulations are conducted to verify the effectiveness and feasibility of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08075v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yiyuan Wang</dc:creator>
    </item>
    <item>
      <title>Constrained Pricing under Finite Mixtures of Logit</title>
      <link>https://arxiv.org/abs/2602.08119</link>
      <description>arXiv:2602.08119v1 Announce Type: new 
Abstract: The mixed logit model is a flexible and widely used demand model in pricing and revenue management. However, existing work on mixed-logit pricing largely focuses on unconstrained settings, limiting its applicability in practice where prices are subject to business or regulatory constraints. We study the constrained pricing problem under multinomial and mixed logit demand models. For the multinomial logit model, corresponding to a single customer segment, we show that the constrained pricing problem admits a polynomial-time approximation scheme (PTAS) via a reformulation based on exponential cone programming, yielding an $\varepsilon$-optimal solution in polynomial time. For finite mixed logit models with $T$ customer segments, we reformulate the problem as a bilinear exponential cone program with $O(T)$ bilinear terms. This structure enables a Branch-and-Bound algorithm whose complexity is exponential only in $T$. Consequently, constrained pricing under finite mixtures of logit admits a PTAS when the number of customer segments is bounded. Numerical experiments demonstrate strong performance relative to state-of-the-art baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08119v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hoang Giang Pham, Tien Mai</dc:creator>
    </item>
    <item>
      <title>On Busemann subgradient methods for stochastic minimization in Hadamard spaces</title>
      <link>https://arxiv.org/abs/2602.08127</link>
      <description>arXiv:2602.08127v1 Announce Type: new 
Abstract: We study the recently introduced Busemann subgradient method due to Goodwin, Lewis, Nicolae and L\'opez-Acedo, extending it to minimize the mean of a stochastic function over general Hadamard spaces. We prove a strong convergence theorem under a local compactness assumption and further prove weak ergodic convergence of the method over Hadamard spaces satisfying condition $(\overline{Q}_4)$, a slight extension of the $(Q_4)$ condition of Kirk and Payanak, which in particular includes Hilbert spaces, $\mathbb{R}$-trees and spaces of constant curvature. The proof is based on a general (weak) convergence theorem for stochastic processes in Hadamard spaces which confine to a stochastic variant of quasi-Fej\'er monotonicity, together with a nonlinear variant of Pettis' theorem, which are of independent interest. Lastly, we provide a strong convergence result under a strong convexity assumption, and in that case in particular derive explicit rates of convergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08127v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicholas Pischke</dc:creator>
    </item>
    <item>
      <title>Robust design optimization for a nonlinear system via Bayesian neural network enhanced polynomial dimensional decomposition</title>
      <link>https://arxiv.org/abs/2602.08161</link>
      <description>arXiv:2602.08161v1 Announce Type: new 
Abstract: Uncertainties such as manufacturing tolerances cause performance variations in complex engineering systems, making robust design optimization (RDO) essential. However, simulation-based RDO faces high computational cost for statistical moment estimation, and strong nonlinearity limits the accuracy of conventional surrogate models. This study proposes a novel RDO method that integrates Bayesian neural networks (BNN) with polynomial dimensional decomposition (PDD). The method employs uncertainty-based active learning to enhance BNN surrogate accuracy and a multi-point single-step strategy that partitions the design space into dynamically adjusted subregions, within which PDD analytically estimates statistical moments from BNN predictions. Validation through a mathematical benchmark and an electric motor shape optimization demonstrates that the method converges to robust optimal solutions with significantly fewer function evaluations. In the ten-dimensional benchmark, the proposed method achieved a 99.97% mean reduction, while Gaussian process-based and Monte Carlo approaches failed to locate the global optimum. In the motor design problem, the method reduced cogging torque by 94.75% with only 6644 finite element evaluations, confirming its computational efficiency for high-dimensional, strongly nonlinear engineering problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08161v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hyunho Jang, Dongjin Lee</dc:creator>
    </item>
    <item>
      <title>Implicit regularization of normalized gradient descent</title>
      <link>https://arxiv.org/abs/2602.08177</link>
      <description>arXiv:2602.08177v1 Announce Type: new 
Abstract: How to find flat minima? We propose running normalized gradient descent, usually reserved for nonsmooth optimization, with sufficiently slowly diminishing step sizes. This induces implicit regularization towards flat minima if an appropriate Lyapunov functions exists in the gradient dynamics. Our analysis shows that implicit regularization is intrinsically a question of nonsmooth analysis, for which we deploy the full power of variational analysis and stratification theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08177v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>C\'edric Josz</dc:creator>
    </item>
    <item>
      <title>Adaptive Matrix Online Learning through Smoothing with Guarantees for Nonsmooth Nonconvex Optimization</title>
      <link>https://arxiv.org/abs/2602.08232</link>
      <description>arXiv:2602.08232v1 Announce Type: new 
Abstract: We study online linear optimization with matrix variables constrained by the operator norm, a setting where the geometry renders designing data-dependent and efficient adaptive algorithms challenging. The best-known adaptive regret bounds are achieved by Shampoo-like methods, but they require solving a costly quadratic projection subproblem. To address this, we extend the gradient-based prediction scheme to adaptive matrix online learning and cast algorithm design as constructing a family of smoothed potentials for the nuclear norm. We define a notion of admissibility for such smoothings and prove any admissible smoothing yields a regret bound matching the best-known guarantees of one-sided Shampoo. We instantiate this framework with two efficient methods that avoid quadratic projections. The first is an adaptive Follow-the-Perturbed-Leader (FTPL) method using Gaussian stochastic smoothing. The second is Follow-the-Augmented-Matrix-Leader (FAML), which uses a deterministic hyperbolic smoothing in an augmented matrix space. By analyzing the admissibility of these smoothings, we show both methods admit closed-form updates and match one-sided Shampoo's regret up to a constant factor, while significantly reducing computational cost. Lastly, using the online-to-nonconvex conversion, we derive two matrix-based optimizers, Pion (from FTPL) and Leon (from FAML). We prove convergence guarantees for these methods in nonsmooth nonconvex settings, a guarantee that the popular Muon optimizer lacks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08232v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruichen Jiang, Zakaria Mhammedi, Mehryar Mohri, Aryan Mokhtari</dc:creator>
    </item>
    <item>
      <title>Testing Backward-Flatness of Nonlinear Discrete-Time Systems</title>
      <link>https://arxiv.org/abs/2602.08385</link>
      <description>arXiv:2602.08385v1 Announce Type: new 
Abstract: Despite ongoing research, testing the flatness of discrete-time systems remains a challenging problem. To date, only the property of forward-flatness - a special case of difference-flatness - can be checked in a computationally efficient manner. In this paper, we propose a systematic approach for testing backward-flatness, which is another special case of difference-flatness, and for deriving a corresponding backward-flat output. Additionally, we discuss the relationship between the Jacobian matrices associated with the flat parameterization of backward- and forward-flat systems and illustrate our results by an academic example.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08385v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Johannes Schrotshamer, Bernd Kolar, Markus Sch\"oberl</dc:creator>
    </item>
    <item>
      <title>Constructive conditional normalizing flows</title>
      <link>https://arxiv.org/abs/2602.08606</link>
      <description>arXiv:2602.08606v1 Announce Type: new 
Abstract: Motivated by applications in conditional sampling, given a probability measure $\mu$ and a diffeomorphism $\phi$, we consider the problem of simultaneously approximating $\phi$ and the pushforward $\phi_{\#}\mu$ by means of the flow of a continuity equation whose velocity field is a perceptron neural network with piecewise constant weights. We provide an explicit construction based on a polar-like decomposition of the Lagrange interpolant of $\phi$. The latter involves a compressible component, given by the gradient of a particular convex function, which can be realized exactly, and an incompressible component, which -- after approximating via permutations -- can be implemented through shear flows intrinsic to the continuity equation. For more regular maps $\phi$ -- such as the Kn\"othe-Rosenblatt rearrangement -- we provide an alternative, probabilistic construction inspired by the Maurey empirical method, in which the number of discontinuities in the weights doesn't scale inversely with the ambient dimension.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08606v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>math.AP</category>
      <category>math.PR</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Borjan Geshkovski, Dom\`enec Ruiz-Balet</dc:creator>
    </item>
    <item>
      <title>Nesterov's accelerated gradient for unbounded convex functions finds the minimum-norm point in the dual space</title>
      <link>https://arxiv.org/abs/2602.08618</link>
      <description>arXiv:2602.08618v1 Announce Type: new 
Abstract: We study the behavior of first-order methods applied to a lower-unbounded convex function $f$, i.e., $\inf f = -\infty$. Such a setting has received little attention since the trajectories of gradient descent and Nesterov's accelerated gradient method diverge. In this paper, we establish quantitative convergence results describing their speeds and directions of divergence, with implications for unboundedness judgment. A key idea is a relation to a norm-minimization problem in the dual space: minimize $\|p\|^2/2$ over $p \in \mathrm{dom}f^\ast$, which can be naturally solved via mirror descent by taking the Legendre--Fenchel conjugate $f^\ast$ as the distance-generating function. It then turns out that gradient descent for $f$ coincides with mirror descent for this norm-minimization problem, and thus it simultaneously solves both problems at $\mathcal{O}(k^{-1})$. This result admits acceleration; Nesterov's accelerated gradient method, without any modifications, simultaneously solves the original minimization and the dual norm-minimization problems at $\mathcal{O}(k^{-2})$, providing a quantitative characterization of divergence in unbounded convex optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08618v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Keiya Sakabe</dc:creator>
    </item>
    <item>
      <title>Heterogeneous Distributed Zeroth-Order Nonconvex Optimization with Communication Compression</title>
      <link>https://arxiv.org/abs/2602.08659</link>
      <description>arXiv:2602.08659v1 Announce Type: new 
Abstract: Distributed zeroth-order optimization is increasingly applied in heterogeneous scenarios where agents possess distinct data distributions and objectives. This heterogeneity poses fundamental challenges for convergence analysis, as existing convergence analyses rely on relatively strong assumptions to ensure theoretical guarantees. Specifically, at least one of the following three assumptions is usually required: (i) data homogeneity across agents, (ii) $\mathcal{O}(pn)$ function evaluations per iteration with $p$ denoting the dimension and $n$ the number of agents, or (iii) the Polyak--{\L}ojasiewicz (P--L) or strong convexity condition with a known corresponding constant. To overcome these limitations, we propose a Heterogeneous Distributed Zeroth-Order Compressed (HEDZOC) algorithm, which is based on a two-point zeroth-order gradient estimator and a general class of compressors. Without assuming data homogeneity, we develop the analysis covering three settings: general nonconvex functions, functions satisfying the P--L condition without knowing the P--L constant, and those with a known constant. To the best of our knowledge, the proposed HEDZOC algorithm is the first distributed zeroth-order method that establishes convergence without relying on the above three assumptions. Moreover, it achieves linear speedup convergence rate, which is comparable to state-of-the-art results attainable under data homogeneity and exact communication assumptions. Finally, experiments on heterogeneous adversarial example generation validate the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08659v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haonan Wang, Xinlei Yi, Yiguang Hong, Minghui Liwang</dc:creator>
    </item>
    <item>
      <title>Branch-Price-and-Cut Accelerated with a Pricing for Integrality Heuristic for the Electrical Vehicle Routing Problem with Time Windows and Charging Time Slots</title>
      <link>https://arxiv.org/abs/2602.08673</link>
      <description>arXiv:2602.08673v2 Announce Type: new 
Abstract: Branch-price-and-cut is the state-of-the-art exact method for solving many types of vehicle routing problems, and is particularly effective for vehicle routing problems with time windows. A well-known challenge in branch-price-and-cut is that the generation of columns is guided by information from the linear relaxation of the master problem, with no guarantee that they will be useful from an integer perspective. As a consequence, high-quality primal solutions are often found only after significant cutting and branching or the use of primal heuristics. In this work, based on the ideas of pricing for integrality, we propose a new primal heuristic for vehicle routing problems. The heuristic is designed to generate columns that are more likely to be part of high-quality integer solutions. It begins by constructing a partial integer solution from a given column pool and then iteratively searches for columns that complement this solution. The search is done by modifying the pricing problem with respect to the partial solution, linear program dual information as well as previously generated columns in the heuristic. Computational tests are performed on the electrical vehicle routing problem with time windows extended with charging time slots, a problem that has both scheduling and routing aspects, making it well-suited to evaluate the performance of the proposed heuristic. The results show that the proposed heuristic closes 30% - 40% of the root node gap on average in comparison to a restricted master heuristic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08673v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lukas Eveborn, Elina R\"onnberg</dc:creator>
    </item>
    <item>
      <title>Switching Point Optimization for Abstract Parabolic Equations</title>
      <link>https://arxiv.org/abs/2602.08906</link>
      <description>arXiv:2602.08906v1 Announce Type: new 
Abstract: This work is concerned with a switching point optimization problem governed by a semilinear parabolic equation in abstract function spaces. It is shown that the switching-point-to-control mapping is continuously Fr\'echet-differentiable when considered with values in the dual of H\"older continuous functions in time. By treating the state equation in weak form based on the concept of maximal parabolic regularity, one can then show that the reduced objective is continuously differentiable w.r.t.\ the switching points which allows to use gradient-based method like the proximal gradient method for its minimization. In order to apply the known convergence results of this method, the gradient of the reduced objective must be Lipschitz continuous, which requires additional assumptions on the data. Numerical experiments confirm our theoretical findings, but also illustrate that such a method will in general not be able to solve the problem up to global optimality due to the non-convex nature of the switching-point-to-control map.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08906v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Christian Meyer, Alimhan Musalatov</dc:creator>
    </item>
    <item>
      <title>Sensitivity analysis of the perturbed utility stochastic traffic equilibrium</title>
      <link>https://arxiv.org/abs/2409.08347</link>
      <description>arXiv:2409.08347v4 Announce Type: cross 
Abstract: This paper develops a sensitivity analysis framework for the perturbed utility route choice (PURC) model and the accompanying stochastic traffic equilibrium model. We derive analytical sensitivity expressions for the Jacobian of the individual optimal PURC flow and equilibrium link flows with respect to link cost parameters under general assumptions. This allows us to determine the marginal change in link flows following a marginal change in link costs across the network. We show how to implement these results while exploiting the sparsity generated by the PURC model. Numerical examples illustrate the use of our method for estimating equilibrium link flows after link cost shifts, identifying critical design parameters, and quantifying uncertainty in performance predictions. Finally, we demonstrate the method in a large-scale example. The findings have implications for network design, pricing strategies, and policy analysis in transportation planning and economics, providing a bridge between theoretical models and real-world applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08347v4</guid>
      <category>econ.EM</category>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mogens Fosgerau, Nikolaj Nielsen, Mads Paulsen, Thomas Kj{\ae}r Rasmussen, Rui Yao</dc:creator>
    </item>
    <item>
      <title>Convex Dominance in Deep Learning I: A Scaling Law of Loss and Learning Rate</title>
      <link>https://arxiv.org/abs/2602.07145</link>
      <description>arXiv:2602.07145v1 Announce Type: cross 
Abstract: Deep learning has non-convex loss landscape and its optimization dynamics is hard to analyze or control. Nevertheless, the dynamics can be empirically convex-like across various tasks, models, optimizers, hyperparameters, etc. In this work, we examine the applicability of convexity and Lipschitz continuity in deep learning, in order to precisely control the loss dynamics via the learning rate schedules. We illustrate that deep learning quickly becomes weakly convex after a short period of training, and the loss is predicable by an upper bound on the last iterate, which further informs the scaling of optimal learning rate. Through the lens of convexity, we build scaling laws of learning rates and losses that extrapolate as much as 80X across training horizons and 70X across model sizes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07145v1</guid>
      <category>cs.LG</category>
      <category>cs.CL</category>
      <category>math.OC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhiqi Bu, Shiyun Xu, Jialin Mao</dc:creator>
    </item>
    <item>
      <title>Multifidelity sensor placement in Bayesian state estimation problems</title>
      <link>https://arxiv.org/abs/2602.07269</link>
      <description>arXiv:2602.07269v1 Announce Type: cross 
Abstract: We study optimal sensor placement for Bayesian state estimation problems in which sensors vary in cost and fidelity, resulting in a budget-constrained multifidelity optimal experimental design problem. Sensor placement optimality is quantified using the D-optimality criterion, and the problem is approached by leveraging connections with the column subset selection problem in numerical linear algebra. We implement a greedy approach for this problem, whose computational efficiency we improve using rank-one updates via the Sherman-Morrison formula. We additionally present an iterative algorithm that, for each feasible allocation of sensors, greedily optimizes over each sensor fidelity subject to previous sensor choices, repeating this process until a termination criterion is satisfied. To the best of our knowledge, these algorithms are novel in the context of cost constrained multifidelity sensor placement. We evaluate our methods on several benchmark state estimation problems, including reconstructions of sea surface temperature and flow around a cylinder, and empirically demonstrate improved performance over random designs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07269v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gabriela Ramon, Geena Sarnoski, Vasishta Tumuluri, Hugo D\'iaz, Arvind K. Saibaba</dc:creator>
    </item>
    <item>
      <title>Sign-Based Optimizers Are Effective Under Heavy-Tailed Noise</title>
      <link>https://arxiv.org/abs/2602.07425</link>
      <description>arXiv:2602.07425v1 Announce Type: cross 
Abstract: While adaptive gradient methods are the workhorse of modern machine learning, sign-based optimization algorithms such as Lion and Muon have recently demonstrated superior empirical performance over AdamW in training large language models (LLM). However, a theoretical understanding of why sign-based updates outperform variance-adapted methods remains elusive. In this paper, we aim to bridge the gap between theory and practice through the lens of heavy-tailed gradient noise, a phenomenon frequently observed in language modeling tasks. Theoretically, we introduce a novel generalized heavy-tailed noise condition that captures the behavior of LLMs more accurately than standard finite variance assumptions. Under this noise model, we establish sharp convergence rates of SignSGD and Lion for generalized smooth function classes, matching or surpassing previous best-known bounds. Furthermore, we extend our analysis to Muon and Muonlight, providing what is, to our knowledge, the first rigorous analysis of matrix optimization under heavy-tailed stochasticity. These results offer a strong theoretical justification for the empirical superiority of sign-based optimizers, showcasing that they are naturally suited to handle the noisy gradients associated with heavy tails. Empirically, LLM pretraining experiments validate our theoretical insights and confirm that our proposed noise models are well-aligned with practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07425v1</guid>
      <category>cs.LG</category>
      <category>cs.CL</category>
      <category>math.OC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dingzhi Yu, Hongyi Tao, Yuanyu Wan, Luo Luo, Lijun Zhang</dc:creator>
    </item>
    <item>
      <title>Bandit Allocational Instability</title>
      <link>https://arxiv.org/abs/2602.07472</link>
      <description>arXiv:2602.07472v1 Announce Type: cross 
Abstract: When multi-armed bandit (MAB) algorithms allocate pulls among competing arms, the resulting allocation can exhibit huge variation. This is particularly harmful in modern applications such as learning-enhanced platform operations and post-bandit statistical inference. Thus motivated, we introduce a new performance metric of MAB algorithms termed allocation variability, which is the largest (over arms) standard deviation of an arm's number of pulls. We establish a fundamental trade-off between allocation variability and regret, the canonical performance metric of reward maximization. In particular, for any algorithm, the worst-case regret $R_T$ and worst-case allocation variability $S_T$ must satisfy $R_T \cdot S_T=\Omega(T^{\frac{3}{2}})$ as $T\rightarrow\infty$, as long as $R_T=o(T)$. This indicates that any minimax regret-optimal algorithm must incur worst-case allocation variability $\Theta(T)$, the largest possible scale; while any algorithm with sublinear worst-case regret must necessarily incur ${S}_T= \omega(\sqrt{T})$. We further show that this lower bound is essentially tight, and that any point on the Pareto frontier $R_T \cdot S_T=\tilde{\Theta}(T^{3/2})$ can be achieved by a simple tunable algorithm UCB-f, a generalization of the classic UCB1. Finally, we discuss implications for platform operations and for statistical inference, when bandit algorithms are used. As a byproduct of our result, we resolve an open question of Praharaj and Khamaru (2025).</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07472v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yilun Chen, Jiaqi Lu</dc:creator>
    </item>
    <item>
      <title>ODELoRA: Training Low-Rank Adaptation by Solving Ordinary Differential Equations</title>
      <link>https://arxiv.org/abs/2602.07479</link>
      <description>arXiv:2602.07479v1 Announce Type: cross 
Abstract: Low-rank adaptation (LoRA) has emerged as a widely adopted parameter-efficient fine-tuning method in deep transfer learning, due to its reduced number of trainable parameters and lower memory requirements enabled by Burer-Monteiro factorization on adaptation matrices. However, classical LoRA training methods treat the low-rank factor matrices individually and optimize them using standard gradient-based algorithms. Such decoupled optimization schemes are theoretically and empirically suboptimal, as they fail to fully exploit the intrinsic structure of the LoRA parameterization. In this work, we propose a novel continuous-time optimization dynamic for LoRA factor matrices in the form of an ordinary differential equation (ODE) that emulates the gradient flow of full fine-tuning on the balanced manifold. We term this approach ODELoRA. To faithfully track the trajectories of ODELoRA, we adopt well-established and theoretically grounded time-discretization schemes, including Euler and Runge--Kutta methods. Our framework provides a unified ODE-based perspective for understanding and designing LoRA training algorithms. We establish linear convergence of the proposed method under strongly convex objectives for certain discretization schemes under mild conditions, and further extend our analysis to the matrix sensing setting. Moreover, we show that ODELoRA achieves stable feature learning, a property that is crucial for training deep neural networks at different scales of problem dimensionality. Empirical results on matrix sensing tasks confirm the derived linear convergence behavior, and experiments on training physics-informed neural networks further demonstrate the superiority of ODELoRA over existing baselines, especially in the training stability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07479v1</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yihang Gao, Vincent Y. F. Tan</dc:creator>
    </item>
    <item>
      <title>Low-distortion planar embedding of rod-based structures</title>
      <link>https://arxiv.org/abs/2602.07789</link>
      <description>arXiv:2602.07789v1 Announce Type: cross 
Abstract: Rod-based structures are commonly used in practical applications in science and engineering. However, in many design, analysis, and manufacturing tasks, handling the rod-based structures in three dimensions directly is generally challenging. To simplify the tasks, it is usually more desirable to achieve a two-dimensional representation of the rod-based structures via some suitable geometric mappings. In this work, we develop a novel method for computing a low-distortion planar embedding of rod-based structures. Specifically, we identify geometrical constraints that aim to preserve key length and angle quantities of the 3D rod-based structures and prevent the occurrence of overlapping rods in the planar embedding. Experimental results with a variety of rod-based structures are presented to demonstrate the effectiveness of our approach. Moreover, our method can be naturally extended to the design and mapping of hybrid structures consisting of both rods and surface elements. Altogether, our approach paves a new way for the efficient design and fabrication of novel three-dimensional geometric structures for practical applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07789v1</guid>
      <category>cs.CG</category>
      <category>math.OC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mark Yan Lok Yip, Gary P. T. Choi</dc:creator>
    </item>
    <item>
      <title>Optimized Human-Robot Co-Dispatch Planning for Petro-Site Surveillance under Varying Criticalities</title>
      <link>https://arxiv.org/abs/2602.07924</link>
      <description>arXiv:2602.07924v1 Announce Type: cross 
Abstract: Securing petroleum infrastructure requires balancing autonomous system efficiency with human judgment for threat escalation, a challenge unaddressed by classical facility location models assuming homogeneous resources. This paper formulates the Human-Robot Co-Dispatch Facility Location Problem (HRCD-FLP), a capacitated facility location variant incorporating tiered infrastructure criticality, human-robot supervision ratio constraints, and minimum utilization requirements. We evaluate command center selection across three technology maturity scenarios. Results show transitioning from conservative (1:3 human-robot supervision) to future autonomous operations (1:10) yields significant cost reduction while maintaining complete critical infrastructure coverage. For small problems, exact methods dominate in both cost and computation time; for larger problems, the proposed heuristic achieves feasible solutions in under 3 minutes with approximately 14% optimality gap where comparison is possible. From systems perspective, our work demonstrate that optimized planning for human-robot teaming is key to achieve both cost-effective and mission-reliable deployments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.07924v1</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nur Ahmad Khatim, Mansur Arief</dc:creator>
    </item>
    <item>
      <title>Observability properties of the singular Grushin equation</title>
      <link>https://arxiv.org/abs/2602.08044</link>
      <description>arXiv:2602.08044v1 Announce Type: cross 
Abstract: We study the observability properties of the Grushin equation with an inverse square potential, whose singularity occurs at the boundary of two-dimensional rectangular domains or in the interior of the domain in higher dimensions. In some specific configurations of the observation set, we obtain the exact minimal time of observability. The analysis we present relies on recent Carleman estimates obtained by K. Beauchard, J. Dard\'e, and S. Ervedoza. As a byproduct of these results, we observe, for the heat equation associated to the Laplace-Beltrami operator on almost-Riemannian manifolds, a dependence of the minimal time of observability on the dimension of the singularity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08044v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Roman Vanlaere</dc:creator>
    </item>
    <item>
      <title>Schr\"odinger bridge with transport relaxation</title>
      <link>https://arxiv.org/abs/2602.08118</link>
      <description>arXiv:2602.08118v1 Announce Type: cross 
Abstract: Motivated by modern machine learning applications where we only have access to empirical measures constructed from finite samples, we relax the marginal constraints of the classical Schr\"odinger bridge problem by penalizing the transport cost between the bridge's marginals and the prescribed marginals. We derive a duality formula for this transport-relaxed bridge and demonstrate that it reduces to a finite-dimensional concave optimization problem when the prescribed marginals are discrete and the reference distribution is absolutely continuous. We establish the existence and uniqueness of solutions for both the primal and dual problems. Moreover, as the penalty blows up, we characterize the limiting bridge as the solution to a discrete Schr\"odinger bridge problem and identify a leading-order logarithmic divergence. Finally, we propose gradient ascent and Sinkhorn-type algorithms to numerically solve the transport-relaxed Schr\"odinger bridge, establishing a linear convergence rate for both algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08118v1</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yifan Jiang, Renyuan Xu, Luhao Zhang</dc:creator>
    </item>
    <item>
      <title>Efficient $k$-Sign Consistency Verification of Hankel Matrices via Schur Polynomials</title>
      <link>https://arxiv.org/abs/2602.08122</link>
      <description>arXiv:2602.08122v1 Announce Type: cross 
Abstract: We consider the problem of certifying (strict) $k$-sign consistency of a matrix, that is, whether all of its $k$-th order minors share the same (strict) sign. Although this problem is generally of combinatorial complexity, we show that for Hankel matrices it can be significantly simplified: our sufficient condition requires checking only the $k$-th order minors of a reshaped Hankel matrix with $k$ rows. Remarkably, when applied to the Hankel operator, this sufficient condition is also necessary. Comparable results were known only in the setting of (strictly) $k$-positive Hankel matrices and operators, in which all minors of order up to $k$ have the same (strict) sign.
  More concretely, we derive a formula expressing the $k$-th order minors of Hankel matrices as nonnegative integer linear combinations of $k$-th order minors with consecutive row indices. Our derivation uses Schur polynomial theory to show that the $k$-th order minors of any matrix are nonnegative integer linear combinations of row-consecutive $k$-th order minors, meaning minors formed from distinct columns whose consecutive row indices need not coincide across columns. For Hankel matrices, these minors coincide -- up to sign changes arising from column swaps -- with the usual $k$-th order minors with consecutive row indices. Our main result then follows by showing that the sum of certain signed nonnegative integer coefficients equals the corresponding Littlewood--Richardson coefficients. In our problem, the nonnegativity of these coefficients ensures that negatively signed column permutations are cancelled by positively signed ones. Our results also extend naturally to Toeplitz matrices and operators, and we present a partial analogue for circulant matrices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08122v1</guid>
      <category>math.CO</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <category>math.RT</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Christian Grussler, Tobias Damm</dc:creator>
    </item>
    <item>
      <title>Dynamic Regret via Discounted-to-Dynamic Reduction with Applications to Curved Losses and Adam Optimizer</title>
      <link>https://arxiv.org/abs/2602.08372</link>
      <description>arXiv:2602.08372v1 Announce Type: cross 
Abstract: We study dynamic regret minimization in non-stationary online learning, with a primary focus on follow-the-regularized-leader (FTRL) methods. FTRL is important for curved losses and for understanding adaptive optimizers such as Adam, yet existing dynamic regret analyses are less explored for FTRL. To address this, we build on the discounted-to-dynamic reduction and present a modular way to obtain dynamic regret bounds of FTRL-related problems. Specifically, we focus on two representative curved losses: linear regression and logistic regression. Our method not only simplifies existing proofs for the optimal dynamic regret of online linear regression, but also yields new dynamic regret guarantees for online logistic regression. Beyond online convex optimization, we apply the reduction to analyze the Adam optimizers, obtaining optimal convergence rates in stochastic, non-convex, and non-smooth settings. The reduction also enables a more detailed treatment of Adam with two discount parameters $(\beta_1,\beta_2)$, leading to new results for both clipped and clip-free variants of Adam optimizers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08372v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yan-Feng Xie, Yu-Jie Zhang, Peng Zhao, Zhi-Hua Zhou</dc:creator>
    </item>
    <item>
      <title>UAV-Supported Maritime Search System: Experience from Valun Bay Field Trials</title>
      <link>https://arxiv.org/abs/2602.08450</link>
      <description>arXiv:2602.08450v1 Announce Type: cross 
Abstract: This paper presents the integration of flow field reconstruction, dynamic probabilistic modeling, search control, and machine vision detection in a system for autonomous maritime search operations. Field experiments conducted in Valun Bay (Cres Island, Croatia) involved real-time drifter data acquisition, surrogate flow model fitting based on computational fluid dynamics and numerical optimization, advanced multi-UAV search control and vision sensing, as well as deep learning-based object detection. The results demonstrate that a tightly coupled approach enables reliable detection of floating targets under realistic uncertainties and complex environmental conditions, providing concrete insights for future autonomous maritime search and rescue applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08450v1</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Stefan Ivi\'c, Luka Lan\v{c}a, Karlo Jakac, Ante Sikirica, Stella Dumen\v{c}i\'c, Matej Mali\v{s}a, Zvonimir Mrle, Bojan Crnkovi\'c</dc:creator>
    </item>
    <item>
      <title>A Machine Learning Enabled MDO for Bio-Inspired Autonomous Underwater Gliders</title>
      <link>https://arxiv.org/abs/2602.08508</link>
      <description>arXiv:2602.08508v1 Announce Type: cross 
Abstract: The preliminary design of AUGs is intrinsically challenging due to the strong coupling between the external hydrodynamic shape, the hydrostatic balance, the structural integrity, and internal packaging constraints. This complexity is further amplified for bio-inspired configurations, whose rich geometric parametrizations lead to high-dimensional design spaces that are difficult to explore using conventional optimization approaches. This work presents a ML-enabled bi-level multidisciplinary design optimization (MDO) framework for the performance-driven design of a manta-ray-inspired AUG. At the upper level, hydrodynamically efficient external geometries are explored in a reduced design space obtained through physics-driven parametric model embedding, which identifies a low-dimensional latent representation directly correlated with the lift, drag, and pressure distributions. At the lower level, a constrained internal sizing problem determines the minimum feasible empty weight by accounting for structural, hydrostatic, geometric, and payload constraints. To render the resulting bi-level problem computationally tractable, a multi-fidelity surrogate-based optimization strategy is adopted, combining low- and high-fidelity hydrodynamic models with stochastic radial basis function surrogates and adaptive Bayesian sampling. The framework enables efficient exploration of the coupled design space while rigorously managing model uncertainty and computational cost. The optimized configurations exhibit a 14.7\% improvement in maximum hydrodynamic efficiency and a 12.8\% reduction in empty weight relative to the baseline design, while satisfying all disciplinary constraints. These results demonstrate that the integration of physics-driven dimensionality reduction and multi-fidelity machine learning enables scalable and physically consistent MDO of complex bio-inspired underwater vehicles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08508v1</guid>
      <category>cs.CE</category>
      <category>math.OC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrea Serani, Giorgio Palma, Jeroen Wackers, Matteo Diez</dc:creator>
    </item>
    <item>
      <title>Do physics-informed neural networks (PINNs) need to be deep? Shallow PINNs using the Levenberg-Marquardt algorithm</title>
      <link>https://arxiv.org/abs/2602.08515</link>
      <description>arXiv:2602.08515v1 Announce Type: cross 
Abstract: This work investigates the use of shallow physics-informed neural networks (PINNs) for solving forward and inverse problems of nonlinear partial differential equations (PDEs). By reformulating PINNs as nonlinear systems, the Levenberg-Marquardt (LM) algorithm is employed to efficiently optimize the network parameters. Analytical expressions for the neural network derivatives with respect to the input variables are derived, enabling accurate and efficient computation of the Jacobian matrix required by LM. The proposed approach is tested on several benchmark problems, including the Burgers, Schr\"odinger, Allen-Cahn, and three-dimensional Bratu equations. Numerical results demonstrate that LM significantly outperforms BFGS in terms of convergence speed, accuracy, and final loss values, even when using shallow network architectures with only two hidden layers. These findings indicate that, for a wide class of PDEs, shallow PINNs combined with efficient second-order optimization methods can provide accurate and computationally efficient solutions for both forward and inverse problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08515v1</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>cs.NE</category>
      <category>math.OC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Muhammad Luthfi Shahab, Imam Mukhlash, Hadi Susanto</dc:creator>
    </item>
    <item>
      <title>Automatic regularization parameter choice for tomography using a double model approach</title>
      <link>https://arxiv.org/abs/2602.08528</link>
      <description>arXiv:2602.08528v2 Announce Type: cross 
Abstract: Image reconstruction in X-ray tomography is an ill-posed inverse problem, particularly with limited available data. Regularization is thus essential, but its effectiveness hinges on the choice of a regularization parameter that balances data fidelity against a priori information. We present a novel method for automatic parameter selection based on the use of two distinct computational discretizations of the same problem. A feedback control algorithm dynamically adjusts the regularization strength, driving an iterative reconstruction toward the smallest parameter that yields sufficient similarity between reconstructions on the two grids. The effectiveness of the proposed approach is demonstrated using real tomographic data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08528v2</guid>
      <category>cs.CV</category>
      <category>math.OC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chuyang Wu, Samuli Siltanen</dc:creator>
    </item>
    <item>
      <title>Quantum Riemannian Cubics with Obstacle Avoidance for Quantum Geometric Model Predictive Control</title>
      <link>https://arxiv.org/abs/2602.08881</link>
      <description>arXiv:2602.08881v1 Announce Type: cross 
Abstract: We propose a geometric model predictive control framework for quantum systems subject to smoothness and state constraints. By formulating quantum state evolution intrinsically on the projective Hilbert space, we penalize covariant accelerations to generate smooth trajectories in the form of Riemannian cubics, while incorporating state-dependent constraints through potential functions. A structure-preserving variational discretization enables receding-horizon implementation, and a Lyapunov-type stability result is established for the closed-loop system. The approach is illustrated on the Bloch sphere for a two-level quantum system, providing a viable pathway toward predictive feedback control of constrained quantum dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08881v1</guid>
      <category>math-ph</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.MP</category>
      <category>math.OC</category>
      <category>quant-ph</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Leonardo Colombo</dc:creator>
    </item>
    <item>
      <title>Accelerated Stabilization of Switched Linear MIMO Systems using Generalized Homogeneity</title>
      <link>https://arxiv.org/abs/2602.08903</link>
      <description>arXiv:2602.08903v1 Announce Type: cross 
Abstract: This paper addresses the problem of exponential and accelerated finite-time, as well as nearly fixed-time, stabilization of switched linear MIMO systems. The proposed approach relies on a generalized homogenization framework for switched linear systems and employs implicit Lyapunov functions for control design, covering both common and multiple Lyapunov function settings. Linear matrix equations and inequalities are derived to characterize the dilation generator and to synthesize the controller gains. Robustness of the resulting control laws with respect to system uncertainties and external disturbances is analyzed. The effectiveness of the proposed approach is illustrated through numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08903v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Moussa Labbadi, Andrey Polyakov, Denis Efimov</dc:creator>
    </item>
    <item>
      <title>Reduced-order Control and Geometric Structure of Learned Lagrangian Latent Dynamics</title>
      <link>https://arxiv.org/abs/2602.08963</link>
      <description>arXiv:2602.08963v1 Announce Type: cross 
Abstract: Model-based controllers can offer strong guarantees on stability and convergence by relying on physically accurate dynamic models. However, these are rarely available for high-dimensional mechanical systems such as deformable objects or soft robots. While neural architectures can learn to approximate complex dynamics, they are either limited to low-dimensional systems or provide only limited formal control guarantees due to a lack of embedded physical structure. This paper introduces a latent control framework based on learned structure-preserving reduced-order dynamics for high-dimensional Lagrangian systems. We derive a reduced tracking law for fully actuated systems and adopt a Riemannian perspective on projection-based model-order reduction to study the resulting latent and projected closed-loop dynamics. By quantifying the sources of modeling error, we derive interpretable conditions for stability and convergence. We extend the proposed controller and analysis to underactuated systems by introducing learned actuation patterns. Experimental results on simulated and real-world systems validate our theoretical investigation and the accuracy of our controllers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08963v1</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Katharina Friedl, No\'emie Jaquier, Seungyeon Kim, Jens Lundell, Danica Kragic</dc:creator>
    </item>
    <item>
      <title>ARO: A New Lens On Matrix Optimization For Large Models</title>
      <link>https://arxiv.org/abs/2602.09006</link>
      <description>arXiv:2602.09006v1 Announce Type: cross 
Abstract: Matrix-based optimizers have attracted growing interest for improving LLM training efficiency, with significant progress centered on orthogonalization/whitening based methods. While yielding substantial performance gains, a fundamental question arises: can we develop new paradigms beyond orthogonalization, pushing the efficiency frontier further? We present \textbf{Adaptively Rotated Optimization (ARO}, a new matrix optimization framework that treats gradient rotation as a first class design principle. ARO accelerates LLM training by performing normed steepest descent in a rotated coordinate system, where the rotation is determined by a novel norm-informed policy. This perspective yields update rules that go beyond existing orthogonalization and whitening optimizers, improving sample efficiency in practice. To make comparisons reliable, we propose a rigorously controlled benchmarking protocol that reduces confounding and bias. Under this protocol, ARO consistently outperforms AdamW (by 1.3 $\sim$1.35$\times$) and orthogonalization methods (by 1.1$\sim$1.15$\times$) in LLM pretraining at up to 8B activated parameters, and up to $8\times$ overtrain budget, without evidence of diminishing returns. Finally, we discuss how ARO can be reformulated as a symmetry-aware optimizer grounded in rotational symmetries of residual streams, motivating advanced designs that enable computationally efficient exploitation of cross-layer/cross module couplings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.09006v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenbo Gong, Javier Zazo, Qijun Luo, Puqian Wang, James Hensman, Chao Ma</dc:creator>
    </item>
    <item>
      <title>A Global Optimization Algorithm for K-Center Clustering of One Billion Samples</title>
      <link>https://arxiv.org/abs/2301.00061</link>
      <description>arXiv:2301.00061v3 Announce Type: replace 
Abstract: This paper presents a practical global optimization algorithm for the K-center clustering problem, which aims to select K samples as the cluster centers to minimize the maximum within-cluster distance. This algorithm is based on a reduced-space branch and bound scheme and guarantees convergence to the global optimum in a finite number of steps by only branching on the regions of centers. To improve efficiency, we have designed a two-stage decomposable lower bound, the solution of which can be derived in a closed form. In addition, we also propose several acceleration techniques to narrow down the region of centers, including bounds tightening, sample reduction, and parallelization. Extensive studies on synthetic and real-world datasets have demonstrated that our algorithm can solve the K-center problems to global optimal within 4 hours for ten million samples in the serial mode and one billion samples in the parallel mode. Moreover, compared with the state-of-the-art heuristic methods, the global optimum obtained by our algorithm can averagely reduce the objective function by 25.8% on all the synthetic and real-world datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.00061v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiayang Ren, Ningning You, Kaixun Hua, Chaojie Ji, Yankai Cao</dc:creator>
    </item>
    <item>
      <title>Stochastic Optimization Algorithms for Problems with Controllable Biased Oracles</title>
      <link>https://arxiv.org/abs/2306.07810</link>
      <description>arXiv:2306.07810v4 Announce Type: replace 
Abstract: Motivated by emerging applications in machine learning, we consider an optimization problem in a general form where the gradient of the objective function is available through a biased stochastic oracle. We assume a bias-control parameter can reduce the bias magnitude; however, a lower bias requires more computation/samples. For instance, in two applications on stochastic composition optimization and policy optimization for infinite-horizon Markov decision processes, we show that the bias follows a power law and exponential decay, respectively, as functions of their corresponding bias control parameters. For problems with such gradient oracles, the paper proposes stochastic algorithms that adjust the bias-control parameter throughout the iterations. We analyze the nonasymptotic performance of the proposed algorithms in the nonconvex regime and establish their sample or bias-control computational complexities to obtain a stationary point in expectation or with high probability. Finally, we numerically evaluate the performance of the proposed algorithms over three applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.07810v4</guid>
      <category>math.OC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yin Liu, Sam Davanloo Tajbakhsh</dc:creator>
    </item>
    <item>
      <title>Curve fitting on a quantum annealer for an advanced navigation method</title>
      <link>https://arxiv.org/abs/2402.15308</link>
      <description>arXiv:2402.15308v3 Announce Type: replace 
Abstract: We explore the applicability of quantum annealing to the approximation task of curve fitting. To this end, we consider a function that shall approximate a given set of data points and is written as a finite linear combination of standardized functions, e.g., orthogonal polynomials. Consequently, the decision variables subject to optimization are the coefficients of that expansion. Although this task can be accomplished classically, it can also be formulated as a quadratic unconstrained binary optimization problem, which is suited to be solved with quantum annealing. Given the size of the problem stays below a certain threshold, we find that quantum annealing yields comparable results to the classical solution. Regarding a real-world use case, we discuss the problem to find an optimized speed profile for a vessel using the framework of dynamic programming and outline how the aforementioned approximation task can be put into play. Similar to the curve fitting task, our findings indicate that quantum annealing is currently only feasible if the routing problem is modeled sufficiently small and sparse.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.15308v3</guid>
      <category>math.OC</category>
      <category>quant-ph</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Philipp Isserstedt, Daniel Jaroszewski, Wolfgang Mergenthaler, Felix Paul, Bastian Harrach</dc:creator>
    </item>
    <item>
      <title>Q-Learning under Finite Model Uncertainty</title>
      <link>https://arxiv.org/abs/2407.04259</link>
      <description>arXiv:2407.04259v3 Announce Type: replace 
Abstract: We propose a robust Q-learning algorithm for Markov decision processes under model uncertainty when each state-action pair is associated with a finite ambiguity set of candidate transition kernels. This finite-measure framework enables highly flexible, user-designed uncertainty models and goes beyond the common KL and Wasserstein ball formulations. We establish almost sure convergence of the learned Q-function to the robust optimum, and derive non-asymptotic high-probability error bounds that separate stochastic approximation error from transition-kernel estimation error. Finally, we show that Wasserstein ball and parametric ambiguity sets can be approximated by finite ambiguity sets, allowing our algorithm to be used as a generic solver beyond the finite setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04259v3</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Julian Sester, C\'ecile Decker</dc:creator>
    </item>
    <item>
      <title>Adaptive Algorithms for Robust Phase Retrieval</title>
      <link>https://arxiv.org/abs/2409.19162</link>
      <description>arXiv:2409.19162v2 Announce Type: replace 
Abstract: This paper considers the robust phase retrieval, which can be cast as a nonsmooth and nonconvex composite optimization problem. We propose two first-order algorithms with adaptive step sizes: the subgradient algorithm (AdaSubGrad) and the inexact proximal linear algorithm (AdaIPL). Our contribution lies in the novel design of adaptive step sizes based on quantiles of the absolute residuals. Local linear convergences of both algorithms are analyzed under different regimes for the hyper-parameters. Numerical experiments on synthetic datasets and image recovery also demonstrate that our methods are competitive against the existing methods in the literature utilizing predetermined (possibly impractical) step sizes, such as the subgradient methods and the inexact proximal linear method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19162v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhong Zheng, Necdet Serhat Aybat, Shiqian Ma, Lingzhou Xue</dc:creator>
    </item>
    <item>
      <title>On System Operators with Variation Bounding Properties</title>
      <link>https://arxiv.org/abs/2409.20275</link>
      <description>arXiv:2409.20275v3 Announce Type: replace 
Abstract: The property of linear discrete-time time-invariant system operators mapping inputs with at most $k-1$ sign changes to outputs with at most $k-1$ sign changes is investigated. We show that this property is tractable via the notion of $k$-sign consistency in case of the observability/controllability operator, which as such can also be used as a sufficient condition for the Hankel operator. Our results complement the mathematical literature by providing an algebraic characterization, independent of rank and dimension for variation bounding and diminishing matrices as well as by discussing their computational tractability. Based on these, we conduct our studies of variation bounding system operators beyond existing studies on order-preserving $k$-variation diminishment. Our findings are applied to the open problem of bounding the number of sign changes in a system's impulse response, which appears, e.g., when bounding the number of over- and undershoots in a step response or the number of bangs in bounded optimal control problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.20275v3</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Christian Grussler, Chaim Roth, Kang Tong</dc:creator>
    </item>
    <item>
      <title>Control of the Fisher-Stefan system</title>
      <link>https://arxiv.org/abs/2503.23154</link>
      <description>arXiv:2503.23154v2 Announce Type: replace 
Abstract: This paper addresses the exact controllability of trajectories in the one-dimensional Fisher-Stefan problem--a reaction-diffusion equation that models the spatial propagation of biological, chemical, or physical populations within a free-end domain, governed by Stefan's law. We establish the local exact controllability to the trajectories by reformulating the problem as the local null controllability of a nonlinear system with distributed controls. Our approach leverages the Lyusternik-Graves theorem to achieve local inversion, leading to the desired controllability result. Finally, we illustrate our theoretical findings through several numerical experiments based on the Physics-Informed Neural Networks (PINNs) approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.23154v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Idriss Boutaayamou, Fouad Et-tahri, Lahcen Maniar, Francisco Periago</dc:creator>
    </item>
    <item>
      <title>Discrete-Time Periodic Monotonicity Preserving Systems</title>
      <link>https://arxiv.org/abs/2503.23520</link>
      <description>arXiv:2503.23520v4 Announce Type: replace 
Abstract: Two nested classes of discrete-time linear time-invariant systems, which differ by the set of periodic signals that they leave invariant, are studied. The first class preserves the property of periodic monotonicity (period-wise unimodality). The second class is invariant to signals with at most two sign changes per period, and requires that periodic signals with zero sign changes are mapped to the same kind. Tractable characterizations for each system class are derived by the use and extension of total positivity theory via geometric interpretations. Central to our results is the characterization of sequentially convex contours via consecutive minors.
  Our characterizations also extend to the loop gain of Lur'e feedback systems as the considered signals sets are invariant under common static non-linearities, e.g., ideal relay, saturation, sigmoid function, quantizer, etc. The presented developments aim to form a base for future signal-based fixed-point theorems towards the prediction of self-sustained oscillations. Our examples on relay feedback systems indicate how periodic monotonicity preservation gives rise to useful insights towards this goal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.23520v4</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Christian Grussler</dc:creator>
    </item>
    <item>
      <title>Optimal Non-Asymptotic Rates of Value Iteration for Average-Reward Markov Decision Processes</title>
      <link>https://arxiv.org/abs/2504.09913</link>
      <description>arXiv:2504.09913v2 Announce Type: replace 
Abstract: While there is an extensive body of research on the analysis of Value Iteration (VI) for discounted cumulative-reward MDPs, prior work on analyzing VI for (undiscounted) average-reward MDPs has been limited, and most prior results focus on asymptotic rates in terms of Bellman error. In this work, we conduct refined non-asymptotic analyses of average-reward MDPs, obtaining a collection of convergence results that advance our understanding of the setup. Among our new results, most notable are the $\mathcal{O}(1/k)$-rates of Anchored Value Iteration on the Bellman error under the multichain setup and the span-based complexity lower bound that matches the $\mathcal{O}(1/k)$ upper bound up to a constant factor of $8$ in the weakly communicating and unichain setups</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.09913v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>International Conference on Learning Representations, 2025</arxiv:journal_reference>
      <dc:creator>Jongmin Lee, Ernest K. Ryu</dc:creator>
    </item>
    <item>
      <title>Advancing Averaged Primer Vector Theory with Bang-Bang Control and Eclipsing</title>
      <link>https://arxiv.org/abs/2505.11660</link>
      <description>arXiv:2505.11660v2 Announce Type: replace 
Abstract: Low-thrust, many-revolution spacecraft trajectories are increasingly required for mission design due to the efficiency and reliability of electric propulsion technology. Primer vector theory using averaged dynamics is well suited for such applications, but is difficult to implement in a way that maintains both optimality and computational efficiency. An improved model is presented that combines advances from several past works into a general and practical formulation for minimum-fuel, perturbed Keplerian dynamics. The model maintains computational efficiency of dynamics averaging with optimal handling of the eclipsing constraint and bang-bang control through the use of the Leibniz integral rule for multi-arc averaging. A subtle, but important singularity arising from the averaged eclipsing constraint is identified and fixed. A maximum number of six switching function roots per revolution is established within the averaged dynamics. This new theoretical insight provides a practical upper-bound on the number of thrusting arcs required for any low-thrust optimization problem. Variational equations are provided for fast and accurate calculation of the state transition matrix for use in targeting and optimization. The dynamics include generic two-body perturbations and an expanded state to allow for sensitivity calculations with respect to launch date and flight time. A 48-revolution GTO to GEO transfer is used to directly compare optimal averaged and unaveraged trajectories. The capabilities of averaged dynamics are then demonstrated with an optimal 486-revolution GTO to GEO minimum fuel transfer.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.11660v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.2514/1.G009348</arxiv:DOI>
      <dc:creator>Noah Lifset, Ryan P. Russell</dc:creator>
    </item>
    <item>
      <title>Accelerated Markov Chain Monte Carlo Algorithms on Discrete States</title>
      <link>https://arxiv.org/abs/2505.12599</link>
      <description>arXiv:2505.12599v2 Announce Type: replace 
Abstract: We propose a class of discrete state sampling algorithms based on Nesterov's accelerated gradient method, which extends the classical Metropolis-Hastings (MH) algorithm. The evolution of the discrete states probability distribution governed by MH can be interpreted as a gradient descent direction of the Kullback--Leibler (KL) divergence, via a mobility function and a score function. Specifically, this gradient is defined on a probability simplex equipped with a discrete Wasserstein-2 metric with a mobility function. This motivates us to study a momentum-based acceleration framework using damped Hamiltonian flows on the simplex set, whose stationary distribution matches the discrete target distribution. Furthermore, we design an interacting particle system to approximate the proposed accelerated sampling dynamics. The extension of the algorithm with a general choice of potentials and mobilities is also discussed. In particular, we choose the accelerated gradient flow of the relative Fisher information, demonstrating the advantages of the algorithm in estimating discrete score functions without requiring the normalizing constant and keeping positive probabilities. Numerical examples, including sampling on a Gaussian mixture supported on lattices or a distribution on a hypercube, demonstrate the effectiveness of the proposed discrete-state sampling algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12599v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.CO</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bohan Zhou, Shu Liu, Xinzhe Zuo, Wuchen Li</dc:creator>
    </item>
    <item>
      <title>A Saddle Point Algorithm for Robust Data-Driven Factor Model Problems</title>
      <link>https://arxiv.org/abs/2506.09776</link>
      <description>arXiv:2506.09776v2 Announce Type: replace 
Abstract: We study the factor model problem, which aims to uncover low-dimensional structures in high-dimensional datasets. Adopting a robust data-driven approach, we formulate the problem as a saddle-point optimization. Our primary contribution is a first-order algorithm that solves this reformulation by leveraging a linear minimization oracle (LMO). We further develop semi-closed form solutions (up to a scalar) for three specific LMOs, corresponding to the Frobenius norm, Kullback-Leibler divergence, and Gelbrich (aka Wasserstein) distance. The analysis includes explicit quantification of these LMOs' regularity conditions, notably the Lipschitz constants of the dual function, which govern the algorithm's convergence performance. Numerical experiments confirm our method's effectiveness in high-dimensional settings, outperforming standard off-the-shelf optimization solvers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.09776v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Shabnam Khodakaramzadeh, Soroosh Shafiee, Gabriel de Albuquerque Gleizer, Peyman Mohajerin Esfahani</dc:creator>
    </item>
    <item>
      <title>On circumcentered direct methods for monotone variational inequality problems</title>
      <link>https://arxiv.org/abs/2506.17814</link>
      <description>arXiv:2506.17814v2 Announce Type: replace 
Abstract: Circumcentered techniques have been shown to significantly accelerate projection-based methods for convex feasibility problems. Motivated by this success, we propose two direct methods with circumcenter acceleration for solving variational inequality problems involving two classes of operators: paramonotone and monotone. Both schemes rely on approximate projections onto separating halfspaces, thereby avoiding computationally expensive exact projections. We establish convergence results for both methods and conduct numerical experiments, demonstrating that the proposed algorithms outperform classical methods, such as the extragradient algorithm, by orders of magnitude in terms of computational time, particularly when the feasible set is a complex intersection of convex sets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.17814v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Roger Behling, Yunier Bello-Cruz, Alfredo Iusem, Di Liu, Luiz-Rafael Santos</dc:creator>
    </item>
    <item>
      <title>Graphon Mean-Field Logit Dynamic: Derivation, Computation, and Applications</title>
      <link>https://arxiv.org/abs/2508.12523</link>
      <description>arXiv:2508.12523v2 Announce Type: replace 
Abstract: We present a graphon mean-field logit dynamic, a stationary mean-field game based on logit interactions. This dynamic emerges from a stochastic control problem involving a continuum of nonexchangeable and interacting agents and reduces to solving a continuum of Hamilton-Jacobi-Bellman (HJB) equations connected through a graphon that models the connections among agents. Using a fixed-point argument, we prove that this HJB system admits a unique solution in the space of bounded functions when the discount rate is high (i.e., agents are myopic). Under certain assumptions, we also establish regularity properties of the system, such as equi-continuity. We propose a finite difference scheme for computing the HJB system and prove the uniqueness and existence of its numerical solutions. The mean-field logit dynamic is applied to a case study on inland fisheries resource management in the upper Tedori River of Japan. A series of computational cases are then conducted to investigate the dependence of the dynamic on both the discount rate and graphon.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.12523v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>H. Yoshioka</dc:creator>
    </item>
    <item>
      <title>Predictability Enables Parallelization of Nonlinear State Space Models</title>
      <link>https://arxiv.org/abs/2508.16817</link>
      <description>arXiv:2508.16817v4 Announce Type: replace 
Abstract: The rise of parallel computing hardware has made it increasingly important to understand which nonlinear state space models can be efficiently parallelized. Recent advances like DEER (arXiv:2309.12252) and DeepPCR (arXiv:2309.16318) recast sequential evaluation as a parallelizable optimization problem, sometimes yielding dramatic speedups. However, the factors governing the difficulty of these optimization problems remained unclear, limiting broader adoption. In this work, we establish a precise relationship between a system's dynamics and the conditioning of its corresponding optimization problem, as measured by its Polyak-Lojasiewicz (PL) constant. We show that the predictability of a system, defined as the degree to which small perturbations in state influence future behavior and quantified by the largest Lyapunov exponent (LLE), impacts the number of optimization steps required for evaluation. For predictable systems, the state trajectory can be computed in at worst $O((\log T)^2)$ time, where $T$ is the sequence length: a major improvement over the conventional sequential approach. In contrast, chaotic or unpredictable systems exhibit poor conditioning, with the consequence that parallel evaluation converges too slowly to be useful. Importantly, our theoretical analysis shows that predictable systems always yield well-conditioned optimization problems, whereas unpredictable systems lead to severe conditioning degradation. We validate our claims through extensive experiments, providing practical guidance on when nonlinear dynamical systems can be efficiently parallelized. We highlight predictability as a key design principle for parallelizable models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.16817v4</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.DS</category>
      <category>stat.ML</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xavier Gonzalez, Leo Kozachkov, David M. Zoltowski, Kenneth L. Clarkson, Scott W. Linderman</dc:creator>
    </item>
    <item>
      <title>Collaborative-Online-Learning-Enabled Distributionally Robust Motion Control for Multi-Robot Systems</title>
      <link>https://arxiv.org/abs/2508.17173</link>
      <description>arXiv:2508.17173v2 Announce Type: replace 
Abstract: This paper develops a novel COllaborative-Online-Learning (COOL)-enabled motion control framework for multi-robot systems to avoid collision amid randomly moving obstacles whose motion distributions are partially observable through decentralized data streams. To address the notable challenge of data acquisition due to occlusion, a COOL approach based on the Dirichlet process mixture model is proposed to efficiently extract motion distribution information by exchanging among robots selected learning structures. By leveraging the fine-grained local-moment information learned through COOL, a data-stream-driven ambiguity set for obstacle motion is constructed. We then introduce a novel ambiguity set propagation method, which theoretically admits the derivation of the ambiguity sets for obstacle positions over the entire prediction horizon by utilizing obstacle current positions and the ambiguity set for obstacle motion. Additionally, we develop a compression scheme with its safety guarantee to automatically adjust the complexity and granularity of the ambiguity set by aggregating basic ambiguity sets that are close in a measure space, thereby striking an attractive trade-off between control performance and computation time. Then the probabilistic collision-free trajectories are generated through distributionally robust optimization problems. The distributionally robust obstacle avoidance constraints based on the compressed ambiguity set are equivalently reformulated by deriving separating hyperplanes through tractable semi-definite programming. Finally, we establish the probabilistic collision avoidance guarantee and the long-term tracking performance guarantee for the proposed framework. The numerical simulations are used to demonstrate the efficacy and superiority of the proposed approach compared with state-of-the-art methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.17173v2</guid>
      <category>math.OC</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chao Ning, Han Wang, Longyan Li, Yang Shi</dc:creator>
    </item>
    <item>
      <title>Improving Online-to-Nonconvex Conversion for Smooth Optimization via Double Optimism</title>
      <link>https://arxiv.org/abs/2510.03167</link>
      <description>arXiv:2510.03167v3 Announce Type: replace 
Abstract: A recent breakthrough in nonconvex optimization is the online-to-nonconvex conversion framework of [Cutkosky et al., 2023], which reformulates the task of finding an $\varepsilon$-first-order stationary point as an online learning problem. When both the gradient and the Hessian are Lipschitz continuous, instantiating this framework with two different online learners achieves a complexity of $O(\varepsilon^{-1.75}\log(1/\varepsilon))$ in the deterministic case and a complexity of $O(\varepsilon^{-3.5})$ in the stochastic case. However, this approach suffers from several limitations: (i) the deterministic method relies on a complex double-loop scheme that solves a fixed-point equation to construct hint vectors for an optimistic online learner, introducing an extra logarithmic factor; (ii) the stochastic method assumes a bounded second-order moment of the stochastic gradient, which is stronger than standard variance bounds; and (iii) different online learning algorithms are used in the two settings. In this paper, we address these issues by introducing an online optimistic gradient method based on a novel doubly optimistic hint function. Specifically, we use the gradient at an extrapolated point as the hint, motivated by two optimistic assumptions: that the difference between the hint and the target gradient remains near constant, and that consecutive update directions change slowly due to smoothness. Our method eliminates the need for a double loop and removes the logarithmic factor. Furthermore, by simply replacing full gradients with stochastic gradients and under the standard assumption that their variance is bounded by $\sigma^2$, we obtain a unified algorithm with complexity $O(\varepsilon^{-1.75} + \sigma^2 \varepsilon^{-3.5})$, smoothly interpolating between the best-known deterministic rate and the optimal stochastic rate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.03167v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Francisco Patitucci, Ruichen Jiang, Aryan Mokhtari</dc:creator>
    </item>
    <item>
      <title>Decentralized Optimization over Time-Varying Row-Stochastic Digraphs</title>
      <link>https://arxiv.org/abs/2512.24483</link>
      <description>arXiv:2512.24483v2 Announce Type: replace 
Abstract: Decentralized optimization over directed graphs is essential for applications such as robotic swarms, sensor networks, and distributed learning. In many practical scenarios, the underlying network takes the form of a Time-Varying Broadcast Network (TVBN), where only row-stochastic mixing matrices can be constructed due to the unavailability of out-degree information. Achieving exact convergence for decentralized optimization over TVBNs has remained a long-standing open problem, as the limiting distribution of time-varying row-stochastic mixing matrices depends on unpredictable future graph realizations, rendering standard bias-correction techniques infeasible. This paper develops the first decentralized optimization algorithm that achieves exact convergence using only time-varying row-stochastic matrices. We first propose PULM (Pull-with-Memory), a gossip protocol that achieves average consensus with exponential convergence by alternating between row-stochastic mixing and local adjustment steps. Building on PULM, we develop PULM-DGD, which converges to a stationary solution at a rate of $\mathcal{O}(\ln(T)/T)$ for smooth nonconvex objectives, where $T$ denotes the communication round. Our results significantly broaden the applicability of decentralized optimization to highly dynamic communication environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.24483v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Liyuan Liang, Yilong Song, Kun Yuan</dc:creator>
    </item>
    <item>
      <title>Asymptotically tight Lagrangian dual of smooth nonconvex problems via improved error bound of Shapley-Folkman Lemma</title>
      <link>https://arxiv.org/abs/2601.19003</link>
      <description>arXiv:2601.19003v2 Announce Type: replace 
Abstract: In convex geometry, the Shapley-Folkman Lemma asserts that the nonconvexity of a Minkowski sum of $n$ dimensional bounded nonconvex sets does not accumulate once the number of summands exceeds the dimension $n$, and thus the sum becomes approximately convex. Originally published by Starr in the context of quasi-equilibrium in nonconvex market models in economics, the lemma has since found widespread use in optimization, particularly for estimating the duality gap of the Lagrangian dual of separable nonconvex problems. Given its foundational nature, we pose the following geometric question: Is it possible for the nonconvexity of the Minkowski sum of $n$-dimensional nonconvex sets to even diminish instead of just not accumulating as the number of summands increases, under some general conditions? We answer this affirmatively. First, we provide an elementary geometric proof of the Shapley-Folkman Lemma based on the facial structure of the convex hull of each set. This leads to refinement of the classical error bound derived from the lemma. Building on this new geometric perspective, we further show that when most of the sets satisfy a certain local smoothness condition which naturally arises in the epigraphs of smooth functions, their Minkowski sum converges directly to a convex set, with a vanishing nonconvexity measure. In optimization, this implies that the Lagrangian dual of block-structured smooth nonconvex problems with potentially additional sparsity constraints is asymptotically tight under mild assumptions, which contracts nonvanishing duality gap obtained via classical Shapley-Folkman Lemma.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.19003v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Santanu S Dey, Jingye Xu</dc:creator>
    </item>
    <item>
      <title>Adaptive Accelerated Gradient Descent Methods for Convex Optimization</title>
      <link>https://arxiv.org/abs/2601.19013</link>
      <description>arXiv:2601.19013v2 Announce Type: replace 
Abstract: This work proposes A$^2$GD, a novel adaptive accelerated gradient descent method for convex and composite optimization. Smoothness and convexity constants are updated via Lyapunov analysis. Inspired by stability analysis in ODE solvers, the method triggers line search only when accumulated perturbations become positive, thereby reducing gradient evaluations while preserving strong convergence guarantees. By integrating adaptive step size and momentum acceleration, A$^2$GD outperforms existing first-order methods across a range of problem settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.19013v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zeyi Xu, Long Chen</dc:creator>
    </item>
    <item>
      <title>On the Analysis of Misspecified Variational Inequalities with Nonlinear Constraints</title>
      <link>https://arxiv.org/abs/2602.00448</link>
      <description>arXiv:2602.00448v2 Announce Type: replace 
Abstract: In this paper, we study a class of misspecified variational inequalities (VIs) where both the monotone operator and nonlinear convex constraints depend on an unknown parameter learned via a secondary VI. Existing data-driven VI methods typically follow a decoupled learn-then-optimize scheme, causing the approximation error from the learning to propagate the main decision-making problem and hinder convergence. We instead consider a simultaneous approach that jointly solves the main and secondary VIs. To efficiently handle nonlinear constraints with parameter misspecification, we propose a single-loop inexact Augmented Lagrangian method that simultaneously updates the primal decision variables, dual multipliers, and the misspecified parameter. The method combines a forward-reflected-backward step with an Augmented Lagrangian penalty, and explicitly handles misspecification on both the operator and constraint functions. Moreover, we introduce a relaxed performance metric based on the Minty VI gap combined with an aggregated infeasibility metric. By proving boundedness of the dual iterates, we establish $\mathcal{O}(1/K)$ ergodic convergence rates for these metrics. Numerical Experiments are provided to showcase the superior performance of our algorithm compared to state-of-the-art methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.00448v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Novel Kumar Dey, Mohammad Mahdi Ahmadi, Erfan Yazdandoost Hamedani, Afrooz Jalilzadeh</dc:creator>
    </item>
    <item>
      <title>Non-Uniform Noise-to-Signal Ratio in the REINFORCE Policy-Gradient Estimator</title>
      <link>https://arxiv.org/abs/2602.01460</link>
      <description>arXiv:2602.01460v2 Announce Type: replace 
Abstract: Policy-gradient methods are widely used in reinforcement learning, yet training often becomes unstable or slows down as learning progresses. We study this phenomenon through the noise-to-signal ratio (NSR) of a policy-gradient estimator, defined as the estimator variance (noise) normalized by the squared norm of the true gradient (signal). Our main result is that, for (i) finite-horizon linear systems with Gaussian policies and linear state-feedback, and (ii) finite-horizon polynomial systems with Gaussian policies and polynomial feedback, the NSR of the REINFORCE estimator can be characterized exactly-either in closed form or via numerical moment-evaluation algorithms-without approximation. For general nonlinear dynamics and expressive policies (including neural policies), we further derive a general upper bound on the variance. These characterizations enable a direct examination of how NSR varies across policy parameters and how it evolves along optimization trajectories (e.g. SGD and Adam). Across a range of examples, we find that the NSR landscape is highly non-uniform and typically increases as the policy approaches an optimum; in some regimes it blows up, which can trigger training instability and policy collapse.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01460v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haoyu Han, Heng Yang</dc:creator>
    </item>
    <item>
      <title>Nonsmooth Optimization with Zeroth Order Comparison Feedback</title>
      <link>https://arxiv.org/abs/2602.05622</link>
      <description>arXiv:2602.05622v2 Announce Type: replace 
Abstract: We study unconstrained optimization problems of nonsmooth, nonconvex Lipschitz functions, using only noisy pairwise comparisons governed by a known link function. Our goal is to compute a $(\delta,\varepsilon)$-Goldstein stationary point. We combine randomized smoothing with a novel unbiased reduction from comparisons to local value differences. By leveraging a Russian-roulette truncation on the Bernoulli-product expansion of the inverse link, we construct an exactly unbiased estimator for directional differences. This estimator has finite expected cost and variance scaling quadratically with the function gap, $\mathcal{O}(B^2)$, under mild conditions. Plugging this into the smoothed gradient identity enables a standard nonconvex SGD analysis, yielding explicit comparison-complexity bounds for common symmetric links such as logistic, probit, and cauchit.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.05622v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Taha El Bakkali, El Mahdi Chayti, Omar Saadi</dc:creator>
    </item>
    <item>
      <title>Optimization of the L1 norm of the solution of a Fisher-KPP equations in the small diffusivity regime</title>
      <link>https://arxiv.org/abs/2112.02876</link>
      <description>arXiv:2112.02876v2 Announce Type: replace-cross 
Abstract: We investigate in the present paper the maximization problem for the L1 norm of the unique positive solution of an heterogeneous Fisher-KPP equation with respect to the growth rate. It is already known that the BV norms of maximizers of this functional blow up when the diffusivity tends to zero. Here, we first show that the maximizers are always BV. Next, we completely characterize the limit of the maximas of this functional as the diffusivity tends to zero, and we show that one can construct a quasi-maximizer which is periodic, in a sense, and with a BV norm behaving like the inverse of the square root of the diffusivity. Lastly, we prove that along a subsequence of diffusivities, any maximizer is periodic, in a sense.</description>
      <guid isPermaLink="false">oai:arXiv.org:2112.02876v2</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gr\'egoire Nadin (IDP)</dc:creator>
    </item>
    <item>
      <title>Rates of Convergence in the Central Limit Theorem for Markov Chains, with an Application to TD Learning</title>
      <link>https://arxiv.org/abs/2401.15719</link>
      <description>arXiv:2401.15719v4 Announce Type: replace-cross 
Abstract: We prove a non-asymptotic central limit theorem for vector-valued martingale differences using Stein's method, and use Poisson's equation to extend the result to functions of Markov Chains. We then show that these results can be applied to establish a non-asymptotic central limit theorem for Temporal Difference (TD) learning with averaging.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.15719v4</guid>
      <category>math.PR</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>R. Srikant</dc:creator>
    </item>
    <item>
      <title>Joint Optimization of Pattern, Headway, and Fleet Size of Multiple Urban Transit Lines with Perceived Headway Consideration and Passenger Flow Allocation</title>
      <link>https://arxiv.org/abs/2409.19068</link>
      <description>arXiv:2409.19068v3 Announce Type: replace-cross 
Abstract: This study addresses the urban transit pattern design problem, optimizing stop sequences, headways, and fleet sizes across multiple routes and periods simultaneously to minimize user costs (composed of riding, waiting, and transfer times) under operational constraints (e.g., vehicle capacity and fleet size). A destination-labeled multi-commodity network flow (MCNF) formulation is developed to solve the problem at a large scale more efficiently compared to the previous literature. The model allows for flexible pattern options without relying on pre-defined candidate sets and simultaneously considers multiple operational strategies such as express/local services, short-turning, and deadheading. It evaluates perceived headways of joint patterns for passengers, assigns passenger flows to each pattern accordingly, and allows transfers across patterns in different directions. The mixed-integer linear programming (MILP) model is demonstrated with a city-sized network of metro lines in Chicago, IL, USA, achieving near-optimal solutions in hours. The total weighted journey times are reduced by 0.61% and 5.76% under single-route and multi-period multi-route scenarios respectively. The model provides transit agencies with an efficient tool for comprehensive service design and resource allocation, improving service quality and resource utilization without additional operational costs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19068v3</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Max T. M. Ng, Draco Tong, Hani S. Mahmassani, Omer Verbas, Taner Cokyasar</dc:creator>
    </item>
    <item>
      <title>The Oracle Complexity of Simplex-based Matrix Games</title>
      <link>https://arxiv.org/abs/2412.06990</link>
      <description>arXiv:2412.06990v4 Announce Type: replace-cross 
Abstract: We study the problem of solving matrix games of the form $\min_{\mathbf{p}\in\Delta}\max_{\mathbf{w}\in\mathcal{W}}\mathbf{p}^{\top}A\mathbf{w}$, where $A$ is a matrix and $\Delta$ is the probability simplex. This problem encapsulates canonical tasks such as finding a linear separator and computing Nash equilibria in zero-sum games. However, perhaps surprisingly, its inherent complexity (as formalized in the standard framework of oracle complexity) is not well understood. In this work, we first identify different oracle models that are implicitly used by prior algorithms, corresponding to multiplying the matrix $A$ by a vector from either one or both sides. We then prove complexity lower bounds for algorithms under both access models, which in particular imply a separation between them. As our main result, we prove that in the general $\ell_p$/simplex setting where $\mathcal{W}$ is an $\ell_p$ ball for $p\in[1,\infty]$, any algorithm that utilizes two-sided matrix-vector multiplications requires $\tilde{\Omega}(\epsilon^{-2/3})$ iterations to return an $\epsilon$-suboptimal solution. For any $p\in[1,\infty]$, this is either the first lower bound for such problems, or an exponential improvement over the previously best-known results. Moreover, for the canonical tasks of finding a linear separator and computing a Nash equilibrium, our lower bounds match (up to log factors) recent algorithms of Karmarkar, O'Carroll and Sidford (2026), thereby resolving their oracle complexities in a natural setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06990v4</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guy Kornowski, Ohad Shamir</dc:creator>
    </item>
    <item>
      <title>Solving Optimal Execution Problems via In-Context Operator Networks</title>
      <link>https://arxiv.org/abs/2501.15106</link>
      <description>arXiv:2501.15106v2 Announce Type: replace-cross 
Abstract: We propose a novel transformer-based neural network architecture (ICON-OCnet) for solving optimal order execution problems in the presence of unknown price impact. Our architecture facilitates data-driven in-context operator learning for the incurred price impact by merging offline pre-training with online few-shot prompting inference. First, the operator learning component (ICON) learns the prevailing price impact environment from only a few executed trade and price impact trajectories (time series data) provided as context. Second, we employ ICON as a surrogate operator to train a neural network policy (OCnet) for the optimal order execution strategy for the price impact regime inferred from the in-context examples. We study the efficiency of our approach for linear propagator models with path-dependent transient price impact and explicitly known optimal execution strategies. In this model class, price impact persists and decays over time according to some propagator kernel. We illustrate that ICON is capable of accurately inferring the underlying price impact model from the data prompts, even for propagator kernels not seen in the training data. Moreover, we demonstrate that ICON-OCnet correctly retrieves the exact optimal order execution strategy for the model generating the in-context examples. Our introduced methodology is very general, offering a new approach to solving path-dependent optimal stochastic control problems sample-based with unknown state dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.15106v2</guid>
      <category>q-fin.TR</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>q-fin.CP</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tingwei Meng, Moritz Vo{\ss}, Nils Detering, Giulio Farolfi, Stanley Osher, Georg Menz</dc:creator>
    </item>
    <item>
      <title>Meta-reinforcement learning with minimum attention</title>
      <link>https://arxiv.org/abs/2505.16741</link>
      <description>arXiv:2505.16741v3 Announce Type: replace-cross 
Abstract: Minimum attention applies the least action principle in the changes of control concerning state and time, first proposed by Brockett. The involved regularization is highly relevant in emulating biological control, such as motor learning. We apply minimum attention in reinforcement learning (RL) as part of the rewards and investigate its connection to meta-learning and stabilization. Specifically, model-based meta-learning with minimum attention is explored in high-dimensional nonlinear dynamics. Ensemble-based model learning and gradient-based meta-policy learning are alternately performed. Empirically, the minimum attention does show outperforming competence in comparison to the state-of-the-art algorithms of model-free and model-based RL, i.e., fast adaptation in few shots and variance reduction from the perturbations of the model and environment. Furthermore, the minimum attention demonstrates an improvement in energy efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.16741v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Shashank Gupta, Pilhwa Lee</dc:creator>
    </item>
    <item>
      <title>HiFo-Prompt: Prompting with Hindsight and Foresight for LLM-based Automatic Heuristic Design</title>
      <link>https://arxiv.org/abs/2508.13333</link>
      <description>arXiv:2508.13333v2 Announce Type: replace-cross 
Abstract: LLM-based Automatic Heuristic Design (AHD) within Evolutionary Computation (EC) frameworks has shown promising results. However, its effectiveness is hindered by the use of static operators and the lack of knowledge accumulation mechanisms. We introduce HiFo-Prompt, a framework that guides LLMs with two synergistic prompting strategies: Foresight and Hindsight. Foresight-based prompts adaptively steer the search based on population dynamics, managing the exploration-exploitation trade-off. In addition, hindsight-based prompts mimic human expertise by distilling successful heuristics from past generations into fundamental, reusable design principles. This dual mechanism transforms transient discoveries into a persistent knowledge base, enabling the LLM to learn from its own experience. Empirical results demonstrate that HiFo-Prompt significantly outperforms state-of-the-art LLM-based AHD methods, generating higher-quality heuristics while achieving substantially faster convergence and superior query efficiency. Our code is available at https://github.com/Challenger-XJTU/HiFo-Prompt.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.13333v2</guid>
      <category>cs.AI</category>
      <category>cs.NE</category>
      <category>math.OC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chentong Chen, Mengyuan Zhong, Ye Fan, Jialong Shi, Jianyong Sun</dc:creator>
    </item>
    <item>
      <title>Probabilistic Control Barrier Functions: Safety in Probability for Discrete-Time Stochastic Systems</title>
      <link>https://arxiv.org/abs/2510.01501</link>
      <description>arXiv:2510.01501v2 Announce Type: replace-cross 
Abstract: Control systems operating in the real world face countless sources of unpredictable uncertainties. These random disturbances can render deterministic guarantees inapplicable and cause catastrophic safety failures. To overcome this, this paper proposes a method for designing safe controllers for discrete-time stochastic systems that retain probabilistic guarantees of safety. To do this we modify the traditional notion of a control barrier function (CBF) to explicitly account for these stochastic uncertainties and call these new modified functions probabilistic CBFs. We show that probabilistic CBFs can be used to design controllers that guarantee safety over a finite number of time steps with a prescribed probability. Next, by leveraging various uncertainty quantification methods, such as concentration inequalities and the scenario approach, we provide a variety of sufficient conditions that result in computationally tractable controllers with tunable probabilistic guarantees across a plethora of practical scenarios. Finally, we showcase the applicability of our results in simulation and hardware for the control of a quadruped robot.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01501v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pol Mestres, Blake Werner, Ryan K. Cosner, Aaron D. Ames</dc:creator>
    </item>
    <item>
      <title>Fast and robust parametric and functional learning with Hybrid Genetic Optimisation (HyGO)</title>
      <link>https://arxiv.org/abs/2510.09391</link>
      <description>arXiv:2510.09391v2 Announce Type: replace-cross 
Abstract: The Hybrid Genetic Optimisation framework (HYGO) is introduced to meet the pressing need for efficient and unified optimisation frameworks that support both parametric and functional learning in complex engineering problems. Evolutionary algorithms are widely employed as derivative-free global optimisation methods but often suffer from slow convergence rates, especially during late-stage learning. HYGO integrates the global exploration capabilities of evolutionary algorithms with accelerated local search for robust solution refinement. The key enabler is a two-stage strategy that balances exploration and exploitation. For parametric problems, HYGO alternates between genetic algorithm and targeted improvement through a degeneracy-proof Dowhill Simplex Method (DSM). For function optimisation tasks, HYGO rotates between genetic programming and DSM. Validation is performed on (a) parametric optimisation benchmarks, where HYGO demonstrates faster and more robust convergence than standard genetic algorithms, and (b) function optimisation tasks, including control of a damped Landau oscillator. Practical relevance is showcased through aerodynamic drag reduction of an Ahmed body via Reynolds-Averaged Navier-Stokes simulations, achieving consistently interpretable results and reductions exceeding 20% by controlled jet injection in the back of the body for flow reattachment and separation bubble reduction. Overall, HYGO emerges as a versatile hybrid optimisation framework suitable for a broad spectrum of engineering and scientific problems involving parametric and functional learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.09391v2</guid>
      <category>cs.NE</category>
      <category>math.OC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Isaac Robledo, Yiqing Li, Guy Y. Cornejo Maceda, Rodrigo Castellanos</dc:creator>
    </item>
    <item>
      <title>Reducing base drag on road vehicles using pulsed jets optimized by hybrid genetic algorithms</title>
      <link>https://arxiv.org/abs/2510.26718</link>
      <description>arXiv:2510.26718v2 Announce Type: replace-cross 
Abstract: Aerodynamic drag on flat-backed vehicles like vans and trucks is dominated by a low-pressure wake, whose control is critical for reducing fuel consumption. This paper presents an experimental study at $Re_W\approx 78,300$ on active flow control using four pulsed jets at the rear edges of a bluff body model. A hybrid genetic algorithm, combining a global search with a local gradient-based optimizer, was used to determine the best-performing jet actuation parameters in an experiment-in-the-loop setup. The cost function was designed to achieve a net energy saving by simultaneously minimizing aerodynamic drag and penalizing the actuation's energy consumption. The optimization campaign successfully identified a control strategy that yields a drag reduction of approximately 8.8%. The best-performing control law features a strong, low-frequency actuation from the bottom jet, which targets the main vortex shedding, while the top and lateral jets address higher-frequency, less energetic phenomena. Particle Image Velocimetry analysis reveals a significant upward shift and stabilization of the wake, leading to substantial pressure recovery on the model's lower base. Ultimately, this work demonstrates that a model-free optimization approach can successfully identify non-intuitive, multi-faceted actuation strategies that yield significant and energetically efficient drag reduction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.26718v2</guid>
      <category>physics.flu-dyn</category>
      <category>cs.NE</category>
      <category>math.OC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Isaac Robledo, Juan Alfaro, V\'ictor Duro, Alberto Solera-Rico, Rodrigo Castellanos, Carlos Sanmiguel Vila</dc:creator>
    </item>
    <item>
      <title>When Indemnity Insurance Fails: Parametric Coverage under Binding Budget and Risk Constraints</title>
      <link>https://arxiv.org/abs/2512.21973</link>
      <description>arXiv:2512.21973v5 Announce Type: replace-cross 
Abstract: In high-risk environments, traditional indemnity insurance is often unaffordable or ineffective, despite its well-known optimality under expected utility. We compare excess-of-loss indemnity insurance with parametric insurance within a common mean-variance framework, allowing for fixed costs, heterogeneous premium loadings, and binding budget constraints. Motivated by the disaster insurance and risk-sharing literature, we show that, once these realistic frictions are introduced, parametric insurance can yield higher welfare for risk-averse individuals, even under the same utility objective and without relying on behavioral assumptions. The welfare advantage arises precisely when indemnity insurance becomes impractical, and disappears once both contracts are unconstrained. Our results help reconcile classical insurance theory with the growing use of parametric risk transfer in high-risk settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.21973v5</guid>
      <category>econ.GN</category>
      <category>math.OC</category>
      <category>q-fin.EC</category>
      <category>q-fin.RM</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Benjamin Avanzi, Debbie Kusch Falden, Mogens Steffensen</dc:creator>
    </item>
    <item>
      <title>Calibrated Multi-Level Quantile Forecasting</title>
      <link>https://arxiv.org/abs/2512.23671</link>
      <description>arXiv:2512.23671v2 Announce Type: replace-cross 
Abstract: We develop an online method that guarantees calibration of quantile forecasts at multiple quantile levels simultaneously. In this work, a sequence of quantile forecasts is said to be calibrated provided that its $\alpha$-level predictions are greater than or equal to the target value at an $\alpha$ fraction of time steps, for each level $\alpha$. Our procedure, called the multi-level quantile tracker (MultiQT), is lightweight and wraps around any point or quantile forecaster to produce adjusted quantile forecasts that are guaranteed to be calibrated, even against adversarial distribution shifts. Critically, it does so while ensuring that the quantiles remain ordered, e.g., the 0.5-level quantile forecast will never be larger than the 0.6-level forecast. Moreover, the method has a no-regret guarantee, implying it will not degrade the performance of the existing forecaster (asymptotically), with respect to the quantile loss. In our experiments, we find that MultiQT significantly improves the calibration of real forecasters in epidemic and energy forecasting problems, while leaving the quantile loss largely unchanged or slightly improved.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.23671v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ME</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tiffany Ding, Isaac Gibbs, Ryan J. Tibshirani</dc:creator>
    </item>
    <item>
      <title>Boundary adaptive observer design for semilinear hyperbolic rolling contact ODE-PDE systems with uncertain friction</title>
      <link>https://arxiv.org/abs/2601.09223</link>
      <description>arXiv:2601.09223v2 Announce Type: replace-cross 
Abstract: This paper presents an adaptive observer design for semilinear hyperbolic rolling contact ODE-PDE systems with uncertain friction characteristics parameterized by a matrix of unknown coefficients appearing in the nonlinear (and possibly non-smooth) PDE source terms. Under appropriate assumptions of forward completeness and boundary sensing, an adaptive observer is synthesized to simultaneously estimate the lumped and distributed states, as well as the uncertain friction parameters, using only boundary measurements. The observer combines a finite-dimensional parameter estimator with an infinite-dimensional description of the state error dynamics, and achieves exponential convergence under persistent excitation. The effectiveness of the proposed design is demonstrated in simulation by considering a relevant example borrowed from road vehicle dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.09223v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luigi Romano, Ole Morten Aamo, Miroslav Krsti\'c, Jan {\AA}slund, Erik Frisk</dc:creator>
    </item>
    <item>
      <title>Small Gradient Norm Regret for Online Convex Optimization</title>
      <link>https://arxiv.org/abs/2601.13519</link>
      <description>arXiv:2601.13519v3 Announce Type: replace-cross 
Abstract: This paper introduces a new problem-dependent regret measure for online convex optimization with smooth losses. The notion, which we call the $G^\star$ regret, depends on the cumulative squared gradient norm evaluated at the decision in hindsight. We show that the $G^\star$ regret strictly refines the existing $L^\star$ (small loss) regret, and that it can be arbitrarily sharper when the losses have vanishing curvature around the hindsight decision. We establish upper and lower bounds on the $G^\star$ regret and extend our results to dynamic regret and bandit settings. As a byproduct, we refine the existing convergence analysis of stochastic optimization algorithms in the interpolation regime. Some experiments validate our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.13519v3</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Wenzhi Gao, Chang He, Madeleine Udell</dc:creator>
    </item>
    <item>
      <title>Solver-in-the-Loop: MDP-Based Benchmarks for Self-Correction and Behavioral Rationality in Operations Research</title>
      <link>https://arxiv.org/abs/2601.21008</link>
      <description>arXiv:2601.21008v2 Announce Type: replace-cross 
Abstract: Operations Research practitioners routinely debug infeasible models through an iterative process: analyzing Irreducible Infeasible Subsystems (\IIS{}), identifying constraint conflicts, and systematically repairing formulations until feasibility is achieved. Yet existing LLM benchmarks evaluate OR as one-shot translation -- given a problem description, generate solver code -- ignoring this diagnostic loop entirely. We introduce two benchmarks that place the \textbf{solver in the evaluation loop}. \textbf{\ORDebug{}} evaluates iterative self-correction through 5,000+ problems spanning 9 error types; each repair action triggers solver re-execution and \IIS{} recomputation, providing deterministic, verifiable feedback. \textbf{\ORBias{}} evaluates behavioral rationality through 2,000 newsvendor instances (1,000 ID + 1,000 OOD), measuring systematic deviations from closed-form optimal policies. Across 26 models and 12,000+ samples, we find that domain-specific RLVR training enables an 8B model to surpass frontier APIs: 95.3\% vs 86.2\% recovery rate (+9.1\%), 62.4\% vs 47.8\% diagnostic accuracy (+14.6\%), and 2.25 vs 3.78 steps to resolution (1.7$\times$ faster). On \ORBias{}, curriculum training achieves the only negative ID$\rightarrow$OOD bias drift among models evaluated (-9.6\%), reducing systematic bias by 48\% (from 20.0\% to 10.4\%). These results demonstrate that process-level evaluation with verifiable oracles enables targeted training that outperforms scale.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21008v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Tue, 10 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ruicheng Ao, David Simchi-Levi, Xinshang Wang</dc:creator>
    </item>
  </channel>
</rss>
