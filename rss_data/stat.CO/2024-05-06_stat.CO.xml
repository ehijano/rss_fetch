<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.CO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.CO</link>
    <description>stat.CO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.CO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 07 May 2024 04:00:52 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 07 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Permutation time irreversibility in sleep electroencephalograms: Dependence on sleep stage and the effect of equal values</title>
      <link>https://arxiv.org/abs/2405.02802</link>
      <description>arXiv:2405.02802v1 Announce Type: new 
Abstract: Time irreversibility (TIR) refers to the manifestation of nonequilibrium brain activity influenced by various physiological conditions; however, the influence of sleep on electroencephalogram (EEG) TIR has not been sufficiently investigated. In this paper, a comprehensive study on permutation TIR (pTIR) of EEG data under different sleep stages is conducted. Two basic ordinal patterns (i.e., the original and amplitude permutations) are distinguished to simplify sleep EEGs, and then the influences of equal values and forbidden permutation on pTIR are elucidated. To detect pTIR of brain electric signals, 5 groups of EEGs in the awake, stages I, II, III, and rapid eye movement (REM) stages are collected from the public Polysomnographic Database in PhysioNet. Test results suggested that the pTIR of sleep EEGs significantly decreases as the sleep stage increases (p&lt;0.001), with the awake and REM EEGs, demonstrating greater differences than others. Comparative analysis and numerical simulations support the importance of equal values. Distribution of equal states, a simple quantification of amplitude fluctuations, significantly increases with the sleep stage (p&lt;0.001). If these equalities are ignored, incorrect probabilistic differences may arise in the forward-backward and symmetric permutations of TIR, leading to contradictory results; moreover, the ascending and descending orders for symmetric permutations also lead different outcomes in sleep EEGs. Overall, pTIR in sleep EEGs contributes to our understanding of quantitative TIR and classification of sleep EEGs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.02802v1</guid>
      <category>stat.CO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <arxiv:DOI>10.1103/PhysRevE.109.054104</arxiv:DOI>
      <arxiv:journal_reference>Yao, WP. Permutation time irreversibility in sleep electroencephalograms: Dependence on sleep stage and the effect of equal values. Physical Review E, 2024, 109(5): 054104</arxiv:journal_reference>
      <dc:creator>Wenpo Yao</dc:creator>
    </item>
    <item>
      <title>Generalizing Orthogonalization for Models with Non-linearities</title>
      <link>https://arxiv.org/abs/2405.02475</link>
      <description>arXiv:2405.02475v1 Announce Type: cross 
Abstract: The complexity of black-box algorithms can lead to various challenges, including the introduction of biases. These biases present immediate risks in the algorithms' application. It was, for instance, shown that neural networks can deduce racial information solely from a patient's X-ray scan, a task beyond the capability of medical experts. If this fact is not known to the medical expert, automatic decision-making based on this algorithm could lead to prescribing a treatment (purely) based on racial information. While current methodologies allow for the "orthogonalization" or "normalization" of neural networks with respect to such information, existing approaches are grounded in linear models. Our paper advances the discourse by introducing corrections for non-linearities such as ReLU activations. Our approach also encompasses scalar and tensor-valued predictions, facilitating its integration into neural network architectures. Through extensive experiments, we validate our method's effectiveness in safeguarding sensitive data in generalized linear models, normalizing convolutional neural networks for metadata, and rectifying pre-existing embeddings for undesired attributes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.02475v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David R\"ugamer, Chris Kolb, Tobias Weber, Lucas Kook, Thomas Nagler</dc:creator>
    </item>
    <item>
      <title>Modelling Sampling Distributions of Test Statistics with Autograd</title>
      <link>https://arxiv.org/abs/2405.02488</link>
      <description>arXiv:2405.02488v1 Announce Type: cross 
Abstract: Simulation-based inference methods that feature correct conditional coverage of confidence sets based on observations that have been compressed to a scalar test statistic require accurate modelling of either the p-value function or the cumulative distribution function (cdf) of the test statistic. If the model of the cdf, which is typically a deep neural network, is a function of the test statistic then the derivative of the neural network with respect to the test statistic furnishes an approximation of the sampling distribution of the test statistic. We explore whether this approach to modelling conditional 1-dimensional sampling distributions is a viable alternative to the probability density-ratio method, also known as the likelihood-ratio trick. Relatively simple, yet effective, neural network models are used whose predictive uncertainty is quantified through a variety of methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.02488v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>hep-ex</category>
      <category>stat.CO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ali Al Kadhim, Harrison B. Prosper</dc:creator>
    </item>
    <item>
      <title>Unscented Trajectory Optimization</title>
      <link>https://arxiv.org/abs/2405.02753</link>
      <description>arXiv:2405.02753v1 Announce Type: cross 
Abstract: In a nutshell, unscented trajectory optimization is the generation of optimal trajectories through the use of an unscented transform. Although unscented trajectory optimization was introduced by the authors about a decade ago, it is reintroduced in this paper as a special instantiation of tychastic optimal control theory. Tychastic optimal control theory (from \textit{Tyche}, the Greek goddess of chance) avoids the use of a Brownian motion and the resulting It\^{o} calculus even though it uses random variables across the entire spectrum of a problem formulation. This approach circumvents the enormous technical and numerical challenges associated with stochastic trajectory optimization. Furthermore, it is shown how a tychastic optimal control problem that involves nonlinear transformations of the expectation operator can be quickly instantiated using an unscented transform. These nonlinear transformations are particularly useful in managing trajectory dispersions be it associated with path constraints or targeted values of final-time conditions. This paper also presents a systematic and rapid process for formulating and computing the most desirable tychastic trajectory using an unscented transform. Numerical examples are used to illustrate how unscented trajectory optimization may be used for risk reduction and mission recovery caused by uncertainties and failures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.02753v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>I. M. Ross, R. J. Proulx, M. Karpenko</dc:creator>
    </item>
    <item>
      <title>CVXSADes: a stochastic algorithm for constructing optimal exact regression designs with single or multiple objectives</title>
      <link>https://arxiv.org/abs/2405.02983</link>
      <description>arXiv:2405.02983v1 Announce Type: cross 
Abstract: We propose an algorithm to construct optimal exact designs (EDs). Most of the work in the optimal regression design literature focuses on the approximate design (AD) paradigm due to its desired properties, including the optimality verification conditions derived by Kiefer (1959, 1974). ADs may have unbalanced weights, and practitioners may have difficulty implementing them with a designated run size $n$. Some EDs are constructed using rounding methods to get an integer number of runs at each support point of an AD, but this approach may not yield optimal results. To construct EDs, one may need to perform new combinatorial constructions for each $n$, and there is no unified approach to construct them. Therefore, we develop a systematic way to construct EDs for any given $n$. Our method can transform ADs into EDs while retaining high statistical efficiency in two steps. The first step involves constructing an AD by utilizing the convex nature of many design criteria. The second step employs a simulated annealing algorithm to search for the ED stochastically. Through several applications, we demonstrate the utility of our method for various design problems. Additionally, we show that the design efficiency approaches unity as the number of design points increases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.02983v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chi-Kuang Yeh, Julie Zhou</dc:creator>
    </item>
    <item>
      <title>Functional Post-Clustering Selective Inference with Applications to EHR Data Analysis</title>
      <link>https://arxiv.org/abs/2405.03042</link>
      <description>arXiv:2405.03042v1 Announce Type: cross 
Abstract: In electronic health records (EHR) analysis, clustering patients according to patterns in their data is crucial for uncovering new subtypes of diseases. Existing medical literature often relies on classical hypothesis testing methods to test for differences in means between these clusters. Due to selection bias induced by clustering algorithms, the implementation of these classical methods on post-clustering data often leads to an inflated type-I error. In this paper, we introduce a new statistical approach that adjusts for this bias when analyzing data collected over time. Our method extends classical selective inference methods for cross-sectional data to longitudinal data. We provide theoretical guarantees for our approach with upper bounds on the selective type-I and type-II errors. We apply the method to simulated data and real-world Acute Kidney Injury (AKI) EHR datasets, thereby illustrating the advantages of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03042v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Zihan Zhu, Xin Gai, Anru R. Zhang</dc:creator>
    </item>
    <item>
      <title>Reversibility of elliptical slice sampling revisited</title>
      <link>https://arxiv.org/abs/2301.02426</link>
      <description>arXiv:2301.02426v2 Announce Type: replace-cross 
Abstract: We extend elliptical slice sampling, a Markov chain transition kernel suggested in Murray, Adams and MacKay 2010, to infinite-dimensional separable Hilbert spaces and discuss its well-definedness. We point to a regularity requirement, provide an alternative proof of the desirable reversibility property and show that it induces a positive semi-definite Markov operator. Crucial within the proof of the formerly mentioned results is the analysis of a shrinkage Markov chain that may be interesting on its own.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.02426v2</guid>
      <category>math.ST</category>
      <category>cs.LG</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mareike Hasenpflug, Viacheslav Telezhnikov, Daniel Rudolf</dc:creator>
    </item>
  </channel>
</rss>
